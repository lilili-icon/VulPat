17,61,CVE-2017-7616,0,"unsigned int mempolicy_slab_node(void){	struct mempolicy *policy;	int node = numa_mem_id();	if (in_interrupt())		return node;	policy = current->mempolicy;	if (!policy || policy->flags & MPOL_F_LOCAL)		return node;	switch (policy->mode) {	case MPOL_PREFERRED:		 		return policy->v.preferred_node;	case MPOL_INTERLEAVE:		return interleave_nodes(policy);	case MPOL_BIND: {		struct zoneref *z;		 		struct zonelist *zonelist;		enum zone_type highest_zoneidx = gfp_zone(GFP_KERNEL);		zonelist = &NODE_DATA(node)->node_zonelists[ZONELIST_FALLBACK];		z = first_zones_zonelist(zonelist, highest_zoneidx,							&policy->v.nodes);		return z->zone ? z->zone->node : node;	}	default:		BUG();	}}",21525
11,63,CVE-2017-7616,0,"int mpol_misplaced(struct page *page, struct vm_area_struct *vma, unsigned long addr){	struct mempolicy *pol;	struct zoneref *z;	int curnid = page_to_nid(page);	unsigned long pgoff;	int thiscpu = raw_smp_processor_id();	int thisnid = cpu_to_node(thiscpu);	int polnid = -1;	int ret = -1;	BUG_ON(!vma);	pol = get_vma_policy(vma, addr);	if (!(pol->flags & MPOL_F_MOF))		goto out;	switch (pol->mode) {	case MPOL_INTERLEAVE:		BUG_ON(addr >= vma->vm_end);		BUG_ON(addr < vma->vm_start);		pgoff = vma->vm_pgoff;		pgoff += (addr - vma->vm_start) >> PAGE_SHIFT;		polnid = offset_il_node(pol, vma, pgoff);		break;	case MPOL_PREFERRED:		if (pol->flags & MPOL_F_LOCAL)			polnid = numa_node_id();		else			polnid = pol->v.preferred_node;		break;	case MPOL_BIND:		 		if (node_isset(curnid, pol->v.nodes))			goto out;		z = first_zones_zonelist(				node_zonelist(numa_node_id(), GFP_HIGHUSER),				gfp_zone(GFP_HIGHUSER),				&pol->v.nodes);		polnid = z->zone->node;		break;	default:		BUG();	}	 	if (pol->flags & MPOL_F_MORON) {		polnid = thisnid;		if (!should_numa_migrate_memory(current, page, curnid, thiscpu))			goto out;	}	if (curnid != polnid)		ret = polnid;out:	mpol_cond_put(pol);	return ret;}",21527
23,30,CVE-2016-9588,0,static inline void vm_entry_controls_reset_shadow(struct vcpu_vmx *vmx){	vmx->vm_entry_controls_shadow = vmcs_read32(VM_ENTRY_CONTROLS);},15142
22,62,CVE-2017-7616,0,"static void migrate_page_add(struct page *page, struct list_head *pagelist,				unsigned long flags){	 	if ((flags & MPOL_MF_MOVE_ALL) || page_mapcount(page) == 1) {		if (!isolate_lru_page(page)) {			list_add_tail(&page->lru, pagelist);			inc_node_page_state(page, NR_ISOLATED_ANON +					    page_is_file_cache(page));		}	}}",21526
21,70,CVE-2017-7616,0,"static struct page *new_page(struct page *page, unsigned long start, int **x){	return NULL;}",21534
15,51,CVE-2017-8072,0,"static int cp2112_gpio_irq_type(struct irq_data *d, unsigned int type){	return 0;}",21292
0,24,CVE-2016-9588,0,"static inline void nested_release_vmcs12(struct vcpu_vmx *vmx){	if (vmx->nested.current_vmptr == -1ull)		return;	 	if (WARN_ON(vmx->nested.current_vmcs12 == NULL))		return;	if (enable_shadow_vmcs) {		 		copy_shadow_to_vmcs12(vmx);		vmx->nested.sync_shadow_vmcs = false;		vmcs_clear_bits(SECONDARY_VM_EXEC_CONTROL,				SECONDARY_EXEC_SHADOW_VMCS);		vmcs_write64(VMCS_LINK_POINTER, -1ull);	}	vmx->nested.posted_intr_nv = -1;	 	memcpy(vmx->nested.current_vmcs12, vmx->nested.cached_vmcs12,	       VMCS12_SIZE);	kunmap(vmx->nested.current_vmcs12_page);	nested_release_page(vmx->nested.current_vmcs12_page);	vmx->nested.current_vmptr = -1ull;	vmx->nested.current_vmcs12 = NULL;}",15136
3,82,CVE-2017-5577,0,"vc4_free_hang_state(struct drm_device *dev, struct vc4_hang_state *state){	unsigned int i;	for (i = 0; i < state->user_state.bo_count; i++)		drm_gem_object_unreference_unlocked(state->bo[i]);	kfree(state);}",22012
20,73,CVE-2017-7616,0,"static struct sp_node *sp_alloc(unsigned long start, unsigned long end,				struct mempolicy *pol){	struct sp_node *n;	struct mempolicy *newpol;	n = kmem_cache_alloc(sn_cache, GFP_KERNEL);	if (!n)		return NULL;	newpol = mpol_dup(pol);	if (IS_ERR(newpol)) {		kmem_cache_free(sn_cache, n);		return NULL;	}	newpol->flags |= MPOL_F_SHARED;	sp_node_init(n, start, end, newpol);	return n;}",21537
10,16,CVE-2016-9588,0,static int handle_wbinvd(struct kvm_vcpu *vcpu){	return kvm_emulate_wbinvd(vcpu);},15128
25,2,CVE-2016-9588,0,static void free_loaded_vmcs(struct loaded_vmcs *loaded_vmcs){	if (!loaded_vmcs->vmcs)		return;	loaded_vmcs_clear(loaded_vmcs);	free_vmcs(loaded_vmcs->vmcs);	loaded_vmcs->vmcs = NULL;	WARN_ON(loaded_vmcs->shadow_vmcs != NULL);},15114
24,45,CVE-2016-9588,0,"static void vmx_sync_pir_to_irr(struct kvm_vcpu *vcpu){	struct vcpu_vmx *vmx = to_vmx(vcpu);	if (!pi_test_on(&vmx->pi_desc))		return;	pi_clear_on(&vmx->pi_desc);	 	smp_mb__after_atomic();	kvm_apic_update_irr(vcpu, vmx->pi_desc.pir);}",15157
5,79,CVE-2017-7616,0,"static int vma_replace_policy(struct vm_area_struct *vma,						struct mempolicy *pol){	int err;	struct mempolicy *old;	struct mempolicy *new;	pr_debug(""vma %lx-%lx/%lx vm_ops %p vm_file %p set_policy %p\n"",		 vma->vm_start, vma->vm_end, vma->vm_pgoff,		 vma->vm_ops, vma->vm_file,		 vma->vm_ops ? vma->vm_ops->set_policy : NULL);	new = mpol_dup(pol);	if (IS_ERR(new))		return PTR_ERR(new);	if (vma->vm_ops && vma->vm_ops->set_policy) {		err = vma->vm_ops->set_policy(vma, new);		if (err)			goto err_out;	}	old = vma->vm_policy;	vma->vm_policy = new;  	mpol_put(old);	return 0; err_out:	mpol_put(new);	return err;}",21543
7,69,CVE-2017-7616,0,"static struct page *new_page(struct page *page, unsigned long start, int **x){	struct vm_area_struct *vma;	unsigned long uninitialized_var(address);	vma = find_vma(current->mm, start);	while (vma) {		address = page_address_in_vma(page, vma);		if (address != -EFAULT)			break;		vma = vma->vm_next;	}	if (PageHuge(page)) {		BUG_ON(!vma);		return alloc_huge_page_noerr(vma, address, 1);	}	 	return alloc_page_vma(GFP_HIGHUSER_MOVABLE, vma, address);}",21533
8,39,CVE-2016-9588,0,static void vmx_post_block(struct kvm_vcpu *vcpu){	if (kvm_x86_ops->set_hv_timer)		kvm_lapic_switch_to_hv_timer(vcpu);	pi_post_block(vcpu);},15151
18,36,CVE-2016-9588,0,static void vmx_free_vcpu_nested(struct kvm_vcpu *vcpu){       struct vcpu_vmx *vmx = to_vmx(vcpu);       int r;       r = vcpu_load(vcpu);       BUG_ON(r);       vmx_load_vmcs01(vcpu);       free_nested(vmx);       vcpu_put(vcpu);},15148
16,91,CVE-2017-5577,0,"vc4_submit_next_bin_job(struct drm_device *dev){	struct vc4_dev *vc4 = to_vc4_dev(dev);	struct vc4_exec_info *exec;again:	exec = vc4_first_bin_job(vc4);	if (!exec)		return;	vc4_flush_caches(dev);	 	if (exec->ct0ca != exec->ct0ea) {		submit_cl(dev, 0, exec->ct0ca, exec->ct0ea);	} else {		vc4_move_job_to_render(dev, exec);		goto again;	}}",22021
1,11,CVE-2016-9588,0,static int handle_pause(struct kvm_vcpu *vcpu){	if (ple_gap)		grow_ple_window(vcpu);	kvm_vcpu_on_spin(vcpu);	return kvm_skip_emulated_instruction(vcpu);},15123
14,60,CVE-2017-7616,0,"static int lookup_node(unsigned long addr){	struct page *p;	int err;	err = get_user_pages(addr & PAGE_MASK, 1, 0, &p, NULL);	if (err >= 0) {		err = page_to_nid(p);		put_page(p);	}	return err;}",21524
19,98,CVE-2016-3179,0,"containsForbiddenChars(const unsigned char * p, int len){	while(len > 0) {		if(*p < ' ' || *p >= '\x7f')			return 1;		p++;		len--;	}	return 0;}",22833
4,13,CVE-2016-9588,0,"static int handle_set_cr0(struct kvm_vcpu *vcpu, unsigned long val){	if (is_guest_mode(vcpu)) {		struct vmcs12 *vmcs12 = get_vmcs12(vcpu);		unsigned long orig_val = val;		 		val = (val & ~vmcs12->cr0_guest_host_mask) |			(vmcs12->guest_cr0 & vmcs12->cr0_guest_host_mask);		if (!nested_guest_cr0_valid(vcpu, val))			return 1;		if (kvm_set_cr0(vcpu, val))			return 1;		vmcs_writel(CR0_READ_SHADOW, orig_val);		return 0;	} else {		if (to_vmx(vcpu)->nested.vmxon &&		    !nested_host_cr0_valid(vcpu, val))			return 1;		return kvm_set_cr0(vcpu, val);	}}",15125
9,46,CVE-2016-9588,0,"static void vmx_vcpu_pi_load(struct kvm_vcpu *vcpu, int cpu){	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);	struct pi_desc old, new;	unsigned int dest;	if (!kvm_arch_has_assigned_device(vcpu->kvm) ||		!irq_remapping_cap(IRQ_POSTING_CAP)  ||		!kvm_vcpu_apicv_active(vcpu))		return;	do {		old.control = new.control = pi_desc->control;		 		if (pi_desc->nv != POSTED_INTR_WAKEUP_VECTOR) {			if (vcpu->cpu != cpu) {				dest = cpu_physical_id(cpu);				if (x2apic_enabled())					new.ndst = dest;				else					new.ndst = (dest << 8) & 0xFF00;			}			 			new.nv = POSTED_INTR_VECTOR;		}		 		new.sn = 0;	} while (cmpxchg(&pi_desc->control, old.control,			new.control) != old.control);}",15158
6,76,CVE-2017-7616,0,"static void sp_node_init(struct sp_node *node, unsigned long start,			unsigned long end, struct mempolicy *pol){	node->start = start;	node->end = end;	node->policy = pol;}",21540
13,28,CVE-2016-9588,0,"static void pi_post_block(struct kvm_vcpu *vcpu){	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);	struct pi_desc old, new;	unsigned int dest;	unsigned long flags;	if (!kvm_arch_has_assigned_device(vcpu->kvm) ||		!irq_remapping_cap(IRQ_POSTING_CAP)  ||		!kvm_vcpu_apicv_active(vcpu))		return;	do {		old.control = new.control = pi_desc->control;		dest = cpu_physical_id(vcpu->cpu);		if (x2apic_enabled())			new.ndst = dest;		else			new.ndst = (dest << 8) & 0xFF00;		 		new.sn = 0;		 		new.nv = POSTED_INTR_VECTOR;	} while (cmpxchg(&pi_desc->control, old.control,			new.control) != old.control);	if(vcpu->pre_pcpu != -1) {		spin_lock_irqsave(			&per_cpu(blocked_vcpu_on_cpu_lock,			vcpu->pre_pcpu), flags);		list_del(&vcpu->blocked_vcpu_list);		spin_unlock_irqrestore(			&per_cpu(blocked_vcpu_on_cpu_lock,			vcpu->pre_pcpu), flags);		vcpu->pre_pcpu = -1;	}}",15140
2,20,CVE-2016-9588,0,"static void load_vmcs12_host_state(struct kvm_vcpu *vcpu,				   struct vmcs12 *vmcs12){	struct kvm_segment seg;	unsigned long entry_failure_code;	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER)		vcpu->arch.efer = vmcs12->host_ia32_efer;	else if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		vcpu->arch.efer |= (EFER_LMA | EFER_LME);	else		vcpu->arch.efer &= ~(EFER_LMA | EFER_LME);	vmx_set_efer(vcpu, vcpu->arch.efer);	kvm_register_write(vcpu, VCPU_REGS_RSP, vmcs12->host_rsp);	kvm_register_write(vcpu, VCPU_REGS_RIP, vmcs12->host_rip);	vmx_set_rflags(vcpu, X86_EFLAGS_FIXED);	 	vmx_set_cr0(vcpu, vmcs12->host_cr0);	 	update_exception_bitmap(vcpu);	vcpu->arch.cr0_guest_owned_bits = (vcpu->fpu_active ? X86_CR0_TS : 0);	vmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits);	 	vcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK);	kvm_set_cr4(vcpu, vmcs12->host_cr4);	nested_ept_uninit_mmu_context(vcpu);	 	if (nested_vmx_load_cr3(vcpu, vmcs12->host_cr3, false, &entry_failure_code))		nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_PDPTE_FAIL);	if (!enable_ept)		vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;	if (enable_vpid) {		 		vmx_flush_tlb(vcpu);	}	vmcs_write32(GUEST_SYSENTER_CS, vmcs12->host_ia32_sysenter_cs);	vmcs_writel(GUEST_SYSENTER_ESP, vmcs12->host_ia32_sysenter_esp);	vmcs_writel(GUEST_SYSENTER_EIP, vmcs12->host_ia32_sysenter_eip);	vmcs_writel(GUEST_IDTR_BASE, vmcs12->host_idtr_base);	vmcs_writel(GUEST_GDTR_BASE, vmcs12->host_gdtr_base);	 	if (vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS)		vmcs_write64(GUEST_BNDCFGS, 0);	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT) {		vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat);		vcpu->arch.pat = vmcs12->host_ia32_pat;	}	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)		vmcs_write64(GUEST_IA32_PERF_GLOBAL_CTRL,			vmcs12->host_ia32_perf_global_ctrl);	 	seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.selector = vmcs12->host_cs_selector,		.type = 11,		.present = 1,		.s = 1,		.g = 1	};	if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		seg.l = 1;	else		seg.db = 1;	vmx_set_segment(vcpu, &seg, VCPU_SREG_CS);	seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.type = 3,		.present = 1,		.s = 1,		.db = 1,		.g = 1	};	seg.selector = vmcs12->host_ds_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_DS);	seg.selector = vmcs12->host_es_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_ES);	seg.selector = vmcs12->host_ss_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_SS);	seg.selector = vmcs12->host_fs_selector;	seg.base = vmcs12->host_fs_base;	vmx_set_segment(vcpu, &seg, VCPU_SREG_FS);	seg.selector = vmcs12->host_gs_selector;	seg.base = vmcs12->host_gs_base;	vmx_set_segment(vcpu, &seg, VCPU_SREG_GS);	seg = (struct kvm_segment) {		.base = vmcs12->host_tr_base,		.limit = 0x67,		.selector = vmcs12->host_tr_selector,		.type = 11,		.present = 1	};	vmx_set_segment(vcpu, &seg, VCPU_SREG_TR);	kvm_set_dr(vcpu, 7, 0x400);	vmcs_write64(GUEST_IA32_DEBUGCTL, 0);	if (cpu_has_vmx_msr_bitmap())		vmx_set_msr_bitmap(vcpu);	if (nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,				vmcs12->vm_exit_msr_load_count))		nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL);}",15132
12,14,CVE-2016-9588,0,static int handle_vmcall(struct kvm_vcpu *vcpu){	return kvm_emulate_hypercall(vcpu);},15126
18,61,CVE-2012-3520,1,"static int unix_mkname(struct sockaddr_un *sunaddr, int len, unsigned int *hashp){	if (len <= sizeof(short) || len > sizeof(*sunaddr))		return -EINVAL;	if (!sunaddr || sunaddr->sun_family != AF_UNIX)		return -EINVAL;	if (sunaddr->sun_path[0]) {		 		((char *)sunaddr)[len] = 0;		len = strlen(sunaddr->sun_path)+1+sizeof(short);		return len;	}	*hashp = unix_hash_fold(csum_partial(sunaddr, len, 0));	return len;}",2998
3,13,CVE-2012-3520,1,"static void netlink_cmsg_recv_pktinfo(struct msghdr *msg, struct sk_buff *skb){	struct nl_pktinfo info;	info.group = NETLINK_CB(skb).dst_group;	put_cmsg(msg, SOL_NETLINK, NETLINK_PKTINFO, sizeof(info), &info);}",2950
26,2,CVE-2012-3520,1,"int __netlink_change_ngroups(struct sock *sk, unsigned int groups){	struct listeners *new, *old;	struct netlink_table *tbl = &nl_table[sk->sk_protocol];	if (groups < 32)		groups = 32;	if (NLGRPSZ(tbl->groups) < NLGRPSZ(groups)) {		new = kzalloc(sizeof(*new) + NLGRPSZ(groups), GFP_ATOMIC);		if (!new)			return -ENOMEM;		old = rcu_dereference_protected(tbl->listeners, 1);		memcpy(new->masks, old->masks, NLGRPSZ(tbl->groups));		rcu_assign_pointer(tbl->listeners, new);		kfree_rcu(old, rcu);	}	tbl->groups = groups;	return 0;}",2939
23,62,CVE-2012-3520,1,"static inline int unix_our_peer(struct sock *sk, struct sock *osk){	return unix_peer(osk) == sk;}",2999
10,16,CVE-2012-3520,1,"static void netlink_data_ready(struct sock *sk, int len){	BUG();}",2953
0,11,CVE-2012-3520,1,"int netlink_change_ngroups(struct sock *sk, unsigned int groups){	int err;	netlink_table_grab();	err = __netlink_change_ngroups(sk, groups);	netlink_table_ungrab();	return err;}",2948
17,91,CVE-2017-10807,1,static void _c2s_signal(int signum){    c2s_shutdown = 1;    c2s_lost_router = 0;},20606
22,70,CVE-2012-3520,1,"static int unix_scm_to_skb(struct scm_cookie *scm, struct sk_buff *skb, int send_fds){	int err = 0;	UNIXCB(skb).pid  = get_pid(scm->pid);	if (scm->cred)		UNIXCB(skb).cred = get_cred(scm->cred);	UNIXCB(skb).fp = NULL;	if (scm->fp && send_fds)		err = unix_attach_fds(scm, skb);	skb->destructor = unix_destruct_scm;	return err;}",3007
15,51,CVE-2012-3520,1,"static void unix_detach_fds(struct scm_cookie *scm, struct sk_buff *skb){	int i;	scm->fp = UNIXCB(skb).fp;	UNIXCB(skb).fp = NULL;	for (i = scm->fp->count-1; i >= 0; i--)		unix_notinflight(scm->fp->fp[i]);}",2988
21,73,CVE-2012-3520,1,"static void unix_set_peek_off(struct sock *sk, int val){	struct unix_sock *u = unix_sk(sk);	mutex_lock(&u->readlock);	sk->sk_peek_off = val;	mutex_unlock(&u->readlock);}",3010
11,63,CVE-2012-3520,1,long unix_outq_len(struct sock *sk){	return sk_wmem_alloc_get(sk);},3000
24,30,CVE-2012-3520,1,"static int netlink_release(struct socket *sock){	struct sock *sk = sock->sk;	struct netlink_sock *nlk;	if (!sk)		return 0;	netlink_remove(sk);	sock_orphan(sk);	nlk = nlk_sk(sk);	 	sock->sk = NULL;	wake_up_interruptible_all(&nlk->wait);	skb_queue_purge(&sk->sk_write_queue);	if (nlk->pid) {		struct netlink_notify n = {						.net = sock_net(sk),						.protocol = sk->sk_protocol,						.pid = nlk->pid,					  };		atomic_notifier_call_chain(&netlink_chain,				NETLINK_URELEASE, &n);	}	module_put(nlk->module);	netlink_table_grab();	if (netlink_is_kernel(sk)) {		BUG_ON(nl_table[sk->sk_protocol].registered == 0);		if (--nl_table[sk->sk_protocol].registered == 0) {			kfree(nl_table[sk->sk_protocol].listeners);			nl_table[sk->sk_protocol].module = NULL;			nl_table[sk->sk_protocol].registered = 0;		}	} else if (nlk->subscriptions) {		netlink_update_listeners(sk);	}	netlink_table_ungrab();	kfree(nlk->groups);	nlk->groups = NULL;	local_bh_disable();	sock_prot_inuse_add(sock_net(sk), &netlink_proto, -1);	local_bh_enable();	sock_put(sk);	return 0;}",2967
25,45,CVE-2012-3520,1,"static void maybe_add_creds(struct sk_buff *skb, const struct socket *sock,			    const struct sock *other){	if (UNIXCB(skb).cred)		return;	if (test_bit(SOCK_PASSCRED, &sock->flags) ||	    !other->sk_socket ||	    test_bit(SOCK_PASSCRED, &other->sk_socket->flags)) {		UNIXCB(skb).pid  = get_pid(task_tgid(current));		UNIXCB(skb).cred = get_current_cred();	}}",2982
5,76,CVE-2012-3520,1,"static int unix_shutdown(struct socket *sock, int mode){	struct sock *sk = sock->sk;	struct sock *other;	mode = (mode+1)&(RCV_SHUTDOWN|SEND_SHUTDOWN);	if (!mode)		return 0;	unix_state_lock(sk);	sk->sk_shutdown |= mode;	other = unix_peer(sk);	if (other)		sock_hold(other);	unix_state_unlock(sk);	sk->sk_state_change(sk);	if (other &&		(sk->sk_type == SOCK_STREAM || sk->sk_type == SOCK_SEQPACKET)) {		int peer_mode = 0;		if (mode&RCV_SHUTDOWN)			peer_mode |= SEND_SHUTDOWN;		if (mode&SEND_SHUTDOWN)			peer_mode |= RCV_SHUTDOWN;		unix_state_lock(other);		other->sk_shutdown |= peer_mode;		unix_state_unlock(other);		other->sk_state_change(other);		if (peer_mode == SHUTDOWN_MASK)			sk_wake_async(other, SOCK_WAKE_WAITD, POLL_HUP);		else if (peer_mode & RCV_SHUTDOWN)			sk_wake_async(other, SOCK_WAKE_WAITD, POLL_IN);	}	if (other)		sock_put(other);	return 0;}",3013
7,69,CVE-2012-3520,1,static inline void unix_remove_socket(struct sock *sk){	spin_lock(&unix_table_lock);	__unix_remove_socket(sk);	spin_unlock(&unix_table_lock);},3006
8,39,CVE-2012-3520,1,"	__acquires(unix_table_lock){	spin_lock(&unix_table_lock);	if (!*pos)		return SEQ_START_TOKEN;	if (get_bucket(*pos) >= ARRAY_SIZE(unix_socket_table))		return NULL;	return unix_next_socket(seq, NULL, pos);}",2976
20,103,CVE-2013-0910,1,   MockPluginServiceFilter() {},29456
16,94,CVE-2017-10807,1,static void _c2s_signal_usr2(int signum){    set_debug_flag(1);},20609
1,20,CVE-2012-3520,1,struct sock *netlink_getsockbyfilp(struct file *filp){	struct inode *inode = filp->f_path.dentry->d_inode;	struct sock *sock;	if (!S_ISSOCK(inode->i_mode))		return ERR_PTR(-ENOTSOCK);	sock = SOCKET_I(inode)->sk;	if (sock->sk_family != AF_NETLINK)		return ERR_PTR(-EINVAL);	sock_hold(sock);	return sock;},2957
14,60,CVE-2012-3520,1,"static inline int unix_may_send(struct sock *sk, struct sock *osk){	return unix_peer(osk) == NULL || unix_our_peer(sk, osk);}",2997
19,36,CVE-2012-3520,1,"static void netlink_update_socket_mc(struct netlink_sock *nlk,				     unsigned int group,				     int is_new){	int old, new = !!is_new, subscriptions;	old = test_bit(group - 1, nlk->groups);	subscriptions = nlk->subscriptions - old + new;	if (new)		__set_bit(group - 1, nlk->groups);	else		__clear_bit(group - 1, nlk->groups);	netlink_update_subscriptions(&nlk->sk, subscriptions);	netlink_update_listeners(&nlk->sk);}",2973
4,79,CVE-2012-3520,1,"static void unix_state_double_lock(struct sock *sk1, struct sock *sk2){	if (unlikely(sk1 == sk2) || !sk2) {		unix_state_lock(sk1);		return;	}	if (sk1 < sk2) {		unix_state_lock(sk1);		unix_state_lock_nested(sk2);	} else {		unix_state_lock(sk2);		unix_state_lock_nested(sk1);	}}",3016
9,46,CVE-2012-3520,1,"static int unix_accept(struct socket *sock, struct socket *newsock, int flags){	struct sock *sk = sock->sk;	struct sock *tsk;	struct sk_buff *skb;	int err;	err = -EOPNOTSUPP;	if (sock->type != SOCK_STREAM && sock->type != SOCK_SEQPACKET)		goto out;	err = -EINVAL;	if (sk->sk_state != TCP_LISTEN)		goto out;	 	skb = skb_recv_datagram(sk, 0, flags&O_NONBLOCK, &err);	if (!skb) {		 		if (err == 0)			err = -EINVAL;		goto out;	}	tsk = skb->sk;	skb_free_datagram(sk, skb);	wake_up_interruptible(&unix_sk(sk)->peer_wait);	 	unix_state_lock(tsk);	newsock->state = SS_CONNECTED;	sock_graft(tsk, newsock);	unix_state_unlock(tsk);	return 0;out:	return err;}",2983
6,82,CVE-2012-3520,1,"static long unix_wait_for_peer(struct sock *other, long timeo){	struct unix_sock *u = unix_sk(other);	int sched;	DEFINE_WAIT(wait);	prepare_to_wait_exclusive(&u->peer_wait, &wait, TASK_INTERRUPTIBLE);	sched = !sock_flag(other, SOCK_DEAD) &&		!(other->sk_shutdown & RCV_SHUTDOWN) &&		unix_recvq_full(other);	unix_state_unlock(other);	if (sched)		timeo = schedule_timeout(timeo);	finish_wait(&u->peer_wait, &wait);	return timeo;}",3019
13,28,CVE-2012-3520,1,"static int netlink_realloc_groups(struct sock *sk){	struct netlink_sock *nlk = nlk_sk(sk);	unsigned int groups;	unsigned long *new_groups;	int err = 0;	netlink_table_grab();	groups = nl_table[sk->sk_protocol].groups;	if (!nl_table[sk->sk_protocol].registered) {		err = -ENOENT;		goto out_unlock;	}	if (nlk->ngroups >= groups)		goto out_unlock;	new_groups = krealloc(nlk->groups, NLGRPSZ(groups), GFP_ATOMIC);	if (new_groups == NULL) {		err = -ENOMEM;		goto out_unlock;	}	memset((char *)new_groups + NLGRPSZ(nlk->ngroups), 0,	       NLGRPSZ(groups) - NLGRPSZ(nlk->ngroups));	nlk->groups = new_groups;	nlk->ngroups = groups; out_unlock:	netlink_table_ungrab();	return err;}",2965
2,86,CVE-2016-7141,1,"void Curl_nss_cleanup(void){     PR_Lock(nss_initlock);  if(initialized) {         SSL_ClearSessionCache();    if(mod && SECSuccess == SECMOD_UnloadUserModule(mod)) {      SECMOD_DestroyModule(mod);      mod = NULL;    }    NSS_ShutdownContext(nss_context);    nss_context = NULL;  }     Curl_llist_destroy(nss_crl_list, NULL);  nss_crl_list = NULL;  PR_Unlock(nss_initlock);  PR_DestroyLock(nss_initlock);  PR_DestroyLock(nss_crllock);  nss_initlock = NULL;  initialized = 0;}",15854
12,14,CVE-2012-3520,1,"static int netlink_connect(struct socket *sock, struct sockaddr *addr,			   int alen, int flags){	int err = 0;	struct sock *sk = sock->sk;	struct netlink_sock *nlk = nlk_sk(sk);	struct sockaddr_nl *nladdr = (struct sockaddr_nl *)addr;	if (alen < sizeof(addr->sa_family))		return -EINVAL;	if (addr->sa_family == AF_UNSPEC) {		sk->sk_state	= NETLINK_UNCONNECTED;		nlk->dst_pid	= 0;		nlk->dst_group  = 0;		return 0;	}	if (addr->sa_family != AF_NETLINK)		return -EINVAL;	 	if (nladdr->nl_groups && !netlink_capable(sock, NL_NONROOT_SEND))		return -EPERM;	if (!nlk->pid)		err = netlink_autobind(sock);	if (err == 0) {		sk->sk_state	= NETLINK_CONNECTED;		nlk->dst_pid 	= nladdr->nl_pid;		nlk->dst_group  = ffs(nladdr->nl_groups);	}	return err;}",2951
11,877,CVE-2018-12684,18,"get_http_method_info(const char *method){	 	const struct mg_http_method_info *m = http_methods;	while (m->name) {		if (!strcmp(m->name, method)) {			return m;		}		m++;	}	return NULL;}",25044
163,328,CVE-2017-12893,18,"int_unix_date(int dos_date){    struct tm t;    if (dos_date == 0)	return(0);    interpret_dos_date(dos_date, &t);    t.tm_wday = 1;    t.tm_yday = 1;    t.tm_isdst = 0;    return (mktime(&t));}",20281
71,22,CVE-2017-9739,18,  static void  Ins_CEILING( INS_ARG )  { (void)exc;    args[0] = (args[0] + 63) & (-64);  },901
196,826,CVE-2018-16427,18,sc_get_driver(void){	if (iso_ops == NULL)		iso_ops = sc_get_iso7816_driver()->ops;	auth_ops = *iso_ops;	auth_ops.match_card = auth_match_card;	auth_ops.init = auth_init;	auth_ops.finish = auth_finish;	auth_ops.select_file = auth_select_file;	auth_ops.list_files = auth_list_files;	auth_ops.delete_file = auth_delete_file;	auth_ops.create_file = auth_create_file;	auth_ops.read_binary = auth_read_binary;	auth_ops.update_binary = auth_update_binary;	auth_ops.read_record = auth_read_record;	auth_ops.delete_record = auth_delete_record;	auth_ops.card_ctl = auth_card_ctl;	auth_ops.set_security_env = auth_set_security_env;	auth_ops.restore_security_env = auth_restore_security_env;	auth_ops.compute_signature = auth_compute_signature;	auth_ops.decipher = auth_decipher;	auth_ops.process_fci = auth_process_fci;	auth_ops.pin_cmd = auth_pin_cmd;	auth_ops.logout = auth_logout;	auth_ops.check_sw = auth_check_sw;	return &auth_drv;},24353
0,78,CVE-2017-9620,18,"xps_parse_glyph_advance(char *s, float *advance, int bidi_level){    int advance_overridden = false;        if (*s == ',') {        s = xps_parse_real_num(s + 1, advance, &advance_overridden);                 if (advance_overridden && (bidi_level & 1))            *advance *= -1;    }    return s;}",958
106,602,CVE-2016-10197,18,"server_request_free(struct server_request *req){	int i, rc=1, lock=0;	if (req->base.questions) {		for (i = 0; i < req->base.nquestions; ++i)			mm_free(req->base.questions[i]);		mm_free(req->base.questions);	}	if (req->port) {		EVDNS_LOCK(req->port);		lock=1;		if (req->port->pending_replies == req) {			if (req->next_pending && req->next_pending != req)				req->port->pending_replies = req->next_pending;			else				req->port->pending_replies = NULL;		}		rc = --req->port->refcnt;	}	if (req->response) {		mm_free(req->response);	}	server_request_free_answers(req);	if (req->next_pending && req->next_pending != req) {		req->next_pending->prev_pending = req->prev_pending;		req->prev_pending->next_pending = req->next_pending;	}	if (rc == 0) {		EVDNS_UNLOCK(req->port);  		server_port_free(req->port);		mm_free(req);		return (1);	}	if (lock)		EVDNS_UNLOCK(req->port);	mm_free(req);	return (0);}",22421
154,458,CVE-2017-7277,18,"int kernel_accept(struct socket *sock, struct socket **newsock, int flags){	struct sock *sk = sock->sk;	int err;	err = sock_create_lite(sk->sk_family, sk->sk_type, sk->sk_protocol,			       newsock);	if (err < 0)		goto done;	err = sock->ops->accept(sock, *newsock, flags, true);	if (err < 0) {		sock_release(*newsock);		*newsock = NULL;		goto done;	}	(*newsock)->ops = sock->ops;	__module_get((*newsock)->ops->owner);done:	return err;}",21768
61,324,CVE-2017-12902,18,"str_to_lower(const char *string){    char *zb_string;    strncpy(z_buf, string, sizeof(z_buf));    z_buf[sizeof(z_buf)-1] = '\0';    zb_string = z_buf;    while (*zb_string) {	*zb_string = tolower((unsigned char)(*zb_string));	zb_string++;    }    return z_buf;}",20277
118,961,CVE-2018-20854,18,"static int serdes_set_mode(struct phy *phy, enum phy_mode mode){	struct serdes_macro *macro = phy_get_drvdata(phy);	unsigned int i;	int ret;	for (i = 0; i < ARRAY_SIZE(ocelot_serdes_muxes); i++) {		if (macro->idx != ocelot_serdes_muxes[i].idx ||		    mode != ocelot_serdes_muxes[i].mode)			continue;		if (mode != PHY_MODE_QSGMII &&		    macro->port != ocelot_serdes_muxes[i].port)			continue;		ret = regmap_update_bits(macro->ctrl->regs, HSIO_HW_CFG,					 ocelot_serdes_muxes[i].mask,					 ocelot_serdes_muxes[i].mux);		if (ret)			return ret;		if (macro->idx <= SERDES1G_MAX)			return serdes_init_s1g(macro->ctrl->regs, macro->idx);		 		return -EOPNOTSUPP;	}	return -EINVAL;}",27604
87,654,CVE-2018-18445,18,"static int check_func_call(struct bpf_verifier_env *env, struct bpf_insn *insn,			   int *insn_idx){	struct bpf_verifier_state *state = env->cur_state;	struct bpf_func_state *caller, *callee;	int i, subprog, target_insn;	if (state->curframe + 1 >= MAX_CALL_FRAMES) {		verbose(env, ""the call stack of %d frames is too deep\n"",			state->curframe + 2);		return -E2BIG;	}	target_insn = *insn_idx + insn->imm;	subprog = find_subprog(env, target_insn + 1);	if (subprog < 0) {		verbose(env, ""verifier bug. No program starts at insn %d\n"",			target_insn + 1);		return -EFAULT;	}	caller = state->frame[state->curframe];	if (state->frame[state->curframe + 1]) {		verbose(env, ""verifier bug. Frame %d already allocated\n"",			state->curframe + 1);		return -EFAULT;	}	callee = kzalloc(sizeof(*callee), GFP_KERNEL);	if (!callee)		return -ENOMEM;	state->frame[state->curframe + 1] = callee;	 	init_func_state(env, callee,			 			*insn_idx  ,			state->curframe + 1  ,			subprog  );	 	for (i = BPF_REG_1; i <= BPF_REG_5; i++)		callee->regs[i] = caller->regs[i];	 	for (i = 0; i < CALLER_SAVED_REGS; i++) {		mark_reg_not_init(env, caller->regs, caller_saved[i]);		check_reg_arg(env, caller_saved[i], DST_OP_NO_MARK);	}	 	state->curframe++;	 	*insn_idx = target_insn;	if (env->log.level) {		verbose(env, ""caller:\n"");		print_verifier_state(env, caller);		verbose(env, ""callee:\n"");		print_verifier_state(env, callee);	}	return 0;}",23500
50,721,CVE-2018-16427,18,static struct sc_card_driver * sc_get_driver(void){	if (iso_ops == NULL)		iso_ops = sc_get_iso7816_driver()->ops;	asepcos_ops = *iso_ops;	asepcos_ops.match_card        = asepcos_match_card;	asepcos_ops.init              = asepcos_init;	asepcos_ops.select_file       = asepcos_select_file;	asepcos_ops.set_security_env  = asepcos_set_security_env;	asepcos_ops.decipher          = asepcos_decipher;	asepcos_ops.compute_signature = asepcos_compute_signature;	asepcos_ops.create_file       = asepcos_create_file;	asepcos_ops.delete_file       = asepcos_delete_file;	asepcos_ops.list_files        = asepcos_list_files;	asepcos_ops.card_ctl          = asepcos_card_ctl;	asepcos_ops.pin_cmd           = asepcos_pin_cmd;	asepcos_ops.card_reader_lock_obtained = asepcos_card_reader_lock_obtained;	return &asepcos_drv;},24248
128,274,CVE-2017-16529,18,"static int snd_usb_audio_create(struct usb_interface *intf,				struct usb_device *dev, int idx,				const struct snd_usb_audio_quirk *quirk,				unsigned int usb_id,				struct snd_usb_audio **rchip){	struct snd_card *card;	struct snd_usb_audio *chip;	int err, len;	char component[14];	static struct snd_device_ops ops = {		.dev_free =	snd_usb_audio_dev_free,	};	*rchip = NULL;	switch (snd_usb_get_speed(dev)) {	case USB_SPEED_LOW:	case USB_SPEED_FULL:	case USB_SPEED_HIGH:	case USB_SPEED_WIRELESS:	case USB_SPEED_SUPER:	case USB_SPEED_SUPER_PLUS:		break;	default:		dev_err(&dev->dev, ""unknown device speed %d\n"", snd_usb_get_speed(dev));		return -ENXIO;	}	err = snd_card_new(&intf->dev, index[idx], id[idx], THIS_MODULE,			   0, &card);	if (err < 0) {		dev_err(&dev->dev, ""cannot create card instance %d\n"", idx);		return err;	}	chip = kzalloc(sizeof(*chip), GFP_KERNEL);	if (! chip) {		snd_card_free(card);		return -ENOMEM;	}	mutex_init(&chip->mutex);	init_waitqueue_head(&chip->shutdown_wait);	chip->index = idx;	chip->dev = dev;	chip->card = card;	chip->setup = device_setup[idx];	chip->autoclock = autoclock;	atomic_set(&chip->active, 1);  	atomic_set(&chip->usage_count, 0);	atomic_set(&chip->shutdown, 0);	chip->usb_id = usb_id;	INIT_LIST_HEAD(&chip->pcm_list);	INIT_LIST_HEAD(&chip->ep_list);	INIT_LIST_HEAD(&chip->midi_list);	INIT_LIST_HEAD(&chip->mixer_list);	if ((err = snd_device_new(card, SNDRV_DEV_LOWLEVEL, chip, &ops)) < 0) {		snd_usb_audio_free(chip);		snd_card_free(card);		return err;	}	strcpy(card->driver, ""USB-Audio"");	sprintf(component, ""USB%04x:%04x"",		USB_ID_VENDOR(chip->usb_id), USB_ID_PRODUCT(chip->usb_id));	snd_component_add(card, component);	 	if (quirk && quirk->product_name && *quirk->product_name) {		strlcpy(card->shortname, quirk->product_name, sizeof(card->shortname));	} else {		if (!dev->descriptor.iProduct ||		    usb_string(dev, dev->descriptor.iProduct,		    card->shortname, sizeof(card->shortname)) <= 0) {			 			sprintf(card->shortname, ""USB Device %#04x:%#04x"",				USB_ID_VENDOR(chip->usb_id),				USB_ID_PRODUCT(chip->usb_id));		}	}	strim(card->shortname);	 	if (quirk && quirk->vendor_name && *quirk->vendor_name) {		len = strlcpy(card->longname, quirk->vendor_name, sizeof(card->longname));	} else {		if (dev->descriptor.iManufacturer)			len = usb_string(dev, dev->descriptor.iManufacturer,					 card->longname, sizeof(card->longname));		else			len = 0;		 	}	if (len > 0) {		strim(card->longname);		if (*card->longname)			strlcat(card->longname, "" "", sizeof(card->longname));	}	strlcat(card->longname, card->shortname, sizeof(card->longname));	len = strlcat(card->longname, "" at "", sizeof(card->longname));	if (len < sizeof(card->longname))		usb_make_path(dev, card->longname + len, sizeof(card->longname) - len);	switch (snd_usb_get_speed(dev)) {	case USB_SPEED_LOW:		strlcat(card->longname, "", low speed"", sizeof(card->longname));		break;	case USB_SPEED_FULL:		strlcat(card->longname, "", full speed"", sizeof(card->longname));		break;	case USB_SPEED_HIGH:		strlcat(card->longname, "", high speed"", sizeof(card->longname));		break;	case USB_SPEED_SUPER:		strlcat(card->longname, "", super speed"", sizeof(card->longname));		break;	case USB_SPEED_SUPER_PLUS:		strlcat(card->longname, "", super speed plus"", sizeof(card->longname));		break;	default:		break;	}	snd_usb_audio_create_proc(chip);	*rchip = chip;	return 0;}",19806
162,875,CVE-2018-12684,18,fc(struct mg_context *ctx){	static struct mg_connection fake_connection;	fake_connection.phys_ctx = ctx;	fake_connection.dom_ctx = &(ctx->dd);	return &fake_connection;},25042
212,943,CVE-2018-10360,18,"do_note_freebsd_version(struct magic_set *ms, int swap, void *v){	int desc;	memcpy(&desc, v, sizeof(desc));	desc = elf_getu32(swap, desc);	if (file_printf(ms, "", for FreeBSD"") == -1)		return;	 	if (desc == 460002) {		if (file_printf(ms, "" 4.6.2"") == -1)			return;	} else if (desc < 460100) {		if (file_printf(ms, "" %d.%d"", desc / 100000,		    desc / 10000 % 10) == -1)			return;		if (desc / 1000 % 10 > 0)			if (file_printf(ms, "".%d"", desc / 1000 % 10) == -1)				return;		if ((desc % 1000 > 0) || (desc % 100000 == 0))			if (file_printf(ms, "" (%d)"", desc) == -1)				return;	} else if (desc < 500000) {		if (file_printf(ms, "" %d.%d"", desc / 100000,		    desc / 10000 % 10 + desc / 1000 % 10) == -1)			return;		if (desc / 100 % 10 > 0) {			if (file_printf(ms, "" (%d)"", desc) == -1)				return;		} else if (desc / 10 % 10 > 0) {			if (file_printf(ms, "".%d"", desc / 10 % 10) == -1)				return;		}	} else {		if (file_printf(ms, "" %d.%d"", desc / 100000,		    desc / 1000 % 100) == -1)			return;		if ((desc / 100 % 10 > 0) ||		    (desc % 100000 / 100 == 0)) {			if (file_printf(ms, "" (%d)"", desc) == -1)				return;		} else if (desc / 10 % 10 > 0) {			if (file_printf(ms, "".%d"", desc / 10 % 10) == -1)				return;		}	}}",25222
184,334,CVE-2017-11664,18,"static void _WM_CheckEventMemoryPool(struct _mdi *mdi) {    if ((mdi->event_count + 1) >= mdi->events_size) {        mdi->events_size += MEM_CHUNK;        mdi->events = realloc(mdi->events,                              (mdi->events_size * sizeof(struct _event)));    }}",20467
95,835,CVE-2018-16427,18,"static unsigned int to_sec_attr(unsigned int method, unsigned int key_ref){	if (method == SC_AC_NEVER || method == SC_AC_NONE)		return method;	if (method == SC_AC_CHV  &&  (key_ref == 1 || key_ref == 2))		return key_ref;	return 0;}",24362
74,144,CVE-2016-9539,18,"static void initDumpOptions(struct dump_opts *dump)  {  dump->debug  = 0;  dump->format = DUMP_NONE;  dump->level  = 1;  sprintf (dump->mode, ""w"");  memset (dump->infilename, '\0', PATH_MAX + 1);  memset (dump->outfilename, '\0',PATH_MAX + 1);  dump->infile = NULL;  dump->outfile = NULL;  }",15185
200,837,CVE-2018-16427,18,struct sc_card_driver *sc_get_setcos_driver(void){	return sc_get_driver();},24364
258,782,CVE-2018-16427,18,"iasecc_logout(struct sc_card *card){	struct sc_context *ctx = card->ctx;	struct sc_path path;	int rv;	LOG_FUNC_CALLED(ctx);	if (!card->ef_atr || !card->ef_atr->aid.len)		return SC_SUCCESS;	memset(&path, 0, sizeof(struct sc_path));	path.type = SC_PATH_TYPE_DF_NAME;	memcpy(path.value, card->ef_atr->aid.value, card->ef_atr->aid.len);	path.len = card->ef_atr->aid.len;	rv = iasecc_select_file(card, &path, NULL);	sc_log(ctx, ""Select ECC ROOT with the AID from EF.ATR: rv %i"", rv);	LOG_FUNC_RETURN(ctx, rv);}",24309
219,151,CVE-2016-7917,18,int nfnetlink_subsys_unregister(const struct nfnetlink_subsystem *n){	nfnl_lock(n->subsys_id);	table[n->subsys_id].subsys = NULL;	nfnl_unlock(n->subsys_id);	synchronize_rcu();	return 0;},15592
182,145,CVE-2016-9539,18,initImageData (struct image_data *image)  {  image->xres = 0.0;  image->yres = 0.0;  image->width = 0;  image->length = 0;  image->res_unit = RESUNIT_NONE;  image->bps = 0;  image->spp = 0;  image->planar = 0;  image->photometric = 0;  image->orientation = 0;  image->compression = COMPRESSION_NONE;  image->adjustments = 0;  },15186
242,687,CVE-2018-18445,18,"static int regsafe(struct bpf_reg_state *rold, struct bpf_reg_state *rcur,		    struct idpair *idmap){	int equal;	if (!(rold->live & REG_LIVE_READ))		 		return true;	equal = memcmp(rold, rcur, offsetof(struct bpf_reg_state, frameno)) == 0;	if (rold->type == PTR_TO_STACK)		 		return equal && rold->frameno == rcur->frameno;	if (equal)		return true;	if (rold->type == NOT_INIT)		 		return true;	if (rcur->type == NOT_INIT)		return false;	switch (rold->type) {	case SCALAR_VALUE:		if (rcur->type == SCALAR_VALUE) {			 			return range_within(rold, rcur) &&			       tnum_in(rold->var_off, rcur->var_off);		} else {			 			return false;		}	case PTR_TO_MAP_VALUE:		 		return memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)) == 0 &&		       range_within(rold, rcur) &&		       tnum_in(rold->var_off, rcur->var_off);	case PTR_TO_MAP_VALUE_OR_NULL:		 		if (rcur->type != PTR_TO_MAP_VALUE_OR_NULL)			return false;		if (memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)))			return false;		 		return check_ids(rold->id, rcur->id, idmap);	case PTR_TO_PACKET_META:	case PTR_TO_PACKET:		if (rcur->type != rold->type)			return false;		 		if (rold->range > rcur->range)			return false;		 		if (rold->off != rcur->off)			return false;		 		if (rold->id && !check_ids(rold->id, rcur->id, idmap))			return false;		 		return range_within(rold, rcur) &&		       tnum_in(rold->var_off, rcur->var_off);	case PTR_TO_CTX:	case CONST_PTR_TO_MAP:	case PTR_TO_PACKET_END:		 	default:		 		return false;	}	 	WARN_ON_ONCE(1);	return false;}",23533
190,997,CVE-2019-5770,18,int BytesPerElement(int type) {  switch (type) {    case GL_FLOAT_32_UNSIGNED_INT_24_8_REV:      return 8;    case GL_FLOAT:    case GL_UNSIGNED_INT_24_8_OES:    case GL_UNSIGNED_INT:    case GL_INT:    case GL_UNSIGNED_INT_2_10_10_10_REV:    case GL_UNSIGNED_INT_10F_11F_11F_REV:    case GL_UNSIGNED_INT_5_9_9_9_REV:      return 4;    case GL_HALF_FLOAT:    case GL_HALF_FLOAT_OES:    case GL_UNSIGNED_SHORT:    case GL_SHORT:    case GL_UNSIGNED_SHORT_5_6_5:    case GL_UNSIGNED_SHORT_4_4_4_4:    case GL_UNSIGNED_SHORT_5_5_5_1:      return 2;    case GL_UNSIGNED_BYTE:    case GL_BYTE:      return 1;    default:      return 0;  }},30226
185,452,CVE-2017-7277,18,"int skb_to_sgvec_nomark(struct sk_buff *skb, struct scatterlist *sg,			int offset, int len){	return __skb_to_sgvec(skb, sg, offset, len);}",21762
56,407,CVE-2017-9985,18,"static int snd_msnd_mpu401_open(struct snd_mpu401 *mpu){	snd_msnd_enable_irq(mpu->private_data);	snd_msnd_send_dsp_cmd(mpu->private_data, HDEX_MIDI_IN_START);	return 0;}",20696
101,446,CVE-2017-7277,18,"unsigned char *skb_pull_rcsum(struct sk_buff *skb, unsigned int len){	unsigned char *data = skb->data;	BUG_ON(len > skb->len);	__skb_pull(skb, len);	skb_postpull_rcsum(skb, data, len);	return skb->data;}",21756
135,956,CVE-2019-8906,18,"do_note_freebsd_version(struct magic_set *ms, int swap, void *v){	int desc;	memcpy(&desc, v, sizeof(desc));	desc = elf_getu32(swap, desc);	if (file_printf(ms, "", for FreeBSD"") == -1)		return;	 	if (desc == 460002) {		if (file_printf(ms, "" 4.6.2"") == -1)			return;	} else if (desc < 460100) {		if (file_printf(ms, "" %d.%d"", desc / 100000,		    desc / 10000 % 10) == -1)			return;		if (desc / 1000 % 10 > 0)			if (file_printf(ms, "".%d"", desc / 1000 % 10) == -1)				return;		if ((desc % 1000 > 0) || (desc % 100000 == 0))			if (file_printf(ms, "" (%d)"", desc) == -1)				return;	} else if (desc < 500000) {		if (file_printf(ms, "" %d.%d"", desc / 100000,		    desc / 10000 % 10 + desc / 1000 % 10) == -1)			return;		if (desc / 100 % 10 > 0) {			if (file_printf(ms, "" (%d)"", desc) == -1)				return;		} else if (desc / 10 % 10 > 0) {			if (file_printf(ms, "".%d"", desc / 10 % 10) == -1)				return;		}	} else {		if (file_printf(ms, "" %d.%d"", desc / 100000,		    desc / 1000 % 100) == -1)			return;		if ((desc / 100 % 10 > 0) ||		    (desc % 100000 / 100 == 0)) {			if (file_printf(ms, "" (%d)"", desc) == -1)				return;		} else if (desc / 10 % 10 > 0) {			if (file_printf(ms, "".%d"", desc / 10 % 10) == -1)				return;		}	}}",27289
172,289,CVE-2017-14166,18,"add_link(struct archive_read *a, struct xar *xar, struct xar_file *file){	struct hdlink *hdlink;	for (hdlink = xar->hdlink_list; hdlink != NULL; hdlink = hdlink->next) {		if (hdlink->id == file->link) {			file->hdnext = hdlink->files;			hdlink->cnt++;			hdlink->files = file;			return (ARCHIVE_OK);		}	}	hdlink = malloc(sizeof(*hdlink));	if (hdlink == NULL) {		archive_set_error(&a->archive, ENOMEM, ""Out of memory"");		return (ARCHIVE_FATAL);	}	file->hdnext = NULL;	hdlink->id = file->link;	hdlink->cnt = 1;	hdlink->files = file;	hdlink->next = xar->hdlink_list;	xar->hdlink_list = hdlink;	return (ARCHIVE_OK);}",20162
230,57,CVE-2017-9739,18,"  static void  Ins_SFVTL( INS_ARG )  {    if ( INS_SxVTL( (Int)(args[1]),                    (Int)(args[0]),                    CUR.opcode,                    &CUR.GS.freeVector) == FAILURE )      return;    COMPUTE_Funcs();  }",936
1,495,CVE-2017-5601,18,"lzh_decode_init(struct lzh_stream *strm, const char *method){	struct lzh_dec *ds;	int w_bits, w_size;	if (strm->ds == NULL) {		strm->ds = calloc(1, sizeof(*strm->ds));		if (strm->ds == NULL)			return (ARCHIVE_FATAL);	}	ds = strm->ds;	ds->error = ARCHIVE_FAILED;	if (method == NULL || method[0] != 'l' || method[1] != 'h')		return (ARCHIVE_FAILED);	switch (method[2]) {	case '5':		w_bits = 13; 		break;	case '6':		w_bits = 15; 		break;	case '7':		w_bits = 16; 		break;	default:		return (ARCHIVE_FAILED); 	}	ds->error = ARCHIVE_FATAL;	 	ds->w_size = 1U << 17;	ds->w_mask = ds->w_size -1;	if (ds->w_buff == NULL) {		ds->w_buff = malloc(ds->w_size);		if (ds->w_buff == NULL)			return (ARCHIVE_FATAL);	}	w_size = 1U << w_bits;	memset(ds->w_buff + ds->w_size - w_size, 0x20, w_size);	ds->w_pos = 0;	ds->state = 0;	ds->pos_pt_len_size = w_bits + 1;	ds->pos_pt_len_bits = (w_bits == 15 || w_bits == 16)? 5: 4;	ds->literal_pt_len_size = PT_BITLEN_SIZE;	ds->literal_pt_len_bits = 5;	ds->br.cache_buffer = 0;	ds->br.cache_avail = 0;	if (lzh_huffman_init(&(ds->lt), LT_BITLEN_SIZE, 16)	    != ARCHIVE_OK)		return (ARCHIVE_FATAL);	ds->lt.len_bits = 9;	if (lzh_huffman_init(&(ds->pt), PT_BITLEN_SIZE, 16)	    != ARCHIVE_OK)		return (ARCHIVE_FATAL);	ds->error = 0;	return (ARCHIVE_OK);}",22000
64,644,CVE-2018-18445,18,"static int add_subprog(struct bpf_verifier_env *env, int off){	int insn_cnt = env->prog->len;	int ret;	if (off >= insn_cnt || off < 0) {		verbose(env, ""call to invalid destination\n"");		return -EINVAL;	}	ret = find_subprog(env, off);	if (ret >= 0)		return 0;	if (env->subprog_cnt >= BPF_MAX_SUBPROGS) {		verbose(env, ""too many subprograms\n"");		return -E2BIG;	}	env->subprog_info[env->subprog_cnt++].start = off;	sort(env->subprog_info, env->subprog_cnt,	     sizeof(env->subprog_info[0]), cmp_subprogs, NULL);	return 0;}",23490
170,549,CVE-2016-10197,18,evdns_count_nameservers(void){	return evdns_base_count_nameservers(current_base);},22368
12,497,CVE-2017-5601,18,"lzh_make_fake_table(struct huffman *hf, int c){	if (c >= hf->len_size)		return (0);	hf->tbl[0] = c;	hf->max_bits = 0;	hf->shift_bits = 0;	hf->bitlen[hf->tbl[0]] = 0;	return (1);}",22002
262,414,CVE-2017-9074,18,"static struct sk_buff **ip4ip6_gro_receive(struct sk_buff **head,					   struct sk_buff *skb){	 	if (NAPI_GRO_CB(skb)->encap_mark) {		NAPI_GRO_CB(skb)->flush = 1;		return NULL;	}	NAPI_GRO_CB(skb)->encap_mark = 1;	return inet_gro_receive(head, skb);}",20878
125,928,CVE-2018-11363,18,void pdf_clear_err(struct pdf_doc *pdf){    if (!pdf)        return;    pdf->errstr[0] = '\0';    pdf->errval = 0;},25188
111,443,CVE-2017-7277,18,static void skb_free_head(struct sk_buff *skb){	unsigned char *head = skb->head;	if (skb->head_frag)		skb_free_frag(head);	else		kfree(head);},21753
171,295,CVE-2017-14166,18,"file_new(struct archive_read *a, struct xar *xar, struct xmlattr_list *list){	struct xar_file *file;	struct xmlattr *attr;	file = calloc(1, sizeof(*file));	if (file == NULL) {		archive_set_error(&a->archive, ENOMEM, ""Out of memory"");		return (ARCHIVE_FATAL);	}	file->parent = xar->file;	file->mode = 0777 | AE_IFREG;	file->atime = time(NULL);	file->mtime = time(NULL);	xar->file = file;	xar->xattr = NULL;	for (attr = list->first; attr != NULL; attr = attr->next) {		if (strcmp(attr->name, ""id"") == 0)			file->id = atol10(attr->value, strlen(attr->value));	}	file->nlink = 1;	if (heap_add_entry(a, &(xar->file_queue), file) != ARCHIVE_OK)		return (ARCHIVE_FATAL);	return (ARCHIVE_OK);}",20168
7,784,CVE-2018-16427,18,"iasecc_oberthur_match(struct sc_card *card){	struct sc_context *ctx = card->ctx;	unsigned char *hist = card->reader->atr_info.hist_bytes;	LOG_FUNC_CALLED(ctx);	if (*hist != 0x80 || ((*(hist+1)&0xF0) != 0xF0))		LOG_FUNC_RETURN(ctx, SC_ERROR_OBJECT_NOT_FOUND);	sc_log_hex(ctx, ""AID in historical_bytes"", hist + 2, *(hist+1) & 0x0F);	if (memcmp(hist + 2, OberthurIASECC_AID.value, *(hist+1) & 0x0F))		LOG_FUNC_RETURN(ctx, SC_ERROR_RECORD_NOT_FOUND);	if (!card->ef_atr)		card->ef_atr = calloc(1, sizeof(struct sc_ef_atr));	if (!card->ef_atr)		LOG_FUNC_RETURN(ctx, SC_ERROR_OUT_OF_MEMORY);	memcpy(card->ef_atr->aid.value, OberthurIASECC_AID.value, OberthurIASECC_AID.len);	card->ef_atr->aid.len = OberthurIASECC_AID.len;	LOG_FUNC_RETURN(ctx, SC_SUCCESS);}",24311
181,871,CVE-2018-12684,18,"event_signal(void *eventhdl){	int u = 1;	int evhdl, s;	if (!eventhdl) {		 		return 0;	}	evhdl = *(int *)eventhdl;	s = (int)write(evhdl, &u, sizeof(u));	if (s != sizeof(u)) {		 		return 0;	}	return 1;}",25038
249,276,CVE-2017-16529,18,int snd_usb_autoresume(struct snd_usb_audio *chip){	if (atomic_read(&chip->shutdown))		return -EIO;	if (atomic_inc_return(&chip->active) == 1)		return usb_autopm_get_interface(chip->pm_intf);	return 0;},19808
153,373,CVE-2017-11664,18,"static int midi_setup_copyright(struct _mdi *mdi, char * text) {    MIDI_EVENT_SDEBUG(__FUNCTION__,0, text);    strip_text(text);    _WM_CheckEventMemoryPool(mdi);    mdi->events[mdi->event_count].do_event = *_WM_do_meta_copyright;    mdi->events[mdi->event_count].event_data.channel = 0;    mdi->events[mdi->event_count].event_data.data.string = text;    mdi->events[mdi->event_count].samples_to_next = 0;    mdi->event_count++;    return (0);}",20506
114,125,CVE-2017-2633,18,"void vnc_start_worker_thread(void){    VncJobQueue *q;    if (vnc_worker_thread_running())        return ;    q = vnc_queue_init();    qemu_thread_create(&q->thread, vnc_worker_thread, q, QEMU_THREAD_DETACHED);    queue = q;  }",2592
191,52,CVE-2017-9739,18,  static void  Ins_POP( INS_ARG )  { (void)exc; (void)args;       },931
224,2,CVE-2018-20102,18,"int dns_link_resolution(void *requester, int requester_type, int requester_locked){	struct dns_resolution *res = NULL;	struct dns_requester  *req;	struct dns_resolvers  *resolvers;	struct server         *srv   = NULL;	struct dns_srvrq      *srvrq = NULL;	char **hostname_dn;	int   hostname_dn_len, query_type;	switch (requester_type) {		case OBJ_TYPE_SERVER:			srv             = (struct server *)requester;			hostname_dn     = &srv->hostname_dn;			hostname_dn_len = srv->hostname_dn_len;			resolvers       = srv->resolvers;			query_type      = ((srv->dns_opts.family_prio == AF_INET)					   ? DNS_RTYPE_A					   : DNS_RTYPE_AAAA);			break;		case OBJ_TYPE_SRVRQ:			srvrq           = (struct dns_srvrq *)requester;			hostname_dn     = &srvrq->hostname_dn;			hostname_dn_len = srvrq->hostname_dn_len;			resolvers       = srvrq->resolvers;			query_type      = DNS_RTYPE_SRV;			break;		default:			goto err;	}	 	if ((res = dns_pick_resolution(resolvers, hostname_dn, hostname_dn_len, query_type)) == NULL)		goto err;	if (srv) {		if (!requester_locked)			HA_SPIN_LOCK(SERVER_LOCK, &srv->lock);		if (srv->dns_requester == NULL) {			if ((req = calloc(1, sizeof(*req))) == NULL) {				if (!requester_locked)					HA_SPIN_UNLOCK(SERVER_LOCK, &srv->lock);				goto err;			}			req->owner         = &srv->obj_type;			srv->dns_requester = req;		}		else			req = srv->dns_requester;		if (!requester_locked)			HA_SPIN_UNLOCK(SERVER_LOCK, &srv->lock);	}	else if (srvrq) {		if (srvrq->dns_requester == NULL) {			if ((req = calloc(1, sizeof(*req))) == NULL)				goto err;			req->owner           = &srvrq->obj_type;			srvrq->dns_requester = req;		}		else			req = srvrq->dns_requester;	}	else		goto err;	req->resolution         = res;	req->requester_cb       = snr_resolution_cb;	req->requester_error_cb = snr_resolution_error_cb;	LIST_ADDQ(&res->requesters, &req->list);	return 0;  err:	if (res && LIST_ISEMPTY(&res->requesters))		dns_free_resolution(res);	return -1;}",111
214,383,CVE-2017-11664,18,"static int midi_setup_sequenceno(struct _mdi *mdi, int setting) {    MIDI_EVENT_DEBUG(__FUNCTION__,0, setting);    _WM_CheckEventMemoryPool(mdi);    mdi->events[mdi->event_count].do_event = *_WM_do_meta_sequenceno;    mdi->events[mdi->event_count].event_data.channel = 0;    mdi->events[mdi->event_count].event_data.data.value = setting;    mdi->events[mdi->event_count].samples_to_next = 0;    mdi->event_count++;    return (0);}",20516
254,488,CVE-2017-5601,18,"lha_read_file_header_0(struct archive_read *a, struct lha *lha){	const unsigned char *p;	int extdsize, namelen;	unsigned char headersum, sum_calculated;	if ((p = __archive_read_ahead(a, H0_FIXED_SIZE, NULL)) == NULL)		return (truncated_error(a));	lha->header_size = p[H0_HEADER_SIZE_OFFSET] + 2;	headersum = p[H0_HEADER_SUM_OFFSET];	lha->compsize = archive_le32dec(p + H0_COMP_SIZE_OFFSET);	lha->origsize = archive_le32dec(p + H0_ORIG_SIZE_OFFSET);	lha->mtime = lha_dos_time(p + H0_DOS_TIME_OFFSET);	namelen = p[H0_NAME_LEN_OFFSET];	extdsize = (int)lha->header_size - H0_FIXED_SIZE - namelen;	if ((namelen > 221 || extdsize < 0) && extdsize != -2) {		archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,		    ""Invalid LHa header"");		return (ARCHIVE_FATAL);	}	if ((p = __archive_read_ahead(a, lha->header_size, NULL)) == NULL)		return (truncated_error(a));	archive_strncpy(&lha->filename, p + H0_FILE_NAME_OFFSET, namelen);	 	if (extdsize >= 0) {		lha->crc = archive_le16dec(p + H0_FILE_NAME_OFFSET + namelen);		lha->setflag |= CRC_IS_SET;	}	sum_calculated = lha_calcsum(0, p, 2, lha->header_size - 2);	 	if (extdsize > 0) {		 		p += H0_FILE_NAME_OFFSET + namelen + 2;		if (p[0] == 'U' && extdsize == 12) {			 			lha->mtime = archive_le32dec(&p[2]);			lha->mode = archive_le16dec(&p[6]);			lha->uid = archive_le16dec(&p[8]);			lha->gid = archive_le16dec(&p[10]);			lha->setflag |= UNIX_MODE_IS_SET;		}	}	__archive_read_consume(a, lha->header_size);	if (sum_calculated != headersum) {		archive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,		    ""LHa header sum error"");		return (ARCHIVE_FATAL);	}	return (ARCHIVE_OK);}",21993
3,612,CVE-2016-10165,18,"void Type_ColorantOrderType_Free(struct _cms_typehandler_struct* self, void* Ptr){    _cmsFree(self ->ContextID, Ptr);}",22467
109,47,CVE-2017-9739,18,  static void  Ins_NEG( INS_ARG )  { (void)exc;    args[0] = -args[0];  },926
53,183,CVE-2016-6520,18,"static void Contrast(const int sign,double *red,double *green,double *blue){  double    brightness,    hue,    saturation;     assert(red != (double *) NULL);  assert(green != (double *) NULL);  assert(blue != (double *) NULL);  hue=0.0;  saturation=0.0;  brightness=0.0;  ConvertRGBToHSB(*red,*green,*blue,&hue,&saturation,&brightness);  brightness+=0.5*sign*(0.5*(sin((double) (MagickPI*(brightness-0.5)))+1.0)-    brightness);  if (brightness > 1.0)    brightness=1.0;  else    if (brightness < 0.0)      brightness=0.0;  ConvertHSBToRGB(hue,saturation,brightness,red,green,blue);}",15993
194,786,CVE-2018-16427,18,"iasecc_pin_cmd(struct sc_card *card, struct sc_pin_cmd_data *data, int *tries_left){	struct sc_context *ctx = card->ctx;	int rv;	LOG_FUNC_CALLED(ctx);	sc_log(ctx, ""iasecc_pin_cmd() cmd 0x%X, PIN type 0x%X, PIN reference %i, PIN-1 %p:%i, PIN-2 %p:%i"",			data->cmd, data->pin_type, data->pin_reference,			data->pin1.data, data->pin1.len, data->pin2.data, data->pin2.len);	switch (data->cmd)   {	case SC_PIN_CMD_VERIFY:		rv = iasecc_pin_verify(card, data->pin_type, data->pin_reference, data->pin1.data, data->pin1.len, tries_left);		break;	case SC_PIN_CMD_CHANGE:		if (data->pin_type == SC_AC_AUT)			rv = iasecc_keyset_change(card, data, tries_left);		else			rv = iasecc_pin_change(card, data, tries_left);		break;	case SC_PIN_CMD_UNBLOCK:		rv = iasecc_pin_reset(card, data, tries_left);		break;	case SC_PIN_CMD_GET_INFO:		rv = iasecc_pin_get_policy(card, data);		break;	default:		sc_log(ctx, ""Other pin commands not supported yet: 0x%X"", data->cmd);		rv = SC_ERROR_NOT_SUPPORTED;	}	LOG_FUNC_RETURN(ctx, rv);}",24313
198,396,CVE-2017-9985,18,static void snd_msndmidi_free(struct snd_rawmidi *rmidi){	struct snd_msndmidi *mpu = rmidi->private_data;	kfree(mpu);},20685
199,900,CVE-2018-11363,18,"static const int *find_font_widths(const char *font_name){    if (strcmp(font_name, ""Helvetica"") == 0)        return helvetica_widths;    if (strcmp(font_name, ""Helvetica-Bold"") == 0)        return helvetica_bold_widths;    if (strcmp(font_name, ""Helvetica-BoldOblique"") == 0)        return helvetica_bold_oblique_widths;    if (strcmp(font_name, ""Helvetica-Oblique"") == 0)        return helvetica_oblique_widths;    if (strcmp(font_name, ""Courier"") == 0 ||            strcmp(font_name, ""Courier-Bold"") == 0 ||            strcmp(font_name, ""Courier-BoldOblique"") == 0 ||            strcmp(font_name, ""Courier-Oblique"") == 0)        return courier_widths;    if (strcmp(font_name, ""Times-Roman"") == 0)        return times_widths;    if (strcmp(font_name, ""Times-Bold"") == 0)        return times_bold_widths;    if (strcmp(font_name, ""Times-Italic"") == 0)        return times_italic_widths;    if (strcmp(font_name, ""Times-BoldItalic"") == 0)        return times_bold_italic_widths;    if (strcmp(font_name, ""Symbol"") == 0)        return symbol_widths;    if (strcmp(font_name, ""ZapfDingbats"") == 0)        return zapfdingbats_widths;    return NULL;}",25160
177,474,CVE-2017-6347,18,"void ip_cmsg_recv_offset(struct msghdr *msg, struct sock *sk,			 struct sk_buff *skb, int tlen, int offset){	struct inet_sock *inet = inet_sk(sk);	unsigned int flags = inet->cmsg_flags;	 	if (flags & IP_CMSG_PKTINFO) {		ip_cmsg_recv_pktinfo(msg, skb);		flags &= ~IP_CMSG_PKTINFO;		if (!flags)			return;	}	if (flags & IP_CMSG_TTL) {		ip_cmsg_recv_ttl(msg, skb);		flags &= ~IP_CMSG_TTL;		if (!flags)			return;	}	if (flags & IP_CMSG_TOS) {		ip_cmsg_recv_tos(msg, skb);		flags &= ~IP_CMSG_TOS;		if (!flags)			return;	}	if (flags & IP_CMSG_RECVOPTS) {		ip_cmsg_recv_opts(msg, skb);		flags &= ~IP_CMSG_RECVOPTS;		if (!flags)			return;	}	if (flags & IP_CMSG_RETOPTS) {		ip_cmsg_recv_retopts(msg, skb);		flags &= ~IP_CMSG_RETOPTS;		if (!flags)			return;	}	if (flags & IP_CMSG_PASSSEC) {		ip_cmsg_recv_security(msg, skb);		flags &= ~IP_CMSG_PASSSEC;		if (!flags)			return;	}	if (flags & IP_CMSG_ORIGDSTADDR) {		ip_cmsg_recv_dstaddr(msg, skb);		flags &= ~IP_CMSG_ORIGDSTADDR;		if (!flags)			return;	}	if (flags & IP_CMSG_CHECKSUM)		ip_cmsg_recv_checksum(msg, skb, tlen, offset);	if (flags & IP_CMSG_RECVFRAGSIZE)		ip_cmsg_recv_fragsize(msg, skb);}",21815
85,853,CVE-2018-12684,18,b64reverse(char letter){	if ((letter >= 'A') && (letter <= 'Z')) {		return letter - 'A';	}	if ((letter >= 'a') && (letter <= 'z')) {		return letter - 'a' + 26;	}	if ((letter >= '0') && (letter <= '9')) {		return letter - '0' + 52;	}	if (letter == '+') {		return 62;	}	if (letter == '/') {		return 63;	}	if (letter == '=') {		return 255;  	}	return 254;  },25020
208,255,CVE-2017-16530,18,static void uas_free_unsubmitted_urbs(struct scsi_cmnd *cmnd){	struct uas_cmd_info *cmdinfo;	if (!cmnd)		return;	cmdinfo = (void *)&cmnd->SCp;	if (cmdinfo->state & SUBMIT_CMD_URB)		usb_free_urb(cmdinfo->cmd_urb);	 	if (!(cmdinfo->state & DATA_IN_URB_INFLIGHT))		usb_free_urb(cmdinfo->data_in_urb);	if (!(cmdinfo->state & DATA_OUT_URB_INFLIGHT))		usb_free_urb(cmdinfo->data_out_urb);},19787
35,611,CVE-2016-10165,18,"void Type_Chromaticity_Free(struct _cms_typehandler_struct* self, void* Ptr){    _cmsFree(self ->ContextID, Ptr);}",22466
195,245,CVE-2017-16533,18,"static void usbhid_submit_report(struct hid_device *hid, struct hid_report *report, unsigned char dir){	struct usbhid_device *usbhid = hid->driver_data;	unsigned long flags;	spin_lock_irqsave(&usbhid->lock, flags);	__usbhid_submit_report(hid, report, dir);	spin_unlock_irqrestore(&usbhid->lock, flags);}",19747
96,194,CVE-2016-5114,18,int fpm_log_init_child(struct fpm_worker_pool_s *wp)   {	if (!wp || !wp->config) {		return -1;	}	if (wp->config->access_log && *wp->config->access_log) {		if (wp->config->access_format) {			fpm_log_format = strdup(wp->config->access_format);		}	}	if (fpm_log_fd == -1) {		fpm_log_fd = wp->log_fd;	}	for (wp = fpm_worker_all_pools; wp; wp = wp->next) {		if (wp->log_fd > -1 && wp->log_fd != fpm_log_fd) {			close(wp->log_fd);			wp->log_fd = -1;		}	}	return 0;} ,16518
89,982,CVE-2017-7277,18,"int sock_queue_err_skb(struct sock *sk, struct sk_buff *skb){	if (atomic_read(&sk->sk_rmem_alloc) + skb->truesize >=	    (unsigned int)sk->sk_rcvbuf)		return -ENOMEM;	skb_orphan(skb);	skb->sk = sk;	skb->destructor = sock_rmem_free;	atomic_add(skb->truesize, &sk->sk_rmem_alloc);	skb_set_err_queue(skb);	 	skb_dst_force(skb);	skb_queue_tail(&sk->sk_error_queue, skb);	if (!sock_flag(sk, SOCK_DEAD))		sk->sk_data_ready(sk);	return 0;}",28576
129,500,CVE-2017-5601,18,"lzh_read_pt_bitlen(struct lzh_stream *strm, int start, int end){	struct lzh_dec *ds = strm->ds;	struct lzh_br *br = &(ds->br);	int c, i;	for (i = start; i < end; ) {		 		if (!lzh_br_read_ahead(strm, br, 3))			return (i);		if ((c = lzh_br_bits(br, 3)) == 7) {			if (!lzh_br_read_ahead(strm, br, 13))				return (i);			c = bitlen_tbl[lzh_br_bits(br, 13) & 0x3FF];			if (c)				lzh_br_consume(br, c - 3);			else				return (-1); 		} else			lzh_br_consume(br, 3);		ds->pt.bitlen[i++] = c;		ds->pt.freq[c]++;	}	return (i);}",22005
15,1042,CVE-2017-0812,18,"static int out_set_sample_rate(struct audio_stream *stream, int rate){ (void)stream; (void)rate; return -ENOSYS;}",30770
23,1023,CVE-2017-0812,18,"static int get_command_status(int status, int fct_status, int cmd_status) { if (fct_status != 0)        status = fct_status; else if (cmd_status != 0)        status = cmd_status; return status;}",30751
68,296,CVE-2017-14166,18,"getsumalgorithm(struct xmlattr_list *list){	struct xmlattr *attr;	int alg = CKSUM_NONE;	for (attr = list->first; attr != NULL; attr = attr->next) {		if (strcmp(attr->name, ""style"") == 0) {			const char *v = attr->value;			if ((v[0] == 'S' || v[0] == 's') &&			    (v[1] == 'H' || v[1] == 'h') &&			    (v[2] == 'A' || v[2] == 'a') &&			    v[3] == '1' && v[4] == '\0')				alg = CKSUM_SHA1;			if ((v[0] == 'M' || v[0] == 'm') &&			    (v[1] == 'D' || v[1] == 'd') &&			    v[2] == '5' && v[3] == '\0')				alg = CKSUM_MD5;		}	}	return (alg);}",20169
92,849,CVE-2018-14016,18,static void r_bin_mdmp_free_pe64_bin(void *pe_bin_) {	struct Pe64_r_bin_mdmp_pe_bin *pe_bin = pe_bin_;	if (pe_bin) {		sdb_free (pe_bin->bin->kv);		Pe64_r_bin_pe_free (pe_bin->bin);		R_FREE (pe_bin);	}},24562
186,528,CVE-2016-10197,18,"evdns_base_clear_host_addresses(struct evdns_base *base){	struct hosts_entry *victim;	EVDNS_LOCK(base);	while ((victim = TAILQ_FIRST(&base->hostsdb))) {		TAILQ_REMOVE(&base->hostsdb, victim, next);		mm_free(victim);	}	EVDNS_UNLOCK(base);}",22347
134,934,CVE-2018-11363,18,"static struct pdf_object *pdf_get_object(struct pdf_doc *pdf, int index){    return flexarray_get(&pdf->objects, index);}",25194
247,148,CVE-2016-7917,18,"static int nfnetlink_bind(struct net *net, int group){	const struct nfnetlink_subsystem *ss;	int type;	if (group <= NFNLGRP_NONE || group > NFNLGRP_MAX)		return 0;	type = nfnl_group2type[group];	rcu_read_lock();	ss = nfnetlink_get_subsys(type << 8);	rcu_read_unlock();	if (!ss)		request_module(""nfnetlink-subsys-%d"", type);	return 0;}",15589
228,9,CVE-2018-20102,18,"int dns_read_name(unsigned char *buffer, unsigned char *bufend,		  unsigned char *name, char *destination, int dest_len,		  int *offset, unsigned int depth){	int nb_bytes = 0, n = 0;	int label_len;	unsigned char *reader = name;	char *dest = destination;	while (1) {		if (reader >= bufend)			goto err;		 		if ((*reader & 0xc0) == 0xc0) {			if (reader + 1 >= bufend)				goto err;			 			if ((buffer + reader[1]) > reader)				goto err;			if (depth++ > 100)				goto err;			n = dns_read_name(buffer, bufend, buffer + reader[1],					  dest, dest_len - nb_bytes, offset, depth);			if (n == 0)				goto err;			dest     += n;			nb_bytes += n;			goto out;		}		label_len = *reader;		if (label_len == 0)			goto out;		 		if ((reader + label_len >= bufend) || (nb_bytes + label_len >= dest_len))			goto err;		 		label_len++;		memcpy(dest, reader, label_len);		dest     += label_len;		nb_bytes += label_len;		reader   += label_len;	}  out:	 	reader  = name;	*offset = 0;	while (reader < bufend) {		if ((reader[0] & 0xc0) == 0xc0) {			*offset += 2;			break;		}		else if (*reader == 0) {			*offset += 1;			break;		}		*offset += 1;		++reader;	}	return nb_bytes;  err:	return 0;}",242
169,221,CVE-2017-16533,18,"static int hid_post_reset(struct usb_interface *intf){	struct usb_device *dev = interface_to_usbdev (intf);	struct hid_device *hid = usb_get_intfdata(intf);	struct usbhid_device *usbhid = hid->driver_data;	struct usb_host_interface *interface = intf->cur_altsetting;	int status;	char *rdesc;	 	rdesc = kmalloc(hid->dev_rsize, GFP_KERNEL);	if (!rdesc)		return -ENOMEM;	status = hid_get_class_descriptor(dev,				interface->desc.bInterfaceNumber,				HID_DT_REPORT, rdesc, hid->dev_rsize);	if (status < 0) {		dbg_hid(""reading report descriptor failed (post_reset)\n"");		kfree(rdesc);		return status;	}	status = memcmp(rdesc, hid->dev_rdesc, hid->dev_rsize);	kfree(rdesc);	if (status != 0) {		dbg_hid(""report descriptor changed\n"");		return -EPERM;	}	 	spin_lock_irq(&usbhid->lock);	clear_bit(HID_RESET_PENDING, &usbhid->iofl);	clear_bit(HID_CLEAR_HALT, &usbhid->iofl);	spin_unlock_irq(&usbhid->lock);	hid_set_idle(dev, intf->cur_altsetting->desc.bInterfaceNumber, 0, 0);	hid_restart_io(hid);	return 0;}",19723
65,5,CVE-2018-20102,18,"struct dns_srvrq *new_dns_srvrq(struct server *srv, char *fqdn){	struct proxy     *px    = srv->proxy;	struct dns_srvrq *srvrq = NULL;	int fqdn_len, hostname_dn_len;	fqdn_len = strlen(fqdn);	hostname_dn_len = dns_str_to_dn_label(fqdn, fqdn_len + 1, trash.area,					      trash.size);	if (hostname_dn_len == -1) {		ha_alert(""config : %s '%s', server '%s': failed to parse FQDN '%s'\n"",			 proxy_type_str(px), px->id, srv->id, fqdn);		goto err;	}	if ((srvrq = calloc(1, sizeof(*srvrq))) == NULL) {		ha_alert(""config : %s '%s', server '%s': out of memory\n"",			 proxy_type_str(px), px->id, srv->id);		goto err;	}	srvrq->obj_type        = OBJ_TYPE_SRVRQ;	srvrq->proxy           = px;	srvrq->name            = strdup(fqdn);	srvrq->hostname_dn     = strdup(trash.area);	srvrq->hostname_dn_len = hostname_dn_len;	if (!srvrq->name || !srvrq->hostname_dn) {		ha_alert(""config : %s '%s', server '%s': out of memory\n"",			 proxy_type_str(px), px->id, srv->id);		goto err;	}	LIST_ADDQ(&dns_srvrq_list, &srvrq->list);	return srvrq;  err:	if (srvrq) {		free(srvrq->name);		free(srvrq->hostname_dn);		free(srvrq);	}	return NULL;}",114
40,308,CVE-2017-14166,18,"xml_parse_file_flags(struct xar *xar, const char *name){	const char *flag = NULL;	if (strcmp(name, ""UserNoDump"") == 0) {		xar->xmlsts = FILE_FLAGS_USER_NODUMP;		flag = ""nodump"";	}	else if (strcmp(name, ""UserImmutable"") == 0) {		xar->xmlsts = FILE_FLAGS_USER_IMMUTABLE;		flag = ""uimmutable"";	}	else if (strcmp(name, ""UserAppend"") == 0) {		xar->xmlsts = FILE_FLAGS_USER_APPEND;		flag = ""uappend"";	}	else if (strcmp(name, ""UserOpaque"") == 0) {		xar->xmlsts = FILE_FLAGS_USER_OPAQUE;		flag = ""opaque"";	}	else if (strcmp(name, ""UserNoUnlink"") == 0) {		xar->xmlsts = FILE_FLAGS_USER_NOUNLINK;		flag = ""nouunlink"";	}	else if (strcmp(name, ""SystemArchived"") == 0) {		xar->xmlsts = FILE_FLAGS_SYS_ARCHIVED;		flag = ""archived"";	}	else if (strcmp(name, ""SystemImmutable"") == 0) {		xar->xmlsts = FILE_FLAGS_SYS_IMMUTABLE;		flag = ""simmutable"";	}	else if (strcmp(name, ""SystemAppend"") == 0) {		xar->xmlsts = FILE_FLAGS_SYS_APPEND;		flag = ""sappend"";	}	else if (strcmp(name, ""SystemNoUnlink"") == 0) {		xar->xmlsts = FILE_FLAGS_SYS_NOUNLINK;		flag = ""nosunlink"";	}	else if (strcmp(name, ""SystemSnapshot"") == 0) {		xar->xmlsts = FILE_FLAGS_SYS_SNAPSHOT;		flag = ""snapshot"";	}	if (flag == NULL)		return (0);	xar->file->has |= HAS_FFLAGS;	if (archive_strlen(&(xar->file->fflags_text)) > 0)		archive_strappend_char(&(xar->file->fflags_text), ',');	archive_strcat(&(xar->file->fflags_text), flag);	return (1);}",20181
22,462,CVE-2017-6430,18,"struct block * compiler_add_instr(struct instruction *ins, struct block *blk){   struct block *bl;   SAFE_CALLOC(bl, 1, sizeof(struct block));       bl->type = BLK_INSTR;   bl->un.ins = ins;       bl->next = blk;   return bl;}",21800
98,363,CVE-2017-11664,18,"_WM_initMDI(void) {    struct _mdi *mdi;    mdi = malloc(sizeof(struct _mdi));    memset(mdi, 0, (sizeof(struct _mdi)));    mdi->extra_info.copyright = NULL;    mdi->extra_info.mixer_options = _WM_MixerOptions;    _WM_load_patch(mdi, 0x0000);    mdi->events_size = MEM_CHUNK;    mdi->events = malloc(mdi->events_size * sizeof(struct _event));    mdi->event_count = 0;    mdi->current_event = mdi->events;    mdi->samples_to_mix = 0;    mdi->extra_info.current_sample = 0;    mdi->extra_info.total_midi_time = 0;    mdi->extra_info.approx_total_samples = 0;    mdi->dyn_vol = 1.0;    mdi->dyn_vol_adjust = 0.0;    mdi->dyn_vol_peak = 0;    mdi->dyn_vol_to_reach = 1.0;    mdi->is_type2 = 0;    mdi->lyric = NULL;    _WM_do_sysex_gm_reset(mdi, NULL);    return (mdi);}",20496
149,27,CVE-2017-9739,18,  static void  Ins_DUP( INS_ARG )  { (void)exc;    args[1] = args[0];  },906
76,115,CVE-2018-20679,18,"static void init_packet(struct dhcp_packet *packet, struct dhcp_packet *oldpacket, char type){	 	udhcp_init_header(packet, type);	packet->xid = oldpacket->xid;	memcpy(packet->chaddr, oldpacket->chaddr, sizeof(oldpacket->chaddr));	packet->flags = oldpacket->flags;	packet->gateway_nip = oldpacket->gateway_nip;	packet->ciaddr = oldpacket->ciaddr;	udhcp_add_simple_option(packet, DHCP_SERVER_ID, server_config.server_nip);}",2174
158,596,CVE-2016-10197,18,"search_reverse(struct evdns_base *base) {	struct search_domain *cur, *prev = NULL, *next;	ASSERT_LOCKED(base);	cur = base->global_search_state->head;	while (cur) {		next = cur->next;		cur->next = prev;		prev = cur;		cur = next;	}	base->global_search_state->head = prev;}",22415
202,793,CVE-2018-16427,18,"iasecc_se_cache_info(struct sc_card *card, struct iasecc_se_info *se){	struct iasecc_private_data *prv = (struct iasecc_private_data *) card->drv_data;	struct sc_context *ctx = card->ctx;	struct iasecc_se_info *se_info = NULL, *si = NULL;	int rv;	LOG_FUNC_CALLED(ctx);	se_info = calloc(1, sizeof(struct iasecc_se_info));	if (!se_info)		LOG_TEST_RET(ctx, SC_ERROR_OUT_OF_MEMORY, ""SE info allocation error"");	memcpy(se_info, se, sizeof(struct iasecc_se_info));	if (card->cache.valid && card->cache.current_df)   {		sc_file_dup(&se_info->df, card->cache.current_df);		if (se_info->df == NULL)   {			free(se_info);			LOG_TEST_RET(ctx, SC_ERROR_OUT_OF_MEMORY, ""Cannot duplicate current DF file"");		}	}	rv = iasecc_docp_copy(ctx, &se->docp, &se_info->docp);	if (rv < 0)   {		free(se_info->df);		free(se_info);		LOG_TEST_RET(ctx, rv, ""Cannot make copy of DOCP"");	}	if (!prv->se_info)   {		prv->se_info = se_info;	}	else    {		for (si = prv->se_info; si->next; si = si->next)			;		si->next = se_info;	}	LOG_FUNC_RETURN(ctx, rv);}",24320
44,772,CVE-2018-16427,18,"iasecc_chv_verify_pinpad(struct sc_card *card, struct sc_pin_cmd_data *pin_cmd, int *tries_left){	struct sc_context *ctx = card->ctx;	unsigned char buffer[0x100];	int rv;	LOG_FUNC_CALLED(ctx);	sc_log(ctx, ""CHV PINPAD PIN reference %i"", pin_cmd->pin_reference);	rv = iasecc_pin_is_verified(card, pin_cmd, tries_left);	if (!rv)		LOG_FUNC_RETURN(ctx, rv);	if (!card->reader || !card->reader->ops || !card->reader->ops->perform_verify)   {		sc_log(ctx, ""Reader not ready for PIN PAD"");		LOG_FUNC_RETURN(ctx, SC_ERROR_READER);	}	 	pin_cmd->pin1.len = pin_cmd->pin1.stored_length;	pin_cmd->pin1.length_offset = 5;	memset(buffer, 0xFF, sizeof(buffer));	pin_cmd->pin1.data = buffer;	pin_cmd->cmd = SC_PIN_CMD_VERIFY;	pin_cmd->flags |= SC_PIN_CMD_USE_PINPAD;	 	rv = iso_ops->pin_cmd(card, pin_cmd, tries_left);	sc_log(ctx, ""rv %i"", rv);	LOG_FUNC_RETURN(ctx, rv);}",24299
31,969,CVE-2018-14470,18,"network_address(int ae, const unsigned char *a, unsigned int len,                unsigned char *a_r){    return network_prefix(ae, -1, 0, a, NULL, len, a_r);}",27934
201,217,CVE-2017-16533,18,"static void hid_free_buffers(struct usb_device *dev, struct hid_device *hid){	struct usbhid_device *usbhid = hid->driver_data;	usb_free_coherent(dev, usbhid->bufsize, usbhid->inbuf, usbhid->inbuf_dma);	usb_free_coherent(dev, usbhid->bufsize, usbhid->outbuf, usbhid->outbuf_dma);	kfree(usbhid->cr);	usb_free_coherent(dev, usbhid->bufsize, usbhid->ctrlbuf, usbhid->ctrlbuf_dma);}",19719
43,478,CVE-2017-6347,18,"static int ipv4_datagram_support_cmsg(const struct sock *sk,				       struct sk_buff *skb,				       int ee_origin){	struct in_pktinfo *info;	if (ee_origin == SO_EE_ORIGIN_ICMP)		return true;	if (ee_origin == SO_EE_ORIGIN_LOCAL)		return false;	 	if ((!(sk->sk_tsflags & SOF_TIMESTAMPING_OPT_CMSG)) ||	    (!skb->dev))		return false;	info = PKTINFO_SKB_CB(skb);	info->ipi_spec_dst.s_addr = ip_hdr(skb)->saddr;	info->ipi_ifindex = skb->dev->ifindex;	return true;}",21819
137,582,CVE-2016-10197,18,"evdns_transmit(struct evdns_base *base) {	char did_try_to_transmit = 0;	int i;	ASSERT_LOCKED(base);	for (i = 0; i < base->n_req_heads; ++i) {		if (base->req_heads[i]) {			struct request *const started_at = base->req_heads[i], *req = started_at;			 			do {				if (req->transmit_me) {					did_try_to_transmit = 1;					evdns_request_transmit(req);				}				req = req->next;			} while (req != started_at);		}	}	return did_try_to_transmit;}",22401
14,98,CVE-2019-5747,18,static const char *valid_domain_label(const char *label){	unsigned char ch;	if (label[0] == '-')		return NULL;	for (;;) {		ch = *label;		if ((ch|0x20) < 'a' || (ch|0x20) > 'z') {			if (ch < '0' || ch > '9') {				if (ch == '\0' || ch == '.')					return label;				 				if (ch != '-' && ch != '_')					return NULL;			}		}		label++;	}},1422
110,249,CVE-2017-16530,18," static int uas_configure_endpoints(struct uas_dev_info *devinfo){	struct usb_host_endpoint *eps[4] = { };	struct usb_device *udev = devinfo->udev;	int r;	r = uas_find_endpoints(devinfo->intf->cur_altsetting, eps);	if (r)		return r;	devinfo->cmd_pipe = usb_sndbulkpipe(udev,					    usb_endpoint_num(&eps[0]->desc));	devinfo->status_pipe = usb_rcvbulkpipe(udev,					    usb_endpoint_num(&eps[1]->desc));	devinfo->data_in_pipe = usb_rcvbulkpipe(udev,					    usb_endpoint_num(&eps[2]->desc));	devinfo->data_out_pipe = usb_sndbulkpipe(udev,					    usb_endpoint_num(&eps[3]->desc));	if (udev->speed < USB_SPEED_SUPER) {		devinfo->qdepth = 32;		devinfo->use_streams = 0;	} else {		devinfo->qdepth = usb_alloc_streams(devinfo->intf, eps + 1,						    3, MAX_CMNDS, GFP_NOIO);		if (devinfo->qdepth < 0)			return devinfo->qdepth;		devinfo->use_streams = 1;	}	return 0;}",19781
167,850,CVE-2018-14016,18,"static int r_bin_mdmp_init(struct r_bin_mdmp_obj *obj) {	r_bin_mdmp_init_parsing (obj);	if (!r_bin_mdmp_init_hdr (obj)) {		eprintf (""[ERROR] Failed to initialise header\n"");		return false;	}	if (!r_bin_mdmp_init_directory (obj)) {		eprintf (""[ERROR] Failed to initialise directory structures!\n"");		return false;	}	if (!r_bin_mdmp_init_pe_bins (obj)) {		eprintf (""[ERROR] Failed to initialise pe binaries!\n"");		return false;	}	return true;}",24563
49,163,CVE-2016-7915,18,static void hid_device_release(struct device *dev){	struct hid_device *hid = to_hid_device(dev);	hid_close_report(hid);	kfree(hid->dev_rdesc);	kfree(hid);},15657
104,36,CVE-2017-9739,18,  static void  Ins_GT( INS_ARG )  { (void)exc;    if ( args[0] > args[1] )      args[0] = 1;    else      args[0] = 0;  },915
81,265,CVE-2017-16530,18,"static int uas_slave_configure(struct scsi_device *sdev){	struct uas_dev_info *devinfo = sdev->hostdata;	if (devinfo->flags & US_FL_NO_REPORT_OPCODES)		sdev->no_report_opcodes = 1;	 	if (devinfo->flags & US_FL_BROKEN_FUA)		sdev->broken_fua = 1;	scsi_change_queue_depth(sdev, devinfo->qdepth - 2);	return 0;}",19797
17,1021,CVE-2017-0812,18,static int do_out_standby_l(struct stream_out *out){ struct audio_device *adev = out->dev; int status = 0;    out->standby = true;    out_close_pcm_devices(out);    status = stop_output_stream(out); return status;},30749
55,1027,CVE-2017-0812,18,static int in_get_input_frames_lost(struct audio_stream_in *stream){ (void)stream; return 0;},30755
108,584,CVE-2016-10197,18,free_getaddrinfo_request(struct evdns_getaddrinfo_request *data){	 	if (data->pending_result)		evutil_freeaddrinfo(data->pending_result);	if (data->cname_result)		mm_free(data->cname_result);	event_del(&data->timeout);	mm_free(data);	return;},22403
67,193,CVE-2016-6520,18,"static inline double gamma_pow(const double value,const double gamma){  return(value < 0.0 ? value : pow(value,gamma));}",16003
66,153,CVE-2016-7917,18,static void nfnl_err_del(struct nfnl_err *nfnl_err){	list_del(&nfnl_err->head);	kfree(nfnl_err);},15594
218,619,CVE-2016-10165,18,"void Type_U16Fixed16_Free(struct _cms_typehandler_struct* self, void* Ptr){    _cmsFree(self ->ContextID, Ptr);}",22474
124,381,CVE-2017-11664,18,"static int midi_setup_pitch(struct _mdi *mdi, int channel, int pitch) {    MIDI_EVENT_DEBUG(__FUNCTION__,channel, pitch);    _WM_CheckEventMemoryPool(mdi);    mdi->events[mdi->event_count].do_event = *_WM_do_pitch;    mdi->events[mdi->event_count].event_data.channel = channel;    mdi->events[mdi->event_count].event_data.data.value = pitch;    mdi->events[mdi->event_count].samples_to_next = 0;    mdi->event_count++;    return (0);}",20514
41,700,CVE-2018-16790,18,"test_bson_append_document (void){   bson_t *b;   bson_t *b2;   b = bson_new ();   b2 = bson_new ();   BSON_ASSERT (bson_append_document (b, ""document"", -1, b2));   bson_destroy (b2);   b2 = get_bson (""test21.bson"");   BSON_ASSERT_BSON_EQUAL (b, b2);   bson_destroy (b);   bson_destroy (b2);}",24224
123,924,CVE-2018-11363,18,"int pdf_add_text_wrap(struct pdf_doc *pdf, struct pdf_object *page,                      const char *text, int size, int xoff, int yoff,                      int colour, int wrap_width){         const char *start = text;    const char *last_best = text;    const char *end = text;    char line[512];    const int *widths;    int orig_yoff = yoff;    widths = find_font_widths(pdf->current_font->font.name);    if (!widths)        return pdf_set_err(pdf, -EINVAL, ""Unable to determine width for font '%s'"",                           pdf->current_font->font.name);    while (start && *start) {        const char *new_end = find_word_break(end + 1);        int line_width;        int output = 0;        end = new_end;        line_width = pdf_text_pixel_width(start, end - start, size, widths);        if (line_width >= wrap_width) {            if (last_best == start) {                                 int i;                                 for (i = end - start - 1; i > 0; i--)                    if (pdf_text_pixel_width(start, i, size, widths) < wrap_width)                        break;                end = start + i;            } else                end = last_best;            output = 1;        }        if (*end == '\0')            output = 1;        if (*end == '\n' || *end == '\r')            output = 1;        if (output) {            int len = end - start;            strncpy(line, start, len);            line[len] = '\0';            pdf_add_text(pdf, page, line, size, xoff, yoff, colour);            if (*end == ' ')                end++;            start = last_best = end;            yoff -= size;        } else            last_best = end;    }    return orig_yoff - yoff;}",25184
62,728,CVE-2018-16427,18,"authentic_init(struct sc_card *card){	struct sc_context *ctx = card->ctx;	int ii, rv = SC_ERROR_INVALID_CARD;	LOG_FUNC_CALLED(ctx);	for(ii=0;authentic_known_atrs[ii].atr;ii++)   {		if (card->type == authentic_known_atrs[ii].type)   {			card->name = authentic_known_atrs[ii].name;			card->flags = authentic_known_atrs[ii].flags;			break;		}	}	if (!authentic_known_atrs[ii].atr)		LOG_FUNC_RETURN(ctx, SC_ERROR_INVALID_CARD);	card->cla  = 0x00;	card->drv_data = (struct authentic_private_data *) calloc(sizeof(struct authentic_private_data), 1);	if (!card->drv_data)		LOG_FUNC_RETURN(ctx, SC_ERROR_OUT_OF_MEMORY);	if (card->type == SC_CARD_TYPE_OBERTHUR_AUTHENTIC_3_2)		rv = authentic_init_oberthur_authentic_3_2(card);	if (rv != SC_SUCCESS)		rv = authentic_get_serialnr(card, NULL);	if (rv != SC_SUCCESS)		rv = SC_ERROR_INVALID_CARD;	LOG_FUNC_RETURN(ctx, rv);}",24255
19,357,CVE-2017-11664,18,"void _WM_do_note_off_extra(struct _note *nte) {    MIDI_EVENT_DEBUG(__FUNCTION__,0, 0);    nte->is_off = 0;        {        if (!(nte->modes & SAMPLE_ENVELOPE)) {            if (nte->modes & SAMPLE_LOOP) {                nte->modes ^= SAMPLE_LOOP;            }            nte->env_inc = 0;        } else if (nte->hold) {            nte->hold |= HOLD_OFF;         } else if (nte->modes & SAMPLE_CLAMPED) {            if (nte->env < 5) {                nte->env = 5;                if (nte->env_level > nte->sample->env_target[5]) {                    nte->env_inc = -nte->sample->env_rate[5];                } else {                    nte->env_inc = nte->sample->env_rate[5];                }            }        } else if (nte->env < 3) {            nte->env = 3;            if (nte->env_level > nte->sample->env_target[3]) {                nte->env_inc = -nte->sample->env_rate[3];            } else {                nte->env_inc = nte->sample->env_rate[3];            }        }    }}",20490
75,426,CVE-2017-8831,18,"static void saa7164_bus_dumpmsg(struct saa7164_dev *dev, struct tmComResInfo *m,				void *buf){	dprintk(DBGLVL_BUS, ""Dumping msg structure:\n"");	dprintk(DBGLVL_BUS, "" .id               = %d\n"",   m->id);	dprintk(DBGLVL_BUS, "" .flags            = 0x%x\n"", m->flags);	dprintk(DBGLVL_BUS, "" .size             = 0x%x\n"", m->size);	dprintk(DBGLVL_BUS, "" .command          = 0x%x\n"", m->command);	dprintk(DBGLVL_BUS, "" .controlselector  = 0x%x\n"", m->controlselector);	dprintk(DBGLVL_BUS, "" .seqno            = %d\n"",   m->seqno);	if (buf)		dprintk(DBGLVL_BUS, "" .buffer (ignored)\n"");}",21255
119,650,CVE-2018-18445,18,"static int check_arg_pair_ok(const struct bpf_func_proto *fn){	 	if (arg_type_is_mem_size(fn->arg1_type) ||	    arg_type_is_mem_ptr(fn->arg5_type)  ||	    check_args_pair_invalid(fn->arg1_type, fn->arg2_type) ||	    check_args_pair_invalid(fn->arg2_type, fn->arg3_type) ||	    check_args_pair_invalid(fn->arg3_type, fn->arg4_type) ||	    check_args_pair_invalid(fn->arg4_type, fn->arg5_type))		return false;	return true;}",23496
138,722,CVE-2018-16427,18,"authentic_card_ctl(struct sc_card *card, unsigned long cmd, void *ptr){	struct sc_context *ctx = card->ctx;	struct sc_authentic_sdo *sdo = (struct sc_authentic_sdo *) ptr;	switch (cmd) {	case SC_CARDCTL_GET_SERIALNR:		return authentic_get_serialnr(card, (struct sc_serial_number *)ptr);	case SC_CARDCTL_AUTHENTIC_SDO_CREATE:		sc_log(ctx, ""CARDCTL SDO_CREATE: sdo(mech:%X,id:%X)"", sdo->docp.mech, sdo->docp.id);		return authentic_manage_sdo(card, (struct sc_authentic_sdo *) ptr, cmd);	case SC_CARDCTL_AUTHENTIC_SDO_DELETE:		sc_log(ctx, ""CARDCTL SDO_DELETE: sdo(mech:%X,id:%X)"", sdo->docp.mech, sdo->docp.id);		return authentic_manage_sdo(card, (struct sc_authentic_sdo *) ptr, cmd);	case SC_CARDCTL_AUTHENTIC_SDO_STORE:		sc_log(ctx, ""CARDCTL SDO_STORE: sdo(mech:%X,id:%X)"", sdo->docp.mech, sdo->docp.id);		return authentic_manage_sdo(card, (struct sc_authentic_sdo *) ptr, cmd);	case SC_CARDCTL_AUTHENTIC_SDO_GENERATE:		sc_log(ctx, ""CARDCTL SDO_GENERATE: sdo(mech:%X,id:%X)"", sdo->docp.mech, sdo->docp.id);		return authentic_manage_sdo_generate(card, (struct sc_authentic_sdo *) ptr);	}	return SC_ERROR_NOT_SUPPORTED;}",24249
189,191,CVE-2016-6520,18,"static inline void ModulateLCHab(const double percent_luma,  const double percent_chroma,const double percent_hue,double *red,  double *green,double *blue){  double    hue,    luma,    chroma;     ConvertRGBToLCHab(*red,*green,*blue,&luma,&chroma,&hue);  luma*=0.01*percent_luma;  chroma*=0.01*percent_chroma;  hue+=0.5*(0.01*percent_hue-1.0);  while (hue < 0.0)    hue+=1.0;  while (hue >= 1.0)    hue-=1.0;  ConvertLCHabToRGB(luma,chroma,hue,red,green,blue);}",16001
143,130,CVE-2016-9777,18,"static int ioapic_service(struct kvm_ioapic *ioapic, int irq, int line_status){	union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];	struct kvm_lapic_irq irqe;	int ret;	if (entry->fields.mask)		return -1;	ioapic_debug(""dest=%x dest_mode=%x delivery_mode=%x ""		     ""vector=%x trig_mode=%x\n"",		     entry->fields.dest_id, entry->fields.dest_mode,		     entry->fields.delivery_mode, entry->fields.vector,		     entry->fields.trig_mode);	irqe.dest_id = entry->fields.dest_id;	irqe.vector = entry->fields.vector;	irqe.dest_mode = entry->fields.dest_mode;	irqe.trig_mode = entry->fields.trig_mode;	irqe.delivery_mode = entry->fields.delivery_mode << 8;	irqe.level = 1;	irqe.shorthand = 0;	irqe.msi_redir_hint = false;	if (irqe.trig_mode == IOAPIC_EDGE_TRIG)		ioapic->irr_delivered |= 1 << irq;	if (irq == RTC_GSI && line_status) {		 		BUG_ON(ioapic->rtc_status.pending_eoi != 0);		ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,					       &ioapic->rtc_status.dest_map);		ioapic->rtc_status.pending_eoi = (ret < 0 ? 0 : ret);	} else		ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);	if (ret && irqe.trig_mode == IOAPIC_LEVEL_TRIG)		entry->fields.remote_irr = 1;	return ret;}",15082
150,544,CVE-2016-10197,18,"evdns_base_set_option_impl(struct evdns_base *base,    const char *option, const char *val, int flags){	ASSERT_LOCKED(base);	if (str_matches_option(option, ""ndots:"")) {		const int ndots = strtoint(val);		if (ndots == -1) return -1;		if (!(flags & DNS_OPTION_SEARCH)) return 0;		log(EVDNS_LOG_DEBUG, ""Setting ndots to %d"", ndots);		if (!base->global_search_state) base->global_search_state = search_state_new();		if (!base->global_search_state) return -1;		base->global_search_state->ndots = ndots;	} else if (str_matches_option(option, ""timeout:"")) {		struct timeval tv;		if (evdns_strtotimeval(val, &tv) == -1) return -1;		if (!(flags & DNS_OPTION_MISC)) return 0;		log(EVDNS_LOG_DEBUG, ""Setting timeout to %s"", val);		memcpy(&base->global_timeout, &tv, sizeof(struct timeval));	} else if (str_matches_option(option, ""getaddrinfo-allow-skew:"")) {		struct timeval tv;		if (evdns_strtotimeval(val, &tv) == -1) return -1;		if (!(flags & DNS_OPTION_MISC)) return 0;		log(EVDNS_LOG_DEBUG, ""Setting getaddrinfo-allow-skew to %s"",		    val);		memcpy(&base->global_getaddrinfo_allow_skew, &tv,		    sizeof(struct timeval));	} else if (str_matches_option(option, ""max-timeouts:"")) {		const int maxtimeout = strtoint_clipped(val, 1, 255);		if (maxtimeout == -1) return -1;		if (!(flags & DNS_OPTION_MISC)) return 0;		log(EVDNS_LOG_DEBUG, ""Setting maximum allowed timeouts to %d"",			maxtimeout);		base->global_max_nameserver_timeout = maxtimeout;	} else if (str_matches_option(option, ""max-inflight:"")) {		const int maxinflight = strtoint_clipped(val, 1, 65000);		if (maxinflight == -1) return -1;		if (!(flags & DNS_OPTION_MISC)) return 0;		log(EVDNS_LOG_DEBUG, ""Setting maximum inflight requests to %d"",			maxinflight);		evdns_base_set_max_requests_inflight(base, maxinflight);	} else if (str_matches_option(option, ""attempts:"")) {		int retries = strtoint(val);		if (retries == -1) return -1;		if (retries > 255) retries = 255;		if (!(flags & DNS_OPTION_MISC)) return 0;		log(EVDNS_LOG_DEBUG, ""Setting retries to %d"", retries);		base->global_max_retransmits = retries;	} else if (str_matches_option(option, ""randomize-case:"")) {		int randcase = strtoint(val);		if (!(flags & DNS_OPTION_MISC)) return 0;		base->global_randomize_case = randcase;	} else if (str_matches_option(option, ""bind-to:"")) {		 		int len = sizeof(base->global_outgoing_address);		if (!(flags & DNS_OPTION_NAMESERVERS)) return 0;		if (evutil_parse_sockaddr_port(val,			(struct sockaddr*)&base->global_outgoing_address, &len))			return -1;		base->global_outgoing_addrlen = len;	} else if (str_matches_option(option, ""initial-probe-timeout:"")) {		struct timeval tv;		if (evdns_strtotimeval(val, &tv) == -1) return -1;		if (tv.tv_sec > 3600)			tv.tv_sec = 3600;		if (!(flags & DNS_OPTION_MISC)) return 0;		log(EVDNS_LOG_DEBUG, ""Setting initial probe timeout to %s"",		    val);		memcpy(&base->global_nameserver_probe_initial_timeout, &tv,		    sizeof(tv));	}	return 0;}",22363
157,392,CVE-2017-11664,18,"static void strip_text(char * text) {    char * ch_loc = NULL;    ch_loc = strrchr(text, '\n');    while (ch_loc != NULL) {        *ch_loc = ' ';        ch_loc = strrchr(text, '\n');    }    ch_loc = strrchr(text, '\r');    while (ch_loc != NULL) {        *ch_loc = ' ';        ch_loc = strrchr(text, '\r');    }}",20525
47,689,CVE-2018-18445,18,"static void sanitize_dead_code(struct bpf_verifier_env *env){	struct bpf_insn_aux_data *aux_data = env->insn_aux_data;	struct bpf_insn trap = BPF_JMP_IMM(BPF_JA, 0, 0, -1);	struct bpf_insn *insn = env->prog->insnsi;	const int insn_cnt = env->prog->len;	int i;	for (i = 0; i < insn_cnt; i++) {		if (aux_data[i].seen)			continue;		memcpy(insn + i, &trap, sizeof(trap));	}}",23535
59,930,CVE-2018-11363,18,"static struct pdf_object *pdf_find_first_object(struct pdf_doc *pdf,        int type){    return pdf->first_objects[type];}",25190
183,525,CVE-2016-10197,18,dnslabel_clear(struct dnslabel_table *table){	int i;	for (i = 0; i < table->n_labels; ++i)		mm_free(table->labels[i].v);	table->n_labels = 0;},22344
30,800,CVE-2018-16427,18,"acl_to_ac_byte(struct sc_card *card, const struct sc_acl_entry *e){	unsigned key_ref;	if (e == NULL)		return SC_ERROR_OBJECT_NOT_FOUND;	key_ref = e->key_ref & ~OBERTHUR_PIN_LOCAL;	switch (e->method) {	case SC_AC_NONE:		LOG_FUNC_RETURN(card->ctx, 0);	case SC_AC_CHV:		if (key_ref > 0 && key_ref < 6)			LOG_FUNC_RETURN(card->ctx, (0x20 | key_ref));		else			LOG_FUNC_RETURN(card->ctx, SC_ERROR_INCORRECT_PARAMETERS);	case SC_AC_PRO:		if (((key_ref & 0xE0) != 0x60) || ((key_ref & 0x18) == 0))			LOG_FUNC_RETURN(card->ctx, SC_ERROR_INCORRECT_PARAMETERS);		else			LOG_FUNC_RETURN(card->ctx, key_ref);	case SC_AC_NEVER:		return 0xff;	}	LOG_FUNC_RETURN(card->ctx, SC_ERROR_INCORRECT_PARAMETERS);}",24327
248,24,CVE-2017-9739,18,  static void  Ins_DEBUG( INS_ARG )  { (void)args;    CUR.error = TT_Err_Debug_OpCode;  },903
48,642,CVE-2018-18445,18,"static void __mark_reg_const_zero(struct bpf_reg_state *reg){	__mark_reg_known(reg, 0);	reg->off = 0;	reg->type = SCALAR_VALUE;}",23488
193,995,CVE-2018-6038,18,int ClampMin(int value) {  const static int kMinInt16Value = INT16_MIN + 1;  return value < kMinInt16Value ? kMinInt16Value : value;},30074
146,247,CVE-2017-16530,18,"static void uas_cmd_cmplt(struct urb *urb){	if (urb->status)		dev_err(&urb->dev->dev, ""cmd cmplt err %d\n"", urb->status);	usb_free_urb(urb);}",19779
28,521,CVE-2016-10208,18,"static int ext4_quota_on(struct super_block *sb, int type, int format_id,			 struct path *path){	int err;	if (!test_opt(sb, QUOTA))		return -EINVAL;	 	if (path->dentry->d_sb != sb)		return -EXDEV;	 	if (EXT4_SB(sb)->s_qf_names[type]) {		 		if (path->dentry->d_parent != sb->s_root)			ext4_msg(sb, KERN_WARNING,				""Quota file not on filesystem root. ""				""Journaled quota will not work"");	}	 	if (EXT4_SB(sb)->s_journal &&	    ext4_should_journal_data(d_inode(path->dentry))) {		 		jbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);		err = jbd2_journal_flush(EXT4_SB(sb)->s_journal);		jbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);		if (err)			return err;	}	lockdep_set_quota_inode(path->dentry->d_inode, I_DATA_SEM_QUOTA);	err = dquot_quota_on(sb, type, format_id, path);	if (err)		lockdep_set_quota_inode(path->dentry->d_inode,					     I_DATA_SEM_NORMAL);	return err;}",22337
120,28,CVE-2017-9739,18,  static void  Ins_EIF( INS_ARG )  { (void)exc; (void)args;       },907
187,538,CVE-2016-10197,18,evdns_base_resume(struct evdns_base *base){	EVDNS_LOCK(base);	evdns_requests_pump_waiting_queue(base);	EVDNS_UNLOCK(base);	return 0;},22357
234,505,CVE-2016-10269,18,LogL10toY(int p10)		 {	if (p10 == 0)		return (0.);	return (exp(M_LN2/64.*(p10+.5) - M_LN2*12.));},22318
216,967,CVE-2018-14470,18,"format_interval_update(const int i){    return i == 0xFFFF ? ""infinity"" : format_interval(i);}",27932
29,110,CVE-2018-20679,18,"static void add_server_options(struct dhcp_packet *packet){	struct option_set *curr = server_config.options;	while (curr) {		if (curr->data[OPT_CODE] != DHCP_LEASE_TIME)			udhcp_add_binary_option(packet, curr->data);		curr = curr->next;	}	packet->siaddr_nip = server_config.siaddr_nip;	if (server_config.sname)		strncpy((char*)packet->sname, server_config.sname, sizeof(packet->sname) - 1);	if (server_config.boot_file)		strncpy((char*)packet->file, server_config.boot_file, sizeof(packet->file) - 1);}",2169
205,99,CVE-2017-5956,18,"void vrend_renderer_context_destroy(int handle){   struct vrend_decode_ctx *ctx;   int ret;   if (handle >= VREND_MAX_CTX)      return;   ctx = dec_ctx[handle];   if (!ctx)      return;   dec_ctx[handle] = NULL;   ret = vrend_destroy_context(ctx->grctx);   free(ctx);       if (ret && handle != 0)      vrend_hw_switch_context(dec_ctx[0]->grctx, true);}",1616
173,404,CVE-2017-9985,18,"static int snd_msnd_dev_free(struct snd_device *device){	snd_printdd(""snd_msnd_chip_free()\n"");	return 0;}",20693
160,625,CVE-2016-3178,18,"sendNotifications(int notif_type, const struct device * dev, const struct service * serv){	struct reqelem * req;	unsigned int m;	unsigned char rbuf[RESPONSE_BUFFER_SIZE];	unsigned char * rp;	for(req = reqlisthead.lh_first; req; req = req->entries.le_next) {		if(!req->is_notify) continue;		rbuf[0] = '\xff';  		rbuf[1] = (unsigned char)notif_type;		rbuf[2] = 0;		rp = rbuf + 3;		if(dev) {			 			m = dev->headers[HEADER_LOCATION].l;			CODELENGTH(m, rp);			memcpy(rp, dev->headers[HEADER_LOCATION].p, dev->headers[HEADER_LOCATION].l);			rp += dev->headers[HEADER_LOCATION].l;			m = dev->headers[HEADER_NT].l;			CODELENGTH(m, rp);			memcpy(rp, dev->headers[HEADER_NT].p, dev->headers[HEADER_NT].l);			rp += dev->headers[HEADER_NT].l;			m = dev->headers[HEADER_USN].l;			CODELENGTH(m, rp);			memcpy(rp, dev->headers[HEADER_USN].p, dev->headers[HEADER_USN].l);			rp += dev->headers[HEADER_USN].l;			rbuf[2]++;		}		if(serv) {			 			m = strlen(serv->location);			CODELENGTH(m, rp);			memcpy(rp, serv->location, m);			rp += m;			m = strlen(serv->st);			CODELENGTH(m, rp);			memcpy(rp, serv->st, m);			rp += m;			m = strlen(serv->usn);			CODELENGTH(m, rp);			memcpy(rp, serv->usn, m);			rp += m;			rbuf[2]++;		}		if(rbuf[2] > 0) {			if(write_or_buffer(req, rbuf, rp - rbuf) < 0) {				syslog(LOG_ERR, ""(s=%d) write: %m"", req->socket);				 			}		}	}}",22838
159,10,CVE-2018-20102,18,"int dns_str_to_dn_label(const char *str, int str_len, char *dn, int dn_len){	int i, offset;	if (dn_len < str_len + 1)		return -1;	 	offset = 0;	for (i = 0; i < str_len; ++i) {		if (str[i] == '.') {			 			if (i == offset)				return -1;			dn[offset] = (i - offset);			offset = i+1;			continue;		}		dn[i+1] = str[i];	}	dn[offset] = (i - offset - 1);	dn[i] = '\0';	return i;}",243
152,260,CVE-2017-16530,18,"static int uas_reset_resume(struct usb_interface *intf){	struct Scsi_Host *shost = usb_get_intfdata(intf);	struct uas_dev_info *devinfo = (struct uas_dev_info *)shost->hostdata;	unsigned long flags;	int err;	err = uas_configure_endpoints(devinfo);	if (err) {		shost_printk(KERN_ERR, shost,			     ""%s: alloc streams error %d after reset"",			     __func__, err);		return -EIO;	}	spin_lock_irqsave(shost->host_lock, flags);	scsi_report_bus_reset(shost, 0);	spin_unlock_irqrestore(shost->host_lock, flags);	return 0;}",19792
206,861,CVE-2018-12684,18,"consume_socket(struct mg_context *ctx, struct socket *sp, int thread_index){	DEBUG_TRACE(""%s"", ""going idle"");	ctx->client_socks[thread_index].in_use = 0;	event_wait(ctx->client_wait_events[thread_index]);	*sp = ctx->client_socks[thread_index];	DEBUG_TRACE(""grabbed socket %d, going busy"", sp ? sp->sock : -1);	return !ctx->stop_flag;}",25028
165,668,CVE-2018-18445,18,"static int find_subprog(struct bpf_verifier_env *env, int off){	struct bpf_subprog_info *p;	p = bsearch(&off, env->subprog_info, env->subprog_cnt,		    sizeof(env->subprog_info[0]), cmp_subprogs);	if (!p)		return -ENOENT;	return p - env->subprog_info;}",23514
90,376,CVE-2017-11664,18,"static int midi_setup_keysignature(struct _mdi *mdi, int setting) {    MIDI_EVENT_DEBUG(__FUNCTION__,0, setting);    _WM_CheckEventMemoryPool(mdi);    mdi->events[mdi->event_count].do_event = *_WM_do_meta_keysignature;    mdi->events[mdi->event_count].event_data.channel = 0;    mdi->events[mdi->event_count].event_data.data.value = setting;    mdi->events[mdi->event_count].samples_to_next = 0;    mdi->event_count++;    return (0);}",20509
131,338,CVE-2017-11664,18,"void _WM_do_aftertouch(struct _mdi *mdi, struct _event_data *data) {    struct _note *nte;    int ch = data->channel;    MIDI_EVENT_DEBUG(__FUNCTION__,ch, data->data.value);    nte = &mdi->note_table[0][ch][(data->data.value >> 8)];    if (!nte->active) {        nte = &mdi->note_table[1][ch][(data->data.value >> 8)];        if (!nte->active) {            return;        }    }    nte->velocity = data->data.value & 0xff;    _WM_AdjustNoteVolumes(mdi, ch, nte);    if (nte->replay) {        nte->replay->velocity = data->data.value & 0xff;        _WM_AdjustNoteVolumes(mdi, ch, nte->replay);    }}",20471
121,80,CVE-2017-9620,18,"xps_parse_glyph_metrics(char *s, float *advance, float *uofs, float *vofs, int bidi_level){    s = xps_parse_glyph_advance(s, advance, bidi_level);    s = xps_parse_glyph_offsets(s, uofs, vofs);    return s;}",960
264,830,CVE-2018-16427,18,static struct sc_card_driver * sc_get_driver(void){	struct sc_card_driver *iso_drv = sc_get_iso7816_driver();	piv_ops = *iso_drv->ops;	piv_ops.match_card = piv_match_card;	piv_ops.init = piv_init;	piv_ops.finish = piv_finish;	piv_ops.select_file =  piv_select_file;  	piv_ops.get_challenge = piv_get_challenge;	piv_ops.logout = piv_logout;	piv_ops.read_binary = piv_read_binary;	piv_ops.write_binary = piv_write_binary;	piv_ops.set_security_env = piv_set_security_env;	piv_ops.restore_security_env = piv_restore_security_env;	piv_ops.compute_signature = piv_compute_signature;	piv_ops.decipher =  piv_decipher;	piv_ops.check_sw = piv_check_sw;	piv_ops.card_ctl = piv_card_ctl;	piv_ops.pin_cmd = piv_pin_cmd;	piv_ops.card_reader_lock_obtained = piv_card_reader_lock_obtained;	return &piv_drv;},24357
73,827,CVE-2018-16427,18,sc_get_oberthur_driver(void){	return sc_get_driver();},24354
97,926,CVE-2018-11363,18,"struct pdf_object *pdf_append_page(struct pdf_doc *pdf){    struct pdf_object *page;    page = pdf_add_object(pdf, OBJ_page);    if (!page)        return NULL;    page->page.width = pdf->width;    page->page.height = pdf->height;    return page;}",25186
8,974,CVE-2016-10749,18,static unsigned parse_hex4(const char *str){	unsigned h=0;	if (*str>='0' && *str<='9') h+=(*str)-'0'; else if (*str>='A' && *str<='F') h+=10+(*str)-'A'; else if (*str>='a' && *str<='f') h+=10+(*str)-'a'; else return 0;	h=h<<4;str++;	if (*str>='0' && *str<='9') h+=(*str)-'0'; else if (*str>='A' && *str<='F') h+=10+(*str)-'A'; else if (*str>='a' && *str<='f') h+=10+(*str)-'a'; else return 0;	h=h<<4;str++;	if (*str>='0' && *str<='9') h+=(*str)-'0'; else if (*str>='A' && *str<='F') h+=10+(*str)-'A'; else if (*str>='a' && *str<='f') h+=10+(*str)-'a'; else return 0;	h=h<<4;str++;	if (*str>='0' && *str<='9') h+=(*str)-'0'; else if (*str>='A' && *str<='F') h+=10+(*str)-'A'; else if (*str>='a' && *str<='f') h+=10+(*str)-'a'; else return 0;	return h;},28121
130,463,CVE-2017-6430,18,"struct condition * compiler_create_condition(struct filter_op *fop){   struct condition *cnd;   SAFE_CALLOC(cnd, 1, sizeof(struct condition));          memcpy(&cnd->fop, fop, sizeof(struct filter_op));   return cnd;}",21801
105,361,CVE-2017-11664,18,"void _WM_do_sysex_roland_drum_track(struct _mdi *mdi, struct _event_data *data) {    int ch = data->channel;    MIDI_EVENT_DEBUG(__FUNCTION__,ch, data->data.value);    if (data->data.value > 0) {        mdi->channel[ch].isdrum = 1;        mdi->channel[ch].patch = NULL;    } else {        mdi->channel[ch].isdrum = 0;        mdi->channel[ch].patch = _WM_get_patch_data(mdi, 0);    }}",20494
255,400,CVE-2017-9985,18,"int snd_msndmidi_new(struct snd_card *card, int device){	struct snd_msnd *chip = card->private_data;	struct snd_msndmidi *mpu;	struct snd_rawmidi *rmidi;	int err;	err = snd_rawmidi_new(card, ""MSND-MIDI"", device, 1, 1, &rmidi);	if (err < 0)		return err;	mpu = kzalloc(sizeof(*mpu), GFP_KERNEL);	if (mpu == NULL) {		snd_device_free(card, rmidi);		return -ENOMEM;	}	mpu->dev = chip;	chip->msndmidi_mpu = mpu;	rmidi->private_data = mpu;	rmidi->private_free = snd_msndmidi_free;	spin_lock_init(&mpu->input_lock);	strcpy(rmidi->name, ""MSND MIDI"");	snd_rawmidi_set_ops(rmidi, SNDRV_RAWMIDI_STREAM_INPUT,			    &snd_msndmidi_input);	rmidi->info_flags |= SNDRV_RAWMIDI_INFO_INPUT;	return 0;}",20689
6,637,CVE-2018-19497,18,"hfs_attrTypeName(int typeNum){    switch (typeNum) {    case TSK_FS_ATTR_TYPE_HFS_DEFAULT:        return ""DFLT"";    case TSK_FS_ATTR_TYPE_HFS_DATA:        return ""DATA"";    case TSK_FS_ATTR_TYPE_HFS_EXT_ATTR:        return ""ExATTR"";    case TSK_FS_ATTR_TYPE_HFS_COMP_REC:        return ""CMPF"";    case TSK_FS_ATTR_TYPE_HFS_RSRC:        return ""RSRC"";    default:        return ""UNKN"";    }}",23346
240,261,CVE-2017-16530,18,static int uas_resume(struct usb_interface *intf){	return 0;},19793
250,885,CVE-2018-11598,18,int jspHasError() {  return JSP_HAS_ERROR;},25121
32,732,CVE-2018-16427,18,"authentic_pin_reset(struct sc_card *card, struct sc_pin_cmd_data *data, int *tries_left){	struct sc_context *ctx = card->ctx;	struct authentic_private_data *prv_data = (struct authentic_private_data *) card->drv_data;	struct sc_pin_cmd_data pin_cmd, puk_cmd;	struct sc_apdu apdu;	unsigned reference;	int rv, ii;	LOG_FUNC_CALLED(ctx);	sc_log(ctx, ""reset PIN (ref:%i,lengths %i/%i)"", data->pin_reference, data->pin1.len, data->pin2.len);	memset(prv_data->pins_sha1[data->pin_reference], 0, sizeof(prv_data->pins_sha1[0]));	memset(&pin_cmd, 0, sizeof(pin_cmd));	pin_cmd.pin_reference = data->pin_reference;	pin_cmd.pin_type = data->pin_type;	pin_cmd.pin1.tries_left = -1;	rv = authentic_pin_get_policy(card, &pin_cmd);	LOG_TEST_RET(ctx, rv, ""Get 'PIN policy' error"");	if (pin_cmd.pin1.acls[AUTHENTIC_ACL_NUM_PIN_RESET].method == SC_AC_CHV)   {		for (ii=0;ii<8;ii++)   {			unsigned char mask = 0x01 << ii;			if (pin_cmd.pin1.acls[AUTHENTIC_ACL_NUM_PIN_RESET].key_ref & mask)   {				memset(&puk_cmd, 0, sizeof(puk_cmd));				puk_cmd.pin_reference = ii + 1;				rv = authentic_pin_get_policy(card, &puk_cmd);				LOG_TEST_RET(ctx, rv, ""Get 'PIN policy' error"");				if (puk_cmd.pin_type == SC_AC_CHV)					break;			}		}		if (ii < 8)   {			puk_cmd.pin1.data = data->pin1.data;			puk_cmd.pin1.len = data->pin1.len;			rv = authentic_pin_verify(card, &puk_cmd);			if (tries_left && rv == SC_ERROR_PIN_CODE_INCORRECT)				*tries_left = puk_cmd.pin1.tries_left;			LOG_TEST_RET(ctx, rv, ""Cannot verify PUK"");		}	}	reference = data->pin_reference;	if (data->pin2.len)   {		unsigned char pin_data[SC_MAX_APDU_BUFFER_SIZE];		memset(pin_data, pin_cmd.pin1.pad_char, sizeof(pin_data));		memcpy(pin_data, data->pin2.data, data->pin2.len);		sc_format_apdu(card, &apdu, SC_APDU_CASE_3_SHORT, 0x2C, 0x02, reference);		apdu.data = pin_data;		apdu.datalen = pin_cmd.pin1.pad_length;		apdu.lc = pin_cmd.pin1.pad_length;		rv = sc_transmit_apdu(card, &apdu);		LOG_TEST_RET(ctx, rv, ""APDU transmit failed"");		rv = sc_check_sw(card, apdu.sw1, apdu.sw2);		LOG_TEST_RET(ctx, rv, ""PIN cmd failed"");	}	else if (data->pin2.data) {		sc_format_apdu(card, &apdu, SC_APDU_CASE_1, 0x2C, 3, reference);		rv = sc_transmit_apdu(card, &apdu);		LOG_TEST_RET(ctx, rv, ""APDU transmit failed"");		rv = sc_check_sw(card, apdu.sw1, apdu.sw2);		LOG_TEST_RET(ctx, rv, ""PIN cmd failed"");	}	else   {		rv = authentic_chv_set_pinpad(card, reference);		LOG_TEST_RET(ctx, rv, ""Failed to set PIN with pin-pad"");	}	LOG_FUNC_RETURN(ctx, rv);}",24259
4,894,CVE-2018-11379,18,"static char* _resource_lang_str(int id) {	switch(id) {	case 0x00: return ""LANG_NEUTRAL"";	case 0x7f: return ""LANG_INVARIANT"";	case 0x36: return ""LANG_AFRIKAANS"";	case 0x1c: return ""LANG_ALBANIAN "";	case 0x01: return ""LANG_ARABIC"";	case 0x2b: return ""LANG_ARMENIAN"";	case 0x4d: return ""LANG_ASSAMESE"";	case 0x2c: return ""LANG_AZERI"";	case 0x2d: return ""LANG_BASQUE"";	case 0x23: return ""LANG_BELARUSIAN"";	case 0x45: return ""LANG_BENGALI"";	case 0x02: return ""LANG_BULGARIAN"";	case 0x03: return ""LANG_CATALAN"";	case 0x04: return ""LANG_CHINESE"";	case 0x1a: return ""LANG_CROATIAN"";	case 0x05: return ""LANG_CZECH"";	case 0x06: return ""LANG_DANISH"";	case 0x65: return ""LANG_DIVEHI"";	case 0x13: return ""LANG_DUTCH"";	case 0x09: return ""LANG_ENGLISH"";	case 0x25: return ""LANG_ESTONIAN"";	case 0x38: return ""LANG_FAEROESE"";	case 0x29: return ""LANG_FARSI"";	case 0x0b: return ""LANG_FINNISH"";	case 0x0c: return ""LANG_FRENCH"";	case 0x56: return ""LANG_GALICIAN"";	case 0x37: return ""LANG_GEORGIAN"";	case 0x07: return ""LANG_GERMAN"";	case 0x08: return ""LANG_GREEK"";	case 0x47: return ""LANG_GUJARATI"";	case 0x0d: return ""LANG_HEBREW"";	case 0x39: return ""LANG_HINDI"";	case 0x0e: return ""LANG_HUNGARIAN"";	case 0x0f: return ""LANG_ICELANDIC"";	case 0x21: return ""LANG_INDONESIAN"";	case 0x10: return ""LANG_ITALIAN"";	case 0x11: return ""LANG_JAPANESE"";	case 0x4b: return ""LANG_KANNADA"";	case 0x60: return ""LANG_KASHMIRI"";	case 0x3f: return ""LANG_KAZAK"";	case 0x57: return ""LANG_KONKANI"";	case 0x12: return ""LANG_KOREAN"";	case 0x40: return ""LANG_KYRGYZ"";	case 0x26: return ""LANG_LATVIAN"";	case 0x27: return ""LANG_LITHUANIAN"";	case 0x2f: return ""LANG_MACEDONIAN"";	case 0x3e: return ""LANG_MALAY"";	case 0x4c: return ""LANG_MALAYALAM"";	case 0x58: return ""LANG_MANIPURI"";	case 0x4e: return ""LANG_MARATHI"";	case 0x50: return ""LANG_MONGOLIAN"";	case 0x61: return ""LANG_NEPALI"";	case 0x14: return ""LANG_NORWEGIAN"";	case 0x48: return ""LANG_ORIYA"";	case 0x15: return ""LANG_POLISH"";	case 0x16: return ""LANG_PORTUGUESE"";	case 0x46: return ""LANG_PUNJABI"";	case 0x18: return ""LANG_ROMANIAN"";	case 0x19: return ""LANG_RUSSIAN"";	case 0x4f: return ""LANG_SANSKRIT"";	case 0x59: return ""LANG_SINDHI"";	case 0x1b: return ""LANG_SLOVAK"";	case 0x24: return ""LANG_SLOVENIAN"";	case 0x0a: return ""LANG_SPANISH "";	case 0x41: return ""LANG_SWAHILI"";	case 0x1d: return ""LANG_SWEDISH"";	case 0x5a: return ""LANG_SYRIAC"";	case 0x49: return ""LANG_TAMIL"";	case 0x44: return ""LANG_TATAR"";	case 0x4a: return ""LANG_TELUGU"";	case 0x1e: return ""LANG_THAI"";	case 0x1f: return ""LANG_TURKISH"";	case 0x22: return ""LANG_UKRAINIAN"";	case 0x20: return ""LANG_URDU"";	case 0x43: return ""LANG_UZBEK"";	case 0x2a: return ""LANG_VIETNAMESE"";	case 0x3c: return ""LANG_GAELIC"";	case 0x3a: return ""LANG_MALTESE"";	case 0x28: return ""LANG_MAORI"";	case 0x17: return ""LANG_RHAETO_ROMANCE"";	case 0x3b: return ""LANG_SAAMI"";	case 0x2e: return ""LANG_SORBIAN"";	case 0x30: return ""LANG_SUTU"";	case 0x31: return ""LANG_TSONGA"";	case 0x32: return ""LANG_TSWANA"";	case 0x33: return ""LANG_VENDA"";	case 0x34: return ""LANG_XHOSA"";	case 0x35: return ""LANG_ZULU"";	case 0x8f: return ""LANG_ESPERANTO"";	case 0x90: return ""LANG_WALON"";	case 0x91: return ""LANG_CORNISH"";	case 0x92: return ""LANG_WELSH"";	case 0x93: return ""LANG_BRETON"";	default: return ""UNKNOWN"";	}}",25154
245,676,CVE-2018-18445,18,"static int is_ctx_reg(struct bpf_verifier_env *env, int regno){	const struct bpf_reg_state *reg = cur_regs(env) + regno;	return reg->type == PTR_TO_CTX;}",23522
115,1024,CVE-2017-0812,18,"static int in_dump(const struct audio_stream *stream, int fd){ (void)stream; (void)fd; return 0;}",30752
136,377,CVE-2017-11664,18,"static int midi_setup_lyric(struct _mdi *mdi, char * text) {    MIDI_EVENT_SDEBUG(__FUNCTION__,0, text);    strip_text(text);    _WM_CheckEventMemoryPool(mdi);    mdi->events[mdi->event_count].do_event = *_WM_do_meta_lyric;    mdi->events[mdi->event_count].event_data.channel = 0;    mdi->events[mdi->event_count].event_data.data.string = text;    mdi->events[mdi->event_count].samples_to_next = 0;    mdi->event_count++;    return (0);}",20510
84,299,CVE-2017-14166,18,"move_reading_point(struct archive_read *a, int offset){	struct xar *xar;	xar = (struct xar *)(a->format->data);	if (xar->offset - xar->h_base != offset) {		 		int step;		step = offset - (xar->offset - xar->h_base);		if (step > 0) {			step = __archive_read_consume(a, step);			if (step < 0)				return ((int)step);			xar->offset += step;		} else {			int pos = __archive_read_seek(a, offset, SEEK_SET);			if (pos == ARCHIVE_FAILED) {				archive_set_error(&(a->archive),				    ARCHIVE_ERRNO_MISC,				    ""Cannot seek."");				return (ARCHIVE_FAILED);			}			xar->offset = pos;		}	}	return (ARCHIVE_OK);}",20172
10,540,CVE-2016-10197,18,evdns_base_search_clear(struct evdns_base *base){	EVDNS_LOCK(base);	search_postfix_clear(base);	EVDNS_UNLOCK(base);},22359
113,542,CVE-2016-10197,18,"evdns_base_set_max_requests_inflight(struct evdns_base *base, int maxinflight){	int old_n_heads = base->n_req_heads, n_heads;	struct request **old_heads = base->req_heads, **new_heads, *req;	int i;	ASSERT_LOCKED(base);	if (maxinflight < 1)		maxinflight = 1;	n_heads = (maxinflight+4) / 5;	EVUTIL_ASSERT(n_heads > 0);	new_heads = mm_calloc(n_heads, sizeof(struct request*));	if (!new_heads)		return (-1);	if (old_heads) {		for (i = 0; i < old_n_heads; ++i) {			while (old_heads[i]) {				req = old_heads[i];				evdns_request_remove(req, &old_heads[i]);				evdns_request_insert(req, &new_heads[req->trans_id % n_heads]);			}		}		mm_free(old_heads);	}	base->req_heads = new_heads;	base->n_req_heads = n_heads;	base->global_max_requests_inflight = maxinflight;	return (0);}",22361
180,314,CVE-2017-13051,18,rsvp_clear_checksum(void *header){    struct rsvp_common_header *rsvp_com_header = (struct rsvp_common_header *) header;    rsvp_com_header->checksum[0] = 0;    rsvp_com_header->checksum[1] = 0;},20265
215,822,CVE-2018-16427,18,"auth_restore_security_env(struct sc_card *card, int se_num){	return SC_SUCCESS;}",24349
72,19,CVE-2017-9739,18,  static void  Ins_ABS( INS_ARG )  { (void)exc;    args[0] = ABS( args[0] );  },898
197,828,CVE-2018-16427,18,"tlv_get(const unsigned char *msg, int len, unsigned char tag,		unsigned char *ret, int *ret_len){	int cur = 0;	while (cur < len)  {		if (*(msg+cur)==tag)  {			int ii, ln = *(msg+cur+1);			if (ln > *ret_len)				return SC_ERROR_WRONG_LENGTH;			for (ii=0; ii<ln; ii++)				*(ret + ii) = *(msg+cur+2+ii);			*ret_len = ln;			return SC_SUCCESS;		}		cur += 2 + *(msg+cur+1);	}	return SC_ERROR_INCORRECT_PARAMETERS;}",24355
82,234,CVE-2017-16533,18,"struct usb_interface *usbhid_find_interface(int minor){	return usb_find_interface(&hid_driver, minor);}",19736
238,673,CVE-2018-18445,18,"static int get_callee_stack_depth(struct bpf_verifier_env *env,				  const struct bpf_insn *insn, int idx){	int start = idx + insn->imm + 1, subprog;	subprog = find_subprog(env, start);	if (subprog < 0) {		WARN_ONCE(1, ""verifier bug. No program starts at insn %d\n"",			  start);		return -EFAULT;	}	return env->subprog_info[subprog].stack_depth;}",23519
37,367,CVE-2017-11664,18,"int _WM_midi_setup_tempo(struct _mdi *mdi, int setting) {    MIDI_EVENT_DEBUG(__FUNCTION__,0,setting);    _WM_CheckEventMemoryPool(mdi);    mdi->events[mdi->event_count].do_event = *_WM_do_meta_tempo;    mdi->events[mdi->event_count].event_data.channel = 0;    mdi->events[mdi->event_count].event_data.data.value = setting;    mdi->events[mdi->event_count].samples_to_next = 0;    mdi->event_count++;    return (0);}",20500
252,204,CVE-2017-16535,18,"static int find_next_descriptor(unsigned char *buffer, int size,    int dt1, int dt2, int *num_skipped){	struct usb_descriptor_header *h;	int n = 0;	unsigned char *buffer0 = buffer;	 	while (size > 0) {		h = (struct usb_descriptor_header *) buffer;		if (h->bDescriptorType == dt1 || h->bDescriptorType == dt2)			break;		buffer += h->bLength;		size -= h->bLength;		++n;	}	 	if (num_skipped)		*num_skipped = n;	return buffer - buffer0;}",19675
33,219,CVE-2017-16533,18,"static void hid_io_error(struct hid_device *hid){	unsigned long flags;	struct usbhid_device *usbhid = hid->driver_data;	spin_lock_irqsave(&usbhid->lock, flags);	 	if (test_bit(HID_DISCONNECTED, &usbhid->iofl))		goto done;	 	if (time_after(jiffies, usbhid->stop_retry + HZ/2))		usbhid->retry_delay = 0;	 	if (usbhid->retry_delay == 0) {		usbhid->retry_delay = 13;	 		usbhid->stop_retry = jiffies + msecs_to_jiffies(1000);	} else if (usbhid->retry_delay < 100)		usbhid->retry_delay *= 2;	if (time_after(jiffies, usbhid->stop_retry)) {		 		if (!test_bit(HID_NO_BANDWIDTH, &usbhid->iofl)		     && !test_and_set_bit(HID_RESET_PENDING, &usbhid->iofl)) {			schedule_work(&usbhid->reset_work);			goto done;		}	}	mod_timer(&usbhid->io_retry,			jiffies + msecs_to_jiffies(usbhid->retry_delay));done:	spin_unlock_irqrestore(&usbhid->lock, flags);}",19721
241,16,CVE-2017-11147,18,ZEND_INI_MH(phar_ini_cache_list)  {	PHAR_G(cache_list) = new_value;	if (stage == ZEND_INI_STAGE_STARTUP) {		phar_split_cache_list(TSRMLS_C);	}	return SUCCESS;} ,818
227,1055,CVE-2018-9506,18,"void avrc_flush_cmd_q(int handle) {  AVRC_TRACE_DEBUG(""AVRC: Flushing command queue for handle=0x%02x"", handle);  avrc_cb.ccb_int[handle].flags &= ~AVRC_CB_FLAGS_RSP_PENDING;  alarm_cancel(avrc_cb.ccb_int[handle].tle);  fixed_queue_free(avrc_cb.ccb_int[handle].cmd_q, osi_free);  avrc_cb.ccb_int[handle].cmd_q = NULL;}",30789
209,1037,CVE-2017-0812,18,static int out_get_channels(const struct audio_stream *stream){ struct stream_out *out = (struct stream_out *)stream; return out->channel_mask;},30765
116,369,CVE-2017-11664,18,"static int midi_setup_aftertouch(struct _mdi *mdi, int channel,                                 int note, int pressure) {    MIDI_EVENT_DEBUG(__FUNCTION__,channel, note);    _WM_CheckEventMemoryPool(mdi);    mdi->events[mdi->event_count].do_event = *_WM_do_aftertouch;    mdi->events[mdi->event_count].event_data.channel = channel;    mdi->events[mdi->event_count].event_data.data.value = (note << 8) | pressure;    mdi->events[mdi->event_count].samples_to_next = 0;    mdi->event_count++;    return (0);}",20502
235,1026,CVE-2017-0812,18,static int in_get_channels(const struct audio_stream *stream){ struct stream_in *in = (struct stream_in *)stream; return in->main_channels;},30754
226,77,CVE-2017-9620,18,"xps_parse_digits(char *s, int *digit){    *digit = 0;    while (*s >= '0' && *s <= '9')    {        *digit = *digit * 10 + (*s - '0');        s ++;    }    return s;}",957
145,136,CVE-2016-9777,18,"void kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode){	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;	spin_lock(&ioapic->lock);	__kvm_ioapic_update_eoi(vcpu, ioapic, vector, trigger_mode);	spin_unlock(&ioapic->lock);}",15088
13,445,CVE-2017-7277,18,"static int skb_may_tx_timestamp(struct sock *sk, int tsonly){	int ret;	if (likely(sysctl_tstamp_allow_data || tsonly))		return true;	read_lock_bh(&sk->sk_callback_lock);	ret = sk->sk_socket && sk->sk_socket->file &&	      file_ns_capable(sk->sk_socket->file, &init_user_ns, CAP_NET_RAW);	read_unlock_bh(&sk->sk_callback_lock);	return ret;}",21755
78,300,CVE-2017-14166,18,"rd_contents_init(struct archive_read *a, enum enctype encoding,    int a_sum_alg, int e_sum_alg){	int r;	 	if ((r = decompression_init(a, encoding)) != ARCHIVE_OK)		return (r);	 	checksum_init(a, a_sum_alg, e_sum_alg);	return (ARCHIVE_OK);}",20173
253,807,CVE-2018-16427,18,"auth_get_default_key(struct sc_card *card, struct sc_cardctl_default_key *data){	LOG_FUNC_RETURN(card->ctx, SC_ERROR_NO_DEFAULT_KEY);}",24334
229,678,CVE-2018-18445,18,"static int is_state_visited(struct bpf_verifier_env *env, int insn_idx){	struct bpf_verifier_state_list *new_sl;	struct bpf_verifier_state_list *sl;	struct bpf_verifier_state *cur = env->cur_state;	int i, j, err;	sl = env->explored_states[insn_idx];	if (!sl)		 		return 0;	while (sl != STATE_LIST_MARK) {		if (states_equal(env, &sl->state, cur)) {			 			err = propagate_liveness(env, &sl->state, cur);			if (err)				return err;			return 1;		}		sl = sl->next;	}	 	new_sl = kzalloc(sizeof(struct bpf_verifier_state_list), GFP_KERNEL);	if (!new_sl)		return -ENOMEM;	 	err = copy_verifier_state(&new_sl->state, cur);	if (err) {		free_verifier_state(&new_sl->state, false);		kfree(new_sl);		return err;	}	new_sl->next = env->explored_states[insn_idx];	env->explored_states[insn_idx] = new_sl;	 	cur->parent = &new_sl->state;	 	for (i = 0; i < BPF_REG_FP; i++)		cur->frame[cur->curframe]->regs[i].live = REG_LIVE_NONE;	 	for (j = 0; j <= cur->curframe; j++) {		struct bpf_func_state *frame = cur->frame[j];		for (i = 0; i < frame->allocated_stack / BPF_REG_SIZE; i++)			frame->stack[i].spilled_ptr.live = REG_LIVE_NONE;	}	return 0;}",23524
263,70,CVE-2017-9739,18,  static void  Ins_SZPS( INS_ARG )  {    switch ( args[0] )    {    case 0:      CUR.zp0 = CUR.twilight;      break;    case 1:      CUR.zp0 = CUR.pts;      break;    default:      CUR.error = TT_Err_Invalid_Reference;      return;    }    CUR.zp1 = CUR.zp0;    CUR.zp2 = CUR.zp0;    CUR.GS.gep0 = (Int)(args[0]);    CUR.GS.gep1 = (Int)(args[0]);    CUR.GS.gep2 = (Int)(args[0]);  },949
179,714,CVE-2018-16790,18,"test_bson_has_field (void){   bson_t *b;   int r;   b = BCON_NEW (""foo"", ""["", ""{"", ""bar"", BCON_INT32 (1), ""}"", ""]"");   r = bson_has_field (b, ""foo"");   BSON_ASSERT (r);   r = bson_has_field (b, ""foo.0"");   BSON_ASSERT (r);   r = bson_has_field (b, ""foo.0.bar"");   BSON_ASSERT (r);   r = bson_has_field (b, ""0"");   BSON_ASSERT (!r);   r = bson_has_field (b, ""bar"");   BSON_ASSERT (!r);   r = bson_has_field (b, ""0.bar"");   BSON_ASSERT (!r);   bson_destroy (b);}",24238
52,457,CVE-2017-7277,18,"static void init_inodecache(void){	sock_inode_cachep = kmem_cache_create(""sock_inode_cache"",					      sizeof(struct socket_alloc),					      0,					      (SLAB_HWCACHE_ALIGN |					       SLAB_RECLAIM_ACCOUNT |					       SLAB_MEM_SPREAD | SLAB_ACCOUNT),					      init_once);	BUG_ON(sock_inode_cachep == NULL);}",21767
244,174,CVE-2016-7915,18,"int hid_open_report(struct hid_device *device){	struct hid_parser *parser;	struct hid_item item;	unsigned int size;	__u8 *start;	__u8 *buf;	__u8 *end;	int ret;	static int (*dispatch_type[])(struct hid_parser *parser,				      struct hid_item *item) = {		hid_parser_main,		hid_parser_global,		hid_parser_local,		hid_parser_reserved	};	if (WARN_ON(device->status & HID_STAT_PARSED))		return -EBUSY;	start = device->dev_rdesc;	if (WARN_ON(!start))		return -ENODEV;	size = device->dev_rsize;	buf = kmemdup(start, size, GFP_KERNEL);	if (buf == NULL)		return -ENOMEM;	if (device->driver->report_fixup)		start = device->driver->report_fixup(device, buf, &size);	else		start = buf;	start = kmemdup(start, size, GFP_KERNEL);	kfree(buf);	if (start == NULL)		return -ENOMEM;	device->rdesc = start;	device->rsize = size;	parser = vzalloc(sizeof(struct hid_parser));	if (!parser) {		ret = -ENOMEM;		goto err;	}	parser->device = device;	end = start + size;	device->collection = kcalloc(HID_DEFAULT_NUM_COLLECTIONS,				     sizeof(struct hid_collection), GFP_KERNEL);	if (!device->collection) {		ret = -ENOMEM;		goto err;	}	device->collection_size = HID_DEFAULT_NUM_COLLECTIONS;	ret = -EINVAL;	while ((start = fetch_item(start, end, &item)) != NULL) {		if (item.format != HID_ITEM_FORMAT_SHORT) {			hid_err(device, ""unexpected long global item\n"");			goto err;		}		if (dispatch_type[item.type](parser, &item)) {			hid_err(device, ""item %u %u %u %u parsing failed\n"",				item.format, (unsigned)item.size,				(unsigned)item.type, (unsigned)item.tag);			goto err;		}		if (start == end) {			if (parser->collection_stack_ptr) {				hid_err(device, ""unbalanced collection at end of report description\n"");				goto err;			}			if (parser->local.delimiter_depth) {				hid_err(device, ""unbalanced delimiter at end of report description\n"");				goto err;			}			vfree(parser);			device->status |= HID_STAT_PARSED;			return 0;		}	}	hid_err(device, ""item fetching failed at offset %d\n"", (int)(end - start));err:	vfree(parser);	hid_close_report(device);	return ret;}",15668
178,428,CVE-2017-7277,18,void __kfree_skb_defer(struct sk_buff *skb){	_kfree_skb_defer(skb);},21738
18,189,CVE-2016-6520,18,"static inline void ModulateHSV(const double percent_hue,  const double percent_saturation,const double percent_value,double *red,  double *green,double *blue){  double    hue,    saturation,    value;     ConvertRGBToHSV(*red,*green,*blue,&hue,&saturation,&value);  hue+=0.5*(0.01*percent_hue-1.0);  while (hue < 0.0)    hue+=1.0;  while (hue >= 1.0)    hue-=1.0;  saturation*=0.01*percent_saturation;  value*=0.01*percent_value;  ConvertHSVToRGB(hue,saturation,value,red,green,blue);}",15999
58,68,CVE-2017-9739,18,  static void  Ins_SZP1( INS_ARG )  {    switch ( args[0] )    {    case 0:      CUR.zp1 = CUR.twilight;      break;    case 1:      CUR.zp1 = CUR.pts;      break;    default:      CUR.error = TT_Err_Invalid_Reference;      return;    }    CUR.GS.gep1 = (Int)(args[0]);  },947
260,563,CVE-2016-10197,18,"evdns_request_transmit_to(struct request *req, struct nameserver *server) {	int r;	ASSERT_LOCKED(req->base);	ASSERT_VALID_REQUEST(req);	if (server->requests_inflight == 1 &&		req->base->disable_when_inactive &&		event_add(&server->event, NULL) < 0) {		return 1;	}	r = sendto(server->socket, (void*)req->request, req->request_len, 0,	    (struct sockaddr *)&server->address, server->addrlen);	if (r < 0) {		int err = evutil_socket_geterror(server->socket);		if (EVUTIL_ERR_RW_RETRIABLE(err))			return 1;		nameserver_failed(req->ns, evutil_socket_error_to_string(err));		return 2;	} else if (r != (int)req->request_len) {		return 1;   	} else {		return 0;	}}",22382
140,448,CVE-2017-7277,18,"static struct sk_buff *skb_reorder_vlan_header(struct sk_buff *skb){	if (skb_cow(skb, skb_headroom(skb)) < 0) {		kfree_skb(skb);		return NULL;	}	memmove(skb->data - ETH_HLEN, skb->data - skb->mac_len - VLAN_HLEN,		2 * ETH_ALEN);	skb->mac_header += VLAN_HLEN;	return skb;}",21758
132,39,CVE-2017-9739,18,  static void  Ins_JROT( INS_ARG )  {    if ( args[1] != 0 )    {      CUR.IP      += (Int)(args[0]);      CUR.step_ins = FALSE;             if(CUR.IP > CUR.codeSize ||         (CUR.code[CUR.IP] != 0x2D && CUR.code[CUR.IP - 1] == 0x2D))        CUR.IP -= 1;    }  },918
246,624,CVE-2016-3178,18,"removeDevice(const struct header * headers){	struct device ** pp = &devlist;	struct device * p = *pp;	 	while(p)	{		if(  p->headers[HEADER_NT].l == headers[HEADER_NT].l		  && (0==memcmp(p->headers[HEADER_NT].p, headers[HEADER_NT].p, headers[HEADER_NT].l))		  && p->headers[HEADER_USN].l == headers[HEADER_USN].l		  && (0==memcmp(p->headers[HEADER_USN].p, headers[HEADER_USN].p, headers[HEADER_USN].l)) )		{			syslog(LOG_INFO, ""remove device : %.*s"", headers[HEADER_USN].l, headers[HEADER_USN].p);			sendNotifications(NOTIF_REMOVE, p, NULL);			*pp = p->next;			free(p);			return -1;		}		pp = &p->next;		p = *pp;	 	}	syslog(LOG_WARNING, ""device not found for removing : %.*s"", headers[HEADER_USN].l, headers[HEADER_USN].p);	return 0;}",22837
25,583,CVE-2016-10197,18,"find_hosts_entry(struct evdns_base *base, const char *hostname,    struct hosts_entry *find_after){	struct hosts_entry *e;	if (find_after)		e = TAILQ_NEXT(find_after, next);	else		e = TAILQ_FIRST(&base->hostsdb);	for (; e; e = TAILQ_NEXT(e, next)) {		if (!evutil_ascii_strcasecmp(e->hostname, hostname))			return e;	}	return NULL;}",22402
133,979,CVE-2013-7456,18,"static inline int _color_blend (const int dst, const int src){    const int src_alpha = gdTrueColorGetAlpha(src);    if( src_alpha == gdAlphaOpaque ) {		return src;	} else {		const int dst_alpha = gdTrueColorGetAlpha(dst);		if( src_alpha == gdAlphaTransparent ) return dst;		if( dst_alpha == gdAlphaTransparent ) {			return src;		} else {			register int alpha, red, green, blue;			const int src_weight = gdAlphaTransparent - src_alpha;			const int dst_weight = (gdAlphaTransparent - dst_alpha) * src_alpha / gdAlphaMax;			const int tot_weight = src_weight + dst_weight;			alpha = src_alpha * dst_alpha / gdAlphaMax;			red = (gdTrueColorGetRed(src) * src_weight				   + gdTrueColorGetRed(dst) * dst_weight) / tot_weight;			green = (gdTrueColorGetGreen(src) * src_weight				   + gdTrueColorGetGreen(dst) * dst_weight) / tot_weight;			blue = (gdTrueColorGetBlue(src) * src_weight				   + gdTrueColorGetBlue(dst) * dst_weight) / tot_weight;			return ((alpha << 24) + (red << 16) + (green << 8) + blue);		} 	} }",28495
203,133,CVE-2016-9777,18,"int kvm_ioapic_init(struct kvm *kvm){	struct kvm_ioapic *ioapic;	int ret;	ioapic = kzalloc(sizeof(struct kvm_ioapic), GFP_KERNEL);	if (!ioapic)		return -ENOMEM;	spin_lock_init(&ioapic->lock);	INIT_DELAYED_WORK(&ioapic->eoi_inject, kvm_ioapic_eoi_inject_work);	kvm->arch.vioapic = ioapic;	kvm_ioapic_reset(ioapic);	kvm_iodevice_init(&ioapic->dev, &ioapic_mmio_ops);	ioapic->kvm = kvm;	mutex_lock(&kvm->slots_lock);	ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, ioapic->base_address,				      IOAPIC_MEM_LENGTH, &ioapic->dev);	mutex_unlock(&kvm->slots_lock);	if (ret < 0) {		kvm->arch.vioapic = NULL;		kfree(ioapic);		return ret;	}	kvm_vcpu_request_scan_ioapic(kvm);	return ret;}",15085
99,169,CVE-2016-7915,18,"static unsigned hid_lookup_collection(struct hid_parser *parser, unsigned type){	struct hid_collection *collection = parser->device->collection;	int n;	for (n = parser->collection_stack_ptr - 1; n >= 0; n--) {		unsigned index = parser->collection_stack[n];		if (collection[index].type == type)			return collection[index].usage;	}	return 0;  }",15663
93,489,CVE-2017-5601,18,"lzh_br_fillup(struct lzh_stream *strm, struct lzh_br *br){	int n = CACHE_BITS - br->cache_avail;	for (;;) {		const int x = n >> 3;		if (strm->avail_in >= x) {			switch (x) {			case 8:				br->cache_buffer =				    ((int)strm->next_in[0]) << 56 |				    ((int)strm->next_in[1]) << 48 |				    ((int)strm->next_in[2]) << 40 |				    ((int)strm->next_in[3]) << 32 |				    ((int)strm->next_in[4]) << 24 |				    ((int)strm->next_in[5]) << 16 |				    ((int)strm->next_in[6]) << 8 |				     (int)strm->next_in[7];				strm->next_in += 8;				strm->avail_in -= 8;				br->cache_avail += 8 * 8;				return (1);			case 7:				br->cache_buffer =		 		   (br->cache_buffer << 56) |				    ((int)strm->next_in[0]) << 48 |				    ((int)strm->next_in[1]) << 40 |				    ((int)strm->next_in[2]) << 32 |				    ((int)strm->next_in[3]) << 24 |				    ((int)strm->next_in[4]) << 16 |				    ((int)strm->next_in[5]) << 8 |				     (int)strm->next_in[6];				strm->next_in += 7;				strm->avail_in -= 7;				br->cache_avail += 7 * 8;				return (1);			case 6:				br->cache_buffer =		 		   (br->cache_buffer << 48) |				    ((int)strm->next_in[0]) << 40 |				    ((int)strm->next_in[1]) << 32 |				    ((int)strm->next_in[2]) << 24 |				    ((int)strm->next_in[3]) << 16 |				    ((int)strm->next_in[4]) << 8 |				     (int)strm->next_in[5];				strm->next_in += 6;				strm->avail_in -= 6;				br->cache_avail += 6 * 8;				return (1);			case 0:				 				return (1);			default:				break;			}		}		if (strm->avail_in == 0) {			 			return (0);		}		br->cache_buffer =		   (br->cache_buffer << 8) | *strm->next_in++;		strm->avail_in--;		br->cache_avail += 8;		n -= 8;	}}",21994
21,140,CVE-2016-9777,18,static int rtc_irq_check_coalesced(struct kvm_ioapic *ioapic){	if (ioapic->rtc_status.pending_eoi > 0)		return true;  	return false;},15092
188,347,CVE-2017-11664,18,"void _WM_do_control_data_decrement(struct _mdi *mdi,                                      struct _event_data *data) {    int ch = data->channel;    MIDI_EVENT_DEBUG(__FUNCTION__,ch, data->data.value);    if ((mdi->channel[ch].reg_non == 0)        && (mdi->channel[ch].reg_data == 0x0000)) {          if (mdi->channel[ch].pitch_range > 0)            mdi->channel[ch].pitch_range--;    }}",20480
168,908,CVE-2018-11363,18,"static int flexarray_set(struct flexarray *flex, int index, void *data){    int bin = flexarray_get_bin(flex, index);    if (bin < 0)        return -EINVAL;    if (bin >= flex->bin_count) {        void *bins = realloc(flex->bins, (flex->bin_count + 1) *                             sizeof(flex->bins));        if (!bins)            return -ENOMEM;        flex->bin_count++;        flex->bins = bins;        flex->bins[flex->bin_count - 1] =            calloc(flexarray_get_bin_size(flex, flex->bin_count - 1),                   sizeof(void *));        if (!flex->bins[flex->bin_count - 1]) {            flex->bin_count--;            return -ENOMEM;        }    }    flex->item_count++;    flex->bins[bin][flexarray_get_bin_offset(flex, bin, index)] = data;    return flex->item_count - 1;}",25168
147,774,CVE-2018-16427,18,"iasecc_emulate_fcp(struct sc_context *ctx, struct sc_apdu *apdu){	unsigned char dummy_df_fcp[] = {		0x62,0xFF,			0x82,0x01,0x38,			0x8A,0x01,0x05,			0xA1,0x04,0x8C,0x02,0x02,0x00,			0x84,0xFF,				0xFF,0xFF,0xFF,0xFF,0xFF,0xFF,0xFF,0xFF,				0xFF,0xFF,0xFF,0xFF,0xFF,0xFF,0xFF,0xFF	};	LOG_FUNC_CALLED(ctx);	if (apdu->p1 != 0x04)		LOG_TEST_RET(ctx, SC_ERROR_NOT_SUPPORTED, ""FCP emulation supported only for the DF-NAME selection type"");	if (apdu->datalen > 16)		LOG_TEST_RET(ctx, SC_ERROR_INVALID_DATA, ""Invalid DF-NAME length"");	if (apdu->resplen < apdu->datalen + 16)		LOG_TEST_RET(ctx, SC_ERROR_BUFFER_TOO_SMALL, ""not enough space for FCP data"");	memcpy(dummy_df_fcp + 16, apdu->data, apdu->datalen);	dummy_df_fcp[15] = apdu->datalen;	dummy_df_fcp[1] = apdu->datalen + 14;	memcpy(apdu->resp, dummy_df_fcp, apdu->datalen + 16);	LOG_FUNC_RETURN(ctx, SC_SUCCESS);}",24301
233,802,CVE-2018-16427,18,"auth_check_sw(struct sc_card *card, unsigned int sw1, unsigned int sw2){	int ii;	for (ii=0; auth_warnings[ii].SWs; ii++)   {		if (auth_warnings[ii].SWs == ((sw1 << 8) | sw2))   {			sc_log(card->ctx, ""%s"", auth_warnings[ii].errorstr);			return auth_warnings[ii].errorno;		}	}	return iso_ops->check_sw(card, sw1, sw2);}",24329
127,592,CVE-2016-10197,18,"request_submit(struct request *const req) {	struct evdns_base *base = req->base;	ASSERT_LOCKED(base);	ASSERT_VALID_REQUEST(req);	if (req->ns) {		 		 		evdns_request_insert(req, &REQ_HEAD(base, req->trans_id));		base->global_requests_inflight++;		req->ns->requests_inflight++;		evdns_request_transmit(req);	} else {		evdns_request_insert(req, &base->req_waiting_head);		base->global_requests_waiting++;	}}",22411
54,658,CVE-2018-18445,18,"static int check_max_stack_depth(struct bpf_verifier_env *env){	int depth = 0, frame = 0, idx = 0, i = 0, subprog_end;	struct bpf_subprog_info *subprog = env->subprog_info;	struct bpf_insn *insn = env->prog->insnsi;	int ret_insn[MAX_CALL_FRAMES];	int ret_prog[MAX_CALL_FRAMES];process_func:	 	depth += round_up(max_t(u32, subprog[idx].stack_depth, 1), 32);	if (depth > MAX_BPF_STACK) {		verbose(env, ""combined stack size of %d calls is %d. Too large\n"",			frame + 1, depth);		return -EACCES;	}continue_func:	subprog_end = subprog[idx + 1].start;	for (; i < subprog_end; i++) {		if (insn[i].code != (BPF_JMP | BPF_CALL))			continue;		if (insn[i].src_reg != BPF_PSEUDO_CALL)			continue;		 		ret_insn[frame] = i + 1;		ret_prog[frame] = idx;		 		i = i + insn[i].imm + 1;		idx = find_subprog(env, i);		if (idx < 0) {			WARN_ONCE(1, ""verifier bug. No program starts at insn %d\n"",				  i);			return -EFAULT;		}		frame++;		if (frame >= MAX_CALL_FRAMES) {			WARN_ONCE(1, ""verifier bug. Call stack is too deep\n"");			return -EFAULT;		}		goto process_func;	}	 	if (frame == 0)		return 0;	depth -= round_up(max_t(u32, subprog[idx].stack_depth, 1), 32);	frame--;	i = ret_insn[frame];	idx = ret_prog[frame];	goto continue_func;}",23504
243,122,CVE-2017-18030,18,"static int blit_is_unsafe(struct CirrusVGAState *s, int dst_only){         assert(s->cirrus_blt_width > 0);    assert(s->cirrus_blt_height > 0);    if (s->cirrus_blt_width > CIRRUS_BLTBUFSIZE) {        return true;    }    if (blit_region_is_unsafe(s, s->cirrus_blt_dstpitch,                              s->cirrus_blt_dstaddr & s->cirrus_addr_mask)) {        return true;    }    if (dst_only) {        return false;    }    if (blit_region_is_unsafe(s, s->cirrus_blt_srcpitch,                              s->cirrus_blt_srcaddr & s->cirrus_addr_mask)) {        return true;    }    return false;}",2498
107,208,CVE-2017-16535,18,"static void usb_parse_ss_endpoint_companion(struct device *ddev, int cfgno,		int inum, int asnum, struct usb_host_endpoint *ep,		unsigned char *buffer, int size){	struct usb_ss_ep_comp_descriptor *desc;	int max_tx;	 	desc = (struct usb_ss_ep_comp_descriptor *) buffer;	if (desc->bDescriptorType != USB_DT_SS_ENDPOINT_COMP ||			size < USB_DT_SS_EP_COMP_SIZE) {		dev_warn(ddev, ""No SuperSpeed endpoint companion for config %d ""				"" interface %d altsetting %d ep %d: ""				""using minimum values\n"",				cfgno, inum, asnum, ep->desc.bEndpointAddress);		 		ep->ss_ep_comp.bLength = USB_DT_SS_EP_COMP_SIZE;		ep->ss_ep_comp.bDescriptorType = USB_DT_SS_ENDPOINT_COMP;		if (usb_endpoint_xfer_isoc(&ep->desc) ||				usb_endpoint_xfer_int(&ep->desc))			ep->ss_ep_comp.wBytesPerInterval =					ep->desc.wMaxPacketSize;		return;	}	buffer += desc->bLength;	size -= desc->bLength;	memcpy(&ep->ss_ep_comp, desc, USB_DT_SS_EP_COMP_SIZE);	 	if (usb_endpoint_xfer_control(&ep->desc) && desc->bMaxBurst != 0) {		dev_warn(ddev, ""Control endpoint with bMaxBurst = %d in ""				""config %d interface %d altsetting %d ep %d: ""				""setting to zero\n"", desc->bMaxBurst,				cfgno, inum, asnum, ep->desc.bEndpointAddress);		ep->ss_ep_comp.bMaxBurst = 0;	} else if (desc->bMaxBurst > 15) {		dev_warn(ddev, ""Endpoint with bMaxBurst = %d in ""				""config %d interface %d altsetting %d ep %d: ""				""setting to 15\n"", desc->bMaxBurst,				cfgno, inum, asnum, ep->desc.bEndpointAddress);		ep->ss_ep_comp.bMaxBurst = 15;	}	if ((usb_endpoint_xfer_control(&ep->desc) ||			usb_endpoint_xfer_int(&ep->desc)) &&				desc->bmAttributes != 0) {		dev_warn(ddev, ""%s endpoint with bmAttributes = %d in ""				""config %d interface %d altsetting %d ep %d: ""				""setting to zero\n"",				usb_endpoint_xfer_control(&ep->desc) ? ""Control"" : ""Bulk"",				desc->bmAttributes,				cfgno, inum, asnum, ep->desc.bEndpointAddress);		ep->ss_ep_comp.bmAttributes = 0;	} else if (usb_endpoint_xfer_bulk(&ep->desc) &&			desc->bmAttributes > 16) {		dev_warn(ddev, ""Bulk endpoint with more than 65536 streams in ""				""config %d interface %d altsetting %d ep %d: ""				""setting to max\n"",				cfgno, inum, asnum, ep->desc.bEndpointAddress);		ep->ss_ep_comp.bmAttributes = 16;	} else if (usb_endpoint_xfer_isoc(&ep->desc) &&		   !USB_SS_SSP_ISOC_COMP(desc->bmAttributes) &&		   USB_SS_MULT(desc->bmAttributes) > 3) {		dev_warn(ddev, ""Isoc endpoint has Mult of %d in ""				""config %d interface %d altsetting %d ep %d: ""				""setting to 3\n"",				USB_SS_MULT(desc->bmAttributes),				cfgno, inum, asnum, ep->desc.bEndpointAddress);		ep->ss_ep_comp.bmAttributes = 2;	}	if (usb_endpoint_xfer_isoc(&ep->desc))		max_tx = (desc->bMaxBurst + 1) *			(USB_SS_MULT(desc->bmAttributes)) *			usb_endpoint_maxp(&ep->desc);	else if (usb_endpoint_xfer_int(&ep->desc))		max_tx = usb_endpoint_maxp(&ep->desc) *			(desc->bMaxBurst + 1);	else		max_tx = 999999;	if (le16_to_cpu(desc->wBytesPerInterval) > max_tx) {		dev_warn(ddev, ""%s endpoint with wBytesPerInterval of %d in ""				""config %d interface %d altsetting %d ep %d: ""				""setting to %d\n"",				usb_endpoint_xfer_isoc(&ep->desc) ? ""Isoc"" : ""Int"",				le16_to_cpu(desc->wBytesPerInterval),				cfgno, inum, asnum, ep->desc.bEndpointAddress,				max_tx);		ep->ss_ep_comp.wBytesPerInterval = cpu_to_le16(max_tx);	}	 	if (usb_endpoint_xfer_isoc(&ep->desc) &&	    USB_SS_SSP_ISOC_COMP(desc->bmAttributes))		usb_parse_ssp_isoc_endpoint_companion(ddev, cfgno, inum, asnum,							ep, buffer, size);}",19679
151,656,CVE-2018-18445,18,"static int check_map_func_compatibility(struct bpf_verifier_env *env,					struct bpf_map *map, int func_id){	if (!map)		return 0;	 	switch (map->map_type) {	case BPF_MAP_TYPE_PROG_ARRAY:		if (func_id != BPF_FUNC_tail_call)			goto error;		break;	case BPF_MAP_TYPE_PERF_EVENT_ARRAY:		if (func_id != BPF_FUNC_perf_event_read &&		    func_id != BPF_FUNC_perf_event_output &&		    func_id != BPF_FUNC_perf_event_read_value)			goto error;		break;	case BPF_MAP_TYPE_STACK_TRACE:		if (func_id != BPF_FUNC_get_stackid)			goto error;		break;	case BPF_MAP_TYPE_CGROUP_ARRAY:		if (func_id != BPF_FUNC_skb_under_cgroup &&		    func_id != BPF_FUNC_current_task_under_cgroup)			goto error;		break;	case BPF_MAP_TYPE_CGROUP_STORAGE:		if (func_id != BPF_FUNC_get_local_storage)			goto error;		break;	 	case BPF_MAP_TYPE_DEVMAP:		if (func_id != BPF_FUNC_redirect_map)			goto error;		break;	 	case BPF_MAP_TYPE_CPUMAP:	case BPF_MAP_TYPE_XSKMAP:		if (func_id != BPF_FUNC_redirect_map)			goto error;		break;	case BPF_MAP_TYPE_ARRAY_OF_MAPS:	case BPF_MAP_TYPE_HASH_OF_MAPS:		if (func_id != BPF_FUNC_map_lookup_elem)			goto error;		break;	case BPF_MAP_TYPE_SOCKMAP:		if (func_id != BPF_FUNC_sk_redirect_map &&		    func_id != BPF_FUNC_sock_map_update &&		    func_id != BPF_FUNC_map_delete_elem &&		    func_id != BPF_FUNC_msg_redirect_map)			goto error;		break;	case BPF_MAP_TYPE_SOCKHASH:		if (func_id != BPF_FUNC_sk_redirect_hash &&		    func_id != BPF_FUNC_sock_hash_update &&		    func_id != BPF_FUNC_map_delete_elem &&		    func_id != BPF_FUNC_msg_redirect_hash)			goto error;		break;	case BPF_MAP_TYPE_REUSEPORT_SOCKARRAY:		if (func_id != BPF_FUNC_sk_select_reuseport)			goto error;		break;	default:		break;	}	 	switch (func_id) {	case BPF_FUNC_tail_call:		if (map->map_type != BPF_MAP_TYPE_PROG_ARRAY)			goto error;		if (env->subprog_cnt > 1) {			verbose(env, ""tail_calls are not allowed in programs with bpf-to-bpf calls\n"");			return -EINVAL;		}		break;	case BPF_FUNC_perf_event_read:	case BPF_FUNC_perf_event_output:	case BPF_FUNC_perf_event_read_value:		if (map->map_type != BPF_MAP_TYPE_PERF_EVENT_ARRAY)			goto error;		break;	case BPF_FUNC_get_stackid:		if (map->map_type != BPF_MAP_TYPE_STACK_TRACE)			goto error;		break;	case BPF_FUNC_current_task_under_cgroup:	case BPF_FUNC_skb_under_cgroup:		if (map->map_type != BPF_MAP_TYPE_CGROUP_ARRAY)			goto error;		break;	case BPF_FUNC_redirect_map:		if (map->map_type != BPF_MAP_TYPE_DEVMAP &&		    map->map_type != BPF_MAP_TYPE_CPUMAP &&		    map->map_type != BPF_MAP_TYPE_XSKMAP)			goto error;		break;	case BPF_FUNC_sk_redirect_map:	case BPF_FUNC_msg_redirect_map:	case BPF_FUNC_sock_map_update:		if (map->map_type != BPF_MAP_TYPE_SOCKMAP)			goto error;		break;	case BPF_FUNC_sk_redirect_hash:	case BPF_FUNC_msg_redirect_hash:	case BPF_FUNC_sock_hash_update:		if (map->map_type != BPF_MAP_TYPE_SOCKHASH)			goto error;		break;	case BPF_FUNC_get_local_storage:		if (map->map_type != BPF_MAP_TYPE_CGROUP_STORAGE)			goto error;		break;	case BPF_FUNC_sk_select_reuseport:		if (map->map_type != BPF_MAP_TYPE_REUSEPORT_SOCKARRAY)			goto error;		break;	default:		break;	}	return 0;error:	verbose(env, ""cannot pass map_type %d into func %s#%d\n"",		map->map_type, func_id_name(func_id), func_id);	return -EINVAL;}",23502
256,575,CVE-2016-10197,18,"evdns_server_request_add_reply(struct evdns_server_request *req_, int section, const char *name, int type, int class, int ttl, int datalen, int is_name, const char *data){	struct server_request *req = TO_SERVER_REQUEST(req_);	struct server_reply_item **itemp, *item;	int *countp;	int result = -1;	EVDNS_LOCK(req->port);	if (req->response)  		goto done;	switch (section) {	case EVDNS_ANSWER_SECTION:		itemp = &req->answer;		countp = &req->n_answer;		break;	case EVDNS_AUTHORITY_SECTION:		itemp = &req->authority;		countp = &req->n_authority;		break;	case EVDNS_ADDITIONAL_SECTION:		itemp = &req->additional;		countp = &req->n_additional;		break;	default:		goto done;	}	while (*itemp) {		itemp = &((*itemp)->next);	}	item = mm_malloc(sizeof(struct server_reply_item));	if (!item)		goto done;	item->next = NULL;	if (!(item->name = mm_strdup(name))) {		mm_free(item);		goto done;	}	item->type = type;	item->dns_question_class = class;	item->ttl = ttl;	item->is_name = is_name != 0;	item->datalen = 0;	item->data = NULL;	if (data) {		if (item->is_name) {			if (!(item->data = mm_strdup(data))) {				mm_free(item->name);				mm_free(item);				goto done;			}			item->datalen = (u16)-1;		} else {			if (!(item->data = mm_malloc(datalen))) {				mm_free(item->name);				mm_free(item);				goto done;			}			item->datalen = datalen;			memcpy(item->data, data, datalen);		}	}	*itemp = item;	++(*countp);	result = 0;done:	EVDNS_UNLOCK(req->port);	return result;}",22394
88,166,CVE-2016-7915,18,static void hid_free_report(struct hid_report *report){	unsigned n;	for (n = 0; n < report->maxfield; n++)		kfree(report->field[n]);	kfree(report);},15660
100,79,CVE-2017-9620,18,"xps_parse_glyph_index(char *s, int *glyph_index){    if (*s >= '0' && *s <= '9')        s = xps_parse_digits(s, glyph_index);    return s;}",959
213,724,CVE-2018-16427,18,"authentic_debug_select_file(struct sc_card *card, const struct sc_path *path){	struct sc_context *ctx = card->ctx;	struct sc_card_cache *cache = &card->cache;	if (path)		sc_log(ctx, ""try to select path(type:%i) %s"",				path->type, sc_print_path(path));	if (!cache->valid)		return;	if (cache->current_df)		sc_log(ctx, ""current_df(type=%i) %s"",				cache->current_df->path.type, sc_print_path(&cache->current_df->path));	else		sc_log(ctx, ""current_df empty"");	if (cache->current_ef)		sc_log(ctx, ""current_ef(type=%i) %s"",				cache->current_ef->path.type, sc_print_path(&cache->current_ef->path));	else		sc_log(ctx, ""current_ef empty"");}",24251
257,737,CVE-2018-16427,18,sc_get_authentic_driver(void){	return sc_get_driver();},24264
231,155,CVE-2016-7915,18,"void __hid_request(struct hid_device *hid, struct hid_report *report,		int reqtype){	char *buf;	int ret;	int len;	buf = hid_alloc_report_buf(report, GFP_KERNEL);	if (!buf)		return;	len = hid_report_len(report);	if (reqtype == HID_REQ_SET_REPORT)		hid_output_report(report, buf);	ret = hid->ll_driver->raw_request(hid, report->id, buf, len,					  report->type, reqtype);	if (ret < 0) {		dbg_hid(""unable to complete request: %d\n"", ret);		goto out;	}	if (reqtype == HID_REQ_GET_REPORT)		hid_input_report(hid, report->type, buf, ret, 0);out:	kfree(buf);}",15649
261,222,CVE-2017-16533,18,"static int hid_pre_reset(struct usb_interface *intf){	struct hid_device *hid = usb_get_intfdata(intf);	struct usbhid_device *usbhid = hid->driver_data;	spin_lock_irq(&usbhid->lock);	set_bit(HID_RESET_PENDING, &usbhid->iofl);	spin_unlock_irq(&usbhid->lock);	hid_cease_io(usbhid);	return 0;}",19724
9,339,CVE-2017-11664,18,"void _WM_do_channel_pressure(struct _mdi *mdi, struct _event_data *data) {    int ch = data->channel;    struct _note *note_data = mdi->note;    MIDI_EVENT_DEBUG(__FUNCTION__,ch, data->data.value);    mdi->channel[ch].pressure = data->data.value;    while (note_data) {        if (!note_data->ignore_chan_events) {            if ((note_data->noteid >> 8) == ch) {                note_data->velocity = data->data.value & 0xff;                _WM_AdjustNoteVolumes(mdi, ch, note_data);                if (note_data->replay) {                    note_data->replay->velocity = data->data.value & 0xff;                    _WM_AdjustNoteVolumes(mdi, ch, note_data->replay);                }            }        }        note_data = note_data->next;    }}",20472
166,514,CVE-2016-10208,18,"static int ext4_enable_quotas(struct super_block *sb){	int type, err = 0;	unsigned long qf_inums[EXT4_MAXQUOTAS] = {		le32_to_cpu(EXT4_SB(sb)->s_es->s_usr_quota_inum),		le32_to_cpu(EXT4_SB(sb)->s_es->s_grp_quota_inum),		le32_to_cpu(EXT4_SB(sb)->s_es->s_prj_quota_inum)	};	int quota_mopt[EXT4_MAXQUOTAS] = {		test_opt(sb, USRQUOTA),		test_opt(sb, GRPQUOTA),		test_opt(sb, PRJQUOTA),	};	sb_dqopt(sb)->flags |= DQUOT_QUOTA_SYS_FILE;	for (type = 0; type < EXT4_MAXQUOTAS; type++) {		if (qf_inums[type]) {			err = ext4_quota_enable(sb, type, QFMT_VFS_V1,				DQUOT_USAGE_ENABLED |				(quota_mopt[type] ? DQUOT_LIMITS_ENABLED : 0));			if (err) {				ext4_warning(sb,					""Failed to enable quota tracking ""					""(type=%d, err=%d). Please run ""					""e2fsck to fix."", type, err);				return err;			}		}	}	return 0;}",22330
83,502,CVE-2017-5545,18,"static void print_usage(int argc, char *argv[]){    char *name = NULL;    name = strrchr(argv[0], '/');    printf(""Usage: %s -i|--infile FILE [-o|--outfile FILE] [-d|--debug]\n"", (name ? name + 1: argv[0]));    printf(""Convert a plist FILE from binary to XML format or vice-versa.\n\n"");    printf(""  -i, --infile FILE\tThe FILE to convert from\n"");    printf(""  -o, --outfile FILE\tOptional FILE to convert to or stdout if not used\n"");    printf(""  -d, --debug\t\tEnable extended debug output\n"");    printf(""\n"");}",22118
57,985,CVE-2017-5077,18,  ConnectionTracker() {},29868
80,543,CVE-2016-10197,18,"evdns_base_set_option(struct evdns_base *base,    const char *option, const char *val){	int res;	EVDNS_LOCK(base);	res = evdns_base_set_option_impl(base, option, val, DNS_OPTIONS_ALL);	EVDNS_UNLOCK(base);	return res;}",22362
155,883,CVE-2018-12684,18,"get_req_headers(const struct mg_request_info *ri,                const char *name,                const char **output,                int output_max_size){	int i;	int cnt = 0;	if (ri) {		for (i = 0; i < ri->num_headers && cnt < output_max_size; i++) {			if (!mg_strcasecmp(name, ri->http_headers[i].name)) {				output[cnt++] = ri->http_headers[i].value;			}		}	}	return cnt;}",25050
217,907,CVE-2018-11363,18,"static inline int flexarray_get_bin_size(struct flexarray *flex, int bin){    (void)flex;    if (bin >= ARRAY_SIZE(bin_offset))        return -1;    int next = bin_offset[bin + 1];    return next - bin_offset[bin];}",25167
239,554,CVE-2016-10197,18,"evdns_getaddrinfo_set_timeout(struct evdns_base *evdns_base,    struct evdns_getaddrinfo_request *data){	return event_add(&data->timeout, &evdns_base->global_getaddrinfo_allow_skew);}",22373
79,341,CVE-2017-11664,18,"void _WM_do_control_channel_balance(struct _mdi *mdi,                                       struct _event_data *data) {    int ch = data->channel;    MIDI_EVENT_DEBUG(__FUNCTION__,ch, data->data.value);    mdi->channel[ch].balance = data->data.value;    _WM_AdjustChannelVolumes(mdi, ch);}",20474
220,63,CVE-2017-9739,18,  static void  Ins_SRP1( INS_ARG )  {    CUR.GS.rp1 = (Int)(args[0]);  },942
86,105,CVE-2016-6294,18,"PHP_FUNCTION(locale_get_display_script){    get_icu_disp_value_src_php( LOC_SCRIPT_TAG , INTERNAL_FUNCTION_PARAM_PASSTHRU );}",1685
34,570,CVE-2016-10197,18,evdns_search_clear(void) {	evdns_base_search_clear(current_base);},22389
2,707,CVE-2018-16790,18,"test_bson_append_regex (void){   bson_t *b;   bson_t *b2;   b = bson_new ();   BSON_ASSERT (bson_append_regex (b, ""regex"", -1, ""^abcd"", ""ilx""));   b2 = get_bson (""test27.bson"");   BSON_ASSERT_BSON_EQUAL (b, b2);   bson_destroy (b);   bson_destroy (b2);}",24231
211,659,CVE-2018-18445,18,static int check_raw_mode_ok(const struct bpf_func_proto *fn){	int count = 0;	if (fn->arg1_type == ARG_PTR_TO_UNINIT_MEM)		count++;	if (fn->arg2_type == ARG_PTR_TO_UNINIT_MEM)		count++;	if (fn->arg3_type == ARG_PTR_TO_UNINIT_MEM)		count++;	if (fn->arg4_type == ARG_PTR_TO_UNINIT_MEM)		count++;	if (fn->arg5_type == ARG_PTR_TO_UNINIT_MEM)		count++;	 	return count <= 1;},23505
221,88,CVE-2019-5747,18,"static void change_listen_mode(int new_mode){	log1(""entering listen mode: %s"",		new_mode != LISTEN_NONE			? (new_mode == LISTEN_KERNEL ? ""kernel"" : ""raw"")			: ""none""	);	listen_mode = new_mode;	if (sockfd >= 0) {		close(sockfd);		sockfd = -1;	}	if (new_mode == LISTEN_KERNEL)		sockfd = udhcp_listen_socket(  CLIENT_PORT, client_config.interface);	else if (new_mode != LISTEN_NONE)		sockfd = udhcp_raw_socket(client_config.ifindex);	 }",1412
126,157,CVE-2016-7915,18,"static int hid_add_usage(struct hid_parser *parser, unsigned usage){	if (parser->local.usage_index >= HID_MAX_USAGES) {		hid_err(parser->device, ""usage index exceeded\n"");		return -1;	}	parser->local.usage[parser->local.usage_index] = usage;	parser->local.collection_index[parser->local.usage_index] =		parser->collection_stack_ptr ?		parser->collection_stack[parser->collection_stack_ptr - 1] : 0;	parser->local.usage_index++;	return 0;}",15651
38,147,CVE-2016-9539,18,"usage(void)  {  int i;  fprintf(stderr, ""\n%s\n"", TIFFGetVersion());  for (i = 0; usage_info[i] != NULL; i++)    fprintf(stderr, ""%s\n"", usage_info[i]);  exit(-1);  }",15188
102,403,CVE-2017-9985,18,"static int snd_msnd_activate_logical(int cfg, int num){	if (snd_msnd_write_cfg(cfg, IREG_LOGDEVICE, num))		return -EIO;	if (snd_msnd_write_cfg(cfg, IREG_ACTIVATE, LD_ACTIVATE))		return -EIO;	return 0;}",20692
142,776,CVE-2018-16427,18,"iasecc_get_algorithm(struct sc_context *ctx, const struct sc_security_env *env,		unsigned operation, unsigned mechanism){    const struct sc_supported_algo_info *info = NULL;    int ii;    if (!env)        return 0;    for (ii=0;ii<SC_MAX_SUPPORTED_ALGORITHMS && env->supported_algos[ii].reference; ii++)        if ((env->supported_algos[ii].operations & operation)			&& (env->supported_algos[ii].mechanism == mechanism))            break;    if (ii < SC_MAX_SUPPORTED_ALGORITHMS && env->supported_algos[ii].reference)   {        info = &env->supported_algos[ii];        sc_log(ctx, ""found IAS/ECC algorithm %X:%X:%X:%X"",			info->reference, info->mechanism, info->operations, info->algo_ref);    }    else   {        sc_log(ctx, ""cannot find IAS/ECC algorithm (operation:%X,mechanism:%X)"", operation, mechanism);    }    return info ? info->algo_ref : 0;}",24303
27,1049,CVE-2017-0812,18,"static int stop_input_stream(struct stream_in *in){ struct audio_usecase *uc_info; struct audio_device *adev = in->dev;    adev->active_input = NULL;    ALOGV(""%s: enter: usecase(%d: %s)"", __func__,          in->usecase, use_case_table[in->usecase]);    uc_info = get_usecase_from_id(adev, in->usecase); if (uc_info == NULL) {        ALOGE(""%s: Could not find the usecase (%d) in the list"",              __func__, in->usecase); return -EINVAL; }      disable_snd_device(adev, uc_info, uc_info->in_snd_device, true);    list_remove(&uc_info->adev_list_node);    free(uc_info); if (list_empty(&in->pcm_dev_list)) {        ALOGE(""%s: pcm device list empty"", __func__); return -EINVAL; }    in_release_pcm_devices(in);    list_init(&in->pcm_dev_list); return 0;}",30777
259,156,CVE-2016-7915,18,"static int close_collection(struct hid_parser *parser){	if (!parser->collection_stack_ptr) {		hid_err(parser->device, ""collection stack underflow\n"");		return -EINVAL;	}	parser->collection_stack_ptr--;	return 0;}",15650
265,236,CVE-2017-16533,18,static void usbhid_mark_busy(struct usbhid_device *usbhid){	struct usb_interface *intf = usbhid->intf;	usb_mark_last_busy(interface_to_usbdev(intf));},19738
192,1044,CVE-2017-0812,18,"static int out_standby(struct audio_stream *stream){ struct stream_out *out = (struct stream_out *)stream; struct audio_device *adev = out->dev;    ALOGV(""%s: enter: usecase(%d: %s)"", __func__,          out->usecase, use_case_table[out->usecase]);    lock_output_stream(out); if (!out->standby) {        pthread_mutex_lock(&adev->lock);        do_out_standby_l(out);        pthread_mutex_unlock(&adev->lock); }    pthread_mutex_unlock(&out->lock);    ALOGV(""%s: exit"", __func__); return 0;}",30772
161,998,CVE-2019-5770,18,  int IsApplicable() {    return !GetParam() ||           !gl_.context()->GetVersionInfo()->is_desktop_core_profile;  },30227
45,859,CVE-2018-12684,18,close_all_listening_sockets(struct mg_context *ctx){	unsigned int i;	if (!ctx) {		return;	}	for (i = 0; i < ctx->num_listening_sockets; i++) {		closesocket(ctx->listening_sockets[i].sock);		ctx->listening_sockets[i].sock = INVALID_SOCKET;	}	mg_free(ctx->listening_sockets);	ctx->listening_sockets = NULL;	mg_free(ctx->listening_socket_fds);	ctx->listening_socket_fds = NULL;},25026
103,715,CVE-2018-16790,18,test_bson_new_1mm (void){   bson_t *b;   int i;   for (i = 0; i < 1000000; i++) {      b = bson_new ();      bson_destroy (b);   }},24239
42,842,CVE-2018-16427,18,"static int hextoint(char *src, unsigned int len){	char hex[16];	char *end;	int res;	if(len >= sizeof(hex))		return -1;	strncpy(hex, src, len+1);	hex[len] = '\0';	res = strtol(hex, &end, 0x10);	if(end != (char*)&hex[len])		return -1;	return res;}",24369
5,698,CVE-2018-16790,18,"test_bson_append_code (void){   bson_t *b;   bson_t *b2;   b = bson_new ();   BSON_ASSERT (bson_append_code (b, ""code"", -1, ""var a = {};""));   b2 = get_bson (""test29.bson"");   BSON_ASSERT_BSON_EQUAL (b, b2);   bson_destroy (b);   bson_destroy (b2);}",24222
26,358,CVE-2017-11664,18,"void _WM_do_note_on(struct _mdi *mdi, struct _event_data *data) {    struct _note *nte;    struct _note *prev_nte;    struct _note *nte_array;    int freq = 0;    struct _patch *patch;    struct _sample *sample;    int ch = data->channel;    int note = (data->data.value >> 8);    int velocity = (data->data.value & 0xFF);    if (velocity == 0x00) {        _WM_do_note_off(mdi, data);        return;    }    MIDI_EVENT_DEBUG(__FUNCTION__,ch, data->data.value);    if (!mdi->channel[ch].isdrum) {        patch = mdi->channel[ch].patch;        if (patch == NULL) {            return;        }        freq = _WM_freq_table[(note % 12) * 100] >> (10 - (note / 12));    } else {        patch = _WM_get_patch_data(mdi,                               ((mdi->channel[ch].bank << 8) | note | 0x80));        if (patch == NULL) {            return;        }        if (patch->note) {            freq = _WM_freq_table[(patch->note % 12) * 100]            >> (10 - (patch->note / 12));        } else {            freq = _WM_freq_table[(note % 12) * 100] >> (10 - (note / 12));        }    }    sample = _WM_get_sample_data(patch, (freq / 100));    if (sample == NULL) {        return;    }    nte = &mdi->note_table[0][ch][note];    if (nte->active) {        if ((nte->modes & SAMPLE_ENVELOPE) && (nte->env < 3)            && (!(nte->hold & HOLD_OFF)))            return;        nte->replay = &mdi->note_table[1][ch][note];        nte->env = 6;        nte->env_inc = -nte->sample->env_rate[6];        nte = nte->replay;    } else {        if (mdi->note_table[1][ch][note].active) {            if ((nte->modes & SAMPLE_ENVELOPE) && (nte->env < 3)                && (!(nte->hold & HOLD_OFF)))                return;            mdi->note_table[1][ch][note].replay = nte;            mdi->note_table[1][ch][note].env = 6;            mdi->note_table[1][ch][note].env_inc =            -mdi->note_table[1][ch][note].sample->env_rate[6];        } else {            nte_array = mdi->note;            if (nte_array == NULL) {                mdi->note = nte;            } else {                do {                    prev_nte = nte_array;                    nte_array = nte_array->next;                } while (nte_array);                prev_nte->next = nte;            }            nte->active = 1;            nte->next = NULL;        }    }    nte->noteid = (ch << 8) | note;    nte->patch = patch;    nte->sample = sample;    nte->sample_pos = 0;    nte->sample_inc = get_inc(mdi, nte);    nte->velocity = velocity;    nte->env = 0;    nte->env_inc = nte->sample->env_rate[0];    nte->env_level = 0;    nte->modes = sample->modes;    nte->hold = mdi->channel[ch].hold;    nte->replay = NULL;    nte->is_off = 0;    nte->ignore_chan_events = 0;    _WM_AdjustNoteVolumes(mdi, ch, nte);}",20491
237,960,CVE-2019-8906,18,"toomany(struct magic_set *ms, const char *name, int num){	if (file_printf(ms, "", too many %s (%u)"", name, num) == -1)		return -1;	return 1;}",27293
77,981,CVE-2017-7277,18,static void skb_set_err_queue(struct sk_buff *skb){	 	skb->pkt_type = PACKET_OUTGOING;	BUILD_BUG_ON(PACKET_OUTGOING == 0);},28575
16,1010,CVE-2017-0812,18,"static int adev_get_master_mute(struct audio_hw_device *dev, int *muted){ (void)dev; (void)muted; return -ENOSYS;}",30738
175,335,CVE-2017-11664,18,"float _WM_GetSamplesPerTick(int divisions, int tempo) {    float microseconds_per_tick;    float secs_per_tick;    float samples_per_tick;         microseconds_per_tick = (float) tempo / (float) divisions;    secs_per_tick = microseconds_per_tick / 1000000.0f;    samples_per_tick = _WM_SampleRate * secs_per_tick;    return (samples_per_tick);}",20468
122,241,CVE-2017-16533,18,"static int usbhid_restart_out_queue(struct usbhid_device *usbhid){	struct hid_device *hid = usb_get_intfdata(usbhid->intf);	int kicked;	int r;	if (!hid || test_bit(HID_RESET_PENDING, &usbhid->iofl) ||			test_bit(HID_SUSPENDED, &usbhid->iofl))		return 0;	if ((kicked = (usbhid->outhead != usbhid->outtail))) {		hid_dbg(hid, ""Kicking head %d tail %d"", usbhid->outhead, usbhid->outtail);		 		r = usb_autopm_get_interface_async(usbhid->intf);		if (r < 0)			return r;		 		if (test_bit(HID_SUSPENDED, &usbhid->iofl)) {			usb_autopm_put_interface_no_suspend(usbhid->intf);			return r;		}		 		set_bit(HID_OUT_RUNNING, &usbhid->iofl);		if (hid_submit_out(hid)) {			clear_bit(HID_OUT_RUNNING, &usbhid->iofl);			usb_autopm_put_interface_async(usbhid->intf);		}		wake_up(&usbhid->wait);	}	return kicked;}",19743
174,810,CVE-2018-16427,18,"auth_init(struct sc_card *card){	struct auth_private_data *data;	struct sc_path path;	unsigned long flags;	int rv = 0;	data = calloc(1, sizeof(struct auth_private_data));	if (!data)		LOG_FUNC_RETURN(card->ctx, SC_ERROR_OUT_OF_MEMORY);	card->cla = 0x00;	card->drv_data = data;	card->caps |= SC_CARD_CAP_RNG;	card->caps |= SC_CARD_CAP_USE_FCI_AC;	if (auth_select_aid(card))   {		sc_log(card->ctx, ""Failed to initialize %s"", card->name);		LOG_TEST_RET(card->ctx, SC_ERROR_INVALID_CARD, ""Failed to initialize"");	}	flags = SC_ALGORITHM_RSA_PAD_PKCS1 | SC_ALGORITHM_RSA_PAD_ISO9796;	flags |= SC_ALGORITHM_RSA_HASH_NONE;	flags |= SC_ALGORITHM_ONBOARD_KEY_GEN;	_sc_card_add_rsa_alg(card, 512, flags, 0);	_sc_card_add_rsa_alg(card, 1024, flags, 0);	_sc_card_add_rsa_alg(card, 2048, flags, 0);	sc_format_path(""3F00"", &path);	rv = auth_select_file(card, &path, NULL);	LOG_FUNC_RETURN(card->ctx, rv);}",24337
94,695,CVE-2018-16790,18,"test_bson_append_binary (void){   const static int binary[] = {'1', '2', '3', '4'};   bson_t *b;   bson_t *b2;   b = bson_new ();   BSON_ASSERT (      bson_append_binary (b, ""binary"", -1, BSON_SUBTYPE_USER, binary, 4));   b2 = get_bson (""test24.bson"");   BSON_ASSERT_BSON_EQUAL (b, b2);   bson_destroy (b);   bson_destroy (b2);}",24219
164,709,CVE-2018-16790,18,"test_bson_append_symbol (void){   bson_t *b;   bson_t *b2;   b = bson_new ();   b2 = get_bson (""test32.bson"");   BSON_ASSERT (bson_append_symbol (b, ""hello"", -1, ""world"", -1));   BSON_ASSERT_BSON_EQUAL (b, b2);   bson_destroy (b);   bson_destroy (b2);}",24233
176,884,CVE-2018-12684,18,"get_uri_type(const char *uri){	int i;	const char *hostend, *portbegin;	char *portend;	unsigned long port;	 	if ((uri[0] == '*') && (uri[1] == '\0')) {		 		return 1;	}	 	for (i = 0; uri[i] != 0; i++) {		if (uri[i] < 33) {			 			return 0;		}		if (uri[i] > 126) {			 			return 0;		} else {			switch (uri[i]) {			case '""':   			case '<':   			case '>':   			case '\\':  			case '^':   			case '`':   			case '{':   			case '|':   			case '}':   				return 0;			default:				 				break;			}		}	}	 	if (uri[0] == '/') {		 		return 2;	}	 	 	for (i = 0; abs_uri_protocols[i].proto != NULL; i++) {		if (mg_strncasecmp(uri,		                   abs_uri_protocols[i].proto,		                   abs_uri_protocols[i].proto_len) == 0) {			hostend = strchr(uri + abs_uri_protocols[i].proto_len, '/');			if (!hostend) {				return 0;			}			portbegin = strchr(uri + abs_uri_protocols[i].proto_len, ':');			if (!portbegin) {				return 3;			}			port = strtoul(portbegin + 1, &portend, 10);			if ((portend != hostend) || (port <= 0) || !is_valid_port(port)) {				return 0;			}			return 4;		}	}	return 0;}",25051
112,1001,CVE-2018-6151,18,  int GetRemovalMask() {    return remover_->GetLastUsedRemovalMask();  },30246
36,1015,CVE-2017-0812,18,"static int adev_set_master_volume(struct audio_hw_device *dev, float volume){ (void)dev; (void)volume; return -ENOSYS;}",30743
148,548,CVE-2016-10197,18,"evdns_config_windows_nameservers(void){	if (!current_base) {		current_base = evdns_base_new(NULL, 1);		return current_base == NULL ? -1 : 0;	} else {		return evdns_base_config_windows_nameservers(current_base);	}}",22367
24,1008,CVE-2018-6151,18,  void UpdateDSEOrigin() { dse_changed_callback_.Run(); },30253
139,73,CVE-2017-9739,18,  static void skip_FDEF( EXEC_OP )  {         while ( SKIP_Code() == SUCCESS )    {      switch ( CUR.opcode )      {      case 0x89:           case 0x2c:             CUR.error = TT_Err_Nested_DEFS;        return;      case 0x2d:            return;      }    }  },952
20,409,CVE-2017-9985,18,"static void snd_msnd_unload(struct snd_card *card){	struct snd_msnd *chip = card->private_data;	iounmap(chip->mappedbase);	release_mem_region(chip->base, BUFFSIZE);	release_region(chip->io, DSP_NUMIO);	free_irq(chip->irq, chip);	snd_card_free(card);}",20698
117,304,CVE-2017-14166,18,xattr_free(struct xattr *xattr){	archive_string_free(&(xattr->name));	free(xattr);},20177
251,141,CVE-2016-9777,18,"static void rtc_irq_eoi(struct kvm_ioapic *ioapic, struct kvm_vcpu *vcpu){	if (test_and_clear_bit(vcpu->vcpu_id,			       ioapic->rtc_status.dest_map.map)) {		--ioapic->rtc_status.pending_eoi;		rtc_status_pending_eoi_check_valid(ioapic);	}}",15093
141,353,CVE-2017-11664,18,"void _WM_do_control_registered_param_course(struct _mdi *mdi,                                            struct _event_data *data) {    int ch = data->channel;    MIDI_EVENT_DEBUG(__FUNCTION__,ch, data->data.value);    mdi->channel[ch].reg_data = (mdi->channel[ch].reg_data & 0x7F)                                | (data->data.value << 7);    mdi->channel[ch].reg_non = 0;}",20486
207,789,CVE-2018-16427,18,"iasecc_sdo_get_data(struct sc_card *card, struct iasecc_sdo *sdo){	struct sc_context *ctx = card->ctx;	int rv, sdo_tag;	LOG_FUNC_CALLED(ctx);	sdo_tag = iasecc_sdo_tag_from_class(sdo->sdo_class);	rv = iasecc_sdo_get_tagged_data(card, sdo_tag, sdo);	 	if (rv != SC_ERROR_INCORRECT_PARAMETERS)		LOG_TEST_RET(ctx, rv, ""cannot parse ECC SDO data"");	rv = iasecc_sdo_get_tagged_data(card, IASECC_DOCP_TAG, sdo);	LOG_TEST_RET(ctx, rv, ""cannot parse ECC DOCP data"");	LOG_FUNC_RETURN(ctx, rv);}",24316
204,83,CVE-2016-7155,18,pvscsi_log2(int input){    int log = 0;    assert(input > 0);    while (input >> ++log) {    }     return log; },1404
210,680,CVE-2018-18445,18,"static int may_access_direct_pkt_data(struct bpf_verifier_env *env,				       const struct bpf_call_arg_meta *meta,				       enum bpf_access_type t){	switch (env->prog->type) {	case BPF_PROG_TYPE_LWT_IN:	case BPF_PROG_TYPE_LWT_OUT:	case BPF_PROG_TYPE_LWT_SEG6LOCAL:	case BPF_PROG_TYPE_SK_REUSEPORT:		 		if (t == BPF_WRITE)			return false;		 	case BPF_PROG_TYPE_SCHED_CLS:	case BPF_PROG_TYPE_SCHED_ACT:	case BPF_PROG_TYPE_XDP:	case BPF_PROG_TYPE_LWT_XMIT:	case BPF_PROG_TYPE_SK_SKB:	case BPF_PROG_TYPE_SK_MSG:		if (meta)			return meta->pkt_access;		env->seen_direct_write = true;		return true;	default:		return false;	}}",23526
69,631,CVE-2018-20553,18,"_our_safe_free(void *ptr, const char *funcname, const int line, const char *file){    assert(funcname);    assert(line);    assert(file);    if (ptr == NULL)        return;    free(ptr);}",23260
39,643,CVE-2018-18445,18,static void __mark_reg_unknown(struct bpf_reg_state *reg){	reg->type = SCALAR_VALUE;	reg->id = 0;	reg->off = 0;	reg->var_off = tnum_unknown;	reg->frameno = 0;	__mark_reg_unbounded(reg);},23489
232,847,CVE-2018-14016,18,void r_bin_mdmp_free(struct r_bin_mdmp_obj *obj) {	if (!obj) return;	r_list_free (obj->streams.ex_threads);	r_list_free (obj->streams.memories);	r_list_free (obj->streams.memories64.memories);	r_list_free (obj->streams.memory_infos);	r_list_free (obj->streams.modules);	r_list_free (obj->streams.operations);	r_list_free (obj->streams.thread_infos);	r_list_free (obj->streams.threads);	r_list_free (obj->streams.unloaded_modules);	r_list_free (obj->pe32_bins);	r_list_free (obj->pe64_bins);	r_buf_free (obj->b);	obj->b = NULL;	free (obj);	return;},24560
46,685,CVE-2018-18445,18,"record_func_map(struct bpf_verifier_env *env, struct bpf_call_arg_meta *meta,		int func_id, int insn_idx){	struct bpf_insn_aux_data *aux = &env->insn_aux_data[insn_idx];	if (func_id != BPF_FUNC_tail_call &&	    func_id != BPF_FUNC_map_lookup_elem &&	    func_id != BPF_FUNC_map_update_elem &&	    func_id != BPF_FUNC_map_delete_elem)		return 0;	if (meta->map_ptr == NULL) {		verbose(env, ""kernel subsystem misconfigured verifier\n"");		return -EINVAL;	}	if (!BPF_MAP_PTR(aux->map_state))		bpf_map_ptr_store(aux, meta->map_ptr,				  meta->map_ptr->unpriv_array);	else if (BPF_MAP_PTR(aux->map_state) != meta->map_ptr)		bpf_map_ptr_store(aux, BPF_MAP_PTR_POISON,				  meta->map_ptr->unpriv_array);	return 0;}",23531
144,873,CVE-2018-12684,18,"event_wait(void *eventhdl){	int u;	int evhdl, s;	if (!eventhdl) {		 		return 0;	}	evhdl = *(int *)eventhdl;	s = (int)read(evhdl, &u, sizeof(u));	if (s != sizeof(u)) {		 		return 0;	}	(void)u;  	return 1;}",25040
63,201,CVE-2017-16643,18,"static void gtco_disconnect(struct usb_interface *interface){	 	struct gtco *gtco = usb_get_intfdata(interface);	struct usb_device *udev = interface_to_usbdev(interface);	 	if (gtco) {		input_unregister_device(gtco->inputdevice);		usb_kill_urb(gtco->urbinfo);		usb_free_urb(gtco->urbinfo);		usb_free_coherent(udev, REPORT_MAX_SIZE,				  gtco->buffer, gtco->buf_dma);		kfree(gtco);	}	dev_info(&interface->dev, ""gtco driver disconnected\n"");}",19672
225,45,CVE-2017-9739,18,  static void  Ins_MPS( INS_ARG )  {    args[0] = CUR.metrics.pointSize;  },924
156,427,CVE-2017-8831,18,static void saa7164_bus_verify(struct saa7164_dev *dev){	struct tmComResBusInfo *b = &dev->bus;	int bug = 0;	if (saa7164_readl(b->m_dwSetReadPos) > b->m_dwSizeSetRing)		bug++;	if (saa7164_readl(b->m_dwSetWritePos) > b->m_dwSizeSetRing)		bug++;	if (saa7164_readl(b->m_dwGetReadPos) > b->m_dwSizeGetRing)		bug++;	if (saa7164_readl(b->m_dwGetWritePos) > b->m_dwSizeGetRing)		bug++;	if (bug) {		saa_debug = 0xffff;  		saa7164_bus_dump(dev);		saa_debug = 1024;  		BUG();	}},21256
223,100,CVE-2016-6294,18,"PHP_FUNCTION( locale_get_script ){	get_icu_value_src_php( LOC_SCRIPT_TAG , INTERNAL_FUNCTION_PARAM_PASSTHRU );}",1680
60,808,CVE-2018-16427,18,"auth_get_pin_reference (struct sc_card *card, int type, int reference, int cmd, int *out_ref){	if (!out_ref)		LOG_FUNC_RETURN(card->ctx, SC_ERROR_INVALID_ARGUMENTS);	switch (type) {	case SC_AC_CHV:		if (reference != 1 && reference != 2 && reference != 4)			LOG_FUNC_RETURN(card->ctx, SC_ERROR_INVALID_PIN_REFERENCE);		*out_ref = reference;		if (reference == 1 || reference == 4)			if (cmd == SC_PIN_CMD_VERIFY)				*out_ref |= 0x80;		break;	default:		LOG_FUNC_RETURN(card->ctx, SC_ERROR_INVALID_ARGUMENTS);	}	LOG_FUNC_RETURN(card->ctx, SC_SUCCESS);}",24335
51,984,CVE-2017-5077,18,  void CheckAccepted() {    DCHECK(num_accepted_connections_loop_ ||           num_accepted_connections_needed_ == 0);    if (!num_accepted_connections_loop_ ||        num_accepted_connections_needed_ != sockets_.size()) {      return;    }    num_accepted_connections_loop_->Quit();    num_accepted_connections_needed_ = 0;    num_accepted_connections_loop_ = nullptr;  },29867
222,511,CVE-2016-10269,18,"uv_encode(double u, double v, int em)	 {	register int	vi, ui;	if (v < UV_VSTART)		return oog_encode(u, v);	vi = itrunc((v - UV_VSTART)*(1./UV_SQSIZ), em);	if (vi >= UV_NVS)		return oog_encode(u, v);	if (u < uv_row[vi].ustart)		return oog_encode(u, v);	ui = itrunc((u - uv_row[vi].ustart)*(1./UV_SQSIZ), em);	if (ui >= uv_row[vi].nus)		return oog_encode(u, v);	return (uv_row[vi].ncum + ui);}",22324
91,456,CVE-2017-7277,18,"static void sock_rmem_free(struct sk_buff *skb){	struct sock *sk = skb->sk; 	atomic_sub(skb->truesize, &sk->sk_rmem_alloc); }",21766
70,74,CVE-2017-9727,18,"static inline float reminder(float v, int x){    return ((v / x) - floor(v / x)) * x;}",953
236,142,CVE-2016-9777,18,static void rtc_status_pending_eoi_check_valid(struct kvm_ioapic *ioapic){	if (WARN_ON(ioapic->rtc_status.pending_eoi < 0))		kvm_rtc_eoi_tracking_restore_all(ioapic);},15094
21,73,CVE-2018-6196,2,"check_rowcol(struct table *tbl, struct table_mode *mode){    int row = tbl->row, col = tbl->col;    if (!(tbl->flag & TBL_IN_ROW)) {	tbl->flag |= TBL_IN_ROW;	tbl->row++;	if (tbl->row > tbl->maxrow)	    tbl->maxrow = tbl->row;	tbl->col = -1;    }    if (tbl->row == -1)	tbl->row = 0;    if (tbl->col == -1)	tbl->col = 0;    for (;; tbl->row++) {	check_row(tbl, tbl->row);	for (; tbl->col < MAXCOL &&	     tbl->tabattr[tbl->row][tbl->col] & (HTT_X | HTT_Y); tbl->col++) ;	if (tbl->col < MAXCOL)	    break;	tbl->col = 0;    }    if (tbl->row > tbl->maxrow)	tbl->maxrow = tbl->row;    if (tbl->col > tbl->maxcol)	tbl->maxcol = tbl->col;    if (tbl->row != row || tbl->col != col)	begin_cell(tbl, mode);    tbl->flag |= TBL_IN_COL;}",25461
3,13,CVE-2018-20103,2,static inline unsigned short dns_response_get_query_id(unsigned char *resp){	return resp[0] * 256 + resp[1];},105
25,45,CVE-2017-16932,2,"xmlRecoverFile(const char *filename) {    return(xmlSAXParseFile(NULL, filename, 1));}",19652
24,30,CVE-2018-20103,2,static inline unsigned short dns_response_get_query_id(unsigned char *resp){	return resp[0] * 256 + resp[1];},235
10,16,CVE-2018-20103,2,"void dns_trigger_resolution(struct dns_requester *req){	struct dns_resolvers  *resolvers;	struct dns_resolution *res;	int exp;	if (!req || !req->resolution)		return;	res       = req->resolution;	resolvers = res->resolvers;	 	exp = tick_add(res->last_resolution, resolvers->hold.valid);	if (resolvers->t && (res->status != RSLV_STATUS_VALID ||	    !tick_isset(res->last_resolution) || tick_is_expired(exp, now_ms)))		task_wakeup(resolvers->t, TASK_WOKEN_OTHER);}",108
0,11,CVE-2018-20103,2,static void dns_reset_resolution(struct dns_resolution *resolution){	 	resolution->step            = RSLV_STEP_NONE;	resolution->try             = 0;	resolution->last_resolution = now_ms;	resolution->nb_queries      = 0;	resolution->nb_responses    = 0;	resolution->query_type      = resolution->prefered_query_type;	 	eb32_delete(&resolution->qid);	resolution->query_id = 0;	resolution->qid.key   = 0;},103
15,51,CVE-2017-14058,2,"static void handle_init_section_args(struct init_section_info *info, const char *key,                                           int key_len, char **dest, int *dest_len){    if (!strncmp(key, ""URI="", key_len)) {        *dest     =        info->uri;        *dest_len = sizeof(info->uri);    } else if (!strncmp(key, ""BYTERANGE="", key_len)) {        *dest     =        info->byterange;        *dest_len = sizeof(info->byterange);    }}",20220
23,62,CVE-2018-19840,2,"void *WavpackGetWrapperLocation (void *first_block, int *size){    void *loc;    WavpackLittleEndianToNative (first_block, WavpackHeaderFormat);    loc = find_metadata (first_block, ID_RIFF_HEADER, size);    if (!loc)        loc = find_metadata (first_block, ID_ALT_HEADER, size);    WavpackNativeToLittleEndian (first_block, WavpackHeaderFormat);    return loc;}",23340
18,61,CVE-2018-1999012,2,static int pva_check(const int *p) {    int length = AV_RB16(p + 6);    if (AV_RB16(p) != PVA_MAGIC || !p[2] || p[2] > 2 || p[4] != 0x55 ||        (p[5] & 0xe0) || length > PVA_MAX_PAYLOAD_LENGTH)        return -1;    return length + 8;},23161
22,70,CVE-2018-6196,2,"check_cell_width(short *tabwidth, short *cellwidth,		 short *col, short *colspan, short maxcell,		 short *indexarray, int space, int dir){    int i, j, k, bcol, ecol;    int swidth, width;    for (k = 0; k <= maxcell; k++) {	j = indexarray[k];	if (cellwidth[j] <= 0)	    continue;	bcol = col[j];	ecol = bcol + colspan[j];	swidth = 0;	for (i = bcol; i < ecol; i++)	    swidth += tabwidth[i];	width = cellwidth[j] - (colspan[j] - 1) * space;	if (width > swidth) {	    int w = (width - swidth) / colspan[j];	    int r = (width - swidth) % colspan[j];	    for (i = bcol; i < ecol; i++)		tabwidth[i] += w;	     	    if (dir == 1 && r > 0)		r = colspan[j];	    for (i = 1; i <= r; i++)		tabwidth[ecol - i]++;	}    }}",25458
11,63,CVE-2018-15856,2,"add_production(struct xkb_compose_table *table, struct scanner *s,               const struct production *production){    unsigned lhs_pos;    int curr;    struct compose_node *node;    curr = 0;    node = &darray_item(table->nodes, curr);         for (lhs_pos = 0; lhs_pos < production->len; lhs_pos++) {        while (production->lhs[lhs_pos] != node->keysym) {            if (node->next == 0) {                int next = add_node(table, production->lhs[lhs_pos]);                                 node = &darray_item(table->nodes, curr);                node->next = next;            }            curr = node->next;            node = &darray_item(table->nodes, curr);        }        if (lhs_pos + 1 == production->len)            break;        if (node->is_leaf) {            if (node->u.leaf.utf8 != 0 ||                node->u.leaf.keysym != XKB_KEY_NoSymbol) {                scanner_warn(s, ""a sequence already exists which is a prefix of this sequence; overriding"");                node->u.leaf.utf8 = 0;                node->u.leaf.keysym = XKB_KEY_NoSymbol;            }            {                int successor = add_node(table, production->lhs[lhs_pos + 1]);                                 node = &darray_item(table->nodes, curr);                node->is_leaf = false;                node->u.successor = successor;            }        }        curr = node->u.successor;        node = &darray_item(table->nodes, curr);    }    if (!node->is_leaf) {        scanner_warn(s, ""this compose sequence is a prefix of another; skipping line"");        return;    }    if (node->u.leaf.utf8 != 0 || node->u.leaf.keysym != XKB_KEY_NoSymbol) {        int same_string =            (node->u.leaf.utf8 == 0 && !production->has_string) ||            (                node->u.leaf.utf8 != 0 && production->has_string &&                streq(&darray_item(table->utf8, node->u.leaf.utf8),                      production->string)            );        int same_keysym =            (node->u.leaf.keysym == XKB_KEY_NoSymbol && !production->has_keysym) ||            (                node->u.leaf.keysym != XKB_KEY_NoSymbol && production->has_keysym &&                node->u.leaf.keysym == production->keysym            );        if (same_string && same_keysym) {            scanner_warn(s, ""this compose sequence is a duplicate of another; skipping line"");            return;        }        scanner_warn(s, ""this compose sequence already exists; overriding"");    }    if (production->has_string) {        node->u.leaf.utf8 = darray_size(table->utf8);        darray_append_items(table->utf8, production->string,                            strlen(production->string) + 1);    }    if (production->has_keysym) {        node->u.leaf.keysym = production->keysym;    }}",24404
17,91,CVE-2018-6196,2,"set_table_matrix(struct table *t, int width){    int size = t->maxcol + 1;    int i, j;    double b, s;    int a;    struct table_cell *cell = &t->cell;    if (size < 1)	return;    t->matrix = m_get(size, size);    t->vector = v_get(size);    for (i = 0; i < size; i++) {	for (j = i; j < size; j++)	    m_set_val(t->matrix, i, j, 0.);	v_set_val(t->vector, i, 0.);    }    check_relative_width(t, width);    for (i = 0; i < size; i++) {	if (t->fixed_width[i] > 0) {	    a = max(t->fixed_width[i], t->minimum_width[i]);	    b = sigma_td(a);	    correct_table_matrix(t, i, 1, a, b);	}	else if (t->fixed_width[i] < 0) {	    s = -(double)t->fixed_width[i] / 100.;	    b = sigma_td((int)(s * width));	    correct_table_matrix2(t, i, 1, s, b);	}    }    for (j = 0; j <= cell->maxcell; j++) {	if (cell->fixed_width[j] > 0) {	    a = max(cell->fixed_width[j], cell->minimum_width[j]);	    b = sigma_td(a);	    correct_table_matrix(t, cell->col[j], cell->colspan[j], a, b);	}	else if (cell->fixed_width[j] < 0) {	    s = -(double)cell->fixed_width[j] / 100.;	    b = sigma_td((int)(s * width));	    correct_table_matrix2(t, cell->col[j], cell->colspan[j], s, b);	}    }    set_table_matrix0(t, width);    if (t->total_width > 0) {	b = sigma_table(width);    }    else {	b = sigma_table_nw(width);    }    correct_table_matrix(t, 0, size, width, b);}",25479
27,108,CVE-2018-20103,2," int dns_read_name(unsigned char *buffer, unsigned char *bufend,                  unsigned char *name, char *destination, int dest_len,                 int *offset) {        int nb_bytes = 0, n = 0;        int label_len;	unsigned char *reader = name;	char *dest = destination;	while (1) {		 		if ((*reader & 0xc0) == 0xc0) {			                         if ((buffer + reader[1]) > reader)                                goto err;                         n = dns_read_name(buffer, bufend, buffer + reader[1],                                         dest, dest_len - nb_bytes, offset);                        if (n == 0)                                goto err; 		}		label_len = *reader;		if (label_len == 0)			goto out;		 		if ((reader + label_len >= bufend) || (nb_bytes + label_len >= dest_len))			goto err;		 		label_len++;		memcpy(dest, reader, label_len);		dest     += label_len;		nb_bytes += label_len;		reader   += label_len;	}  out:	 	reader  = name;	*offset = 0;	while (reader < bufend) {		if ((reader[0] & 0xc0) == 0xc0) {			*offset += 2;			break;		}		else if (*reader == 0) {			*offset += 1;			break;		}		*offset += 1;		++reader;	}	return nb_bytes;  err:	return 0;}",30875
26,2,CVE-2018-20482,2,sparse_select_optab (struct tar_sparse_file *file){  switch (current_format == DEFAULT_FORMAT ? archive_format : current_format)    {    case V7_FORMAT:    case USTAR_FORMAT:      return false;    case OLDGNU_FORMAT:    case GNU_FORMAT:        file->optab = &oldgnu_optab;      break;    case POSIX_FORMAT:      file->optab = &pax_optab;      break;    case STAR_FORMAT:      file->optab = &star_optab;      break;    default:      return false;    }  return true;},86
5,76,CVE-2018-6196,2,"correct_table_matrix2(struct table *t, int col, int cspan, double s, double b){    int i, j;    int ecol = col + cspan;    int size = t->maxcol + 1;    double w = 1. / (b * b);    double ss;    for (i = 0; i < size; i++) {	for (j = i; j < size; j++) {	    if (i >= col && i < ecol && j >= col && j < ecol)		ss = (1. - s) * (1. - s);	    else if ((i >= col && i < ecol) || (j >= col && j < ecol))		ss = -(1. - s) * s;	    else		ss = s * s;	    m_add_val(t->matrix, i, j, w * ss);	}    }}",25464
7,69,CVE-2018-6196,2,"ceil_at_intervals(int x, int step){    int mo = x % step;    if (mo > 0)	x += step - mo;    else if (mo < 0)	x -= mo;    return x;}",25457
8,39,CVE-2017-9375,2,"static int xhci_nec_challenge(int hi, int lo){    int val;    val = rotl(lo - 0x49434878, 32 - ((hi>>8) & 0x1F));    val += rotl(lo + 0x49434878, hi & 0x1F);    val -= rotl(hi ^ 0x49434878, (lo >> 16) & 0x1F);    return ~val;}",982
20,105,CVE-2017-18208,2,"static int madvise_free_single_vma(struct vm_area_struct *vma,			unsigned long start_addr, unsigned long end_addr){	unsigned long start, end;	struct mm_struct *mm = vma->vm_mm;	struct mmu_gather tlb;	 	if (!vma_is_anonymous(vma))		return -EINVAL;	start = max(vma->vm_start, start_addr);	if (start >= vma->vm_end)		return -EINVAL;	end = min(vma->vm_end, end_addr);	if (end <= vma->vm_start)		return -EINVAL;	lru_add_drain();	tlb_gather_mmu(&tlb, mm, start, end);	update_hiwater_rss(mm);	mmu_notifier_invalidate_range_start(mm, start, end);	madvise_free_page_range(&tlb, vma, start, end);	mmu_notifier_invalidate_range_end(mm, start, end);	tlb_finish_mmu(&tlb, start, end);	return 0;}",25899
16,94,CVE-2018-6196,2,"table_close_anchor0(struct table *tbl, struct table_mode *mode){    if (!(mode->pre_mode & TBLM_ANCHOR))	return;    mode->pre_mode &= ~TBLM_ANCHOR;    if (tbl->tabcontentssize == mode->anchor_offset) {	check_minimum0(tbl, 1);	addcontentssize(tbl, 1);	setwidth(tbl, mode);    }    else if (tbl->linfo.prev_spaces > 0 &&	     tbl->tabcontentssize - 1 == mode->anchor_offset) {	if (tbl->linfo.prev_spaces > 0)	    tbl->linfo.prev_spaces = -1;    }}",25482
1,20,CVE-2018-20482,2,sparse_skip_file (struct tar_stat_info *st){  int rc = true;  struct tar_sparse_file file;  if (!tar_sparse_init (&file))    return dump_status_not_implemented;  file.stat_info = st;  file.fd = -1;  rc = tar_sparse_decode_header (&file);  skip_file (file.stat_info->archive_file_size - file.dumped_size);  return (tar_sparse_done (&file) && rc) ? dump_status_ok : dump_status_short;},217
14,60,CVE-2017-6214,2,"void tcp_init_sock(struct sock *sk){	struct inet_connection_sock *icsk = inet_csk(sk);	struct tcp_sock *tp = tcp_sk(sk);	tp->out_of_order_queue = RB_ROOT;	tcp_init_xmit_timers(sk);	tcp_prequeue_init(tp);	INIT_LIST_HEAD(&tp->tsq_node);	icsk->icsk_rto = TCP_TIMEOUT_INIT;	tp->mdev_us = jiffies_to_usecs(TCP_TIMEOUT_INIT);	minmax_reset(&tp->rtt_min, tcp_time_stamp, ~0U);	 	tp->snd_cwnd = TCP_INIT_CWND;	 	tp->app_limited = ~0U;	 	tp->snd_ssthresh = TCP_INFINITE_SSTHRESH;	tp->snd_cwnd_clamp = ~0;	tp->mss_cache = TCP_MSS_DEFAULT;	tp->reordering = sock_net(sk)->ipv4.sysctl_tcp_reordering;	tcp_enable_early_retrans(tp);	tcp_assign_congestion_control(sk);	tp->tsoffset = 0;	sk->sk_state = TCP_CLOSE;	sk->sk_write_space = sk_stream_write_space;	sock_set_flag(sk, SOCK_USE_WRITE_QUEUE);	icsk->icsk_sync_mss = tcp_sync_mss;	sk->sk_sndbuf = sysctl_tcp_wmem[1];	sk->sk_rcvbuf = sysctl_tcp_rmem[1];	local_bh_disable();	sk_sockets_allocated_inc(sk);	local_bh_enable();}",21848
19,36,CVE-2017-9375,2,"static const char *lookup_name(int index, const char **list, int llen){    if (index >= llen || list[index] == NULL) {        return ""???"";    }    return list[index];}",979
4,79,CVE-2018-6196,2,"correlation_coefficient2(double sxx, double syy, double sxy){    double coe, tmp;    tmp = (syy + sxx - 2 * sxy) * sxx;    if (tmp < Tiny)	tmp = Tiny;    coe = (sxx - sxy) / sqrt(tmp);    if (coe > 1.)	return 1.;    if (coe < -1.)	return -1.;    return coe;}",25467
9,46,CVE-2017-14058,2,"static int compare_ts_with_wrapdetect(int ts_a, struct playlist *pls_a,                                      int ts_b, struct playlist *pls_b){    int scaled_ts_a = av_rescale_q(ts_a, get_timebase(pls_a), MPEG_TIME_BASE_Q);    int scaled_ts_b = av_rescale_q(ts_b, get_timebase(pls_b), MPEG_TIME_BASE_Q);    return av_compare_mod(scaled_ts_a, scaled_ts_b, 1LL << 33);}",20215
6,82,CVE-2018-6196,2,"floor_at_intervals(int x, int step){    int mo = x % step;    if (mo > 0)	x -= mo;    else if (mo < 0)	x += step - mo;    return x;}",25470
13,28,CVE-2018-20103,2,static void dns_reset_resolution(struct dns_resolution *resolution){	 	resolution->step            = RSLV_STEP_NONE;	resolution->try             = 0;	resolution->last_resolution = now_ms;	resolution->nb_queries      = 0;	resolution->nb_responses    = 0;	resolution->query_type      = resolution->prefered_query_type;	 	eb32_delete(&resolution->qid);	resolution->query_id = 0;	resolution->qid.key   = 0;},233
2,88,CVE-2018-6196,2,minimum_cellspacing(int border_mode){    switch (border_mode) {    case BORDER_THIN:    case BORDER_THICK:    case BORDER_NOWIN:	return RULE_WIDTH;    case BORDER_NONE:	return 1;    default:	 	return 0;    }},25476
12,14,CVE-2018-20103,2,static inline int dns_rnd16(void){	if (!dns_query_id_seed)		dns_query_id_seed = now_ms;	dns_query_id_seed ^= dns_query_id_seed << 13;	dns_query_id_seed ^= dns_query_id_seed >> 7;	dns_query_id_seed ^= dns_query_id_seed << 17;	return dns_query_id_seed;},106
167,1370,CVE-2018-20856,19,"static inline int ioc_batching(struct request_queue *q, struct io_context *ioc){	if (!ioc)		return 0;	 	return ioc->nr_batch_requests == q->nr_batching ||		(ioc->nr_batch_requests > 0		&& time_before(jiffies, ioc->last_waited + BLK_BATCH_TIME));}",27519
48,516,CVE-2017-17052,19,static inline void posix_cpu_timers_init_group(struct signal_struct *sig) { },19602
54,1323,CVE-2018-20856,19,"void blk_drain_queue(struct request_queue *q){	spin_lock_irq(q->queue_lock);	__blk_drain_queue(q, true);	spin_unlock_irq(q->queue_lock);}",27472
248,47,CVE-2014-0131,19,"void __skb_warn_lro_forwarding(const struct sk_buff *skb){	net_warn_ratelimited(""%s: received packets cannot be forwarded while LRO is enabled\n"",			     skb->dev->name);}",12219
227,105,CVE-2016-10088,19,"static struct bsg_device *bsg_alloc_device(void){	struct bsg_device *bd;	bd = kzalloc(sizeof(struct bsg_device), GFP_KERNEL);	if (unlikely(!bd))		return NULL;	spin_lock_init(&bd->lock);	bd->max_queue = BSG_DEFAULT_CMDS;	INIT_LIST_HEAD(&bd->busy_list);	INIT_LIST_HEAD(&bd->done_list);	INIT_HLIST_NODE(&bd->dev_list);	init_waitqueue_head(&bd->wq_free);	init_waitqueue_head(&bd->wq_done);	return bd;}",14950
287,1397,CVE-2019-11487,19,"int fuse_dev_release(struct inode *inode, struct file *file){	struct fuse_dev *fud = fuse_get_dev(file);	if (fud) {		struct fuse_conn *fc = fud->fc;		struct fuse_pqueue *fpq = &fud->pq;		LIST_HEAD(to_end);		unsigned int i;		spin_lock(&fpq->lock);		WARN_ON(!list_empty(&fpq->io));		for (i = 0; i < FUSE_PQ_HASH_SIZE; i++)			list_splice_init(&fpq->processing[i], &to_end);		spin_unlock(&fpq->lock);		end_requests(fc, &to_end);		 		if (atomic_dec_and_test(&fc->dev_count)) {			WARN_ON(fc->iq.fasync != NULL);			fuse_abort_conn(fc);		}		fuse_dev_free(fud);	}	return 0;}",28894
317,1420,CVE-2019-11487,19,"static int lock_request(struct fuse_req *req){	int err = 0;	if (req) {		spin_lock(&req->waitq.lock);		if (test_bit(FR_ABORTED, &req->flags))			err = -ENOENT;		else			set_bit(FR_LOCKED, &req->flags);		spin_unlock(&req->waitq.lock);	}	return err;}",28917
17,112,CVE-2016-10088,19,"static int bsg_open(struct inode *inode, struct file *file){	struct bsg_device *bd;	bd = bsg_get_device(inode, file);	if (IS_ERR(bd))		return PTR_ERR(bd);	file->private_data = bd;	return 0;}",14957
331,1175,CVE-2019-11811,19,"static void handle_flags(struct smi_info *smi_info){retry:	if (smi_info->msg_flags & WDT_PRE_TIMEOUT_INT) {		 		smi_inc_stat(smi_info, watchdog_pretimeouts);		start_clear_flags(smi_info);		smi_info->msg_flags &= ~WDT_PRE_TIMEOUT_INT;		ipmi_smi_watchdog_pretimeout(smi_info->intf);	} else if (smi_info->msg_flags & RECEIVE_MSG_AVAIL) {		 		smi_info->curr_msg = alloc_msg_handle_irq(smi_info);		if (!smi_info->curr_msg)			return;		start_getting_msg_queue(smi_info);	} else if (smi_info->msg_flags & EVENT_MSG_BUFFER_FULL) {		 		smi_info->curr_msg = alloc_msg_handle_irq(smi_info);		if (!smi_info->curr_msg)			return;		start_getting_events(smi_info);	} else if (smi_info->msg_flags & OEM_DATA_AVAIL &&		   smi_info->oem_data_avail_handler) {		if (smi_info->oem_data_avail_handler(smi_info))			goto retry;	} else		smi_info->si_state = SI_NORMAL;}",26938
357,1357,CVE-2018-20856,19,void blk_rq_unprep_clone(struct request *rq){	struct bio *bio;	while ((bio = rq->bio) != NULL) {		rq->bio = bio->bi_next;		bio_put(bio);	}},27506
365,1316,CVE-2018-20856,19,"static void add_acct_request(struct request_queue *q, struct request *rq,			     int where){	blk_account_io_start(rq, true);	__elv_add_request(q, rq, where);}",27465
0,239,CVE-2016-8655,19,"static void register_prot_hook(struct sock *sk){	struct packet_sock *po = pkt_sk(sk);	if (!po->running) {		if (po->fanout)			__fanout_link(sk, po);		else			dev_add_pack(&po->prot_hook);		sock_hold(sk);		po->running = 1;	}}",15521
373,1093,CVE-2017-15126,19,"static int userfaultfd_release(struct inode *inode, struct file *file){	struct userfaultfd_ctx *ctx = file->private_data;	struct mm_struct *mm = ctx->mm;	struct vm_area_struct *vma, *prev;	 	struct userfaultfd_wake_range range = { .len = 0, };	unsigned long new_flags;	ACCESS_ONCE(ctx->released) = true;	if (!mmget_not_zero(mm))		goto wakeup;	 	down_write(&mm->mmap_sem);	prev = NULL;	for (vma = mm->mmap; vma; vma = vma->vm_next) {		cond_resched();		BUG_ON(!!vma->vm_userfaultfd_ctx.ctx ^		       !!(vma->vm_flags & (VM_UFFD_MISSING | VM_UFFD_WP)));		if (vma->vm_userfaultfd_ctx.ctx != ctx) {			prev = vma;			continue;		}		new_flags = vma->vm_flags & ~(VM_UFFD_MISSING | VM_UFFD_WP);		prev = vma_merge(mm, prev, vma->vm_start, vma->vm_end,				 new_flags, vma->anon_vma,				 vma->vm_file, vma->vm_pgoff,				 vma_policy(vma),				 NULL_VM_UFFD_CTX);		if (prev)			vma = prev;		else			prev = vma;		vma->vm_flags = new_flags;		vma->vm_userfaultfd_ctx = NULL_VM_UFFD_CTX;	}	up_write(&mm->mmap_sem);	mmput(mm);wakeup:	 	spin_lock(&ctx->fault_pending_wqh.lock);	__wake_up_locked_key(&ctx->fault_pending_wqh, TASK_NORMAL, &range);	__wake_up_locked_key(&ctx->fault_wqh, TASK_NORMAL, &range);	spin_unlock(&ctx->fault_pending_wqh.lock);	 	wake_up_all(&ctx->event_wqh);	wake_up_poll(&ctx->fd_wqh, POLLHUP);	userfaultfd_ctx_put(ctx);	return 0;}",26224
135,652,CVE-2017-15265,19,"static int snd_seq_ioctl_subscribe_port(struct snd_seq_client *client,					void *arg){	struct snd_seq_port_subscribe *subs = arg;	int result = -EINVAL;	struct snd_seq_client *receiver = NULL, *sender = NULL;	struct snd_seq_client_port *sport = NULL, *dport = NULL;	if ((receiver = snd_seq_client_use_ptr(subs->dest.client)) == NULL)		goto __end;	if ((sender = snd_seq_client_use_ptr(subs->sender.client)) == NULL)		goto __end;	if ((sport = snd_seq_port_use_ptr(sender, subs->sender.port)) == NULL)		goto __end;	if ((dport = snd_seq_port_use_ptr(receiver, subs->dest.port)) == NULL)		goto __end;	result = check_subscription_permission(client, sport, dport, subs);	if (result < 0)		goto __end;	 	result = snd_seq_port_connect(client, sender, sport, receiver, dport, subs);	if (! result)  		snd_seq_client_notify_subscription(SNDRV_SEQ_ADDRESS_SUBSCRIBERS, 0,						   subs, SNDRV_SEQ_EVENT_PORT_SUBSCRIBED);      __end:      	if (sport)		snd_seq_port_unlock(sport);	if (dport)		snd_seq_port_unlock(dport);	if (sender)		snd_seq_client_unlock(sender);	if (receiver)		snd_seq_client_unlock(receiver);	return result;}",20042
363,1456,CVE-2019-11487,19,"static void ftrace_exports(struct ring_buffer_event *event){	struct trace_export *export;	preempt_disable_notrace();	export = rcu_dereference_raw_notrace(ftrace_exports_list);	while (export) {		trace_process_export(export, event);		export = rcu_dereference_raw_notrace(export->next);	}	preempt_enable_notrace();}",28953
160,698,CVE-2017-11176,19,static void init_once(void *foo){	struct mqueue_inode_info *p = (struct mqueue_inode_info *) foo;	inode_init_once(&p->vfs_inode);},20547
96,1005,CVE-2017-18218,19,"static int hns_nic_net_up(struct net_device *ndev){	struct hns_nic_priv *priv = netdev_priv(ndev);	struct hnae_handle *h = priv->ae_handle;	int i, j;	int ret;	ret = hns_nic_init_irq(priv);	if (ret != 0) {		netdev_err(ndev, ""hns init irq failed! ret=%d\n"", ret);		return ret;	}	for (i = 0; i < h->q_num * 2; i++) {		ret = hns_nic_ring_open(ndev, i);		if (ret)			goto out_has_some_queues;	}	ret = h->dev->ops->set_mac_addr(h, ndev->dev_addr);	if (ret)		goto out_set_mac_addr_err;	ret = h->dev->ops->start ? h->dev->ops->start(h) : 0;	if (ret)		goto out_start_err;	if (ndev->phydev)		phy_start(ndev->phydev);	clear_bit(NIC_STATE_DOWN, &priv->state);	(void)mod_timer(&priv->service_timer, jiffies + SERVICE_TIMER_HZ);	return 0;out_start_err:	netif_stop_queue(ndev);out_set_mac_addr_err:out_has_some_queues:	for (j = i - 1; j >= 0; j--)		hns_nic_ring_close(ndev, j);	set_bit(NIC_STATE_DOWN, &priv->state);	return ret;}",25855
18,1388,CVE-2019-11487,19,static int forget_pending(struct fuse_iqueue *fiq){	return fiq->forget_list_head.next != NULL;},28885
123,12,CVE-2016-6295,19," PHP_FUNCTION(snmp2_walk) {	php_snmp(INTERNAL_FUNCTION_PARAM_PASSTHRU, (SNMP_CMD_WALK | SNMP_NUMERIC_KEYS), SNMP_VERSION_2c);}",1666
280,136,CVE-2016-9794,19,static int snd_interval_refine_first(struct snd_interval *i){	if (snd_BUG_ON(snd_interval_empty(i)))		return -EINVAL;	if (snd_interval_single(i))		return 0;	i->max = i->min;	i->openmax = i->openmin;	if (i->openmax)		i->max++;	return 1;},15021
186,63,CVE-2014-0131,19,"struct sk_buff *skb_dequeue(struct sk_buff_head *list){	unsigned long flags;	struct sk_buff *result;	spin_lock_irqsave(&list->lock, flags);	result = __skb_dequeue(list);	spin_unlock_irqrestore(&list->lock, flags);	return result;}",12235
265,1298,CVE-2019-9003,19,static int is_maintenance_mode_cmd(struct kernel_ipmi_msg *msg){	return (((msg->netfn == IPMI_NETFN_APP_REQUEST)		 && ((msg->cmd == IPMI_COLD_RESET_CMD)		     || (msg->cmd == IPMI_WARM_RESET_CMD)))		|| (msg->netfn == IPMI_NETFN_FIRMWARE_REQUEST));},27275
256,514,CVE-2017-17052,19,static inline void posix_cpu_timers_init(struct task_struct *tsk) { },19600
23,1259,CVE-2019-9003,19,"static int i_ipmi_req_lan(struct ipmi_smi        *intf,			  struct ipmi_addr       *addr,			  long                   msgid,			  struct kernel_ipmi_msg *msg,			  struct ipmi_smi_msg    *smi_msg,			  struct ipmi_recv_msg   *recv_msg,			  unsigned char          source_lun,			  int                    retries,			  unsigned int           retry_time_ms){	struct ipmi_lan_addr  *lan_addr;	unsigned char ipmb_seq;	long seqid;	struct ipmi_channel *chans;	int rv = 0;	if (addr->channel >= IPMI_MAX_CHANNELS) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EINVAL;	}	chans = READ_ONCE(intf->channel_list)->c;	if ((chans[addr->channel].medium				!= IPMI_CHANNEL_MEDIUM_8023LAN)			&& (chans[addr->channel].medium			    != IPMI_CHANNEL_MEDIUM_ASYNC)) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EINVAL;	}	 	if ((msg->data_len + 12) > IPMI_MAX_MSG_LENGTH) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EMSGSIZE;	}	lan_addr = (struct ipmi_lan_addr *) addr;	if (lan_addr->lun > 3) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EINVAL;	}	memcpy(&recv_msg->addr, lan_addr, sizeof(*lan_addr));	if (recv_msg->msg.netfn & 0x1) {		 		ipmi_inc_stat(intf, sent_lan_responses);		format_lan_msg(smi_msg, msg, lan_addr, msgid,			       msgid, source_lun);		 		smi_msg->user_data = recv_msg;	} else {		 		unsigned long flags;		spin_lock_irqsave(&intf->seq_lock, flags);		 		rv = intf_next_seq(intf,				   recv_msg,				   retry_time_ms,				   retries,				   0,				   &ipmb_seq,				   &seqid);		if (rv)			 			goto out_err;		ipmi_inc_stat(intf, sent_lan_commands);		 		format_lan_msg(smi_msg, msg, lan_addr,			       STORE_SEQ_IN_MSGID(ipmb_seq, seqid),			       ipmb_seq, source_lun);		 		memcpy(recv_msg->msg_data, smi_msg->data,		       smi_msg->data_size);		recv_msg->msg.data = recv_msg->msg_data;		recv_msg->msg.data_len = smi_msg->data_size;		 out_err:		spin_unlock_irqrestore(&intf->seq_lock, flags);	}	return rv;}",27236
321,99,CVE-2014-0131,19,"static void sock_rmem_free(struct sk_buff *skb){	struct sock *sk = skb->sk;	atomic_sub(skb->truesize, &sk->sk_rmem_alloc);}",12271
224,1258,CVE-2019-9003,19,"static int i_ipmi_req_ipmb(struct ipmi_smi        *intf,			   struct ipmi_addr       *addr,			   long                   msgid,			   struct kernel_ipmi_msg *msg,			   struct ipmi_smi_msg    *smi_msg,			   struct ipmi_recv_msg   *recv_msg,			   unsigned char          source_address,			   unsigned char          source_lun,			   int                    retries,			   unsigned int           retry_time_ms){	struct ipmi_ipmb_addr *ipmb_addr;	unsigned char ipmb_seq;	long seqid;	int broadcast = 0;	struct ipmi_channel *chans;	int rv = 0;	if (addr->channel >= IPMI_MAX_CHANNELS) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EINVAL;	}	chans = READ_ONCE(intf->channel_list)->c;	if (chans[addr->channel].medium != IPMI_CHANNEL_MEDIUM_IPMB) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EINVAL;	}	if (addr->addr_type == IPMI_IPMB_BROADCAST_ADDR_TYPE) {		 		addr->addr_type = IPMI_IPMB_ADDR_TYPE;		broadcast = 1;		retries = 0;  	}	 	if ((msg->data_len + 10 + broadcast) > IPMI_MAX_MSG_LENGTH) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EMSGSIZE;	}	ipmb_addr = (struct ipmi_ipmb_addr *) addr;	if (ipmb_addr->lun > 3) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EINVAL;	}	memcpy(&recv_msg->addr, ipmb_addr, sizeof(*ipmb_addr));	if (recv_msg->msg.netfn & 0x1) {		 		ipmi_inc_stat(intf, sent_ipmb_responses);		format_ipmb_msg(smi_msg, msg, ipmb_addr, msgid,				msgid, broadcast,				source_address, source_lun);		 		smi_msg->user_data = recv_msg;	} else {		 		unsigned long flags;		spin_lock_irqsave(&intf->seq_lock, flags);		if (is_maintenance_mode_cmd(msg))			intf->ipmb_maintenance_mode_timeout =				maintenance_mode_timeout_ms;		if (intf->ipmb_maintenance_mode_timeout && retry_time_ms == 0)			 			retry_time_ms = default_maintenance_retry_ms;		 		rv = intf_next_seq(intf,				   recv_msg,				   retry_time_ms,				   retries,				   broadcast,				   &ipmb_seq,				   &seqid);		if (rv)			 			goto out_err;		ipmi_inc_stat(intf, sent_ipmb_commands);		 		format_ipmb_msg(smi_msg, msg, ipmb_addr,				STORE_SEQ_IN_MSGID(ipmb_seq, seqid),				ipmb_seq, broadcast,				source_address, source_lun);		 		memcpy(recv_msg->msg_data, smi_msg->data,		       smi_msg->data_size);		recv_msg->msg.data = recv_msg->msg_data;		recv_msg->msg.data_len = smi_msg->data_size;		 out_err:		spin_unlock_irqrestore(&intf->seq_lock, flags);	}	return rv;}",27235
114,424,CVE-2015-8963,19,"static int _perf_event_refresh(struct perf_event *event, int refresh){	 	if (event->attr.inherit || !is_sampling_event(event))		return -EINVAL;	atomic_add(refresh, &event->event_limit);	_perf_event_enable(event);	return 0;}",18332
50,1099,CVE-2019-15920,19,SMB2_ioctl_free(struct smb_rqst *rqst){	if (rqst && rqst->rq_iov)		cifs_small_buf_release(rqst->rq_iov[0].iov_base);  },26577
33,741,CVE-2017-9798,19,static int reset_config_defines(void *dummy){    ap_server_config_defines = saved_server_config_defines;    saved_server_config_defines = NULL;    server_config_defined_vars = NULL;    return OK;},20705
158,612,CVE-2017-16527,19,static void snd_usb_mixer_inactivate(struct usb_mixer_interface *mixer){	usb_kill_urb(mixer->urb);	usb_kill_urb(mixer->rc_urb);},19871
95,476,CVE-2015-8963,19,void perf_sched_cb_dec(struct pmu *pmu){	this_cpu_dec(perf_sched_cb_usages);},18384
239,1387,CVE-2019-11487,19,"static struct fuse_forget_link *dequeue_forget(struct fuse_iqueue *fiq,					       unsigned max,					       unsigned *countp){	struct fuse_forget_link *head = fiq->forget_list_head.next;	struct fuse_forget_link **newhead = &head;	unsigned count;	for (count = 0; *newhead != NULL && count < max; count++)		newhead = &(*newhead)->next;	fiq->forget_list_head.next = *newhead;	*newhead = NULL;	if (fiq->forget_list_head.next == NULL)		fiq->forget_list_tail = &fiq->forget_list_head;	if (countp != NULL)		*countp = count;	return head;}",28884
49,1567,CVE-2016-7910,19,"static void disk_seqf_stop(struct seq_file *seqf, void *v){	struct class_dev_iter *iter = seqf->private;	  	if (iter) { 		class_dev_iter_exit(iter); 		kfree(iter); 	} }",31248
275,1097,CVE-2019-15920,19,SMB2_close_free(struct smb_rqst *rqst){	if (rqst && rqst->rq_iov)		cifs_small_buf_release(rqst->rq_iov[0].iov_base);  },26575
198,1487,CVE-2019-11487,19,static inline int PageHugeTemporary(struct page *page){	if (!PageHuge(page))		return false;	return (unsigned long)page[2].mapping == -1U;},28984
185,570,CVE-2017-16528,19,void snd_seq_driver_unregister(struct snd_seq_driver *drv){	driver_unregister(&drv->driver);},19829
391,236,CVE-2016-8655,19,"static void prb_run_all_ft_ops(struct tpacket_kbdq_core *pkc,			struct tpacket3_hdr *ppd){	ppd->hv1.tp_padding = 0;	prb_fill_vlan_info(pkc, ppd);	if (pkc->feature_req_word & TP_FT_REQ_FILL_RXHASH)		prb_fill_rxhash(pkc, ppd);	else		prb_clear_rxhash(pkc, ppd);}",15518
118,705,CVE-2017-11176,19,"static struct dentry *mqueue_mount(struct file_system_type *fs_type,			 int flags, const char *dev_name,			 void *data){	struct ipc_namespace *ns;	if (flags & MS_KERNMOUNT) {		ns = data;		data = NULL;	} else {		ns = current->nsproxy->ipc_ns;	}	return mount_ns(fs_type, flags, data, ns, ns->user_ns, mqueue_fill_super);}",20554
162,784,CVE-2016-10150,19,static struct kvm_memslots *kvm_alloc_memslots(void){	int i;	struct kvm_memslots *slots;	slots = kvm_kvzalloc(sizeof(struct kvm_memslots));	if (!slots)		return NULL;	 	slots->generation = -150;	for (i = 0; i < KVM_MEM_SLOTS_NUM; i++)		slots->id_to_index[i] = slots->memslots[i].id = i;	return slots;},22500
55,425,CVE-2015-8963,19,"static void _perf_event_reset(struct perf_event *event){	(void)perf_event_read(event, false);	local64_set(&event->count, 0);	perf_event_update_userpage(event);}",18333
128,1260,CVE-2019-9003,19,"static int i_ipmi_req_sysintf(struct ipmi_smi        *intf,			      struct ipmi_addr       *addr,			      long                   msgid,			      struct kernel_ipmi_msg *msg,			      struct ipmi_smi_msg    *smi_msg,			      struct ipmi_recv_msg   *recv_msg,			      int                    retries,			      unsigned int           retry_time_ms){	struct ipmi_system_interface_addr *smi_addr;	if (msg->netfn & 1)		 		return -EINVAL;	smi_addr = (struct ipmi_system_interface_addr *) addr;	if (smi_addr->lun > 3) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EINVAL;	}	memcpy(&recv_msg->addr, smi_addr, sizeof(*smi_addr));	if ((msg->netfn == IPMI_NETFN_APP_REQUEST)	    && ((msg->cmd == IPMI_SEND_MSG_CMD)		|| (msg->cmd == IPMI_GET_MSG_CMD)		|| (msg->cmd == IPMI_READ_EVENT_MSG_BUFFER_CMD))) {		 		ipmi_inc_stat(intf, sent_invalid_commands);		return -EINVAL;	}	if (is_maintenance_mode_cmd(msg)) {		unsigned long flags;		spin_lock_irqsave(&intf->maintenance_mode_lock, flags);		intf->auto_maintenance_timeout			= maintenance_mode_timeout_ms;		if (!intf->maintenance_mode		    && !intf->maintenance_mode_enable) {			intf->maintenance_mode_enable = true;			maintenance_mode_update(intf);		}		spin_unlock_irqrestore(&intf->maintenance_mode_lock,				       flags);	}	if (msg->data_len + 2 > IPMI_MAX_MSG_LENGTH) {		ipmi_inc_stat(intf, sent_invalid_commands);		return -EMSGSIZE;	}	smi_msg->data[0] = (msg->netfn << 2) | (smi_addr->lun & 0x3);	smi_msg->data[1] = msg->cmd;	smi_msg->msgid = msgid;	smi_msg->user_data = recv_msg;	if (msg->data_len > 0)		memcpy(&smi_msg->data[2], msg->data, msg->data_len);	smi_msg->data_size = msg->data_len + 2;	ipmi_inc_stat(intf, sent_local_commands);	return 0;}",27237
62,1140,CVE-2019-15917,19,"static int hci_uart_tty_open(struct tty_struct *tty){	struct hci_uart *hu;	BT_DBG(""tty %p"", tty);	 	if (tty->ops->write == NULL)		return -EOPNOTSUPP;	hu = kzalloc(sizeof(struct hci_uart), GFP_KERNEL);	if (!hu) {		BT_ERR(""Can't allocate control structure"");		return -ENFILE;	}	tty->disc_data = hu;	hu->tty = tty;	tty->receive_room = 65536;	 	hu->alignment = 1;	hu->padding = 0;	INIT_WORK(&hu->init_ready, hci_uart_init_work);	INIT_WORK(&hu->write_work, hci_uart_write_work);	percpu_init_rwsem(&hu->proto_lock);	 	tty_driver_flush_buffer(tty);	return 0;}",26619
214,985,CVE-2017-18218,19,"static int hns_enable_serdes_lb(struct net_device *ndev){	struct hns_nic_priv *priv = netdev_priv(ndev);	struct hnae_handle *h = priv->ae_handle;	struct hnae_ae_ops *ops = h->dev->ops;	int speed, duplex;	int ret;	ret = ops->set_loopback(h, MAC_INTERNALLOOP_SERDES, 1);	if (ret)		return ret;	ret = ops->start ? ops->start(h) : 0;	if (ret)		return ret;	 	if (h->phy_if != PHY_INTERFACE_MODE_XGMII)		speed = 1000;	else		speed = 10000;	duplex = 1;	ops->adjust_link(h, speed, duplex);	 	mdelay(300);	return 0;}",25835
205,5,CVE-2016-6295,19," PHP_FUNCTION(snmpgetnext) {	php_snmp(INTERNAL_FUNCTION_PARAM_PASSTHRU, SNMP_CMD_GETNEXT, SNMP_VERSION_1); }",1659
338,1033,CVE-2017-18202,19,static inline int __task_will_free_mem(struct task_struct *task){	struct signal_struct *sig = task->signal;	 	if (sig->flags & SIGNAL_GROUP_COREDUMP)		return false;	if (sig->flags & SIGNAL_GROUP_EXIT)		return true;	if (thread_group_empty(task) && (task->flags & PF_EXITING))		return true;	return false;},26011
64,1438,CVE-2019-11487,19,void pipe_buf_mark_unmergeable(struct pipe_buffer *buf){	if (buf->ops == &anon_pipe_buf_ops)		buf->ops = &anon_pipe_buf_nomerge_ops;},28935
207,193,CVE-2016-9120,19,"struct dma_buf *ion_share_dma_buf(struct ion_client *client,						struct ion_handle *handle){	DEFINE_DMA_BUF_EXPORT_INFO(exp_info);	struct ion_buffer *buffer;	struct dma_buf *dmabuf;	int valid_handle;	mutex_lock(&client->lock);	valid_handle = ion_handle_validate(client, handle);	if (!valid_handle) {		WARN(1, ""%s: invalid handle passed to share.\n"", __func__);		mutex_unlock(&client->lock);		return ERR_PTR(-EINVAL);	}	buffer = handle->buffer;	ion_buffer_get(buffer);	mutex_unlock(&client->lock);	exp_info.ops = &dma_buf_ops;	exp_info.size = buffer->size;	exp_info.flags = O_RDWR;	exp_info.priv = buffer;	dmabuf = dma_buf_export(&exp_info);	if (IS_ERR(dmabuf)) {		ion_buffer_put(buffer);		return dmabuf;	}	return dmabuf;}",15279
329,907,CVE-2018-17182,19,"struct vm_area_struct *vmacache_find_exact(struct mm_struct *mm,					   unsigned long start,					   unsigned long end){	int idx = VMACACHE_HASH(start);	int i;	count_vm_vmacache_event(VMACACHE_FIND_CALLS);	if (!vmacache_valid(mm))		return NULL;	for (i = 0; i < VMACACHE_SIZE; i++) {		struct vm_area_struct *vma = current->vmacache.vmas[idx];		if (vma && vma->vm_start == start && vma->vm_end == end) {			count_vm_vmacache_event(VMACACHE_FIND_HITS);			return vma;		}		if (++idx == VMACACHE_SIZE)			idx = 0;	}	return NULL;}",24198
240,1193,CVE-2019-11811,19,"static void set_run_to_completion(void *send_info, int i_run_to_completion){	struct smi_info   *smi_info = send_info;	smi_info->run_to_completion = i_run_to_completion;	if (i_run_to_completion)		flush_messages(smi_info);}",26956
230,166,CVE-2016-9120,19,static inline void ion_buffer_page_clean(struct page **page){	*page = (struct page *)((unsigned long)(*page) & ~(1UL));},15252
302,1359,CVE-2018-20856,19,"void blk_run_queue_async(struct request_queue *q){	lockdep_assert_held(q->queue_lock);	WARN_ON_ONCE(q->mq_ops);	if (likely(!blk_queue_stopped(q) && !blk_queue_dead(q)))		mod_delayed_work(kblockd_workqueue, &q->delay_work, 0);}",27508
171,77,CVE-2014-0131,19,"static int skb_prepare_for_shift(struct sk_buff *skb){	return skb_cloned(skb) && pskb_expand_head(skb, 0, 0, GFP_ATOMIC);}",12249
56,973,CVE-2018-5344,19,"static int loop_set_block_size(struct loop_device *lo, unsigned long arg){	if (lo->lo_state != Lo_bound)		return -ENXIO;	if (arg < 512 || arg > PAGE_SIZE || !is_power_of_2(arg))		return -EINVAL;	blk_mq_freeze_queue(lo->lo_queue);	blk_queue_logical_block_size(lo->lo_queue, arg);	blk_queue_physical_block_size(lo->lo_queue, arg);	blk_queue_io_min(lo->lo_queue, arg);	loop_update_dio(lo);	blk_mq_unfreeze_queue(lo->lo_queue);	return 0;}",25520
199,183,CVE-2016-9120,19,"static void ion_handle_kmap_put(struct ion_handle *handle){	struct ion_buffer *buffer = handle->buffer;	if (!handle->kmap_cnt) {		WARN(1, ""%s: Double unmap detected! bailing...\n"", __func__);		return;	}	handle->kmap_cnt--;	if (!handle->kmap_cnt)		ion_buffer_kmap_put(buffer);}",15269
21,432,CVE-2015-8963,19,"static int exclusive_event_match(struct perf_event *e1, struct perf_event *e2){	if ((e1->pmu->capabilities & PERF_PMU_CAP_EXCLUSIVE) &&	    (e1->cpu == e2->cpu ||	     e1->cpu == -1 ||	     e2->cpu == -1))		return true;	return false;}",18340
29,900,CVE-2018-1000878,19,"parse_codes(struct archive_read *a){  int i, j, val, n, r;  unsigned char bitlengths[MAX_SYMBOLS], zerocount, ppmd_flags;  unsigned int maxorder;  struct huffman_code precode;  struct rar *rar = (struct rar *)(a->format->data);  struct rar_br *br = &(rar->br);  free_codes(a);     rar_br_consume_unalined_bits(br);     if (!rar_br_read_ahead(a, br, 1))    goto truncated_data;  if ((rar->is_ppmd_block = rar_br_bits(br, 1)) != 0)  {    rar_br_consume(br, 1);    if (!rar_br_read_ahead(a, br, 7))      goto truncated_data;    ppmd_flags = rar_br_bits(br, 7);    rar_br_consume(br, 7);         if (ppmd_flags & 0x20)    {      if (!rar_br_read_ahead(a, br, 8))        goto truncated_data;      rar->dictionary_size = (rar_br_bits(br, 8) + 1) << 20;      rar_br_consume(br, 8);    }    if (ppmd_flags & 0x40)    {      if (!rar_br_read_ahead(a, br, 8))        goto truncated_data;      rar->ppmd_escape = rar->ppmd7_context.InitEsc = rar_br_bits(br, 8);      rar_br_consume(br, 8);    }    else      rar->ppmd_escape = 2;    if (ppmd_flags & 0x20)    {      maxorder = (ppmd_flags & 0x1F) + 1;      if(maxorder > 16)        maxorder = 16 + (maxorder - 16) * 3;      if (maxorder == 1)      {        archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                          ""Truncated RAR file data"");        return (ARCHIVE_FATAL);      }             __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);      rar->bytein.a = a;      rar->bytein.Read = &ppmd_read;      __archive_ppmd7_functions.PpmdRAR_RangeDec_CreateVTable(&rar->range_dec);      rar->range_dec.Stream = &rar->bytein;      __archive_ppmd7_functions.Ppmd7_Construct(&rar->ppmd7_context);      if (rar->dictionary_size == 0) {	      archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                          ""Invalid zero dictionary size"");	      return (ARCHIVE_FATAL);      }      if (!__archive_ppmd7_functions.Ppmd7_Alloc(&rar->ppmd7_context,        rar->dictionary_size))      {        archive_set_error(&a->archive, ENOMEM,                          ""Out of memory"");        return (ARCHIVE_FATAL);      }      if (!__archive_ppmd7_functions.PpmdRAR_RangeDec_Init(&rar->range_dec))      {        archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                          ""Unable to initialize PPMd range decoder"");        return (ARCHIVE_FATAL);      }      __archive_ppmd7_functions.Ppmd7_Init(&rar->ppmd7_context, maxorder);      rar->ppmd_valid = 1;    }    else    {      if (!rar->ppmd_valid) {        archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                          ""Invalid PPMd sequence"");        return (ARCHIVE_FATAL);      }      if (!__archive_ppmd7_functions.PpmdRAR_RangeDec_Init(&rar->range_dec))      {        archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                          ""Unable to initialize PPMd range decoder"");        return (ARCHIVE_FATAL);      }    }  }  else  {    rar_br_consume(br, 1);         if (!rar_br_read_ahead(a, br, 1))      goto truncated_data;    if (!rar_br_bits(br, 1))      memset(rar->lengthtable, 0, sizeof(rar->lengthtable));    rar_br_consume(br, 1);    memset(&bitlengths, 0, sizeof(bitlengths));    for (i = 0; i < MAX_SYMBOLS;)    {      if (!rar_br_read_ahead(a, br, 4))        goto truncated_data;      bitlengths[i++] = rar_br_bits(br, 4);      rar_br_consume(br, 4);      if (bitlengths[i-1] == 0xF)      {        if (!rar_br_read_ahead(a, br, 4))          goto truncated_data;        zerocount = rar_br_bits(br, 4);        rar_br_consume(br, 4);        if (zerocount)        {          i--;          for (j = 0; j < zerocount + 2 && i < MAX_SYMBOLS; j++)            bitlengths[i++] = 0;        }      }    }    memset(&precode, 0, sizeof(precode));    r = create_code(a, &precode, bitlengths, MAX_SYMBOLS, MAX_SYMBOL_LENGTH);    if (r != ARCHIVE_OK) {      free(precode.tree);      free(precode.table);      return (r);    }    for (i = 0; i < HUFFMAN_TABLE_SIZE;)    {      if ((val = read_next_symbol(a, &precode)) < 0) {        free(precode.tree);        free(precode.table);        return (ARCHIVE_FATAL);      }      if (val < 16)      {        rar->lengthtable[i] = (rar->lengthtable[i] + val) & 0xF;        i++;      }      else if (val < 18)      {        if (i == 0)        {          free(precode.tree);          free(precode.table);          archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                            ""Internal error extracting RAR file."");          return (ARCHIVE_FATAL);        }        if(val == 16) {          if (!rar_br_read_ahead(a, br, 3)) {            free(precode.tree);            free(precode.table);            goto truncated_data;          }          n = rar_br_bits(br, 3) + 3;          rar_br_consume(br, 3);        } else {          if (!rar_br_read_ahead(a, br, 7)) {            free(precode.tree);            free(precode.table);            goto truncated_data;          }          n = rar_br_bits(br, 7) + 11;          rar_br_consume(br, 7);        }        for (j = 0; j < n && i < HUFFMAN_TABLE_SIZE; j++)        {          rar->lengthtable[i] = rar->lengthtable[i-1];          i++;        }      }      else      {        if(val == 18) {          if (!rar_br_read_ahead(a, br, 3)) {            free(precode.tree);            free(precode.table);            goto truncated_data;          }          n = rar_br_bits(br, 3) + 3;          rar_br_consume(br, 3);        } else {          if (!rar_br_read_ahead(a, br, 7)) {            free(precode.tree);            free(precode.table);            goto truncated_data;          }          n = rar_br_bits(br, 7) + 11;          rar_br_consume(br, 7);        }        for(j = 0; j < n && i < HUFFMAN_TABLE_SIZE; j++)          rar->lengthtable[i++] = 0;      }    }    free(precode.tree);    free(precode.table);    r = create_code(a, &rar->maincode, &rar->lengthtable[0], MAINCODE_SIZE,                MAX_SYMBOL_LENGTH);    if (r != ARCHIVE_OK)      return (r);    r = create_code(a, &rar->offsetcode, &rar->lengthtable[MAINCODE_SIZE],                OFFSETCODE_SIZE, MAX_SYMBOL_LENGTH);    if (r != ARCHIVE_OK)      return (r);    r = create_code(a, &rar->lowoffsetcode,                &rar->lengthtable[MAINCODE_SIZE + OFFSETCODE_SIZE],                LOWOFFSETCODE_SIZE, MAX_SYMBOL_LENGTH);    if (r != ARCHIVE_OK)      return (r);    r = create_code(a, &rar->lengthcode,                &rar->lengthtable[MAINCODE_SIZE + OFFSETCODE_SIZE +                LOWOFFSETCODE_SIZE], LENGTHCODE_SIZE, MAX_SYMBOL_LENGTH);    if (r != ARCHIVE_OK)      return (r);  }  if (!rar->dictionary_size || !rar->lzss.window)  {         void *new_window;    unsigned int new_size;    if (rar->unp_size >= DICTIONARY_MAX_SIZE)      new_size = DICTIONARY_MAX_SIZE;    else      new_size = rar_fls((unsigned int)rar->unp_size) << 1;    if (new_size == 0) {      archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                        ""Zero window size is invalid."");      return (ARCHIVE_FATAL);    }    new_window = realloc(rar->lzss.window, new_size);    if (new_window == NULL) {      archive_set_error(&a->archive, ENOMEM,                        ""Unable to allocate memory for uncompressed data."");      return (ARCHIVE_FATAL);    }    rar->lzss.window = (unsigned char *)new_window;    rar->dictionary_size = new_size;    memset(rar->lzss.window, 0, rar->dictionary_size);    rar->lzss.mask = rar->dictionary_size - 1;  }  rar->start_new_table = 0;  return (ARCHIVE_OK);truncated_data:  archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                    ""Truncated RAR file data"");  rar->valid = 0;  return (ARCHIVE_FATAL);}",23185
322,861,CVE-2014-9940,19,"static int regulator_ena_gpio_ctrl(struct regulator_dev *rdev, int enable){	struct regulator_enable_gpio *pin = rdev->ena_pin;	if (!pin)		return -EINVAL;	if (enable) {		 		if (pin->enable_count == 0)			gpiod_set_value_cansleep(pin->gpiod,						 !pin->ena_gpio_invert);		pin->enable_count++;	} else {		if (pin->enable_count > 1) {			pin->enable_count--;			return 0;		}		 		if (pin->enable_count <= 1) {			gpiod_set_value_cansleep(pin->gpiod,						 pin->ena_gpio_invert);			pin->enable_count = 0;		}	}	return 0;}",23022
220,341,CVE-2016-4805,19,find_compressor(int type){	struct compressor_entry *ce;	struct compressor *cp = NULL;	spin_lock(&compressor_list_lock);	ce = find_comp_entry(type);	if (ce) {		cp = ce->comp;		if (!try_module_get(cp->owner))			cp = NULL;	}	spin_unlock(&compressor_list_lock);	return cp;},16648
117,248,CVE-2016-7912,19,"static int __ffs_ep0_stall(struct ffs_data *ffs){	if (ffs->ev.can_stall) {		pr_vdebug(""ep0 stall\n"");		usb_ep_set_halt(ffs->gadget->ep0);		ffs->setup_state = FFS_NO_SETUP;		return -EL2HLT;	} else {		pr_debug(""bogus ep0 stall!\n"");		return -ESRCH;	}}",15682
143,572,CVE-2017-16527,19,check_ignored_ctl(const struct usbmix_name_map *p){	if (!p || p->name || p->dB)		return 0;	return 1;},19831
232,1400,CVE-2019-11487,19,static struct fuse_dev *fuse_get_dev(struct file *file){	 	return READ_ONCE(file->private_data);},28897
41,280,CVE-2016-7912,19,"static int ffs_fs_parse_opts(struct ffs_sb_fill_data *data, char *opts){	ENTER();	if (!opts || !*opts)		return 0;	for (;;) {		unsigned long value;		char *eq, *comma;		 		comma = strchr(opts, ',');		if (comma)			*comma = 0;		 		eq = strchr(opts, '=');		if (unlikely(!eq)) {			pr_err(""'=' missing in %s\n"", opts);			return -EINVAL;		}		*eq = 0;		 		if (kstrtoul(eq + 1, 0, &value)) {			pr_err(""%s: invalid value: %s\n"", opts, eq + 1);			return -EINVAL;		}		 		switch (eq - opts) {		case 13:			if (!memcmp(opts, ""no_disconnect"", 13))				data->no_disconnect = !!value;			else				goto invalid;			break;		case 5:			if (!memcmp(opts, ""rmode"", 5))				data->root_mode  = (value & 0555) | S_IFDIR;			else if (!memcmp(opts, ""fmode"", 5))				data->perms.mode = (value & 0666) | S_IFREG;			else				goto invalid;			break;		case 4:			if (!memcmp(opts, ""mode"", 4)) {				data->root_mode  = (value & 0555) | S_IFDIR;				data->perms.mode = (value & 0666) | S_IFREG;			} else {				goto invalid;			}			break;		case 3:			if (!memcmp(opts, ""uid"", 3)) {				data->perms.uid = make_kuid(current_user_ns(), value);				if (!uid_valid(data->perms.uid)) {					pr_err(""%s: unmapped value: %lu\n"", opts, value);					return -EINVAL;				}			} else if (!memcmp(opts, ""gid"", 3)) {				data->perms.gid = make_kgid(current_user_ns(), value);				if (!gid_valid(data->perms.gid)) {					pr_err(""%s: unmapped value: %lu\n"", opts, value);					return -EINVAL;				}			} else {				goto invalid;			}			break;		default:invalid:			pr_err(""%s: invalid option\n"", opts);			return -EINVAL;		}		 		if (!comma)			break;		opts = comma + 1;	}	return 0;}",15714
3,76,CVE-2014-0131,19,"static void skb_panic(struct sk_buff *skb, unsigned int sz, void *addr,		      const char msg[]){	pr_emerg(""%s: text:%p len:%d put:%d head:%p data:%p tail:%#lx end:%#lx dev:%s\n"",		 msg, addr, skb->len, sz, skb->head, skb->data,		 (unsigned long)skb->tail, (unsigned long)skb->end,		 skb->dev ? skb->dev->name : ""<NULL>"");	BUG();}",12248
259,1265,CVE-2019-9003,19,"static int intf_start_seq_timer(struct ipmi_smi *intf,				long       msgid){	int           rv = -ENODEV;	unsigned long flags;	unsigned char seq;	unsigned long seqid;	GET_SEQ_FROM_MSGID(msgid, seq, seqid);	spin_lock_irqsave(&intf->seq_lock, flags);	 	if ((intf->seq_table[seq].inuse)				&& (intf->seq_table[seq].seqid == seqid)) {		struct seq_table *ent = &intf->seq_table[seq];		ent->timeout = ent->orig_timeout;		rv = 0;	}	spin_unlock_irqrestore(&intf->seq_lock, flags);	return rv;}",27242
235,695,CVE-2017-11176,19,"static int do_mq_getsetattr(int mqdes, struct mq_attr *new, struct mq_attr *old){	struct fd f;	struct inode *inode;	struct mqueue_inode_info *info;	if (new && (new->mq_flags & (~O_NONBLOCK)))		return -EINVAL;	f = fdget(mqdes);	if (!f.file)		return -EBADF;	if (unlikely(f.file->f_op != &mqueue_file_operations)) {		fdput(f);		return -EBADF;	}	inode = file_inode(f.file);	info = MQUEUE_I(inode);	spin_lock(&info->lock);	if (old) {		*old = info->attr;		old->mq_flags = f.file->f_flags & O_NONBLOCK;	}	if (new) {		audit_mq_getsetattr(mqdes, new);		spin_lock(&f.file->f_lock);		if (new->mq_flags & O_NONBLOCK)			f.file->f_flags |= O_NONBLOCK;		else			f.file->f_flags &= ~O_NONBLOCK;		spin_unlock(&f.file->f_lock);		inode->i_atime = inode->i_ctime = current_time(inode);	}	spin_unlock(&info->lock);	fdput(f);	return 0;}",20544
355,554,CVE-2017-16939,19,"static int xfrm_set_spdinfo(struct sk_buff *skb, struct nlmsghdr *nlh,			    struct nlattr **attrs){	struct net *net = sock_net(skb->sk);	struct xfrmu_spdhthresh *thresh4 = NULL;	struct xfrmu_spdhthresh *thresh6 = NULL;	 	if (attrs[XFRMA_SPD_IPV4_HTHRESH]) {		struct nlattr *rta = attrs[XFRMA_SPD_IPV4_HTHRESH];		if (nla_len(rta) < sizeof(*thresh4))			return -EINVAL;		thresh4 = nla_data(rta);		if (thresh4->lbits > 32 || thresh4->rbits > 32)			return -EINVAL;	}	if (attrs[XFRMA_SPD_IPV6_HTHRESH]) {		struct nlattr *rta = attrs[XFRMA_SPD_IPV6_HTHRESH];		if (nla_len(rta) < sizeof(*thresh6))			return -EINVAL;		thresh6 = nla_data(rta);		if (thresh6->lbits > 128 || thresh6->rbits > 128)			return -EINVAL;	}	if (thresh4 || thresh6) {		write_seqlock(&net->xfrm.policy_hthresh.lock);		if (thresh4) {			net->xfrm.policy_hthresh.lbits4 = thresh4->lbits;			net->xfrm.policy_hthresh.rbits4 = thresh4->rbits;		}		if (thresh6) {			net->xfrm.policy_hthresh.lbits6 = thresh6->lbits;			net->xfrm.policy_hthresh.rbits6 = thresh6->rbits;		}		write_sequnlock(&net->xfrm.policy_hthresh.lock);		xfrm_policy_hash_rebuild(net);	}	return 0;}",19647
326,943,CVE-2018-5873,19,"void *ns_get_path(struct path *path, struct task_struct *task,			const struct proc_ns_operations *ns_ops){	struct ns_common *ns;	void *ret;again:	ns = ns_ops->get(task);	if (!ns)		return ERR_PTR(-ENOENT);	ret = __ns_get_path(path, ns);	if (IS_ERR(ret) && PTR_ERR(ret) == -EAGAIN)		goto again;	return ret;}",25490
94,1305,CVE-2019-9003,19,"send_channel_info_cmd(struct ipmi_smi *intf, int chan){	struct kernel_ipmi_msg            msg;	unsigned char                     data[1];	struct ipmi_system_interface_addr si;	si.addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;	si.channel = IPMI_BMC_CHANNEL;	si.lun = 0;	msg.netfn = IPMI_NETFN_APP_REQUEST;	msg.cmd = IPMI_GET_CHANNEL_INFO_CMD;	msg.data = data;	msg.data_len = 1;	data[0] = chan;	return i_ipmi_request(NULL,			      intf,			      (struct ipmi_addr *) &si,			      0,			      &msg,			      intf,			      NULL,			      NULL,			      0,			      intf->addrinfo[0].address,			      intf->addrinfo[0].lun,			      -1, 0);}",27282
35,1347,CVE-2018-20856,19,void blk_queue_exit(struct request_queue *q){	percpu_ref_put(&q->q_usage_counter);},27496
293,875,CVE-2014-9940,19,void regulator_has_full_constraints(void){	has_full_constraints = 1;},23036
378,575,CVE-2017-16527,19,"check_mapped_name(const struct usbmix_name_map *p, char *buf, int buflen){	if (!p || !p->name)		return 0;	buflen--;	return strlcpy(buf, p->name, buflen);}",19834
308,1476,CVE-2019-11487,19,"static inline int check_dax_vmas(struct vm_area_struct **vmas, long nr_pages){	return false;}",28973
353,673,CVE-2017-15115,19,"static inline void sctp_copy_descendant(struct sock *sk_to,					const struct sock *sk_from){	int ancestor_size = sizeof(struct inet_sock) +			    sizeof(struct sctp_sock) -			    offsetof(struct sctp_sock, auto_asconf_list);	if (sk_from->sk_family == PF_INET6)		ancestor_size += sizeof(struct ipv6_pinfo);	__inet_sk_copy_descendant(sk_to, sk_from, ancestor_size);}",20069
216,426,CVE-2015-8963,19,"static void account_event(struct perf_event *event){	if (event->parent)		return;	if (event->attach_state & PERF_ATTACH_TASK)		static_key_slow_inc(&perf_sched_events.key);	if (event->attr.mmap || event->attr.mmap_data)		atomic_inc(&nr_mmap_events);	if (event->attr.comm)		atomic_inc(&nr_comm_events);	if (event->attr.task)		atomic_inc(&nr_task_events);	if (event->attr.freq) {		if (atomic_inc_return(&nr_freq_events) == 1)			tick_nohz_full_kick_all();	}	if (event->attr.context_switch) {		atomic_inc(&nr_switch_events);		static_key_slow_inc(&perf_sched_events.key);	}	if (has_branch_stack(event))		static_key_slow_inc(&perf_sched_events.key);	if (is_cgroup_event(event))		static_key_slow_inc(&perf_sched_events.key);	account_event_cpu(event, event->cpu);}",18334
252,542,CVE-2017-16939,19,"static int xfrm_dump_sa_done(struct netlink_callback *cb){	struct xfrm_state_walk *walk = (struct xfrm_state_walk *) &cb->args[1];	struct sock *sk = cb->skb->sk;	struct net *net = sock_net(sk);	if (cb->args[0])		xfrm_state_walk_done(walk, net);	return 0;}",19635
246,602,CVE-2017-16527,19,"static int restore_mixer_value(struct usb_mixer_elem_list *list){	struct usb_mixer_elem_info *cval = (struct usb_mixer_elem_info *)list;	int c, err, idx;	if (cval->cmask) {		idx = 0;		for (c = 0; c < MAX_CHANNELS; c++) {			if (!(cval->cmask & (1 << c)))				continue;			if (cval->cached & (1 << (c + 1))) {				err = snd_usb_set_cur_mix_value(cval, c + 1, idx,							cval->cache_val[idx]);				if (err < 0)					return err;			}			idx++;		}	} else {		 		if (cval->cached) {			err = snd_usb_set_cur_mix_value(cval, 0, 0, *cval->cache_val);			if (err < 0)				return err;		}	}	return 0;}",19861
176,1514,CVE-2014-3194,19,  CustomWindowTargeter() {},29501
93,363,CVE-2016-4805,19,"static inline struct ppp_net *ppp_pernet(struct net *net){	BUG_ON(!net);	return net_generic(net, ppp_net_id);}",16670
152,413,CVE-2016-3841,19,"static void tcp_v6_restore_cb(struct sk_buff *skb){	 	memmove(IP6CB(skb), &TCP_SKB_CB(skb)->header.h6,		sizeof(struct inet6_skb_parm));}",17185
184,957,CVE-2018-5344,19,"static void loop_config_discard(struct loop_device *lo){	struct file *file = lo->lo_backing_file;	struct inode *inode = file->f_mapping->host;	struct request_queue *q = lo->lo_queue;	 	if ((!file->f_op->fallocate) ||	    lo->lo_encrypt_key_size) {		q->limits.discard_granularity = 0;		q->limits.discard_alignment = 0;		blk_queue_max_discard_sectors(q, 0);		blk_queue_max_write_zeroes_sectors(q, 0);		queue_flag_clear_unlocked(QUEUE_FLAG_DISCARD, q);		return;	}	q->limits.discard_granularity = inode->i_sb->s_blocksize;	q->limits.discard_alignment = 0;	blk_queue_max_discard_sectors(q, UINT_MAX >> 9);	blk_queue_max_write_zeroes_sectors(q, UINT_MAX >> 9);	queue_flag_set_unlocked(QUEUE_FLAG_DISCARD, q);}",25504
206,153,CVE-2016-9794,19,"int snd_pcm_update_hw_ptr(struct snd_pcm_substream *substream){	return snd_pcm_update_hw_ptr0(substream, 0);}",15038
61,1065,CVE-2017-15129,19,void net_ns_barrier(void){	mutex_lock(&net_mutex);	mutex_unlock(&net_mutex);},26134
299,295,CVE-2016-7912,19,"ffs_sb_make_inode(struct super_block *sb, void *data,		  const struct file_operations *fops,		  const struct inode_operations *iops,		  struct ffs_file_perms *perms){	struct inode *inode;	ENTER();	inode = new_inode(sb);	if (likely(inode)) {		struct timespec current_time = CURRENT_TIME;		inode->i_ino	 = get_next_ino();		inode->i_mode    = perms->mode;		inode->i_uid     = perms->uid;		inode->i_gid     = perms->gid;		inode->i_atime   = current_time;		inode->i_mtime   = current_time;		inode->i_ctime   = current_time;		inode->i_private = data;		if (fops)			inode->i_fop = fops;		if (iops)			inode->i_op  = iops;	}	return inode;}",15729
228,902,CVE-2018-19824,19,"static int snd_usb_create_streams(struct snd_usb_audio *chip, int ctrlif){	struct usb_device *dev = chip->dev;	struct usb_host_interface *host_iface;	struct usb_interface_descriptor *altsd;	int i, protocol;	 	host_iface = &usb_ifnum_to_if(dev, ctrlif)->altsetting[0];	altsd = get_iface_desc(host_iface);	protocol = altsd->bInterfaceProtocol;	switch (protocol) {	default:		dev_warn(&dev->dev,			 ""unknown interface protocol %#02x, assuming v1\n"",			 protocol);		 	case UAC_VERSION_1: {		struct uac1_ac_header_descriptor *h1;		int rest_bytes;		h1 = snd_usb_find_csint_desc(host_iface->extra,							 host_iface->extralen,							 NULL, UAC_HEADER);		if (!h1) {			dev_err(&dev->dev, ""cannot find UAC_HEADER\n"");			return -EINVAL;		}		rest_bytes = (void *)(host_iface->extra +				host_iface->extralen) - (void *)h1;		 		if (rest_bytes <= 0) {			dev_err(&dev->dev, ""invalid control header\n"");			return -EINVAL;		}		if (rest_bytes < sizeof(*h1)) {			dev_err(&dev->dev, ""too short v1 buffer descriptor\n"");			return -EINVAL;		}		if (!h1->bInCollection) {			dev_info(&dev->dev, ""skipping empty audio interface (v1)\n"");			return -EINVAL;		}		if (rest_bytes < h1->bLength) {			dev_err(&dev->dev, ""invalid buffer length (v1)\n"");			return -EINVAL;		}		if (h1->bLength < sizeof(*h1) + h1->bInCollection) {			dev_err(&dev->dev, ""invalid UAC_HEADER (v1)\n"");			return -EINVAL;		}		for (i = 0; i < h1->bInCollection; i++)			snd_usb_create_stream(chip, ctrlif, h1->baInterfaceNr[i]);		break;	}	case UAC_VERSION_2:	case UAC_VERSION_3: {		struct usb_interface_assoc_descriptor *assoc =			usb_ifnum_to_if(dev, ctrlif)->intf_assoc;		if (!assoc) {			 			struct usb_interface *iface =				usb_ifnum_to_if(dev, ctrlif + 1);			if (iface &&			    iface->intf_assoc &&			    iface->intf_assoc->bFunctionClass == USB_CLASS_AUDIO &&			    iface->intf_assoc->bFunctionProtocol == UAC_VERSION_2)				assoc = iface->intf_assoc;		}		if (!assoc) {			dev_err(&dev->dev, ""Audio class v2/v3 interfaces need an interface association\n"");			return -EINVAL;		}		if (protocol == UAC_VERSION_3) {			int badd = assoc->bFunctionSubClass;			if (badd != UAC3_FUNCTION_SUBCLASS_FULL_ADC_3_0 &&			    (badd < UAC3_FUNCTION_SUBCLASS_GENERIC_IO ||			     badd > UAC3_FUNCTION_SUBCLASS_SPEAKERPHONE)) {				dev_err(&dev->dev,					""Unsupported UAC3 BADD profile\n"");				return -EINVAL;			}			chip->badd_profile = badd;		}		for (i = 0; i < assoc->bInterfaceCount; i++) {			int intf = assoc->bFirstInterface + i;			if (intf != ctrlif)				snd_usb_create_stream(chip, ctrlif, intf);		}		break;	}	}	return 0;}",23342
7,1007,CVE-2017-18218,19,"static inline void hns_nic_reclaim_one_desc(struct hnae_ring *ring,					    int *bytes, int *pkts){	struct hnae_desc_cb *desc_cb = &ring->desc_cb[ring->next_to_clean];	(*pkts) += (desc_cb->type == DESC_TYPE_SKB);	(*bytes) += desc_cb->length;	 	hnae_free_buffer_detach(ring, ring->next_to_clean);	ring_ptr_move_fw(ring, next_to_clean);}",25857
272,1495,CVE-2019-11487,19,"void move_hugetlb_state(struct page *oldpage, struct page *newpage, int reason){	struct hstate *h = page_hstate(oldpage);	hugetlb_cgroup_migrate(oldpage, newpage);	set_page_owner_migrate_reason(newpage, reason);	 	if (PageHugeTemporary(newpage)) {		int old_nid = page_to_nid(oldpage);		int new_nid = page_to_nid(newpage);		SetPageHugeTemporary(oldpage);		ClearPageHugeTemporary(newpage);		spin_lock(&hugetlb_lock);		if (h->surplus_huge_pages_node[old_nid]) {			h->surplus_huge_pages_node[old_nid]--;			h->surplus_huge_pages_node[new_nid]++;		}		spin_unlock(&hugetlb_lock);	}}",28992
76,140,CVE-2016-9794,19,"int snd_pcm_hw_constraint_msbits(struct snd_pcm_runtime *runtime, 				 unsigned int cond,				 unsigned int width,				 unsigned int msbits){	unsigned long l = (msbits << 16) | width;	return snd_pcm_hw_rule_add(runtime, cond, -1,				    snd_pcm_hw_rule_msbits,				    (void*) l,				    SNDRV_PCM_HW_PARAM_SAMPLE_BITS, -1);}",15025
15,1455,CVE-2019-11487,19,"static void buffer_pipe_buf_release(struct pipe_inode_info *pipe,				    struct pipe_buffer *buf){	struct buffer_ref *ref = (struct buffer_ref *)buf->private;	if (--ref->ref)		return;	ring_buffer_free_read_page(ref->buffer, ref->cpu, ref->page);	kfree(ref); 	buf->private = 0; }",28952
65,850,CVE-2014-9940,19,"int regulator_bulk_get(struct device *dev, int num_consumers,		       struct regulator_bulk_data *consumers){	int i;	int ret;	for (i = 0; i < num_consumers; i++)		consumers[i].consumer = NULL;	for (i = 0; i < num_consumers; i++) {		consumers[i].consumer = regulator_get(dev,						      consumers[i].supply);		if (IS_ERR(consumers[i].consumer)) {			ret = PTR_ERR(consumers[i].consumer);			dev_err(dev, ""Failed to get supply '%s': %d\n"",				consumers[i].supply, ret);			consumers[i].consumer = NULL;			goto err;		}	}	return 0;err:	while (--i >= 0)		regulator_put(consumers[i].consumer);	return ret;}",23011
284,544,CVE-2017-16939,19,"static int xfrm_exp_state_notify(struct xfrm_state *x, const struct km_event *c){	struct net *net = xs_net(x);	struct sk_buff *skb;	skb = nlmsg_new(xfrm_expire_msgsize(), GFP_ATOMIC);	if (skb == NULL)		return -ENOMEM;	if (build_expire(skb, x, c) < 0) {		kfree_skb(skb);		return -EMSGSIZE;	}	return xfrm_nlmsg_multicast(net, skb, 0, XFRMNLGRP_EXPIRE);}",19637
362,676,CVE-2017-15115,19,"static void sctp_destroy_sock(struct sock *sk){	struct sctp_sock *sp;	pr_debug(""%s: sk:%p\n"", __func__, sk);	 	sp = sctp_sk(sk);	 	if (sp->ep == NULL)		return;	if (sp->do_auto_asconf) {		sp->do_auto_asconf = 0;		list_del(&sp->auto_asconf_list);	}	sctp_endpoint_free(sp->ep);	local_bh_disable();	percpu_counter_dec(&sctp_sockets_allocated);	sock_prot_inuse_add(sock_net(sk), sk->sk_prot, -1);	local_bh_enable();}",20072
38,961,CVE-2018-5344,19,"static void loop_handle_cmd(struct loop_cmd *cmd){	const int write = op_is_write(req_op(cmd->rq));	struct loop_device *lo = cmd->rq->q->queuedata;	int ret = 0;	if (write && (lo->lo_flags & LO_FLAGS_READ_ONLY)) {		ret = -EIO;		goto failed;	}	ret = do_req_filebacked(lo, cmd->rq); failed:	 	if (!cmd->use_aio || ret) {		cmd->ret = ret ? -EIO : 0;		blk_mq_complete_request(cmd->rq);	}}",25508
121,257,CVE-2016-7912,19,"static void ffs_data_clear(struct ffs_data *ffs){	ENTER();	ffs_closed(ffs);	BUG_ON(ffs->gadget);	if (ffs->epfiles)		ffs_epfiles_destroy(ffs->epfiles, ffs->eps_count);	if (ffs->ffs_eventfd)		eventfd_ctx_put(ffs->ffs_eventfd);	kfree(ffs->raw_descs_data);	kfree(ffs->raw_strings);	kfree(ffs->stringtabs);}",15691
266,500,CVE-2017-17052,19,static int check_unshare_flags(unsigned long unshare_flags){	if (unshare_flags & ~(CLONE_THREAD|CLONE_FS|CLONE_NEWNS|CLONE_SIGHAND|				CLONE_VM|CLONE_FILES|CLONE_SYSVSEM|				CLONE_NEWUTS|CLONE_NEWIPC|CLONE_NEWNET|				CLONE_NEWUSER|CLONE_NEWPID|CLONE_NEWCGROUP))		return -EINVAL;	 	if (unshare_flags & (CLONE_THREAD | CLONE_SIGHAND | CLONE_VM)) {		if (!thread_group_empty(current))			return -EINVAL;	}	if (unshare_flags & (CLONE_SIGHAND | CLONE_VM)) {		if (atomic_read(&current->sighand->count) > 1)			return -EINVAL;	}	if (unshare_flags & CLONE_VM) {		if (!current_is_single_threaded())			return -EINVAL;	}	return 0;},19586
383,563,CVE-2017-16528,19,"static int snd_seq_bus_match(struct device *dev, struct device_driver *drv){	struct snd_seq_device *sdev = to_seq_dev(dev);	struct snd_seq_driver *sdrv = to_seq_drv(drv);	return strcmp(sdrv->id, sdev->id) == 0 &&		sdrv->argsize == sdev->argsize;}",19822
189,308,CVE-2016-7910,19,int bdev_read_only(struct block_device *bdev){	if (!bdev)		return 0;	return bdev->bd_part->policy;},15742
244,1060,CVE-2017-15129,19,"static struct net *net_alloc(void){	struct net *net = NULL;	struct net_generic *ng;	ng = net_alloc_generic();	if (!ng)		goto out;	net = kmem_cache_zalloc(net_cachep, GFP_KERNEL);	if (!net)		goto out_free;	rcu_assign_pointer(net->gen, ng);out:	return net;out_free:	kfree(ng);	goto out;}",26129
374,807,CVE-2016-10150,19,void kvm_vcpu_kick(struct kvm_vcpu *vcpu){	int me;	int cpu = vcpu->cpu;	kvm_vcpu_wake_up(vcpu);	me = get_cpu();	if (cpu != me && (unsigned)cpu < nr_cpu_ids && cpu_online(cpu))		if (kvm_arch_vcpu_should_kick(vcpu))			smp_send_reschedule(cpu);	put_cpu();},22523
20,370,CVE-2016-4805,19,int ppp_unit_number(struct ppp_channel *chan){	struct channel *pch = chan->ppp;	int unit = -1;	if (pch) {		read_lock_bh(&pch->upl);		if (pch->ppp)			unit = pch->ppp->file.index;		read_unlock_bh(&pch->upl);	}	return unit;},16677
369,276,CVE-2016-7912,19,static void ffs_free(struct usb_function *f){	kfree(ffs_func_from_usb(f));},15710
269,39,CVE-2016-8674,19,"	fz_catch(ctx)	{		pdf_drop_obj(ctx, encrypt);		pdf_drop_obj(ctx, id);		pdf_drop_obj(ctx, obj);		pdf_drop_obj(ctx, info);		fz_free(ctx, list);		fz_rethrow(ctx);	}",2237
242,446,CVE-2015-8963,19,"perf_event_ctx_lock_nested(struct perf_event *event, int nesting){	struct perf_event_context *ctx;again:	rcu_read_lock();	ctx = ACCESS_ONCE(event->ctx);	if (!atomic_inc_not_zero(&ctx->refcount)) {		rcu_read_unlock();		goto again;	}	rcu_read_unlock();	mutex_lock_nested(&ctx->mutex, nesting);	if (event->ctx != ctx) {		mutex_unlock(&ctx->mutex);		put_ctx(ctx);		goto again;	}	return ctx;}",18354
165,942,CVE-2018-5873,19,"static char *ns_dname(struct dentry *dentry, char *buffer, int buflen){	struct inode *inode = d_inode(dentry);	const struct proc_ns_operations *ns_ops = dentry->d_fsdata;	return dynamic_dname(dentry, buffer, buflen, ""%s:[%lu]"",		ns_ops->name, inode->i_ino);}",25489
8,724,CVE-2017-10966,19,"char *replace_chars(char *str, char from, char to){	char *p;	for (p = str; *p != '\0'; p++) {		if (*p == from) *p = to;	}	return str;}",20573
341,57,CVE-2014-0131,19,static inline int skb_alloc_rx_flag(const struct sk_buff *skb){	if (skb_pfmemalloc(skb))		return SKB_ALLOC_RX;	return 0;},12229
159,169,CVE-2016-9120,19,"static int ion_buffer_put(struct ion_buffer *buffer){	return kref_put(&buffer->ref, _ion_buffer_destroy);}",15255
273,377,CVE-2016-4805,19,"static int unit_set(struct idr *p, void *ptr, int n){	int unit;	unit = idr_alloc(p, ptr, n, n + 1, GFP_KERNEL);	if (unit == -ENOSPC)		unit = -EINVAL;	return unit;}",16684
97,333,CVE-2016-7910,19,"int register_blkdev(unsigned int major, const char *name){	struct blk_major_name **n, *p;	int index, ret = 0;	mutex_lock(&block_class_lock);	 	if (major == 0) {		for (index = ARRAY_SIZE(major_names)-1; index > 0; index--) {			if (major_names[index] == NULL)				break;		}		if (index == 0) {			printk(""register_blkdev: failed to get major for %s\n"",			       name);			ret = -EBUSY;			goto out;		}		major = index;		ret = major;	}	p = kmalloc(sizeof(struct blk_major_name), GFP_KERNEL);	if (p == NULL) {		ret = -ENOMEM;		goto out;	}	p->major = major;	strlcpy(p->name, name, sizeof(p->name));	p->next = NULL;	index = major_to_index(major);	for (n = &major_names[index]; *n; n = &(*n)->next) {		if ((*n)->major == major)			break;	}	if (!*n)		*n = p;	else		ret = -EBUSY;	if (ret < 0) {		printk(""register_blkdev: cannot get major %d for %s\n"",		       major, name);		kfree(p);	}out:	mutex_unlock(&block_class_lock);	return ret;}",15767
346,802,CVE-2016-10150,19,"static void kvm_sched_in(struct preempt_notifier *pn, int cpu){	struct kvm_vcpu *vcpu = preempt_notifier_to_vcpu(pn);	if (vcpu->preempted)		vcpu->preempted = false;	kvm_arch_sched_in(vcpu, cpu);	kvm_arch_vcpu_load(vcpu, cpu);}",22518
137,1458,CVE-2019-11487,19,"static inline void set_cmdline(int idx, const char *cmdline){	strncpy(get_saved_cmdlines(idx), cmdline, TASK_COMM_LEN);}",28955
106,1544,CVE-2017-15412,19,void Increment(int* i) {  ++(*i);},30136
127,1187,CVE-2019-11811,19,"static void request_events(void *send_info){	struct smi_info *smi_info = send_info;	if (!smi_info->has_event_buffer)		return;	atomic_set(&smi_info->req_events, 1);}",26950
254,369,CVE-2016-4805,19,"ppp_start_xmit(struct sk_buff *skb, struct net_device *dev){	struct ppp *ppp = netdev_priv(dev);	int npi, proto;	unsigned char *pp;	npi = ethertype_to_npindex(ntohs(skb->protocol));	if (npi < 0)		goto outf;	 	switch (ppp->npmode[npi]) {	case NPMODE_PASS:		break;	case NPMODE_QUEUE:		 		goto outf;	case NPMODE_DROP:	case NPMODE_ERROR:		goto outf;	}	 	if (skb_cow_head(skb, PPP_HDRLEN))		goto outf;	pp = skb_push(skb, 2);	proto = npindex_to_proto[npi];	put_unaligned_be16(proto, pp);	skb_scrub_packet(skb, !net_eq(ppp->ppp_net, dev_net(dev)));	skb_queue_tail(&ppp->file.xq, skb);	ppp_xmit_process(ppp);	return NETDEV_TX_OK; outf:	kfree_skb(skb);	++dev->stats.tx_dropped;	return NETDEV_TX_OK;}",16676
11,65,CVE-2014-0131,19,static inline void skb_drop_fraglist(struct sk_buff *skb){	skb_drop_list(&skb_shinfo(skb)->frag_list);},12237
150,429,CVE-2015-8963,19,event_filter_match(struct perf_event *event){	return (event->cpu == -1 || event->cpu == smp_processor_id())	    && perf_cgroup_match(event) && pmu_filter_match(event);},18337
226,853,CVE-2014-9940,19,int regulator_can_change_voltage(struct regulator *regulator){	struct regulator_dev	*rdev = regulator->rdev;	if (rdev->constraints &&	    (rdev->constraints->valid_ops_mask & REGULATOR_CHANGE_VOLTAGE)) {		if (rdev->desc->n_voltages - rdev->desc->linear_min_sel > 1)			return 1;		if (rdev->desc->continuous_voltage_range &&		    rdev->constraints->min_uV && rdev->constraints->max_uV &&		    rdev->constraints->min_uV != rdev->constraints->max_uV)			return 1;	}	return 0;},23014
297,994,CVE-2017-18218,19,"static int hns_nic_init_irq(struct hns_nic_priv *priv){	struct hnae_handle *h = priv->ae_handle;	struct hns_nic_ring_data *rd;	int i;	int ret;	int cpu;	for (i = 0; i < h->q_num * 2; i++) {		rd = &priv->ring_data[i];		if (rd->ring->irq_init_flag == RCB_IRQ_INITED)			break;		snprintf(rd->ring->ring_name, RCB_RING_NAME_LEN,			 ""%s-%s%d"", priv->netdev->name,			 (is_tx_ring(rd->ring) ? ""tx"" : ""rx""), rd->queue_index);		rd->ring->ring_name[RCB_RING_NAME_LEN - 1] = '\0';		ret = request_irq(rd->ring->irq,				  hns_irq_handle, 0, rd->ring->ring_name, rd);		if (ret) {			netdev_err(priv->netdev, ""request irq(%d) fail\n"",				   rd->ring->irq);			return ret;		}		disable_irq(rd->ring->irq);		cpu = hns_nic_init_affinity_mask(h->q_num, i,						 rd->ring, &rd->mask);		if (cpu_online(cpu))			irq_set_affinity_hint(rd->ring->irq,					      &rd->mask);		rd->ring->irq_init_flag = RCB_IRQ_INITED;	}	return 0;}",25844
342,155,CVE-2016-9576,19,"static int __blk_rq_unmap_user(struct bio *bio){	int ret = 0;	if (bio) {		if (bio_flagged(bio, BIO_USER_MAPPED))			bio_unmap_user(bio);		else			ret = bio_uncopy_user(bio);	}	return ret;}",15160
34,167,CVE-2016-9120,19,static inline void ion_buffer_page_dirty(struct page **page){	*page = (struct page *)((unsigned long)(*page) | 1UL);},15253
288,1451,CVE-2019-11487,19,"static long vmsplice_to_pipe(struct file *file, struct iov_iter *iter,			     unsigned int flags){	struct pipe_inode_info *pipe;	long ret = 0;	unsigned buf_flag = 0;	if (flags & SPLICE_F_GIFT)		buf_flag = PIPE_BUF_FLAG_GIFT;	pipe = get_pipe_info(file);	if (!pipe)		return -EBADF;	pipe_lock(pipe);	ret = wait_for_space(pipe, flags);	if (!ret)		ret = iter_to_pipe(iter, pipe, buf_flag);	pipe_unlock(pipe);	if (ret > 0)		wakeup_pipe_readers(pipe);	return ret;}",28948
238,338,CVE-2016-7910,19,"static int show_partition(struct seq_file *seqf, void *v){	struct gendisk *sgp = v;	struct disk_part_iter piter;	struct hd_struct *part;	char buf[BDEVNAME_SIZE];	 	if (!get_capacity(sgp) || (!disk_max_parts(sgp) &&				   (sgp->flags & GENHD_FL_REMOVABLE)))		return 0;	if (sgp->flags & GENHD_FL_SUPPRESS_PARTITION_INFO)		return 0;	 	disk_part_iter_init(&piter, sgp, DISK_PITER_INCL_PART0);	while ((part = disk_part_iter_next(&piter)))		seq_printf(seqf, ""%4d  %7d %10llu %s\n"",			   MAJOR(part_devt(part)), MINOR(part_devt(part)),			   (unsigned long long)part_nr_sects_read(part) >> 1,			   disk_name(sgp, part->partno, buf));	disk_part_iter_exit(&piter);	return 0;}",15772
343,847,CVE-2014-9940,19,"int regulator_bulk_enable(int num_consumers,			  struct regulator_bulk_data *consumers){	ASYNC_DOMAIN_EXCLUSIVE(async_domain);	int i;	int ret = 0;	for (i = 0; i < num_consumers; i++) {		if (consumers[i].consumer->always_on)			consumers[i].ret = 0;		else			async_schedule_domain(regulator_bulk_enable_async,					      &consumers[i], &async_domain);	}	async_synchronize_full_domain(&async_domain);	 	for (i = 0; i < num_consumers; i++) {		if (consumers[i].ret != 0) {			ret = consumers[i].ret;			goto err;		}	}	return 0;err:	for (i = 0; i < num_consumers; i++) {		if (consumers[i].ret < 0)			pr_err(""Failed to enable %s: %d\n"", consumers[i].supply,			       consumers[i].ret);		else			regulator_disable(consumers[i].consumer);	}	return ret;}",23008
389,830,CVE-2014-9940,19,static int _regulator_get_current_limit(struct regulator_dev *rdev){	int ret;	mutex_lock(&rdev->mutex);	 	if (!rdev->desc->ops->get_current_limit) {		ret = -EINVAL;		goto out;	}	ret = rdev->desc->ops->get_current_limit(rdev);out:	mutex_unlock(&rdev->mutex);	return ret;},22991
257,1052,CVE-2017-15129,19,"void __put_net(struct net *net){	 	unsigned long flags;	spin_lock_irqsave(&cleanup_list_lock, flags);	list_add(&net->cleanup_list, &cleanup_list);	spin_unlock_irqrestore(&cleanup_list_lock, flags);	queue_work(netns_wq, &net_cleanup_work);}",26121
387,414,CVE-2016-3841,19,"void udp6_proc_exit(struct net *net){	udp_proc_unregister(net, &udp6_seq_afinfo);}",17186
390,1453,CVE-2019-11487,19,"static int vmsplice_type(struct fd f, int *type){	if (!f.file)		return -EBADF;	if (f.file->f_mode & FMODE_WRITE) {		*type = WRITE;	} else if (f.file->f_mode & FMODE_READ) {		*type = READ;	} else {		fdput(f);		return -EBADF;	}	return 0;}",28950
358,16,CVE-2016-6295,19,"PHP_FUNCTION(snmp3_getnext){	php_snmp(INTERNAL_FUNCTION_PARAM_PASSTHRU, SNMP_CMD_GETNEXT, SNMP_VERSION_3);}",1670
75,1204,CVE-2019-11811,19,"static void start_clear_flags(struct smi_info *smi_info){	unsigned char msg[3];	 	msg[0] = (IPMI_NETFN_APP_REQUEST << 2);	msg[1] = IPMI_CLEAR_MSG_FLAGS_CMD;	msg[2] = WDT_PRE_TIMEOUT_INT;	start_new_msg(smi_info, msg, 3);	smi_info->si_state = SI_CLEARING_FLAGS;}",26967
334,100,CVE-2014-0131,19,"static void sock_spd_release(struct splice_pipe_desc *spd, unsigned int i){	put_page(spd->pages[i]);}",12272
300,1313,CVE-2018-20856,19,void __blk_run_queue(struct request_queue *q){	lockdep_assert_held(q->queue_lock);	WARN_ON_ONCE(q->mq_ops);	if (unlikely(blk_queue_stopped(q)))		return;	__blk_run_queue_uncond(q);},27462
66,372,CVE-2016-4805,19,"ppp_xmit_process(struct ppp *ppp){	struct sk_buff *skb;	ppp_xmit_lock(ppp);	if (!ppp->closing) {		ppp_push(ppp);		while (!ppp->xmit_pending &&		       (skb = skb_dequeue(&ppp->file.xq)))			ppp_send_frame(ppp, skb);		 		if (!ppp->xmit_pending && !skb_peek(&ppp->file.xq))			netif_wake_queue(ppp->dev);		else			netif_stop_queue(ppp->dev);	}	ppp_xmit_unlock(ppp);}",16679
1,269,CVE-2016-7912,19,"static void ffs_epfile_io_complete(struct usb_ep *_ep, struct usb_request *req){	ENTER();	if (likely(req->context)) {		struct ffs_ep *ep = _ep->driver_data;		ep->status = req->status ? req->status : req->actual;		complete(req->context);	}}",15703
12,1039,CVE-2017-18202,19,static inline int is_sysrq_oom(struct oom_control *oc){	return oc->order == -1;},26017
296,668,CVE-2017-15265,19,"int snd_seq_set_port_info(struct snd_seq_client_port * port,			  struct snd_seq_port_info * info){	if (snd_BUG_ON(!port || !info))		return -EINVAL;	 	if (info->name[0])		strlcpy(port->name, info->name, sizeof(port->name));		 	port->capability = info->capability;		 	port->type = info->type;	 	port->midi_channels = info->midi_channels;	port->midi_voices = info->midi_voices;	port->synth_voices = info->synth_voices;	 	port->timestamping = (info->flags & SNDRV_SEQ_PORT_FLG_TIMESTAMP) ? 1 : 0;	port->time_real = (info->flags & SNDRV_SEQ_PORT_FLG_TIME_REAL) ? 1 : 0;	port->time_queue = info->time_queue;	return 0;}",20058
250,443,CVE-2015-8963,19,"static void perf_event_context_sched_out(struct task_struct *task, int ctxn,					 struct task_struct *next){	struct perf_event_context *ctx = task->perf_event_ctxp[ctxn];	struct perf_event_context *next_ctx;	struct perf_event_context *parent, *next_parent;	struct perf_cpu_context *cpuctx;	int do_switch = 1;	if (likely(!ctx))		return;	cpuctx = __get_cpu_context(ctx);	if (!cpuctx->task_ctx)		return;	rcu_read_lock();	next_ctx = next->perf_event_ctxp[ctxn];	if (!next_ctx)		goto unlock;	parent = rcu_dereference(ctx->parent_ctx);	next_parent = rcu_dereference(next_ctx->parent_ctx);	 	if (!parent && !next_parent)		goto unlock;	if (next_parent == ctx || next_ctx == parent || next_parent == parent) {		 		raw_spin_lock(&ctx->lock);		raw_spin_lock_nested(&next_ctx->lock, SINGLE_DEPTH_NESTING);		if (context_equiv(ctx, next_ctx)) {			 			task->perf_event_ctxp[ctxn] = next_ctx;			next->perf_event_ctxp[ctxn] = ctx;			ctx->task = next;			next_ctx->task = task;			swap(ctx->task_ctx_data, next_ctx->task_ctx_data);			do_switch = 0;			perf_event_sync_stat(ctx, next_ctx);		}		raw_spin_unlock(&next_ctx->lock);		raw_spin_unlock(&ctx->lock);	}unlock:	rcu_read_unlock();	if (do_switch) {		raw_spin_lock(&ctx->lock);		ctx_sched_out(ctx, cpuctx, EVENT_ALL);		cpuctx->task_ctx = NULL;		raw_spin_unlock(&ctx->lock);	}}",18351
268,1362,CVE-2018-20856,19,void blk_start_plug(struct blk_plug *plug){	struct task_struct *tsk = current;	 	if (tsk->plug)		return;	INIT_LIST_HEAD(&plug->list);	INIT_LIST_HEAD(&plug->mq_list);	INIT_LIST_HEAD(&plug->cb_list);	 	tsk->plug = plug;},27511
370,885,CVE-2014-9940,19,"int regulator_register_supply_alias(struct device *dev, const char *id,				    struct device *alias_dev,				    const char *alias_id){	struct regulator_supply_alias *map;	map = regulator_find_supply_alias(dev, id);	if (map)		return -EEXIST;	map = kzalloc(sizeof(struct regulator_supply_alias), GFP_KERNEL);	if (!map)		return -ENOMEM;	map->src_dev = dev;	map->src_supply = id;	map->alias_dev = alias_dev;	map->alias_supply = alias_id;	list_add(&map->list, &regulator_supply_alias_list);	pr_info(""Adding alias for supply %s,%s -> %s,%s\n"",		id, dev_name(dev), alias_id, dev_name(alias_dev));	return 0;}",23046
345,1110,CVE-2019-15920,19,"static inline int __smb2_reconnect(const struct nls_table *nlsc,				   struct cifs_tcon *tcon){	return SMB2_tcon(0, tcon->ses, tcon->treeName, tcon, nlsc);}",26588
181,810,CVE-2016-10150,19,"int kvm_vcpu_yield_to(struct kvm_vcpu *target){	struct pid *pid;	struct task_struct *task = NULL;	int ret = 0;	rcu_read_lock();	pid = rcu_dereference(target->pid);	if (pid)		task = get_pid_task(pid, PIDTYPE_PID);	rcu_read_unlock();	if (!task)		return ret;	ret = yield_to(task, 1);	put_task_struct(task);	return ret;}",22526
178,1551,CVE-2018-6171,19,    BluetoothSocketAbstractConnectFunction() {},30239
14,665,CVE-2017-15265,19,"int snd_seq_event_port_detach(int client, int port){	struct snd_seq_port_info portinfo;	int  err;	memset(&portinfo, 0, sizeof(portinfo));	portinfo.addr.client = client;	portinfo.addr.port   = port;	err = snd_seq_kernel_client_ctl(client,					SNDRV_SEQ_IOCTL_DELETE_PORT,					&portinfo);	return err;}",20055
195,1390,CVE-2019-11487,19,"static int fuse_block_alloc(struct fuse_conn *fc, int for_background){	return !fc->initialized || (for_background && fc->blocked);}",28887
172,189,CVE-2016-9120,19,"void *ion_map_kernel(struct ion_client *client, struct ion_handle *handle){	struct ion_buffer *buffer;	void *vaddr;	mutex_lock(&client->lock);	if (!ion_handle_validate(client, handle)) {		pr_err(""%s: invalid handle passed to map_kernel.\n"",		       __func__);		mutex_unlock(&client->lock);		return ERR_PTR(-EINVAL);	}	buffer = handle->buffer;	if (!handle->buffer->heap->ops->map_kernel) {		pr_err(""%s: map_kernel is not implemented by this heap.\n"",		       __func__);		mutex_unlock(&client->lock);		return ERR_PTR(-ENODEV);	}	mutex_lock(&buffer->lock);	vaddr = ion_handle_kmap_get(handle);	mutex_unlock(&buffer->lock);	mutex_unlock(&client->lock);	return vaddr;}",15275
104,711,CVE-2017-11176,19,"static inline void set_cookie(struct sk_buff *skb, char code){	((char *)skb->data)[NOTIFY_COOKIE_LEN-1] = code;}",20560
258,80,CVE-2014-0131,19,"unsigned char *skb_pull_rcsum(struct sk_buff *skb, unsigned int len){	BUG_ON(len > skb->len);	skb->len -= len;	BUG_ON(skb->len < skb->data_len);	skb_postpull_rcsum(skb, skb->data, len);	return skb->data += len;}",12252
87,137,CVE-2016-9794,19,static int snd_interval_refine_last(struct snd_interval *i){	if (snd_BUG_ON(snd_interval_empty(i)))		return -EINVAL;	if (snd_interval_single(i))		return 0;	i->min = i->max;	i->openmin = i->openmax;	if (i->openmin)		i->min--;	return 1;},15022
109,1435,CVE-2019-11487,19,static struct inode * get_pipe_inode(void){	struct inode *inode = new_inode_pseudo(pipe_mnt->mnt_sb);	struct pipe_inode_info *pipe;	if (!inode)		goto fail_inode;	inode->i_ino = get_next_ino();	pipe = alloc_pipe_info();	if (!pipe)		goto fail_iput;	inode->i_pipe = pipe;	pipe->files = 2;	pipe->readers = pipe->writers = 1;	inode->i_fop = &pipefifo_fops;	 	inode->i_state = I_DIRTY;	inode->i_mode = S_IFIFO | S_IRUSR | S_IWUSR;	inode->i_uid = current_fsuid();	inode->i_gid = current_fsgid();	inode->i_atime = inode->i_mtime = inode->i_ctime = current_time(inode);	return inode;fail_iput:	iput(inode);fail_inode:	return NULL;},28932
149,1261,CVE-2019-9003,19,"static int i_ipmi_request(struct ipmi_user     *user,			  struct ipmi_smi      *intf,			  struct ipmi_addr     *addr,			  long                 msgid,			  struct kernel_ipmi_msg *msg,			  void                 *user_msg_data,			  void                 *supplied_smi,			  struct ipmi_recv_msg *supplied_recv,			  int                  priority,			  unsigned char        source_address,			  unsigned char        source_lun,			  int                  retries,			  unsigned int         retry_time_ms){	struct ipmi_smi_msg *smi_msg;	struct ipmi_recv_msg *recv_msg;	int rv = 0;	if (supplied_recv)		recv_msg = supplied_recv;	else {		recv_msg = ipmi_alloc_recv_msg();		if (recv_msg == NULL) {			rv = -ENOMEM;			goto out;		}	}	recv_msg->user_msg_data = user_msg_data;	if (supplied_smi)		smi_msg = (struct ipmi_smi_msg *) supplied_smi;	else {		smi_msg = ipmi_alloc_smi_msg();		if (smi_msg == NULL) {			ipmi_free_recv_msg(recv_msg);			rv = -ENOMEM;			goto out;		}	}	rcu_read_lock();	if (intf->in_shutdown) {		rv = -ENODEV;		goto out_err;	}	recv_msg->user = user;	if (user)		 		kref_get(&user->refcount);	recv_msg->msgid = msgid;	 	recv_msg->msg = *msg;	if (addr->addr_type == IPMI_SYSTEM_INTERFACE_ADDR_TYPE) {		rv = i_ipmi_req_sysintf(intf, addr, msgid, msg, smi_msg,					recv_msg, retries, retry_time_ms);	} else if (is_ipmb_addr(addr) || is_ipmb_bcast_addr(addr)) {		rv = i_ipmi_req_ipmb(intf, addr, msgid, msg, smi_msg, recv_msg,				     source_address, source_lun,				     retries, retry_time_ms);	} else if (is_lan_addr(addr)) {		rv = i_ipmi_req_lan(intf, addr, msgid, msg, smi_msg, recv_msg,				    source_lun, retries, retry_time_ms);	} else {	     		ipmi_inc_stat(intf, sent_invalid_commands);		rv = -EINVAL;	}	if (rv) {out_err:		ipmi_free_smi_msg(smi_msg);		ipmi_free_recv_msg(recv_msg);	} else {		ipmi_debug_msg(""Send"", smi_msg->data, smi_msg->data_size);		smi_send(intf, intf->handlers, smi_msg, priority);	}	rcu_read_unlock();out:	return rv;}",27238
89,275,CVE-2016-7912,19,"static void ffs_event_add(struct ffs_data *ffs,			  enum usb_functionfs_event_type type){	unsigned long flags;	spin_lock_irqsave(&ffs->ev.waitq.lock, flags);	__ffs_event_add(ffs, type);	spin_unlock_irqrestore(&ffs->ev.waitq.lock, flags);}",15709
384,222,CVE-2016-8655,19,"static int packet_direct_xmit(struct sk_buff *skb){	struct net_device *dev = skb->dev;	struct sk_buff *orig_skb = skb;	struct netdev_queue *txq;	int ret = NETDEV_TX_BUSY;	if (unlikely(!netif_running(dev) ||		     !netif_carrier_ok(dev)))		goto drop;	skb = validate_xmit_skb_list(skb, dev);	if (skb != orig_skb)		goto drop;	txq = skb_get_tx_queue(dev, skb);	local_bh_disable();	HARD_TX_LOCK(dev, txq, smp_processor_id());	if (!netif_xmit_frozen_or_drv_stopped(txq))		ret = netdev_start_xmit(skb, dev, txq, false);	HARD_TX_UNLOCK(dev, txq);	local_bh_enable();	if (!dev_xmit_complete(ret))		kfree_skb(skb);	return ret;drop:	atomic_long_inc(&dev->tx_dropped);	kfree_skb_list(skb);	return NET_XMIT_DROP;}",15504
376,1070,CVE-2017-15129,19,"static void ops_free(const struct pernet_operations *ops, struct net *net){	if (ops->id && ops->size) {		kfree(net_generic(net, *ops->id));	}}",26139
92,32,CVE-2016-9137,19,"ZEND_METHOD(CURLFile, __construct){	return_value = getThis();	curlfile_ctor(INTERNAL_FUNCTION_PARAM_PASSTHRU);}",2230
180,1134,CVE-2019-15917,19,"static int hci_uart_send_frame(struct hci_dev *hdev, struct sk_buff *skb){	struct hci_uart *hu = hci_get_drvdata(hdev);	BT_DBG(""%s: type %d len %d"", hdev->name, hci_skb_pkt_type(skb),	       skb->len);	percpu_down_read(&hu->proto_lock);	if (!test_bit(HCI_UART_PROTO_READY, &hu->flags)) {		percpu_up_read(&hu->proto_lock);		return -EUNATCH;	}	hu->proto->enqueue(hu, skb);	percpu_up_read(&hu->proto_lock);	hci_uart_tx_wakeup(hu);	return 0;}",26613
6,1329,CVE-2018-20856,19,int blk_get_queue(struct request_queue *q){	if (likely(!blk_queue_dying(q))) {		__blk_get_queue(q);		return true;	}	return false;},27478
234,913,CVE-2018-16840,19,void Curl_freeset(struct Curl_easy *data){     enum dupstring i;  for(i = (enum dupstring)0; i < STRING_LAST; i++) {    Curl_safefree(data->set.str[i]);  }  if(data->change.referer_alloc) {    Curl_safefree(data->change.referer);    data->change.referer_alloc = FALSE;  }  data->change.referer = NULL;  if(data->change.url_alloc) {    Curl_safefree(data->change.url);    data->change.url_alloc = FALSE;  }  data->change.url = NULL;  Curl_mime_cleanpart(&data->set.mimepost);},24204
319,1157,CVE-2019-12819,19,static void mdiobus_release(struct device *d){	struct mii_bus *bus = to_mii_bus(d);	BUG_ON(bus->state != MDIOBUS_RELEASED &&	        	       bus->state != MDIOBUS_ALLOCATED);	kfree(bus);},26827
78,329,CVE-2016-7910,19,"int invalidate_partition(struct gendisk *disk, int partno){	int res = 0;	struct block_device *bdev = bdget_disk(disk, partno);	if (bdev) {		fsync_bdev(bdev);		res = __invalidate_device(bdev, true);		bdput(bdev);	}	return res;}",15763
154,1346,CVE-2018-20856,19,void blk_queue_congestion_threshold(struct request_queue *q){	int nr;	nr = q->nr_requests - (q->nr_requests / 8) + 1;	if (nr > q->nr_requests)		nr = q->nr_requests;	q->nr_congestion_on = nr;	nr = q->nr_requests - (q->nr_requests / 8) - (q->nr_requests / 16) - 1;	if (nr < 1)		nr = 1;	q->nr_congestion_off = nr;},27495
327,1407,CVE-2019-11487,19,"static int fuse_ref_page(struct fuse_copy_state *cs, struct page *page,			 unsigned offset, unsigned count){	struct pipe_buffer *buf;	int err;	if (cs->nr_segs == cs->pipe->buffers)		return -EIO;	err = unlock_request(cs->req);	if (err)		return err;	fuse_copy_finish(cs);	buf = cs->pipebufs;	get_page(page);	buf->page = page;	buf->offset = offset;	buf->len = count;	cs->pipebufs++;	cs->nr_segs++;	cs->len = 0;	return 0;}",28904
263,157,CVE-2016-9576,19,"int blk_rq_unmap_user(struct bio *bio){	struct bio *mapped_bio;	int ret = 0, ret2;	while (bio) {		mapped_bio = bio;		if (unlikely(bio_flagged(bio, BIO_BOUNCED)))			mapped_bio = bio->bi_private;		ret2 = __blk_rq_unmap_user(mapped_bio);		if (ret2 && !ret)			ret = ret2;		mapped_bio = bio;		bio = bio->bi_next;		bio_put(mapped_bio);	}	return ret;}",15162
380,782,CVE-2016-10150,19,"static void hardware_enable_nolock(void *junk){	int cpu = raw_smp_processor_id();	int r;	if (cpumask_test_cpu(cpu, cpus_hardware_enabled))		return;	cpumask_set_cpu(cpu, cpus_hardware_enabled);	r = kvm_arch_hardware_enable();	if (r) {		cpumask_clear_cpu(cpu, cpus_hardware_enabled);		atomic_inc(&hardware_enable_failed);		pr_info(""kvm: enabling virtualization on CPU%d failed\n"", cpu);	}}",22498
116,1505,CVE-2019-11487,19,"static int anon_pipe_buf_steal(struct pipe_inode_info *pipe,			       struct pipe_buffer *buf){	struct page *page = buf->page;	if (page_count(page) == 1) {		if (memcg_kmem_enabled())			memcg_kmem_uncharge(page, 0);		__SetPageLocked(page);		return 0;	}	return 1;}",29002
336,1069,CVE-2017-15129,19,static void netns_put(struct ns_common *ns){	put_net(to_net_ns(ns));},26138
314,837,CVE-2014-9940,19,static int have_full_constraints(void){	return has_full_constraints || of_have_populated_dt();},22998
267,463,CVE-2015-8963,19,"static void perf_event_task(struct task_struct *task,			      struct perf_event_context *task_ctx,			      int new){	struct perf_task_event task_event;	if (!atomic_read(&nr_comm_events) &&	    !atomic_read(&nr_mmap_events) &&	    !atomic_read(&nr_task_events))		return;	task_event = (struct perf_task_event){		.task	  = task,		.task_ctx = task_ctx,		.event_id    = {			.header = {				.type = new ? PERF_RECORD_FORK : PERF_RECORD_EXIT,				.misc = 0,				.size = sizeof(task_event.event_id),			},			 			 			 			 			 		},	};	perf_event_aux(perf_event_task_output,		       &task_event,		       task_ctx);}",18371
196,642,CVE-2017-15265,19,"static int snd_seq_ioctl_query_next_client(struct snd_seq_client *client,					   void *arg){	struct snd_seq_client_info *info = arg;	struct snd_seq_client *cptr = NULL;	 	info->client++;	if (info->client < 0)		info->client = 0;	for (; info->client < SNDRV_SEQ_MAX_CLIENTS; info->client++) {		cptr = snd_seq_client_use_ptr(info->client);		if (cptr)			break;  	}	if (cptr == NULL)		return -ENOENT;	get_client_info(cptr, info);	snd_seq_client_unlock(cptr);	return 0;}",20032
98,798,CVE-2016-10150,19,"static int kvm_mmu_notifier_clear_young(struct mmu_notifier *mn,					struct mm_struct *mm,					unsigned long start,					unsigned long end){	struct kvm *kvm = mmu_notifier_to_kvm(mn);	int young, idx;	idx = srcu_read_lock(&kvm->srcu);	spin_lock(&kvm->mmu_lock);	 	young = kvm_age_hva(kvm, start, end);	spin_unlock(&kvm->mmu_lock);	srcu_read_unlock(&kvm->srcu, idx);	return young;}",22514
187,1171,CVE-2019-11811,19,static inline int disable_si_irq(struct smi_info *smi_info){	if ((smi_info->io.irq) && (!smi_info->interrupt_disabled)) {		smi_info->interrupt_disabled = true;		start_check_enables(smi_info);		return true;	}	return false;},26934
368,1163,CVE-2019-12819,19,"static inline void of_mdiobus_link_mdiodev(struct mii_bus *mdio,					   struct mdio_device *mdiodev){}",26833
330,619,CVE-2017-16527,19,static int uac2_ctl_value_size(int val_type){	switch (val_type) {	case USB_MIXER_S32:	case USB_MIXER_U32:		return 4;	case USB_MIXER_S16:	case USB_MIXER_U16:		return 2;	default:		return 1;	}	return 0;  },19878
129,583,CVE-2017-16527,19,"static int get_ctl_value(struct usb_mixer_elem_info *cval, int request,			 int validx, int *value_ret){	validx += cval->idx_off;	return (cval->head.mixer->protocol == UAC_VERSION_1) ?		get_ctl_value_v1(cval, request, validx, value_ret) :		get_ctl_value_v2(cval, request, validx, value_ret);}",19842
101,1192,CVE-2019-11811,19,"static void set_need_watch(void *send_info, int enable){	struct smi_info *smi_info = send_info;	unsigned long flags;	atomic_set(&smi_info->need_watch, enable);	spin_lock_irqsave(&smi_info->si_lock, flags);	check_start_timer_thread(smi_info);	spin_unlock_irqrestore(&smi_info->si_lock, flags);}",26955
213,827,CVE-2014-9940,19,"static void _regulator_enable_delay(unsigned int delay){	unsigned int ms = delay / 1000;	unsigned int us = delay % 1000;	if (ms > 0) {		 		if (ms < 20)			us += ms * 1000;		else			msleep(ms);	}	 	if (us >= 10)		usleep_range(us, us + 100);	else		udelay(us);}",22988
140,1360,CVE-2018-20856,19,"int blk_set_preempt_only(struct request_queue *q){	return blk_queue_flag_test_and_set(QUEUE_FLAG_PREEMPT_ONLY, q);}",27509
53,117,CVE-2016-10088,19,"bsg_validate_sgv4_hdr(struct sg_io_v4 *hdr, int *rw){	int ret = 0;	if (hdr->guard != 'Q')		return -EINVAL;	switch (hdr->protocol) {	case BSG_PROTOCOL_SCSI:		switch (hdr->subprotocol) {		case BSG_SUB_PROTOCOL_SCSI_CMD:		case BSG_SUB_PROTOCOL_SCSI_TRANSPORT:			break;		default:			ret = -EINVAL;		}		break;	default:		ret = -EINVAL;	}	*rw = hdr->dout_xfer_len ? WRITE : READ;	return ret;}",14962
179,521,CVE-2017-16939,19,"static int attach_aead(struct xfrm_state *x, struct nlattr *rta){	struct xfrm_algo_aead *p, *ualg;	struct xfrm_algo_desc *algo;	if (!rta)		return 0;	ualg = nla_data(rta);	algo = xfrm_aead_get_byname(ualg->alg_name, ualg->alg_icv_len, 1);	if (!algo)		return -ENOSYS;	x->props.ealgo = algo->desc.sadb_alg_id;	p = kmemdup(ualg, aead_len(ualg), GFP_KERNEL);	if (!p)		return -ENOMEM;	strcpy(p->alg_name, algo->name);	x->aead = p;	x->geniv = algo->uinfo.aead.geniv;	return 0;}",19614
124,293,CVE-2016-7912,19,"static struct dentry *ffs_sb_create_file(struct super_block *sb,					const char *name, void *data,					const struct file_operations *fops){	struct ffs_data	*ffs = sb->s_fs_info;	struct dentry	*dentry;	struct inode	*inode;	ENTER();	dentry = d_alloc_name(sb->s_root, name);	if (unlikely(!dentry))		return NULL;	inode = ffs_sb_make_inode(sb, data, fops, NULL, &ffs->file_perms);	if (unlikely(!inode)) {		dput(dentry);		return NULL;	}	d_add(dentry, inode);	return dentry;}",15727
71,764,CVE-2017-7185,19,"static void MD5Transform(int buf[4], int const in[16]) {  register int a, b, c, d;  a = buf[0];  b = buf[1];  c = buf[2];  d = buf[3];  MD5STEP(F1, a, b, c, d, in[0] + 0xd76aa478, 7);  MD5STEP(F1, d, a, b, c, in[1] + 0xe8c7b756, 12);  MD5STEP(F1, c, d, a, b, in[2] + 0x242070db, 17);  MD5STEP(F1, b, c, d, a, in[3] + 0xc1bdceee, 22);  MD5STEP(F1, a, b, c, d, in[4] + 0xf57c0faf, 7);  MD5STEP(F1, d, a, b, c, in[5] + 0x4787c62a, 12);  MD5STEP(F1, c, d, a, b, in[6] + 0xa8304613, 17);  MD5STEP(F1, b, c, d, a, in[7] + 0xfd469501, 22);  MD5STEP(F1, a, b, c, d, in[8] + 0x698098d8, 7);  MD5STEP(F1, d, a, b, c, in[9] + 0x8b44f7af, 12);  MD5STEP(F1, c, d, a, b, in[10] + 0xffff5bb1, 17);  MD5STEP(F1, b, c, d, a, in[11] + 0x895cd7be, 22);  MD5STEP(F1, a, b, c, d, in[12] + 0x6b901122, 7);  MD5STEP(F1, d, a, b, c, in[13] + 0xfd987193, 12);  MD5STEP(F1, c, d, a, b, in[14] + 0xa679438e, 17);  MD5STEP(F1, b, c, d, a, in[15] + 0x49b40821, 22);  MD5STEP(F2, a, b, c, d, in[1] + 0xf61e2562, 5);  MD5STEP(F2, d, a, b, c, in[6] + 0xc040b340, 9);  MD5STEP(F2, c, d, a, b, in[11] + 0x265e5a51, 14);  MD5STEP(F2, b, c, d, a, in[0] + 0xe9b6c7aa, 20);  MD5STEP(F2, a, b, c, d, in[5] + 0xd62f105d, 5);  MD5STEP(F2, d, a, b, c, in[10] + 0x02441453, 9);  MD5STEP(F2, c, d, a, b, in[15] + 0xd8a1e681, 14);  MD5STEP(F2, b, c, d, a, in[4] + 0xe7d3fbc8, 20);  MD5STEP(F2, a, b, c, d, in[9] + 0x21e1cde6, 5);  MD5STEP(F2, d, a, b, c, in[14] + 0xc33707d6, 9);  MD5STEP(F2, c, d, a, b, in[3] + 0xf4d50d87, 14);  MD5STEP(F2, b, c, d, a, in[8] + 0x455a14ed, 20);  MD5STEP(F2, a, b, c, d, in[13] + 0xa9e3e905, 5);  MD5STEP(F2, d, a, b, c, in[2] + 0xfcefa3f8, 9);  MD5STEP(F2, c, d, a, b, in[7] + 0x676f02d9, 14);  MD5STEP(F2, b, c, d, a, in[12] + 0x8d2a4c8a, 20);  MD5STEP(F3, a, b, c, d, in[5] + 0xfffa3942, 4);  MD5STEP(F3, d, a, b, c, in[8] + 0x8771f681, 11);  MD5STEP(F3, c, d, a, b, in[11] + 0x6d9d6122, 16);  MD5STEP(F3, b, c, d, a, in[14] + 0xfde5380c, 23);  MD5STEP(F3, a, b, c, d, in[1] + 0xa4beea44, 4);  MD5STEP(F3, d, a, b, c, in[4] + 0x4bdecfa9, 11);  MD5STEP(F3, c, d, a, b, in[7] + 0xf6bb4b60, 16);  MD5STEP(F3, b, c, d, a, in[10] + 0xbebfbc70, 23);  MD5STEP(F3, a, b, c, d, in[13] + 0x289b7ec6, 4);  MD5STEP(F3, d, a, b, c, in[0] + 0xeaa127fa, 11);  MD5STEP(F3, c, d, a, b, in[3] + 0xd4ef3085, 16);  MD5STEP(F3, b, c, d, a, in[6] + 0x04881d05, 23);  MD5STEP(F3, a, b, c, d, in[9] + 0xd9d4d039, 4);  MD5STEP(F3, d, a, b, c, in[12] + 0xe6db99e5, 11);  MD5STEP(F3, c, d, a, b, in[15] + 0x1fa27cf8, 16);  MD5STEP(F3, b, c, d, a, in[2] + 0xc4ac5665, 23);  MD5STEP(F4, a, b, c, d, in[0] + 0xf4292244, 6);  MD5STEP(F4, d, a, b, c, in[7] + 0x432aff97, 10);  MD5STEP(F4, c, d, a, b, in[14] + 0xab9423a7, 15);  MD5STEP(F4, b, c, d, a, in[5] + 0xfc93a039, 21);  MD5STEP(F4, a, b, c, d, in[12] + 0x655b59c3, 6);  MD5STEP(F4, d, a, b, c, in[3] + 0x8f0ccc92, 10);  MD5STEP(F4, c, d, a, b, in[10] + 0xffeff47d, 15);  MD5STEP(F4, b, c, d, a, in[1] + 0x85845dd1, 21);  MD5STEP(F4, a, b, c, d, in[8] + 0x6fa87e4f, 6);  MD5STEP(F4, d, a, b, c, in[15] + 0xfe2ce6e0, 10);  MD5STEP(F4, c, d, a, b, in[6] + 0xa3014314, 15);  MD5STEP(F4, b, c, d, a, in[13] + 0x4e0811a1, 21);  MD5STEP(F4, a, b, c, d, in[4] + 0xf7537e82, 6);  MD5STEP(F4, d, a, b, c, in[11] + 0xbd3af235, 10);  MD5STEP(F4, c, d, a, b, in[2] + 0x2ad7d2bb, 15);  MD5STEP(F4, b, c, d, a, in[9] + 0xeb86d391, 21);  buf[0] += a;  buf[1] += b;  buf[2] += c;  buf[3] += d;}",21773
348,505,CVE-2017-17052,19,"static void free_thread_stack(struct task_struct *tsk){	kmem_cache_free(thread_stack_cache, tsk->stack);}",19591
229,654,CVE-2017-15265,19,"static int snd_seq_ioctl_unsubscribe_port(struct snd_seq_client *client,					  void *arg){	struct snd_seq_port_subscribe *subs = arg;	int result = -ENXIO;	struct snd_seq_client *receiver = NULL, *sender = NULL;	struct snd_seq_client_port *sport = NULL, *dport = NULL;	if ((receiver = snd_seq_client_use_ptr(subs->dest.client)) == NULL)		goto __end;	if ((sender = snd_seq_client_use_ptr(subs->sender.client)) == NULL)		goto __end;	if ((sport = snd_seq_port_use_ptr(sender, subs->sender.port)) == NULL)		goto __end;	if ((dport = snd_seq_port_use_ptr(receiver, subs->dest.port)) == NULL)		goto __end;	result = check_subscription_permission(client, sport, dport, subs);	if (result < 0)		goto __end;	result = snd_seq_port_disconnect(client, sender, sport, receiver, dport, subs);	if (! result)  		snd_seq_client_notify_subscription(SNDRV_SEQ_ADDRESS_SUBSCRIBERS, 0,						   subs, SNDRV_SEQ_EVENT_PORT_UNSUBSCRIBED);      __end:      	if (sport)		snd_seq_port_unlock(sport);	if (dport)		snd_seq_port_unlock(dport);	if (sender)		snd_seq_client_unlock(sender);	if (receiver)		snd_seq_client_unlock(receiver);	return result;}",20044
110,1236,CVE-2019-9003,19,"static void check_msg_timeout(struct ipmi_smi *intf, struct seq_table *ent,			      struct list_head *timeouts,			      unsigned long timeout_period,			      int slot, unsigned long *flags,			      unsigned int *waiting_msgs){	struct ipmi_recv_msg *msg;	if (intf->in_shutdown)		return;	if (!ent->inuse)		return;	if (timeout_period < ent->timeout) {		ent->timeout -= timeout_period;		(*waiting_msgs)++;		return;	}	if (ent->retries_left == 0) {		 		ent->inuse = 0;		msg = ent->recv_msg;		list_add_tail(&msg->link, timeouts);		if (ent->broadcast)			ipmi_inc_stat(intf, timed_out_ipmb_broadcasts);		else if (is_lan_addr(&ent->recv_msg->addr))			ipmi_inc_stat(intf, timed_out_lan_commands);		else			ipmi_inc_stat(intf, timed_out_ipmb_commands);	} else {		struct ipmi_smi_msg *smi_msg;		 		(*waiting_msgs)++;		 		ent->timeout = MAX_MSG_TIMEOUT;		ent->retries_left--;		smi_msg = smi_from_recv_msg(intf, ent->recv_msg, slot,					    ent->seqid);		if (!smi_msg) {			if (is_lan_addr(&ent->recv_msg->addr))				ipmi_inc_stat(intf,					      dropped_rexmit_lan_commands);			else				ipmi_inc_stat(intf,					      dropped_rexmit_ipmb_commands);			return;		}		spin_unlock_irqrestore(&intf->seq_lock, *flags);		 		if (intf->handlers) {			if (is_lan_addr(&ent->recv_msg->addr))				ipmi_inc_stat(intf,					      retransmitted_lan_commands);			else				ipmi_inc_stat(intf,					      retransmitted_ipmb_commands);			smi_send(intf, intf->handlers, smi_msg, 0);		} else			ipmi_free_smi_msg(smi_msg);		spin_lock_irqsave(&intf->seq_lock, *flags);	}}",27213
285,656,CVE-2017-15265,19,"static int snd_seq_open(struct inode *inode, struct file *file){	int c, mode;			 	struct snd_seq_client *client;	struct snd_seq_user_client *user;	int err;	err = nonseekable_open(inode, file);	if (err < 0)		return err;	if (mutex_lock_interruptible(&register_mutex))		return -ERESTARTSYS;	client = seq_create_client1(-1, SNDRV_SEQ_DEFAULT_EVENTS);	if (client == NULL) {		mutex_unlock(&register_mutex);		return -ENOMEM;	 	}	mode = snd_seq_file_flags(file);	if (mode & SNDRV_SEQ_LFLG_INPUT)		client->accept_input = 1;	if (mode & SNDRV_SEQ_LFLG_OUTPUT)		client->accept_output = 1;	user = &client->data.user;	user->fifo = NULL;	user->fifo_pool_size = 0;	if (mode & SNDRV_SEQ_LFLG_INPUT) {		user->fifo_pool_size = SNDRV_SEQ_DEFAULT_CLIENT_EVENTS;		user->fifo = snd_seq_fifo_new(user->fifo_pool_size);		if (user->fifo == NULL) {			seq_free_client1(client);			kfree(client);			mutex_unlock(&register_mutex);			return -ENOMEM;		}	}	usage_alloc(&client_usage, 1);	client->type = USER_CLIENT;	mutex_unlock(&register_mutex);	c = client->number;	file->private_data = client;	 	user->file = file;	sprintf(client->name, ""Client-%d"", c);	client->data.user.owner = get_pid(task_pid(current));	 	snd_seq_system_client_ev_client_start(c);	return 0;}",20046
356,261,CVE-2016-7912,19,"static void ffs_data_opened(struct ffs_data *ffs){	ENTER();	atomic_inc(&ffs->ref);	if (atomic_add_return(1, &ffs->opened) == 1 &&			ffs->state == FFS_DEACTIVATED) {		ffs->state = FFS_CLOSING;		ffs_data_reset(ffs);	}}",15695
182,732,CVE-2017-10661,19,"static int do_timerfd_settime(int ufd, int flags, 		const struct itimerspec *new,		struct itimerspec *old){	struct fd f;	struct timerfd_ctx *ctx;	int ret;	if ((flags & ~TFD_SETTIME_FLAGS) ||	    !timespec_valid(&new->it_value) ||	    !timespec_valid(&new->it_interval))		return -EINVAL;	ret = timerfd_fget(ufd, &f);	if (ret)		return ret;	ctx = f.file->private_data;	if (!capable(CAP_WAKE_ALARM) && isalarm(ctx)) {		fdput(f);		return -EPERM;	}	timerfd_setup_cancel(ctx, flags);	 	for (;;) {		spin_lock_irq(&ctx->wqh.lock);		if (isalarm(ctx)) {			if (alarm_try_to_cancel(&ctx->t.alarm) >= 0)				break;		} else {			if (hrtimer_try_to_cancel(&ctx->t.tmr) >= 0)				break;		}		spin_unlock_irq(&ctx->wqh.lock);		cpu_relax();	}	 	if (ctx->expired && ctx->tintv) {		if (isalarm(ctx))			alarm_forward_now(&ctx->t.alarm, ctx->tintv);		else			hrtimer_forward_now(&ctx->t.tmr, ctx->tintv);	}	old->it_value = ktime_to_timespec(timerfd_get_remaining(ctx));	old->it_interval = ktime_to_timespec(ctx->tintv);	 	ret = timerfd_setup(ctx, flags, new);	spin_unlock_irq(&ctx->wqh.lock);	fdput(f);	return ret;}",20654
58,31,CVE-2016-9137,19,"PHP_FUNCTION(curl_file_create){    object_init_ex( return_value, curl_CURLFile_class );    curlfile_ctor(INTERNAL_FUNCTION_PARAM_PASSTHRU);}",2229
315,245,CVE-2016-7913,19,"static void free_firmware(struct xc2028_data *priv){	int i;	tuner_dbg(""%s called\n"", __func__);	if (!priv->firm)		return;	for (i = 0; i < priv->firm_size; i++)		kfree(priv->firm[i].ptr);	kfree(priv->firm);	priv->firm = NULL;	priv->firm_size = 0;	priv->state = XC2028_NO_FIRMWARE;	memset(&priv->cur_fw, 0, sizeof(priv->cur_fw));}",15679
372,204,CVE-2016-8655,19,"static int __tpacket_v3_has_room(struct packet_sock *po, int pow_off){	int idx, len;	len = po->rx_ring.prb_bdqc.knum_blocks;	idx = po->rx_ring.prb_bdqc.kactive_blk_num;	if (pow_off)		idx += len >> pow_off;	if (idx >= len)		idx -= len;	return prb_lookup_block(po, &po->rx_ring, idx, TP_STATUS_KERNEL);}",15486
111,915,CVE-2018-16840,19,"int Curl_removeHandleFromPipeline(struct Curl_easy *handle,                                  struct curl_llist *pipeline){  if(pipeline) {    struct curl_llist_element *curr;    curr = pipeline->head;    while(curr) {      if(curr->ptr == handle) {        Curl_llist_remove(pipeline, curr, NULL);        return 1;        }      curr = curr->next;    }  }  return 0;}",24206
253,125,CVE-2016-9794,19,"static int pcm_chmap_ctl_info(struct snd_kcontrol *kcontrol,			      struct snd_ctl_elem_info *uinfo){	struct snd_pcm_chmap *info = snd_kcontrol_chip(kcontrol);	uinfo->type = SNDRV_CTL_ELEM_TYPE_INTEGER;	uinfo->count = 0;	uinfo->count = info->max_channels;	uinfo->value.integer.min = 0;	uinfo->value.integer.max = SNDRV_CHMAP_LAST;	return 0;}",15010
131,736,CVE-2017-10661,19,"static int timerfd_release(struct inode *inode, struct file *file){	struct timerfd_ctx *ctx = file->private_data;	timerfd_remove_cancel(ctx);	if (isalarm(ctx))		alarm_cancel(&ctx->t.alarm);	else		hrtimer_cancel(&ctx->t.tmr);	kfree_rcu(ctx, rcu);	return 0;}",20658
307,1358,CVE-2018-20856,19,"void blk_run_queue(struct request_queue *q){	unsigned long flags;	WARN_ON_ONCE(q->mq_ops);	spin_lock_irqsave(q->queue_lock, flags);	__blk_run_queue(q);	spin_unlock_irqrestore(q->queue_lock, flags);}",27507
188,643,CVE-2017-15265,19,"static int snd_seq_ioctl_query_next_port(struct snd_seq_client *client,					 void *arg){	struct snd_seq_port_info *info = arg;	struct snd_seq_client *cptr;	struct snd_seq_client_port *port = NULL;	cptr = snd_seq_client_use_ptr(info->addr.client);	if (cptr == NULL)		return -ENXIO;	 	info->addr.port++;	port = snd_seq_port_query_nearest(cptr, info);	if (port == NULL) {		snd_seq_client_unlock(cptr);		return -ENOENT;	}	 	info->addr = port->addr;	snd_seq_get_port_info(port, info);	snd_seq_port_unlock(port);	snd_seq_client_unlock(cptr);	return 0;}",20033
367,24,CVE-2016-6295,19," PHP_METHOD(snmp, set) {	php_snmp(INTERNAL_FUNCTION_PARAM_PASSTHRU, SNMP_CMD_SET, (-1));}",1678
4,1206,CVE-2019-11811,19,"static void start_getting_msg_queue(struct smi_info *smi_info){	smi_info->curr_msg->data[0] = (IPMI_NETFN_APP_REQUEST << 2);	smi_info->curr_msg->data[1] = IPMI_GET_MSG_CMD;	smi_info->curr_msg->data_size = 2;	start_new_msg(smi_info, smi_info->curr_msg->data,		      smi_info->curr_msg->data_size);	smi_info->si_state = SI_GETTING_MESSAGES;}",26969
211,22,CVE-2016-6295,19,"PHP_METHOD(snmp, getnext){	php_snmp(INTERNAL_FUNCTION_PARAM_PASSTHRU, SNMP_CMD_GETNEXT, (-1));}",1676
173,357,CVE-2016-4805,19,"ppp_get_stats(struct ppp *ppp, struct ppp_stats *st){	struct slcompress *vj = ppp->vj;	memset(st, 0, sizeof(*st));	st->p.ppp_ipackets = ppp->stats64.rx_packets;	st->p.ppp_ierrors = ppp->dev->stats.rx_errors;	st->p.ppp_ibytes = ppp->stats64.rx_bytes;	st->p.ppp_opackets = ppp->stats64.tx_packets;	st->p.ppp_oerrors = ppp->dev->stats.tx_errors;	st->p.ppp_obytes = ppp->stats64.tx_bytes;	if (!vj)		return;	st->vj.vjs_packets = vj->sls_o_compressed + vj->sls_o_uncompressed;	st->vj.vjs_compressed = vj->sls_o_compressed;	st->vj.vjs_searches = vj->sls_o_searches;	st->vj.vjs_misses = vj->sls_o_misses;	st->vj.vjs_errorin = vj->sls_i_error;	st->vj.vjs_tossed = vj->sls_i_tossed;	st->vj.vjs_uncompressedin = vj->sls_i_uncompressed;	st->vj.vjs_compressedin = vj->sls_i_compressed;}",16664
108,714,CVE-2017-10966,19,"char *convert_home(const char *path){	const char *home;	if (*path == '~' && (*(path+1) == '/' || *(path+1) == '\0')) {		home = g_get_home_dir();		if (home == NULL)			home = ""."";		return g_strconcat(home, path+1, NULL);	} else {		return g_strdup(path);	}}",20563
237,1218,CVE-2019-11811,19,"static void intf_mem_outl(const struct si_sm_io *io, unsigned int offset,			  unsigned char b){	writel(b << io->regshift, (io->addr)+(offset * io->regspacing));}",26981
279,1154,CVE-2019-12819,19,"int mdiobus_is_registered_device(struct mii_bus *bus, int addr){	return bus->mdio_map[addr];}",26824
163,884,CVE-2014-9940,19,"int regulator_register_notifier(struct regulator *regulator,			      struct notifier_block *nb){	return blocking_notifier_chain_register(&regulator->rdev->notifier,						nb);}",23045
305,145,CVE-2016-9794,19,"static int snd_pcm_hw_rule_ranges(struct snd_pcm_hw_params *params,				  struct snd_pcm_hw_rule *rule){	struct snd_pcm_hw_constraint_ranges *r = rule->private;	return snd_interval_ranges(hw_param_interval(params, rule->var),				   r->count, r->ranges, r->mask);}",15030
243,715,CVE-2017-10966,19,"int dec2octal(int decimal){	int octal, pos;	octal = 0; pos = 0;	while (decimal > 0) {		octal += (decimal & 7)*(pos == 0 ? 1 : pos);		decimal /= 8;		pos += 10;	}	return octal;}",20564
146,345,CVE-2016-4805,19,"ppp_ccp_peek(struct ppp *ppp, struct sk_buff *skb, int inbound){	unsigned char *dp;	int len;	if (!pskb_may_pull(skb, CCP_HDRLEN + 2))		return;	 	dp = skb->data + 2;	switch (CCP_CODE(dp)) {	case CCP_CONFREQ:		 		if(inbound)			 			ppp->xstate &= ~SC_COMP_RUN;		else			 			ppp->rstate &= ~SC_DECOMP_RUN;		break;	case CCP_TERMREQ:	case CCP_TERMACK:		 		ppp->rstate &= ~SC_DECOMP_RUN;		ppp->xstate &= ~SC_COMP_RUN;		break;	case CCP_CONFACK:		if ((ppp->flags & (SC_CCP_OPEN | SC_CCP_UP)) != SC_CCP_OPEN)			break;		len = CCP_LENGTH(dp);		if (!pskb_may_pull(skb, len + 2))			return;		 		dp += CCP_HDRLEN;		len -= CCP_HDRLEN;		if (len < CCP_OPT_MINLEN || len < CCP_OPT_LENGTH(dp))			break;		if (inbound) {			 			if (!ppp->rc_state)				break;			if (ppp->rcomp->decomp_init(ppp->rc_state, dp, len,					ppp->file.index, 0, ppp->mru, ppp->debug)) {				ppp->rstate |= SC_DECOMP_RUN;				ppp->rstate &= ~(SC_DC_ERROR | SC_DC_FERROR);			}		} else {			 			if (!ppp->xc_state)				break;			if (ppp->xcomp->comp_init(ppp->xc_state, dp, len,					ppp->file.index, 0, ppp->debug))				ppp->xstate |= SC_COMP_RUN;		}		break;	case CCP_RESETACK:		 		if ((ppp->flags & SC_CCP_UP) == 0)			break;		if (inbound) {			if (ppp->rc_state && (ppp->rstate & SC_DECOMP_RUN)) {				ppp->rcomp->decomp_reset(ppp->rc_state);				ppp->rstate &= ~SC_DC_ERROR;			}		} else {			if (ppp->xc_state && (ppp->xstate & SC_COMP_RUN))				ppp->xcomp->comp_reset(ppp->xc_state);		}		break;	}}",16652
251,1498,CVE-2019-11487,19,unsigned long vma_kernel_pagesize(struct vm_area_struct *vma){	if (vma->vm_ops && vma->vm_ops->pagesize)		return vma->vm_ops->pagesize(vma);	return PAGE_SIZE;},28995
324,1279,CVE-2019-9003,19,"int ipmi_get_my_address(struct ipmi_user *user,			unsigned int  channel,			unsigned char *address){	int index, rv = 0;	user = acquire_ipmi_user(user, &index);	if (!user)		return -ENODEV;	if (channel >= IPMI_MAX_CHANNELS) {		rv = -EINVAL;	} else {		channel = array_index_nospec(channel, IPMI_MAX_CHANNELS);		*address = user->intf->addrinfo[channel].address;	}	release_ipmi_user(user, index);	return rv;}",27256
25,948,CVE-2018-5873,19,struct file *proc_ns_fget(int fd){	struct file *file;	file = fget(fd);	if (!file)		return ERR_PTR(-EBADF);	if (file->f_op != &ns_file_operations)		goto out_invalid;	return file;out_invalid:	fput(file);	return ERR_PTR(-EINVAL);},25495
209,631,CVE-2017-15265,19,"static int snd_seq_ioctl_delete_queue(struct snd_seq_client *client, void *arg){	struct snd_seq_queue_info *info = arg;	return snd_seq_queue_delete(client->number, info->queue);}",20021
309,538,CVE-2017-16939,19,"static int xfrm_add_sa(struct sk_buff *skb, struct nlmsghdr *nlh,		struct nlattr **attrs){	struct net *net = sock_net(skb->sk);	struct xfrm_usersa_info *p = nlmsg_data(nlh);	struct xfrm_state *x;	int err;	struct km_event c;	err = verify_newsa_info(p, attrs);	if (err)		return err;	x = xfrm_state_construct(net, p, attrs, &err);	if (!x)		return err;	xfrm_state_hold(x);	if (nlh->nlmsg_type == XFRM_MSG_NEWSA)		err = xfrm_state_add(x);	else		err = xfrm_state_update(x);	xfrm_audit_state_add(x, err ? 0 : 1, true);	if (err < 0) {		x->km.state = XFRM_STATE_DEAD;		xfrm_dev_state_delete(x);		__xfrm_state_put(x);		goto out;	}	c.seq = nlh->nlmsg_seq;	c.portid = nlh->nlmsg_pid;	c.event = nlh->nlmsg_type;	km_state_notify(x, &c);out:	xfrm_state_put(x);	return err;}",19631
215,1168,CVE-2019-11811,19,"void debug_timestamp(char *msg){	struct timespec64 t;	ktime_get_ts64(&t);	pr_debug(""**%s: %lld.%9.9ld\n"", msg, (long long) t.tv_sec, t.tv_nsec);}",26931
68,419,CVE-2015-8963,19,"static int __perf_event_enable(void *info){	struct perf_event *event = info;	struct perf_event_context *ctx = event->ctx;	struct perf_event *leader = event->group_leader;	struct perf_cpu_context *cpuctx = __get_cpu_context(ctx);	int err;	 	if (!ctx->is_active)		return -EINVAL;	raw_spin_lock(&ctx->lock);	update_context_time(ctx);	if (event->state >= PERF_EVENT_STATE_INACTIVE)		goto unlock;	 	perf_cgroup_set_timestamp(current, ctx);	__perf_event_mark_enabled(event);	if (!event_filter_match(event)) {		if (is_cgroup_event(event))			perf_cgroup_defer_enabled(event);		goto unlock;	}	 	if (leader != event && leader->state != PERF_EVENT_STATE_ACTIVE)		goto unlock;	if (!group_can_go_on(event, cpuctx, 1)) {		err = -EEXIST;	} else {		if (event == leader)			err = group_sched_in(event, cpuctx, ctx);		else			err = event_sched_in(event, cpuctx, ctx);	}	if (err) {		 		if (leader != event) {			group_sched_out(leader, cpuctx, ctx);			perf_mux_hrtimer_restart(cpuctx);		}		if (leader->attr.pinned) {			update_group_times(leader);			leader->state = PERF_EVENT_STATE_ERROR;		}	}unlock:	raw_spin_unlock(&ctx->lock);	return 0;}",18327
201,1448,CVE-2019-11487,19,"static void splice_from_pipe_end(struct pipe_inode_info *pipe, struct splice_desc *sd){	if (sd->need_wakeup)		wakeup_pipe_writers(pipe);}",28945
132,1176,CVE-2019-11811,19,"void ipmi_irq_finish_setup(struct si_sm_io *io){	if (io->si_type == SI_BT)		 		io->outputb(io, IPMI_BT_INTMASK_REG,			    IPMI_BT_INTMASK_ENABLE_IRQ_BIT);}",26939
5,779,CVE-2016-10150,19,"static int get_user_page_nowait(unsigned long start, int write,		struct page **page){	int flags = FOLL_NOWAIT | FOLL_HWPOISON;	if (write)		flags |= FOLL_WRITE;	return get_user_pages(start, 1, flags, page, NULL);}",22495
153,510,CVE-2017-17052,19,"init_task_pid(struct task_struct *task, enum pid_type type, struct pid *pid){	 task->pids[type].pid = pid;}",19596
193,685,CVE-2017-15115,19,"struct sk_buff *sctp_skb_recv_datagram(struct sock *sk, int flags,				       int noblock, int *err){	int error;	struct sk_buff *skb;	long timeo;	timeo = sock_rcvtimeo(sk, noblock);	pr_debug(""%s: timeo:%ld, max:%ld\n"", __func__, timeo,		 MAX_SCHEDULE_TIMEOUT);	do {		 		if (flags & MSG_PEEK) {			skb = skb_peek(&sk->sk_receive_queue);			if (skb)				refcount_inc(&skb->users);		} else {			skb = __skb_dequeue(&sk->sk_receive_queue);		}		if (skb)			return skb;		 		error = sock_error(sk);		if (error)			goto no_packet;		if (sk->sk_shutdown & RCV_SHUTDOWN)			break;		if (sk_can_busy_loop(sk)) {			sk_busy_loop(sk, noblock);			if (!skb_queue_empty(&sk->sk_receive_queue))				continue;		}		 		error = -EAGAIN;		if (!timeo)			goto no_packet;	} while (sctp_wait_for_packet(sk, err, &timeo) == 0);	return NULL;no_packet:	*err = error;	return NULL;}",20081
40,968,CVE-2018-5344,19,"static int loop_prepare_queue(struct loop_device *lo){	kthread_init_worker(&lo->worker);	lo->worker_task = kthread_run(loop_kthread_worker_fn,			&lo->worker, ""loop%d"", lo->lo_number);	if (IS_ERR(lo->worker_task))		return -ENOMEM;	set_user_nice(lo->worker_task, MIN_NICE);	return 0;}",25515
119,1318,CVE-2018-20856,19,"int bio_attempt_front_merge(struct request_queue *q, struct request *req,			     struct bio *bio){	const int ff = bio->bi_opf & REQ_FAILFAST_MASK;	if (!ll_front_merge_fn(q, req, bio))		return false;	trace_block_bio_frontmerge(q, req, bio);	if ((req->cmd_flags & REQ_FAILFAST_MASK) != ff)		blk_rq_set_mixed_merge(req);	bio->bi_next = req->bio;	req->bio = bio;	req->__sector = bio->bi_iter.bi_sector;	req->__data_len += bio->bi_iter.bi_size;	req->ioprio = ioprio_best(req->ioprio, bio_prio(bio));	blk_account_io_start(req, false);	return true;}",27467
74,519,CVE-2017-17052,19,void set_task_stack_end_magic(struct task_struct *tsk){	unsigned long *stackend;	stackend = end_of_stack(tsk);	*stackend = STACK_END_MAGIC;	 },19605
22,1253,CVE-2019-9003,19,"static int handle_ipmb_get_msg_rsp(struct ipmi_smi *intf,				   struct ipmi_smi_msg *msg){	struct ipmi_ipmb_addr ipmb_addr;	struct ipmi_recv_msg  *recv_msg;	 	if (msg->rsp_size < 11) {		 		ipmi_inc_stat(intf, invalid_ipmb_responses);		return 0;	}	if (msg->rsp[2] != 0) {		 		return 0;	}	ipmb_addr.addr_type = IPMI_IPMB_ADDR_TYPE;	ipmb_addr.slave_addr = msg->rsp[6];	ipmb_addr.channel = msg->rsp[3] & 0x0f;	ipmb_addr.lun = msg->rsp[7] & 3;	 	if (intf_find_seq(intf,			  msg->rsp[7] >> 2,			  msg->rsp[3] & 0x0f,			  msg->rsp[8],			  (msg->rsp[4] >> 2) & (~1),			  (struct ipmi_addr *) &ipmb_addr,			  &recv_msg)) {		 		ipmi_inc_stat(intf, unhandled_ipmb_responses);		return 0;	}	memcpy(recv_msg->msg_data, &msg->rsp[9], msg->rsp_size - 9);	 	recv_msg->msg.netfn = msg->rsp[4] >> 2;	recv_msg->msg.data = recv_msg->msg_data;	recv_msg->msg.data_len = msg->rsp_size - 10;	recv_msg->recv_type = IPMI_RESPONSE_RECV_TYPE;	if (deliver_response(intf, recv_msg))		ipmi_inc_stat(intf, unhandled_ipmb_responses);	else		ipmi_inc_stat(intf, handled_ipmb_responses);	return 0;}",27230
19,530,CVE-2017-16939,19,"static int dump_one_policy(struct xfrm_policy *xp, int dir, int count, void *ptr){	struct xfrm_dump_info *sp = ptr;	struct xfrm_userpolicy_info *p;	struct sk_buff *in_skb = sp->in_skb;	struct sk_buff *skb = sp->out_skb;	struct nlmsghdr *nlh;	int err;	nlh = nlmsg_put(skb, NETLINK_CB(in_skb).portid, sp->nlmsg_seq,			XFRM_MSG_NEWPOLICY, sizeof(*p), sp->nlmsg_flags);	if (nlh == NULL)		return -EMSGSIZE;	p = nlmsg_data(nlh);	copy_to_user_policy(xp, p, dir);	err = copy_to_user_tmpl(xp, skb);	if (!err)		err = copy_to_user_sec_ctx(xp, skb);	if (!err)		err = copy_to_user_policy_type(xp->type, skb);	if (!err)		err = xfrm_mark_put(skb, &xp->mark);	if (err) {		nlmsg_cancel(skb, nlh);		return err;	}	nlmsg_end(skb, nlh);	return 0;}",19623
59,925,CVE-2018-16840,19,"static void llist_dtor(void *user, void *element){  (void)user;  (void)element;   }",24216
311,191,CVE-2016-9120,19,"static int ion_release(struct inode *inode, struct file *file){	struct ion_client *client = file->private_data;	pr_debug(""%s: %d\n"", __func__, __LINE__);	ion_client_destroy(client);	return 0;}",15277
286,260,CVE-2016-7912,19,"static struct ffs_data *ffs_data_new(void){	struct ffs_data *ffs = kzalloc(sizeof *ffs, GFP_KERNEL);	if (unlikely(!ffs))		return NULL;	ENTER();	atomic_set(&ffs->ref, 1);	atomic_set(&ffs->opened, 0);	ffs->state = FFS_READ_DESCRIPTORS;	mutex_init(&ffs->mutex);	spin_lock_init(&ffs->eps_lock);	init_waitqueue_head(&ffs->ev.waitq);	init_completion(&ffs->ep0req_completion);	 	ffs->ev.can_stall = 1;	return ffs;}",15694
170,1542,CVE-2018-6031,19,"int CheckIfEditableFormTextArea(int flags, int form_type) {  if (!!(flags & FPDF_FORMFLAG_READONLY))    return false;  if (form_type == FPDF_FORMFIELD_TEXTFIELD)    return true;  if (form_type == FPDF_FORMFIELD_COMBOBOX &&      (!!(flags & FPDF_FORMFLAG_CHOICE_EDIT))) {    return true;  }  return false;}",30066
115,1081,CVE-2017-15129,19,"static int rtnl_net_getid(struct sk_buff *skb, struct nlmsghdr *nlh,			  struct netlink_ext_ack *extack){	struct net *net = sock_net(skb->sk);	struct nlattr *tb[NETNSA_MAX + 1];	struct nlattr *nla;	struct sk_buff *msg;	struct net *peer;	int err, id;	err = nlmsg_parse(nlh, sizeof(struct rtgenmsg), tb, NETNSA_MAX,			  rtnl_net_policy, extack);	if (err < 0)		return err;	if (tb[NETNSA_PID]) {		peer = get_net_ns_by_pid(nla_get_u32(tb[NETNSA_PID]));		nla = tb[NETNSA_PID];	} else if (tb[NETNSA_FD]) {		peer = get_net_ns_by_fd(nla_get_u32(tb[NETNSA_FD]));		nla = tb[NETNSA_FD];	} else {		NL_SET_ERR_MSG(extack, ""Peer netns reference is missing"");		return -EINVAL;	}	if (IS_ERR(peer)) {		NL_SET_BAD_ATTR(extack, nla);		NL_SET_ERR_MSG(extack, ""Peer netns reference is invalid"");		return PTR_ERR(peer);	}	msg = nlmsg_new(rtnl_net_get_size(), GFP_KERNEL);	if (!msg) {		err = -ENOMEM;		goto out;	}	id = peernet2id(net, peer);	err = rtnl_net_fill(msg, NETLINK_CB(skb).portid, nlh->nlmsg_seq, 0,			    RTM_NEWNSID, net, id);	if (err < 0)		goto err_out;	err = rtnl_unicast(msg, net, NETLINK_CB(skb).portid);	goto out;err_out:	nlmsg_free(msg);out:	put_net(peer);	return err;}",26150
303,428,CVE-2015-8963,19,"static int cpu_clock_event_add(struct perf_event *event, int flags){	if (flags & PERF_EF_START)		cpu_clock_event_start(event, flags);	perf_event_update_userpage(event);	return 0;}",18336
44,1500,CVE-2019-11487,19,"long get_user_pages_longterm(unsigned long start, unsigned long nr_pages,		unsigned int gup_flags, struct page **pages,		struct vm_area_struct **vmas_arg){	struct vm_area_struct **vmas = vmas_arg;	struct vm_area_struct *vma_prev = NULL;	long rc, i;	if (!pages)		return -EINVAL;	if (!vmas) {		vmas = kcalloc(nr_pages, sizeof(struct vm_area_struct *),			       GFP_KERNEL);		if (!vmas)			return -ENOMEM;	}	rc = get_user_pages(start, nr_pages, gup_flags, pages, vmas);	for (i = 0; i < rc; i++) {		struct vm_area_struct *vma = vmas[i];		if (vma == vma_prev)			continue;		vma_prev = vma;		if (vma_is_fsdax(vma))			break;	}	 	if (i >= rc)		goto out;	for (i = 0; i < rc; i++)		put_page(pages[i]);	rc = -EOPNOTSUPP;out:	if (vmas != vmas_arg)		kfree(vmas);	return rc;}",28997
231,945,CVE-2018-5873,19,static void nsfs_evict(struct inode *inode){	struct ns_common *ns = inode->i_private;	clear_inode(inode);	ns->ops->put(ns);},25492
31,359,CVE-2016-4805,19,"ppp_input(struct ppp_channel *chan, struct sk_buff *skb){	struct channel *pch = chan->ppp;	int proto;	if (!pch) {		kfree_skb(skb);		return;	}	read_lock_bh(&pch->upl);	if (!pskb_may_pull(skb, 2)) {		kfree_skb(skb);		if (pch->ppp) {			++pch->ppp->dev->stats.rx_length_errors;			ppp_receive_error(pch->ppp);		}		goto done;	}	proto = PPP_PROTO(skb);	if (!pch->ppp || proto >= 0xc000 || proto == PPP_CCPFRAG) {		 		skb_queue_tail(&pch->file.rq, skb);		 		while (pch->file.rq.qlen > PPP_MAX_RQLEN &&		       (skb = skb_dequeue(&pch->file.rq)))			kfree_skb(skb);		wake_up_interruptible(&pch->file.rwait);	} else {		ppp_do_recv(pch->ppp, skb, pch);	}done:	read_unlock_bh(&pch->upl);}",16666
332,1087,CVE-2017-15126,19,"static void __wake_userfault(struct userfaultfd_ctx *ctx,			     struct userfaultfd_wake_range *range){	spin_lock(&ctx->fault_pending_wqh.lock);	 	if (waitqueue_active(&ctx->fault_pending_wqh))		__wake_up_locked_key(&ctx->fault_pending_wqh, TASK_NORMAL,				     range);	if (waitqueue_active(&ctx->fault_wqh))		__wake_up_locked_key(&ctx->fault_wqh, TASK_NORMAL, range);	spin_unlock(&ctx->fault_pending_wqh.lock);}",26218
43,1492,CVE-2019-11487,19,"int dissolve_free_huge_page(struct page *page){	int rc = -EBUSY;	spin_lock(&hugetlb_lock);	if (PageHuge(page) && !page_count(page)) {		struct page *head = compound_head(page);		struct hstate *h = page_hstate(head);		int nid = page_to_nid(head);		if (h->free_huge_pages - h->resv_huge_pages == 0)			goto out;		 		if (PageHWPoison(head) && page != head) {			SetPageHWPoison(page);			ClearPageHWPoison(head);		}		list_del(&head->lru);		h->free_huge_pages--;		h->free_huge_pages_node[nid]--;		h->max_huge_pages--;		update_and_free_page(h, head);		rc = 0;	}out:	spin_unlock(&hugetlb_lock);	return rc;}",28989
85,321,CVE-2016-7910,19,"struct hd_struct *disk_part_iter_next(struct disk_part_iter *piter){	struct disk_part_tbl *ptbl;	int inc, end;	 	disk_put_part(piter->part);	piter->part = NULL;	 	rcu_read_lock();	ptbl = rcu_dereference(piter->disk->part_tbl);	 	if (piter->flags & DISK_PITER_REVERSE) {		inc = -1;		if (piter->flags & (DISK_PITER_INCL_PART0 |				    DISK_PITER_INCL_EMPTY_PART0))			end = -1;		else			end = 0;	} else {		inc = 1;		end = ptbl->len;	}	 	for (; piter->idx != end; piter->idx += inc) {		struct hd_struct *part;		part = rcu_dereference(ptbl->part[piter->idx]);		if (!part)			continue;		if (!part_nr_sects_read(part) &&		    !(piter->flags & DISK_PITER_INCL_EMPTY) &&		    !(piter->flags & DISK_PITER_INCL_EMPTY_PART0 &&		      piter->idx == 0))			continue;		get_device(part_to_dev(part));		piter->part = part;		piter->idx += inc;		break;	}	rcu_read_unlock();	return piter->part;}",15755
105,1443,CVE-2019-11487,19,static int too_many_pipe_buffers_hard(unsigned long user_bufs){	unsigned long hard_limit = READ_ONCE(pipe_user_pages_hard);	return hard_limit && user_bufs > hard_limit;},28940
134,1038,CVE-2017-18202,19,static inline int is_memcg_oom(struct oom_control *oc){	return oc->memcg != NULL;},26016
349,1026,CVE-2017-18218,19,"static int hns_nic_uc_unsync(struct net_device *netdev,			     const unsigned char *addr){	struct hns_nic_priv *priv = netdev_priv(netdev);	struct hnae_handle *h = priv->ae_handle;	if (h->dev->ops->rm_uc_addr)		return h->dev->ops->rm_uc_addr(h, addr);	return 0;}",25876
278,1377,CVE-2018-20856,19,"static int should_fail_request(struct hd_struct *part, unsigned int bytes){	return part->make_it_fail && should_fail(&fail_make_request, bytes);}",27526
304,1338,CVE-2018-20856,19,"void blk_post_runtime_resume(struct request_queue *q, int err){	if (!q->dev)		return;	spin_lock_irq(q->queue_lock);	if (!err) {		q->rpm_status = RPM_ACTIVE;		__blk_run_queue(q);		pm_runtime_mark_last_busy(q->dev);		pm_request_autosuspend(q->dev);	} else {		q->rpm_status = RPM_SUSPENDED;	}	spin_unlock_irq(q->queue_lock);}",27487
177,964,CVE-2018-5344,19,"static int loop_init_request(struct blk_mq_tag_set *set, struct request *rq,		unsigned int hctx_idx, unsigned int numa_node){	struct loop_cmd *cmd = blk_mq_rq_to_pdu(rq);	cmd->rq = rq;	kthread_init_work(&cmd->work, loop_queue_work);	return 0;}",25511
120,322,CVE-2016-7910,19,"static void disk_release(struct device *dev){	struct gendisk *disk = dev_to_disk(dev);	blk_free_devt(dev->devt);	disk_release_events(disk);	kfree(disk->random);	disk_replace_part_tbl(disk, NULL);	hd_free_part(&disk->part0);	if (disk->queue)		blk_put_queue(disk->queue);	kfree(disk);}",15756
200,1092,CVE-2017-15126,19,"static inline int userfaultfd_must_wait(struct userfaultfd_ctx *ctx,					 unsigned long address,					 unsigned long flags,					 unsigned long reason){	struct mm_struct *mm = ctx->mm;	pgd_t *pgd;	p4d_t *p4d;	pud_t *pud;	pmd_t *pmd, _pmd;	pte_t *pte;	int ret = true;	VM_BUG_ON(!rwsem_is_locked(&mm->mmap_sem));	pgd = pgd_offset(mm, address);	if (!pgd_present(*pgd))		goto out;	p4d = p4d_offset(pgd, address);	if (!p4d_present(*p4d))		goto out;	pud = pud_offset(p4d, address);	if (!pud_present(*pud))		goto out;	pmd = pmd_offset(pud, address);	 	_pmd = READ_ONCE(*pmd);	if (!pmd_present(_pmd))		goto out;	ret = false;	if (pmd_trans_huge(_pmd))		goto out;	 	pte = pte_offset_map(pmd, address);	 	if (pte_none(*pte))		ret = true;	pte_unmap(pte);out:	return ret;}",26223
81,1398,CVE-2019-11487,19,"static int fuse_device_clone(struct fuse_conn *fc, struct file *new){	struct fuse_dev *fud;	if (new->private_data)		return -EINVAL;	fud = fuse_dev_alloc(fc);	if (!fud)		return -ENOMEM;	new->private_data = fud;	atomic_inc(&fc->dev_count);	return 0;}",28895
354,1325,CVE-2018-20856,19,struct request *blk_fetch_request(struct request_queue *q){	struct request *rq;	lockdep_assert_held(q->queue_lock);	WARN_ON_ONCE(q->mq_ops);	rq = blk_peek_request(q);	if (rq)		blk_start_request(rq);	return rq;},27474
233,456,CVE-2015-8963,19,"void perf_event_output(struct perf_event *event,			struct perf_sample_data *data,			struct pt_regs *regs){	struct perf_output_handle handle;	struct perf_event_header header;	 	rcu_read_lock();	perf_prepare_sample(&header, data, event, regs);	if (perf_output_begin(&handle, event, header.size))		goto exit;	perf_output_sample(&handle, &header, data, event);	perf_output_end(&handle);exit:	rcu_read_unlock();}",18364
183,1523,CVE-2016-5185,19,  void ShowCardsFromAccountOption() {    should_show_cards_from_account_option_ = true;  },29717
306,525,CVE-2017-16939,19,"static int build_polexpire(struct sk_buff *skb, struct xfrm_policy *xp,			   int dir, const struct km_event *c){	struct xfrm_user_polexpire *upe;	int hard = c->data.hard;	struct nlmsghdr *nlh;	int err;	nlh = nlmsg_put(skb, c->portid, 0, XFRM_MSG_POLEXPIRE, sizeof(*upe), 0);	if (nlh == NULL)		return -EMSGSIZE;	upe = nlmsg_data(nlh);	copy_to_user_policy(xp, &upe->pol, dir);	err = copy_to_user_tmpl(xp, skb);	if (!err)		err = copy_to_user_sec_ctx(xp, skb);	if (!err)		err = copy_to_user_policy_type(xp->type, skb);	if (!err)		err = xfrm_mark_put(skb, &xp->mark);	if (err) {		nlmsg_cancel(skb, nlh);		return err;	}	upe->hard = !!hard;	nlmsg_end(skb, nlh);	return 0;}",19618
67,496,CVE-2017-17052,19,"static inline void __mmput(struct mm_struct *mm){	VM_BUG_ON(atomic_read(&mm->mm_users));	uprobe_clear_state(mm);	exit_aio(mm);	ksm_exit(mm);	khugepaged_exit(mm);  	exit_mmap(mm);	mm_put_huge_zero_page(mm);	set_mm_exe_file(mm, NULL);	if (!list_empty(&mm->mmlist)) {		spin_lock(&mmlist_lock);		list_del(&mm->mmlist);		spin_unlock(&mmlist_lock);	}	if (mm->binfmt)		module_put(mm->binfmt->module);	set_bit(MMF_OOM_SKIP, &mm->flags);	mmdrop(mm);}",19582
194,876,CVE-2014-9940,19,int regulator_is_enabled(struct regulator *regulator){	int ret;	if (regulator->always_on)		return 1;	mutex_lock(&regulator->rdev->mutex);	ret = _regulator_is_enabled(regulator->rdev);	mutex_unlock(&regulator->rdev->mutex);	return ret;},23037
218,528,CVE-2017-16939,19,"static int copy_to_user_state_extra(struct xfrm_state *x,				    struct xfrm_usersa_info *p,				    struct sk_buff *skb){	int ret = 0;	copy_to_user_state(x, p);	if (x->props.extra_flags) {		ret = nla_put_u32(skb, XFRMA_SA_EXTRA_FLAGS,				  x->props.extra_flags);		if (ret)			goto out;	}	if (x->coaddr) {		ret = nla_put(skb, XFRMA_COADDR, sizeof(*x->coaddr), x->coaddr);		if (ret)			goto out;	}	if (x->lastused) {		ret = nla_put_u64_64bit(skb, XFRMA_LASTUSED, x->lastused,					XFRMA_PAD);		if (ret)			goto out;	}	if (x->aead) {		ret = nla_put(skb, XFRMA_ALG_AEAD, aead_len(x->aead), x->aead);		if (ret)			goto out;	}	if (x->aalg) {		ret = copy_to_user_auth(x->aalg, skb);		if (!ret)			ret = nla_put(skb, XFRMA_ALG_AUTH_TRUNC,				      xfrm_alg_auth_len(x->aalg), x->aalg);		if (ret)			goto out;	}	if (x->ealg) {		ret = nla_put(skb, XFRMA_ALG_CRYPT, xfrm_alg_len(x->ealg), x->ealg);		if (ret)			goto out;	}	if (x->calg) {		ret = nla_put(skb, XFRMA_ALG_COMP, sizeof(*(x->calg)), x->calg);		if (ret)			goto out;	}	if (x->encap) {		ret = nla_put(skb, XFRMA_ENCAP, sizeof(*x->encap), x->encap);		if (ret)			goto out;	}	if (x->tfcpad) {		ret = nla_put_u32(skb, XFRMA_TFCPAD, x->tfcpad);		if (ret)			goto out;	}	ret = xfrm_mark_put(skb, &x->mark);	if (ret)		goto out;	if (x->replay_esn)		ret = nla_put(skb, XFRMA_REPLAY_ESN_VAL,			      xfrm_replay_state_esn_len(x->replay_esn),			      x->replay_esn);	else		ret = nla_put(skb, XFRMA_REPLAY_VAL, sizeof(x->replay),			      &x->replay);	if (ret)		goto out;	if(x->xso.dev)		ret = copy_user_offload(&x->xso, skb);	if (ret)		goto out;	if (x->props.output_mark) {		ret = nla_put_u32(skb, XFRMA_OUTPUT_MARK, x->props.output_mark);		if (ret)			goto out;	}	if (x->security)		ret = copy_sec_ctx(x->security, skb);out:	return ret;}",19621
82,135,CVE-2016-9794,19,"int snd_interval_refine(struct snd_interval *i, const struct snd_interval *v){	int changed = 0;	if (snd_BUG_ON(snd_interval_empty(i)))		return -EINVAL;	if (i->min < v->min) {		i->min = v->min;		i->openmin = v->openmin;		changed = 1;	} else if (i->min == v->min && !i->openmin && v->openmin) {		i->openmin = 1;		changed = 1;	}	if (i->max > v->max) {		i->max = v->max;		i->openmax = v->openmax;		changed = 1;	} else if (i->max == v->max && !i->openmax && v->openmax) {		i->openmax = 1;		changed = 1;	}	if (!i->integer && v->integer) {		i->integer = 1;		changed = 1;	}	if (i->integer) {		if (i->openmin) {			i->min++;			i->openmin = 0;		}		if (i->openmax) {			i->max--;			i->openmax = 0;		}	} else if (!i->openmin && !i->openmax && i->min == i->max)		i->integer = 1;	if (snd_interval_checkempty(i)) {		snd_interval_none(i);		return -EINVAL;	}	return changed;}",15020
323,789,CVE-2016-10150,19,static void kvm_destroy_dirty_bitmap(struct kvm_memory_slot *memslot){	if (!memslot->dirty_bitmap)		return;	kvfree(memslot->dirty_bitmap);	memslot->dirty_bitmap = NULL;},22505
169,879,CVE-2014-9940,19,"int regulator_list_voltage(struct regulator *regulator, unsigned selector){	struct regulator_dev *rdev = regulator->rdev;	const struct regulator_ops *ops = rdev->desc->ops;	int ret;	if (rdev->desc->fixed_uV && rdev->desc->n_voltages == 1 && !selector)		return rdev->desc->fixed_uV;	if (ops->list_voltage) {		if (selector >= rdev->desc->n_voltages)			return -EINVAL;		mutex_lock(&rdev->mutex);		ret = ops->list_voltage(rdev, selector);		mutex_unlock(&rdev->mutex);	} else if (rdev->supply) {		ret = regulator_list_voltage(rdev->supply, selector);	} else {		return -EINVAL;	}	if (ret > 0) {		if (ret < rdev->constraints->min_uV)			ret = 0;		else if (ret > rdev->constraints->max_uV)			ret = 0;	}	return ret;}",23040
79,1376,CVE-2018-20856,19,"static void part_round_stats_single(struct request_queue *q, int cpu,				    struct hd_struct *part, unsigned long now,				    unsigned int inflight){	if (inflight) {		__part_stat_add(cpu, part, time_in_queue,				inflight * (now - part->stamp));		__part_stat_add(cpu, part, io_ticks, (now - part->stamp));	}	part->stamp = now;}",27525
190,700,CVE-2017-11176,19,"int mq_init_ns(struct ipc_namespace *ns){	ns->mq_queues_count  = 0;	ns->mq_queues_max    = DFLT_QUEUESMAX;	ns->mq_msg_max       = DFLT_MSGMAX;	ns->mq_msgsize_max   = DFLT_MSGSIZEMAX;	ns->mq_msg_default   = DFLT_MSG;	ns->mq_msgsize_default  = DFLT_MSGSIZE;	ns->mq_mnt = kern_mount_data(&mqueue_fs_type, ns);	if (IS_ERR(ns->mq_mnt)) {		int err = PTR_ERR(ns->mq_mnt);		ns->mq_mnt = NULL;		return err;	}	return 0;}",20549
320,1107,CVE-2019-15920,19,SMB2_set_info_free(struct smb_rqst *rqst){	if (rqst && rqst->rq_iov)		cifs_buf_release(rqst->rq_iov[0].iov_base);  },26585
203,1452,CVE-2019-11487,19,"static long vmsplice_to_user(struct file *file, struct iov_iter *iter,			     unsigned int flags){	struct pipe_inode_info *pipe = get_pipe_info(file);	struct splice_desc sd = {		.total_len = iov_iter_count(iter),		.flags = flags,		.u.data = iter	};	long ret = 0;	if (!pipe)		return -EBADF;	if (sd.total_len) {		pipe_lock(pipe);		ret = __splice_from_pipe(pipe, &sd, pipe_to_user);		pipe_unlock(pipe);	}	return ret;}",28949
381,156,CVE-2016-9576,19,"int blk_rq_append_bio(struct request *rq, struct bio *bio){	if (!rq->bio) {		blk_rq_bio_prep(rq->q, rq, bio);	} else {		if (!ll_back_merge_fn(rq->q, rq, bio))			return -EINVAL;		rq->biotail->bi_next = bio;		rq->biotail = bio;		rq->__data_len += bio->bi_iter.bi_size;	}	return 0;}",15161
340,1363,CVE-2018-20856,19,"void blk_start_queue(struct request_queue *q){	lockdep_assert_held(q->queue_lock);	WARN_ON_ONCE(q->mq_ops);	queue_flag_clear(QUEUE_FLAG_STOPPED, q);	__blk_run_queue(q);}",27512
90,232,CVE-2016-8655,19,"static int prb_calc_retire_blk_tmo(struct packet_sock *po,				int blk_size_in_bytes){	struct net_device *dev;	unsigned int mbits = 0, msec = 0, div = 0, tmo = 0;	struct ethtool_link_ksettings ecmd;	int err;	rtnl_lock();	dev = __dev_get_by_index(sock_net(&po->sk), po->ifindex);	if (unlikely(!dev)) {		rtnl_unlock();		return DEFAULT_PRB_RETIRE_TOV;	}	err = __ethtool_get_link_ksettings(dev, &ecmd);	rtnl_unlock();	if (!err) {		 		if (ecmd.base.speed < SPEED_1000 ||		    ecmd.base.speed == SPEED_UNKNOWN) {			return DEFAULT_PRB_RETIRE_TOV;		} else {			msec = 1;			div = ecmd.base.speed / 1000;		}	}	mbits = (blk_size_in_bytes * 8) / (1024 * 1024);	if (div)		mbits /= div;	tmo = mbits * msec;	if (div)		return tmo+1;	return tmo;}",15514
208,296,CVE-2016-7912,19,"static int ffs_set_inst_name(struct usb_function_instance *fi, const char *name){	struct f_fs_opts *opts;	char *ptr;	const char *tmp;	int name_len, ret;	name_len = strlen(name) + 1;	if (name_len > MAX_INST_NAME_LEN)		return -ENAMETOOLONG;	ptr = kstrndup(name, name_len, GFP_KERNEL);	if (!ptr)		return -ENOMEM;	opts = to_f_fs_opts(fi);	tmp = NULL;	ffs_dev_lock();	tmp = opts->dev->name_allocated ? opts->dev->name : NULL;	ret = _ffs_name_dev(opts->dev, ptr);	if (ret) {		kfree(ptr);		ffs_dev_unlock();		return ret;	}	opts->dev->name_allocated = true;	ffs_dev_unlock();	kfree(tmp);	return 0;}",15730
72,1546,CVE-2019-5759,19,   ExternalPopupMenuDisplayNoneTest() {},30219
47,515,CVE-2017-17052,19,static void posix_cpu_timers_init_group(struct signal_struct *sig){	unsigned long cpu_limit;	cpu_limit = READ_ONCE(sig->rlim[RLIMIT_CPU].rlim_cur);	if (cpu_limit != RLIM_INFINITY) {		sig->cputime_expires.prof_exp = cpu_limit * NSEC_PER_SEC;		sig->cputimer.running = true;	}	 	INIT_LIST_HEAD(&sig->cpu_timers[0]);	INIT_LIST_HEAD(&sig->cpu_timers[1]);	INIT_LIST_HEAD(&sig->cpu_timers[2]);},19601
249,249,CVE-2016-7912,19,"static struct ffs_dev *_ffs_alloc_dev(void){	struct ffs_dev *dev;	int ret;	if (_ffs_get_single_dev())			return ERR_PTR(-EBUSY);	dev = kzalloc(sizeof(*dev), GFP_KERNEL);	if (!dev)		return ERR_PTR(-ENOMEM);	if (list_empty(&ffs_devices)) {		ret = functionfs_init();		if (ret) {			kfree(dev);			return ERR_PTR(ret);		}	}	list_add(&dev->entry, &ffs_devices);	return dev;}",15683
30,759,CVE-2017-7374,19,"int fscrypt_fname_usr_to_disk(struct inode *inode,			const struct qstr *iname,			struct fscrypt_str *oname){	if (fscrypt_is_dot_dotdot(iname)) {		oname->name[0] = '.';		oname->name[iname->len - 1] = '.';		oname->len = iname->len;		return 0;	}	if (inode->i_crypt_info)		return fname_encrypt(inode, iname, oname);	 	return -ENOKEY;}",21733
125,1423,CVE-2019-11487,19,"static void queue_request(struct fuse_iqueue *fiq, struct fuse_req *req){	req->in.h.len = sizeof(struct fuse_in_header) +		len_args(req->in.numargs, (struct fuse_arg *) req->in.args);	list_add_tail(&req->list, &fiq->pending);	wake_up_locked(&fiq->waitq);	kill_fasync(&fiq->fasync, SIGIO, POLL_IN);}",28920
359,687,CVE-2017-15115,19,"struct sctp_transport *sctp_transport_get_next(struct net *net,					       struct rhashtable_iter *iter){	struct sctp_transport *t;	t = rhashtable_walk_next(iter);	for (; t; t = rhashtable_walk_next(iter)) {		if (IS_ERR(t)) {			if (PTR_ERR(t) == -EAGAIN)				continue;			break;		}		if (net_eq(sock_net(t->asoc->base.sk), net) &&		    t->asoc->peer.primary_path == t)			break;	}	return t;}",20083
337,1101,CVE-2019-15920,19,SMB2_query_info_free(struct smb_rqst *rqst){	if (rqst && rqst->rq_iov)		cifs_small_buf_release(rqst->rq_iov[0].iov_base);  },26579
138,360,CVE-2016-4805,19,"ppp_input_error(struct ppp_channel *chan, int code){	struct channel *pch = chan->ppp;	struct sk_buff *skb;	if (!pch)		return;	read_lock_bh(&pch->upl);	if (pch->ppp) {		skb = alloc_skb(0, GFP_ATOMIC);		if (skb) {			skb->len = 0;		 			skb->cb[0] = code;			ppp_do_recv(pch->ppp, skb, pch);		}	}	read_unlock_bh(&pch->upl);}",16667
28,801,CVE-2016-10150,19,"void kvm_reload_remote_mmus(struct kvm *kvm){	kvm_make_all_cpus_request(kvm, KVM_REQ_MMU_RELOAD);}",22517
271,1464,CVE-2019-11487,19,"void tracing_snapshot_cond(struct trace_array *tr, void *cond_data){	tracing_snapshot_instance_cond(tr, cond_data);}",28961
241,1103,CVE-2019-15920,19,"SMB2_sess_alloc_buffer(struct SMB2_sess_data *sess_data){	int rc;	struct cifs_ses *ses = sess_data->ses;	struct smb2_sess_setup_req *req;	struct TCP_Server_Info *server = ses->server;	unsigned int total_len;	rc = smb2_plain_req_init(SMB2_SESSION_SETUP, NULL, (void **) &req,			     &total_len);	if (rc)		return rc;	 	req->sync_hdr.SessionId = 0;	 	req->PreviousSessionId = sess_data->previous_session;	req->Flags = 0;  	 	req->sync_hdr.CreditRequest = cpu_to_le16(130);	 	if (server->sign)		req->SecurityMode = SMB2_NEGOTIATE_SIGNING_REQUIRED;	else if (global_secflags & CIFSSEC_MAY_SIGN)  		req->SecurityMode = SMB2_NEGOTIATE_SIGNING_ENABLED;	else		req->SecurityMode = 0;	req->Capabilities = 0;	req->Channel = 0;  	sess_data->iov[0].iov_base = (char *)req;	 	sess_data->iov[0].iov_len = total_len - 1;	 	sess_data->buf0_type = CIFS_SMALL_BUFFER;	return 0;}",26581
157,922,CVE-2018-16840,19,"static char *detect_proxy(struct connectdata *conn){  char *proxy = NULL;     char proxy_env[128];  const char *protop = conn->handler->scheme;  char *envp = proxy_env;  char *prox;     while(*protop)    *envp++ = (char)tolower((int)*protop++);     strcpy(envp, ""_proxy"");     prox = curl_getenv(proxy_env);     if(!prox && !strcasecompare(""http_proxy"", proxy_env)) {         Curl_strntoupper(proxy_env, proxy_env, sizeof(proxy_env));    prox = curl_getenv(proxy_env);  }  envp = proxy_env;  if(prox) {    proxy = prox;    }  else {    envp = (char *)""all_proxy"";    proxy = curl_getenv(envp);      if(!proxy) {      envp = (char *)""ALL_PROXY"";      proxy = curl_getenv(envp);    }  }  if(proxy)    infof(conn->data, ""Uses proxy env variable %s == '%s'\n"", envp, proxy);  return proxy;}",24213
339,678,CVE-2017-15115,19,"static int sctp_do_bind(struct sock *sk, union sctp_addr *addr, int len){	struct net *net = sock_net(sk);	struct sctp_sock *sp = sctp_sk(sk);	struct sctp_endpoint *ep = sp->ep;	struct sctp_bind_addr *bp = &ep->base.bind_addr;	struct sctp_af *af;	unsigned short snum;	int ret = 0;	 	af = sctp_sockaddr_af(sp, addr, len);	if (!af) {		pr_debug(""%s: sk:%p, newaddr:%p, len:%d EINVAL\n"",			 __func__, sk, addr, len);		return -EINVAL;	}	snum = ntohs(addr->v4.sin_port);	pr_debug(""%s: sk:%p, new addr:%pISc, port:%d, new port:%d, len:%d\n"",		 __func__, sk, &addr->sa, bp->port, snum, len);	 	if (!sp->pf->bind_verify(sp, addr))		return -EADDRNOTAVAIL;	 	if (bp->port) {		if (!snum)			snum = bp->port;		else if (snum != bp->port) {			pr_debug(""%s: new port %d doesn't match existing port ""				 ""%d\n"", __func__, snum, bp->port);			return -EINVAL;		}	}	if (snum && snum < inet_prot_sock(net) &&	    !ns_capable(net->user_ns, CAP_NET_BIND_SERVICE))		return -EACCES;	 	if (sctp_bind_addr_match(bp, addr, sp))		return -EINVAL;	 	addr->v4.sin_port = htons(snum);	if ((ret = sctp_get_port_local(sk, addr))) {		return -EADDRINUSE;	}	 	if (!bp->port)		bp->port = inet_sk(sk)->inet_num;	 	ret = sctp_add_bind_addr(bp, addr, af->sockaddr_len,				 SCTP_ADDR_SRC, GFP_ATOMIC);	 	if (!ret) {		inet_sk(sk)->inet_sport = htons(inet_sk(sk)->inet_num);		sp->pf->to_sk_saddr(addr, sk);	}	return ret;}",20074
39,475,CVE-2015-8963,19,"static int perf_rotate_context(struct perf_cpu_context *cpuctx){	struct perf_event_context *ctx = NULL;	int rotate = 0;	if (cpuctx->ctx.nr_events) {		if (cpuctx->ctx.nr_events != cpuctx->ctx.nr_active)			rotate = 1;	}	ctx = cpuctx->task_ctx;	if (ctx && ctx->nr_events) {		if (ctx->nr_events != ctx->nr_active)			rotate = 1;	}	if (!rotate)		goto done;	perf_ctx_lock(cpuctx, cpuctx->task_ctx);	perf_pmu_disable(cpuctx->ctx.pmu);	cpu_ctx_sched_out(cpuctx, EVENT_FLEXIBLE);	if (ctx)		ctx_sched_out(ctx, cpuctx, EVENT_FLEXIBLE);	rotate_ctx(&cpuctx->ctx);	if (ctx)		rotate_ctx(ctx);	perf_event_sched_in(cpuctx, ctx, current);	perf_pmu_enable(cpuctx->ctx.pmu);	perf_ctx_unlock(cpuctx, cpuctx->task_ctx);done:	return rotate;}",18383
316,828,CVE-2014-9940,19,"static int _regulator_force_disable(struct regulator_dev *rdev){	int ret = 0;	ret = _regulator_do_disable(rdev);	if (ret < 0) {		rdev_err(rdev, ""failed to force disable\n"");		return ret;	}	_notifier_call_chain(rdev, REGULATOR_EVENT_FORCE_DISABLE |			REGULATOR_EVENT_DISABLE, NULL);	return 0;}",22989
291,625,CVE-2017-16525,19,void usb_serial_console_exit(void){	if (usbcons_info.port) {		unregister_console(&usbcons);		usbcons_info.port->port.console = 0;		usbcons_info.port = NULL;	}},19887
388,70,CVE-2014-0131,19,"static void skb_headers_offset_update(struct sk_buff *skb, int off){	 	if (skb->ip_summed == CHECKSUM_PARTIAL)		skb->csum_start += off;	 	skb->transport_header += off;	skb->network_header   += off;	if (skb_mac_header_was_set(skb))		skb->mac_header += off;	skb->inner_transport_header += off;	skb->inner_network_header += off;	skb->inner_mac_header += off;}",12242
375,488,CVE-2015-8963,19,"static void unaccount_event_cpu(struct perf_event *event, int cpu){	if (event->parent)		return;	if (is_cgroup_event(event))		atomic_dec(&per_cpu(perf_cgroup_events, cpu));}",18396
73,682,CVE-2017-15115,19,"static int sctp_init_sock(struct sock *sk){	struct net *net = sock_net(sk);	struct sctp_sock *sp;	pr_debug(""%s: sk:%p\n"", __func__, sk);	sp = sctp_sk(sk);	 	switch (sk->sk_type) {	case SOCK_SEQPACKET:		sp->type = SCTP_SOCKET_UDP;		break;	case SOCK_STREAM:		sp->type = SCTP_SOCKET_TCP;		break;	default:		return -ESOCKTNOSUPPORT;	}	sk->sk_gso_type = SKB_GSO_SCTP;	 	sp->default_stream = 0;	sp->default_ppid = 0;	sp->default_flags = 0;	sp->default_context = 0;	sp->default_timetolive = 0;	sp->default_rcv_context = 0;	sp->max_burst = net->sctp.max_burst;	sp->sctp_hmac_alg = net->sctp.sctp_hmac_alg;	 	sp->initmsg.sinit_num_ostreams   = sctp_max_outstreams;	sp->initmsg.sinit_max_instreams  = sctp_max_instreams;	sp->initmsg.sinit_max_attempts   = net->sctp.max_retrans_init;	sp->initmsg.sinit_max_init_timeo = net->sctp.rto_max;	 	sp->rtoinfo.srto_initial = net->sctp.rto_initial;	sp->rtoinfo.srto_max     = net->sctp.rto_max;	sp->rtoinfo.srto_min     = net->sctp.rto_min;	 	sp->assocparams.sasoc_asocmaxrxt = net->sctp.max_retrans_association;	sp->assocparams.sasoc_number_peer_destinations = 0;	sp->assocparams.sasoc_peer_rwnd = 0;	sp->assocparams.sasoc_local_rwnd = 0;	sp->assocparams.sasoc_cookie_life = net->sctp.valid_cookie_life;	 	memset(&sp->subscribe, 0, sizeof(struct sctp_event_subscribe));	 	sp->hbinterval  = net->sctp.hb_interval;	sp->pathmaxrxt  = net->sctp.max_retrans_path;	sp->pathmtu     = 0;  	sp->sackdelay   = net->sctp.sack_timeout;	sp->sackfreq	= 2;	sp->param_flags = SPP_HB_ENABLE |			  SPP_PMTUD_ENABLE |			  SPP_SACKDELAY_ENABLE;	 	sp->disable_fragments = 0;	 	sp->nodelay           = 0;	sp->recvrcvinfo = 0;	sp->recvnxtinfo = 0;	 	sp->v4mapped          = 1;	 	sp->autoclose         = 0;	 	sp->user_frag         = 0;	sp->adaptation_ind = 0;	sp->pf = sctp_get_pf_specific(sk->sk_family);	 	atomic_set(&sp->pd_mode, 0);	skb_queue_head_init(&sp->pd_lobby);	sp->frag_interleave = 0;	 	sp->ep = sctp_endpoint_new(sk, GFP_KERNEL);	if (!sp->ep)		return -ENOMEM;	sp->hmac = NULL;	sk->sk_destruct = sctp_destruct_sock;	SCTP_DBG_OBJCNT_INC(sock);	local_bh_disable();	percpu_counter_inc(&sctp_sockets_allocated);	sock_prot_inuse_add(net, sk->sk_prot, 1);	 	if (net->sctp.default_auto_asconf) {		spin_lock(&sock_net(sk)->sctp.addr_wq_lock);		list_add_tail(&sp->auto_asconf_list,		    &net->sctp.auto_asconf_splist);		sp->do_auto_asconf = 1;		spin_unlock(&sock_net(sk)->sctp.addr_wq_lock);	} else {		sp->do_auto_asconf = 0;	}	local_bh_enable();	return 0;}",20078
264,592,CVE-2017-16527,19,"static int mixer_ctl_procunit_get(struct snd_kcontrol *kcontrol,				  struct snd_ctl_elem_value *ucontrol){	struct usb_mixer_elem_info *cval = kcontrol->private_data;	int err, val;	err = get_cur_ctl_value(cval, cval->control << 8, &val);	if (err < 0) {		ucontrol->value.integer.value[0] = cval->min;		return filter_error(cval, err);	}	val = get_relative_value(cval, val);	ucontrol->value.integer.value[0] = val;	return 0;}",19851
130,102,CVE-2014-0131,19,"static int spd_fill_page(struct splice_pipe_desc *spd,			  struct pipe_inode_info *pipe, struct page *page,			  unsigned int *len, unsigned int offset,			  int linear,			  struct sock *sk){	if (unlikely(spd->nr_pages == MAX_SKB_FRAGS))		return true;	if (linear) {		page = linear_to_page(page, len, &offset, sk);		if (!page)			return true;	}	if (spd_can_coalesce(spd, page, offset)) {		spd->partial[spd->nr_pages - 1].len += *len;		return false;	}	get_page(page);	spd->pages[spd->nr_pages] = page;	spd->partial[spd->nr_pages].len = *len;	spd->partial[spd->nr_pages].offset = offset;	spd->nr_pages++;	return false;}",12274
136,710,CVE-2017-11176,19,"static void remove_notification(struct mqueue_inode_info *info){	if (info->notify_owner != NULL &&	    info->notify.sigev_notify == SIGEV_THREAD) {		set_cookie(info->notify_cookie, NOTIFY_REMOVED);		netlink_sendskb(info->notify_sock, info->notify_cookie);	}	put_pid(info->notify_owner);	put_user_ns(info->notify_user_ns);	info->notify_owner = NULL;	info->notify_user_ns = NULL;}",20559
247,1232,CVE-2019-9003,19,"static int __scan_channels(struct ipmi_smi *intf, struct ipmi_device_id *id){	int rv;	if (ipmi_version_major(id) > 1			|| (ipmi_version_major(id) == 1			    && ipmi_version_minor(id) >= 5)) {		unsigned int set;		 		set = !intf->curr_working_cset;		intf->curr_working_cset = set;		memset(&intf->wchannels[set], 0,		       sizeof(struct ipmi_channel_set));		intf->null_user_handler = channel_handler;		intf->curr_channel = 0;		rv = send_channel_info_cmd(intf, 0);		if (rv) {			dev_warn(intf->si_dev,				 ""Error sending channel information for channel 0, %d\n"",				 rv);			return -EIO;		}		 		wait_event(intf->waitq, intf->channels_ready);		intf->null_user_handler = NULL;	} else {		unsigned int set = intf->curr_working_cset;		 		intf->wchannels[set].c[0].medium = IPMI_CHANNEL_MEDIUM_IPMB;		intf->wchannels[set].c[0].protocol = IPMI_CHANNEL_PROTOCOL_IPMB;		intf->channel_list = intf->wchannels + set;		intf->channels_ready = true;	}	return 0;}",27209
262,1446,CVE-2019-11487,19,"static void page_cache_pipe_buf_release(struct pipe_inode_info *pipe,					struct pipe_buffer *buf){	put_page(buf->page);	buf->flags &= ~PIPE_BUF_FLAG_LRU;}",28943
36,168,CVE-2016-9120,19,static inline int ion_buffer_page_is_dirty(struct page *page){	return !!((unsigned long)page & 1UL);},15254
27,393,CVE-2016-3841,19,"static int ipv6_hop_ra(struct sk_buff *skb, int optoff){	const unsigned char *nh = skb_network_header(skb);	if (nh[optoff + 1] == 2) {		IP6CB(skb)->flags |= IP6SKB_ROUTERALERT;		memcpy(&IP6CB(skb)->ra, nh + optoff + 2, sizeof(IP6CB(skb)->ra));		return true;	}	net_dbg_ratelimited(""ipv6_hop_ra: wrong RA length %d\n"",			    nh[optoff + 1]);	kfree_skb(skb);	return false;}",17165
32,663,CVE-2017-15265,19,static void port_subs_info_init(struct snd_seq_port_subs_info *grp){	INIT_LIST_HEAD(&grp->list_head);	grp->count = 0;	grp->exclusive = 0;	rwlock_init(&grp->list_lock);	init_rwsem(&grp->list_mutex);	grp->open = NULL;	grp->close = NULL; },20053
144,680,CVE-2017-15115,19,static int sctp_hash(struct sock *sk){	 	return 0;},20076
260,1442,CVE-2019-11487,19,unsigned int round_pipe_size(unsigned long size){	if (size > (1U << 31))		return 0;	 	if (size < PAGE_SIZE)		return PAGE_SIZE;	return roundup_pow_of_two(size);},28939
84,844,CVE-2014-9940,19,"static void rdev_init_debugfs(struct regulator_dev *rdev){	rdev->debugfs = debugfs_create_dir(rdev_get_name(rdev), debugfs_root);	if (!rdev->debugfs) {		rdev_warn(rdev, ""Failed to create debugfs directory\n"");		return;	}	debugfs_create_u32(""use_count"", 0444, rdev->debugfs,			   &rdev->use_count);	debugfs_create_u32(""open_count"", 0444, rdev->debugfs,			   &rdev->open_count);	debugfs_create_u32(""bypass_count"", 0444, rdev->debugfs,			   &rdev->bypass_count);}",23005
10,1488,CVE-2019-11487,19,static inline void SetPageHugeTemporary(struct page *page){	page[2].mapping = (void *)-1U;},28985
113,219,CVE-2016-8655,19,static void packet_dec_pending(struct packet_ring_buffer *rb){	this_cpu_dec(*rb->pending_refcnt);},15501
313,1300,CVE-2019-9003,19,"static void need_waiter(struct ipmi_smi *intf){	 	if (!timer_pending(&ipmi_timer))		mod_timer(&ipmi_timer, jiffies + IPMI_TIMEOUT_JIFFIES);}",27277
197,163,CVE-2016-9120,19,"static void *ion_buffer_kmap_get(struct ion_buffer *buffer){	void *vaddr;	if (buffer->kmap_cnt) {		buffer->kmap_cnt++;		return buffer->vaddr;	}	vaddr = buffer->heap->ops->map_kernel(buffer->heap, buffer);	if (WARN_ONCE(vaddr == NULL,			""heap->ops->map_kernel should return ERR_PTR on error""))		return ERR_PTR(-EINVAL);	if (IS_ERR(vaddr))		return vaddr;	buffer->vaddr = vaddr;	buffer->kmap_cnt++;	return vaddr;}",15249
382,1084,CVE-2017-15129,19,void unregister_pernet_device(struct pernet_operations *ops){	mutex_lock(&net_mutex);	if (&ops->list == first_device)		first_device = first_device->next;	unregister_pernet_operations(ops);	mutex_unlock(&net_mutex);},26153
328,822,CVE-2014-9940,19,"static int _regulator_disable(struct regulator_dev *rdev){	int ret = 0;	if (WARN(rdev->use_count <= 0,		 ""unbalanced disables for %s\n"", rdev_get_name(rdev)))		return -EIO;	 	if (rdev->use_count == 1 &&	    (rdev->constraints && !rdev->constraints->always_on)) {		 		if (_regulator_can_change_status(rdev)) {			ret = _regulator_do_disable(rdev);			if (ret < 0) {				rdev_err(rdev, ""failed to disable\n"");				return ret;			}			_notifier_call_chain(rdev, REGULATOR_EVENT_DISABLE,					NULL);		}		rdev->use_count = 0;	} else if (rdev->use_count > 1) {		if (rdev->constraints &&			(rdev->constraints->valid_ops_mask &			REGULATOR_CHANGE_DRMS))			drms_uA_update(rdev);		rdev->use_count--;	}	return ret;}",22983
221,996,CVE-2017-18218,19,"static int hns_nic_init_ring_data(struct hns_nic_priv *priv){	struct hnae_handle *h = priv->ae_handle;	struct hns_nic_ring_data *rd;	int is_ver1 = AE_IS_VER1(priv->enet_ver);	int i;	if (h->q_num > NIC_MAX_Q_PER_VF) {		netdev_err(priv->netdev, ""too much queue (%d)\n"", h->q_num);		return -EINVAL;	}	priv->ring_data = kzalloc(h->q_num * sizeof(*priv->ring_data) * 2,				  GFP_KERNEL);	if (!priv->ring_data)		return -ENOMEM;	for (i = 0; i < h->q_num; i++) {		rd = &priv->ring_data[i];		rd->queue_index = i;		rd->ring = &h->qs[i]->tx_ring;		rd->poll_one = hns_nic_tx_poll_one;		rd->fini_process = is_ver1 ? hns_nic_tx_fini_pro :			hns_nic_tx_fini_pro_v2;		netif_napi_add(priv->netdev, &rd->napi,			       hns_nic_common_poll, NIC_TX_CLEAN_MAX_NUM);		rd->ring->irq_init_flag = RCB_IRQ_NOT_INITED;	}	for (i = h->q_num; i < h->q_num * 2; i++) {		rd = &priv->ring_data[i];		rd->queue_index = i - h->q_num;		rd->ring = &h->qs[i - h->q_num]->rx_ring;		rd->poll_one = hns_nic_rx_poll_one;		rd->ex_process = hns_nic_rx_up_pro;		rd->fini_process = is_ver1 ? hns_nic_rx_fini_pro :			hns_nic_rx_fini_pro_v2;		netif_napi_add(priv->netdev, &rd->napi,			       hns_nic_common_poll, NIC_RX_CLEAN_MAX_NUM);		rd->ring->irq_init_flag = RCB_IRQ_NOT_INITED;	}	return 0;}",25846
37,1167,CVE-2019-11811,19,static void cleanup_one_si(struct smi_info *smi_info){	if (!smi_info)		return;	list_del(&smi_info->link);	if (smi_info->intf)		ipmi_unregister_smi(smi_info->intf);	if (smi_info->pdev) {		if (smi_info->pdev_registered)			platform_device_unregister(smi_info->pdev);		else			platform_device_put(smi_info->pdev);	}	kfree(smi_info);},26930
377,400,CVE-2016-3841,19,"static int raw6_getfrag(void *from, char *to, int offset, int len, int odd,		       struct sk_buff *skb){	struct raw6_frag_vec *rfv = from;	if (offset < rfv->hlen) {		int copy = min(rfv->hlen - offset, len);		if (skb->ip_summed == CHECKSUM_PARTIAL)			memcpy(to, rfv->c + offset, copy);		else			skb->csum = csum_block_add(				skb->csum,				csum_partial_copy_nocheck(rfv->c + offset,							  to, copy, 0),				odd);		odd = 0;		offset += copy;		to += copy;		len -= copy;		if (!len)			return 0;	}	offset -= rfv->hlen;	return ip_generic_getfrag(rfv->msg, to, offset, len, odd, skb);}",17172
289,392,CVE-2016-3841,19,"struct ipv6_txoptions *ipv6_fixup_options(struct ipv6_txoptions *opt_space,					  struct ipv6_txoptions *opt){	 	if (opt && opt->dst0opt && !opt->srcrt) {		if (opt_space != opt) {			memcpy(opt_space, opt, sizeof(*opt_space));			opt = opt_space;		}		opt->opt_nflen -= ipv6_optlen(opt->dst0opt);		opt->dst0opt = NULL;	}	return opt;}",17164
298,221,CVE-2016-8655,19,"static void packet_dev_mclist_delete(struct net_device *dev,				     struct packet_mclist **mlp){	struct packet_mclist *ml;	while ((ml = *mlp) != NULL) {		if (ml->ifindex == dev->ifindex) {			packet_dev_mc(dev, ml, -1);			*mlp = ml->next;			kfree(ml);		} else			mlp = &ml->next;	}}",15503
202,324,CVE-2016-7910,19,"static void disk_replace_part_tbl(struct gendisk *disk,				  struct disk_part_tbl *new_ptbl){	struct disk_part_tbl *old_ptbl = disk->part_tbl;	rcu_assign_pointer(disk->part_tbl, new_ptbl);	if (old_ptbl) {		rcu_assign_pointer(old_ptbl->last_lookup, NULL);		kfree_rcu(old_ptbl, rcu_head);	}}",15758
145,1557,CVE-2018-9476,19,"int btif_av_peer_supports_3mbps(void) { int is3mbps = ((btif_av_cb.edr & BTA_AV_EDR_3MBPS) != 0);  BTIF_TRACE_DEBUG(""%s: connected %d, edr_3mbps %d"", __func__,                   btif_av_is_connected(), is3mbps); return (btif_av_is_connected() && is3mbps);}",30796
13,1031,CVE-2017-18218,19,"static int is_valid_clean_head(struct hnae_ring *ring, int h){	int u = ring->next_to_use;	int c = ring->next_to_clean;	if (unlikely(h > ring->desc_num))		return 0;	assert(u > 0 && u < ring->desc_num);	assert(c > 0 && c < ring->desc_num);	assert(u != c && h != c);  	return u > c ? (h > c && h <= u) : (h > c || h <= u);}",25881
360,122,CVE-2016-9794,19,"static inline unsigned int div_up(unsigned int a, unsigned int b){	unsigned int r;	unsigned int q;	if (b == 0)		return UINT_MAX;	q = div32(a, b, &r);	if (r)		++q;	return q;}",15007
26,809,CVE-2016-10150,19,void kvm_vcpu_wake_up(struct kvm_vcpu *vcpu){	struct swait_queue_head *wqp;	wqp = kvm_arch_vcpu_wq(vcpu);	if (swait_active(wqp)) {		swake_up(wqp);		++vcpu->stat.halt_wakeup;	}},22525
191,478,CVE-2015-8963,19,"static int perf_tp_filter_match(struct perf_event *event,				struct perf_sample_data *data){	void *record = data->raw->data;	 	if (event->parent)		event = event->parent;	if (likely(!event->filter) || filter_match_preds(event->filter, record))		return 1;	return 0;}",18386
312,1076,CVE-2017-15129,19,"static int register_pernet_operations(struct list_head *list,				      struct pernet_operations *ops){	int error;	if (ops->id) {again:		error = ida_get_new_above(&net_generic_ids, MIN_PERNET_OPS_ID, ops->id);		if (error < 0) {			if (error == -EAGAIN) {				ida_pre_get(&net_generic_ids, GFP_KERNEL);				goto again;			}			return error;		}		max_gen_ptrs = max(max_gen_ptrs, *ops->id + 1);	}	error = __register_pernet_operations(list, ops);	if (error) {		rcu_barrier();		if (ops->id)			ida_remove(&net_generic_ids, *ops->id);	}	return error;}",26145
52,366,CVE-2016-4805,19,"ppp_register_compressor(struct compressor *cp){	struct compressor_entry *ce;	int ret;	spin_lock(&compressor_list_lock);	ret = -EEXIST;	if (find_comp_entry(cp->compress_proto))		goto out;	ret = -ENOMEM;	ce = kmalloc(sizeof(struct compressor_entry), GFP_ATOMIC);	if (!ce)		goto out;	ret = 0;	ce->comp = cp;	list_add(&ce->list, &compressor_list); out:	spin_unlock(&compressor_list_lock);	return ret;}",16673
371,141,CVE-2016-9794,19,"int snd_pcm_hw_params_choose(struct snd_pcm_substream *pcm,			     struct snd_pcm_hw_params *params){	static int vars[] = {		SNDRV_PCM_HW_PARAM_ACCESS,		SNDRV_PCM_HW_PARAM_FORMAT,		SNDRV_PCM_HW_PARAM_SUBFORMAT,		SNDRV_PCM_HW_PARAM_CHANNELS,		SNDRV_PCM_HW_PARAM_RATE,		SNDRV_PCM_HW_PARAM_PERIOD_TIME,		SNDRV_PCM_HW_PARAM_BUFFER_SIZE,		SNDRV_PCM_HW_PARAM_TICK_TIME,		-1	};	int err, *v;	for (v = vars; *v != -1; v++) {		if (*v != SNDRV_PCM_HW_PARAM_BUFFER_SIZE)			err = snd_pcm_hw_param_first(pcm, params, *v, NULL);		else			err = snd_pcm_hw_param_last(pcm, params, *v, NULL);		if (snd_BUG_ON(err < 0))			return err;	}	return 0;}",15026
274,582,CVE-2017-16527,19,"static int get_abs_value(struct usb_mixer_elem_info *cval, int val){	if (val < 0)		return cval->min;	if (!cval->res)		cval->res = 1;	val *= cval->res;	val += cval->min;	if (val > cval->max)		return cval->max;	return val;}",19841
245,361,CVE-2016-4805,19,"static int ppp_open(struct inode *inode, struct file *file){	 	if (!capable(CAP_NET_ADMIN))		return -EPERM;	return 0;}",16668
217,1139,CVE-2019-15917,19,"static void hci_uart_tty_close(struct tty_struct *tty){	struct hci_uart *hu = tty->disc_data;	struct hci_dev *hdev;	BT_DBG(""tty %p"", tty);	 	tty->disc_data = NULL;	if (!hu)		return;	hdev = hu->hdev;	if (hdev)		hci_uart_close(hdev);	if (test_bit(HCI_UART_PROTO_READY, &hu->flags)) {		percpu_down_write(&hu->proto_lock);		clear_bit(HCI_UART_PROTO_READY, &hu->flags);		percpu_up_write(&hu->proto_lock);		cancel_work_sync(&hu->write_work);		if (hdev) {			if (test_bit(HCI_UART_REGISTERED, &hu->flags))				hci_unregister_dev(hdev);			hci_free_dev(hdev);		}		hu->proto->close(hu);	}	clear_bit(HCI_UART_PROTO_SET, &hu->flags);	percpu_free_rwsem(&hu->proto_lock);	kfree(hu);}",26618
281,247,CVE-2016-7913,19,"static int xc2028_set_analog_freq(struct dvb_frontend *fe,			      struct analog_parameters *p){	struct xc2028_data *priv = fe->tuner_priv;	unsigned int       type=0;	tuner_dbg(""%s called\n"", __func__);	if (p->mode == V4L2_TUNER_RADIO) {		type |= FM;		if (priv->ctrl.input1)			type |= INPUT1;		return generic_set_freq(fe, (625l * p->frequency) / 10,				V4L2_TUNER_RADIO, type, 0, 0);	}	 	if (!p->std)		p->std = V4L2_STD_MN;	 	if (!(p->std & V4L2_STD_MN))		type |= F8MHZ;	 	p->std |= parse_audio_std_option();	return generic_set_freq(fe, 62500l * p->frequency,				V4L2_TUNER_ANALOG_TV, type, p->std, 0);}",15681
133,210,CVE-2016-8655,19,"static unsigned int fanout_demux_rnd(struct packet_fanout *f,				     struct sk_buff *skb,				     unsigned int num){	return prandom_u32_max(num);}",15492
83,1445,CVE-2019-11487,19,"static long do_vmsplice(struct file *f, struct iov_iter *iter, unsigned int flags){	if (unlikely(flags & ~SPLICE_F_ALL))		return -EINVAL;	if (!iov_iter_count(iter))		return 0;	if (iov_iter_rw(iter) == WRITE)		return vmsplice_to_pipe(f, iter, flags);	else		return vmsplice_to_user(f, iter, flags);}",28942
99,891,CVE-2014-9940,19,"int regulator_set_voltage_time_sel(struct regulator_dev *rdev,				   unsigned int old_selector,				   unsigned int new_selector){	unsigned int ramp_delay = 0;	int old_volt, new_volt;	if (rdev->constraints->ramp_delay)		ramp_delay = rdev->constraints->ramp_delay;	else if (rdev->desc->ramp_delay)		ramp_delay = rdev->desc->ramp_delay;	if (ramp_delay == 0) {		rdev_warn(rdev, ""ramp_delay not set\n"");		return 0;	}	 	if (!rdev->desc->ops->list_voltage)		return -EINVAL;	old_volt = rdev->desc->ops->list_voltage(rdev, old_selector);	new_volt = rdev->desc->ops->list_voltage(rdev, new_selector);	return DIV_ROUND_UP(abs(new_volt - old_volt), ramp_delay);}",23052
277,448,CVE-2015-8963,19,"void perf_event_disable(struct perf_event *event){	struct perf_event_context *ctx;	ctx = perf_event_ctx_lock(event);	_perf_event_disable(event);	perf_event_ctx_unlock(event, ctx);}",18356
255,304,CVE-2016-7911,19,"int set_task_ioprio(struct task_struct *task, int ioprio){	int err;	struct io_context *ioc;	const struct cred *cred = current_cred(), *tcred;	rcu_read_lock();	tcred = __task_cred(task);	if (!uid_eq(tcred->uid, cred->euid) &&	    !uid_eq(tcred->uid, cred->uid) && !capable(CAP_SYS_NICE)) {		rcu_read_unlock();		return -EPERM;	}	rcu_read_unlock();	err = security_task_setioprio(task, ioprio);	if (err)		return err;	ioc = get_task_io_context(task, GFP_ATOMIC, NUMA_NO_NODE);	if (ioc) {		ioc->ioprio = ioprio;		put_io_context(ioc);	}	return err;}",15738
361,174,CVE-2016-9120,19,"struct ion_device *ion_device_create(long (*custom_ioctl)				     (struct ion_client *client,				      unsigned int cmd,				      unsigned long arg)){	struct ion_device *idev;	int ret;	idev = kzalloc(sizeof(struct ion_device), GFP_KERNEL);	if (!idev)		return ERR_PTR(-ENOMEM);	idev->dev.minor = MISC_DYNAMIC_MINOR;	idev->dev.name = ""ion"";	idev->dev.fops = &ion_fops;	idev->dev.parent = NULL;	ret = misc_register(&idev->dev);	if (ret) {		pr_err(""ion: failed to register misc device.\n"");		kfree(idev);		return ERR_PTR(ret);	}	idev->debug_root = debugfs_create_dir(""ion"", NULL);	if (!idev->debug_root) {		pr_err(""ion: failed to create debugfs root directory.\n"");		goto debugfs_done;	}	idev->heaps_debug_root = debugfs_create_dir(""heaps"", idev->debug_root);	if (!idev->heaps_debug_root) {		pr_err(""ion: failed to create debugfs heaps directory.\n"");		goto debugfs_done;	}	idev->clients_debug_root = debugfs_create_dir(""clients"",						idev->debug_root);	if (!idev->clients_debug_root)		pr_err(""ion: failed to create debugfs clients directory.\n"");debugfs_done:	idev->custom_ioctl = custom_ioctl;	idev->buffers = RB_ROOT;	mutex_init(&idev->buffer_lock);	init_rwsem(&idev->lock);	plist_head_init(&idev->heaps);	idev->clients = RB_ROOT;	ion_root_client = &idev->clients;	mutex_init(&debugfs_mutex);	return idev;}",15260
168,98,CVE-2014-0131,19,"int sock_queue_err_skb(struct sock *sk, struct sk_buff *skb){	int len = skb->len;	if (atomic_read(&sk->sk_rmem_alloc) + skb->truesize >=	    (unsigned int)sk->sk_rcvbuf)		return -ENOMEM;	skb_orphan(skb);	skb->sk = sk;	skb->destructor = sock_rmem_free;	atomic_add(skb->truesize, &sk->sk_rmem_alloc);	 	skb_dst_force(skb);	skb_queue_tail(&sk->sk_error_queue, skb);	if (!sock_flag(sk, SOCK_DEAD))		sk->sk_data_ready(sk, len);	return 0;}",12270
147,504,CVE-2017-17052,19,"static inline void free_signal_struct(struct signal_struct *sig){	taskstats_tgid_free(sig);	sched_autogroup_exit(sig);	 	if (sig->oom_mm)		mmdrop_async(sig->oom_mm);	kmem_cache_free(signal_cachep, sig);}",19590
212,1043,CVE-2017-18202,19,"void oom_killer_enable(void){	oom_killer_disabled = false;	pr_info(""OOM killer enabled.\n"");}",26021
310,1371,CVE-2018-20856,19,"static void ioc_set_batching(struct request_queue *q, struct io_context *ioc){	if (!ioc || ioc_batching(q, ioc))		return;	ioc->nr_batch_requests = q->nr_batching;	ioc->last_waited = jiffies;}",27520
107,1479,CVE-2019-11487,19,"long get_user_pages(unsigned long start, unsigned long nr_pages,		unsigned int gup_flags, struct page **pages,		struct vm_area_struct **vmas){	return __get_user_pages_locked(current, current->mm, start, nr_pages,				       pages, vmas, NULL,				       gup_flags | FOLL_TOUCH);}",28976
151,1008,CVE-2017-18218,19,"static void hns_nic_reset_subtask(struct hns_nic_priv *priv){	enum hnae_port_type type = priv->ae_handle->port_type;	if (!test_bit(NIC_STATE2_RESET_REQUESTED, &priv->state))		return;	clear_bit(NIC_STATE2_RESET_REQUESTED, &priv->state);	 	if (test_bit(NIC_STATE_DOWN, &priv->state) ||	    test_bit(NIC_STATE_REMOVING, &priv->state) ||	    test_bit(NIC_STATE_RESETTING, &priv->state))		return;	hns_nic_dump(priv);	netdev_info(priv->netdev, ""try to reset %s port!\n"",		    (type == HNAE_PORT_DEBUG ? ""debug"" : ""service""));	rtnl_lock();	 	netif_trans_update(priv->netdev);	if (type == HNAE_PORT_DEBUG) {		hns_nic_net_reinit(priv->netdev);	} else {		netif_carrier_off(priv->netdev);		netif_tx_disable(priv->netdev);	}	rtnl_unlock();}",25858
379,737,CVE-2017-10661,19,"static void timerfd_show(struct seq_file *m, struct file *file){	struct timerfd_ctx *ctx = file->private_data;	struct itimerspec t;	spin_lock_irq(&ctx->wqh.lock);	t.it_value = ktime_to_timespec(timerfd_get_remaining(ctx));	t.it_interval = ktime_to_timespec(ctx->tintv);	spin_unlock_irq(&ctx->wqh.lock);	seq_printf(m,		   ""clockid: %d\n""		   ""ticks: %llu\n""		   ""settime flags: 0%o\n""		   ""it_value: (%llu, %llu)\n""		   ""it_interval: (%llu, %llu)\n"",		   ctx->clockid,		   (unsigned long long)ctx->ticks,		   ctx->settime_flags,		   (unsigned long long)t.it_value.tv_sec,		   (unsigned long long)t.it_value.tv_nsec,		   (unsigned long long)t.it_interval.tv_sec,		   (unsigned long long)t.it_interval.tv_nsec);}",20659
88,550,CVE-2017-16939,19,"static int xfrm_notify_policy_flush(const struct km_event *c){	struct net *net = c->net;	struct nlmsghdr *nlh;	struct sk_buff *skb;	int err;	skb = nlmsg_new(userpolicy_type_attrsize(), GFP_ATOMIC);	if (skb == NULL)		return -ENOMEM;	nlh = nlmsg_put(skb, c->portid, c->seq, XFRM_MSG_FLUSHPOLICY, 0, 0);	err = -EMSGSIZE;	if (nlh == NULL)		goto out_free_skb;	err = copy_to_user_policy_type(c->data.type, skb);	if (err)		goto out_free_skb;	nlmsg_end(skb, nlh);	return xfrm_nlmsg_multicast(net, skb, 0, XFRMNLGRP_POLICY);out_free_skb:	kfree_skb(skb);	return err;}",19643
100,1238,CVE-2019-9003,19,"static void deliver_err_response(struct ipmi_smi *intf,				 struct ipmi_recv_msg *msg, int err){	msg->recv_type = IPMI_RESPONSE_RECV_TYPE;	msg->msg_data[0] = err;	msg->msg.netfn |= 1;  	msg->msg.data_len = 1;	msg->msg.data = msg->msg_data;	deliver_local_response(intf, msg);}",27215
344,1307,CVE-2019-9003,19,"send_guid_cmd(struct ipmi_smi *intf, int chan){	struct kernel_ipmi_msg            msg;	struct ipmi_system_interface_addr si;	si.addr_type = IPMI_SYSTEM_INTERFACE_ADDR_TYPE;	si.channel = IPMI_BMC_CHANNEL;	si.lun = 0;	msg.netfn = IPMI_NETFN_APP_REQUEST;	msg.cmd = IPMI_GET_DEVICE_GUID_CMD;	msg.data = NULL;	msg.data_len = 0;	return i_ipmi_request(NULL,			      intf,			      (struct ipmi_addr *) &si,			      0,			      &msg,			      intf,			      NULL,			      NULL,			      0,			      intf->addrinfo[0].address,			      intf->addrinfo[0].lun,			      -1, 0);}",27284
45,1425,CVE-2019-11487,19,static int request_pending(struct fuse_iqueue *fiq){	return !list_empty(&fiq->pending) || !list_empty(&fiq->interrupts) ||		forget_pending(fiq);},28922
77,928,CVE-2018-15857,19,"ExprCreateFloat(void){    EXPR_CREATE(ExprFloat, expr, EXPR_VALUE, EXPR_TYPE_FLOAT);    return expr;}",24397
385,1115,CVE-2019-15920,19,build_encrypt_ctxt(struct smb2_encryption_neg_context *pneg_ctxt){	pneg_ctxt->ContextType = SMB2_ENCRYPTION_CAPABILITIES;	pneg_ctxt->DataLength = cpu_to_le16(4);  	pneg_ctxt->CipherCount = cpu_to_le16(1);   	pneg_ctxt->Ciphers[0] = SMB2_ENCRYPTION_AES128_CCM;},26593
9,1412,CVE-2019-11487,19,"int fuse_request_queue_background(struct fuse_conn *fc, struct fuse_req *req){	int queued = false;	WARN_ON(!test_bit(FR_BACKGROUND, &req->flags));	if (!test_bit(FR_WAITING, &req->flags)) {		__set_bit(FR_WAITING, &req->flags);		atomic_inc(&fc->num_waiting);	}	__set_bit(FR_ISREPLY, &req->flags);	spin_lock(&fc->bg_lock);	if (likely(fc->connected)) {		fc->num_background++;		if (fc->num_background == fc->max_background)			fc->blocked = 1;		if (fc->num_background == fc->congestion_threshold && fc->sb) {			set_bdi_congested(fc->sb->s_bdi, BLK_RW_SYNC);			set_bdi_congested(fc->sb->s_bdi, BLK_RW_ASYNC);		}		list_add_tail(&req->list, &fc->bg_queue);		flush_bg_queue(fc);		queued = true;	}	spin_unlock(&fc->bg_lock);	return queued;}",28909
166,1408,CVE-2019-11487,19,static void fuse_req_pages_free(struct fuse_req *req){	if (req->pages != req->inline_pages)		kfree(req->pages);},28905
57,490,CVE-2015-8961,19,"static int ext4_journal_check_start(struct super_block *sb){	journal_t *journal;	might_sleep();	if (sb->s_flags & MS_RDONLY)		return -EROFS;	WARN_ON(sb->s_writers.frozen == SB_FREEZE_COMPLETE);	journal = EXT4_SB(sb)->s_journal;	 	if (journal && is_journal_aborted(journal)) {		ext4_abort(sb, ""Detected aborted journal"");		return -EROFS;	}	return 0;}",18398
80,266,CVE-2016-7912,19,"static int ffs_ep0_open(struct inode *inode, struct file *file){	struct ffs_data *ffs = inode->i_private;	ENTER();	if (unlikely(ffs->state == FFS_CLOSING))		return -EBUSY;	file->private_data = ffs;	ffs_data_opened(ffs);	return 0;}",15700
155,1102,CVE-2019-15920,19,"SMB2_select_sec(struct cifs_ses *ses, struct SMB2_sess_data *sess_data){	int type;	type = smb2_select_sectype(ses->server, ses->sectype);	cifs_dbg(FYI, ""sess setup type %d\n"", type);	if (type == Unspecified) {		cifs_dbg(VFS,			""Unable to select appropriate authentication method!"");		return -EINVAL;	}	switch (type) {	case Kerberos:		sess_data->func = SMB2_auth_kerberos;		break;	case RawNTLMSSP:		sess_data->func = SMB2_sess_auth_rawntlmssp_negotiate;		break;	default:		cifs_dbg(VFS, ""secType %d not supported!\n"", type);		return -EOPNOTSUPP;	}	return 0;}",26580
347,1243,CVE-2019-9003,19,static void dummy_recv_done_handler(struct ipmi_recv_msg *msg){	atomic_dec(&panic_done_count);},27220
366,148,CVE-2016-9794,19,"static int snd_pcm_hw_rule_step(struct snd_pcm_hw_params *params,				struct snd_pcm_hw_rule *rule){	unsigned long step = (unsigned long) rule->private;	return snd_interval_step(hw_param_interval(params, rule->var), step);}",15033
335,1525,CVE-2017-5080,19,  SaveCardBubbleControllerImplTest() {},29874
351,142,CVE-2016-9794,19,"static int snd_pcm_hw_rule_list(struct snd_pcm_hw_params *params,				struct snd_pcm_hw_rule *rule){	struct snd_pcm_hw_constraint_list *list = rule->private;	return snd_interval_list(hw_param_interval(params, rule->var), list->count, list->list, list->mask);}		",15027
86,283,CVE-2016-7912,19,"static void ffs_func_eps_disable(struct ffs_function *func){	struct ffs_ep *ep         = func->eps;	struct ffs_epfile *epfile = func->ffs->epfiles;	unsigned count            = func->ffs->eps_count;	unsigned long flags;	spin_lock_irqsave(&func->ffs->eps_lock, flags);	do {		 		if (likely(ep->ep))			usb_ep_disable(ep->ep);		++ep;		if (epfile) {			epfile->ep = NULL;			++epfile;		}	} while (--count);	spin_unlock_irqrestore(&func->ffs->eps_lock, flags);}",15717
290,10,CVE-2016-6295,19," PHP_FUNCTION(snmp2_get) {	php_snmp(INTERNAL_FUNCTION_PARAM_PASSTHRU, SNMP_CMD_GET, SNMP_VERSION_2c); }",1664
219,300,CVE-2016-7912,19,"static void functionfs_cleanup(void){	ENTER();	pr_info(""unloading\n"");	unregister_filesystem(&ffs_fs_type);}",15734
2,1135,CVE-2019-15917,19,"void hci_uart_set_baudrate(struct hci_uart *hu, unsigned int speed){	struct tty_struct *tty = hu->tty;	struct ktermios ktermios;	ktermios = tty->termios;	ktermios.c_cflag &= ~CBAUD;	tty_termios_encode_baud_rate(&ktermios, speed, speed);	 	tty_set_termios(tty, &ktermios);	BT_DBG(""%s: New tty speeds: %d/%d"", hu->hdev->name,	       tty->termios.c_ispeed, tty->termios.c_ospeed);}",26614
352,960,CVE-2018-5344,19,"loop_get_status(struct loop_device *lo, struct loop_info64 *info){	struct file *file = lo->lo_backing_file;	struct kstat stat;	int error;	if (lo->lo_state != Lo_bound)		return -ENXIO;	error = vfs_getattr(&file->f_path, &stat,			    STATX_INO, AT_STATX_SYNC_AS_STAT);	if (error)		return error;	memset(info, 0, sizeof(*info));	info->lo_number = lo->lo_number;	info->lo_device = huge_encode_dev(stat.dev);	info->lo_inode = stat.ino;	info->lo_rdevice = huge_encode_dev(lo->lo_device ? stat.rdev : stat.dev);	info->lo_offset = lo->lo_offset;	info->lo_sizelimit = lo->lo_sizelimit;	info->lo_flags = lo->lo_flags;	memcpy(info->lo_file_name, lo->lo_file_name, LO_NAME_SIZE);	memcpy(info->lo_crypt_name, lo->lo_crypt_name, LO_NAME_SIZE);	info->lo_encrypt_type =		lo->lo_encryption ? lo->lo_encryption->number : 0;	if (lo->lo_encrypt_key_size && capable(CAP_SYS_ADMIN)) {		info->lo_encrypt_key_size = lo->lo_encrypt_key_size;		memcpy(info->lo_encrypt_key, lo->lo_encrypt_key,		       lo->lo_encrypt_key_size);	}	return 0;}",25507
126,180,CVE-2016-9120,19,"static struct ion_handle *ion_handle_create(struct ion_client *client,				     struct ion_buffer *buffer){	struct ion_handle *handle;	handle = kzalloc(sizeof(struct ion_handle), GFP_KERNEL);	if (!handle)		return ERR_PTR(-ENOMEM);	kref_init(&handle->ref);	RB_CLEAR_NODE(&handle->node);	handle->client = client;	ion_buffer_get(buffer);	ion_buffer_add_to_handle(buffer);	handle->buffer = buffer;	return handle;}",15266
294,1352,CVE-2018-20856,19,"void blk_requeue_request(struct request_queue *q, struct request *rq){	lockdep_assert_held(q->queue_lock);	WARN_ON_ONCE(q->mq_ops);	blk_delete_timer(rq);	blk_clear_rq_complete(rq);	trace_block_rq_requeue(q, rq);	rq_qos_requeue(q, rq);	if (rq->rq_flags & RQF_QUEUED)		blk_queue_end_tag(q, rq);	BUG_ON(blk_queued_rq(rq));	elv_requeue_request(q, rq);}",27501
102,1380,CVE-2018-20836,19,"static int sas_expander_discover(struct domain_device *dev){	struct expander_device *ex = &dev->ex_dev;	int res = -ENOMEM;	ex->ex_phy = kcalloc(ex->num_phys, sizeof(*ex->ex_phy), GFP_KERNEL);	if (!ex->ex_phy)		return -ENOMEM;	res = sas_ex_phy_discover(dev, -1);	if (res)		goto out_err;	return 0; out_err:	kfree(ex->ex_phy);	ex->ex_phy = NULL;	return res;}",27635
142,365,CVE-2016-4805,19,"int ppp_register_channel(struct ppp_channel *chan){	return ppp_register_net_channel(current->nsproxy->net_ns, chan);}",16672
283,27,CVE-2016-6290,19,"CACHE_LIMITER_FUNC(private)  {	ADD_HEADER(""Expires: Thu, 19 Nov 1981 08:52:00 GMT"");	CACHE_LIMITER(private_no_expire)(TSRMLS_C);} ",1691
364,624,CVE-2017-16525,19,void usb_serial_console_disconnect(struct usb_serial *serial){	if (serial->port[0] && serial->port[0] == usbcons_info.port) {		usb_serial_console_exit();		usb_serial_put(serial);	}},19886
192,644,CVE-2017-15265,19,"static int snd_seq_ioctl_remove_events(struct snd_seq_client *client,				       void *arg){	struct snd_seq_remove_events *info = arg;	 	if (info->remove_mode & SNDRV_SEQ_REMOVE_INPUT) {		 		if (client->type == USER_CLIENT && client->data.user.fifo)			snd_seq_fifo_clear(client->data.user.fifo);	}	if (info->remove_mode & SNDRV_SEQ_REMOVE_OUTPUT)		snd_seq_queue_remove_cells(client->number, info);	return 0;}",20034
161,637,CVE-2017-15265,19,"static int snd_seq_ioctl_get_queue_info(struct snd_seq_client *client,					void *arg){	struct snd_seq_queue_info *info = arg;	struct snd_seq_queue *q;	q = queueptr(info->queue);	if (q == NULL)		return -EINVAL;	memset(info, 0, sizeof(*info));	info->queue = q->queue;	info->owner = q->owner;	info->locked = q->locked;	strlcpy(info->name, q->name, sizeof(info->name));	queuefree(q);	return 0;}",20027
301,1428,CVE-2019-11487,19,"static unsigned long account_pipe_buffers(struct user_struct *user,                                 unsigned long old, unsigned long new){	return atomic_long_add_return(new - old, &user->pipe_bufs);}",28925
103,1393,CVE-2019-11487,19,"static void fuse_copy_init(struct fuse_copy_state *cs, int write,			   struct iov_iter *iter){	memset(cs, 0, sizeof(*cs));	cs->write = write;	cs->iter = iter;}",28890
42,616,CVE-2017-16527,19,"static int snd_usb_mixer_status_create(struct usb_mixer_interface *mixer){	struct usb_endpoint_descriptor *ep;	void *transfer_buffer;	int buffer_length;	unsigned int epnum;	 	if (get_iface_desc(mixer->hostif)->bNumEndpoints < 1)		return 0;	ep = get_endpoint(mixer->hostif, 0);	if (!usb_endpoint_dir_in(ep) || !usb_endpoint_xfer_int(ep))		return 0;	epnum = usb_endpoint_num(ep);	buffer_length = le16_to_cpu(ep->wMaxPacketSize);	transfer_buffer = kmalloc(buffer_length, GFP_KERNEL);	if (!transfer_buffer)		return -ENOMEM;	mixer->urb = usb_alloc_urb(0, GFP_KERNEL);	if (!mixer->urb) {		kfree(transfer_buffer);		return -ENOMEM;	}	usb_fill_int_urb(mixer->urb, mixer->chip->dev,			 usb_rcvintpipe(mixer->chip->dev, epnum),			 transfer_buffer, buffer_length,			 snd_usb_mixer_interrupt, mixer, ep->bInterval);	usb_submit_urb(mixer->urb, GFP_KERNEL);	return 0;}",19875
261,381,CVE-2016-3841,19,static void dccp_v6_reqsk_destructor(struct request_sock *req){	dccp_feat_list_purge(&dccp_rsk(req)->dreq_featneg);	kfree_skb(inet_rsk(req)->pktopts);},17153
282,774,CVE-2016-10200,19,"static int l2tp_ip6_backlog_recv(struct sock *sk, struct sk_buff *skb){	int rc;	 	rc = sock_queue_rcv_skb(sk, skb);	if (rc < 0)		goto drop;	return 0;drop:	IP_INC_STATS(sock_net(sk), IPSTATS_MIB_INDISCARDS);	kfree_skb(skb);	return -1;}",22341
333,1112,CVE-2019-15920,19,"add_durable_reconnect_v2_context(struct kvec *iov, unsigned int *num_iovec,		    struct cifs_open_parms *oparms){	struct smb2_create_req *req = iov[0].iov_base;	unsigned int num = *num_iovec;	 	oparms->reconnect = false;	iov[num].iov_base = create_reconnect_durable_v2_buf(oparms->fid);	if (iov[num].iov_base == NULL)		return -ENOMEM;	iov[num].iov_len = sizeof(struct create_durable_handle_reconnect_v2);	if (!req->CreateContextsOffset)		req->CreateContextsOffset =			cpu_to_le32(sizeof(struct smb2_create_req) +								iov[1].iov_len);	le32_add_cpu(&req->CreateContextsLength,			sizeof(struct create_durable_handle_reconnect_v2));	*num_iovec = num + 1;	return 0;}",26590
16,541,CVE-2017-16939,19,"static int xfrm_del_sa(struct sk_buff *skb, struct nlmsghdr *nlh,		struct nlattr **attrs){	struct net *net = sock_net(skb->sk);	struct xfrm_state *x;	int err = -ESRCH;	struct km_event c;	struct xfrm_usersa_id *p = nlmsg_data(nlh);	x = xfrm_user_state_lookup(net, p, attrs, &err);	if (x == NULL)		return err;	if ((err = security_xfrm_state_delete(x)) != 0)		goto out;	if (xfrm_state_kern(x)) {		err = -EPERM;		goto out;	}	err = xfrm_state_delete(x);	if (err < 0)		goto out;	c.seq = nlh->nlmsg_seq;	c.portid = nlh->nlmsg_pid;	c.event = nlh->nlmsg_type;	km_state_notify(x, &c);out:	xfrm_audit_state_delete(x, err ? 0 : 1, true);	xfrm_state_put(x);	return err;}",19634
175,1164,CVE-2019-11811,19,static struct ipmi_smi_msg *alloc_msg_handle_irq(struct smi_info *smi_info){	struct ipmi_smi_msg *msg;	msg = ipmi_alloc_smi_msg();	if (!msg) {		if (!disable_si_irq(smi_info))			smi_info->si_state = SI_NORMAL;	} else if (enable_si_irq(smi_info)) {		ipmi_free_smi_msg(msg);		msg = NULL;	}	return msg;},26927
122,1191,CVE-2019-11811,19,"static void set_maintenance_mode(void *send_info, int enable){	struct smi_info   *smi_info = send_info;	if (!enable)		atomic_set(&smi_info->req_events, 0);}",26954
174,409,CVE-2016-3841,19,"static int tcp_v6_md5_hash_skb(char *md5_hash,			       const struct tcp_md5sig_key *key,			       const struct sock *sk,			       const struct sk_buff *skb){	const struct in6_addr *saddr, *daddr;	struct tcp_md5sig_pool *hp;	struct hash_desc *desc;	const struct tcphdr *th = tcp_hdr(skb);	if (sk) {  		saddr = &sk->sk_v6_rcv_saddr;		daddr = &sk->sk_v6_daddr;	} else {		const struct ipv6hdr *ip6h = ipv6_hdr(skb);		saddr = &ip6h->saddr;		daddr = &ip6h->daddr;	}	hp = tcp_get_md5sig_pool();	if (!hp)		goto clear_hash_noput;	desc = &hp->md5_desc;	if (crypto_hash_init(desc))		goto clear_hash;	if (tcp_v6_md5_hash_pseudoheader(hp, daddr, saddr, skb->len))		goto clear_hash;	if (tcp_md5_hash_header(hp, th))		goto clear_hash;	if (tcp_md5_hash_skb_data(hp, skb, th->doff << 2))		goto clear_hash;	if (tcp_md5_hash_key(hp, key))		goto clear_hash;	if (crypto_hash_final(desc, md5_hash))		goto clear_hash;	tcp_put_md5sig_pool();	return 0;clear_hash:	tcp_put_md5sig_pool();clear_hash_noput:	memset(md5_hash, 0, 16);	return 1;}",17181
350,1491,CVE-2019-11487,19,"struct page *alloc_huge_page(struct vm_area_struct *vma,				    unsigned long addr, int avoid_reserve){	struct hugepage_subpool *spool = subpool_vma(vma);	struct hstate *h = hstate_vma(vma);	struct page *page;	long map_chg, map_commit;	long gbl_chg;	int ret, idx;	struct hugetlb_cgroup *h_cg;	idx = hstate_index(h);	 	map_chg = gbl_chg = vma_needs_reservation(h, vma, addr);	if (map_chg < 0)		return ERR_PTR(-ENOMEM);	 	if (map_chg || avoid_reserve) {		gbl_chg = hugepage_subpool_get_pages(spool, 1);		if (gbl_chg < 0) {			vma_end_reservation(h, vma, addr);			return ERR_PTR(-ENOSPC);		}		 		if (avoid_reserve)			gbl_chg = 1;	}	ret = hugetlb_cgroup_charge_cgroup(idx, pages_per_huge_page(h), &h_cg);	if (ret)		goto out_subpool_put;	spin_lock(&hugetlb_lock);	 	page = dequeue_huge_page_vma(h, vma, addr, avoid_reserve, gbl_chg);	if (!page) {		spin_unlock(&hugetlb_lock);		page = alloc_buddy_huge_page_with_mpol(h, vma, addr);		if (!page)			goto out_uncharge_cgroup;		if (!avoid_reserve && vma_has_reserves(vma, gbl_chg)) {			SetPagePrivate(page);			h->resv_huge_pages--;		}		spin_lock(&hugetlb_lock);		list_move(&page->lru, &h->hugepage_activelist);		 	}	hugetlb_cgroup_commit_charge(idx, pages_per_huge_page(h), h_cg, page);	spin_unlock(&hugetlb_lock);	set_page_private(page, (unsigned long)spool);	map_commit = vma_commit_reservation(h, vma, addr);	if (unlikely(map_chg > map_commit)) {		 		long rsv_adjust;		rsv_adjust = hugepage_subpool_put_pages(spool, 1);		hugetlb_acct_memory(h, -rsv_adjust);	}	return page;out_uncharge_cgroup:	hugetlb_cgroup_uncharge_cgroup(idx, pages_per_huge_page(h), h_cg);out_subpool_put:	if (map_chg || avoid_reserve)		hugepage_subpool_put_pages(spool, 1);	vma_end_reservation(h, vma, addr);	return ERR_PTR(-ENOSPC);}",28988
164,923,CVE-2018-16840,19,static unsigned int get_protocol_family(unsigned int protocol){  unsigned int family;  switch(protocol) {  case CURLPROTO_HTTP:  case CURLPROTO_HTTPS:    family = CURLPROTO_HTTP;    break;  case CURLPROTO_FTP:  case CURLPROTO_FTPS:    family = CURLPROTO_FTP;    break;  case CURLPROTO_SCP:    family = CURLPROTO_SCP;    break;  case CURLPROTO_SFTP:    family = CURLPROTO_SFTP;    break;  case CURLPROTO_TELNET:    family = CURLPROTO_TELNET;    break;  case CURLPROTO_LDAP:  case CURLPROTO_LDAPS:    family = CURLPROTO_LDAP;    break;  case CURLPROTO_DICT:    family = CURLPROTO_DICT;    break;  case CURLPROTO_FILE:    family = CURLPROTO_FILE;    break;  case CURLPROTO_TFTP:    family = CURLPROTO_TFTP;    break;  case CURLPROTO_IMAP:  case CURLPROTO_IMAPS:    family = CURLPROTO_IMAP;    break;  case CURLPROTO_POP3:  case CURLPROTO_POP3S:    family = CURLPROTO_POP3;    break;  case CURLPROTO_SMTP:  case CURLPROTO_SMTPS:      family = CURLPROTO_SMTP;      break;  case CURLPROTO_RTSP:    family = CURLPROTO_RTSP;    break;  case CURLPROTO_RTMP:  case CURLPROTO_RTMPS:    family = CURLPROTO_RTMP;    break;  case CURLPROTO_RTMPT:  case CURLPROTO_RTMPTS:    family = CURLPROTO_RTMPT;    break;  case CURLPROTO_RTMPE:    family = CURLPROTO_RTMPE;    break;  case CURLPROTO_RTMPTE:    family = CURLPROTO_RTMPTE;    break;  case CURLPROTO_GOPHER:    family = CURLPROTO_GOPHER;    break;  case CURLPROTO_SMB:  case CURLPROTO_SMBS:    family = CURLPROTO_SMB;    break;  default:      family = 0;      break;  }  return family;},24214
112,90,CVE-2014-0131,19,"int skb_to_sgvec(struct sk_buff *skb, struct scatterlist *sg, int offset, int len){	int nsg = __skb_to_sgvec(skb, sg, offset, len);	sg_mark_end(&sg[nsg - 1]);	return nsg;}",12262
292,133,CVE-2016-9794,19,"static int snd_interval_ratden(struct snd_interval *i,			       unsigned int rats_count,			       const struct snd_ratden *rats,			       unsigned int *nump, unsigned int *denp){	unsigned int best_num, best_diff, best_den;	unsigned int k;	struct snd_interval t;	int err;	best_num = best_den = best_diff = 0;	for (k = 0; k < rats_count; ++k) {		unsigned int num;		unsigned int den = rats[k].den;		unsigned int q = i->min;		int diff;		num = mul(q, den);		if (num > rats[k].num_max)			continue;		if (num < rats[k].num_min)			num = rats[k].num_max;		else {			unsigned int r;			r = (num - rats[k].num_min) % rats[k].num_step;			if (r != 0)				num += rats[k].num_step - r;		}		diff = num - q * den;		if (best_num == 0 ||		    diff * best_den < best_diff * den) {			best_diff = diff;			best_den = den;			best_num = num;		}	}	if (best_den == 0) {		i->empty = 1;		return -EINVAL;	}	t.min = div_down(best_num, best_den);	t.openmin = !!(best_num % best_den);		best_num = best_den = best_diff = 0;	for (k = 0; k < rats_count; ++k) {		unsigned int num;		unsigned int den = rats[k].den;		unsigned int q = i->max;		int diff;		num = mul(q, den);		if (num < rats[k].num_min)			continue;		if (num > rats[k].num_max)			num = rats[k].num_max;		else {			unsigned int r;			r = (num - rats[k].num_min) % rats[k].num_step;			if (r != 0)				num -= r;		}		diff = q * den - num;		if (best_num == 0 ||		    diff * best_den < best_diff * den) {			best_diff = diff;			best_den = den;			best_num = num;		}	}	if (best_den == 0) {		i->empty = 1;		return -EINVAL;	}	t.max = div_up(best_num, best_den);	t.openmax = !!(best_num % best_den);	t.integer = 0;	err = snd_interval_refine(i, &t);	if (err < 0)		return err;	if (snd_interval_single(i)) {		if (nump)			*nump = best_num;		if (denp)			*denp = best_den;	}	return err;}",15018
148,1558,CVE-2018-9476,19,"static void cleanup(int service_uuid) {  BTIF_TRACE_EVENT(""%s"", __func__);  btif_transfer_context(btif_av_handle_event, BTIF_AV_CLEANUP_REQ_EVT, NULL, 0,                        NULL);  btif_disable_service(service_uuid);  alarm_free(av_open_on_rc_timer);  av_open_on_rc_timer = NULL;    btif_sm_shutdown(btif_av_cb.sm_handle);  btif_av_cb.sm_handle = NULL;}",30797
24,797,CVE-2016-10150,19,"static int kvm_mmu_notifier_clear_flush_young(struct mmu_notifier *mn,					      struct mm_struct *mm,					      unsigned long start,					      unsigned long end){	struct kvm *kvm = mmu_notifier_to_kvm(mn);	int young, idx;	idx = srcu_read_lock(&kvm->srcu);	spin_lock(&kvm->mmu_lock);	young = kvm_age_hva(kvm, start, end);	if (young)		kvm_flush_remote_tlbs(kvm);	spin_unlock(&kvm->mmu_lock);	srcu_read_unlock(&kvm->srcu, idx);	return young;}",22513
139,1384,CVE-2019-11487,19,void __fuse_get_request(struct fuse_req *req){	refcount_inc(&req->count);},28881
276,1471,CVE-2019-11487,19,"static int __gup_device_huge(unsigned long pfn, unsigned long addr,		unsigned long end, struct page **pages, int *nr){	int nr_start = *nr;	struct dev_pagemap *pgmap = NULL;	do {		struct page *page = pfn_to_page(pfn);		pgmap = get_dev_pagemap(pfn, pgmap);		if (unlikely(!pgmap)) {			undo_dev_pagemap(nr, nr_start, pages);			return 0;		}		SetPageReferenced(page);		pages[*nr] = page;		get_page(page);		(*nr)++;		pfn++;	} while (addr += PAGE_SIZE, addr != end);	if (pgmap)		put_dev_pagemap(pgmap);	return 1;}",28968
325,1535,CVE-2016-5216,19,void ShutdownSDK() {  FPDF_DestroyLibrary();  TearDownV8();},29932
141,855,CVE-2014-9940,19,"static int regulator_check_drms(struct regulator_dev *rdev){	if (!rdev->constraints) {		rdev_err(rdev, ""no constraints\n"");		return -ENODEV;	}	if (!(rdev->constraints->valid_ops_mask & REGULATOR_CHANGE_DRMS)) {		rdev_err(rdev, ""operation not allowed\n"");		return -EPERM;	}	return 0;}",23016
204,201,CVE-2016-8655,19,"static int __packet_rcv_has_room(struct packet_sock *po, struct sk_buff *skb){	struct sock *sk = &po->sk;	int ret = ROOM_NONE;	if (po->prot_hook.func != tpacket_rcv) {		int avail = sk->sk_rcvbuf - atomic_read(&sk->sk_rmem_alloc)					  - (skb ? skb->truesize : 0);		if (avail > (sk->sk_rcvbuf >> ROOM_POW_OFF))			return ROOM_NORMAL;		else if (avail > 0)			return ROOM_LOW;		else			return ROOM_NONE;	}	if (po->tp_version == TPACKET_V3) {		if (__tpacket_v3_has_room(po, ROOM_POW_OFF))			ret = ROOM_NORMAL;		else if (__tpacket_v3_has_room(po, 0))			ret = ROOM_LOW;	} else {		if (__tpacket_has_room(po, ROOM_POW_OFF))			ret = ROOM_NORMAL;		else if (__tpacket_has_room(po, 0))			ret = ROOM_LOW;	}	return ret;}",15483
210,74,CVE-2014-0131,19,"static void skb_over_panic(struct sk_buff *skb, unsigned int sz, void *addr){	skb_panic(skb, sz, addr, __func__);}",12246
69,391,CVE-2016-3841,19,"static int ip6_tlvopt_unknown(struct sk_buff *skb, int optoff){	switch ((skb_network_header(skb)[optoff] & 0xC0) >> 6) {	case 0:  		return true;	case 1:  		break;	case 3:  		 		if (ipv6_addr_is_multicast(&ipv6_hdr(skb)->daddr))			break;	case 2:  		icmpv6_param_prob(skb, ICMPV6_UNK_OPTION, optoff);		return false;	}	kfree_skb(skb);	return false;}",17163
295,1016,CVE-2017-18218,19,"static void hns_nic_service_timer(unsigned long data){	struct hns_nic_priv *priv = (struct hns_nic_priv *)data;	(void)mod_timer(&priv->service_timer, jiffies + SERVICE_TIMER_HZ);	hns_nic_task_schedule(priv);}",25866
46,998,CVE-2017-18218,19,"static int hns_nic_maybe_stop_tx(	struct sk_buff **out_skb, int *bnum, struct hnae_ring *ring){	struct sk_buff *skb = *out_skb;	struct sk_buff *new_skb = NULL;	int buf_num;	 	buf_num = skb_shinfo(skb)->nr_frags + 1;	if (unlikely(buf_num > ring->max_desc_num_per_pkt)) {		if (ring_space(ring) < 1)			return -EBUSY;		new_skb = skb_copy(skb, GFP_ATOMIC);		if (!new_skb)			return -ENOMEM;		dev_kfree_skb_any(skb);		*out_skb = new_skb;		buf_num = 1;	} else if (buf_num > ring_space(ring)) {		return -EBUSY;	}	*bnum = buf_num;	return 0;}",25848
63,620,CVE-2017-16527,19,"static void usb_mixer_selector_elem_free(struct snd_kcontrol *kctl){	int i, num_ins = 0;	if (kctl->private_data) {		struct usb_mixer_elem_info *cval = kctl->private_data;		num_ins = cval->max;		kfree(cval);		kctl->private_data = NULL;	}	if (kctl->private_value) {		char **itemlist = (char **)kctl->private_value;		for (i = 0; i < num_ins; i++)			kfree(itemlist[i]);		kfree(itemlist);		kctl->private_value = 0;	}}",19879
225,299,CVE-2016-7912,19,"static int functionfs_bind(struct ffs_data *ffs, struct usb_composite_dev *cdev){	struct usb_gadget_strings **lang;	int first_id;	ENTER();	if (WARN_ON(ffs->state != FFS_ACTIVE		 || test_and_set_bit(FFS_FL_BOUND, &ffs->flags)))		return -EBADFD;	first_id = usb_string_ids_n(cdev, ffs->strings_count);	if (unlikely(first_id < 0))		return first_id;	ffs->ep0req = usb_ep_alloc_request(cdev->gadget->ep0, GFP_KERNEL);	if (unlikely(!ffs->ep0req))		return -ENOMEM;	ffs->ep0req->complete = ffs_ep0_complete;	ffs->ep0req->context = ffs;	lang = ffs->stringtabs;	if (lang) {		for (; *lang; ++lang) {			struct usb_string *str = (*lang)->strings;			int id = first_id;			for (; str->s; ++id, ++str)				str->id = id;		}	}	ffs->gadget = cdev->gadget;	ffs_data_get(ffs);	return 0;}",15733
270,334,CVE-2016-7910,19,"static void register_disk(struct device *parent, struct gendisk *disk){	struct device *ddev = disk_to_dev(disk);	struct block_device *bdev;	struct disk_part_iter piter;	struct hd_struct *part;	int err;	ddev->parent = parent;	dev_set_name(ddev, ""%s"", disk->disk_name);	 	dev_set_uevent_suppress(ddev, 1);	if (device_add(ddev))		return;	if (!sysfs_deprecated) {		err = sysfs_create_link(block_depr, &ddev->kobj,					kobject_name(&ddev->kobj));		if (err) {			device_del(ddev);			return;		}	}	 	pm_runtime_set_memalloc_noio(ddev, true);	disk->part0.holder_dir = kobject_create_and_add(""holders"", &ddev->kobj);	disk->slave_dir = kobject_create_and_add(""slaves"", &ddev->kobj);	 	if (!disk_part_scan_enabled(disk))		goto exit;	 	if (!get_capacity(disk))		goto exit;	bdev = bdget_disk(disk, 0);	if (!bdev)		goto exit;	bdev->bd_invalidated = 1;	err = blkdev_get(bdev, FMODE_READ, NULL);	if (err < 0)		goto exit;	blkdev_put(bdev, FMODE_READ);exit:	 	dev_set_uevent_suppress(ddev, 0);	kobject_uevent(&ddev->kobj, KOBJ_ADD);	 	disk_part_iter_init(&piter, disk, 0);	while ((part = disk_part_iter_next(&piter)))		kobject_uevent(&part_to_dev(part)->kobj, KOBJ_ADD);	disk_part_iter_exit(&piter);}",15768
156,707,CVE-2017-11176,19,"static int mqueue_unlink(struct inode *dir, struct dentry *dentry){	struct inode *inode = d_inode(dentry);	dir->i_ctime = dir->i_mtime = dir->i_atime = current_time(dir);	dir->i_size -= DIRENT_SIZE;	drop_nlink(inode);	dput(dentry);	return 0;}",20556
223,1289,CVE-2019-9003,19,"int ipmi_set_my_address(struct ipmi_user *user,			unsigned int  channel,			unsigned char address){	int index, rv = 0;	user = acquire_ipmi_user(user, &index);	if (!user)		return -ENODEV;	if (channel >= IPMI_MAX_CHANNELS) {		rv = -EINVAL;	} else {		channel = array_index_nospec(channel, IPMI_MAX_CHANNELS);		user->intf->addrinfo[channel].address = address;	}	release_ipmi_user(user, index);	return rv;}",27266
60,1392,CVE-2019-11487,19,static void fuse_copy_finish(struct fuse_copy_state *cs){	if (cs->currbuf) {		struct pipe_buffer *buf = cs->currbuf;		if (cs->write)			buf->len = PAGE_SIZE - cs->len;		cs->currbuf = NULL;	} else if (cs->pg) {		if (cs->write) {			flush_dcache_page(cs->pg);			set_page_dirty_lock(cs->pg);		}		put_page(cs->pg);	}	cs->pg = NULL;},28889
51,48,CVE-2014-0131,19,"static int __splice_segment(struct page *page, unsigned int poff,			     unsigned int plen, unsigned int *off,			     unsigned int *len,			     struct splice_pipe_desc *spd, int linear,			     struct sock *sk,			     struct pipe_inode_info *pipe){	if (!*len)		return true;	 	if (*off >= plen) {		*off -= plen;		return false;	}	 	poff += *off;	plen -= *off;	*off = 0;	do {		unsigned int flen = min(*len, plen);		if (spd_fill_page(spd, pipe, page, &flen, poff,				  linear, sk))			return true;		poff += flen;		plen -= flen;		*len -= flen;	} while (*len && plen);	return false;}",12220
222,543,CVE-2017-16939,19,"static int xfrm_exp_policy_notify(struct xfrm_policy *xp, int dir, const struct km_event *c){	struct net *net = xp_net(xp);	struct sk_buff *skb;	skb = nlmsg_new(xfrm_polexpire_msgsize(xp), GFP_ATOMIC);	if (skb == NULL)		return -ENOMEM;	if (build_polexpire(skb, xp, dir, c) < 0)		BUG();	return xfrm_nlmsg_multicast(net, skb, 0, XFRMNLGRP_EXPIRE);}",19636
91,241,CVE-2016-8655,19,"static int tpacket_parse_header(struct packet_sock *po, void *frame,				int size_max, void **data){	union tpacket_uhdr ph;	int tp_len, off;	ph.raw = frame;	switch (po->tp_version) {	case TPACKET_V2:		tp_len = ph.h2->tp_len;		break;	default:		tp_len = ph.h1->tp_len;		break;	}	if (unlikely(tp_len > size_max)) {		pr_err(""packet size is too long (%d > %d)\n"", tp_len, size_max);		return -EMSGSIZE;	}	if (unlikely(po->tp_tx_has_off)) {		int off_min, off_max;		off_min = po->tp_hdrlen - sizeof(struct sockaddr_ll);		off_max = po->tx_ring.frame_size - tp_len;		if (po->sk.sk_type == SOCK_DGRAM) {			switch (po->tp_version) {			case TPACKET_V2:				off = ph.h2->tp_net;				break;			default:				off = ph.h1->tp_net;				break;			}		} else {			switch (po->tp_version) {			case TPACKET_V2:				off = ph.h2->tp_mac;				break;			default:				off = ph.h1->tp_mac;				break;			}		}		if (unlikely((off < off_min) || (off_max < off)))			return -EINVAL;	} else {		off = po->tp_hdrlen - sizeof(struct sockaddr_ll);	}	*data = frame + off;	return tp_len;}",15523
70,46,CVE-2014-0131,19,"unsigned char *__pskb_pull_tail(struct sk_buff *skb, int delta){	 	int i, k, eat = (skb->tail + delta) - skb->end;	if (eat > 0 || skb_cloned(skb)) {		if (pskb_expand_head(skb, 0, eat > 0 ? eat + 128 : 0,				     GFP_ATOMIC))			return NULL;	}	if (skb_copy_bits(skb, skb_headlen(skb), skb_tail_pointer(skb), delta))		BUG();	 	if (!skb_has_frag_list(skb))		goto pull_pages;	 	eat = delta;	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {		int size = skb_frag_size(&skb_shinfo(skb)->frags[i]);		if (size >= eat)			goto pull_pages;		eat -= size;	}	 	if (eat) {		struct sk_buff *list = skb_shinfo(skb)->frag_list;		struct sk_buff *clone = NULL;		struct sk_buff *insp = NULL;		do {			BUG_ON(!list);			if (list->len <= eat) {				 				eat -= list->len;				list = list->next;				insp = list;			} else {				 				if (skb_shared(list)) {					 					clone = skb_clone(list, GFP_ATOMIC);					if (!clone)						return NULL;					insp = list->next;					list = clone;				} else {					 					insp = list;				}				if (!pskb_pull(list, eat)) {					kfree_skb(clone);					return NULL;				}				break;			}		} while (eat);		 		while ((list = skb_shinfo(skb)->frag_list) != insp) {			skb_shinfo(skb)->frag_list = list->next;			kfree_skb(list);		}		 		if (clone) {			clone->next = list;			skb_shinfo(skb)->frag_list = clone;		}	}	 pull_pages:	eat = delta;	k = 0;	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {		int size = skb_frag_size(&skb_shinfo(skb)->frags[i]);		if (size <= eat) {			skb_frag_unref(skb, i);			eat -= size;		} else {			skb_shinfo(skb)->frags[k] = skb_shinfo(skb)->frags[i];			if (eat) {				skb_shinfo(skb)->frags[k].page_offset += eat;				skb_frag_size_sub(&skb_shinfo(skb)->frags[k], eat);				eat = 0;			}			k++;		}	}	skb_shinfo(skb)->nr_frags = k;	skb->tail     += delta;	skb->data_len -= delta;	return skb_tail_pointer(skb);}",12218
318,217,CVE-2016-8655,19,static struct net_device *packet_cached_dev_get(struct packet_sock *po){	struct net_device *dev;	rcu_read_lock();	dev = rcu_dereference(po->cached_dev);	if (likely(dev))		dev_hold(dev);	rcu_read_unlock();	return dev;},15499
386,1469,CVE-2019-11487,19,"static int wait_on_pipe(struct trace_iterator *iter, int full){	 	if (trace_buffer_iter(iter, iter->cpu_file))		return 0;	return ring_buffer_wait(iter->trace_buffer->buffer, iter->cpu_file,				full);}",28966
236,986,CVE-2017-18218,19,"static void hns_init_mac_addr(struct net_device *ndev){	struct hns_nic_priv *priv = netdev_priv(ndev);	if (!device_get_mac_address(priv->dev, ndev->dev_addr, ETH_ALEN)) {		eth_hw_addr_random(ndev);		dev_warn(priv->dev, ""No valid mac, use random mac %pM"",			 ndev->dev_addr);	}}",25836
39,62,CVE-2015-1573,3,"static int nf_tables_loop_check_setelem(const struct nft_ctx *ctx,					const struct nft_set *set,					const struct nft_set_iter *iter,					const struct nft_set_elem *elem){	if (elem->flags & NFT_SET_ELEM_INTERVAL_END)		return 0;	switch (elem->data.verdict) {	case NFT_JUMP:	case NFT_GOTO:		return nf_tables_check_loops(ctx, elem->data.chain);	default:		return 0;	}}",19158
19,112,CVE-2015-1573,3,static void nft_verdict_uninit(const struct nft_data *data){	switch (data->verdict) {	case NFT_JUMP:	case NFT_GOTO:		data->chain->use--;		break;	}},19208
41,130,CVE-2006-5331,3,platform_machine_check(struct pt_regs *regs){},23153
3,121,CVE-2006-5331,3,"void SMIException(struct pt_regs *regs){	die(""System Management Interrupt"", regs, SIGABRT);}",23144
35,51,CVE-2015-1573,3,"static void nf_tables_expr_destroy(const struct nft_ctx *ctx,				   struct nft_expr *expr){	if (expr->ops->destroy)		expr->ops->destroy(ctx, expr);	module_put(expr->ops->type->owner);}",19147
23,20,CVE-2016-7117,3,"struct socket *sock_alloc(void){	struct inode *inode;	struct socket *sock;	inode = new_inode_pseudo(sock_mnt->mnt_sb);	if (!inode)		return NULL;	sock = SOCKET_I(inode);	kmemcheck_annotate_bitfield(sock, type);	inode->i_ino = get_next_ino();	inode->i_mode = S_IFSOCK | S_IRWXUGO;	inode->i_uid = current_fsuid();	inode->i_gid = current_fsgid();	inode->i_op = &sockfs_inode_ops;	this_cpu_add(sockets_in_use, 1);	return sock;}",15862
34,60,CVE-2015-1573,3,"static int nf_tables_gettable(struct sock *nlsk, struct sk_buff *skb,			      const struct nlmsghdr *nlh,			      const struct nlattr * const nla[]){	const struct nfgenmsg *nfmsg = nlmsg_data(nlh);	const struct nft_af_info *afi;	const struct nft_table *table;	struct sk_buff *skb2;	struct net *net = sock_net(skb->sk);	int family = nfmsg->nfgen_family;	int err;	if (nlh->nlmsg_flags & NLM_F_DUMP) {		struct netlink_dump_control c = {			.dump = nf_tables_dump_tables,		};		return netlink_dump_start(nlsk, skb, nlh, &c);	}	afi = nf_tables_afinfo_lookup(net, family, false);	if (IS_ERR(afi))		return PTR_ERR(afi);	table = nf_tables_table_lookup(afi, nla[NFTA_TABLE_NAME]);	if (IS_ERR(table))		return PTR_ERR(table);	if (table->flags & NFT_TABLE_INACTIVE)		return -ENOENT;	skb2 = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);	if (!skb2)		return -ENOMEM;	err = nf_tables_fill_table_info(skb2, net, NETLINK_CB(skb).portid,					nlh->nlmsg_seq, NFT_MSG_NEWTABLE, 0,					family, table);	if (err < 0)		goto err;	return nlmsg_unicast(nlsk, skb2, NETLINK_CB(skb).portid);err:	kfree_skb(skb2);	return err;}",19156
38,70,CVE-2015-1573,3,"static struct nft_table *nf_tables_table_lookup(const struct nft_af_info *afi,						const struct nlattr *nla){	struct nft_table *table;	if (nla == NULL)		return ERR_PTR(-EINVAL);	table = nft_table_lookup(afi, nla);	if (table != NULL)		return table;	return ERR_PTR(-ENOENT);}",19166
26,141,CVE-2015-8952,3,"static struct dentry *ext2_mount(struct file_system_type *fs_type,	int flags, const char *dev_name, void *data){	return mount_bdev(fs_type, flags, dev_name, data, ext2_fill_super);}",28446
20,36,CVE-2016-2085,3,"int evm_inode_setattr(struct dentry *dentry, struct iattr *attr){	unsigned int ia_valid = attr->ia_valid;	enum integrity_status evm_status;	if (!(ia_valid & (ATTR_MODE | ATTR_UID | ATTR_GID)))		return 0;	evm_status = evm_verify_current_integrity(dentry);	if ((evm_status == INTEGRITY_PASS) ||	    (evm_status == INTEGRITY_NOXATTRS))		return 0;	integrity_audit_msg(AUDIT_INTEGRITY_METADATA, d_backing_inode(dentry),			    dentry->d_name.name, ""appraise_metadata"",			    integrity_status_msg[evm_status], -EPERM, 0);	return -EPERM;}",17995
21,24,CVE-2016-7117,3,"int sock_register(const struct net_proto_family *ops){	int err;	if (ops->family >= NPROTO) {		pr_crit(""protocol %d >= NPROTO(%d)\n"", ops->family, NPROTO);		return -ENOBUFS;	}	spin_lock(&net_family_lock);	if (rcu_dereference_protected(net_families[ops->family],				      lockdep_is_held(&net_family_lock)))		err = -EEXIST;	else {		rcu_assign_pointer(net_families[ops->family], ops);		err = 0;	}	spin_unlock(&net_family_lock);	pr_info(""NET: Registered protocol family %d\n"", ops->family);	return err;}",15866
22,139,CVE-2015-8952,3,"static int ext2_freeze(struct super_block *sb){	struct ext2_sb_info *sbi = EXT2_SB(sb);	 	if (atomic_long_read(&sb->s_remove_count)) {		ext2_sync_fs(sb, 1);		return 0;	}	 	spin_lock(&sbi->s_lock);	sbi->s_es->s_state = cpu_to_le16(sbi->s_mount_state);	spin_unlock(&sbi->s_lock);	ext2_sync_super(sb, sbi->s_es, 1);	return 0;}",28444
0,86,CVE-2015-1573,3,"static int nft_deltable(struct nft_ctx *ctx){	int err;	err = nft_trans_table_add(ctx, NFT_MSG_DELTABLE);	if (err < 0)		return err;	list_del_rcu(&ctx->table->list);	return err;}",19182
10,45,CVE-2015-1573,3,"static void nf_tables_commit_release(struct nft_trans *trans){	switch (trans->msg_type) {	case NFT_MSG_DELTABLE:		nf_tables_table_destroy(&trans->ctx);		break;	case NFT_MSG_DELCHAIN:		nf_tables_chain_destroy(trans->ctx.chain);		break;	case NFT_MSG_DELRULE:		nf_tables_rule_destroy(&trans->ctx, nft_trans_rule(trans));		break;	case NFT_MSG_DELSET:		nft_set_destroy(nft_trans_set(trans));		break;	}	kfree(trans);}",19141
32,14,CVE-2015-0274,3,"xfs_attr_leaf_newentsize(int namelen, int valuelen, int blocksize, int *local){	int size;	size = xfs_attr_leaf_entsize_local(namelen, valuelen);	if (size < xfs_attr_leaf_entsize_local_max(blocksize)) {		if (local) {			*local = 1;		}	} else {		size = xfs_attr_leaf_entsize_remote(namelen);		if (local) {			*local = 0;		}	}	return size;}",14091
24,117,CVE-2014-9803,3,"void show_pte(struct mm_struct *mm, unsigned long addr){	pgd_t *pgd;	if (!mm)		mm = &init_mm;	pr_alert(""pgd = %p\n"", mm->pgd);	pgd = pgd_offset(mm, addr);	pr_alert(""[%08lx] *pgd=%016llx"", addr, pgd_val(*pgd));	do {		pud_t *pud;		pmd_t *pmd;		pte_t *pte;		if (pgd_none(*pgd) || pgd_bad(*pgd))			break;		pud = pud_offset(pgd, addr);		if (pud_none(*pud) || pud_bad(*pud))			break;		pmd = pmd_offset(pud, addr);		printk("", *pmd=%016llx"", pmd_val(*pmd));		if (pmd_none(*pmd) || pmd_bad(*pmd))			break;		pte = pte_offset_map(pmd, addr);		printk("", *pte=%016llx"", pte_val(*pte));		pte_unmap(pte);	} while(0);	printk(""\n"");}",19347
17,122,CVE-2006-5331,3,"void SPEFloatingPointException(struct pt_regs *regs){	unsigned long spefscr;	int fpexc_mode;	int code = 0;	spefscr = current->thread.spefscr;	fpexc_mode = current->thread.fpexc_mode;	 	if ((spefscr & SPEFSCR_FOVF) && (fpexc_mode & PR_FP_EXC_OVF)) {		code = FPE_FLTOVF;		spefscr |= SPEFSCR_FOVFS;	}	else if ((spefscr & SPEFSCR_FUNF) && (fpexc_mode & PR_FP_EXC_UND)) {		code = FPE_FLTUND;		spefscr |= SPEFSCR_FUNFS;	}	else if ((spefscr & SPEFSCR_FDBZ) && (fpexc_mode & PR_FP_EXC_DIV))		code = FPE_FLTDIV;	else if ((spefscr & SPEFSCR_FINV) && (fpexc_mode & PR_FP_EXC_INV)) {		code = FPE_FLTINV;		spefscr |= SPEFSCR_FINVS;	}	else if ((spefscr & (SPEFSCR_FG | SPEFSCR_FX)) && (fpexc_mode & PR_FP_EXC_RES))		code = FPE_FLTRES;	current->thread.spefscr = spefscr;	_exception(SIGFPE, regs, code, regs->nip);	return;}",23145
29,46,CVE-2015-1573,3,"static int nf_tables_delchain(struct sock *nlsk, struct sk_buff *skb,			      const struct nlmsghdr *nlh,			      const struct nlattr * const nla[]){	const struct nfgenmsg *nfmsg = nlmsg_data(nlh);	struct nft_af_info *afi;	struct nft_table *table;	struct nft_chain *chain;	struct net *net = sock_net(skb->sk);	int family = nfmsg->nfgen_family;	struct nft_ctx ctx;	afi = nf_tables_afinfo_lookup(net, family, false);	if (IS_ERR(afi))		return PTR_ERR(afi);	table = nf_tables_table_lookup(afi, nla[NFTA_CHAIN_TABLE]);	if (IS_ERR(table))		return PTR_ERR(table);	if (table->flags & NFT_TABLE_INACTIVE)		return -ENOENT;	chain = nf_tables_chain_lookup(table, nla[NFTA_CHAIN_NAME]);	if (IS_ERR(chain))		return PTR_ERR(chain);	if (chain->flags & NFT_CHAIN_INACTIVE)		return -ENOENT;	if (chain->use > 0)		return -EBUSY;	nft_ctx_init(&ctx, skb, nlh, afi, table, chain, nla);	return nft_delchain(&ctx);}",19142
4,2,CVE-2015-0274,3,"xfs_attr3_leaf_add(	struct xfs_buf		*bp,	struct xfs_da_args	*args){	struct xfs_attr_leafblock *leaf;	struct xfs_attr3_icleaf_hdr ichdr;	int			tablesize;	int			entsize;	int			sum;	int			tmp;	int			i;	trace_xfs_attr_leaf_add(args);	leaf = bp->b_addr;	xfs_attr3_leaf_hdr_from_disk(&ichdr, leaf);	ASSERT(args->index >= 0 && args->index <= ichdr.count);	entsize = xfs_attr_leaf_newentsize(args->namelen, args->valuelen,			   args->trans->t_mountp->m_sb.sb_blocksize, NULL);	 	tablesize = (ichdr.count + 1) * sizeof(xfs_attr_leaf_entry_t)					+ xfs_attr3_leaf_hdr_size(leaf);	for (sum = 0, i = XFS_ATTR_LEAF_MAPSIZE - 1; i >= 0; i--) {		if (tablesize > ichdr.firstused) {			sum += ichdr.freemap[i].size;			continue;		}		if (!ichdr.freemap[i].size)			continue;	 		tmp = entsize;		if (ichdr.freemap[i].base < ichdr.firstused)			tmp += sizeof(xfs_attr_leaf_entry_t);		if (ichdr.freemap[i].size >= tmp) {			tmp = xfs_attr3_leaf_add_work(bp, &ichdr, args, i);			goto out_log_hdr;		}		sum += ichdr.freemap[i].size;	}	 	if (!ichdr.holes && sum < entsize)		return XFS_ERROR(ENOSPC);	 	xfs_attr3_leaf_compact(args, &ichdr, bp);	 	if (ichdr.freemap[0].size < (entsize + sizeof(xfs_attr_leaf_entry_t))) {		tmp = ENOSPC;		goto out_log_hdr;	}	tmp = xfs_attr3_leaf_add_work(bp, &ichdr, args, 0);out_log_hdr:	xfs_attr3_leaf_hdr_to_disk(leaf, &ichdr);	xfs_trans_log_buf(args->trans, bp,		XFS_DA_LOGRANGE(leaf, &leaf->hdr,				xfs_attr3_leaf_hdr_size(leaf)));	return tmp;}",14079
11,103,CVE-2015-1573,3,void nft_unregister_chain_type(const struct nf_chain_type *ctype){	nfnl_lock(NFNL_SUBSYS_NFTABLES);	chain_type[ctype->family][ctype->type] = NULL;	nfnl_unlock(NFNL_SUBSYS_NFTABLES);},19199
25,151,CVE-2015-8952,3,"static int ext4_enable_quotas(struct super_block *sb){	int type, err = 0;	unsigned long qf_inums[EXT4_MAXQUOTAS] = {		le32_to_cpu(EXT4_SB(sb)->s_es->s_usr_quota_inum),		le32_to_cpu(EXT4_SB(sb)->s_es->s_grp_quota_inum),		le32_to_cpu(EXT4_SB(sb)->s_es->s_prj_quota_inum)	};	sb_dqopt(sb)->flags |= DQUOT_QUOTA_SYS_FILE;	for (type = 0; type < EXT4_MAXQUOTAS; type++) {		if (qf_inums[type]) {			err = ext4_quota_enable(sb, type, QFMT_VFS_V1,						DQUOT_USAGE_ENABLED);			if (err) {				ext4_warning(sb,					""Failed to enable quota tracking ""					""(type=%d, err=%d). Please run ""					""e2fsck to fix."", type, err);				return err;			}		}	}	return 0;}",28456
13,5,CVE-2015-0274,3,"xfs_attr3_leaf_order(	struct xfs_buf	*leaf1_bp,	struct xfs_attr3_icleaf_hdr *leaf1hdr,	struct xfs_buf	*leaf2_bp,	struct xfs_attr3_icleaf_hdr *leaf2hdr){	struct xfs_attr_leaf_entry *entries1;	struct xfs_attr_leaf_entry *entries2;	entries1 = xfs_attr3_leaf_entryp(leaf1_bp->b_addr);	entries2 = xfs_attr3_leaf_entryp(leaf2_bp->b_addr);	if (leaf1hdr->count > 0 && leaf2hdr->count > 0 &&	    ((be32_to_cpu(entries2[0].hashval) <	      be32_to_cpu(entries1[0].hashval)) ||	     (be32_to_cpu(entries2[leaf2hdr->count - 1].hashval) <	      be32_to_cpu(entries1[leaf1hdr->count - 1].hashval)))) {		return 1;	}	return 0;}",14082
15,77,CVE-2015-1573,3,"static int nft_ctx_init_from_elemattr(struct nft_ctx *ctx,				      const struct sk_buff *skb,				      const struct nlmsghdr *nlh,				      const struct nlattr * const nla[],				      int trans){	const struct nfgenmsg *nfmsg = nlmsg_data(nlh);	struct nft_af_info *afi;	struct nft_table *table;	struct net *net = sock_net(skb->sk);	afi = nf_tables_afinfo_lookup(net, nfmsg->nfgen_family, false);	if (IS_ERR(afi))		return PTR_ERR(afi);	table = nf_tables_table_lookup(afi, nla[NFTA_SET_ELEM_LIST_TABLE]);	if (IS_ERR(table))		return PTR_ERR(table);	if (!trans && (table->flags & NFT_TABLE_INACTIVE))		return -ENOENT;	nft_ctx_init(ctx, skb, nlh, afi, table, NULL, nla);	return 0;}",19173
12,42,CVE-2015-1573,3,"static int nf_tables_bind_check_setelem(const struct nft_ctx *ctx,					const struct nft_set *set,					const struct nft_set_iter *iter,					const struct nft_set_elem *elem){	enum nft_registers dreg;	dreg = nft_type_to_reg(set->dtype);	return nft_validate_data_load(ctx, dreg, &elem->data,				      set->dtype == NFT_DATA_VERDICT ?				      NFT_DATA_VERDICT : NFT_DATA_VALUE);}",19138
18,94,CVE-2015-1573,3,"nft_rule_is_active_next(struct net *net, const struct nft_rule *rule){	return (rule->genmask & (1 << gencursor_next(net))) == 0;}",19190
5,126,CVE-2006-5331,3,struct bug_entry *find_bug(unsigned long bugaddr){	struct bug_entry *bug;	for (bug = __start___bug_table; bug < __stop___bug_table; ++bug)		if (bugaddr == bug->bug_addr)			return bug;	return module_find_bug(bugaddr);},23149
7,102,CVE-2015-1573,3,void nft_unregister_afinfo(struct nft_af_info *afi){	nfnl_lock(NFNL_SUBSYS_NFTABLES);	list_del_rcu(&afi->list);	nfnl_unlock(NFNL_SUBSYS_NFTABLES);},19198
8,27,CVE-2016-7117,3,"void sock_unregister(int family){	BUG_ON(family < 0 || family >= NPROTO);	spin_lock(&net_family_lock);	RCU_INIT_POINTER(net_families[family], NULL);	spin_unlock(&net_family_lock);	synchronize_rcu();	pr_info(""NET: Unregistered protocol family %d\n"", family);}",15869
33,156,CVE-2015-8952,3,"ext4_xattr_cmp(struct ext4_xattr_header *header1,	       struct ext4_xattr_header *header2){	struct ext4_xattr_entry *entry1, *entry2;	entry1 = ENTRY(header1+1);	entry2 = ENTRY(header2+1);	while (!IS_LAST_ENTRY(entry1)) {		if (IS_LAST_ENTRY(entry2))			return 1;		if (entry1->e_hash != entry2->e_hash ||		    entry1->e_name_index != entry2->e_name_index ||		    entry1->e_name_len != entry2->e_name_len ||		    entry1->e_value_size != entry2->e_value_size ||		    memcmp(entry1->e_name, entry2->e_name, entry1->e_name_len))			return 1;		if (entry1->e_value_block != 0 || entry2->e_value_block != 0)			return -EFSCORRUPTED;		if (memcmp((char *)header1 + le16_to_cpu(entry1->e_value_offs),			   (char *)header2 + le16_to_cpu(entry2->e_value_offs),			   le32_to_cpu(entry1->e_value_size)))			return 1;		entry1 = EXT4_XATTR_NEXT(entry1);		entry2 = EXT4_XATTR_NEXT(entry2);	}	if (!IS_LAST_ENTRY(entry2))		return 1;	return 0;}",28461
16,16,CVE-2015-0274,3,"xfs_attr_namesp_match(int arg_flags, int ondisk_flags){	return XFS_ATTR_NSP_ONDISK(ondisk_flags) == XFS_ATTR_NSP_ARGS_TO_ONDISK(arg_flags);}",14093
1,34,CVE-2016-2085,3,"void evm_inode_post_setattr(struct dentry *dentry, int ia_valid){	if (!evm_initialized)		return;	if (ia_valid & (ATTR_MODE | ATTR_UID | ATTR_GID))		evm_update_evmxattr(dentry, NULL, NULL, 0);}",17993
14,26,CVE-2016-7117,3,"static inline int sock_sendmsg_nosec(struct socket *sock, struct msghdr *msg){	int ret = sock->ops->sendmsg(sock, msg, msg_data_left(msg));	BUG_ON(ret == -EIOCBQUEUED);	return ret;}",15868
28,39,CVE-2016-2085,3,"static enum integrity_status evm_verify_current_integrity(struct dentry *dentry){	struct inode *inode = d_backing_inode(dentry);	if (!evm_initialized || !S_ISREG(inode->i_mode) || evm_fixmode)		return 0;	return evm_verify_hmac(dentry, NULL, NULL, 0, NULL);}",17998
31,63,CVE-2015-1573,3,"static int nf_tables_newexpr(const struct nft_ctx *ctx,			     const struct nft_expr_info *info,			     struct nft_expr *expr){	const struct nft_expr_ops *ops = info->ops;	int err;	expr->ops = ops;	if (ops->init) {		err = ops->init(ctx, expr, (const struct nlattr **)info->tb);		if (err < 0)			goto err1;	}	return 0;err1:	expr->ops = NULL;	return err;}",19159
37,164,CVE-2015-0274,3,"xfs_attr3_leaf_add_work(	struct xfs_buf		*bp,	struct xfs_attr3_icleaf_hdr *ichdr,	struct xfs_da_args	*args,	int			mapindex){	struct xfs_attr_leafblock *leaf;	struct xfs_attr_leaf_entry *entry;	struct xfs_attr_leaf_name_local *name_loc;	struct xfs_attr_leaf_name_remote *name_rmt;	struct xfs_mount	*mp;	int			tmp;	int			i;	trace_xfs_attr_leaf_add_work(args);	leaf = bp->b_addr;	ASSERT(mapindex >= 0 && mapindex < XFS_ATTR_LEAF_MAPSIZE);	ASSERT(args->index >= 0 && args->index <= ichdr->count);	 	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];	if (args->index < ichdr->count) {		tmp  = ichdr->count - args->index;		tmp *= sizeof(xfs_attr_leaf_entry_t);		memmove(entry + 1, entry, tmp);		xfs_trans_log_buf(args->trans, bp,		    XFS_DA_LOGRANGE(leaf, entry, tmp + sizeof(*entry)));	}	ichdr->count++;	 	mp = args->trans->t_mountp;	ASSERT(ichdr->freemap[mapindex].base < XFS_LBSIZE(mp));	ASSERT((ichdr->freemap[mapindex].base & 0x3) == 0);	ASSERT(ichdr->freemap[mapindex].size >=		xfs_attr_leaf_newentsize(args->namelen, args->valuelen,					 mp->m_sb.sb_blocksize, NULL));	ASSERT(ichdr->freemap[mapindex].size < XFS_LBSIZE(mp));	ASSERT((ichdr->freemap[mapindex].size & 0x3) == 0);	ichdr->freemap[mapindex].size -=			xfs_attr_leaf_newentsize(args->namelen, args->valuelen,						 mp->m_sb.sb_blocksize, &tmp);	entry->nameidx = cpu_to_be16(ichdr->freemap[mapindex].base +				     ichdr->freemap[mapindex].size);	entry->hashval = cpu_to_be32(args->hashval);	entry->flags = tmp ? XFS_ATTR_LOCAL : 0;	entry->flags |= XFS_ATTR_NSP_ARGS_TO_ONDISK(args->flags);	if (args->op_flags & XFS_DA_OP_RENAME) {		entry->flags |= XFS_ATTR_INCOMPLETE;		if ((args->blkno2 == args->blkno) &&		    (args->index2 <= args->index)) {			args->index2++;		}	}	xfs_trans_log_buf(args->trans, bp,			  XFS_DA_LOGRANGE(leaf, entry, sizeof(*entry)));	ASSERT((args->index == 0) ||	       (be32_to_cpu(entry->hashval) >= be32_to_cpu((entry-1)->hashval)));	ASSERT((args->index == ichdr->count - 1) ||	       (be32_to_cpu(entry->hashval) <= be32_to_cpu((entry+1)->hashval)));	 	if (entry->flags & XFS_ATTR_LOCAL) {		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);		name_loc->namelen = args->namelen;		name_loc->valuelen = cpu_to_be16(args->valuelen);		memcpy((char *)name_loc->nameval, args->name, args->namelen);		memcpy((char *)&name_loc->nameval[args->namelen], args->value,				   be16_to_cpu(name_loc->valuelen));	} else {		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);		name_rmt->namelen = args->namelen;		memcpy((char *)name_rmt->name, args->name, args->namelen);		entry->flags |= XFS_ATTR_INCOMPLETE;		 		name_rmt->valuelen = 0; 		name_rmt->valueblk = 0; 		args->rmtblkno = 1; 		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen); 	} 	xfs_trans_log_buf(args->trans, bp, 	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),				   xfs_attr_leaf_entsize(leaf, args->index)));	 	if (be16_to_cpu(entry->nameidx) < ichdr->firstused)		ichdr->firstused = be16_to_cpu(entry->nameidx);	ASSERT(ichdr->firstused >= ichdr->count * sizeof(xfs_attr_leaf_entry_t)					+ xfs_attr3_leaf_hdr_size(leaf));	tmp = (ichdr->count - 1) * sizeof(xfs_attr_leaf_entry_t)					+ xfs_attr3_leaf_hdr_size(leaf);	for (i = 0; i < XFS_ATTR_LEAF_MAPSIZE; i++) {		if (ichdr->freemap[i].base == tmp) {			ichdr->freemap[i].base += sizeof(xfs_attr_leaf_entry_t);			ichdr->freemap[i].size -= sizeof(xfs_attr_leaf_entry_t);		}	}	ichdr->usedbytes += xfs_attr_leaf_entsize(leaf, args->index);	return 0;}",31215
27,69,CVE-2015-1573,3,static void nf_tables_table_destroy(struct nft_ctx *ctx){	BUG_ON(ctx->table->use > 0);	kfree(ctx->table);	module_put(ctx->afi->owner);},19165
36,91,CVE-2015-1573,3,"nft_rule_activate_next(struct net *net, struct nft_rule *rule){	 	rule->genmask = (1 << net->nft.gencursor);}",19187
40,158,CVE-2015-8952,3,"int ext4_xattr_ibody_find(struct inode *inode, struct ext4_xattr_info *i,			  struct ext4_xattr_ibody_find *is){	struct ext4_xattr_ibody_header *header;	struct ext4_inode *raw_inode;	int error;	if (EXT4_I(inode)->i_extra_isize == 0)		return 0;	raw_inode = ext4_raw_inode(&is->iloc);	header = IHDR(inode, raw_inode);	is->s.base = is->s.first = IFIRST(header);	is->s.here = is->s.first;	is->s.end = (void *)raw_inode + EXT4_SB(inode->i_sb)->s_inode_size;	if (ext4_test_inode_state(inode, EXT4_STATE_XATTR)) {		error = ext4_xattr_check_names(IFIRST(header), is->s.end,					       IFIRST(header));		if (error)			return error;		 		error = ext4_xattr_find_entry(&is->s.here, i->name_index,					      i->name, is->s.end -					      (void *)is->s.base, 0);		if (error && error != -ENODATA)			return error;		is->s.not_found = error;	}	return 0;}",28463
9,142,CVE-2015-8952,3,"static int ext2_sync_fs(struct super_block *sb, int wait){	struct ext2_sb_info *sbi = EXT2_SB(sb);	struct ext2_super_block *es = EXT2_SB(sb)->s_es;	 	dquot_writeback_dquots(sb, -1);	spin_lock(&sbi->s_lock);	if (es->s_state & cpu_to_le16(EXT2_VALID_FS)) {		ext2_debug(""setting valid to 0\n"");		es->s_state &= cpu_to_le16(~EXT2_VALID_FS);	}	spin_unlock(&sbi->s_lock);	ext2_sync_super(sb, es, wait);	return 0;}",28447
6,38,CVE-2016-2085,3,static void evm_reset_status(struct inode *inode){	struct integrity_iint_cache *iint;	iint = integrity_iint_find(inode);	if (iint)		iint->evm_status = INTEGRITY_UNKNOWN;},17997
30,144,CVE-2015-8952,3,static int ext2_unfreeze(struct super_block *sb){	 	ext2_write_super(sb);	return 0;},28449
2,160,CVE-2011-3927,3,inline float square(float n){    return n * n;},29296
41,62,CVE-2016-3132,4,"SPL_METHOD(SplDoublyLinkedList, push){	zval *value;	spl_dllist_object *intern;	if (zend_parse_parameters(ZEND_NUM_ARGS(), ""z"", &value) == FAILURE) {		return;	}	intern = Z_SPLDLLIST_P(getThis());	spl_ptr_llist_push(intern->llist, value);	RETURN_TRUE;}",17440
22,24,CVE-2016-9806,4,"static int netlink_broadcast_deliver(struct sock *sk, struct sk_buff *skb){	struct netlink_sock *nlk = nlk_sk(sk);	if (atomic_read(&sk->sk_rmem_alloc) <= sk->sk_rcvbuf &&	    !test_bit(NETLINK_S_CONGESTED, &nlk->state)) {		netlink_skb_set_owner_r(skb, sk);		__netlink_sendskb(sk, skb);		return atomic_read(&sk->sk_rmem_alloc) > (sk->sk_rcvbuf >> 1);	}	return -1;}",14981
43,130,CVE-2018-7480,4,static void blkcg_css_free(struct cgroup_subsys_state *css){	struct blkcg *blkcg = css_to_blkcg(css);	int i;	mutex_lock(&blkcg_pol_mutex);	list_del(&blkcg->all_blkcgs_node);	for (i = 0; i < BLKCG_MAX_POLS; i++)		if (blkcg->cpd[i])			blkcg_policy[i]->cpd_free_fn(blkcg->cpd[i]);	mutex_unlock(&blkcg_pol_mutex);	kfree(blkcg);},25371
3,34,CVE-2016-9806,4,netlink_kernel_release(struct sock *sk){	if (sk == NULL || sk->sk_socket == NULL)		return;	sock_release(sk->sk_socket);},14991
38,164,CVE-2018-20961,4,static void f_midi_rmidi_free(struct snd_rawmidi *rmidi){	f_midi_free(rmidi->private_data);},27453
26,169,CVE-2018-20961,4,static inline void f_midi_unregister_card(struct f_midi *midi){	if (midi->card) {		snd_card_free(midi->card);		midi->card = NULL;	}},27458
1,138,CVE-2018-7480,4,"struct blkcg_gq *blkg_lookup_create(struct blkcg *blkcg,				    struct request_queue *q){	struct blkcg_gq *blkg;	WARN_ON_ONCE(!rcu_read_lock_held());	lockdep_assert_held(q->queue_lock);	 	if (unlikely(blk_queue_bypass(q)))		return ERR_PTR(blk_queue_dying(q) ? -ENODEV : -EBUSY);	blkg = __blkg_lookup(blkcg, q, true);	if (blkg)		return blkg;	 	while (true) {		struct blkcg *pos = blkcg;		struct blkcg *parent = blkcg_parent(blkcg);		while (parent && !__blkg_lookup(parent, q, false)) {			pos = parent;			parent = blkcg_parent(parent);		}		blkg = blkg_create(pos, q, NULL);		if (pos == blkcg || IS_ERR(blkg))			return blkg;	}}",25379
40,70,CVE-2017-16820,4,"static void csnmp_host_definition_destroy(void *arg)  {  host_definition_t *hd;  hd = arg;  if (hd == NULL)    return;  if (hd->name != NULL) {    DEBUG(""snmp plugin: Destroying host definition for host `%s'."", hd->name);  }  csnmp_host_close_session(hd);  sfree(hd->name);  sfree(hd->address);  sfree(hd->community);  sfree(hd->username);  sfree(hd->auth_passphrase);  sfree(hd->priv_passphrase);  sfree(hd->context);  sfree(hd->data_list);  sfree(hd);}  ",19667
29,39,CVE-2016-9806,4,"static int netlink_release(struct socket *sock){	struct sock *sk = sock->sk;	struct netlink_sock *nlk;	if (!sk)		return 0;	netlink_remove(sk);	sock_orphan(sk);	nlk = nlk_sk(sk);	 	 	if (nlk->netlink_unbind) {		int i;		for (i = 0; i < nlk->ngroups; i++)			if (test_bit(i, nlk->groups))				nlk->netlink_unbind(sock_net(sk), i + 1);	}	if (sk->sk_protocol == NETLINK_GENERIC &&	    atomic_dec_return(&genl_sk_destructing_cnt) == 0)		wake_up(&genl_sk_destructing_waitq);	sock->sk = NULL;	wake_up_interruptible_all(&nlk->wait);	skb_queue_purge(&sk->sk_write_queue);	if (nlk->portid && nlk->bound) {		struct netlink_notify n = {						.net = sock_net(sk),						.protocol = sk->sk_protocol,						.portid = nlk->portid,					  };		atomic_notifier_call_chain(&netlink_chain,				NETLINK_URELEASE, &n);	}	module_put(nlk->module);	if (netlink_is_kernel(sk)) {		netlink_table_grab();		BUG_ON(nl_table[sk->sk_protocol].registered == 0);		if (--nl_table[sk->sk_protocol].registered == 0) {			struct listeners *old;			old = nl_deref_protected(nl_table[sk->sk_protocol].listeners);			RCU_INIT_POINTER(nl_table[sk->sk_protocol].listeners, NULL);			kfree_rcu(old, rcu);			nl_table[sk->sk_protocol].module = NULL;			nl_table[sk->sk_protocol].bind = NULL;			nl_table[sk->sk_protocol].unbind = NULL;			nl_table[sk->sk_protocol].flags = 0;			nl_table[sk->sk_protocol].registered = 0;		}		netlink_table_ungrab();	}	kfree(nlk->groups);	nlk->groups = NULL;	local_bh_disable();	sock_prot_inuse_add(sock_net(sk), &netlink_proto, -1);	local_bh_enable();	call_rcu(&nlk->rcu, deferred_put_nlk_sk);	return 0;}",14996
23,139,CVE-2018-7480,4,"struct blkcg_gq *blkg_lookup_slowpath(struct blkcg *blkcg,				      struct request_queue *q, int update_hint){	struct blkcg_gq *blkg;	 	blkg = radix_tree_lookup(&blkcg->blkg_tree, q->id);	if (blkg && blkg->q == q) {		if (update_hint) {			lockdep_assert_held(q->queue_lock);			rcu_assign_pointer(blkcg->blkg_hint, blkg);		}		return blkg;	}	return NULL;}",25380
24,20,CVE-2016-9806,4,"int netlink_add_tap(struct netlink_tap *nt){	if (unlikely(nt->dev->type != ARPHRD_NETLINK))		return -EINVAL;	spin_lock(&netlink_tap_lock);	list_add_rcu(&nt->list, &netlink_tap_all);	spin_unlock(&netlink_tap_lock);	__module_get(nt->module);	return 0;}",14977
17,122,CVE-2018-16425,4,int sc_valid_oid(const struct sc_object_id *oid){	int ii;	if (!oid)		return 0;	if (oid->value[0] == -1 || oid->value[1] == -1)		return 0;	if (oid->value[0] > 2 || oid->value[1] > 39)		return 0;	for (ii=0;ii<SC_MAX_OBJECT_ID_OCTETS;ii++)		if (oid->value[ii])			break;	if (ii==SC_MAX_OBJECT_ID_OCTETS)		return 0;	return 1;},24386
0,79,CVE-2017-8890,4,"struct sock *inet_csk_reqsk_queue_add(struct sock *sk,				      struct request_sock *req,				      struct sock *child){	struct request_sock_queue *queue = &inet_csk(sk)->icsk_accept_queue;	spin_lock(&queue->rskq_lock);	if (unlikely(sk->sk_state != TCP_LISTEN)) {		inet_child_forget(sk, req, child);		child = NULL;	} else {		req->sk = child;		req->dl_next = NULL;		if (queue->rskq_accept_head == NULL)			queue->rskq_accept_head = req;		else			queue->rskq_accept_tail->dl_next = req;		queue->rskq_accept_tail = req;		sk_acceptq_added(sk);	}	spin_unlock(&queue->rskq_lock);	return child;}",21245
10,45,CVE-2016-9806,4,"static int netlink_walk_start(struct nl_seq_iter *iter){	int err;	err = rhashtable_walk_init(&nl_table[iter->link].hash, &iter->hti,				   GFP_KERNEL);	if (err) {		iter->link = MAX_LINKS;		return err;	}	err = rhashtable_walk_start(&iter->hti);	return err == -EAGAIN ? 0 : err;}",15002
25,117,CVE-2018-16425,4,const char *sc_get_version(void){    return sc_version;},24381
35,60,CVE-2016-5768,4,const char *php_mb_regex_get_mbctype(TSRMLS_D){	return _php_mb_regex_mbctype2name(MBREX(current_mbctype));},16365
19,112,CVE-2018-16425,4,static unsigned int map_operations (int commandbyte ){	unsigned int op = (unsigned int)-1;	switch ( (commandbyte & 0xfe) ) {		case 0xe2:     op = SC_AC_OP_UPDATE; break;		case 0x24:   op = SC_AC_OP_UPDATE; break;		case 0xe0:            op = SC_AC_OP_CREATE; break;		case 0xe4:            op = SC_AC_OP_DELETE; break;		case 0xe8:       op = SC_AC_OP_WRITE; break;		case 0x82:     op = SC_AC_OP_READ; break;		case 0xe6:       op = SC_AC_OP_WRITE; break;		case 0x88:     op = SC_AC_OP_READ; break;		case 0x04:        op = SC_AC_OP_INVALIDATE; break;		case 0x2a:   op = SC_AC_OP_SELECT; break;		case 0xb0:       op = SC_AC_OP_READ; break;		case 0xb2:       op = SC_AC_OP_READ; break;		case 0x44:      op = SC_AC_OP_REHABILITATE; break;		case 0xa4:            op = SC_AC_OP_SELECT; break;		case 0xee:     op = SC_AC_OP_CREATE; break;		case 0x2c:  op = SC_AC_OP_WRITE; break;		case 0xd6:     op = SC_AC_OP_WRITE; break;		case 0xdc:     op = SC_AC_OP_WRITE; break;		case 0x20:   op = SC_AC_OP_SELECT; break;		case 0x60:       op = SC_AC_OP_CREATE; break;	}	return op;},24376
37,91,CVE-2017-6353,4,"struct sk_buff *sctp_skb_recv_datagram(struct sock *sk, int flags,				       int noblock, int *err){	int error;	struct sk_buff *skb;	long timeo;	timeo = sock_rcvtimeo(sk, noblock);	pr_debug(""%s: timeo:%ld, max:%ld\n"", __func__, timeo,		 MAX_SCHEDULE_TIMEOUT);	do {		 		if (flags & MSG_PEEK) {			skb = skb_peek(&sk->sk_receive_queue);			if (skb)				atomic_inc(&skb->users);		} else {			skb = __skb_dequeue(&sk->sk_receive_queue);		}		if (skb)			return skb;		 		error = sock_error(sk);		if (error)			goto no_packet;		if (sk->sk_shutdown & RCV_SHUTDOWN)			break;		if (sk_can_busy_loop(sk) &&		    sk_busy_loop(sk, noblock))			continue;		 		error = -EAGAIN;		if (!timeo)			goto no_packet;	} while (sctp_wait_for_packet(sk, err, &timeo) == 0);	return NULL;no_packet:	*err = error;	return NULL;}",21812
32,63,CVE-2016-3132,4,"SPL_METHOD(SplDoublyLinkedList, unshift){	zval *value;	spl_dllist_object *intern;	if (zend_parse_parameters(ZEND_NUM_ARGS(), ""z"", &value) == FAILURE) {		return;	}	intern = Z_SPLDLLIST_P(getThis());	spl_ptr_llist_unshift(intern->llist, value);	RETURN_TRUE;}",17441
4,2,CVE-2016-5384,4,FcCacheObjectDereference (void *object){    FcCacheSkip	*skip;    lock_cache ();    skip = FcCacheFindByAddrUnlocked (object);    if (skip)    {	if (FcRefDec (&skip->ref) == 1)	    FcDirCacheDisposeUnlocked (skip->cache);    }    unlock_cache ();},1840
11,103,CVE-2017-5506,4,"static inline const unsigned char *ReadResourceShort(const unsigned char *p,  unsigned short *quantum){  *quantum=(unsigned short) (*p++) << 8;  *quantum|=(unsigned short) (*p++);  return(p);}",22132
20,36,CVE-2016-9806,4,"int netlink_ns_capable(const struct sk_buff *skb,			struct user_namespace *user_ns, int cap){	return __netlink_ns_capable(&NETLINK_CB(skb), user_ns, cap);}",14993
21,148,CVE-2017-18174,4,"static int amd_pinconf_group_set(struct pinctrl_dev *pctldev,				unsigned group, unsigned long *configs,				unsigned num_configs){	const unsigned *pins;	unsigned npins;	int i, ret;	ret = amd_get_group_pins(pctldev, group, &pins, &npins);	if (ret)		return ret;	for (i = 0; i < npins; i++) {		if (amd_pinconf_set(pctldev, pins[i], configs, num_configs))			return -ENOTSUPP;	}	return 0;}",26080
34,156,CVE-2018-20961,4,static void f_midi_drop_out_substreams(struct f_midi *midi){	unsigned int i;	for (i = 0; i < midi->in_ports; i++) {		struct gmidi_in_port *port = midi->in_ports_array + i;		struct snd_rawmidi_substream *substream = port->substream;		if (port->active && substream)			snd_rawmidi_drop_output(substream);	}},27445
13,5,CVE-2016-5384,4,unlock_cache (void){  FcMutexUnlock (cache_lock);},1843
15,77,CVE-2017-8890,4,"void inet_csk_destroy_sock(struct sock *sk){	WARN_ON(sk->sk_state != TCP_CLOSE);	WARN_ON(!sock_flag(sk, SOCK_DEAD));	 	WARN_ON(!sk_unhashed(sk));	 	WARN_ON(inet_sk(sk)->inet_num && !inet_csk(sk)->icsk_bind_hash);	sk->sk_prot->destroy(sk);	sk_stream_kill_queues(sk);	xfrm_sk_free_policy(sk);	sk_refcnt_debug_release(sk);	percpu_counter_dec(sk->sk_prot->orphan_count);	sock_put(sk);}",21243
12,42,CVE-2016-9806,4,static void netlink_skb_destructor(struct sk_buff *skb){	if (is_vmalloc_addr(skb->head)) {		if (!skb->cloned ||		    !atomic_dec_return(&(skb_shinfo(skb)->dataref)))			vfree(skb->head);		skb->head = NULL;	}	if (skb->sk != NULL)		sock_rfree(skb);},14999
18,94,CVE-2017-6074,4,"static void dccp_enqueue_skb(struct sock *sk, struct sk_buff *skb){	__skb_pull(skb, dccp_hdr(skb)->dccph_doff * 4);	__skb_queue_tail(&sk->sk_receive_queue, skb);	skb_set_owner_r(skb, sk);	sk->sk_data_ready(sk);}",21851
5,126,CVE-2018-8099,4,unsigned int git_index__create_mode(unsigned int mode){	if (S_ISLNK(mode))		return S_IFLNK;	if (S_ISDIR(mode) || (mode & S_IFMT) == (S_IFLNK | S_IFDIR))		return (S_IFLNK | S_IFDIR);	return S_IFREG | GIT_PERMS_CANONICAL(mode);},25282
7,102,CVE-2017-5506,4,"static inline const unsigned char *ReadResourceLong(const unsigned char *p,  unsigned int *quantum){  *quantum=(unsigned int) (*p++) << 24;  *quantum|=(unsigned int) (*p++) << 16;  *quantum|=(unsigned int) (*p++) << 8;  *quantum|=(unsigned int) (*p++);  return(p);}",22131
8,27,CVE-2016-9806,4,"static inline int netlink_compare(struct rhashtable_compare_arg *arg,				  const void *ptr){	const struct netlink_compare_arg *x = arg->key;	const struct netlink_sock *nlk = ptr;	return nlk->portid != x->portid ||	       !net_eq(sock_net(&nlk->sk), read_pnet(&x->pnet));}",14984
33,14,CVE-2016-9806,4,"static int __netlink_insert(struct netlink_table *table, struct sock *sk){	struct netlink_compare_arg arg;	netlink_compare_arg_init(&arg, sock_net(sk), nlk_sk(sk)->portid);	return rhashtable_lookup_insert_key(&table->hash, &arg,					    &nlk_sk(sk)->node,					    netlink_rhashtable_params);}",14971
16,16,CVE-2016-9806,4,"int __netlink_ns_capable(const struct netlink_skb_parms *nsp,			struct user_namespace *user_ns, int cap){	return ((nsp->flags & NETLINK_SKB_DST) ||		file_ns_capable(nsp->sk->sk_socket->file, user_ns, cap)) &&		ns_capable(user_ns, cap);}",14973
14,26,CVE-2016-9806,4,"static void netlink_cmsg_listen_all_nsid(struct sock *sk, struct msghdr *msg,					 struct sk_buff *skb){	if (!NETLINK_CB(skb).nsid_is_set)		return;	put_cmsg(msg, SOL_NETLINK, NETLINK_LISTEN_ALL_NSID, sizeof(int),		 &NETLINK_CB(skb).nsid);}",14983
28,69,CVE-2017-16820,4,static void call_snmp_init_once(void) {  static int have_init = 0;  if (have_init == 0)    init_snmp(PACKAGE_NAME);  have_init = 1;}  ,19666
31,144,CVE-2017-18174,4,"static int amd_get_group_pins(struct pinctrl_dev *pctldev,			      unsigned group,			      const unsigned **pins,			      unsigned *num_pins){	struct amd_gpio *gpio_dev = pinctrl_dev_get_drvdata(pctldev);	*pins = gpio_dev->groups[group].pins;	*num_pins = gpio_dev->groups[group].npins;	return 0;}",26076
39,172,CVE-2017-18594,4,"int make_socketpair (int socks[2], int dummy) {    if (socks == 0) {        errno = EINVAL;        return -1;    }    dummy = socketpair(AF_UNIX, SOCK_STREAM, 0, socks);    if (dummy) {        socks[0] = socks[1] = -1;    }    return dummy;}",28037
27,141,CVE-2018-7480,4,"int blkg_print_stat_bytes_recursive(struct seq_file *sf, void *v){	blkcg_print_blkgs(sf, css_to_blkcg(seq_css(sf)),			  blkg_prfill_rwstat_field_recursive,			  (void *)seq_cft(sf)->private,			  offsetof(struct blkcg_gq, stat_bytes), true);	return 0;}",25382
36,51,CVE-2016-5768,4,"PHP_FUNCTION(mb_ereg_replace_callback){	_php_mb_regex_ereg_replace_exec(INTERNAL_FUNCTION_PARAM_PASSTHRU, 0, 1);}",16356
42,158,CVE-2018-20961,4,static void f_midi_in_tasklet(unsigned long data){	struct f_midi *midi = (struct f_midi *) data;	f_midi_transmit(midi);},27447
9,151,CVE-2019-6978,4,"const char * gdJpegGetVersionString(){	switch(JPEG_LIB_VERSION) {		case 62:			return ""6b"";			break;		case 70:			return ""7"";			break;		case 80:			return ""8"";			break;		case 90:			return ""9 compatible"";			break;		default:			return ""unknown""; 	} }",27354
6,38,CVE-2016-9806,4,"static void netlink_rcv_wake(struct sock *sk){	struct netlink_sock *nlk = nlk_sk(sk);	if (skb_queue_empty(&sk->sk_receive_queue))		clear_bit(NETLINK_S_CONGESTED, &nlk->state);	if (!test_bit(NETLINK_S_CONGESTED, &nlk->state))		wake_up_interruptible(&nlk->wait);}",14995
30,46,CVE-2016-9806,4,static void netlink_walk_stop(struct nl_seq_iter *iter){	rhashtable_walk_stop(&iter->hti);	rhashtable_walk_exit(&iter->hti);},15003
2,86,CVE-2017-8890,4,"void inet_get_local_port_range(struct net *net, int *low, int *high){	unsigned int seq;	do {		seq = read_seqbegin(&net->ipv4.ip_local_ports.lock);		*low = net->ipv4.ip_local_ports.range[0];		*high = net->ipv4.ip_local_ports.range[1];	} while (read_seqretry(&net->ipv4.ip_local_ports.lock, seq));}",21252
413,276,CVE-2012-2375,20,"static int _nfs4_recover_proc_open(struct nfs4_opendata *data){	struct inode *dir = data->dir->d_inode;	struct nfs_openres *o_res = &data->o_res;        int status;	status = nfs4_run_open_task(data, 1);	if (status != 0 || !data->rpc_done)		return status;	nfs_fattr_map_and_free_names(NFS_SERVER(dir), &data->f_attr);	nfs_refresh_inode(dir, o_res->dir_attr);	if (o_res->rflags & NFS4_OPEN_RESULT_CONFIRM) {		status = _nfs4_proc_open_confirm(data);		if (status != 0)			return status;	}	return status;}",3253
393,1638,CVE-2019-7308,20,static int type_is_refcounted_or_null(enum bpf_reg_type type){	return type == PTR_TO_SOCKET || type == PTR_TO_SOCKET_OR_NULL;},27351
150,210,CVE-2012-3412,20,"static void efx_ethtool_get_drvinfo(struct net_device *net_dev,				    struct ethtool_drvinfo *info){	struct efx_nic *efx = netdev_priv(net_dev);	strlcpy(info->driver, KBUILD_MODNAME, sizeof(info->driver));	strlcpy(info->version, EFX_DRIVER_VERSION, sizeof(info->version));	if (efx_nic_rev(efx) >= EFX_REV_SIENA_A0)		efx_mcdi_print_fwver(efx, info->fw_version,				     sizeof(info->fw_version));	strlcpy(info->bus_info, pci_name(efx->pci_dev), sizeof(info->bus_info));}",3084
160,572,CVE-2011-4131,20,"static void nfs41_call_sync_prepare(struct rpc_task *task, void *calldata){	struct nfs41_call_sync_data *data = calldata;	dprintk(""--> %s data->seq_server %p\n"", __func__, data->seq_server);	if (nfs4_setup_sequence(data->seq_server, data->seq_args,				data->seq_res, data->cache_reply, task))		return;	rpc_call_start(task);}",4913
341,145,CVE-2015-8312,20,DECL_PIOCTL(PBogus){    AFS_STATCNT(PBogus);    return EINVAL;},2265
0,269,CVE-2012-2375,20,"static int _nfs4_proc_pathconf(struct nfs_server *server, struct nfs_fh *fhandle,		struct nfs_pathconf *pathconf){	struct nfs4_pathconf_arg args = {		.fh = fhandle,		.bitmask = server->attr_bitmask,	};	struct nfs4_pathconf_res res = {		.pathconf = pathconf,	};	struct rpc_message msg = {		.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_PATHCONF],		.rpc_argp = &args,		.rpc_resp = &res,	};	 	if ((args.bitmask[0] & nfs4_pathconf_bitmap[0]) == 0) {		memset(pathconf, 0, sizeof(*pathconf));		return 0;	}	nfs_fattr_init(pathconf->fattr);	return nfs4_call_sync(server->client, server, &msg, &args.seq_args, &res.seq_res, 0);}",3246
368,1175,CVE-2013-6376,20,"static inline void apic_set_vector(int vec, void *bitmap){	set_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));}",7376
59,48,CVE-2014-6269,20,"char *find_hdr_value_end(char *s, const char *e){	int quoted, qdpair;	quoted = qdpair = 0;	for (; s < e; s++) {		if (qdpair)                    qdpair = 0;		else if (quoted) {			if (*s == '\\')        qdpair = 1;			else if (*s == '""')    quoted = 0;		}		else if (*s == '""')            quoted = 1;		else if (*s == ',')            return s;	}	return s;}",1712
81,46,CVE-2014-6269,20,"void debug_hdr(const char *dir, struct session *s, const char *start, const char *end){	int max;	chunk_printf(&trash, ""%08x:%s.%s[%04x:%04x]: "", s->uniq_id, s->be->id,		      dir,		     objt_conn(s->req->prod->end) ? (unsigned short)objt_conn(s->req->prod->end)->t.sock.fd : -1,		     objt_conn(s->req->cons->end) ? (unsigned short)objt_conn(s->req->cons->end)->t.sock.fd : -1);	for (max = 0; start + max < end; max++)		if (start[max] == '\r' || start[max] == '\n')			break;	UBOUND(max, trash.size - trash.len - 3);	trash.len += strlcpy2(trash.str + trash.len, start, max + 1);	trash.str[trash.len++] = '\n';	shut_your_big_mouth_gcc(write(1, trash.str, trash.len));}",1710
50,616,CVE-2011-4131,20,"void nfs4_release_lockowner(const struct nfs4_lock_state *lsp){	struct nfs_server *server = lsp->ls_state->owner->so_server;	struct nfs_release_lockowner_args *args;	struct rpc_message msg = {		.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_RELEASE_LOCKOWNER],	};	if (server->nfs_client->cl_mvops->minor_version != 0)		return;	args = kmalloc(sizeof(*args), GFP_NOFS);	if (!args)		return;	args->lock_owner.clientid = server->nfs_client->cl_clientid;	args->lock_owner.id = lsp->ls_id.id;	args->lock_owner.s_dev = server->s_dev;	msg.rpc_argp = args;	rpc_call_async(server->client, &msg, 0, &nfs4_release_lockowner_ops, args);}",4957
266,1218,CVE-2013-4483,20,"void sem_exit_ns(struct ipc_namespace *ns){	free_ipcs(ns, &sem_ids(ns), freeary);	idr_destroy(&ns->ids[IPC_SEM_IDS].ipcs_idr);}",7778
306,1635,CVE-2019-7308,20,"static int states_equal(struct bpf_verifier_env *env,			 struct bpf_verifier_state *old,			 struct bpf_verifier_state *cur){	int i;	if (old->curframe != cur->curframe)		return false;	 	if (old->speculative && !cur->speculative)		return false;	 	for (i = 0; i <= old->curframe; i++) {		if (old->frame[i]->callsite != cur->frame[i]->callsite)			return false;		if (!func_states_equal(old->frame[i], cur->frame[i]))			return false;	}	return true;}",27348
232,153,CVE-2014-10375,20,"eXosip_malloc (void){  struct eXosip_t *ptr = (struct eXosip_t *) osip_malloc (sizeof (eXosip_t));  if (ptr)    memset (ptr, 0, sizeof (eXosip_t));  return ptr;}",2529
165,1733,CVE-2013-4483,20,"static struct sem_undo *find_alloc_undo(struct ipc_namespace *ns, int semid){ 	struct sem_array *sma; 	struct sem_undo_list *ulp; 	struct sem_undo *un, *new;	int nsems;	int error;  	error = get_undo_list(&ulp); 	if (error)		return ERR_PTR(error);	rcu_read_lock();	spin_lock(&ulp->lock);	un = lookup_undo(ulp, semid);	spin_unlock(&ulp->lock);	if (likely(un!=NULL))		goto out;	 	 	sma = sem_obtain_object_check(ns, semid);	if (IS_ERR(sma)) {		rcu_read_unlock();		return ERR_CAST(sma); 	}  	nsems = sma->sem_nsems;	ipc_rcu_getref(sma); 	rcu_read_unlock();  	 	new = kzalloc(sizeof(struct sem_undo) + sizeof(short)*nsems, GFP_KERNEL);	if (!new) {		sem_putref(sma);		return ERR_PTR(-ENOMEM);	} 	  	sem_lock_and_putref(sma); 	if (sma->sem_perm.deleted) {		sem_unlock(sma); 		kfree(new); 		un = ERR_PTR(-EIDRM); 		goto out;	}	spin_lock(&ulp->lock);	 	un = lookup_undo(ulp, semid);	if (un) {		kfree(new);		goto success;	}	 	new->semadj = (short *) &new[1];	new->ulp = ulp;	new->semid = semid;	assert_spin_locked(&ulp->lock);	list_add_rcu(&new->list_proc, &ulp->list_proc);	assert_spin_locked(&sma->sem_perm.lock);	list_add(&new->list_id, &sma->list_id);	un = new; success: 	spin_unlock(&ulp->lock); 	rcu_read_lock();	sem_unlock(sma); out: 	return un; }",31046
34,900,CVE-2011-3209,20,"static void deactivate_slab(struct kmem_cache *s, struct kmem_cache_cpu *c){	struct page *page = c->page;	int tail = 1;	if (page->freelist)		stat(c, DEACTIVATE_REMOTE_FREES);	 	while (unlikely(c->freelist)) {		void **object;		tail = 0;	 		 		object = c->freelist;		c->freelist = c->freelist[c->offset];		 		object[c->offset] = page->freelist;		page->freelist = object;		page->inuse--;	}	c->page = NULL;	unfreeze_slab(s, page, tail);}",5668
215,478,CVE-2012-2100,20,static inline void register_as_ext2(void) { },3633
200,1382,CVE-2014-4656,20,static void snd_ctl_elem_user_free(struct snd_kcontrol *kcontrol){	struct user_element *ue = kcontrol->private_data;	kfree(ue->tlv_data);	kfree(ue->priv_data);	kfree(ue);},10816
172,510,CVE-2012-0044,20,"int drm_mode_create_dvi_i_properties(struct drm_device *dev){	struct drm_property *dvi_i_selector;	struct drm_property *dvi_i_subconnector;	int i;	if (dev->mode_config.dvi_i_select_subconnector_property)		return 0;	dvi_i_selector =		drm_property_create(dev, DRM_MODE_PROP_ENUM,				    ""select subconnector"",				    ARRAY_SIZE(drm_dvi_i_select_enum_list));	for (i = 0; i < ARRAY_SIZE(drm_dvi_i_select_enum_list); i++)		drm_property_add_enum(dvi_i_selector, i,				      drm_dvi_i_select_enum_list[i].type,				      drm_dvi_i_select_enum_list[i].name);	dev->mode_config.dvi_i_select_subconnector_property = dvi_i_selector;	dvi_i_subconnector =		drm_property_create(dev, DRM_MODE_PROP_ENUM |				    DRM_MODE_PROP_IMMUTABLE,				    ""subconnector"",				    ARRAY_SIZE(drm_dvi_i_subconnector_enum_list));	for (i = 0; i < ARRAY_SIZE(drm_dvi_i_subconnector_enum_list); i++)		drm_property_add_enum(dvi_i_subconnector, i,				      drm_dvi_i_subconnector_enum_list[i].type,				      drm_dvi_i_subconnector_enum_list[i].name);	dev->mode_config.dvi_i_subconnector_property = dvi_i_subconnector;	return 0;}",4283
93,1555,CVE-2019-14763,20,"static int dwc3_gadget_ep_disable(struct usb_ep *ep){	struct dwc3_ep			*dep;	struct dwc3			*dwc;	unsigned long			flags;	int				ret;	if (!ep) {		pr_debug(""dwc3: invalid parameters\n"");		return -EINVAL;	}	dep = to_dwc3_ep(ep);	dwc = dep->dwc;	if (dev_WARN_ONCE(dwc->dev, !(dep->flags & DWC3_EP_ENABLED),					""%s is already disabled\n"",					dep->name))		return 0;	spin_lock_irqsave(&dwc->lock, flags);	ret = __dwc3_gadget_ep_disable(dep);	spin_unlock_irqrestore(&dwc->lock, flags);	return ret;}",26664
96,844,CVE-2011-4131,20,"xdr_inline_pages(struct xdr_buf *xdr, unsigned int offset,		 struct page **pages, unsigned int base, unsigned int len){	struct kvec *head = xdr->head;	struct kvec *tail = xdr->tail;	char *buf = (char *)head->iov_base;	unsigned int buflen = head->iov_len;	head->iov_len  = offset;	xdr->pages = pages;	xdr->page_base = base;	xdr->page_len = len;	tail->iov_base = buf + offset;	tail->iov_len = buflen - offset;	xdr->buflen += len;}",5185
427,563,CVE-2011-4131,20,"int _nfs4_call_sync_session(struct rpc_clnt *clnt,			    struct nfs_server *server,			    struct rpc_message *msg,			    struct nfs4_sequence_args *args,			    struct nfs4_sequence_res *res,			    int cache_reply){	return nfs4_call_sync_sequence(clnt, server, msg, args, res, cache_reply, 0);}",4904
207,957,CVE-2011-3209,20,"static void unfreeze_slab(struct kmem_cache *s, struct page *page, int tail){	struct kmem_cache_node *n = get_node(s, page_to_nid(page));	struct kmem_cache_cpu *c = get_cpu_slab(s, smp_processor_id());	ClearSlabFrozen(page);	if (page->inuse) {		if (page->freelist) {			add_partial(n, page, tail);			stat(c, tail ? DEACTIVATE_TO_TAIL : DEACTIVATE_TO_HEAD);		} else {			stat(c, DEACTIVATE_FULL);			if (SlabDebug(page) && (s->flags & SLAB_STORE_USER))				add_full(n, page);		}		slab_unlock(page);	} else {		stat(c, DEACTIVATE_EMPTY);		if (n->nr_partial < MIN_PARTIAL) {			 			add_partial(n, page, 1);			slab_unlock(page);		} else {			slab_unlock(page);			stat(get_cpu_slab(s, raw_smp_processor_id()), FREE_SLAB);			discard_slab(s, page);		}	}}",5725
21,1273,CVE-2013-4247,20,"static int match_session(struct cifs_ses *ses, struct smb_vol *vol){	switch (ses->server->secType) {	case Kerberos:		if (!uid_eq(vol->cred_uid, ses->cred_uid))			return 0;		break;	default:		 		if (ses->user_name == NULL) {			if (!vol->nullauth)				return 0;			break;		}		 		if (strncmp(ses->user_name,			    vol->username ? vol->username : "",			    MAX_USERNAME_SIZE))			return 0;		if (strlen(vol->username) != 0 &&		    ses->password != NULL &&		    strncmp(ses->password,			    vol->password ? vol->password : "",			    MAX_PASSWORD_SIZE))			return 0;	}	return 1;}",7925
244,528,CVE-2012-0044,20,"int drm_mode_page_flip_ioctl(struct drm_device *dev,			     void *data, struct drm_file *file_priv){	struct drm_mode_crtc_page_flip *page_flip = data;	struct drm_mode_object *obj;	struct drm_crtc *crtc;	struct drm_framebuffer *fb;	struct drm_pending_vblank_event *e = NULL;	unsigned long flags;	int ret = -EINVAL;	if (page_flip->flags & ~DRM_MODE_PAGE_FLIP_FLAGS ||	    page_flip->reserved != 0)		return -EINVAL;	mutex_lock(&dev->mode_config.mutex);	obj = drm_mode_object_find(dev, page_flip->crtc_id, DRM_MODE_OBJECT_CRTC);	if (!obj)		goto out;	crtc = obj_to_crtc(obj);	if (crtc->fb == NULL) {		 		ret = -EBUSY;		goto out;	}	if (crtc->funcs->page_flip == NULL)		goto out;	obj = drm_mode_object_find(dev, page_flip->fb_id, DRM_MODE_OBJECT_FB);	if (!obj)		goto out;	fb = obj_to_fb(obj);	if (page_flip->flags & DRM_MODE_PAGE_FLIP_EVENT) {		ret = -ENOMEM;		spin_lock_irqsave(&dev->event_lock, flags);		if (file_priv->event_space < sizeof e->event) {			spin_unlock_irqrestore(&dev->event_lock, flags);			goto out;		}		file_priv->event_space -= sizeof e->event;		spin_unlock_irqrestore(&dev->event_lock, flags);		e = kzalloc(sizeof *e, GFP_KERNEL);		if (e == NULL) {			spin_lock_irqsave(&dev->event_lock, flags);			file_priv->event_space += sizeof e->event;			spin_unlock_irqrestore(&dev->event_lock, flags);			goto out;		}		e->event.base.type = DRM_EVENT_FLIP_COMPLETE;		e->event.base.length = sizeof e->event;		e->event.user_data = page_flip->user_data;		e->base.event = &e->event.base;		e->base.file_priv = file_priv;		e->base.destroy =			(void (*) (struct drm_pending_event *)) kfree;	}	ret = crtc->funcs->page_flip(crtc, fb, e);	if (ret) {		spin_lock_irqsave(&dev->event_lock, flags);		file_priv->event_space += sizeof e->event;		spin_unlock_irqrestore(&dev->event_lock, flags);		kfree(e);	}out:	mutex_unlock(&dev->mode_config.mutex);	return ret;}",4301
159,365,CVE-2012-2375,20,"int nfs4_proc_create_session(struct nfs_client *clp){	int status;	unsigned *ptr;	struct nfs4_session *session = clp->cl_session;	dprintk(""--> %s clp=%p session=%p\n"", __func__, clp, session);	status = _nfs4_proc_create_session(clp);	if (status)		goto out;	 	status = nfs4_setup_session_slot_tables(session);	dprintk(""slot table setup returned %d\n"", status);	if (status)		goto out;	ptr = (unsigned *)&session->sess_id.data[0];	dprintk(""%s client>seqid %d sessionid %u:%u:%u:%u\n"", __func__,		clp->cl_seqid, ptr[0], ptr[1], ptr[2], ptr[3]);out:	dprintk(""<-- %s\n"", __func__);	return status;}",3342
397,1325,CVE-2013-2094,20,"static void perf_event_output(struct perf_event *event,				struct perf_sample_data *data,				struct pt_regs *regs){	struct perf_output_handle handle;	struct perf_event_header header;	 	rcu_read_lock();	perf_prepare_sample(&header, data, event, regs);	if (perf_output_begin(&handle, event, header.size))		goto exit;	perf_output_sample(&handle, &header, data, event);	perf_output_end(&handle);exit:	rcu_read_unlock();}",8913
117,1537,CVE-2019-1010294,20,static int elf_flags_to_mattr(int flags){	int mattr = 0;	if (flags & PF_X)		mattr |= TEE_MATTR_UX;	if (flags & PF_W)		mattr |= TEE_MATTR_UW;	if (flags & PF_R)		mattr |= TEE_MATTR_UR;	return mattr;},26371
218,876,CVE-2011-3209,20,static inline void notify_cmos_timer(void) { },5644
361,1279,CVE-2013-2596,20,"void fb_append_extra_logo(const struct linux_logo *logo, unsigned int n){	if (!n || fb_logo_ex_num == FB_LOGO_EX_NUM_MAX)		return;	fb_logo_ex[fb_logo_ex_num].logo = logo;	fb_logo_ex[fb_logo_ex_num].n = n;	fb_logo_ex_num++;}",8547
418,807,CVE-2011-4131,20,"static void nfs4_xdr_enc_lockt(struct rpc_rqst *req, struct xdr_stream *xdr,			       struct nfs_lockt_args *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_putfh(xdr, args->fh, &hdr);	encode_lockt(xdr, args, &hdr);	encode_nops(&hdr);}",5148
11,65,CVE-2014-6269,20,int http_resync_states(struct session *s){	struct http_txn *txn = &s->txn;	int old_req_state = txn->req.msg_state;	int old_res_state = txn->rsp.msg_state;	http_sync_req_state(s);	while (1) {		if (!http_sync_res_state(s))			break;		if (!http_sync_req_state(s))			break;	}	 	if (txn->req.msg_state == HTTP_MSG_TUNNEL ||	    txn->rsp.msg_state == HTTP_MSG_TUNNEL ||	    (txn->req.msg_state == HTTP_MSG_CLOSED &&	     txn->rsp.msg_state == HTTP_MSG_CLOSED)) {		s->req->analysers = 0;		channel_auto_close(s->req);		channel_auto_read(s->req);		s->rep->analysers = 0;		channel_auto_close(s->rep);		channel_auto_read(s->rep);	}	else if ((txn->req.msg_state >= HTTP_MSG_DONE &&		  (txn->rsp.msg_state == HTTP_MSG_CLOSED || (s->rep->flags & CF_SHUTW))) ||		 txn->rsp.msg_state == HTTP_MSG_ERROR ||		 txn->req.msg_state == HTTP_MSG_ERROR) {		s->rep->analysers = 0;		channel_auto_close(s->rep);		channel_auto_read(s->rep);		s->req->analysers = 0;		channel_abort(s->req);		channel_auto_close(s->req);		channel_auto_read(s->req);		bi_erase(s->req);	}	else if ((txn->req.msg_state == HTTP_MSG_DONE ||		  txn->req.msg_state == HTTP_MSG_CLOSED) &&		 txn->rsp.msg_state == HTTP_MSG_DONE &&		 ((txn->flags & TX_CON_WANT_MSK) == TX_CON_WANT_SCL ||		  (txn->flags & TX_CON_WANT_MSK) == TX_CON_WANT_KAL)) {		 		http_end_txn_clean_session(s);	}	return txn->req.msg_state != old_req_state ||		txn->rsp.msg_state != old_res_state;},1729
285,304,CVE-2012-2375,20,"static void nfs4_close_context(struct nfs_open_context *ctx, int is_sync){	if (ctx->state == NULL)		return;	if (is_sync)		nfs4_close_sync(ctx->state, ctx->mode);	else		nfs4_close_state(ctx->state, ctx->mode);}",3281
421,400,CVE-2012-2375,20,"static void nfs4_proc_unlink_setup(struct rpc_message *msg, struct inode *dir){	struct nfs_server *server = NFS_SERVER(dir);	struct nfs_removeargs *args = msg->rpc_argp;	struct nfs_removeres *res = msg->rpc_resp;	args->bitmask = server->cache_consistency_bitmask;	res->server = server;	msg->rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_REMOVE];	nfs41_init_sequence(&args->seq_args, &res->seq_res, 1);}",3377
54,998,CVE-2011-2906,20,"static void pmcraid_initiate_reset(struct pmcraid_instance *pinstance){	struct pmcraid_cmd *cmd;	 	if (!pinstance->ioa_reset_in_progress) {		scsi_block_requests(pinstance->host);		cmd = pmcraid_get_free_cmd(pinstance);		if (cmd == NULL) {			pmcraid_err(""no cmnd blocks for initiate_reset\n"");			return;		}		pinstance->ioa_shutdown_type = SHUTDOWN_NONE;		pinstance->reset_cmd = cmd;		pinstance->force_ioa_reset = 1;		pmcraid_notify_ioastate(pinstance,					PMC_DEVICE_EVENT_RESET_START);		pmcraid_ioa_reset(cmd);	}}",6449
355,217,CVE-2012-3412,20,"static void efx_ethtool_get_wol(struct net_device *net_dev,				struct ethtool_wolinfo *wol){	struct efx_nic *efx = netdev_priv(net_dev);	return efx->type->get_wol(efx, wol);}",3091
279,249,CVE-2012-2375,20,"_nfs41_proc_secinfo_no_name(struct nfs_server *server, struct nfs_fh *fhandle,		    struct nfs_fsinfo *info, struct nfs4_secinfo_flavors *flavors){	struct nfs41_secinfo_no_name_args args = {		.style = SECINFO_STYLE_CURRENT_FH,	};	struct nfs4_secinfo_res res = {		.flavors = flavors,	};	struct rpc_message msg = {		.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_SECINFO_NO_NAME],		.rpc_argp = &args,		.rpc_resp = &res,	};	return nfs4_call_sync(server->client, server, &msg, &args.seq_args, &res.seq_res, 0);}",3226
287,1052,CVE-2011-1476,20,"midi_synth_close(int dev){	int             orig_dev = synth_devs[dev]->midi_dev;	leave_sysex(dev);	 	midi_devs[orig_dev]->outputc(orig_dev, 0xfe);	midi_devs[orig_dev]->close(orig_dev);}",6869
55,515,CVE-2012-0044,20,"int drm_mode_cursor_ioctl(struct drm_device *dev,			void *data, struct drm_file *file_priv){	struct drm_mode_cursor *req = data;	struct drm_mode_object *obj;	struct drm_crtc *crtc;	int ret = 0;	if (!drm_core_check_feature(dev, DRIVER_MODESET))		return -EINVAL;	if (!req->flags) {		DRM_ERROR(""no operation set\n"");		return -EINVAL;	}	mutex_lock(&dev->mode_config.mutex);	obj = drm_mode_object_find(dev, req->crtc_id, DRM_MODE_OBJECT_CRTC);	if (!obj) {		DRM_DEBUG_KMS(""Unknown CRTC ID %d\n"", req->crtc_id);		ret = -EINVAL;		goto out;	}	crtc = obj_to_crtc(obj);	if (req->flags & DRM_MODE_CURSOR_BO) {		if (!crtc->funcs->cursor_set) {			DRM_ERROR(""crtc does not support cursor\n"");			ret = -ENXIO;			goto out;		}		 		ret = crtc->funcs->cursor_set(crtc, file_priv, req->handle,					      req->width, req->height);	}	if (req->flags & DRM_MODE_CURSOR_MOVE) {		if (crtc->funcs->cursor_move) {			ret = crtc->funcs->cursor_move(crtc, req->x, req->y);		} else {			DRM_ERROR(""crtc does not support cursor\n"");			ret = -EFAULT;			goto out;		}	}out:	mutex_unlock(&dev->mode_config.mutex);	return ret;}",4288
267,338,CVE-2012-2375,20,"static void nfs4_layoutreturn_done(struct rpc_task *task, void *calldata){	struct nfs4_layoutreturn *lrp = calldata;	struct nfs_server *server;	struct pnfs_layout_hdr *lo = lrp->args.layout;	dprintk(""--> %s\n"", __func__);	if (!nfs4_sequence_done(task, &lrp->res.seq_res))		return;	server = NFS_SERVER(lrp->args.inode);	if (nfs4_async_handle_error(task, server, NULL) == -EAGAIN) {		rpc_restart_call_prepare(task);		return;	}	spin_lock(&lo->plh_inode->i_lock);	if (task->tk_status == 0) {		if (lrp->res.lrs_present) {			pnfs_set_layout_stateid(lo, &lrp->res.stateid, true);		} else			BUG_ON(!list_empty(&lo->plh_segs));	}	lo->plh_block_lgets--;	spin_unlock(&lo->plh_inode->i_lock);	dprintk(""<-- %s\n"", __func__);}",3315
242,426,CVE-2012-2375,20,"static int nfs4_verify_fore_channel_attrs(struct nfs41_create_session_args *args, struct nfs4_session *session){	struct nfs4_channel_attrs *sent = &args->fc_attrs;	struct nfs4_channel_attrs *rcvd = &session->fc_attrs;	if (rcvd->max_resp_sz > sent->max_resp_sz)		return -EINVAL;	 	if (rcvd->max_ops < sent->max_ops)		return -EINVAL;	if (rcvd->max_reqs == 0)		return -EINVAL;	if (rcvd->max_reqs > NFS4_MAX_SLOT_TABLE)		rcvd->max_reqs = NFS4_MAX_SLOT_TABLE;	return 0;}",3403
178,169,CVE-2012-3412,20,"void efx_get_irq_moderation(struct efx_nic *efx, unsigned int *tx_usecs,			    unsigned int *rx_usecs, int *rx_adaptive){	*rx_adaptive = efx->irq_rx_adaptive;	*rx_usecs = efx->irq_rx_moderation * EFX_IRQ_MOD_RESOLUTION;	 	if (efx->tx_channel_offset == 0)		*tx_usecs = *rx_usecs;	else		*tx_usecs =			efx->channel[efx->tx_channel_offset]->irq_moderation *			EFX_IRQ_MOD_RESOLUTION;}",3043
328,1016,CVE-2011-2906,20,"static void pmcraid_release_config_buffers(struct pmcraid_instance *pinstance){	if (pinstance->cfg_table != NULL &&	    pinstance->cfg_table_bus_addr != 0) {		pci_free_consistent(pinstance->pdev,				    sizeof(struct pmcraid_config_table),				    pinstance->cfg_table,				    pinstance->cfg_table_bus_addr);		pinstance->cfg_table = NULL;		pinstance->cfg_table_bus_addr = 0;	}	if (pinstance->res_entries != NULL) {		int i;		for (i = 0; i < PMCRAID_MAX_RESOURCES; i++)			list_del(&pinstance->res_entries[i].queue);		kfree(pinstance->res_entries);		pinstance->res_entries = NULL;	}	pmcraid_release_hcams(pinstance);}",6467
305,1097,CVE-2013-7010,20,"static inline void avg_tpel_pixels_mc10_c(int *dst, const int *src, int stride, int width, int height){    int i,j;    for (i=0; i < height; i++) {      for (j=0; j < width; j++) {        dst[j] = (dst[j] + ((683*(2*src[j] + src[j+1] + 1)) >> 11) + 1) >> 1;      }      src += stride;      dst += stride;    }}",7086
49,280,CVE-2012-2375,20,"static void nfs41_call_sync_done(struct rpc_task *task, void *calldata){	struct nfs41_call_sync_data *data = calldata;	nfs41_sequence_done(task, data->seq_res);}",3257
256,654,CVE-2011-4131,20,"static int decode_attr_time_delta(struct xdr_stream *xdr, int *bitmap,				  struct timespec *time){	int status = 0;	time->tv_sec = 0;	time->tv_nsec = 0;	if (unlikely(bitmap[1] & (FATTR4_WORD1_TIME_DELTA - 1U)))		return -EIO;	if (likely(bitmap[1] & FATTR4_WORD1_TIME_DELTA)) {		status = decode_attr_time(xdr, time);		bitmap[1] &= ~FATTR4_WORD1_TIME_DELTA;	}	dprintk(""%s: time_delta=%ld %ld\n"", __func__, (long)time->tv_sec,		(long)time->tv_nsec);	return status;}",4995
64,425,CVE-2012-2375,20,"static int nfs4_verify_channel_attrs(struct nfs41_create_session_args *args,				     struct nfs4_session *session){	int ret;	ret = nfs4_verify_fore_channel_attrs(args, session);	if (ret)		return ret;	return nfs4_verify_back_channel_attrs(args, session);}",3402
17,112,CVE-2014-6269,20,"static int val_hdr(struct arg *arg, char **err_msg){	if (arg && arg[1].type == ARGT_SINT && arg[1].data.sint < -MAX_HDR_HISTORY) {		memprintf(err_msg, ""header occurrence must be >= %d"", -MAX_HDR_HISTORY);		return 0;	}	return 1;}",1776
134,1466,CVE-2015-4471,20,"static int lzxd_read_lens(struct lzxd_stream *lzx, unsigned char *lens,			  unsigned int first, unsigned int last){     register unsigned int bit_buffer;  register int bits_left, i;  register unsigned short sym;  unsigned char *i_ptr, *i_end;  unsigned int x, y;  int z;  RESTORE_BITS;       for (x = 0; x < 20; x++) {    READ_BITS(y, 4);    lzx->PRETREE_len[x] = y;  }  BUILD_TABLE(PRETREE);  for (x = first; x < last; ) {    READ_HUFFSYM(PRETREE, z);    if (z == 17) {             READ_BITS(y, 4); y += 4;      while (y--) lens[x++] = 0;    }    else if (z == 18) {             READ_BITS(y, 5); y += 20;      while (y--) lens[x++] = 0;    }    else if (z == 19) {             READ_BITS(y, 1); y += 4;      READ_HUFFSYM(PRETREE, z);      z = lens[x] - z; if (z < 0) z += 17;      while (y--) lens[x++] = z;    }    else {             z = lens[x] - z; if (z < 0) z += 17;      lens[x++] = z;    }  }  STORE_BITS;  return MSPACK_ERR_OK;}",13509
18,1545,CVE-2019-14763,20,"int __dwc3_gadget_ep_set_halt(struct dwc3_ep *dep, int value, int protocol){	struct dwc3_gadget_ep_cmd_params	params;	struct dwc3				*dwc = dep->dwc;	int					ret;	if (usb_endpoint_xfer_isoc(dep->endpoint.desc)) {		dev_err(dwc->dev, ""%s is of Isochronous type\n"", dep->name);		return -EINVAL;	}	memset(&params, 0x00, sizeof(params));	if (value) {		struct dwc3_trb *trb;		unsigned transfer_in_flight;		unsigned started;		if (dep->flags & DWC3_EP_STALL)			return 0;		if (dep->number > 1)			trb = dwc3_ep_prev_trb(dep, dep->trb_enqueue);		else			trb = &dwc->ep0_trb[dep->trb_enqueue];		transfer_in_flight = trb->ctrl & DWC3_TRB_CTRL_HWO;		started = !list_empty(&dep->started_list);		if (!protocol && ((dep->direction && transfer_in_flight) ||				(!dep->direction && started))) {			return -EAGAIN;		}		ret = dwc3_send_gadget_ep_cmd(dep, DWC3_DEPCMD_SETSTALL,				&params);		if (ret)			dev_err(dwc->dev, ""failed to set STALL on %s\n"",					dep->name);		else			dep->flags |= DWC3_EP_STALL;	} else {		if (!(dep->flags & DWC3_EP_STALL))			return 0;		ret = dwc3_send_clear_stall_ep_cmd(dep);		if (ret)			dev_err(dwc->dev, ""failed to clear STALL on %s\n"",					dep->name);		else			dep->flags &= ~(DWC3_EP_STALL | DWC3_EP_WEDGE);	}	return ret;}",26654
56,516,CVE-2012-0044,20,"void drm_mode_destroy(struct drm_device *dev, struct drm_display_mode *mode){	drm_mode_object_put(dev, &mode->base);	kfree(mode);}",4289
44,961,CVE-2011-3191,20,"__smb_init(int smb_command, int wct, struct cifs_tcon *tcon,			void **request_buf, void **response_buf){	*request_buf = cifs_buf_get();	if (*request_buf == NULL) {		 		return -ENOMEM;	}                    	if (response_buf)		*response_buf = *request_buf;	header_assemble((struct smb_hdr *) *request_buf, smb_command, tcon,			wct);	if (tcon != NULL)		cifs_stats_inc(&tcon->num_smbs_sent);	return 0;}",5729
268,1387,CVE-2014-4656,20,"static void snd_ctl_empty_read_queue(struct snd_ctl_file * ctl){	unsigned long flags;	struct snd_kctl_event *cread;		spin_lock_irqsave(&ctl->read_lock, flags);	while (!list_empty(&ctl->events)) {		cread = snd_kctl_event(ctl->events.next);		list_del(&cread->list);		kfree(cread);	}	spin_unlock_irqrestore(&ctl->read_lock, flags);}",10821
121,1719,CVE-2014-6269,20,"static void si_conn_send(struct connection *conn){	struct stream_interface *si = conn->owner;	struct channel *chn = si->ob;	int ret;        if (chn->pipe && conn->xprt->snd_pipe) {                ret = conn->xprt->snd_pipe(conn, chn->pipe);                if (ret > 0)                       chn->flags |= CF_WRITE_PARTIAL;                 if (!chn->pipe->data) {                        put_pipe(chn->pipe);			chn->pipe = NULL;		}		if (conn->flags & CO_FL_ERROR)			return;	}	 	if (!chn->buf->o)		return;	 	if (!(conn->flags & (CO_FL_ERROR | CO_FL_SOCK_WR_SH | CO_FL_DATA_WR_SH | CO_FL_WAIT_DATA | CO_FL_HANDSHAKE))) {		 		unsigned int send_flag = 0;		if ((!(chn->flags & (CF_NEVER_WAIT|CF_SEND_DONTWAIT)) &&		     ((chn->to_forward && chn->to_forward != CHN_INFINITE_FORWARD) ||		      (chn->flags & CF_EXPECT_MORE))) ||		    ((chn->flags & (CF_SHUTW|CF_SHUTW_NOW)) == CF_SHUTW_NOW))			send_flag |= CO_SFL_MSG_MORE;		if (chn->flags & CF_STREAMER)			send_flag |= CO_SFL_STREAMER;                 ret = conn->xprt->snd_buf(conn, chn->buf, send_flag);                if (ret > 0) {                       chn->flags |= CF_WRITE_PARTIAL;                         if (!chn->buf->o) {                                 				chn->flags &= ~(CF_EXPECT_MORE | CF_SEND_DONTWAIT);			}			 		}	}	return;}",30905
379,1363,CVE-2013-0211,20,"archive_write_set_bytes_in_last_block(struct archive *_a, int bytes){	struct archive_write *a = (struct archive_write *)_a;	archive_check_magic(&a->archive, ARCHIVE_WRITE_MAGIC,	    ARCHIVE_STATE_ANY, ""archive_write_set_bytes_in_last_block"");	a->bytes_in_last_block = bytes;	return (ARCHIVE_OK);}",9827
378,678,CVE-2011-4131,20,"static int decode_open_downgrade(struct xdr_stream *xdr, struct nfs_closeres *res){	int status;	status = decode_op_hdr(xdr, OP_OPEN_DOWNGRADE);	if (status != -EIO)		nfs_increment_open_seqid(status, res->seqid);	if (!status)		status = decode_stateid(xdr, &res->stateid);	return status;}",5019
391,1491,CVE-2015-4001,20,static void oz_hcd_shutdown(struct usb_hcd *hcd){},13567
383,1648,CVE-2019-14763,20,"void ghid_cleanup(void){	if (major) {		unregister_chrdev_region(MKDEV(major, 0), minors);		major = minors = 0;	}	class_destroy(hidg_class);	hidg_class = NULL;}",28866
118,1550,CVE-2019-14763,20,"static void dwc3_free_trb_pool(struct dwc3_ep *dep){	struct dwc3		*dwc = dep->dwc;	dma_free_coherent(dwc->sysdev, sizeof(struct dwc3_trb) * DWC3_TRB_NUM,			dep->trb_pool, dep->trb_pool_dma);	dep->trb_pool = NULL;	dep->trb_pool_dma = 0;}",26659
354,1420,CVE-2014-2889,20,static inline int is_imm8(int value){	return value <= 127 && value >= -128;},11611
363,943,CVE-2011-3209,20,"static int slab_memory_callback(struct notifier_block *self,				unsigned long action, void *arg){	int ret = 0;	switch (action) {	case MEM_GOING_ONLINE:		ret = slab_mem_going_online_callback(arg);		break;	case MEM_GOING_OFFLINE:		ret = slab_mem_going_offline_callback(arg);		break;	case MEM_OFFLINE:	case MEM_CANCEL_ONLINE:		slab_mem_offline_callback(arg);		break;	case MEM_ONLINE:	case MEM_CANCEL_OFFLINE:		break;	}	ret = notifier_from_errno(ret);	return ret;}",5711
263,1513,CVE-2014-9683,20,static void set_extent_mask_and_shift(struct ecryptfs_crypt_stat *crypt_stat){	int extent_size_tmp;	crypt_stat->extent_mask = 0xFFFFFFFF;	crypt_stat->extent_shift = 0;	if (crypt_stat->extent_size == 0)		return;	extent_size_tmp = crypt_stat->extent_size;	while ((extent_size_tmp & 0x01) == 0) {		extent_size_tmp >>= 1;		crypt_stat->extent_mask <<= 1;		crypt_stat->extent_shift++;	}},14167
317,260,CVE-2012-2375,20,"static int _nfs4_proc_create_session(struct nfs_client *clp){	struct nfs4_session *session = clp->cl_session;	struct nfs41_create_session_args args = {		.client = clp,		.cb_program = NFS4_CALLBACK,	};	struct nfs41_create_session_res res = {		.client = clp,	};	struct rpc_message msg = {		.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_CREATE_SESSION],		.rpc_argp = &args,		.rpc_resp = &res,	};	int status;	nfs4_init_channel_attrs(&args);	args.flags = (SESSION4_PERSIST | SESSION4_BACK_CHAN);	status = rpc_call_sync(session->clp->cl_rpcclient, &msg, RPC_TASK_TIMEOUT);	if (!status)		 		status = nfs4_verify_channel_attrs(&args, session);	if (!status) {		 		clp->cl_seqid++;	}	return status;}",3237
327,1352,CVE-2013-0211,20,__archive_write_close_filter(struct archive_write_filter *f){	if (f->close != NULL)		return (f->close)(f);	if (f->next_filter != NULL)		return (__archive_write_close_filter(f->next_filter));	return (ARCHIVE_OK);},9816
205,732,CVE-2011-4131,20,"encode_secinfo_no_name(struct xdr_stream *xdr,		       const struct nfs41_secinfo_no_name_args *args,		       struct compound_hdr *hdr){	__be32 *p;	p = reserve_space(xdr, 8);	*p++ = cpu_to_be32(OP_SECINFO_NO_NAME);	*p++ = cpu_to_be32(args->style);	hdr->nops++;	hdr->replen += decode_secinfo_no_name_maxsz;	return 0;}",5073
95,1606,CVE-2019-7308,20,"static int is_ctx_reg(struct bpf_verifier_env *env, int regno){	const struct bpf_reg_state *reg = reg_state(env, regno);	return reg->type == PTR_TO_CTX ||	       reg->type == PTR_TO_SOCKET;}",27319
332,221,CVE-2012-3412,20,"static int efx_ethtool_set_wol(struct net_device *net_dev,			       struct ethtool_wolinfo *wol){	struct efx_nic *efx = netdev_priv(net_dev);	return efx->type->set_wol(efx, wol->wolopts);}",3095
240,985,CVE-2011-2906,20,"static int pmcraid_chr_fasync(int fd, struct file *filep, int mode){	struct pmcraid_instance *pinstance;	int rc;	pinstance = filep->private_data;	mutex_lock(&pinstance->aen_queue_lock);	rc = fasync_helper(fd, filep, mode, &pinstance->aen_queue);	mutex_unlock(&pinstance->aen_queue_lock);	return rc;}",6436
230,201,CVE-2012-3412,20,"static int efx_set_mac_address(struct net_device *net_dev, void *data){	struct efx_nic *efx = netdev_priv(net_dev);	struct sockaddr *addr = data;	char *new_addr = addr->sa_data;	EFX_ASSERT_RESET_SERIALISED(efx);	if (!is_valid_ether_addr(new_addr)) {		netif_err(efx, drv, efx->net_dev,			  ""invalid ethernet MAC address requested: %pM\n"",			  new_addr);		return -EINVAL;	}	memcpy(net_dev->dev_addr, new_addr, net_dev->addr_len);	 	mutex_lock(&efx->mac_lock);	efx->mac_op->reconfigure(efx);	mutex_unlock(&efx->mac_lock);	return 0;}",3075
33,801,CVE-2011-4131,20,"static void nfs4_xdr_enc_getdeviceinfo(struct rpc_rqst *req,				       struct xdr_stream *xdr,				       struct nfs4_getdeviceinfo_args *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_getdeviceinfo(xdr, args, &hdr);	 	xdr_inline_pages(&req->rq_rcv_buf, (hdr.replen - 2) << 2,			 args->pdev->pages, args->pdev->pgbase,			 args->pdev->pglen);	encode_nops(&hdr);}",5142
359,861,CVE-2011-3209,20,"void posix_cpu_timer_schedule(struct k_itimer *timer){	struct task_struct *p = timer->it.cpu.task;	union cpu_time_count now;	if (unlikely(p == NULL))		 		goto out;	 	if (CPUCLOCK_PERTHREAD(timer->it_clock)) {		cpu_clock_sample(timer->it_clock, p, &now);		bump_cpu_timer(timer, now);		if (unlikely(p->exit_state)) {			clear_dead_task(timer, now);			goto out;		}		read_lock(&tasklist_lock);  	} else {		read_lock(&tasklist_lock);		if (unlikely(p->signal == NULL)) {			 			put_task_struct(p);			timer->it.cpu.task = p = NULL;			timer->it.cpu.expires.sched = 0;			goto out_unlock;		} else if (unlikely(p->exit_state) && thread_group_empty(p)) {			 			clear_dead_task(timer, now);			goto out_unlock;		}		cpu_clock_sample_group(timer->it_clock, p, &now);		bump_cpu_timer(timer, now);		 	}	 	arm_timer(timer, now);out_unlock:	read_unlock(&tasklist_lock);out:	timer->it_overrun_last = timer->it_overrun;	timer->it_overrun = -1;	++timer->it_requeue_pending;}",5629
375,1101,CVE-2013-7010,20,"static inline void avg_tpel_pixels_mc21_c(int *dst, const int *src, int stride, int width, int height){    int i,j;    for (i=0; i < height; i++) {      for (j=0; j < width; j++) {        dst[j] = (dst[j] + ((2731*(3*src[j] + 4*src[j+1] + 2*src[j+stride] + 3*src[j+stride+1] + 6)) >> 15) + 1) >> 1;      }      src += stride;      dst += stride;    }}",7090
23,1570,CVE-2019-14763,20,"static int dwc3_gadget_start(struct usb_gadget *g,		struct usb_gadget_driver *driver){	struct dwc3		*dwc = gadget_to_dwc(g);	unsigned long		flags;	int			ret = 0;	int			irq;	irq = dwc->irq_gadget;	ret = request_threaded_irq(irq, dwc3_interrupt, dwc3_thread_interrupt,			IRQF_SHARED, ""dwc3"", dwc->ev_buf);	if (ret) {		dev_err(dwc->dev, ""failed to request irq #%d --> %d\n"",				irq, ret);		goto err0;	}	spin_lock_irqsave(&dwc->lock, flags);	if (dwc->gadget_driver) {		dev_err(dwc->dev, ""%s is already bound to %s\n"",				dwc->gadget.name,				dwc->gadget_driver->driver.name);		ret = -EBUSY;		goto err1;	}	dwc->gadget_driver	= driver;	if (pm_runtime_active(dwc->dev))		__dwc3_gadget_start(dwc);	spin_unlock_irqrestore(&dwc->lock, flags);	return 0;err1:	spin_unlock_irqrestore(&dwc->lock, flags);	free_irq(irq, dwc);err0:	return ret;}",26679
127,90,CVE-2014-6269,20,"smp_fetch_fhdr_cnt(struct proxy *px, struct session *l4, void *l7, unsigned int opt,                  const struct arg *args, struct sample *smp, const char *kw){	struct http_txn *txn = l7;	struct hdr_idx *idx = &txn->hdr_idx;	struct hdr_ctx ctx;	const struct http_msg *msg = ((opt & SMP_OPT_DIR) == SMP_OPT_DIR_REQ) ? &txn->req : &txn->rsp;	int cnt;	if (!args || args->type != ARGT_STR)		return 0;	CHECK_HTTP_MESSAGE_FIRST();	ctx.idx = 0;	cnt = 0;	while (http_find_full_header2(args->data.str.str, args->data.str.len, msg->chn->buf->p, idx, &ctx))		cnt++;	smp->type = SMP_T_UINT;	smp->data.uint = cnt;	smp->flags = SMP_F_VOL_HDR;	return 1;}",1754
253,853,CVE-2011-3209,20,static int mmtimer_int_pending(int comparator){	if (HUB_L((unsigned long *)LOCAL_MMR_ADDR(SH_EVENT_OCCURRED)) &			SH_EVENT_OCCURRED_RTC1_INT_MASK << comparator)		return 1;	else		return 0;},5621
251,1526,CVE-2016-2070,20,"static int tcp_prune_queue(struct sock *sk){	struct tcp_sock *tp = tcp_sk(sk);	SOCK_DEBUG(sk, ""prune_queue: c=%x\n"", tp->copied_seq);	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PRUNECALLED);	if (atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf)		tcp_clamp_window(sk);	else if (tcp_under_memory_pressure(sk))		tp->rcv_ssthresh = min(tp->rcv_ssthresh, 4U * tp->advmss);	tcp_collapse_ofo_queue(sk);	if (!skb_queue_empty(&sk->sk_receive_queue))		tcp_collapse(sk, &sk->sk_receive_queue,			     skb_peek(&sk->sk_receive_queue),			     NULL,			     tp->copied_seq, tp->rcv_nxt);	sk_mem_reclaim(sk);	if (atomic_read(&sk->sk_rmem_alloc) <= sk->sk_rcvbuf)		return 0;	 	tcp_prune_ofo_queue(sk);	if (atomic_read(&sk->sk_rmem_alloc) <= sk->sk_rcvbuf)		return 0;	 	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_RCVPRUNED);	 	tp->pred_flags = 0;	return -1;}",18009
176,922,CVE-2011-3209,20,static void kmem_cache_release(struct kobject *kobj){	struct kmem_cache *s = to_slab(kobj);	kfree(s);},5690
198,1684,CVE-2012-2807,20,__xmlParserVersion(void) {    if (IS_MAIN_THREAD)	return (&xmlParserVersion);    else	return (&xmlGetGlobalState()->xmlParserVersion);},29270
288,80,CVE-2014-6269,20,"smp_fetch_capture_header_req(struct proxy *px, struct session *l4, void *l7, unsigned int opt,                 const struct arg *args, struct sample *smp, const char *kw){	struct proxy *fe = l4->fe;	struct http_txn *txn = l7;	int idx;	if (!args || args->type != ARGT_UINT)		return 0;	idx = args->data.uint;	if (idx > (fe->nb_req_cap - 1) || txn->req.cap == NULL || txn->req.cap[idx] == NULL)		return 0;	smp->type = SMP_T_STR;	smp->flags |= SMP_F_CONST;	smp->data.str.str = txn->req.cap[idx];	smp->data.str.len = strlen(txn->req.cap[idx]);	return 1;}",1744
187,1525,CVE-2016-2070,20,"static int tcp_prune_ofo_queue(struct sock *sk){	struct tcp_sock *tp = tcp_sk(sk);	int res = false;	if (!skb_queue_empty(&tp->out_of_order_queue)) {		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_OFOPRUNED);		__skb_queue_purge(&tp->out_of_order_queue);		 		if (tp->rx_opt.sack_ok)			tcp_sack_reset(&tp->rx_opt);		sk_mem_reclaim(sk);		res = true;	}	return res;}",18008
246,341,CVE-2012-2375,20,"static void nfs4_lock_done(struct rpc_task *task, void *calldata){	struct nfs4_lockdata *data = calldata;	dprintk(""%s: begin!\n"", __func__);	if (!nfs4_sequence_done(task, &data->res.seq_res))		return;	data->rpc_status = task->tk_status;	if (data->arg.new_lock_owner != 0) {		if (data->rpc_status == 0)			nfs_confirm_seqid(&data->lsp->ls_seqid, 0);		else			goto out;	}	if (data->rpc_status == 0) {		nfs4_stateid_copy(&data->lsp->ls_stateid, &data->res.stateid);		data->lsp->ls_flags |= NFS_LOCK_INITIALIZED;		renew_lease(NFS_SERVER(data->ctx->dentry->d_inode), data->timestamp);	}out:	dprintk(""%s: done, ret = %d!\n"", __func__, data->rpc_status);}",3318
180,637,CVE-2011-4131,20,"static int decode_attr_layout_blksize(struct xdr_stream *xdr, int *bitmap,				      int *res){	__be32 *p;	dprintk(""%s: bitmap is %x\n"", __func__, bitmap[2]);	*res = 0;	if (bitmap[2] & FATTR4_WORD2_LAYOUT_BLKSIZE) {		p = xdr_inline_decode(xdr, 4);		if (unlikely(!p)) {			print_overflow_msg(__func__, xdr);			return -EIO;		}		*res = be32_to_cpup(p);		bitmap[2] &= ~FATTR4_WORD2_LAYOUT_BLKSIZE;	}	return 0;}",4978
3,1342,CVE-2013-2094,20,"static void perf_swevent_init_hrtimer(struct perf_event *event){	struct hw_perf_event *hwc = &event->hw;	if (!is_sampling_event(event))		return;	hrtimer_init(&hwc->hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);	hwc->hrtimer.function = perf_swevent_hrtimer;	 	if (event->attr.freq) {		long freq = event->attr.sample_freq;		event->attr.sample_period = NSEC_PER_SEC / freq;		hwc->sample_period = event->attr.sample_period;		local64_set(&hwc->period_left, hwc->sample_period);		hwc->last_period = hwc->sample_period;		event->attr.freq = 0;	}}",8930
343,1358,CVE-2013-0211,20,"_archive_write_close(struct archive *_a){	struct archive_write *a = (struct archive_write *)_a;	int r = ARCHIVE_OK, r1 = ARCHIVE_OK;	archive_check_magic(&a->archive, ARCHIVE_WRITE_MAGIC,	    ARCHIVE_STATE_ANY | ARCHIVE_STATE_FATAL,	    ""archive_write_close"");	if (a->archive.state == ARCHIVE_STATE_NEW	    || a->archive.state == ARCHIVE_STATE_CLOSED)		return (ARCHIVE_OK);  	archive_clear_error(&a->archive);	 	if (a->archive.state == ARCHIVE_STATE_DATA	    && a->format_finish_entry != NULL)		r = ((a->format_finish_entry)(a));	 	 	if (a->format_close != NULL) {		r1 = (a->format_close)(a);		if (r1 < r)			r = r1;	}	 	r1 = __archive_write_close_filter(a->filter_first);	if (r1 < r)		r = r1;	if (a->archive.state != ARCHIVE_STATE_FATAL)		a->archive.state = ARCHIVE_STATE_CLOSED;	return (r);}",9822
435,236,CVE-2012-3412,20,"static int tso_get_head_fragment(struct tso_state *st, struct efx_nic *efx,				 const struct sk_buff *skb){	int hl = st->header_len;	int len = skb_headlen(skb) - hl;	st->unmap_addr = pci_map_single(efx->pci_dev, skb->data + hl,					len, PCI_DMA_TODEVICE);	if (likely(!pci_dma_mapping_error(efx->pci_dev, st->unmap_addr))) {		st->unmap_single = true;		st->unmap_len = len;		st->in_len = len;		st->dma_addr = st->unmap_addr;		return 0;	}	return -ENOMEM;}",3110
25,1395,CVE-2014-4656,20,"int snd_ctl_remove_id(struct snd_card *card, struct snd_ctl_elem_id *id){	struct snd_kcontrol *kctl;	int ret;	down_write(&card->controls_rwsem);	kctl = snd_ctl_find_id(card, id);	if (kctl == NULL) {		up_write(&card->controls_rwsem);		return -ENOENT;	}	ret = snd_ctl_remove(card, kctl);	up_write(&card->controls_rwsem);	return ret;}",10829
97,321,CVE-2012-2375,20,"static inline void nfs4_exclusive_attrset(struct nfs4_opendata *opendata, struct iattr *sattr){	if ((opendata->o_res.attrset[1] & FATTR4_WORD1_TIME_ACCESS) &&	    !(sattr->ia_valid & ATTR_ATIME_SET))		sattr->ia_valid |= ATTR_ATIME;	if ((opendata->o_res.attrset[1] & FATTR4_WORD1_TIME_MODIFY) &&	    !(sattr->ia_valid & ATTR_MTIME_SET))		sattr->ia_valid |= ATTR_MTIME;}",3298
48,968,CVE-2011-3191,20,"small_smb_init(int smb_command, int wct, struct cifs_tcon *tcon,		void **request_buf){	int rc;	rc = cifs_reconnect_tcon(tcon, smb_command);	if (rc)		return rc;	*request_buf = cifs_small_buf_get();	if (*request_buf == NULL) {		 		return -ENOMEM;	}	header_assemble((struct smb_hdr *) *request_buf, smb_command,			tcon, wct);	if (tcon != NULL)		cifs_stats_inc(&tcon->num_smbs_sent);	return 0;}",5736
431,414,CVE-2012-2375,20,"void nfs4_reset_write(struct rpc_task *task, struct nfs_write_data *data){	dprintk(""%s Reset task for i/o through\n"", __func__);	put_lseg(data->lseg);	data->lseg          = NULL;	data->ds_clp        = NULL;	data->write_done_cb = nfs4_write_done_cb;	data->args.fh       = NFS_FH(data->inode);	data->args.bitmask  = data->res.server->cache_consistency_bitmask;	data->args.offset   = data->mds_offset;	data->res.fattr     = &data->fattr;	task->tk_ops        = data->mds_ops;	rpc_task_reset_client(task, NFS_CLIENT(data->inode));}",3391
167,1372,CVE-2014-4656,20,"int snd_ctl_activate_id(struct snd_card *card, struct snd_ctl_elem_id *id,			int active){	struct snd_kcontrol *kctl;	struct snd_kcontrol_volatile *vd;	unsigned int index_offset;	int ret;	down_write(&card->controls_rwsem);	kctl = snd_ctl_find_id(card, id);	if (kctl == NULL) {		ret = -ENOENT;		goto unlock;	}	index_offset = snd_ctl_get_ioff(kctl, &kctl->id);	vd = &kctl->vd[index_offset];	ret = 0;	if (active) {		if (!(vd->access & SNDRV_CTL_ELEM_ACCESS_INACTIVE))			goto unlock;		vd->access &= ~SNDRV_CTL_ELEM_ACCESS_INACTIVE;	} else {		if (vd->access & SNDRV_CTL_ELEM_ACCESS_INACTIVE)			goto unlock;		vd->access |= SNDRV_CTL_ELEM_ACCESS_INACTIVE;	}	ret = 1; unlock:	up_write(&card->controls_rwsem);	if (ret > 0)		snd_ctl_notify(card, SNDRV_CTL_EVENT_MASK_INFO, id);	return ret;}",10806
366,907,CVE-2011-3209,20,static void free_kmem_cache_nodes(struct kmem_cache *s){},5675
235,631,CVE-2011-4131,20,"static int decode_attr_fileid(struct xdr_stream *xdr, int *bitmap, int *fileid){	__be32 *p;	int ret = 0;	*fileid = 0;	if (unlikely(bitmap[0] & (FATTR4_WORD0_FILEID - 1U)))		return -EIO;	if (likely(bitmap[0] & FATTR4_WORD0_FILEID)) {		p = xdr_inline_decode(xdr, 8);		if (unlikely(!p))			goto out_overflow;		xdr_decode_hyper(p, fileid);		bitmap[0] &= ~FATTR4_WORD0_FILEID;		ret = NFS_ATTR_FATTR_FILEID;	}	dprintk(""%s: fileid=%Lu\n"", __func__, (unsigned long long)*fileid);	return ret;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",4972
43,1167,CVE-2013-6376,20,"static inline int apic_lvt_enabled(struct kvm_lapic *apic, int lvt_type){	return !(kvm_apic_get_reg(apic, lvt_type) & APIC_LVT_MASKED);}",7368
143,180,CVE-2012-3412,20,"static int efx_pm_poweroff(struct device *dev){	struct pci_dev *pci_dev = to_pci_dev(dev);	struct efx_nic *efx = pci_get_drvdata(pci_dev);	efx->type->fini(efx);	efx->reset_pending = 0;	pci_save_state(pci_dev);	return pci_set_power_state(pci_dev, PCI_D3hot);}",3054
199,964,CVE-2011-3191,20,"cifs_reconnect_tcon(struct cifs_tcon *tcon, int smb_command){	int rc;	struct cifs_ses *ses;	struct TCP_Server_Info *server;	struct nls_table *nls_codepage;	 	if (!tcon)		return 0;	ses = tcon->ses;	server = ses->server;	 	if (tcon->tidStatus == CifsExiting) {		if (smb_command != SMB_COM_WRITE_ANDX &&		    smb_command != SMB_COM_OPEN_ANDX &&		    smb_command != SMB_COM_TREE_DISCONNECT) {			cFYI(1, ""can not send cmd %d while umounting"",				smb_command);			return -ENODEV;		}	}	 	while (server->tcpStatus == CifsNeedReconnect) {		wait_event_interruptible_timeout(server->response_q,			(server->tcpStatus != CifsNeedReconnect), 10 * HZ);		 		if (server->tcpStatus != CifsNeedReconnect)			break;		 		if (!tcon->retry) {			cFYI(1, ""gave up waiting on reconnect in smb_init"");			return -EHOSTDOWN;		}	}	if (!ses->need_reconnect && !tcon->need_reconnect)		return 0;	nls_codepage = load_nls_default();	 	mutex_lock(&ses->session_mutex);	rc = cifs_negotiate_protocol(0, ses);	if (rc == 0 && ses->need_reconnect)		rc = cifs_setup_session(0, ses, nls_codepage);	 	if (rc || !tcon->need_reconnect) {		mutex_unlock(&ses->session_mutex);		goto out;	}	mark_open_files_invalid(tcon);	rc = CIFSTCon(0, ses, tcon->treeName, tcon, nls_codepage);	mutex_unlock(&ses->session_mutex);	cFYI(1, ""reconnect tcon rc = %d"", rc);	if (rc)		goto out;	 	atomic_inc(&tconInfoReconnectCount);	 	if (ses->capabilities & CAP_UNIX)		reset_cifs_unix_caps(0, tcon, NULL, NULL);	 out:	 	switch (smb_command) {	case SMB_COM_READ_ANDX:	case SMB_COM_WRITE_ANDX:	case SMB_COM_CLOSE:	case SMB_COM_FIND_CLOSE2:	case SMB_COM_LOCKING_ANDX:		rc = -EAGAIN;	}	unload_nls(nls_codepage);	return rc;}",5732
85,519,CVE-2012-0044,20,"int drm_mode_getblob_ioctl(struct drm_device *dev,			   void *data, struct drm_file *file_priv){	struct drm_mode_object *obj;	struct drm_mode_get_blob *out_resp = data;	struct drm_property_blob *blob;	int ret = 0;	void *blob_ptr;	if (!drm_core_check_feature(dev, DRIVER_MODESET))		return -EINVAL;	mutex_lock(&dev->mode_config.mutex);	obj = drm_mode_object_find(dev, out_resp->blob_id, DRM_MODE_OBJECT_BLOB);	if (!obj) {		ret = -EINVAL;		goto done;	}	blob = obj_to_blob(obj);	if (out_resp->length == blob->length) {		blob_ptr = (void *)(unsigned long)out_resp->data;		if (copy_to_user(blob_ptr, blob->data, blob->length)){			ret = -EFAULT;			goto done;		}	}	out_resp->length = blob->length;done:	mutex_unlock(&dev->mode_config.mutex);	return ret;}",4292
29,797,CVE-2011-4131,20,"static void nfs4_xdr_enc_free_stateid(struct rpc_rqst *req,				     struct xdr_stream *xdr,				     struct nfs41_free_stateid_args *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_free_stateid(xdr, args, &hdr);	encode_nops(&hdr);}",5138
412,1163,CVE-2013-6376,20,static inline int apic_enabled(struct kvm_lapic *apic){	return kvm_apic_sw_enabled(apic) &&	kvm_apic_hw_enabled(apic);},7364
338,1498,CVE-2015-4001,20,static int oz_plat_resume(struct platform_device *dev){	return 0;},13574
243,1139,CVE-2013-7010,20,"static int ssd_int8_vs_int16_c(const int *pix1, const int *pix2,                               int size){    int score=0;    int i;    for(i=0; i<size; i++)        score += (pix1[i]-pix2[i])*(pix1[i]-pix2[i]);    return score;}",7128
41,1499,CVE-2015-4001,20,static void oz_plat_shutdown(struct platform_device *dev){},13575
62,1432,CVE-2014-2669,20,"rintop(PG_FUNCTION_ARGS){	 	return DirectFunctionCall2(intop,							   PG_GETARG_DATUM(1),							   PG_GETARG_DATUM(0));}",11810
67,31,CVE-2012-5667,20,color_cap_rv_fct (void){     color_option = -1;   },1033
149,1176,CVE-2013-6376,20,"static void apic_sync_pv_eoi_from_guest(struct kvm_vcpu *vcpu,					struct kvm_lapic *apic){	int pending;	int vector;	 	BUG_ON(!pv_eoi_enabled(vcpu));	pending = pv_eoi_get_pending(vcpu);	 	pv_eoi_clr_pending(vcpu);	if (pending)		return;	vector = apic_set_eoi(apic);	trace_kvm_pv_eoi(apic, vector);}",7377
257,166,CVE-2012-3412,20,"static void efx_fini_port(struct efx_nic *efx){	netif_dbg(efx, drv, efx->net_dev, ""shut down port\n"");	if (!efx->port_initialized)		return;	efx->phy_op->fini(efx);	efx->port_initialized = false;	efx->link_state.up = false;	efx_link_status_changed(efx);}",3040
239,827,CVE-2011-4131,20,"static void nfs4_xdr_enc_server_caps(struct rpc_rqst *req,				     struct xdr_stream *xdr,				     struct nfs4_server_caps_arg *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_putfh(xdr, args->fhandle, &hdr);	encode_getattr_one(xdr, FATTR4_WORD0_SUPPORTED_ATTRS|			   FATTR4_WORD0_LINK_SUPPORT|			   FATTR4_WORD0_SYMLINK_SUPPORT|			   FATTR4_WORD0_ACLSUPPORT, &hdr);	encode_nops(&hdr);}",5168
128,219,CVE-2012-3412,20,"static int efx_ethtool_phys_id(struct net_device *net_dev,			       enum ethtool_phys_id_state state){	struct efx_nic *efx = netdev_priv(net_dev);	enum efx_led_mode mode = EFX_LED_DEFAULT;	switch (state) {	case ETHTOOL_ID_ON:		mode = EFX_LED_ON;		break;	case ETHTOOL_ID_OFF:		mode = EFX_LED_OFF;		break;	case ETHTOOL_ID_INACTIVE:		mode = EFX_LED_DEFAULT;		break;	case ETHTOOL_ID_ACTIVE:		return 1;	 	}	efx->type->set_id_led(efx, mode);	return 0;}",3093
392,1662,CVE-2012-2807,20,__htmlDefaultSAXHandler(void) {    if (IS_MAIN_THREAD)	return (&htmlDefaultSAXHandler);    else	return (&xmlGetGlobalState()->htmlDefaultSAXHandler);},29248
82,764,CVE-2011-4131,20,"static int nfs4_xdr_dec_open(struct rpc_rqst *rqstp, struct xdr_stream *xdr,			     struct nfs_openres *res){	struct compound_hdr hdr;	int status;	status = decode_compound_hdr(xdr, &hdr);	if (status)		goto out;	status = decode_sequence(xdr, &res->seq_res, rqstp);	if (status)		goto out;	status = decode_putfh(xdr);	if (status)		goto out;	status = decode_savefh(xdr);	if (status)		goto out;	status = decode_open(xdr, res);	if (status)		goto out;	if (decode_getfh(xdr, &res->fh) != 0)		goto out;	if (decode_getfattr(xdr, res->f_attr, res->server,				!RPC_IS_ASYNC(rqstp->rq_task)) != 0)		goto out;	if (decode_restorefh(xdr) != 0)		goto out;	decode_getfattr(xdr, res->dir_attr, res->server,			!RPC_IS_ASYNC(rqstp->rq_task));out:	return status;}",5105
94,135,CVE-2014-3468,20,"_asn1_get_time_der (const unsigned char *der, int der_len, int *ret_len,		    char *str, int str_size){  int len_len, str_len;  if (der_len <= 0 || str == NULL)    return ASN1_DER_ERROR;  str_len = asn1_get_length_der (der, der_len, &len_len);  if (str_len < 0 || str_size < str_len)    return ASN1_DER_ERROR;  memcpy (str, der + len_len, str_len);  str[str_len] = 0;  *ret_len = str_len + len_len;  return ASN1_SUCCESS;}",2068
35,759,CVE-2011-4131,20,"static int nfs4_xdr_dec_lock(struct rpc_rqst *rqstp, struct xdr_stream *xdr,			     struct nfs_lock_res *res){	struct compound_hdr hdr;	int status;	status = decode_compound_hdr(xdr, &hdr);	if (status)		goto out;	status = decode_sequence(xdr, &res->seq_res, rqstp);	if (status)		goto out;	status = decode_putfh(xdr);	if (status)		goto out;	status = decode_lock(xdr, res);out:	return status;}",5100
254,105,CVE-2014-6269,20,"smp_fetch_url32(struct proxy *px, struct session *l4, void *l7, unsigned int opt,                 const struct arg *args, struct sample *smp, const char *kw){	struct http_txn *txn = l7;	struct hdr_ctx ctx;	unsigned int hash = 0;	char *ptr, *beg, *end;	int len;	CHECK_HTTP_MESSAGE_FIRST();	ctx.idx = 0;	if (http_find_header2(""Host"", 4, txn->req.chn->buf->p, &txn->hdr_idx, &ctx)) {		 		ptr = ctx.line + ctx.val;		len = ctx.vlen;		while (len--)			hash = *(ptr++) + (hash << 6) + (hash << 16) - hash;	}	 	end = txn->req.chn->buf->p + txn->req.sl.rq.u + txn->req.sl.rq.u_l;	beg = http_get_path(txn);	if (!beg)		beg = end;	for (ptr = beg; ptr < end ; ptr++);	if (beg < ptr && *beg == '/') {		while (beg < ptr)			hash = *(beg++) + (hash << 6) + (hash << 16) - hash;	}	hash = full_hash(hash);	smp->type = SMP_T_UINT;	smp->data.uint = hash;	smp->flags = SMP_F_VOL_1ST;	return 1;}",1769
417,1093,CVE-2013-7010,20,"static void add_hfyu_median_prediction_c(int *dst, const int *src1, const int *diff, int w, int *left, int *left_top){    int i;    int l, lt;    l= *left;    lt= *left_top;    for(i=0; i<w; i++){        l= mid_pred(l, src1[i], (l + src1[i] - lt)&0xFF) + diff[i];        lt= src1[i];        dst[i]= l;    }    *left= l;    *left_top= lt;}",7082
229,1613,CVE-2019-7308,20,static const char *ltrim(const char *s){	while (isspace(*s))		s++;	return s;},27326
171,413,CVE-2012-2375,20,"void nfs4_reset_read(struct rpc_task *task, struct nfs_read_data *data){	dprintk(""%s Reset task for i/o through\n"", __func__);	put_lseg(data->lseg);	data->lseg = NULL;	 	data->args.offset = data->mds_offset;	data->ds_clp = NULL;	data->args.fh     = NFS_FH(data->inode);	data->read_done_cb = nfs4_read_done_cb;	task->tk_ops = data->mds_ops;	rpc_task_reset_client(task, NFS_CLIENT(data->inode));}",3390
384,847,CVE-2011-4131,20,"static void xdr_set_next_page(struct xdr_stream *xdr){	unsigned int newbase;	newbase = (1 + xdr->page_ptr - xdr->buf->pages) << PAGE_SHIFT;	newbase -= xdr->buf->page_base;	if (xdr_set_page_base(xdr, newbase, PAGE_SIZE) < 0)		xdr_set_iov(xdr, xdr->buf->tail, NULL, xdr->buf->len);}",5188
329,668,CVE-2011-4131,20,"static int decode_getdeviceinfo(struct xdr_stream *xdr,				struct pnfs_device *pdev){	__be32 *p;	int len, type;	int status;	status = decode_op_hdr(xdr, OP_GETDEVICEINFO);	if (status) {		if (status == -ETOOSMALL) {			p = xdr_inline_decode(xdr, 4);			if (unlikely(!p))				goto out_overflow;			pdev->mincount = be32_to_cpup(p);			dprintk(""%s: Min count too small. mincnt = %u\n"",				__func__, pdev->mincount);		}		return status;	}	p = xdr_inline_decode(xdr, 8);	if (unlikely(!p))		goto out_overflow;	type = be32_to_cpup(p++);	if (type != pdev->layout_type) {		dprintk(""%s: layout mismatch req: %u pdev: %u\n"",			__func__, pdev->layout_type, type);		return -EINVAL;	}	 	pdev->mincount = be32_to_cpup(p);	xdr_read_pages(xdr, pdev->mincount);  	 	p = xdr_inline_decode(xdr, 4);	if (unlikely(!p))		goto out_overflow;	len = be32_to_cpup(p);	if (len) {		int i;		p = xdr_inline_decode(xdr, 4 * len);		if (unlikely(!p))			goto out_overflow;		for (i = 0; i < len; i++, p++) {			if (be32_to_cpup(p)) {				dprintk(""%s: notifications not supported\n"",					__func__);				return -EIO;			}		}	}	return 0;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",5009
162,1732,CVE-2013-7010,20," static void add_bytes_c(int *dst, int *src, int w){     long i;    for(i=0; i<=w-sizeof(long); i+=sizeof(long)){         long a = *(long*)(src+i);         long b = *(long*)(dst+i);         *(long*)(dst+i) = ((a&pb_7f) + (b&pb_7f)) ^ ((a^b)&pb_80);    }    for(; i<w; i++)        dst[i+0] += src[i+0];}",31038
259,945,CVE-2011-3209,20,"static int slab_pad_check(struct kmem_cache *s, struct page *page){	u8 *start;	u8 *fault;	u8 *end;	int length;	int remainder;	if (!(s->flags & SLAB_POISON))		return 1;	start = page_address(page);	length = (PAGE_SIZE << compound_order(page));	end = start + length;	remainder = length % s->size;	if (!remainder)		return 1;	fault = check_bytes(end - remainder, POISON_INUSE, remainder);	if (!fault)		return 1;	while (end > fault && end[-1] == POISON_INUSE)		end--;	slab_err(s, page, ""Padding overwritten. 0x%p-0x%p"", fault, end - 1);	print_section(""Padding"", end - remainder, remainder);	restore_bytes(s, ""slab padding"", POISON_INUSE, start, end);	return 0;}",5713
135,322,CVE-2012-2375,20,static void nfs4_free_closedata(void *data){	struct nfs4_closedata *calldata = data;	struct nfs4_state_owner *sp = calldata->state->owner;	struct super_block *sb = calldata->state->inode->i_sb;	if (calldata->roc)		pnfs_roc_release(calldata->state->inode);	nfs4_put_open_state(calldata->state);	nfs_free_seqid(calldata->arg.seqid);	nfs4_put_state_owner(sp);	nfs_sb_deactive(sb);	kfree(calldata);},3299
303,377,CVE-2012-2375,20,"nfs4_proc_lock(struct file *filp, int cmd, struct file_lock *request){	struct nfs_open_context *ctx;	struct nfs4_state *state;	unsigned long timeout = NFS4_LOCK_MINTIMEOUT;	int status;	 	ctx = nfs_file_open_context(filp);	state = ctx->state;	if (request->fl_start < 0 || request->fl_end < 0)		return -EINVAL;	if (IS_GETLK(cmd)) {		if (state != NULL)			return nfs4_proc_getlk(state, F_GETLK, request);		return 0;	}	if (!(IS_SETLK(cmd) || IS_SETLKW(cmd)))		return -EINVAL;	if (request->fl_type == F_UNLCK) {		if (state != NULL)			return nfs4_proc_unlck(state, cmd, request);		return 0;	}	if (state == NULL)		return -ENOLCK;	do {		status = nfs4_proc_setlk(state, cmd, request);		if ((status != -EAGAIN) || IS_SETLK(cmd))			break;		timeout = nfs4_set_lock_task_retry(timeout);		status = -ERESTARTSYS;		if (signalled())			break;	} while(status < 0);	return status;}",3354
275,361,CVE-2012-2375,20,"static struct nfs4_state *nfs4_opendata_to_nfs4_state(struct nfs4_opendata *data){	struct inode *inode;	struct nfs4_state *state = NULL;	struct nfs_delegation *delegation;	int ret;	if (!data->rpc_done) {		state = nfs4_try_open_cached(data);		goto out;	}	ret = -EAGAIN;	if (!(data->f_attr.valid & NFS_ATTR_FATTR))		goto err;	inode = nfs_fhget(data->dir->d_sb, &data->o_res.fh, &data->f_attr);	ret = PTR_ERR(inode);	if (IS_ERR(inode))		goto err;	ret = -ENOMEM;	state = nfs4_get_open_state(inode, data->owner);	if (state == NULL)		goto err_put_inode;	if (data->o_res.delegation_type != 0) {		struct nfs_client *clp = NFS_SERVER(inode)->nfs_client;		int delegation_flags = 0;		rcu_read_lock();		delegation = rcu_dereference(NFS_I(inode)->delegation);		if (delegation)			delegation_flags = delegation->flags;		rcu_read_unlock();		if (data->o_arg.claim == NFS4_OPEN_CLAIM_DELEGATE_CUR) {			pr_err_ratelimited(""NFS: Broken NFSv4 server %s is ""					""returning a delegation for ""					""OPEN(CLAIM_DELEGATE_CUR)\n"",					clp->cl_hostname);		} else if ((delegation_flags & 1UL<<NFS_DELEGATION_NEED_RECLAIM) == 0)			nfs_inode_set_delegation(state->inode,					data->owner->so_cred,					&data->o_res);		else			nfs_inode_reclaim_delegation(state->inode,					data->owner->so_cred,					&data->o_res);	}	update_open_stateid(state, &data->o_res.stateid, NULL,			data->o_arg.fmode);	iput(inode);out:	return state;err_put_inode:	iput(inode);err:	return ERR_PTR(ret);}",3338
258,1562,CVE-2019-14763,20,"static int dwc3_gadget_get_irq(struct dwc3 *dwc){	struct platform_device *dwc3_pdev = to_platform_device(dwc->dev);	int irq;	irq = platform_get_irq_byname(dwc3_pdev, ""peripheral"");	if (irq > 0)		goto out;	if (irq == -EPROBE_DEFER)		goto out;	irq = platform_get_irq_byname(dwc3_pdev, ""dwc_usb3"");	if (irq > 0)		goto out;	if (irq == -EPROBE_DEFER)		goto out;	irq = platform_get_irq(dwc3_pdev, 0);	if (irq > 0)		goto out;	if (irq != -EPROBE_DEFER)		dev_err(dwc->dev, ""missing peripheral IRQ\n"");	if (!irq)		irq = -EINVAL;out:	return irq;}",26671
61,117,CVE-2014-6269,20,static void si_idle_conn_null_cb(struct connection *conn){	if (conn->flags & (CO_FL_ERROR | CO_FL_SOCK_RD_SH))		return;	if (fdtab[conn->t.sock.fd].ev & (FD_POLL_ERR|FD_POLL_HUP)) {		fdtab[conn->t.sock.fd].linger_risk = 0;		conn->flags |= CO_FL_SOCK_RD_SH;	}	else {		conn_drain(conn);	}	 	if (!conn->ctrl->drain)		__conn_data_stop_recv(conn);},1781
320,1451,CVE-2015-5707,20,"sg_proc_cleanup(void){	int k;	int num_leaves = ARRAY_SIZE(sg_proc_leaf_arr);	if (!sg_proc_sgp)		return;	for (k = 0; k < num_leaves; ++k)		remove_proc_entry(sg_proc_leaf_arr[k].name, sg_proc_sgp);	remove_proc_entry(sg_proc_sg_dirname, NULL);}",13166
319,1482,CVE-2015-4001,20,"static void oz_hcd_endpoint_reset(struct usb_hcd *hcd,				struct usb_host_endpoint *ep){}",13558
273,715,CVE-2011-4131,20,"static void encode_open(struct xdr_stream *xdr, const struct nfs_openargs *arg, struct compound_hdr *hdr){	encode_openhdr(xdr, arg);	encode_opentype(xdr, arg);	switch (arg->claim) {	case NFS4_OPEN_CLAIM_NULL:		encode_claim_null(xdr, arg->name);		break;	case NFS4_OPEN_CLAIM_PREVIOUS:		encode_claim_previous(xdr, arg->u.delegation_type);		break;	case NFS4_OPEN_CLAIM_DELEGATE_CUR:		encode_claim_delegate_cur(xdr, arg->name, &arg->u.delegation);		break;	default:		BUG();	}	hdr->nops++;	hdr->replen += decode_open_maxsz;}",5056
7,1007,CVE-2011-2906,20,"static void pmcraid_querycfg(struct pmcraid_cmd *cmd){	struct pmcraid_ioarcb *ioarcb = &cmd->ioa_cb->ioarcb;	struct pmcraid_ioadl_desc *ioadl = ioarcb->add_data.u.ioadl;	struct pmcraid_instance *pinstance = cmd->drv_inst;	int cfg_table_size = cpu_to_be32(sizeof(struct pmcraid_config_table));	if (be16_to_cpu(pinstance->inq_data->fw_version) <=					PMCRAID_FW_VERSION_1)		pinstance->config_table_entry_size =			sizeof(struct pmcraid_config_table_entry);	else		pinstance->config_table_entry_size =			sizeof(struct pmcraid_config_table_entry_ext);	ioarcb->request_type = REQ_TYPE_IOACMD;	ioarcb->resource_handle = cpu_to_le32(PMCRAID_IOA_RES_HANDLE);	ioarcb->cdb[0] = PMCRAID_QUERY_IOA_CONFIG;	 	memcpy(&(ioarcb->cdb[10]), &cfg_table_size, sizeof(cfg_table_size));	 	ioarcb->ioadl_bus_addr = cpu_to_le64((cmd->ioa_cb_bus_addr) +					offsetof(struct pmcraid_ioarcb,						add_data.u.ioadl[0]));	ioarcb->ioadl_length = cpu_to_le32(sizeof(struct pmcraid_ioadl_desc));	ioarcb->ioarcb_bus_addr &= ~(0x1FULL);	ioarcb->request_flags0 |= NO_LINK_DESCS;	ioarcb->data_transfer_length =		cpu_to_le32(sizeof(struct pmcraid_config_table));	ioadl = &(ioarcb->add_data.u.ioadl[0]);	ioadl->flags = IOADL_FLAGS_LAST_DESC;	ioadl->address = cpu_to_le64(pinstance->cfg_table_bus_addr);	ioadl->data_len = cpu_to_le32(sizeof(struct pmcraid_config_table));	pmcraid_send_cmd(cmd, pmcraid_init_res_table,			 PMCRAID_INTERNAL_TIMEOUT, pmcraid_timeout_handler);}",6458
302,1663,CVE-2012-2807,20,__oldXMLWDcompatibility(void) {    if (IS_MAIN_THREAD)	return (&oldXMLWDcompatibility);    else	return (&xmlGetGlobalState()->oldXMLWDcompatibility);},29249
376,1587,CVE-2019-7308,20,static int bpf_map_is_cgroup_storage(struct bpf_map *map){	return (map->map_type == BPF_MAP_TYPE_CGROUP_STORAGE ||		map->map_type == BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE);},27300
76,850,CVE-2011-4097,20,"int register_oom_notifier(struct notifier_block *nb){	return blocking_notifier_chain_register(&oom_notify_list, nb);}",5475
15,1688,CVE-2012-2807,20,__xmlSaveNoEmptyTags(void) {    if (IS_MAIN_THREAD)	return (&xmlSaveNoEmptyTags);    else	return (&xmlGetGlobalState()->xmlSaveNoEmptyTags);},29274
65,973,CVE-2011-2906,20,"static void _pmcraid_fire_command(struct pmcraid_cmd *cmd){	struct pmcraid_instance *pinstance = cmd->drv_inst;	unsigned long lock_flags;	 	spin_lock_irqsave(&pinstance->pending_pool_lock, lock_flags);	list_add_tail(&cmd->free_list, &pinstance->pending_cmd_pool);	spin_unlock_irqrestore(&pinstance->pending_pool_lock, lock_flags);	atomic_inc(&pinstance->outstanding_cmds);	 	mb();	iowrite32(le32_to_cpu(cmd->ioa_cb->ioarcb.ioarcb_bus_addr),		  pinstance->ioarrin);}",6424
331,1538,CVE-2019-1010294,20,static int hex(char c){	char lc = tolower(c);	if (isdigit(lc))		return lc - '0';	if (isxdigit(lc))		return lc - 'a' + 10;	return -1;},26372
38,741,CVE-2011-4131,20,"static int nfs4_xdr_dec_close(struct rpc_rqst *rqstp, struct xdr_stream *xdr,			      struct nfs_closeres *res){	struct compound_hdr hdr;	int status;	status = decode_compound_hdr(xdr, &hdr);	if (status)		goto out;	status = decode_sequence(xdr, &res->seq_res, rqstp);	if (status)		goto out;	status = decode_putfh(xdr);	if (status)		goto out;	status = decode_close(xdr, res);	if (status != 0)		goto out;	 	decode_getfattr(xdr, res->fattr, res->server,			!RPC_IS_ASYNC(rqstp->rq_task));out:	return status;}",5082
269,1193,CVE-2013-6376,20,int kvm_lapic_find_highest_irr(struct kvm_vcpu *vcpu){	int highest_irr;	 	if (!kvm_vcpu_has_lapic(vcpu))		return 0;	highest_irr = apic_find_highest_irr(vcpu->arch.apic);	return highest_irr;},7394
322,1620,CVE-2019-7308,20,"static int push_insn(int t, int w, int e, struct bpf_verifier_env *env){	if (e == FALLTHROUGH && insn_state[t] >= (DISCOVERED | FALLTHROUGH))		return 0;	if (e == BRANCH && insn_state[t] >= (DISCOVERED | BRANCH))		return 0;	if (w < 0 || w >= env->prog->len) {		verbose_linfo(env, t, ""%d: "", t);		verbose(env, ""jump out of range from insn %d to %d\n"", t, w);		return -EINVAL;	}	if (e == BRANCH)		 		env->explored_states[w] = STATE_LIST_MARK;	if (insn_state[w] == 0) {		 		insn_state[t] = DISCOVERED | e;		insn_state[w] = DISCOVERED;		if (cur_stack >= env->prog->len)			return -E2BIG;		insn_stack[cur_stack++] = w;		return 1;	} else if ((insn_state[w] & 0xF0) == DISCOVERED) {		verbose_linfo(env, t, ""%d: "", t);		verbose_linfo(env, w, ""%d: "", w);		verbose(env, ""back-edge from insn %d to %d\n"", t, w);		return -EINVAL;	} else if (insn_state[w] == EXPLORED) {		 		insn_state[t] = DISCOVERED | e;	} else {		verbose(env, ""insn state internal bug\n"");		return -EFAULT;	}	return 0;}",27333
360,789,CVE-2011-4131,20,"static void nfs4_xdr_enc_access(struct rpc_rqst *req, struct xdr_stream *xdr,				const struct nfs4_accessargs *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_putfh(xdr, args->fh, &hdr);	encode_access(xdr, args->access, &hdr);	encode_getfattr(xdr, args->bitmask, &hdr);	encode_nops(&hdr);}",5130
181,784,CVE-2011-4131,20,"static int nfs4_xdr_dec_setclientid_confirm(struct rpc_rqst *req,					    struct xdr_stream *xdr,					    struct nfs_fsinfo *fsinfo){	struct compound_hdr hdr;	int status;	status = decode_compound_hdr(xdr, &hdr);	if (!status)		status = decode_setclientid_confirm(xdr);	if (!status)		status = decode_putrootfh(xdr);	if (!status)		status = decode_fsinfo(xdr, fsinfo);	return status;}",5125
214,700,CVE-2011-4131,20,"static void encode_getattr_one(struct xdr_stream *xdr, int bitmap, struct compound_hdr *hdr){	__be32 *p;	p = reserve_space(xdr, 12);	*p++ = cpu_to_be32(OP_GETATTR);	*p++ = cpu_to_be32(1);	*p = cpu_to_be32(bitmap);	hdr->nops++;	hdr->replen += decode_getattr_maxsz;}",5041
20,370,CVE-2012-2375,20,"int nfs4_proc_getdeviceinfo(struct nfs_server *server, struct pnfs_device *pdev){	struct nfs4_exception exception = { };	int err;	do {		err = nfs4_handle_exception(server,					_nfs4_proc_getdeviceinfo(server, pdev),					&exception);	} while (exception.retry);	return err;}",3347
407,1456,CVE-2015-5707,20,"static int sg_proc_seq_show_dev(struct seq_file *s, void *v){	struct sg_proc_deviter * it = (struct sg_proc_deviter *) v;	Sg_device *sdp;	struct scsi_device *scsidp;	unsigned long iflags;	read_lock_irqsave(&sg_index_lock, iflags);	sdp = it ? sg_lookup_dev(it->index) : NULL;	if ((NULL == sdp) || (NULL == sdp->device) ||	    (atomic_read(&sdp->detaching)))		seq_puts(s, ""-1\t-1\t-1\t-1\t-1\t-1\t-1\t-1\t-1\n"");	else {		scsidp = sdp->device;		seq_printf(s, ""%d\t%d\t%d\t%llu\t%d\t%d\t%d\t%d\t%d\n"",			      scsidp->host->host_no, scsidp->channel,			      scsidp->id, scsidp->lun, (int) scsidp->type,			      1,			      (int) scsidp->queue_depth,			      (int) atomic_read(&scsidp->device_busy),			      (int) scsi_device_online(scsidp));	}	read_unlock_irqrestore(&sg_index_lock, iflags);	return 0;}",13171
340,1338,CVE-2013-2094,20,"static int perf_release(struct inode *inode, struct file *file){	put_event(file->private_data);	return 0;}",8926
114,1288,CVE-2013-2596,20,"int fb_prepare_logo(struct fb_info *info, int rotate) { return 0; }",8556
403,687,CVE-2011-4131,20,"static int decode_setclientid(struct xdr_stream *xdr, struct nfs4_setclientid_res *res){	__be32 *p;	int opnum;	int nfserr;	p = xdr_inline_decode(xdr, 8);	if (unlikely(!p))		goto out_overflow;	opnum = be32_to_cpup(p++);	if (opnum != OP_SETCLIENTID) {		dprintk(""nfs: decode_setclientid: Server returned operation""			"" %d\n"", opnum);		return -EIO;	}	nfserr = be32_to_cpup(p);	if (nfserr == NFS_OK) {		p = xdr_inline_decode(xdr, 8 + NFS4_VERIFIER_SIZE);		if (unlikely(!p))			goto out_overflow;		p = xdr_decode_hyper(p, &res->clientid);		memcpy(res->confirm.data, p, NFS4_VERIFIER_SIZE);	} else if (nfserr == NFSERR_CLID_INUSE) {		int len;		 		p = xdr_inline_decode(xdr, 4);		if (unlikely(!p))			goto out_overflow;		len = be32_to_cpup(p);		p = xdr_inline_decode(xdr, len);		if (unlikely(!p))			goto out_overflow;		 		p = xdr_inline_decode(xdr, 4);		if (unlikely(!p))			goto out_overflow;		len = be32_to_cpup(p);		p = xdr_inline_decode(xdr, len);		if (unlikely(!p))			goto out_overflow;		return -NFSERR_CLID_INUSE;	} else		return nfs4_stat_to_errno(nfserr);	return 0;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",5028
284,369,CVE-2012-2375,20,"static int nfs4_proc_getattr(struct nfs_server *server, struct nfs_fh *fhandle, struct nfs_fattr *fattr){	struct nfs4_exception exception = { };	int err;	do {		err = nfs4_handle_exception(server,				_nfs4_proc_getattr(server, fhandle, fattr),				&exception);	} while (exception.retry);	return err;}",3346
123,714,CVE-2011-4131,20,static void encode_nops(struct compound_hdr *hdr){	BUG_ON(hdr->nops > NFS4_MAX_OPS);	*hdr->nops_p = htonl(hdr->nops);},5055
8,724,CVE-2011-4131,20,"static void encode_reclaim_complete(struct xdr_stream *xdr,				    struct nfs41_reclaim_complete_args *args,				    struct compound_hdr *hdr){	__be32 *p;	p = reserve_space(xdr, 8);	*p++ = cpu_to_be32(OP_RECLAIM_COMPLETE);	*p++ = cpu_to_be32(args->one_fs);	hdr->nops++;	hdr->replen += decode_reclaim_complete_maxsz;}",5065
271,446,CVE-2012-2100,20,"static int ext4_blkdev_put(struct block_device *bdev){	return blkdev_put(bdev, FMODE_READ|FMODE_WRITE|FMODE_EXCL);}",3601
106,363,CVE-2012-2375,20,"static int nfs4_proc_async_renew(struct nfs_client *clp, struct rpc_cred *cred, unsigned renew_flags){	struct rpc_message msg = {		.rpc_proc	= &nfs4_procedures[NFSPROC4_CLNT_RENEW],		.rpc_argp	= clp,		.rpc_cred	= cred,	};	struct nfs4_renewdata *data;	if (renew_flags == 0)		return 0;	if (!atomic_inc_not_zero(&clp->cl_count))		return -EIO;	data = kmalloc(sizeof(*data), GFP_NOFS);	if (data == NULL)		return -ENOMEM;	data->client = clp;	data->timestamp = jiffies;	return rpc_call_async(clp->cl_rpcclient, &msg, RPC_TASK_SOFT,			&nfs4_renew_ops, data);}",3340
158,855,CVE-2011-3209,20,static int sgi_timer_create(struct k_itimer *timer){	 	timer->it.mmtimer.clock = TIMER_OFF;	return 0;},5623
185,1686,CVE-2012-2807,20,__xmlRealloc(void){    if (IS_MAIN_THREAD)        return (&xmlRealloc);    else        return (&xmlGetGlobalState()->xmlRealloc);},29272
120,1604,CVE-2019-7308,20,"static int func_states_equal(struct bpf_func_state *old,			      struct bpf_func_state *cur){	struct idpair *idmap;	int ret = false;	int i;	idmap = kcalloc(ID_MAP_SIZE, sizeof(struct idpair), GFP_KERNEL);	 	if (!idmap)		return false;	for (i = 0; i < MAX_BPF_REG; i++) {		if (!regsafe(&old->regs[i], &cur->regs[i], idmap))			goto out_free;	}	if (!stacksafe(old, cur, idmap))		goto out_free;	if (!refsafe(old, cur))		goto out_free;	ret = true;out_free:	kfree(idmap);	return ret;}",27317
238,1043,CVE-2011-2496,20,"unsigned long do_mremap(unsigned long addr,	unsigned long old_len, unsigned long new_len,	unsigned long flags, unsigned long new_addr){	struct mm_struct *mm = current->mm;	struct vm_area_struct *vma;	unsigned long ret = -EINVAL;	unsigned long charged = 0;	if (flags & ~(MREMAP_FIXED | MREMAP_MAYMOVE))		goto out;	if (addr & ~PAGE_MASK)		goto out;	old_len = PAGE_ALIGN(old_len);	new_len = PAGE_ALIGN(new_len);	 	if (!new_len)		goto out;	if (flags & MREMAP_FIXED) {		if (flags & MREMAP_MAYMOVE)			ret = mremap_to(addr, old_len, new_addr, new_len);		goto out;	}	 	if (old_len >= new_len) {		ret = do_munmap(mm, addr+new_len, old_len - new_len);		if (ret && old_len != new_len)			goto out;		ret = addr;		goto out;	}	 	vma = vma_to_resize(addr, old_len, new_len, &charged);	if (IS_ERR(vma)) {		ret = PTR_ERR(vma);		goto out;	}	 	if (old_len == vma->vm_end - addr) {		 		if (vma_expandable(vma, new_len - old_len)) {			int pages = (new_len - old_len) >> PAGE_SHIFT;			if (vma_adjust(vma, vma->vm_start, addr + new_len,				       vma->vm_pgoff, NULL)) {				ret = -ENOMEM;				goto out;			}			mm->total_vm += pages;			vm_stat_account(mm, vma->vm_flags, vma->vm_file, pages);			if (vma->vm_flags & VM_LOCKED) {				mm->locked_vm += pages;				mlock_vma_pages_range(vma, addr + old_len,						   addr + new_len);			}			ret = addr;			goto out;		}	}	 	ret = -ENOMEM;	if (flags & MREMAP_MAYMOVE) {		unsigned long map_flags = 0;		if (vma->vm_flags & VM_MAYSHARE)			map_flags |= MAP_SHARED;		new_addr = get_unmapped_area(vma->vm_file, 0, new_len,					vma->vm_pgoff +					((addr - vma->vm_start) >> PAGE_SHIFT),					map_flags);		if (new_addr & ~PAGE_MASK) {			ret = new_addr;			goto out;		}		ret = security_file_mmap(NULL, 0, 0, 0, new_addr, 1);		if (ret)			goto out;		ret = move_vma(vma, addr, old_len, new_len, new_addr);	}out:	if (ret & ~PAGE_MASK)		vm_unacct_memory(charged);	return ret;}",6599
137,1191,CVE-2013-6376,20,"void kvm_inject_apic_timer_irqs(struct kvm_vcpu *vcpu){	struct kvm_lapic *apic = vcpu->arch.apic;	if (!kvm_vcpu_has_lapic(vcpu))		return;	if (atomic_read(&apic->lapic_timer.pending) > 0) {		kvm_apic_local_deliver(apic, APIC_LVTT);		atomic_set(&apic->lapic_timer.pending, 0);	}}",7392
286,514,CVE-2012-0044,20,"int drm_mode_crtc_set_gamma_size(struct drm_crtc *crtc,				  int gamma_size){	crtc->gamma_size = gamma_size;	crtc->gamma_store = kzalloc(gamma_size * sizeof(int) * 3, GFP_KERNEL);	if (!crtc->gamma_store) {		crtc->gamma_size = 0;		return false;	}	return true;}",4287
291,381,CVE-2012-2375,20,"static void nfs4_proc_read_rpc_prepare(struct rpc_task *task, struct nfs_read_data *data){	if (nfs4_setup_sequence(NFS_SERVER(data->inode),				&data->args.seq_args,				&data->res.seq_res,				task))		return;	rpc_call_start(task);}",3358
75,1599,CVE-2019-7308,20,"static void clean_verifier_state(struct bpf_verifier_env *env,				 struct bpf_verifier_state *st){	int i;	if (st->frame[0]->regs[0].live & REG_LIVE_DONE)		 		return;	for (i = 0; i <= st->curframe; i++)		clean_func_state(env, st->frame[i]);}",27312
372,100,CVE-2014-6269,20,"smp_fetch_proto_http(struct proxy *px, struct session *l4, void *l7, unsigned int opt,                     const struct arg *args, struct sample *smp, const char *kw){	 	CHECK_HTTP_MESSAGE_FIRST_PERM();	smp->type = SMP_T_BOOL;	smp->data.uint = 1;	return 1;}",1764
408,624,CVE-2011-4131,20,"static int decode_access(struct xdr_stream *xdr, struct nfs4_accessres *access){	__be32 *p;	int supp, acc;	int status;	status = decode_op_hdr(xdr, OP_ACCESS);	if (status)		return status;	p = xdr_inline_decode(xdr, 8);	if (unlikely(!p))		goto out_overflow;	supp = be32_to_cpup(p++);	acc = be32_to_cpup(p);	access->supported = supp;	access->access = acc;	return 0;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",4965
179,698,CVE-2011-4131,20,"static void encode_exchange_id(struct xdr_stream *xdr,			       struct nfs41_exchange_id_args *args,			       struct compound_hdr *hdr){	__be32 *p;	p = reserve_space(xdr, 4 + sizeof(args->verifier->data));	*p++ = cpu_to_be32(OP_EXCHANGE_ID);	xdr_encode_opaque_fixed(p, args->verifier->data, sizeof(args->verifier->data));	encode_string(xdr, args->id_len, args->id);	p = reserve_space(xdr, 12);	*p++ = cpu_to_be32(args->flags);	*p++ = cpu_to_be32(0);	 	*p = cpu_to_be32(0);	 	hdr->nops++;	hdr->replen += decode_exchange_id_maxsz;}",5039
66,490,CVE-2012-0044,20,"void drm_crtc_convert_to_umode(struct drm_mode_modeinfo *out,			       struct drm_display_mode *in){	out->clock = in->clock;	out->hdisplay = in->hdisplay;	out->hsync_start = in->hsync_start;	out->hsync_end = in->hsync_end;	out->htotal = in->htotal;	out->hskew = in->hskew;	out->vdisplay = in->vdisplay;	out->vsync_start = in->vsync_start;	out->vsync_end = in->vsync_end;	out->vtotal = in->vtotal;	out->vscan = in->vscan;	out->vrefresh = in->vrefresh;	out->flags = in->flags;	out->type = in->type;	strncpy(out->name, in->name, DRM_DISPLAY_MODE_LEN);	out->name[DRM_DISPLAY_MODE_LEN-1] = 0;}",4263
1,1135,CVE-2013-7010,20,"static inline void put_tpel_pixels_mc21_c(int *dst, const int *src, int stride, int width, int height){    int i,j;    for (i=0; i < height; i++) {      for (j=0; j < width; j++) {        dst[j] = (2731*(3*src[j] + 4*src[j+1] + 2*src[j+stride] + 3*src[j+stride+1] + 6)) >> 15;      }      src += stride;      dst += stride;    }}",7124
12,1039,CVE-2011-2521,20,"perf_callchain_kernel(struct perf_callchain_entry *entry, struct pt_regs *regs){	if (perf_guest_cbs && perf_guest_cbs->is_in_guest()) {		 		return;	}	perf_callchain_store(entry, regs->ip);	dump_trace(NULL, regs, NULL, &backtrace_ops, entry);}",6539
326,875,CVE-2011-3209,20,"static void notify_cmos_timer(void){	if (!no_sync_cmos_clock)		mod_timer(&sync_cmos_timer, jiffies + 1);}",5643
423,737,CVE-2011-4131,20,"static void encode_test_stateid(struct xdr_stream *xdr,				struct nfs41_test_stateid_args *args,				struct compound_hdr *hdr){	__be32 *p;	p = reserve_space(xdr, 8 + NFS4_STATEID_SIZE);	*p++ = cpu_to_be32(OP_TEST_STATEID);	*p++ = cpu_to_be32(1);	xdr_encode_opaque_fixed(p, args->stateid->data, NFS4_STATEID_SIZE);	hdr->nops++;	hdr->replen += decode_test_stateid_maxsz;}",5078
297,463,CVE-2012-2100,20,"static int ext4_li_info_new(void){	struct ext4_lazy_init *eli = NULL;	eli = kzalloc(sizeof(*eli), GFP_KERNEL);	if (!eli)		return -ENOMEM;	INIT_LIST_HEAD(&eli->li_request_list);	mutex_init(&eli->li_list_mtx);	eli->li_state |= EXT4_LAZYINIT_QUIT;	ext4_li_info = eli;	return 0;}",3618
170,1008,CVE-2011-2906,20,"static void pmcraid_register_hcams(struct pmcraid_instance *pinstance){	pmcraid_send_hcam(pinstance, PMCRAID_HCAM_CODE_CONFIG_CHANGE);	pmcraid_send_hcam(pinstance, PMCRAID_HCAM_CODE_LOG_DATA);}",6459
252,299,CVE-2012-2375,20,"nfs4_atomic_open(struct inode *dir, struct nfs_open_context *ctx, int open_flags, struct iattr *attr){	struct nfs4_state *state;	 	state = nfs4_do_open(dir, ctx->dentry, ctx->mode, open_flags, attr, ctx->cred);	if (IS_ERR(state))		return ERR_CAST(state);	ctx->state = state;	return igrab(state->inode);}",3276
224,183,CVE-2012-3412,20,"static int efx_pm_thaw(struct device *dev){	struct efx_nic *efx = pci_get_drvdata(to_pci_dev(dev));	efx->state = STATE_INIT;	efx_init_channels(efx);	mutex_lock(&efx->mac_lock);	efx->phy_op->reconfigure(efx);	mutex_unlock(&efx->mac_lock);	efx_start_all(efx);	netif_device_attach(efx->net_dev);	efx->state = STATE_RUNNING;	efx->type->resume_wol(efx);	 	queue_work(reset_workqueue, &efx->reset_work);	return 0;}",3057
228,324,CVE-2012-2375,20,static void nfs4_free_reclaim_complete_data(void *data){	struct nfs4_reclaim_complete_data *calldata = data;	kfree(calldata);},3301
428,222,CVE-2012-3412,20,"static void efx_dequeue_buffers(struct efx_tx_queue *tx_queue,				unsigned int index){	struct efx_nic *efx = tx_queue->efx;	unsigned int stop_index, read_ptr;	stop_index = (index + 1) & tx_queue->ptr_mask;	read_ptr = tx_queue->read_count & tx_queue->ptr_mask;	while (read_ptr != stop_index) {		struct efx_tx_buffer *buffer = &tx_queue->buffer[read_ptr];		if (unlikely(buffer->len == 0)) {			netif_err(efx, tx_err, efx->net_dev,				  ""TX queue %d spurious TX completion id %x\n"",				  tx_queue->queue, read_ptr);			efx_schedule_reset(efx, RESET_TYPE_TX_SKIP);			return;		}		efx_dequeue_buffer(tx_queue, buffer);		buffer->continuation = true;		buffer->len = 0;		++tx_queue->read_count;		read_ptr = tx_queue->read_count & tx_queue->ptr_mask;	}}",3096
152,652,CVE-2011-4131,20,"static int decode_attr_symlink_support(struct xdr_stream *xdr, int *bitmap, int *res){	__be32 *p;	*res = 0;	if (unlikely(bitmap[0] & (FATTR4_WORD0_SYMLINK_SUPPORT - 1U)))		return -EIO;	if (likely(bitmap[0] & FATTR4_WORD0_SYMLINK_SUPPORT)) {		p = xdr_inline_decode(xdr, 4);		if (unlikely(!p))			goto out_overflow;		*res = be32_to_cpup(p);		bitmap[0] &= ~FATTR4_WORD0_SYMLINK_SUPPORT;	}	dprintk(""%s: symlink support=%s\n"", __func__, *res == 0 ? ""false"" : ""true"");	return 0;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",4993
14,665,CVE-2011-4131,20,"static int decode_exchange_id(struct xdr_stream *xdr,			      struct nfs41_exchange_id_res *res){	__be32 *p;	int dummy;	char *dummy_str;	int status;	struct nfs_client *clp = res->client;	status = decode_op_hdr(xdr, OP_EXCHANGE_ID);	if (status)		return status;	p = xdr_inline_decode(xdr, 8);	if (unlikely(!p))		goto out_overflow;	xdr_decode_hyper(p, &clp->cl_clientid);	p = xdr_inline_decode(xdr, 12);	if (unlikely(!p))		goto out_overflow;	clp->cl_seqid = be32_to_cpup(p++);	clp->cl_exchange_flags = be32_to_cpup(p++);	 	dummy = be32_to_cpup(p);	if (dummy != SP4_NONE)		return -EIO;	 	p = xdr_inline_decode(xdr, 8);	if (unlikely(!p))		goto out_overflow;	 	status = decode_opaque_inline(xdr, &dummy, &dummy_str);	if (unlikely(status))		return status;	 	status = decode_opaque_inline(xdr, &dummy, &dummy_str);	if (unlikely(status))		return status;	if (unlikely(dummy > NFS4_OPAQUE_LIMIT))		return -EIO;	memcpy(res->server_scope->server_scope, dummy_str, dummy);	res->server_scope->server_scope_sz = dummy;	 	status = decode_opaque_inline(xdr, &dummy, &dummy_str);	if (unlikely(status))		return status;	return 0;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",5006
380,57,CVE-2014-6269,20,"void http_init_txn(struct session *s){	struct http_txn *txn = &s->txn;	struct proxy *fe = s->fe;	txn->flags = 0;	txn->status = -1;	txn->cookie_first_date = 0;	txn->cookie_last_date = 0;	txn->req.flags = 0;	txn->req.sol = txn->req.eol = txn->req.eoh = 0;  	txn->req.next = 0;	txn->rsp.flags = 0;	txn->rsp.sol = txn->rsp.eol = txn->rsp.eoh = 0;  	txn->rsp.next = 0;	txn->req.chunk_len = 0LL;	txn->req.body_len = 0LL;	txn->rsp.chunk_len = 0LL;	txn->rsp.body_len = 0LL;	txn->req.msg_state = HTTP_MSG_RQBEFORE;  	txn->rsp.msg_state = HTTP_MSG_RPBEFORE;  	txn->req.chn = s->req;	txn->rsp.chn = s->rep;	txn->auth.method = HTTP_AUTH_UNKNOWN;	txn->req.err_pos = txn->rsp.err_pos = -2;  	if (fe->options2 & PR_O2_REQBUG_OK)		txn->req.err_pos = -1;             	if (txn->req.cap)		memset(txn->req.cap, 0, fe->nb_req_cap * sizeof(void *));	if (txn->rsp.cap)		memset(txn->rsp.cap, 0, fe->nb_rsp_cap * sizeof(void *));	if (txn->hdr_idx.v)		hdr_idx_init(&txn->hdr_idx);}",1721
190,879,CVE-2011-3209,20,static inline void ClearSlabFrozen(struct page *page){	page->flags &= ~FROZEN;},5647
278,47,CVE-2014-6269,20,"int del_hdr_value(struct buffer *buf, char **from, char *next){	char *prev = *from;	if (*prev == ':') {		 		if (!http_is_crlf[(unsigned char)*next])			next++;		prev++;		if (prev < next)			*prev++ = ' ';		while (http_is_spht[(unsigned char)*next])			next++;	} else {		 		while (http_is_spht[(unsigned char)*(prev-1)])			prev--;		*from = prev;		 		if (!http_is_crlf[(unsigned char)*next]) {			*prev++ = *next++;			if (prev + 1 < next)				*prev++ = ' ';			while (http_is_spht[(unsigned char)*next])				next++;		}	}	return buffer_replace2(buf, prev, next, NULL, 0);}",1711
104,32,CVE-2012-5667,20,pr_sgr_end (char const *s){  if (*s)    print_end_colorize (sgr_end);},1034
40,167,CVE-2012-3412,20,static void efx_fini_struct(struct efx_nic *efx){	int i;	for (i = 0; i < EFX_MAX_CHANNELS; i++)		kfree(efx->channel[i]);	if (efx->workqueue) {		destroy_workqueue(efx->workqueue);		efx->workqueue = NULL;	}},3041
87,140,CVE-2016-2105,20,static unsigned char conv_ascii2bin(unsigned char a){    a = os_toascii[a];    if (a & 0x80)        return B64_ERROR;    return data_ascii2bin[a];},2087
109,1657,CVE-2012-2896,20,"static int CharacterIsValidForGLES(unsigned char c) {  if (c >= 32 && c <= 126 &&      c != '""' &&      c != '$' &&      c != '`' &&      c != '@' &&      c != '\\' &&      c != '\'') {    return true;  }  if (c >= 9 && c <= 13) {    return true;  }  return false;}",29186
184,942,CVE-2011-3209,20,int slab_is_available(void){	return slab_state >= UP;},5710
356,1157,CVE-2013-6376,20,"static inline int __apic_test_and_set_vector(int vec, void *bitmap){	return __test_and_set_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));}",7358
323,10,CVE-2009-3605,20,  int getHeight() { return h; },263
89,329,CVE-2012-2375,20,"static void nfs4_init_channel_attrs(struct nfs41_create_session_args *args){	struct nfs4_session *session = args->client->cl_session;	unsigned int mxrqst_sz = session->fc_attrs.max_rqst_sz,		     mxresp_sz = session->fc_attrs.max_resp_sz;	if (mxrqst_sz == 0)		mxrqst_sz = NFS_MAX_FILE_IO_SIZE;	if (mxresp_sz == 0)		mxresp_sz = NFS_MAX_FILE_IO_SIZE;	 	args->fc_attrs.max_rqst_sz = mxrqst_sz;	args->fc_attrs.max_resp_sz = mxresp_sz;	args->fc_attrs.max_ops = NFS4_MAX_OPS;	args->fc_attrs.max_reqs = max_session_slots;	dprintk(""%s: Fore Channel : max_rqst_sz=%u max_resp_sz=%u ""		""max_ops=%u max_reqs=%u\n"",		__func__,		args->fc_attrs.max_rqst_sz, args->fc_attrs.max_resp_sz,		args->fc_attrs.max_ops, args->fc_attrs.max_reqs);	 	args->bc_attrs.max_rqst_sz = PAGE_SIZE;	args->bc_attrs.max_resp_sz = PAGE_SIZE;	args->bc_attrs.max_resp_sz_cached = 0;	args->bc_attrs.max_ops = NFS4_MAX_BACK_CHANNEL_OPS;	args->bc_attrs.max_reqs = 1;	dprintk(""%s: Back Channel : max_rqst_sz=%u max_resp_sz=%u ""		""max_resp_sz_cached=%u max_ops=%u max_reqs=%u\n"",		__func__,		args->bc_attrs.max_rqst_sz, args->bc_attrs.max_resp_sz,		args->bc_attrs.max_resp_sz_cached, args->bc_attrs.max_ops,		args->bc_attrs.max_reqs);}",3306
424,782,CVE-2011-4131,20,"static int nfs4_xdr_dec_setattr(struct rpc_rqst *rqstp,				struct xdr_stream *xdr,				struct nfs_setattrres *res){	struct compound_hdr hdr;	int status;	status = decode_compound_hdr(xdr, &hdr);	if (status)		goto out;	status = decode_sequence(xdr, &res->seq_res, rqstp);	if (status)		goto out;	status = decode_putfh(xdr);	if (status)		goto out;	status = decode_setattr(xdr);	if (status)		goto out;	decode_getfattr(xdr, res->fattr, res->server,			!RPC_IS_ASYNC(rqstp->rq_task));out:	return status;}",5123
415,141,CVE-2015-8312,20,"DECL_PIOCTL(PGetFID){    AFS_STATCNT(PGetFID);    if (!avc)	return EINVAL;    if (afs_pd_putBytes(aout, &avc->f.fid, sizeof(struct VenusFid)) != 0)	return EINVAL;    return 0;}",2261
92,266,CVE-2012-2375,20,"static int _nfs4_proc_mkdir(struct inode *dir, struct dentry *dentry,		struct iattr *sattr){	struct nfs4_createdata *data;	int status = -ENOMEM;	data = nfs4_alloc_createdata(dir, &dentry->d_name, sattr, NF4DIR);	if (data == NULL)		goto out;	status = nfs4_do_create(dir, dentry, data);	nfs4_free_createdata(data);out:	return status;}",3243
311,247,CVE-2012-2384,20,"pin_and_fence_object(struct drm_i915_gem_object *obj,		     struct intel_ring_buffer *ring){	struct drm_i915_gem_exec_object2 *entry = obj->exec_entry;	int has_fenced_gpu_access = INTEL_INFO(ring->dev)->gen < 4;	int need_fence, need_mappable;	int ret;	need_fence =		has_fenced_gpu_access &&		entry->flags & EXEC_OBJECT_NEEDS_FENCE &&		obj->tiling_mode != I915_TILING_NONE;	need_mappable =		entry->relocation_count ? true : need_fence;	ret = i915_gem_object_pin(obj, entry->alignment, need_mappable);	if (ret)		return ret;	if (has_fenced_gpu_access) {		if (entry->flags & EXEC_OBJECT_NEEDS_FENCE) {			if (obj->tiling_mode) {				ret = i915_gem_object_get_fence(obj, ring);				if (ret)					goto err_unpin;				entry->flags |= __EXEC_OBJECT_HAS_FENCE;				i915_gem_object_pin_fence(obj);			} else {				ret = i915_gem_object_put_fence(obj);				if (ret)					goto err_unpin;			}			obj->pending_fenced_gpu_access = true;		}	}	entry->offset = obj->gtt_offset;	return 0;err_unpin:	i915_gem_object_unpin(obj);	return ret;}",3224
227,1609,CVE-2019-7308,20,"static int is_pointer_value(struct bpf_verifier_env *env, int regno){	return __is_pointer_value(env->allow_ptr_leaks, reg_state(env, regno));}",27322
299,39,CVE-2014-6269,20,"int apply_filter_to_req_line(struct session *s, struct channel *req, struct hdr_exp *exp){	char *cur_ptr, *cur_end;	int done;	struct http_txn *txn = &s->txn;	int delta;	if (unlikely(txn->flags & (TX_CLDENY | TX_CLTARPIT)))		return 1;	else if (unlikely(txn->flags & TX_CLALLOW) &&		 (exp->action == ACT_ALLOW ||		  exp->action == ACT_DENY ||		  exp->action == ACT_TARPIT))		return 0;	else if (exp->action == ACT_REMOVE)		return 0;	done = 0;	cur_ptr = req->buf->p;	cur_end = cur_ptr + txn->req.sl.rq.l;	 	if (regex_exec_match2(exp->preg, cur_ptr, cur_end-cur_ptr, MAX_MATCH, pmatch)) {		switch (exp->action) {		case ACT_SETBE:			 			if (s->be != s->fe)				break;			 			session_set_backend(s, (struct proxy *)exp->replace);			done = 1;			break;		case ACT_ALLOW:			txn->flags |= TX_CLALLOW;			done = 1;			break;		case ACT_DENY:			txn->flags |= TX_CLDENY;			done = 1;			break;		case ACT_TARPIT:			txn->flags |= TX_CLTARPIT;			done = 1;			break;		case ACT_REPLACE:			trash.len = exp_replace(trash.str, trash.size, cur_ptr, exp->replace, pmatch);			if (trash.len < 0)				return -1;			delta = buffer_replace2(req->buf, cur_ptr, cur_end, trash.str, trash.len);			 			http_msg_move_end(&txn->req, delta);			cur_end += delta;			cur_end = (char *)http_parse_reqline(&txn->req,							     HTTP_MSG_RQMETH,							     cur_ptr, cur_end + 1,							     NULL, NULL);			if (unlikely(!cur_end))				return -1;			 			txn->meth = find_http_meth(cur_ptr, txn->req.sl.rq.m_l);			hdr_idx_set_start(&txn->hdr_idx, txn->req.sl.rq.l, *cur_end == '\r');			 			return 1;		}	}	return done;}",1703
6,1692,CVE-2012-2807,20,__xmlTreeIndentString(void) {    if (IS_MAIN_THREAD)	return (&xmlTreeIndentString);    else	return (&xmlGetGlobalState()->xmlTreeIndentString);},29278
353,828,CVE-2011-4131,20,"static void nfs4_xdr_enc_setacl(struct rpc_rqst *req, struct xdr_stream *xdr,				struct nfs_setaclargs *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_putfh(xdr, args->fh, &hdr);	encode_setacl(xdr, args, &hdr);	encode_nops(&hdr);}",5169
211,1171,CVE-2013-6376,20,static inline int apic_search_irr(struct kvm_lapic *apic){	return find_highest_vector(apic->regs + APIC_IRR);},7372
78,496,CVE-2012-0044,20,"char *drm_get_connector_name(struct drm_connector *connector){	static char buf[32];	snprintf(buf, 32, ""%s-%d"",		 drm_connector_enum_list[connector->connector_type].name,		 connector->connector_type_id);	return buf;}",4269
231,5,CVE-2009-3607,20,"poppler_rectangle_new (void){  return g_new0 (PopplerRectangle, 1);}",258
154,1619,CVE-2019-7308,20,"static int propagate_liveness(struct bpf_verifier_env *env,			      const struct bpf_verifier_state *vstate,			      struct bpf_verifier_state *vparent){	int i, frame, err = 0;	struct bpf_func_state *state, *parent;	if (vparent->curframe != vstate->curframe) {		WARN(1, ""propagate_live: parent frame %d current frame %d\n"",		     vparent->curframe, vstate->curframe);		return -EFAULT;	}	 	BUILD_BUG_ON(BPF_REG_FP + 1 != MAX_BPF_REG);	 	for (i = 0; i < BPF_REG_FP; i++) {		if (vparent->frame[vparent->curframe]->regs[i].live & REG_LIVE_READ)			continue;		if (vstate->frame[vstate->curframe]->regs[i].live & REG_LIVE_READ) {			err = mark_reg_read(env, &vstate->frame[vstate->curframe]->regs[i],					    &vparent->frame[vstate->curframe]->regs[i]);			if (err)				return err;		}	}	 	for (frame = 0; frame <= vstate->curframe; frame++) {		state = vstate->frame[frame];		parent = vparent->frame[frame];		for (i = 0; i < state->allocated_stack / BPF_REG_SIZE &&			    i < parent->allocated_stack / BPF_REG_SIZE; i++) {			if (parent->stack[i].spilled_ptr.live & REG_LIVE_READ)				continue;			if (state->stack[i].spilled_ptr.live & REG_LIVE_READ)				mark_reg_read(env, &state->stack[i].spilled_ptr,					      &parent->stack[i].spilled_ptr);		}	}	return err;}",27332
364,1407,CVE-2014-3145,20,"static int check_load_and_stores(struct sock_filter *filter, int flen){	u16 *masks, memvalid = 0;  	int pc, ret = 0;	BUILD_BUG_ON(BPF_MEMWORDS > 16);	masks = kmalloc(flen * sizeof(*masks), GFP_KERNEL);	if (!masks)		return -ENOMEM;	memset(masks, 0xff, flen * sizeof(*masks));	for (pc = 0; pc < flen; pc++) {		memvalid &= masks[pc];		switch (filter[pc].code) {		case BPF_S_ST:		case BPF_S_STX:			memvalid |= (1 << filter[pc].k);			break;		case BPF_S_LD_MEM:		case BPF_S_LDX_MEM:			if (!(memvalid & (1 << filter[pc].k))) {				ret = -EINVAL;				goto error;			}			break;		case BPF_S_JMP_JA:			 			masks[pc + 1 + filter[pc].k] &= memvalid;			memvalid = ~0;			break;		case BPF_S_JMP_JEQ_K:		case BPF_S_JMP_JEQ_X:		case BPF_S_JMP_JGE_K:		case BPF_S_JMP_JGE_X:		case BPF_S_JMP_JGT_K:		case BPF_S_JMP_JGT_X:		case BPF_S_JMP_JSET_X:		case BPF_S_JMP_JSET_K:			 			masks[pc + 1 + filter[pc].jt] &= memvalid;			masks[pc + 1 + filter[pc].jf] &= memvalid;			memvalid = ~0;			break;		}	}error:	kfree(masks);	return ret;}",11546
396,673,CVE-2011-4131,20,"static int decode_link(struct xdr_stream *xdr, struct nfs4_change_info *cinfo){	int status;	status = decode_op_hdr(xdr, OP_LINK);	if (status)		return status;	return decode_change_info(xdr, cinfo);}",5014
186,1557,CVE-2019-14763,20,"static void dwc3_gadget_ep_free_request(struct usb_ep *ep,		struct usb_request *request){	struct dwc3_request		*req = to_dwc3_request(request);	struct dwc3_ep			*dep = to_dwc3_ep(ep);	dep->allocated_requests--;	trace_dwc3_free_request(req);	kfree(req);}",26666
405,174,CVE-2012-3412,20,"static struct rtnl_link_stats64 *efx_net_stats(struct net_device *net_dev, struct rtnl_link_stats64 *stats){	struct efx_nic *efx = netdev_priv(net_dev);	struct efx_mac_stats *mac_stats = &efx->mac_stats;	spin_lock_bh(&efx->stats_lock);	efx->type->update_stats(efx);	spin_unlock_bh(&efx->stats_lock);	stats->rx_packets = mac_stats->rx_packets;	stats->tx_packets = mac_stats->tx_packets;	stats->rx_bytes = mac_stats->rx_bytes;	stats->tx_bytes = mac_stats->tx_bytes;	stats->rx_dropped = efx->n_rx_nodesc_drop_cnt;	stats->multicast = mac_stats->rx_multicast;	stats->collisions = mac_stats->tx_collision;	stats->rx_length_errors = (mac_stats->rx_gtjumbo +				   mac_stats->rx_length_error);	stats->rx_crc_errors = mac_stats->rx_bad;	stats->rx_frame_errors = mac_stats->rx_align_error;	stats->rx_fifo_errors = mac_stats->rx_overflow;	stats->rx_missed_errors = mac_stats->rx_missed;	stats->tx_window_errors = mac_stats->tx_late_collision;	stats->rx_errors = (stats->rx_length_errors +			    stats->rx_crc_errors +			    stats->rx_frame_errors +			    mac_stats->rx_symbol_error);	stats->tx_errors = (stats->tx_window_errors +			    mac_stats->tx_bad);	return stats;}",3048
272,1427,CVE-2014-2669,20,"hstore_gt(PG_FUNCTION_ARGS){	int			res = DatumGetInt32(DirectFunctionCall2(hstore_cmp,														PG_GETARG_DATUM(0),														PG_GETARG_DATUM(1)));	PG_RETURN_BOOL(res > 0);}",11805
116,1192,CVE-2013-6376,20,"static void kvm_ioapic_send_eoi(struct kvm_lapic *apic, int vector){	if (!(kvm_apic_get_reg(apic, APIC_SPIV) & APIC_SPIV_DIRECTED_EOI) &&	    kvm_ioapic_handles_vector(apic->vcpu->kvm, vector)) {		int trigger_mode;		if (apic_test_vector(vector, apic->regs + APIC_TMR))			trigger_mode = IOAPIC_LEVEL_TRIG;		else			trigger_mode = IOAPIC_EDGE_TRIG;		kvm_ioapic_update_eoi(apic->vcpu, vector, trigger_mode);	}}",7393
330,994,CVE-2011-2906,20,"static void pmcraid_get_dump(struct pmcraid_instance *pinstance){	pmcraid_info(""%s is not yet implemented\n"", __func__);}",6445
374,1069,CVE-2011-1476,20,"static int alloc_voice(int dev, int chn, int note){	unsigned short  key;	int voice;	key = (chn << 8) | (note + 1);	voice = synth_devs[dev]->alloc_voice(dev, chn, note,					     &synth_devs[dev]->alloc);	synth_devs[dev]->alloc.map[voice] = key;	synth_devs[dev]->alloc.alloc_times[voice] =			synth_devs[dev]->alloc.timestamp++;	return voice;}",6886
401,1357,CVE-2013-0211,20,"_archive_filter_name(struct archive *_a, int n){	struct archive_write_filter *f = filter_lookup(_a, n);	return f == NULL ? NULL : f->name;}",9821
389,505,CVE-2012-0044,20,"int drm_mode_connector_property_set_ioctl(struct drm_device *dev,				       void *data, struct drm_file *file_priv){	struct drm_mode_connector_set_property *out_resp = data;	struct drm_mode_object *obj;	struct drm_property *property;	struct drm_connector *connector;	int ret = -EINVAL;	int i;	if (!drm_core_check_feature(dev, DRIVER_MODESET))		return -EINVAL;	mutex_lock(&dev->mode_config.mutex);	obj = drm_mode_object_find(dev, out_resp->connector_id, DRM_MODE_OBJECT_CONNECTOR);	if (!obj) {		goto out;	}	connector = obj_to_connector(obj);	for (i = 0; i < DRM_CONNECTOR_MAX_PROPERTY; i++) {		if (connector->property_ids[i] == out_resp->prop_id)			break;	}	if (i == DRM_CONNECTOR_MAX_PROPERTY) {		goto out;	}	obj = drm_mode_object_find(dev, out_resp->prop_id, DRM_MODE_OBJECT_PROPERTY);	if (!obj) {		goto out;	}	property = obj_to_property(obj);	if (property->flags & DRM_MODE_PROP_IMMUTABLE)		goto out;	if (property->flags & DRM_MODE_PROP_RANGE) {		if (out_resp->value < property->values[0])			goto out;		if (out_resp->value > property->values[1])			goto out;	} else {		int found = 0;		for (i = 0; i < property->num_values; i++) {			if (property->values[i] == out_resp->value) {				found = 1;				break;			}		}		if (!found) {			goto out;		}	}	 	if (property == connector->dev->mode_config.dpms_property) {		if (connector->funcs->dpms)			(*connector->funcs->dpms)(connector, (int) out_resp->value);		ret = 0;	} else if (connector->funcs->set_property)		ret = connector->funcs->set_property(connector, property, out_resp->value);	 	if (!ret)		drm_connector_property_set_value(connector, property, out_resp->value);out:	mutex_unlock(&dev->mode_config.mutex);	return ret;}",4278
296,500,CVE-2012-0044,20,"static int drm_mode_attachmode(struct drm_device *dev,			       struct drm_connector *connector,			       struct drm_display_mode *mode){	int ret = 0;	list_add_tail(&mode->head, &connector->user_modes);	return ret;}",4273
248,543,CVE-2011-4611,20,static int is_limited_pmc(int pmcnum){	return (ppmu->flags & PPMU_LIMITED_PMC5_6)		&& (pmcnum == 5 || pmcnum == 6);},4620
213,308,CVE-2012-2375,20,"static int nfs4_commit_done_cb(struct rpc_task *task, struct nfs_write_data *data){	struct inode *inode = data->inode;	if (nfs4_async_handle_error(task, NFS_SERVER(inode), NULL) == -EAGAIN) {		rpc_restart_call_prepare(task);		return -EAGAIN;	}	nfs_refresh_inode(inode, data->res.fattr);	return 0;}",3285
98,283,CVE-2012-2375,20,"void nfs41_init_sequence(struct nfs4_sequence_args *args,		struct nfs4_sequence_res *res, int cache_reply){}",3260
237,22,CVE-2015-2331,20,_zip_read2(unsigned char **a){    unsigned short ret;    ret = (*a)[0]+((*a)[1]<<8);    *a += 2;    return ret;},795
406,676,CVE-2011-4131,20,"static int decode_op_hdr(struct xdr_stream *xdr, enum nfs_opnum4 expected){	__be32 *p;	int opnum;	int nfserr;	p = xdr_inline_decode(xdr, 8);	if (unlikely(!p))		goto out_overflow;	opnum = be32_to_cpup(p++);	if (opnum != expected) {		dprintk(""nfs: Server returned operation""			"" %d but we issued a request for %d\n"",				opnum, expected);		return -EIO;	}	nfserr = be32_to_cpup(p);	if (nfserr != NFS_OK)		return nfs4_stat_to_errno(nfserr);	return 0;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",5017
367,619,CVE-2011-4131,20,"int nfs4_setup_sequence(const struct nfs_server *server,			struct nfs4_sequence_args *args,			struct nfs4_sequence_res *res,			int cache_reply,			struct rpc_task *task){	struct nfs4_session *session = nfs4_get_session(server);	int ret = 0;	if (session == NULL) {		args->sa_session = NULL;		res->sr_session = NULL;		goto out;	}	dprintk(""--> %s clp %p session %p sr_slot %td\n"",		__func__, session->clp, session, res->sr_slot ?			res->sr_slot - session->fc_slot_table.slots : -1);	ret = nfs41_setup_sequence(session, args, res, cache_reply,				   task);out:	dprintk(""<-- %s status=%d\n"", __func__, ret);	return ret;}",4960
233,193,CVE-2012-3412,20,"static void efx_remove_eventq(struct efx_channel *channel){	netif_dbg(channel->efx, drv, channel->efx->net_dev,		  ""chan %d remove event queue\n"", channel->channel);	efx_nic_remove_eventq(channel);}",3067
129,424,CVE-2012-2375,20,"static int nfs4_verify_back_channel_attrs(struct nfs41_create_session_args *args, struct nfs4_session *session){	struct nfs4_channel_attrs *sent = &args->bc_attrs;	struct nfs4_channel_attrs *rcvd = &session->bc_attrs;	if (rcvd->max_rqst_sz > sent->max_rqst_sz)		return -EINVAL;	if (rcvd->max_resp_sz < sent->max_resp_sz)		return -EINVAL;	if (rcvd->max_resp_sz_cached > sent->max_resp_sz_cached)		return -EINVAL;	 	if (rcvd->max_ops != sent->max_ops)		return -EINVAL;	if (rcvd->max_reqs != sent->max_reqs)		return -EINVAL;	return 0;}",3401
101,275,CVE-2012-2375,20,"static int _nfs4_proc_symlink(struct inode *dir, struct dentry *dentry,		struct page *page, unsigned int len, struct iattr *sattr){	struct nfs4_createdata *data;	int status = -ENAMETOOLONG;	if (len > NFS4_MAXPATHLEN)		goto out;	status = -ENOMEM;	data = nfs4_alloc_createdata(dir, &dentry->d_name, sattr, NF4LNK);	if (data == NULL)		goto out;	data->msg.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_SYMLINK];	data->arg.u.symlink.pages = &page;	data->arg.u.symlink.len = len;		status = nfs4_do_create(dir, dentry, data);	nfs4_free_createdata(data);out:	return status;}",3252
308,1377,CVE-2014-4656,20,"static int snd_ctl_dev_free(struct snd_device *device){	struct snd_card *card = device->device_data;	struct snd_kcontrol *control;	down_write(&card->controls_rwsem);	while (!list_empty(&card->controls)) {		control = snd_kcontrol(card->controls.next);		snd_ctl_remove(card, control);	}	up_write(&card->controls_rwsem);	return 0;}",10811
140,1584,CVE-2019-7308,20,"static int acquire_reference_state(struct bpf_verifier_env *env, int insn_idx){	struct bpf_func_state *state = cur_func(env);	int new_ofs = state->acquired_refs;	int id, err;	err = realloc_reference_state(state, state->acquired_refs + 1, true);	if (err)		return err;	id = ++env->id_gen;	state->refs[new_ofs].id = id;	state->refs[new_ofs].insn_idx = insn_idx;	return id;}",27297
206,1695,CVE-2012-2807,20,int xmlThrDefDefaultBufferSize(int v) {    int ret;    xmlMutexLock(xmlThrDefMutex);    ret = xmlDefaultBufferSizeThrDef;    xmlDefaultBufferSizeThrDef = v;    xmlMutexUnlock(xmlThrDefMutex);    return ret;},29281
53,1586,CVE-2019-7308,20,static int arg_type_is_refcounted(enum bpf_arg_type type){	return type == ARG_PTR_TO_SOCKET;},27299
226,1092,CVE-2013-7010,20,"static int add_hfyu_left_prediction_c(int *dst, const int *src, int w, int acc){    int i;    for(i=0; i<w-1; i++){        acc+= src[i];        dst[i]= acc;        i++;        acc+= src[i];        dst[i]= acc;    }    for(; i<w; i++){        acc+= src[i];        dst[i]= acc;    }    return acc;}",7081
124,1596,CVE-2019-7308,20,"static int check_xadd(struct bpf_verifier_env *env, int insn_idx, struct bpf_insn *insn){	int err;	if ((BPF_SIZE(insn->code) != BPF_W && BPF_SIZE(insn->code) != BPF_DW) ||	    insn->imm != 0) {		verbose(env, ""BPF_XADD uses reserved fields\n"");		return -EINVAL;	}	 	err = check_reg_arg(env, insn->src_reg, SRC_OP);	if (err)		return err;	 	err = check_reg_arg(env, insn->dst_reg, SRC_OP);	if (err)		return err;	if (is_pointer_value(env, insn->src_reg)) {		verbose(env, ""R%d leaks addr into mem\n"", insn->src_reg);		return -EACCES;	}	if (is_ctx_reg(env, insn->dst_reg) ||	    is_pkt_reg(env, insn->dst_reg) ||	    is_flow_key_reg(env, insn->dst_reg)) {		verbose(env, ""BPF_XADD stores into R%d %s is not allowed\n"",			insn->dst_reg,			reg_type_str[reg_state(env, insn->dst_reg)->type]);		return -EACCES;	}	 	err = check_mem_access(env, insn_idx, insn->dst_reg, insn->off,			       BPF_SIZE(insn->code), BPF_READ, -1, true);	if (err)		return err;	 	return check_mem_access(env, insn_idx, insn->dst_reg, insn->off,				BPF_SIZE(insn->code), BPF_WRITE, -1, true);}",27309
196,1164,CVE-2013-6376,20,static inline int apic_find_highest_irr(struct kvm_lapic *apic){	int result;	 	if (!apic->irr_pending)		return -1;	kvm_x86_ops->sync_pir_to_irr(apic->vcpu);	result = apic_search_irr(apic);	ASSERT(result == -1 || result >= 16);	return result;},7365
358,99,CVE-2014-6269,20,"smp_fetch_path(struct proxy *px, struct session *l4, void *l7, unsigned int opt,               const struct arg *args, struct sample *smp, const char *kw){	struct http_txn *txn = l7;	char *ptr, *end;	CHECK_HTTP_MESSAGE_FIRST();	end = txn->req.chn->buf->p + txn->req.sl.rq.u + txn->req.sl.rq.u_l;	ptr = http_get_path(txn);	if (!ptr)		return 0;	 	smp->type = SMP_T_STR;	smp->data.str.str = ptr;	while (ptr < end && *ptr != '?')		ptr++;	smp->data.str.len = ptr - smp->data.str.str;	smp->flags = SMP_F_VOL_1ST | SMP_F_CONST;	return 1;}",1763
71,1140,CVE-2013-7010,20,"static int sse16_c(void *v, int *pix1, int *pix2, int line_size, int h){    int s, i;    int *sq = ff_squareTbl + 256;    s = 0;    for (i = 0; i < h; i++) {        s += sq[pix1[ 0] - pix2[ 0]];        s += sq[pix1[ 1] - pix2[ 1]];        s += sq[pix1[ 2] - pix2[ 2]];        s += sq[pix1[ 3] - pix2[ 3]];        s += sq[pix1[ 4] - pix2[ 4]];        s += sq[pix1[ 5] - pix2[ 5]];        s += sq[pix1[ 6] - pix2[ 6]];        s += sq[pix1[ 7] - pix2[ 7]];        s += sq[pix1[ 8] - pix2[ 8]];        s += sq[pix1[ 9] - pix2[ 9]];        s += sq[pix1[10] - pix2[10]];        s += sq[pix1[11] - pix2[11]];        s += sq[pix1[12] - pix2[12]];        s += sq[pix1[13] - pix2[13]];        s += sq[pix1[14] - pix2[14]];        s += sq[pix1[15] - pix2[15]];        pix1 += line_size;        pix2 += line_size;    }    return s;}",7129
434,1453,CVE-2015-5707,20,"static int sg_proc_open_dev(struct inode *inode, struct file *file){        return seq_open(file, &dev_seq_ops);}",13168
369,1087,CVE-2011-1476,20,void sequencer_timer(unsigned long dummy){	seq_startplay();},6904
110,1005,CVE-2011-2906,20,"static int pmcraid_notify_ccn(struct pmcraid_instance *pinstance){	return pmcraid_notify_aen(pinstance,				pinstance->ccn.msg,				pinstance->ccn.hcam->data_len +				sizeof(struct pmcraid_hcam_hdr));}",6456
315,544,CVE-2011-4611,20,void perf_event_print_debug(void){},4621
394,142,CVE-2015-8312,20,"DECL_PIOCTL(PStoreBehind){    struct sbstruct sbr;    if (afs_pd_getBytes(ain, &sbr, sizeof(struct sbstruct)) != 0)	return EINVAL;    if (sbr.sb_default != -1) {	if (afs_osi_suser(*acred))	    afs_defaultAsynchrony = sbr.sb_default;	else	    return EPERM;    }    if (avc && (sbr.sb_thisfile != -1)) {	if (afs_AccessOK	    (avc, PRSFS_WRITE | PRSFS_ADMINISTER, areq, DONT_CHECK_MODE_BITS))	    avc->asynchrony = sbr.sb_thisfile;	else	    return EACCES;    }    memset(&sbr, 0, sizeof(sbr));    sbr.sb_default = afs_defaultAsynchrony;    if (avc) {	sbr.sb_thisfile = avc->asynchrony;    }    return afs_pd_putBytes(aout, &sbr, sizeof(sbr));}",2262
220,642,CVE-2011-4131,20,"static int decode_attr_maxread(struct xdr_stream *xdr, int *bitmap, int *res){	__be32 *p;	int status = 0;	*res = 1024;	if (unlikely(bitmap[0] & (FATTR4_WORD0_MAXREAD - 1U)))		return -EIO;	if (likely(bitmap[0] & FATTR4_WORD0_MAXREAD)) {		int maxread;		p = xdr_inline_decode(xdr, 8);		if (unlikely(!p))			goto out_overflow;		xdr_decode_hyper(p, &maxread);		if (maxread > 0x7FFFFFFF)			maxread = 0x7FFFFFFF;		*res = (int)maxread;		bitmap[0] &= ~FATTR4_WORD0_MAXREAD;	}	dprintk(""%s: maxread=%lu\n"", __func__, (unsigned long)*res);	return status;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",4983
182,884,CVE-2011-3209,20,"static void __slab_free(struct kmem_cache *s, struct page *page,				void *x, void *addr, unsigned int offset){	void *prior;	void **object = (void *)x;	struct kmem_cache_cpu *c;	c = get_cpu_slab(s, raw_smp_processor_id());	stat(c, FREE_SLOWPATH);	slab_lock(page);	if (unlikely(SlabDebug(page)))		goto debug;checks_ok:	prior = object[offset] = page->freelist;	page->freelist = object;	page->inuse--;	if (unlikely(SlabFrozen(page))) {		stat(c, FREE_FROZEN);		goto out_unlock;	}	if (unlikely(!page->inuse))		goto slab_empty;	 	if (unlikely(!prior)) {		add_partial(get_node(s, page_to_nid(page)), page, 1);		stat(c, FREE_ADD_PARTIAL);	}out_unlock:	slab_unlock(page);	return;slab_empty:	if (prior) {		 		remove_partial(s, page);		stat(c, FREE_REMOVE_PARTIAL);	}	slab_unlock(page);	stat(c, FREE_SLAB);	discard_slab(s, page);	return;debug:	if (!free_debug_processing(s, page, x, addr))		goto out_unlock;	goto checks_ok;}",5652
381,1616,CVE-2019-7308,20,"static int prepare_func_exit(struct bpf_verifier_env *env, int *insn_idx){	struct bpf_verifier_state *state = env->cur_state;	struct bpf_func_state *caller, *callee;	struct bpf_reg_state *r0;	int err;	callee = state->frame[state->curframe];	r0 = &callee->regs[BPF_REG_0];	if (r0->type == PTR_TO_STACK) {		 		verbose(env, ""cannot return stack pointer to the caller\n"");		return -EINVAL;	}	state->curframe--;	caller = state->frame[state->curframe];	 	caller->regs[BPF_REG_0] = *r0;	 	err = transfer_reference_state(caller, callee);	if (err)		return err;	*insn_idx = callee->callsite + 1;	if (env->log.level) {		verbose(env, ""returning from callee:\n"");		print_verifier_state(env, callee);		verbose(env, ""to caller at %d:\n"", *insn_idx);		print_verifier_state(env, caller);	}	 	free_func_state(callee);	state->frame[state->curframe + 1] = NULL;	return 0;}",27329
189,98,CVE-2014-6269,20,"smp_fetch_meth(struct proxy *px, struct session *l4, void *l7, unsigned int opt,               const struct arg *args, struct sample *smp, const char *kw){	int meth;	struct http_txn *txn = l7;	CHECK_HTTP_MESSAGE_FIRST_PERM();	meth = txn->meth;	smp->type = SMP_T_METH;	smp->data.meth.meth = meth;	if (meth == HTTP_METH_OTHER) {		if (txn->rsp.msg_state != HTTP_MSG_RPBEFORE)			 			return 0;		smp->flags |= SMP_F_CONST;		smp->data.meth.str.len = txn->req.sl.rq.m_l;		smp->data.meth.str.str = txn->req.chn->buf->p;	}	smp->flags |= SMP_F_VOL_1ST;	return 1;}",1762
58,1099,CVE-2013-7010,20,"static inline void avg_tpel_pixels_mc12_c(int *dst, const int *src, int stride, int width, int height){    int i,j;    for (i=0; i < height; i++) {      for (j=0; j < width; j++) {        dst[j] = (dst[j] + ((2731*(3*src[j] + 2*src[j+1] + 4*src[j+stride] + 3*src[j+stride+1] + 6)) >> 15) + 1) >> 1;      }      src += stride;      dst += stride;    }}",7088
351,837,CVE-2011-4131,20,"int write_bytes_to_xdr_buf(struct xdr_buf *buf, unsigned int base, void *obj, unsigned int len){	struct xdr_buf subbuf;	int status;	status = xdr_buf_subsegment(buf, &subbuf, base, len);	if (status != 0)		return status;	__write_bytes_to_xdr_buf(&subbuf, obj, len);	return 0;}",5178
362,1710,CVE-2019-5755,20,"ACTION_P2(ExitMessageLoop, task_runner, quit_closure) {  task_runner->PostTask(FROM_HERE, quit_closure);}",30224
111,333,CVE-2012-2375,20,"nfs4_layoutcommit_done(struct rpc_task *task, void *calldata){	struct nfs4_layoutcommit_data *data = calldata;	struct nfs_server *server = NFS_SERVER(data->args.inode);	if (!nfs4_sequence_done(task, &data->res.seq_res))		return;	switch (task->tk_status) {  	case NFS4ERR_DELEG_REVOKED:  	case NFS4ERR_BADIOMODE:      	case NFS4ERR_BADLAYOUT:      	case NFS4ERR_GRACE:	     		task->tk_status = 0;	}	if (nfs4_async_handle_error(task, server, NULL) == -EAGAIN) {		rpc_restart_call_prepare(task);		return;	}	if (task->tk_status == 0)		nfs_post_op_update_inode_force_wcc(data->args.inode,						   data->res.fattr);}",3310
357,1107,CVE-2013-7010,20,"static void ff_jref_idct1_put(int *dest, int line_size, int *block){    dest[0] = av_clip_uint8((block[0] + 4)>>3);}",7096
131,1673,CVE-2012-2807,20,__xmlIndentTreeOutput(void) {    if (IS_MAIN_THREAD)	return (&xmlIndentTreeOutput);    else	return (&xmlGetGlobalState()->xmlIndentTreeOutput);},29259
195,409,CVE-2012-2375,20,"int nfs4_release_lockowner(struct nfs4_lock_state *lsp){	struct nfs_server *server = lsp->ls_state->owner->so_server;	struct nfs_release_lockowner_data *data;	struct rpc_message msg = {		.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_RELEASE_LOCKOWNER],	};	if (server->nfs_client->cl_mvops->minor_version != 0)		return -EINVAL;	data = kmalloc(sizeof(*data), GFP_NOFS);	if (!data)		return -ENOMEM;	data->lsp = lsp;	data->server = server;	data->args.lock_owner.clientid = server->nfs_client->cl_clientid;	data->args.lock_owner.id = lsp->ls_seqid.owner_id;	data->args.lock_owner.s_dev = server->s_dev;	msg.rpc_argp = &data->args;	rpc_call_async(server->client, &msg, 0, &nfs4_release_lockowner_ops, data);	return 0;}",3386
371,1535,CVE-2016-2070,20,"static int tcp_validate_incoming(struct sock *sk, struct sk_buff *skb,				  const struct tcphdr *th, int syn_inerr){	struct tcp_sock *tp = tcp_sk(sk);	 	if (tcp_fast_parse_options(skb, th, tp) && tp->rx_opt.saw_tstamp &&	    tcp_paws_discard(sk, skb)) {		if (!th->rst) {			NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PAWSESTABREJECTED);			if (!tcp_oow_rate_limited(sock_net(sk), skb,						  LINUX_MIB_TCPACKSKIPPEDPAWS,						  &tp->last_oow_ack_time))				tcp_send_dupack(sk, skb);			goto discard;		}		 	}	 	if (!tcp_sequence(tp, TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq)) {		 		if (!th->rst) {			if (th->syn)				goto syn_challenge;			if (!tcp_oow_rate_limited(sock_net(sk), skb,						  LINUX_MIB_TCPACKSKIPPEDSEQ,						  &tp->last_oow_ack_time))				tcp_send_dupack(sk, skb);		}		goto discard;	}	 	if (th->rst) {		 		if (TCP_SKB_CB(skb)->seq == tp->rcv_nxt)			tcp_reset(sk);		else			tcp_send_challenge_ack(sk, skb);		goto discard;	}	 	 	if (th->syn) {syn_challenge:		if (syn_inerr)			TCP_INC_STATS_BH(sock_net(sk), TCP_MIB_INERRS);		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPSYNCHALLENGE);		tcp_send_challenge_ack(sk, skb);		goto discard;	}	return true;discard:	__kfree_skb(skb);	return false;}",18018
188,1737,CVE-2013-4483,20, static inline void sem_putref(struct sem_array *sma) {	ipc_lock_by_ptr(&sma->sem_perm);	ipc_rcu_putref(sma);	ipc_unlock(&(sma)->sem_perm); },31050
250,1258,CVE-2013-4247,20,"cifs_readv_from_socket(struct TCP_Server_Info *server, struct kvec *iov_orig,		       unsigned int nr_segs, unsigned int to_read){	int length = 0;	int total_read;	unsigned int segs;	struct msghdr smb_msg;	struct kvec *iov;	iov = get_server_iovec(server, nr_segs);	if (!iov)		return -ENOMEM;	smb_msg.msg_control = NULL;	smb_msg.msg_controllen = 0;	for (total_read = 0; to_read; total_read += length, to_read -= length) {		try_to_freeze();		if (server_unresponsive(server)) {			total_read = -EAGAIN;			break;		}		segs = kvec_array_init(iov, iov_orig, nr_segs, total_read);		length = kernel_recvmsg(server->ssocket, &smb_msg,					iov, segs, to_read, 0);		if (server->tcpStatus == CifsExiting) {			total_read = -ESHUTDOWN;			break;		} else if (server->tcpStatus == CifsNeedReconnect) {			cifs_reconnect(server);			total_read = -EAGAIN;			break;		} else if (length == -ERESTARTSYS ||			   length == -EAGAIN ||			   length == -EINTR) {			 			usleep_range(1000, 2000);			length = 0;			continue;		} else if (length <= 0) {			cifs_dbg(FYI, ""Received no data or error: expecting %d\n""				 ""got %d"", to_read, length);			cifs_reconnect(server);			total_read = -EAGAIN;			break;		}	}	return total_read;}",7910
426,1084,CVE-2011-1476,20,"static void seq_sysex_message(unsigned char *event_rec){	unsigned int dev = event_rec[1];	int i, l = 0;	unsigned char  *buf = &event_rec[2];	if (dev > max_synthdev)		return;	if (!(synth_open_mask & (1 << dev)))		return;	if (!synth_devs[dev])		return;	l = 0;	for (i = 0; i < 6 && buf[i] != 0xff; i++)		l = i + 1;	if (!synth_devs[dev]->send_sysex)		return;	if (l > 0)		synth_devs[dev]->send_sysex(dev, buf, l);}",6901
4,779,CVE-2011-4131,20,"static int nfs4_xdr_dec_sequence(struct rpc_rqst *rqstp,				 struct xdr_stream *xdr,				 struct nfs4_sequence_res *res){	struct compound_hdr hdr;	int status;	status = decode_compound_hdr(xdr, &hdr);	if (!status)		status = decode_sequence(xdr, res, rqstp);	return status;}",5120
312,774,CVE-2011-4131,20,"static int nfs4_xdr_dec_remove(struct rpc_rqst *rqstp, struct xdr_stream *xdr,			       struct nfs_removeres *res){	struct compound_hdr hdr;	int status;	status = decode_compound_hdr(xdr, &hdr);	if (status)		goto out;	status = decode_sequence(xdr, &res->seq_res, rqstp);	if (status)		goto out;	status = decode_putfh(xdr);	if (status)		goto out;	status = decode_remove(xdr, &res->cinfo);	if (status)		goto out;	decode_getfattr(xdr, res->dir_attr, res->server,			!RPC_IS_ASYNC(rqstp->rq_task));out:	return status;}",5115
173,1645,CVE-2013-2596,20,"static void zap_page_range_single(struct vm_area_struct *vma, unsigned long address,		unsigned long size, struct zap_details *details){	struct mm_struct *mm = vma->vm_mm;	struct mmu_gather tlb;	unsigned long end = address + size;	lru_add_drain();	tlb_gather_mmu(&tlb, mm, 0);	update_hiwater_rss(mm);	mmu_notifier_invalidate_range_start(mm, address, end);	unmap_single_vma(&tlb, vma, address, end, details);	mmu_notifier_invalidate_range_end(mm, address, end);	tlb_finish_mmu(&tlb, address, end);}",28305
108,476,CVE-2012-2100,20,"static int init_inodecache(void){	ext4_inode_cachep = kmem_cache_create(""ext4_inode_cache"",					     sizeof(struct ext4_inode_info),					     0, (SLAB_RECLAIM_ACCOUNT|						SLAB_MEM_SPREAD),					     init_once);	if (ext4_inode_cachep == NULL)		return -ENOMEM;	return 0;}",3631
347,1371,CVE-2014-8369,20,"void kvm_iommu_unmap_pages(struct kvm *kvm, struct kvm_memory_slot *slot){	kvm_iommu_put_pages(kvm, slot->base_gfn, slot->npages);}",10459
177,612,CVE-2011-4131,20,"static int nfs4_proc_setlk(struct nfs4_state *state, int cmd, struct file_lock *request){	struct nfs4_exception exception = { };	int err;	do {		err = _nfs4_proc_setlk(state, cmd, request);		if (err == -NFS4ERR_DENIED)			err = -EAGAIN;		err = nfs4_handle_exception(NFS_SERVER(state->inode),				err, &exception);	} while (exception.retry);	return err;}",4953
309,1154,CVE-2013-6378,20,"void lbs_debugfs_init(void){	if (!lbs_dir)		lbs_dir = debugfs_create_dir(""lbs_wireless"", NULL);}",7355
163,345,CVE-2012-2375,20,"static void nfs4_lock_release(void *calldata){	struct nfs4_lockdata *data = calldata;	dprintk(""%s: begin!\n"", __func__);	nfs_free_seqid(data->arg.open_seqid);	if (data->cancelled != 0) {		struct rpc_task *task;		task = nfs4_do_unlck(&data->fl, data->ctx, data->lsp,				data->arg.lock_seqid);		if (!IS_ERR(task))			rpc_put_task_async(task);		dprintk(""%s: cancelling lock!\n"", __func__);	} else		nfs_free_seqid(data->arg.lock_seqid);	nfs4_put_lock_state(data->lsp);	put_nfs_open_context(data->ctx);	kfree(data);	dprintk(""%s: done!\n"", __func__);}",3322
209,63,CVE-2014-6269,20,void http_reset_txn(struct session *s){	http_end_txn(s);	http_init_txn(s);	s->be = s->fe;	s->logs.logwait = s->fe->to_log;	s->logs.level = 0;	session_del_srv_conn(s);	s->target = NULL;	 	s->store_count = 0;	s->uniq_id = global.req_count++;	s->pend_pos = NULL;	s->req->flags |= CF_READ_DONTWAIT;  	 	if (unlikely(s->rep->buf->i))		s->rep->buf->i = 0;	s->req->rto = s->fe->timeout.client;	s->req->wto = TICK_ETERNITY;	s->rep->rto = TICK_ETERNITY;	s->rep->wto = s->fe->timeout.client;	s->req->rex = TICK_ETERNITY;	s->req->wex = TICK_ETERNITY;	s->req->analyse_exp = TICK_ETERNITY;	s->rep->rex = TICK_ETERNITY;	s->rep->wex = TICK_ETERNITY;	s->rep->analyse_exp = TICK_ETERNITY;},1727
337,1359,CVE-2013-0211,20,_archive_write_filter_count(struct archive *_a){	struct archive_write *a = (struct archive_write *)_a;	struct archive_write_filter *p = a->filter_first;	int count = 0;	while(p) {		count++;		p = p->next_filter;	}	return count;},9823
395,960,CVE-2011-3191,20,"CIFSSMBTDis(const int xid, struct cifs_tcon *tcon){	struct smb_hdr *smb_buffer;	int rc = 0;	cFYI(1, ""In tree disconnect"");	 	if ((tcon->ses == NULL) || (tcon->ses->server == NULL))		return -EIO;	 	if ((tcon->need_reconnect) || (tcon->ses->need_reconnect))		return 0;	rc = small_smb_init(SMB_COM_TREE_DISCONNECT, 0, tcon,			    (void **)&smb_buffer);	if (rc)		return rc;	rc = SendReceiveNoRsp(xid, tcon->ses, smb_buffer, 0);	if (rc)		cFYI(1, ""Tree disconnect failed %d"", rc);	 	if (rc == -EAGAIN)		rc = 0;	return rc;}",5728
280,443,CVE-2012-2100,20,"static inline int ext3_feature_set_ok(struct super_block *sb){	if (EXT4_HAS_INCOMPAT_FEATURE(sb, ~EXT3_FEATURE_INCOMPAT_SUPP))		return 0;	if (!EXT4_HAS_COMPAT_FEATURE(sb, EXT4_FEATURE_COMPAT_HAS_JOURNAL))		return 0;	if (sb->s_flags & MS_RDONLY)		return 1;	if (EXT4_HAS_RO_COMPAT_FEATURE(sb, ~EXT3_FEATURE_RO_COMPAT_SUPP))		return 0;	return 1;}",3598
146,583,CVE-2011-4131,20,"static void nfs4_close_done(struct rpc_task *task, void *data){	struct nfs4_closedata *calldata = data;	struct nfs4_state *state = calldata->state;	struct nfs_server *server = NFS_SERVER(calldata->inode);	if (!nfs4_sequence_done(task, &calldata->res.seq_res))		return;         	switch (task->tk_status) {		case 0:			if (calldata->roc)				pnfs_roc_set_barrier(state->inode,						     calldata->roc_barrier);			nfs_set_open_stateid(state, &calldata->res.stateid, 0);			renew_lease(server, calldata->timestamp);			nfs4_close_clear_stateid_flags(state,					calldata->arg.fmode);			break;		case -NFS4ERR_STALE_STATEID:		case -NFS4ERR_OLD_STATEID:		case -NFS4ERR_BAD_STATEID:		case -NFS4ERR_EXPIRED:			if (calldata->arg.fmode == 0)				break;		default:			if (nfs4_async_handle_error(task, server, state) == -EAGAIN)				rpc_restart_call_prepare(task);	}	nfs_release_seqid(calldata->arg.seqid);	nfs_refresh_inode(calldata->inode, calldata->res.fattr);}",4924
68,925,CVE-2011-3209,20,"static inline int lock_and_freeze_slab(struct kmem_cache_node *n, struct page *page){	if (slab_trylock(page)) {		list_del(&page->lru);		n->nr_partial--;		SetSlabFrozen(page);		return 1;	}	return 0;}",5693
304,582,CVE-2011-4131,20,"static void nfs4_check_drain_fc_complete(struct nfs4_session *ses){	struct rpc_task *task;	if (!test_bit(NFS4_SESSION_DRAINING, &ses->session_state)) {		task = rpc_wake_up_next(&ses->fc_slot_table.slot_tbl_waitq);		if (task)			rpc_task_set_priority(task, RPC_PRIORITY_PRIVILEGED);		return;	}	if (ses->fc_slot_table.highest_used_slotid != -1)		return;	dprintk(""%s COMPLETE: Session Fore Channel Drained\n"", __func__);	complete(&ses->fc_slot_table.complete);}",4923
216,644,CVE-2011-4131,20,"static int decode_attr_mounted_on_fileid(struct xdr_stream *xdr, int *bitmap, int *fileid){	__be32 *p;	int ret = 0;	*fileid = 0;	if (unlikely(bitmap[1] & (FATTR4_WORD1_MOUNTED_ON_FILEID - 1U)))		return -EIO;	if (likely(bitmap[1] & FATTR4_WORD1_MOUNTED_ON_FILEID)) {		p = xdr_inline_decode(xdr, 8);		if (unlikely(!p))			goto out_overflow;		xdr_decode_hyper(p, fileid);		bitmap[1] &= ~FATTR4_WORD1_MOUNTED_ON_FILEID;		ret = NFS_ATTR_FATTR_MOUNTED_ON_FILEID;	}	dprintk(""%s: fileid=%Lu\n"", __func__, (unsigned long long)*fileid);	return ret;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",4985
201,1726,CVE-2011-4131,20,"nfs4_xdr_dec_getacl(struct rpc_rqst *rqstp, struct xdr_stream *xdr,		    struct nfs_getaclres *res){	struct compound_hdr hdr;	int status;	status = decode_compound_hdr(xdr, &hdr);	if (status)		goto out;	status = decode_sequence(xdr, &res->seq_res, rqstp);	if (status)		goto out; 	status = decode_putfh(xdr); 	if (status) 		goto out;	status = decode_getacl(xdr, rqstp, &res->acl_len);  out: 	return status;}",30976
132,248,CVE-2012-2375,20,void __nfs4_read_done_cb(struct nfs_read_data *data){	nfs_invalidate_atime(data->inode);},3225
5,1479,CVE-2015-4001,20,static int oz_hcd_bus_suspend(struct usb_hcd *hcd){	struct oz_hcd *ozhcd;	ozhcd = oz_hcd_private(hcd);	spin_lock_bh(&ozhcd->hcd_lock);	hcd->state = HC_STATE_SUSPENDED;	ozhcd->flags |= OZ_HDC_F_SUSPENDED;	spin_unlock_bh(&ozhcd->hcd_lock);	return 0;},13555
153,710,CVE-2011-4131,20,"static void encode_lockowner(struct xdr_stream *xdr, const struct nfs_lowner *lowner){	__be32 *p;	p = reserve_space(xdr, 32);	p = xdr_encode_hyper(p, lowner->clientid);	*p++ = cpu_to_be32(20);	p = xdr_encode_opaque_fixed(p, ""lock id:"", 8);	*p++ = cpu_to_be32(lowner->s_dev);	xdr_encode_hyper(p, lowner->id);}",5051
193,189,CVE-2012-3412,20,"static int efx_process_channel(struct efx_channel *channel, int budget){	struct efx_nic *efx = channel->efx;	int spent;	if (unlikely(efx->reset_pending || !channel->enabled))		return 0;	spent = efx_nic_process_eventq(channel, budget);	if (spent == 0)		return 0;	 	if (channel->rx_pkt) {		__efx_rx_packet(channel, channel->rx_pkt,				channel->rx_pkt_csummed);		channel->rx_pkt = NULL;	}	efx_rx_strategy(channel);	efx_fast_push_rx_descriptors(efx_channel_get_rx_queue(channel));	return spent;}",3063
119,711,CVE-2011-4131,20,"static void encode_lockt(struct xdr_stream *xdr, const struct nfs_lockt_args *args, struct compound_hdr *hdr){	__be32 *p;	p = reserve_space(xdr, 24);	*p++ = cpu_to_be32(OP_LOCKT);	*p++ = cpu_to_be32(nfs4_lock_type(args->fl, 0));	p = xdr_encode_hyper(p, args->fl->fl_start);	p = xdr_encode_hyper(p, nfs4_lock_length(args->fl));	encode_lockowner(xdr, &args->lock_owner);	hdr->nops++;	hdr->replen += decode_lockt_maxsz;}",5052
74,620,CVE-2011-4131,20,"static int nfs4_setup_session_slot_tables(struct nfs4_session *ses){	struct nfs4_slot_table *tbl;	int status;	dprintk(""--> %s\n"", __func__);	 	tbl = &ses->fc_slot_table;	if (tbl->slots == NULL) {		status = nfs4_init_slot_table(tbl, ses->fc_attrs.max_reqs, 1);		if (status)  			return status;	} else {		status = nfs4_reset_slot_table(tbl, ses->fc_attrs.max_reqs, 1);		if (status)			return status;	}	 	tbl = &ses->bc_slot_table;	if (tbl->slots == NULL) {		status = nfs4_init_slot_table(tbl, ses->bc_attrs.max_reqs, 0);		if (status)			 			nfs4_destroy_slot_tables(ses);	} else		status = nfs4_reset_slot_table(tbl, ses->bc_attrs.max_reqs, 0);	return status;}",4961
22,432,CVE-2012-2375,20,static void nfs_fixup_referral_attributes(struct nfs_fattr *fattr){	if (!(((fattr->valid & NFS_ATTR_FATTR_MOUNTED_ON_FILEID) ||	       (fattr->valid & NFS_ATTR_FATTR_FILEID)) &&	      (fattr->valid & NFS_ATTR_FATTR_FSID) &&	      (fattr->valid & NFS_ATTR_FATTR_V4_LOCATIONS)))		return;	fattr->valid |= NFS_ATTR_FATTR_TYPE | NFS_ATTR_FATTR_MODE |		NFS_ATTR_FATTR_NLINK | NFS_ATTR_FATTR_V4_REFERRAL;	fattr->mode = S_IFDIR | S_IRUGO | S_IXUGO;	fattr->nlink = 2;},3409
19,530,CVE-2012-0044,20,"void drm_mode_remove(struct drm_connector *connector,		     struct drm_display_mode *mode){	list_del(&mode->head);	kfree(mode);}",4303
345,1552,CVE-2019-14763,20,"static void dwc3_gadget_disconnect_interrupt(struct dwc3 *dwc){	int			reg;	reg = dwc3_readl(dwc->regs, DWC3_DCTL);	reg &= ~DWC3_DCTL_INITU1ENA;	dwc3_writel(dwc->regs, DWC3_DCTL, reg);	reg &= ~DWC3_DCTL_INITU2ENA;	dwc3_writel(dwc->regs, DWC3_DCTL, reg);	dwc3_disconnect_gadget(dwc);	dwc->gadget.speed = USB_SPEED_UNKNOWN;	dwc->setup_packet_pending = false;	usb_gadget_set_state(&dwc->gadget, USB_STATE_NOTATTACHED);	dwc->connected = false;}",26661
115,1238,CVE-2013-4483,20,"int ipcget(struct ipc_namespace *ns, struct ipc_ids *ids,			struct ipc_ops *ops, struct ipc_params *params){	if (params->key == IPC_PRIVATE)		return ipcget_new(ns, ids, ops, params);	else		return ipcget_public(ns, ids, ops, params);}",7798
377,1033,CVE-2011-2906,20,static void pmcraid_slave_destroy(struct scsi_device *scsi_dev){	struct pmcraid_resource_entry *res;	res = (struct pmcraid_resource_entry *)scsi_dev->hostdata;	if (res)		res->scsi_dev = NULL;	scsi_dev->hostdata = NULL;},6484
31,809,CVE-2011-4131,20,"static void nfs4_xdr_enc_lookup(struct rpc_rqst *req, struct xdr_stream *xdr,				const struct nfs4_lookup_arg *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_putfh(xdr, args->dir_fh, &hdr);	encode_lookup(xdr, args->name, &hdr);	encode_getfh(xdr, &hdr);	encode_getfattr(xdr, args->bitmask, &hdr);	encode_nops(&hdr);}",5150
265,986,CVE-2011-2906,20,"static int pmcraid_chr_release(struct inode *inode, struct file *filep){	struct pmcraid_instance *pinstance = filep->private_data;	filep->private_data = NULL;	fasync_helper(-1, filep, 0, &pinstance->aen_queue);	return 0;}",6437
234,296,CVE-2012-2375,20,static void nfs41_sequence_release(void *data){	struct nfs4_sequence_data *calldata = data;	struct nfs_client *clp = calldata->clp;	if (atomic_read(&clp->cl_count) > 1)		nfs4_schedule_state_renewal(clp);	nfs_put_client(clp);	kfree(calldata);},3273
105,1270,CVE-2013-4247,20,"is_smb_response(struct TCP_Server_Info *server, unsigned char type){	 	switch (type) {	case RFC1002_SESSION_MESSAGE:		 		return true;	case RFC1002_SESSION_KEEP_ALIVE:		cifs_dbg(FYI, ""RFC 1002 session keep alive\n"");		break;	case RFC1002_POSITIVE_SESSION_RESPONSE:		cifs_dbg(FYI, ""RFC 1002 positive session response\n"");		break;	case RFC1002_NEGATIVE_SESSION_RESPONSE:		 		cifs_dbg(FYI, ""RFC 1002 negative session response\n"");		 		msleep(1000);		 		cifs_set_port((struct sockaddr *)&server->dstaddr, CIFS_PORT);		cifs_reconnect(server);		wake_up(&server->response_q);		break;	default:		cifs_dbg(VFS, ""RFC 1002 unknown response type 0x%x\n"", type);		cifs_reconnect(server);	}	return false;}",7922
387,802,CVE-2011-4131,20,"static void nfs4_xdr_enc_getdevicelist(struct rpc_rqst *req,				       struct xdr_stream *xdr,				       struct nfs4_getdevicelist_args *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_putfh(xdr, args->fh, &hdr);	encode_getdevicelist(xdr, args, &hdr);	encode_nops(&hdr);}",5143
293,157,CVE-2014-10375,20,"_tls_tl_check_connected (struct eXosip_t *excontext){  struct eXtltls *reserved = (struct eXtltls *) excontext->eXtltls_reserved;  int pos;  int res;  for (pos = 0; pos < EXOSIP_MAX_SOCKETS; pos++) {    if (reserved->socket_tab[pos].invalid > 0) {      OSIP_TRACE (osip_trace                  (__FILE__, __LINE__, OSIP_INFO2, NULL,                   ""_tls_tl_check_connected: socket node is in invalid state:%s:%i, socket %d [pos=%d], family:%d\n"",                   reserved->socket_tab[pos].remote_ip, reserved->socket_tab[pos].remote_port, reserved->socket_tab[pos].socket, pos, reserved->socket_tab[pos].ai_addr.sa_family));      _tls_tl_close_sockinfo (&reserved->socket_tab[pos]);      continue;    }    if (reserved->socket_tab[pos].socket > 0 && reserved->socket_tab[pos].ai_addrlen > 0) {      if (reserved->socket_tab[pos].ssl_state > 0) {                 reserved->socket_tab[pos].ai_addrlen = 0;        continue;      }      res = _tls_tl_is_connected (reserved->socket_tab[pos].socket);      if (res > 0) {        res = connect (reserved->socket_tab[pos].socket, &reserved->socket_tab[pos].ai_addr, reserved->socket_tab[pos].ai_addrlen);        OSIP_TRACE (osip_trace                    (__FILE__, __LINE__, OSIP_INFO2, NULL,                     ""_tls_tl_check_connected: socket node:%s:%i, socket %d [pos=%d], family:%d, in progress\n"",                     reserved->socket_tab[pos].remote_ip, reserved->socket_tab[pos].remote_port, reserved->socket_tab[pos].socket, pos, reserved->socket_tab[pos].ai_addr.sa_family));        continue;      }      else if (res == 0) {        OSIP_TRACE (osip_trace                    (__FILE__, __LINE__, OSIP_INFO1, NULL,                     ""_tls_tl_check_connected: socket node:%s:%i , socket %d [pos=%d], family:%d, connected\n"",                     reserved->socket_tab[pos].remote_ip, reserved->socket_tab[pos].remote_port, reserved->socket_tab[pos].socket, pos, reserved->socket_tab[pos].ai_addr.sa_family));                 reserved->socket_tab[pos].ai_addrlen = 0;        reserved->socket_tab[pos].ssl_state = 1;        continue;      }      else {        OSIP_TRACE (osip_trace                    (__FILE__, __LINE__, OSIP_INFO2, NULL,                     ""_tls_tl_check_connected: socket node:%s:%i, socket %d [pos=%d], family:%d, error\n"",                     reserved->socket_tab[pos].remote_ip, reserved->socket_tab[pos].remote_port, reserved->socket_tab[pos].socket, pos, reserved->socket_tab[pos].ai_addr.sa_family));        _tls_tl_close_sockinfo (&reserved->socket_tab[pos]);        continue;      }    }  }  return 0;}",2533
336,1428,CVE-2014-2669,20,"hstore_le(PG_FUNCTION_ARGS){	int			res = DatumGetInt32(DirectFunctionCall2(hstore_cmp,														PG_GETARG_DATUM(0),														PG_GETARG_DATUM(1)));	PG_RETURN_BOOL(res <= 0);}",11806
183,923,CVE-2011-3209,20,unsigned int kmem_cache_size(struct kmem_cache *s){	return s->objsize;},5691
194,357,CVE-2012-2375,20,"static int nfs4_open_recover(struct nfs4_opendata *opendata, struct nfs4_state *state){	struct nfs4_state *newstate;	int ret;	 	clear_bit(NFS_DELEGATED_STATE, &state->flags);	smp_rmb();	if (state->n_rdwr != 0) {		clear_bit(NFS_O_RDWR_STATE, &state->flags);		ret = nfs4_open_recover_helper(opendata, FMODE_READ|FMODE_WRITE, &newstate);		if (ret != 0)			return ret;		if (newstate != state)			return -ESTALE;	}	if (state->n_wronly != 0) {		clear_bit(NFS_O_WRONLY_STATE, &state->flags);		ret = nfs4_open_recover_helper(opendata, FMODE_WRITE, &newstate);		if (ret != 0)			return ret;		if (newstate != state)			return -ESTALE;	}	if (state->n_rdonly != 0) {		clear_bit(NFS_O_RDONLY_STATE, &state->flags);		ret = nfs4_open_recover_helper(opendata, FMODE_READ, &newstate);		if (ret != 0)			return ret;		if (newstate != state)			return -ESTALE;	}	 	if (test_bit(NFS_DELEGATED_STATE, &state->flags) == 0 &&	    !nfs4_stateid_match(&state->stateid, &state->open_stateid)) {		write_seqlock(&state->seqlock);		if (test_bit(NFS_DELEGATED_STATE, &state->flags) == 0)			nfs4_stateid_copy(&state->stateid, &state->open_stateid);		write_sequnlock(&state->seqlock);	}	return 0;}",3334
169,429,CVE-2012-2375,20,"static int nfs4_write_done(struct rpc_task *task, struct nfs_write_data *data){	if (!nfs4_sequence_done(task, &data->res.seq_res))		return -EAGAIN;	return data->write_done_cb ? data->write_done_cb(task, data) :		nfs4_write_done_cb(task, data);}",3406
79,419,CVE-2012-2375,20,static inline int nfs4_server_supports_acls(struct nfs_server *server){	return (server->caps & NFS_CAP_ACLS)		&& (server->acl_bitmask & ACL4_SUPPORT_ALLOW_ACL)		&& (server->acl_bitmask & ACL4_SUPPORT_DENY_ACL);},3396
203,1134,CVE-2013-7010,20,"static inline void put_tpel_pixels_mc20_c(int *dst, const int *src, int stride, int width, int height){    int i,j;    for (i=0; i < height; i++) {      for (j=0; j < width; j++) {        dst[j] = (683*(src[j] + 2*src[j+1] + 1)) >> 11;      }      src += stride;      dst += stride;    }}",7123
313,1572,CVE-2019-14763,20,"static void dwc3_gadget_suspend_interrupt(struct dwc3 *dwc,					  unsigned int evtinfo){	enum dwc3_link_state next = evtinfo & DWC3_LINK_STATE_MASK;	if (dwc->link_state != next && next == DWC3_LINK_STATE_U3)		dwc3_suspend_gadget(dwc);	dwc->link_state = next;}",26681
90,1533,CVE-2016-2070,20,"static int tcp_try_undo_partial(struct sock *sk, const int acked,				 const int prior_unsacked, int flag){	struct tcp_sock *tp = tcp_sk(sk);	if (tp->undo_marker && tcp_packet_delayed(tp)) {		 		tcp_update_reordering(sk, tcp_fackets_out(tp) + acked, 1);		 		if (tp->retrans_out) {			tcp_cwnd_reduction(sk, prior_unsacked, 0, flag);			return true;		}		if (!tcp_any_retrans_done(sk))			tp->retrans_stamp = 0;		DBGUNDO(sk, ""partial recovery"");		tcp_undo_cwnd_reduction(sk, true);		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPPARTIALUNDO);		tcp_try_keep_open(sk);		return true;	}	return false;}",18016
208,570,CVE-2011-4131,20,"static int _nfs4_recover_proc_open(struct nfs4_opendata *data){	struct inode *dir = data->dir->d_inode;	struct nfs_openres *o_res = &data->o_res;        int status;	status = nfs4_run_open_task(data, 1);	if (status != 0 || !data->rpc_done)		return status;	nfs_refresh_inode(dir, o_res->dir_attr);	if (o_res->rflags & NFS4_OPEN_RESULT_CONFIRM) {		status = _nfs4_proc_open_confirm(data);		if (status != 0)			return status;	}	return status;}",4911
72,1255,CVE-2013-4247,20,"cifs_put_smb_ses(struct cifs_ses *ses){	unsigned int xid;	struct TCP_Server_Info *server = ses->server;	cifs_dbg(FYI, ""%s: ses_count=%d\n"", __func__, ses->ses_count);	spin_lock(&cifs_tcp_ses_lock);	if (--ses->ses_count > 0) {		spin_unlock(&cifs_tcp_ses_lock);		return;	}	list_del_init(&ses->smb_ses_list);	spin_unlock(&cifs_tcp_ses_lock);	if (ses->status == CifsGood && server->ops->logoff) {		xid = get_xid();		server->ops->logoff(xid, ses);		_free_xid(xid);	}	sesInfoFree(ses);	cifs_put_tcp_session(server);}",7907
47,1224,CVE-2013-4483,20,"static void wake_up_sem_queue_prepare(struct list_head *pt,				struct sem_queue *q, int error){	if (list_empty(pt)) {		 		preempt_disable();	}	q->status = IN_WAKEUP;	q->pid = error;	list_add_tail(&q->list, pt);}",7784
249,1289,CVE-2013-2596,20,"static void fb_seq_stop(struct seq_file *m, void *v){	mutex_unlock(&registration_lock);}",8557
30,948,CVE-2011-3209,20,"static inline unsigned long slabs_node(struct kmem_cache *s, int node){	struct kmem_cache_node *n = get_node(s, node);	return atomic_long_read(&n->nr_slabs);}",5716
125,1236,CVE-2013-4483,20,"void ipc_rmid(struct ipc_ids *ids, struct kern_ipc_perm *ipcp){	int lid = ipcid_to_idx(ipcp->id);	idr_remove(&ids->ipcs_idr, lid);	ids->in_use--;	ipcp->deleted = 1;	return;}",7796
370,1112,CVE-2013-7010,20,"static void fill_block16_c(int *block, int value, int line_size, int h){    int i;    for (i = 0; i < h; i++) {        memset(block, value, 16);        block += line_size;    }}",7101
324,625,CVE-2011-4131,20,"static int decode_ace(struct xdr_stream *xdr, void *ace, struct nfs_client *clp){	__be32 *p;	unsigned int strlen;	char *str;	p = xdr_inline_decode(xdr, 12);	if (likely(p))		return decode_opaque_inline(xdr, &strlen, &str);	print_overflow_msg(__func__, xdr);	return -EIO;}",4966
138,12,CVE-2009-3605,20,  int getWidth() { return w; },265
28,1668,CVE-2012-2807,20,__xmlDoValidityCheckingDefaultValue(void) {    if (IS_MAIN_THREAD)	return (&xmlDoValidityCheckingDefaultValue);    else	return (&xmlGetGlobalState()->xmlDoValidityCheckingDefaultValue);},29254
300,334,CVE-2012-2375,20,"static void nfs4_layoutcommit_prepare(struct rpc_task *task, void *calldata){	struct nfs4_layoutcommit_data *data = calldata;	struct nfs_server *server = NFS_SERVER(data->args.inode);	if (nfs4_setup_sequence(server, &data->args.seq_args,				&data->res.seq_res, task))		return;	rpc_call_start(task);}",3311
241,1168,CVE-2013-6376,20,"static inline int apic_lvt_vector(struct kvm_lapic *apic, int lvt_type){	return kvm_apic_get_reg(apic, lvt_type) & APIC_VECTOR_MASK;}",7369
157,1514,CVE-2014-9683,20,"int virt_to_scatterlist(const void *addr, int size, struct scatterlist *sg,			int sg_size){	int i = 0;	struct page *pg;	int offset;	int remainder_of_page;	sg_init_table(sg, sg_size);	while (size > 0 && i < sg_size) {		pg = virt_to_page(addr);		offset = offset_in_page(addr);		sg_set_page(&sg[i], pg, 0, offset);		remainder_of_page = PAGE_CACHE_SIZE - offset;		if (size >= remainder_of_page) {			sg[i].length = remainder_of_page;			addr += remainder_of_page;			size -= remainder_of_page;		} else {			sg[i].length = size;			addr += size;			size = 0;		}		i++;	}	if (size > 0)		return -ENOMEM;	return i;}",14168
410,148,CVE-2015-5479,20,"const int *ff_h263_find_resync_marker(const int *restrict p, const int * restrict end){    assert(p < end);    end-=2;    p++;    for(;p<end; p+=2){        if(!*p){            if     (!p[-1] && p[1]) return p - 1;            else if(!p[ 1] && p[2]) return p;        }    }    return end+2;}",2299
342,525,CVE-2012-0044,20,"struct drm_mode_object *drm_mode_object_find(struct drm_device *dev,		int id, int type){	struct drm_mode_object *obj = NULL;	mutex_lock(&dev->mode_config.idr_mutex);	obj = idr_find(&dev->mode_config.crtc_idr, id);	if (!obj || (obj->type != type) || (obj->id != id))		obj = NULL;	mutex_unlock(&dev->mode_config.idr_mutex);	return obj;}",4298
39,1227,CVE-2013-4483,20,"void ipc_free(void* ptr, int size){	if(size > PAGE_SIZE)		vfree(ptr);	else		kfree(ptr);}",7787
307,448,CVE-2012-2100,20,"void ext4_clear_inode(struct inode *inode){	invalidate_inode_buffers(inode);	end_writeback(inode);	dquot_drop(inode);	ext4_discard_preallocations(inode);	if (EXT4_I(inode)->jinode) {		jbd2_journal_release_jbd_inode(EXT4_JOURNAL(inode),					       EXT4_I(inode)->jinode);		jbd2_free_inode(EXT4_I(inode)->jinode);		EXT4_I(inode)->jinode = NULL;	}}",3603
321,392,CVE-2012-2375,20,"nfs4_proc_setattr(struct dentry *dentry, struct nfs_fattr *fattr,		  struct iattr *sattr){	struct inode *inode = dentry->d_inode;	struct rpc_cred *cred = NULL;	struct nfs4_state *state = NULL;	int status;	if (pnfs_ld_layoutret_on_setattr(inode))		pnfs_return_layout(inode);	nfs_fattr_init(fattr);		 	if (sattr->ia_valid & ATTR_FILE) {		struct nfs_open_context *ctx;		ctx = nfs_file_open_context(sattr->ia_file);		if (ctx) {			cred = ctx->cred;			state = ctx->state;		}	}	 	if (sattr->ia_valid & ATTR_OPEN)		sattr->ia_valid &= ~(ATTR_MTIME|ATTR_CTIME|ATTR_OPEN);	status = nfs4_do_setattr(inode, cred, fattr, sattr, state);	if (status == 0)		nfs_setattr_update_inode(inode, sattr);	return status;}",3369
430,1469,CVE-2015-4001,20,"static void oz_acquire_port(struct oz_port *port, void *hpd){	INIT_LIST_HEAD(&port->isoc_out_ep);	INIT_LIST_HEAD(&port->isoc_in_ep);	port->flags |= OZ_PORT_F_PRESENT | OZ_PORT_F_CHANGED;	port->status |= USB_PORT_STAT_CONNECTION |			(USB_PORT_STAT_C_CONNECTION << 16);	oz_usb_get(hpd);	port->hpd = hpd;}",13545
433,830,CVE-2011-4131,20,"static void nfs4_xdr_enc_setclientid(struct rpc_rqst *req,				     struct xdr_stream *xdr,				     struct nfs4_setclientid *sc){	struct compound_hdr hdr = {		.nops	= 0,	};	encode_compound_hdr(xdr, req, &hdr);	encode_setclientid(xdr, sc, &hdr);	encode_nops(&hdr);}",5171
73,1345,CVE-2013-2094,20,static inline int perf_tryget_cgroup(struct perf_event *event){	return css_tryget(&event->cgrp->css);},8933
264,695,CVE-2011-4131,20,"static void encode_create(struct xdr_stream *xdr, const struct nfs4_create_arg *create, struct compound_hdr *hdr){	__be32 *p;	p = reserve_space(xdr, 8);	*p++ = cpu_to_be32(OP_CREATE);	*p = cpu_to_be32(create->ftype);	switch (create->ftype) {	case NF4LNK:		p = reserve_space(xdr, 4);		*p = cpu_to_be32(create->u.symlink.len);		xdr_write_pages(xdr, create->u.symlink.pages, 0, create->u.symlink.len);		break;	case NF4BLK: case NF4CHR:		p = reserve_space(xdr, 8);		*p++ = cpu_to_be32(create->u.device.specdata1);		*p = cpu_to_be32(create->u.device.specdata2);		break;	default:		break;	}	encode_string(xdr, create->name->len, create->name->name);	hdr->nops++;	hdr->replen += decode_create_maxsz;	encode_attrs(xdr, create->attrs, create->server);}",5036
130,1081,CVE-2011-1476,20,static void seq_panic(void){	 	seq_reset();	 	 },6898
136,257,CVE-2012-2375,20,"static int _nfs4_lookup_root(struct nfs_server *server, struct nfs_fh *fhandle,		struct nfs_fsinfo *info){	struct nfs4_lookup_root_arg args = {		.bitmask = nfs4_fattr_bitmap,	};	struct nfs4_lookup_res res = {		.server = server,		.fattr = info->fattr,		.fh = fhandle,	};	struct rpc_message msg = {		.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_LOOKUP_ROOT],		.rpc_argp = &args,		.rpc_resp = &res,	};	nfs_fattr_init(info->fattr);	return nfs4_call_sync(server->client, server, &msg, &args.seq_args, &res.seq_res, 0);}",3234
247,996,CVE-2011-2906,20,"pmcraid_init_ioadls(struct pmcraid_cmd *cmd, int sgcount){	struct pmcraid_ioadl_desc *ioadl;	struct pmcraid_ioarcb *ioarcb = &cmd->ioa_cb->ioarcb;	int ioadl_count = 0;	if (ioarcb->add_cmd_param_length)		ioadl_count = DIV_ROUND_UP(ioarcb->add_cmd_param_length, 16);	ioarcb->ioadl_length =		sizeof(struct pmcraid_ioadl_desc) * sgcount;	if ((sgcount + ioadl_count) > (ARRAY_SIZE(ioarcb->add_data.u.ioadl))) {		 		ioarcb->ioarcb_bus_addr &= ~(0x1FULL);		ioarcb->ioadl_bus_addr =			cpu_to_le64((cmd->ioa_cb_bus_addr) +				offsetof(struct pmcraid_ioarcb,					add_data.u.ioadl[3]));		ioadl = &ioarcb->add_data.u.ioadl[3];	} else {		ioarcb->ioadl_bus_addr =			cpu_to_le64((cmd->ioa_cb_bus_addr) +				offsetof(struct pmcraid_ioarcb,					add_data.u.ioadl[ioadl_count]));		ioadl = &ioarcb->add_data.u.ioadl[ioadl_count];		ioarcb->ioarcb_bus_addr |=				DIV_ROUND_CLOSEST(sgcount + ioadl_count, 8);	}	return ioadl;}",6447
262,913,CVE-2011-3209,20,"static inline void inc_slabs_node(struct kmem_cache *s, int node,							int objects) {}",5681
36,359,CVE-2012-2375,20,"static void nfs4_open_release(void *calldata){	struct nfs4_opendata *data = calldata;	struct nfs4_state *state = NULL;	 	if (data->cancelled == 0)		goto out_free;	 	if (data->rpc_status != 0 || !data->rpc_done)		goto out_free;	 	if (data->o_res.rflags & NFS4_OPEN_RESULT_CONFIRM)		goto out_free;	state = nfs4_opendata_to_nfs4_state(data);	if (!IS_ERR(state))		nfs4_close_state(state, data->o_arg.fmode);out_free:	nfs4_opendata_put(data);}",3336
27,1402,CVE-2014-3601,20,"int kvm_assign_device(struct kvm *kvm,		      struct kvm_assigned_dev_kernel *assigned_dev){	struct pci_dev *pdev = NULL;	struct iommu_domain *domain = kvm->arch.iommu_domain;	int r;	int noncoherent;	 	if (!domain)		return 0;	pdev = assigned_dev->dev;	if (pdev == NULL)		return -ENODEV;	r = iommu_attach_device(domain, &pdev->dev);	if (r) {		dev_err(&pdev->dev, ""kvm assign device failed ret %d"", r);		return r;	}	noncoherent = !iommu_domain_has_cap(kvm->arch.iommu_domain,					    IOMMU_CAP_CACHE_COHERENCY);	 	if (noncoherent != kvm->arch.iommu_noncoherent) {		kvm_iommu_unmap_memslots(kvm);		kvm->arch.iommu_noncoherent = noncoherent;		r = kvm_iommu_map_memslots(kvm);		if (r)			goto out_unmap;	}	pdev->dev_flags |= PCI_DEV_FLAGS_ASSIGNED;	dev_info(&pdev->dev, ""kvm assign device\n"");	return 0;out_unmap:	kvm_iommu_unmap_memslots(kvm);	return r;}",11425
32,393,CVE-2012-2375,20,"int nfs4_proc_setclientid_confirm(struct nfs_client *clp,		struct nfs4_setclientid_res *arg,		struct rpc_cred *cred){	struct nfs_fsinfo fsinfo;	struct rpc_message msg = {		.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_SETCLIENTID_CONFIRM],		.rpc_argp = arg,		.rpc_resp = &fsinfo,		.rpc_cred = cred,	};	unsigned long now;	int status;	now = jiffies;	status = rpc_call_sync(clp->cl_rpcclient, &msg, RPC_TASK_TIMEOUT);	if (status == 0) {		spin_lock(&clp->cl_lock);		clp->cl_lease_time = fsinfo.lease_time * HZ;		clp->cl_last_renewal = now;		spin_unlock(&clp->cl_lock);	}	return status;}",3370
144,1187,CVE-2013-6376,20,"void kvm_apic_set_eoi_accelerated(struct kvm_vcpu *vcpu, int vector){	struct kvm_lapic *apic = vcpu->arch.apic;	trace_kvm_eoi(apic, vector);	kvm_ioapic_send_eoi(apic, vector);	kvm_make_request(KVM_REQ_EVENT, apic->vcpu);}",7388
260,1400,CVE-2014-4655,20,"static int snd_ctl_elem_write(struct snd_card *card, struct snd_ctl_file *file,			      struct snd_ctl_elem_value *control){	struct snd_kcontrol *kctl;	struct snd_kcontrol_volatile *vd;	unsigned int index_offset;	int result;	down_read(&card->controls_rwsem);	kctl = snd_ctl_find_id(card, &control->id);	if (kctl == NULL) {		result = -ENOENT;	} else {		index_offset = snd_ctl_get_ioff(kctl, &control->id);		vd = &kctl->vd[index_offset];		if (!(vd->access & SNDRV_CTL_ELEM_ACCESS_WRITE) ||		    kctl->put == NULL ||		    (file && vd->owner && vd->owner != file)) {			result = -EPERM;		} else {			snd_ctl_build_ioff(&control->id, kctl, index_offset);			result = kctl->put(kctl, control);		}		if (result > 0) {			up_read(&card->controls_rwsem);			snd_ctl_notify(card, SNDRV_CTL_EVENT_MASK_VALUE,				       &control->id);			return 0;		}	}	up_read(&card->controls_rwsem);	return result;}",10834
84,682,CVE-2011-4131,20,"decode_restorefh(struct xdr_stream *xdr){	return decode_op_hdr(xdr, OP_RESTOREFH); }",5023
10,1656,CVE-2019-7308,20,"static int pop_stack(struct bpf_verifier_env *env, int *prev_insn_idx,		     int *insn_idx){	struct bpf_verifier_state *cur = env->cur_state;	struct bpf_verifier_stack_elem *elem, *head = env->head;	int err;	if (env->head == NULL)		return -ENOENT;	if (cur) {		err = copy_verifier_state(cur, &head->st);		if (err)			return err;	}	if (insn_idx)		*insn_idx = head->insn_idx;	if (prev_insn_idx)		*prev_insn_idx = head->prev_insn_idx;	elem = head->next;	free_verifier_state(&head->st, false);	kfree(head);	env->head = elem;	env->stack_size--;	return 0; }",29013
113,891,CVE-2011-3209,20,"static unsigned long calculate_alignment(unsigned long flags,		unsigned long align, unsigned long size){	 	if (flags & SLAB_HWCACHE_ALIGN) {		unsigned long ralign = cache_line_size();		while (size <= ralign / 2)			ralign /= 2;		align = max(align, ralign);	}	if (align < ARCH_SLAB_MINALIGN)		align = ARCH_SLAB_MINALIGN;	return ALIGN(align, sizeof(void *));}",5659
352,245,CVE-2012-2384,20,"i915_gem_object_set_to_gpu_domain(struct drm_i915_gem_object *obj,				  struct intel_ring_buffer *ring,				  struct change_domains *cd){	int invalidate_domains = 0, flush_domains = 0;	 	if (obj->base.pending_write_domain == 0)		obj->base.pending_read_domains |= obj->base.read_domains;	 	if (obj->base.write_domain &&	    (((obj->base.write_domain != obj->base.pending_read_domains ||	       obj->ring != ring)) ||	     (obj->fenced_gpu_access && !obj->pending_fenced_gpu_access))) {		flush_domains |= obj->base.write_domain;		invalidate_domains |=			obj->base.pending_read_domains & ~obj->base.write_domain;	}	 	invalidate_domains |= obj->base.pending_read_domains & ~obj->base.read_domains;	if ((flush_domains | invalidate_domains) & I915_GEM_DOMAIN_CPU)		i915_gem_clflush_object(obj);	if (obj->base.pending_write_domain)		cd->flips |= atomic_read(&obj->pending_flip);	 	if (flush_domains == 0 && obj->base.pending_write_domain == 0)		obj->base.pending_write_domain = obj->base.write_domain;	cd->invalidate_domains |= invalidate_domains;	cd->flush_domains |= flush_domains;	if (flush_domains & I915_GEM_GPU_DOMAINS)		cd->flush_rings |= intel_ring_flag(obj->ring);	if (invalidate_domains & I915_GEM_GPU_DOMAINS)		cd->flush_rings |= intel_ring_flag(ring);}",3222
197,1486,CVE-2015-4001,20,"struct oz_port *oz_hcd_pd_arrived(void *hpd){	int i;	struct oz_port *hport;	struct oz_hcd *ozhcd;	struct oz_endpoint *ep;	ozhcd = oz_hcd_claim();	if (!ozhcd)		return NULL;	 	ep = oz_ep_alloc(0, GFP_ATOMIC);	if (!ep)		goto err_put;	spin_lock_bh(&ozhcd->hcd_lock);	if (ozhcd->conn_port >= 0)		goto err_unlock;	for (i = 0; i < OZ_NB_PORTS; i++) {		struct oz_port *port = &ozhcd->ports[i];		spin_lock(&port->port_lock);		if (!(port->flags & (OZ_PORT_F_PRESENT | OZ_PORT_F_CHANGED))) {			oz_acquire_port(port, hpd);			spin_unlock(&port->port_lock);			break;		}		spin_unlock(&port->port_lock);	}	if (i == OZ_NB_PORTS)		goto err_unlock;	ozhcd->conn_port = i;	hport = &ozhcd->ports[i];	hport->out_ep[0] = ep;	spin_unlock_bh(&ozhcd->hcd_lock);	if (ozhcd->flags & OZ_HDC_F_SUSPENDED)		usb_hcd_resume_root_hub(ozhcd->hcd);	usb_hcd_poll_rh_status(ozhcd->hcd);	oz_hcd_put(ozhcd);	return hport;err_unlock:	spin_unlock_bh(&ozhcd->hcd_lock);	oz_ep_free(NULL, ep);err_put:	oz_hcd_put(ozhcd);	return NULL;}",13562
422,575,CVE-2011-4131,20,"static int nfs41_open_expired(struct nfs4_state_owner *sp, struct nfs4_state *state){	int status;	struct nfs_server *server = NFS_SERVER(state->inode);	status = nfs41_test_stateid(server, state);	if (status == NFS_OK)		return 0;	nfs41_free_stateid(server, state);	return nfs4_open_expired(sp, state);}",4916
365,822,CVE-2011-4131,20,"static void nfs4_xdr_enc_rename(struct rpc_rqst *req, struct xdr_stream *xdr,				const struct nfs_renameargs *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_putfh(xdr, args->old_dir, &hdr);	encode_savefh(xdr, &hdr);	encode_putfh(xdr, args->new_dir, &hdr);	encode_rename(xdr, args->old_name, args->new_name, &hdr);	encode_getfattr(xdr, args->bitmask, &hdr);	encode_restorefh(xdr, &hdr);	encode_getfattr(xdr, args->bitmask, &hdr);	encode_nops(&hdr);}",5163
221,163,CVE-2012-3412,20,static inline void efx_channel_processed(struct efx_channel *channel){	 	channel->work_pending = false;	smp_wmb();	efx_nic_eventq_read_ack(channel);},3037
37,663,CVE-2011-4131,20,"static int decode_delegation(struct xdr_stream *xdr, struct nfs_openres *res){	__be32 *p;	int delegation_type;	int status;	p = xdr_inline_decode(xdr, 4);	if (unlikely(!p))		goto out_overflow;	delegation_type = be32_to_cpup(p);	if (delegation_type == NFS4_OPEN_DELEGATE_NONE) {		res->delegation_type = 0;		return 0;	}	status = decode_stateid(xdr, &res->delegation);	if (unlikely(status))		return status;	p = xdr_inline_decode(xdr, 4);	if (unlikely(!p))		goto out_overflow;	res->do_recall = be32_to_cpup(p);	switch (delegation_type) {	case NFS4_OPEN_DELEGATE_READ:		res->delegation_type = FMODE_READ;		break;	case NFS4_OPEN_DELEGATE_WRITE:		res->delegation_type = FMODE_WRITE|FMODE_READ;		if (decode_space_limit(xdr, &res->maxsize) < 0)				return -EIO;	}	return decode_ace(xdr, NULL, res->server->nfs_client);out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",5004
416,204,CVE-2012-3412,20,"static void efx_stop_port(struct efx_nic *efx){	netif_dbg(efx, ifdown, efx->net_dev, ""stop port\n"");	mutex_lock(&efx->mac_lock);	efx->port_enabled = false;	mutex_unlock(&efx->mac_lock);	 	if (efx_dev_registered(efx)) {		netif_addr_lock_bh(efx->net_dev);		netif_addr_unlock_bh(efx->net_dev);	}}",3078
289,1265,CVE-2013-4247,20,"expand_dfs_referral(const unsigned int xid, struct cifs_ses *ses,		    struct smb_vol *volume_info, struct cifs_sb_info *cifs_sb,		    int check_prefix){	int rc;	unsigned int num_referrals = 0;	struct dfs_info3_param *referrals = NULL;	char *full_path = NULL, *ref_path = NULL, *mdata = NULL;	full_path = build_unc_path_to_root(volume_info, cifs_sb);	if (IS_ERR(full_path))		return PTR_ERR(full_path);	 	ref_path = check_prefix ? full_path + 1 : volume_info->UNC + 1;	rc = get_dfs_path(xid, ses, ref_path, cifs_sb->local_nls,			  &num_referrals, &referrals,			  cifs_sb->mnt_cifs_flags & CIFS_MOUNT_MAP_SPECIAL_CHR);	if (!rc && num_referrals > 0) {		char *fake_devname = NULL;		mdata = cifs_compose_mount_options(cifs_sb->mountdata,						   full_path + 1, referrals,						   &fake_devname);		free_dfs_info_array(referrals, num_referrals);		if (IS_ERR(mdata)) {			rc = PTR_ERR(mdata);			mdata = NULL;		} else {			cleanup_volume_info_contents(volume_info);			rc = cifs_setup_volume_info(volume_info, mdata,							fake_devname);		}		kfree(fake_devname);		kfree(cifs_sb->mountdata);		cifs_sb->mountdata = mdata;	}	kfree(full_path);	return rc;}",7917
298,1362,CVE-2013-0211,20,"archive_write_new(void){	struct archive_write *a;	unsigned char *nulls;	a = (struct archive_write *)malloc(sizeof(*a));	if (a == NULL)		return (NULL);	memset(a, 0, sizeof(*a));	a->archive.magic = ARCHIVE_WRITE_MAGIC;	a->archive.state = ARCHIVE_STATE_NEW;	a->archive.vtable = archive_write_vtable();	 	a->bytes_per_block = 10240;	a->bytes_in_last_block = -1;	 	 	a->null_length = 1024;	nulls = (unsigned char *)malloc(a->null_length);	if (nulls == NULL) {		free(a);		return (NULL);	}	memset(nulls, 0, a->null_length);	a->nulls = nulls;	return (&a->archive);}",9826
202,521,CVE-2012-0044,20,"int drm_mode_getencoder(struct drm_device *dev, void *data,			struct drm_file *file_priv){	struct drm_mode_get_encoder *enc_resp = data;	struct drm_mode_object *obj;	struct drm_encoder *encoder;	int ret = 0;	if (!drm_core_check_feature(dev, DRIVER_MODESET))		return -EINVAL;	mutex_lock(&dev->mode_config.mutex);	obj = drm_mode_object_find(dev, enc_resp->encoder_id,				   DRM_MODE_OBJECT_ENCODER);	if (!obj) {		ret = -EINVAL;		goto out;	}	encoder = obj_to_encoder(obj);	if (encoder->crtc)		enc_resp->crtc_id = encoder->crtc->base.id;	else		enc_resp->crtc_id = 0;	enc_resp->encoder_type = encoder->encoder_type;	enc_resp->encoder_id = encoder->base.id;	enc_resp->possible_crtcs = encoder->possible_crtcs;	enc_resp->possible_clones = encoder->possible_clones;out:	mutex_unlock(&dev->mode_config.mutex);	return ret;}",4294
344,1476,CVE-2015-4001,20,"static void oz_free_urb_link(struct oz_urb_link *urbl){	if (!urbl)		return;	kmem_cache_free(oz_urb_link_cache, urbl);}",13552
145,1260,CVE-2013-4247,20,"void cifs_setup_cifs_sb(struct smb_vol *pvolume_info,			struct cifs_sb_info *cifs_sb){	INIT_DELAYED_WORK(&cifs_sb->prune_tlinks, cifs_prune_tlinks);	spin_lock_init(&cifs_sb->tlink_tree_lock);	cifs_sb->tlink_tree = RB_ROOT;	 	cifs_sb->rsize = pvolume_info->rsize;	cifs_sb->wsize = pvolume_info->wsize;	cifs_sb->mnt_uid = pvolume_info->linux_uid;	cifs_sb->mnt_gid = pvolume_info->linux_gid;	cifs_sb->mnt_file_mode = pvolume_info->file_mode;	cifs_sb->mnt_dir_mode = pvolume_info->dir_mode;	cifs_dbg(FYI, ""file mode: 0x%hx  dir mode: 0x%hx\n"",		 cifs_sb->mnt_file_mode, cifs_sb->mnt_dir_mode);	cifs_sb->actimeo = pvolume_info->actimeo;	cifs_sb->local_nls = pvolume_info->local_nls;	if (pvolume_info->noperm)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NO_PERM;	if (pvolume_info->setuids)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_SET_UID;	if (pvolume_info->server_ino)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_SERVER_INUM;	if (pvolume_info->remap)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_MAP_SPECIAL_CHR;	if (pvolume_info->no_xattr)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NO_XATTR;	if (pvolume_info->sfu_emul)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_UNX_EMUL;	if (pvolume_info->nobrl)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NO_BRL;	if (pvolume_info->nostrictsync)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NOSSYNC;	if (pvolume_info->mand_lock)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_NOPOSIXBRL;	if (pvolume_info->rwpidforward)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_RWPIDFORWARD;	if (pvolume_info->cifs_acl)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_CIFS_ACL;	if (pvolume_info->backupuid_specified) {		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_CIFS_BACKUPUID;		cifs_sb->mnt_backupuid = pvolume_info->backupuid;	}	if (pvolume_info->backupgid_specified) {		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_CIFS_BACKUPGID;		cifs_sb->mnt_backupgid = pvolume_info->backupgid;	}	if (pvolume_info->override_uid)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_OVERR_UID;	if (pvolume_info->override_gid)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_OVERR_GID;	if (pvolume_info->dynperm)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_DYNPERM;	if (pvolume_info->fsc)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_FSCACHE;	if (pvolume_info->multiuser)		cifs_sb->mnt_cifs_flags |= (CIFS_MOUNT_MULTIUSER |					    CIFS_MOUNT_NO_PERM);	if (pvolume_info->strict_io)		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_STRICT_IO;	if (pvolume_info->direct_io) {		cifs_dbg(FYI, ""mounting share using direct i/o\n"");		cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_DIRECT_IO;	}	if (pvolume_info->mfsymlinks) {		if (pvolume_info->sfu_emul) {			cifs_dbg(VFS, ""mount option mfsymlinks ignored if sfu mount option is used\n"");		} else {			cifs_sb->mnt_cifs_flags |= CIFS_MOUNT_MF_SYMLINKS;		}	}	if ((pvolume_info->cifs_acl) && (pvolume_info->dynperm))		cifs_dbg(VFS, ""mount option dynperm ignored if cifsacl mount option supported\n"");}",7912
13,1031,CVE-2011-2906,20,static void pmcraid_shutdown(struct pci_dev *pdev){	struct pmcraid_instance *pinstance = pci_get_drvdata(pdev);	pmcraid_reset_bringdown(pinstance);},6482
334,295,CVE-2012-2375,20,"static void nfs41_sequence_prepare(struct rpc_task *task, void *data){	struct nfs4_sequence_data *calldata = data;	struct nfs_client *clp = calldata->clp;	struct nfs4_sequence_args *args;	struct nfs4_sequence_res *res;	args = task->tk_msg.rpc_argp;	res = task->tk_msg.rpc_resp;	if (nfs41_setup_sequence(clp->cl_session, args, res, task))		return;	rpc_call_start(task);}",3272
398,1639,CVE-2013-2596,20,"int copy_page_range(struct mm_struct *dst_mm, struct mm_struct *src_mm,		struct vm_area_struct *vma){	pgd_t *src_pgd, *dst_pgd;	unsigned long next;	unsigned long addr = vma->vm_start;	unsigned long end = vma->vm_end;	unsigned long mmun_start;	 	unsigned long mmun_end;		 	int is_cow;	int ret;	 	if (!(vma->vm_flags & (VM_HUGETLB | VM_NONLINEAR |			       VM_PFNMAP | VM_MIXEDMAP))) {		if (!vma->anon_vma)			return 0;	}	if (is_vm_hugetlb_page(vma))		return copy_hugetlb_page_range(dst_mm, src_mm, vma);	if (unlikely(vma->vm_flags & VM_PFNMAP)) {		 		ret = track_pfn_copy(vma);		if (ret)			return ret;	}	 	is_cow = is_cow_mapping(vma->vm_flags);	mmun_start = addr;	mmun_end   = end;	if (is_cow)		mmu_notifier_invalidate_range_start(src_mm, mmun_start,						    mmun_end);	ret = 0;	dst_pgd = pgd_offset(dst_mm, addr);	src_pgd = pgd_offset(src_mm, addr);	do {		next = pgd_addr_end(addr, end);		if (pgd_none_or_clear_bad(src_pgd))			continue;		if (unlikely(copy_pud_range(dst_mm, src_mm, dst_pgd, src_pgd,					    vma, addr, next))) {			ret = -ENOMEM;			break;		}	} while (dst_pgd++, src_pgd++, addr = next, addr != end);	if (is_cow)		mmu_notifier_invalidate_range_end(src_mm, mmun_start, mmun_end);	return ret;}",28299
26,1239,CVE-2013-4483,20,"static int ipcget_new(struct ipc_namespace *ns, struct ipc_ids *ids,		struct ipc_ops *ops, struct ipc_params *params){	int err;	down_write(&ids->rw_mutex);	err = ops->getnew(ns, params);	up_write(&ids->rw_mutex);	return err;}",7799
191,1717,CVE-2014-6269,20,"void http_end_txn_clean_session(struct session *s){	int prev_status = s->txn.status;	 	 	if (((s->txn.flags & TX_CON_WANT_MSK) != TX_CON_WANT_KAL) ||	    !si_conn_ready(s->req->cons)) {		s->req->cons->flags |= SI_FL_NOLINGER | SI_FL_NOHALF;		si_shutr(s->req->cons);		si_shutw(s->req->cons);	}	if (s->flags & SN_BE_ASSIGNED) {		s->be->beconn--;		if (unlikely(s->srv_conn))			sess_change_server(s, NULL);	}	s->logs.t_close = tv_ms_elapsed(&s->logs.tv_accept, &now);	session_process_counters(s);	if (s->txn.status) {		int n;		n = s->txn.status / 100;		if (n < 1 || n > 5)			n = 0;		if (s->fe->mode == PR_MODE_HTTP) {			s->fe->fe_counters.p.http.rsp[n]++;			if (s->comp_algo && (s->flags & SN_COMP_READY))				s->fe->fe_counters.p.http.comp_rsp++;		}		if ((s->flags & SN_BE_ASSIGNED) &&		    (s->be->mode == PR_MODE_HTTP)) {			s->be->be_counters.p.http.rsp[n]++;			s->be->be_counters.p.http.cum_req++;			if (s->comp_algo && (s->flags & SN_COMP_READY))				s->be->be_counters.p.http.comp_rsp++;		}	}	 	s->logs.bytes_in  -= s->req->buf->i;	s->logs.bytes_out -= s->rep->buf->i;	 	if (!LIST_ISEMPTY(&s->fe->logformat) && s->logs.logwait &&	    !(s->flags & SN_MONITOR) &&	    (!(s->fe->options & PR_O_NULLNOLOG) || s->req->total)) {		s->do_log(s);	}	 	session_stop_content_counters(s);	session_update_time_stats(s);	s->logs.accept_date = date;  	s->logs.tv_accept = now;   	tv_zero(&s->logs.tv_request);	s->logs.t_queue = -1;	s->logs.t_connect = -1;	s->logs.t_data = -1;	s->logs.t_close = 0;	s->logs.prx_queue_size = 0;   	s->logs.srv_queue_size = 0;  	s->logs.bytes_in = s->req->total = s->req->buf->i;	s->logs.bytes_out = s->rep->total = s->rep->buf->i;	if (s->pend_pos)		pendconn_free(s->pend_pos);	if (objt_server(s->target)) {		if (s->flags & SN_CURR_SESS) {			s->flags &= ~SN_CURR_SESS;			objt_server(s->target)->cur_sess--;		}		if (may_dequeue_tasks(objt_server(s->target), s->be))			process_srv_queue(objt_server(s->target));	}	s->target = NULL;	 	if (((s->txn.flags & TX_CON_WANT_MSK) != TX_CON_WANT_KAL) ||	    !si_conn_ready(s->req->cons)) {		si_release_endpoint(s->req->cons);	}	s->req->cons->state     = s->req->cons->prev_state = SI_ST_INI;	s->req->cons->err_type  = SI_ET_NONE;        s->req->cons->conn_retries = 0;           s->req->cons->exp       = TICK_ETERNITY;        s->req->cons->flags    &= SI_FL_DONT_WAKE;         s->req->flags &= ~(CF_SHUTW|CF_SHUTW_NOW|CF_AUTO_CONNECT|CF_WRITE_ERROR|CF_STREAMER|CF_STREAMER_FAST|CF_NEVER_WAIT|CF_WAKE_CONNECT);       s->rep->flags &= ~(CF_SHUTR|CF_SHUTR_NOW|CF_READ_ATTACHED|CF_READ_ERROR|CF_READ_NOEXP|CF_STREAMER|CF_STREAMER_FAST|CF_WRITE_PARTIAL|CF_NEVER_WAIT);        s->flags &= ~(SN_DIRECT|SN_ASSIGNED|SN_ADDR_SET|SN_BE_ASSIGNED|SN_FORCE_PRST|SN_IGNORE_PRST);        s->flags &= ~(SN_CURR_SESS|SN_REDIRECTABLE|SN_SRV_REUSED); 	s->txn.meth = 0;	http_reset_txn(s);	s->txn.flags |= TX_NOT_FIRST | TX_WAIT_NEXT_RQ;	if (prev_status == 401 || prev_status == 407) {		 		s->txn.flags |= TX_PREFER_LAST;	}	if (s->fe->options2 & PR_O2_INDEPSTR)		s->req->cons->flags |= SI_FL_INDEP_STR;	if (s->fe->options2 & PR_O2_NODELAY) {		s->req->flags |= CF_NEVER_WAIT;		s->rep->flags |= CF_NEVER_WAIT;	}	 	if (s->req->buf->i) {		if (s->rep->buf->o &&		    !buffer_full(s->rep->buf, global.tune.maxrewrite) &&		    bi_end(s->rep->buf) <= s->rep->buf->data + s->rep->buf->size - global.tune.maxrewrite)			s->rep->flags |= CF_EXPECT_MORE;	}	 	channel_auto_read(s->req);	channel_auto_close(s->req);	channel_auto_read(s->rep);	channel_auto_close(s->rep);	 	si_idle_conn(s->req->cons);	s->req->analysers = s->listener->analysers;	s->rep->analysers = 0;}",30903
348,191,CVE-2012-3412,20,int efx_reconfigure_port(struct efx_nic *efx){	int rc;	EFX_ASSERT_RESET_SERIALISED(efx);	mutex_lock(&efx->mac_lock);	rc = __efx_reconfigure_port(efx);	mutex_unlock(&efx->mac_lock);	return rc;},3065
52,1425,CVE-2014-2669,20,"hstore_eq(PG_FUNCTION_ARGS){	int			res = DatumGetInt32(DirectFunctionCall2(hstore_cmp,														PG_GETARG_DATUM(0),														PG_GETARG_DATUM(1)));	PG_RETURN_BOOL(res == 0);}",11803
409,1316,CVE-2013-2094,20,"static inline void perf_cgroup_sched_out(struct task_struct *task,					 struct task_struct *next){	struct perf_cgroup *cgrp1;	struct perf_cgroup *cgrp2 = NULL;	 	cgrp1 = perf_cgroup_from_task(task);	 	if (next)		cgrp2 = perf_cgroup_from_task(next);	 	if (cgrp1 != cgrp2)		perf_cgroup_switch(task, PERF_CGROUP_SWOUT);}",8904
346,538,CVE-2012-0038,20,"xfs_acl_to_disk(struct xfs_acl *aclp, const struct posix_acl *acl){	const struct posix_acl_entry *acl_e;	struct xfs_acl_entry *ace;	int i;	aclp->acl_cnt = cpu_to_be32(acl->a_count);	for (i = 0; i < acl->a_count; i++) {		ace = &aclp->acl_entry[i];		acl_e = &acl->a_entries[i];		ace->ae_tag = cpu_to_be32(acl_e->e_tag);		ace->ae_id = cpu_to_be32(acl_e->e_id);		ace->ae_perm = cpu_to_be16(acl_e->e_perm);	}}",4311
274,1060,CVE-2011-1476,20,midi_synth_reset(int dev){	leave_sysex(dev);},6877
245,300,CVE-2012-2375,20,"int nfs4_call_sync(struct rpc_clnt *clnt,		   struct nfs_server *server,		   struct rpc_message *msg,		   struct nfs4_sequence_args *args,		   struct nfs4_sequence_res *res,		   int cache_reply){	return server->nfs_client->cl_mvops->call_sync(clnt, server, msg,						args, res, cache_reply);}",3277
314,27,CVE-2012-5667,20,"dfawarn (char const *mesg){  static enum { DW_NONE = 0, DW_POSIX, DW_GNU } mode;  if (mode == DW_NONE)    mode = (getenv (""POSIXLY_CORRECT"") ? DW_POSIX : DW_GNU);  if (mode == DW_GNU)    dfaerror (mesg);}",1029
316,656,CVE-2011-4131,20,"static int decode_attr_type(struct xdr_stream *xdr, int *bitmap, int *type){	__be32 *p;	int ret = 0;	*type = 0;	if (unlikely(bitmap[0] & (FATTR4_WORD0_TYPE - 1U)))		return -EIO;	if (likely(bitmap[0] & FATTR4_WORD0_TYPE)) {		p = xdr_inline_decode(xdr, 4);		if (unlikely(!p))			goto out_overflow;		*type = be32_to_cpup(p);		if (*type < NF4REG || *type > NF4NAMEDATTR) {			dprintk(""%s: bad type %d\n"", __func__, *type);			return -EIO;		}		bitmap[0] &= ~FATTR4_WORD0_TYPE;		ret = NFS_ATTR_FATTR_TYPE;	}	dprintk(""%s: type=0%o\n"", __func__, nfs_type2fmt[*type]);	return ret;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",4997
411,24,CVE-2015-2331,20,"_zip_readstr(unsigned char **buf, int len, int nulp, struct zip_error *error){    char *r, *o;    r = (char *)malloc(nulp ? len+1 : len);    if (!r) {	_zip_error_set(error, ZIP_ER_MEMORY, 0);	return NULL;    }        memcpy(r, *buf, len);    *buf += len;    if (nulp) {	 	r[len] = 0;	for (o=r; o<r+len; o++)	    if (*o == '\0')		*o = ' ';    }    return r;}",797
217,685,CVE-2011-4131,20,"static int decode_sessionid(struct xdr_stream *xdr, struct nfs4_sessionid *sid){	return decode_opaque_fixed(xdr, sid->data, NFS4_MAX_SESSIONID_LEN);}",5026
281,1666,CVE-2012-2807,20,__xmlDefaultSAXLocator(void) {    if (IS_MAIN_THREAD)	return (&xmlDefaultSAXLocator);    else	return (&xmlGetGlobalState()->xmlDefaultSAXLocator);},29252
133,705,CVE-2011-4131,20,"encode_layoutcommit(struct xdr_stream *xdr,		    struct inode *inode,		    const struct nfs4_layoutcommit_args *args,		    struct compound_hdr *hdr){	__be32 *p;	dprintk(""%s: lbw: %llu type: %d\n"", __func__, args->lastbytewritten,		NFS_SERVER(args->inode)->pnfs_curr_ld->id);	p = reserve_space(xdr, 44 + NFS4_STATEID_SIZE);	*p++ = cpu_to_be32(OP_LAYOUTCOMMIT);	 	p = xdr_encode_hyper(p, 0);  	p = xdr_encode_hyper(p, args->lastbytewritten + 1);	 	*p++ = cpu_to_be32(0);  	p = xdr_encode_opaque_fixed(p, args->stateid.data, NFS4_STATEID_SIZE);	*p++ = cpu_to_be32(1);  	p = xdr_encode_hyper(p, args->lastbytewritten);	*p++ = cpu_to_be32(0);  	*p++ = cpu_to_be32(NFS_SERVER(args->inode)->pnfs_curr_ld->id); 	if (NFS_SERVER(inode)->pnfs_curr_ld->encode_layoutcommit)		NFS_SERVER(inode)->pnfs_curr_ld->encode_layoutcommit(			NFS_I(inode)->layout, xdr, args);	else {		p = reserve_space(xdr, 4);		*p = cpu_to_be32(0);  	}	hdr->nops++;	hdr->replen += decode_layoutcommit_maxsz;	return 0;}",5046
83,1721,CVE-2014-3468,20,"asn1_get_octet_der (const unsigned char *der, int der_len, 		    int *ret_len, unsigned char *str, int str_size, 		    int *str_len) {  int len_len;    if (der_len <= 0)     return ASN1_GENERIC_ERROR;     *str_len = asn1_get_length_der (der, der_len, &len_len);  if (*str_len < 0)    return ASN1_DER_ERROR;  *ret_len = *str_len + len_len;  if (str_size >= *str_len)    memcpy (str, der + len_len, *str_len);  else    {      return ASN1_MEM_ERROR;    }  return ASN1_SUCCESS;}",30909
99,137,CVE-2016-2105,20,"int EVP_DecodeValid(unsigned char *buf, int len){    int i, num = 0, bad = 0;    if (len == 0)        return (-1);    while (conv_ascii2bin(*buf) == B64_WS) {        buf++;        len--;        if (len == 0)            return (-1);    }    for (i = len; i >= 4; i -= 4) {        if ((conv_ascii2bin(buf[0]) >= 0x40) ||            (conv_ascii2bin(buf[1]) >= 0x40) ||            (conv_ascii2bin(buf[2]) >= 0x40) ||            (conv_ascii2bin(buf[3]) >= 0x40))            return (-1);        buf += 4;        num += 1 + (buf[2] != '=') + (buf[3] != '=');    }    if ((i == 1) && (conv_ascii2bin(buf[0]) == B64_EOLN))        return (num);    if ((i == 2) && (conv_ascii2bin(buf[0]) == B64_EOLN) &&        (conv_ascii2bin(buf[0]) == B64_EOLN))        return (num);    return (1);}",2084
349,1076,CVE-2011-1476,20,"static void seq_chn_common_event(unsigned char *event_rec){	unsigned char dev = event_rec[1];	unsigned char cmd = event_rec[2];	unsigned char chn = event_rec[3];	unsigned char p1 = event_rec[4];	 	unsigned short w14 = *(short *) &event_rec[6];	if ((int) dev > max_synthdev || synth_devs[dev] == NULL)		return;	if (!(synth_open_mask & (1 << dev)))		return;	if (!synth_devs[dev])		return;	switch (cmd)	{		case MIDI_PGM_CHANGE:			if (seq_mode == SEQ_2)			{				synth_devs[dev]->chn_info[chn].pgm_num = p1;				if ((int) dev >= num_synths)					synth_devs[dev]->set_instr(dev, chn, p1);			}			else				synth_devs[dev]->set_instr(dev, chn, p1);			break;		case MIDI_CTL_CHANGE:			if (seq_mode == SEQ_2)			{				if (chn > 15 || p1 > 127)					break;				synth_devs[dev]->chn_info[chn].controllers[p1] = w14 & 0x7f;				if (p1 < 32)	 					synth_devs[dev]->chn_info[chn].controllers[p1 + 32] = 0;				if ((int) dev < num_synths)				{					int val = w14 & 0x7f;					int i, key;					if (p1 < 64)	 					{						val = ((synth_devs[dev]->							chn_info[chn].controllers[p1 & ~32] & 0x7f) << 7)							| (synth_devs[dev]->							chn_info[chn].controllers[p1 | 32] & 0x7f);						p1 &= ~32;					}					 					key = ((int) chn << 8);					for (i = 0; i < synth_devs[dev]->alloc.max_voice; i++)						if ((synth_devs[dev]->alloc.map[i] & 0xff00) == key)							synth_devs[dev]->controller(dev, i, p1, val);				}				else					synth_devs[dev]->controller(dev, chn, p1, w14);			}			else	 				synth_devs[dev]->controller(dev, chn, p1, w14);			break;		case MIDI_PITCH_BEND:			if (seq_mode == SEQ_2)			{				synth_devs[dev]->chn_info[chn].bender_value = w14;				if ((int) dev < num_synths)				{					 					int i, key;					key = (chn << 8);					for (i = 0; i < synth_devs[dev]->alloc.max_voice; i++)						if ((synth_devs[dev]->alloc.map[i] & 0xff00) == key)							synth_devs[dev]->bender(dev, i, w14);				}				else					synth_devs[dev]->bender(dev, chn, w14);			}			else	 				synth_devs[dev]->bender(dev, chn, w14);			break;		default:;	}}",6893
277,1232,CVE-2013-4483,20,static void ipc_memory_notifier(struct work_struct *work){	ipcns_notify(IPCNS_MEMCHANGED);},7792
255,902,CVE-2011-3209,20,"static inline void dec_slabs_node(struct kmem_cache *s, int node,							int objects) {}",5670
399,554,CVE-2011-4611,20,"int power_pmu_commit_txn(struct pmu *pmu){	struct cpu_hw_events *cpuhw;	long i, n;	if (!ppmu)		return -EAGAIN;	cpuhw = &__get_cpu_var(cpu_hw_events);	n = cpuhw->n_events;	if (check_excludes(cpuhw->event, cpuhw->flags, 0, n))		return -EAGAIN;	i = power_check_constraints(cpuhw, cpuhw->events, cpuhw->flags, n);	if (i < 0)		return -EAGAIN;	for (i = cpuhw->n_txn_start; i < n; ++i)		cpuhw->event[i]->hw.config = cpuhw->events[i];	cpuhw->group_flag &= ~PERF_EVENT_TXN;	perf_pmu_enable(pmu);	return 0;}",4631
168,1474,CVE-2015-4001,20,"static void oz_complete_urb(struct usb_hcd *hcd, struct urb *urb,		int status){	struct oz_hcd *ozhcd = oz_hcd_private(hcd);	unsigned long irq_state;	struct oz_urb_link *cancel_urbl;	spin_lock_irqsave(&g_tasklet_lock, irq_state);	usb_hcd_unlink_urb_from_ep(hcd, urb);	 	urb->hcpriv = NULL;	 	cancel_urbl = oz_uncancel_urb(ozhcd, urb);	 	spin_unlock(&g_tasklet_lock);	if (oz_forget_urb(urb)) {		oz_dbg(ON, ""ERROR Unknown URB %p\n"", urb);	} else {		atomic_dec(&g_pending_urbs);		usb_hcd_giveback_urb(hcd, urb, status);	}	spin_lock(&g_tasklet_lock);	spin_unlock_irqrestore(&g_tasklet_lock, irq_state);	oz_free_urb_link(cancel_urbl);}",13550
147,102,CVE-2014-6269,20,"smp_fetch_stcode(struct proxy *px, struct session *l4, void *l7, unsigned int opt,                 const struct arg *args, struct sample *smp, const char *kw){	struct http_txn *txn = l7;	char *ptr;	int len;	CHECK_HTTP_MESSAGE_FIRST();	if (txn->rsp.msg_state < HTTP_MSG_BODY)		return 0;	len = txn->rsp.sl.st.c_l;	ptr = txn->rsp.chn->buf->p + txn->rsp.sl.st.c;	smp->type = SMP_T_UINT;	smp->data.uint = __strl2ui(ptr, len);	smp->flags = SMP_F_VOL_1ST;	return 1;}",1766
212,643,CVE-2011-4131,20,"static int decode_attr_maxwrite(struct xdr_stream *xdr, int *bitmap, int *res){	__be32 *p;	int status = 0;	*res = 1024;	if (unlikely(bitmap[0] & (FATTR4_WORD0_MAXWRITE - 1U)))		return -EIO;	if (likely(bitmap[0] & FATTR4_WORD0_MAXWRITE)) {		int maxwrite;		p = xdr_inline_decode(xdr, 8);		if (unlikely(!p))			goto out_overflow;		xdr_decode_hyper(p, &maxwrite);		if (maxwrite > 0x7FFFFFFF)			maxwrite = 0x7FFFFFFF;		*res = (int)maxwrite;		bitmap[0] &= ~FATTR4_WORD0_MAXWRITE;	}	dprintk(""%s: maxwrite=%lu\n"", __func__, (unsigned long)*res);	return status;out_overflow:	print_overflow_msg(__func__, xdr);	return -EIO;}",4984
310,136,CVE-2016-2105,20,"int EVP_DecodeBlock(unsigned char *t, const unsigned char *f, int n){    int i, ret = 0, a, b, c, d;    unsigned long l;         while ((conv_ascii2bin(*f) == B64_WS) && (n > 0)) {        f++;        n--;    }         while ((n > 3) && (B64_NOT_BASE64(conv_ascii2bin(f[n - 1]))))        n--;    if (n % 4 != 0)        return (-1);    for (i = 0; i < n; i += 4) {        a = conv_ascii2bin(*(f++));        b = conv_ascii2bin(*(f++));        c = conv_ascii2bin(*(f++));        d = conv_ascii2bin(*(f++));        if ((a & 0x80) || (b & 0x80) || (c & 0x80) || (d & 0x80))            return (-1);        l = ((((unsigned long)a) << 18L) |             (((unsigned long)b) << 12L) |             (((unsigned long)c) << 6L) | (((unsigned long)d)));        *(t++) = (unsigned char)(l >> 16L) & 0xff;        *(t++) = (unsigned char)(l >> 8L) & 0xff;        *(t++) = (unsigned char)(l) & 0xff;        ret += 3;    }    return (ret);}",2083
107,1741,CVE-2014-4655,20,"static int snd_ctl_elem_add(struct snd_ctl_file *file,			    struct snd_ctl_elem_info *info, int replace){	struct snd_card *card = file->card;	struct snd_kcontrol kctl, *_kctl;	unsigned int access;	long private_size; 	struct user_element *ue; 	int idx, err; 	if (!replace && card->user_ctl_count >= MAX_USER_CONTROLS)		return -ENOMEM; 	if (info->count < 1) 		return -EINVAL; 	access = info->access == 0 ? SNDRV_CTL_ELEM_ACCESS_READWRITE :		(info->access & (SNDRV_CTL_ELEM_ACCESS_READWRITE|				 SNDRV_CTL_ELEM_ACCESS_INACTIVE| 				 SNDRV_CTL_ELEM_ACCESS_TLV_READWRITE)); 	info->id.numid = 0; 	memset(&kctl, 0, sizeof(kctl));	down_write(&card->controls_rwsem);	_kctl = snd_ctl_find_id(card, &info->id);	err = 0;	if (_kctl) {		if (replace)			err = snd_ctl_remove(card, _kctl);		else			err = -EBUSY;	} else {		if (replace)			err = -ENOENT; 	}	up_write(&card->controls_rwsem);	if (err < 0)		return err; 	memcpy(&kctl.id, &info->id, sizeof(info->id)); 	kctl.count = info->owner ? info->owner : 1; 	access |= SNDRV_CTL_ELEM_ACCESS_USER;	if (info->type == SNDRV_CTL_ELEM_TYPE_ENUMERATED)		kctl.info = snd_ctl_elem_user_enum_info;	else		kctl.info = snd_ctl_elem_user_info;	if (access & SNDRV_CTL_ELEM_ACCESS_READ)		kctl.get = snd_ctl_elem_user_get;	if (access & SNDRV_CTL_ELEM_ACCESS_WRITE)		kctl.put = snd_ctl_elem_user_put;	if (access & SNDRV_CTL_ELEM_ACCESS_TLV_READWRITE) {		kctl.tlv.c = snd_ctl_elem_user_tlv;		access |= SNDRV_CTL_ELEM_ACCESS_TLV_CALLBACK;	}	switch (info->type) {	case SNDRV_CTL_ELEM_TYPE_BOOLEAN:	case SNDRV_CTL_ELEM_TYPE_INTEGER:		private_size = sizeof(long);		if (info->count > 128)			return -EINVAL;		break;	case SNDRV_CTL_ELEM_TYPE_INTEGER64:		private_size = sizeof(long long);		if (info->count > 64)			return -EINVAL;		break;	case SNDRV_CTL_ELEM_TYPE_ENUMERATED:		private_size = sizeof(unsigned int);		if (info->count > 128 || info->value.enumerated.items == 0)			return -EINVAL;		break;	case SNDRV_CTL_ELEM_TYPE_BYTES:		private_size = sizeof(unsigned char);		if (info->count > 512)			return -EINVAL;		break;	case SNDRV_CTL_ELEM_TYPE_IEC958:		private_size = sizeof(struct snd_aes_iec958);		if (info->count != 1)			return -EINVAL;		break;	default:		return -EINVAL;	}	private_size *= info->count;	ue = kzalloc(sizeof(struct user_element) + private_size, GFP_KERNEL);	if (ue == NULL)		return -ENOMEM;	ue->card = card;	ue->info = *info;	ue->info.access = 0;	ue->elem_data = (char *)ue + sizeof(*ue);	ue->elem_data_size = private_size;	if (ue->info.type == SNDRV_CTL_ELEM_TYPE_ENUMERATED) {		err = snd_ctl_elem_init_enum_names(ue);		if (err < 0) {			kfree(ue);			return err;		}	}	kctl.private_free = snd_ctl_elem_user_free;	_kctl = snd_ctl_new(&kctl, access);	if (_kctl == NULL) {		kfree(ue->priv_data);		kfree(ue);		return -ENOMEM;	}	_kctl->private_data = ue;	for (idx = 0; idx < _kctl->count; idx++)		_kctl->vd[idx].owner = file;	err = snd_ctl_add(card, _kctl);	if (err < 0)		return err;	down_write(&card->controls_rwsem);	card->user_ctl_count++;	up_write(&card->controls_rwsem);	return 0;}",31138
151,1038,CVE-2011-2521,20,"backtrace_warning_symbol(void *data, char *msg, unsigned long symbol){	 }",6538
419,488,CVE-2012-0044,20,"int drm_connector_property_set_value(struct drm_connector *connector,				  struct drm_property *property, int value){	int i;	for (i = 0; i < DRM_CONNECTOR_MAX_PROPERTY; i++) {		if (connector->property_ids[i] == property->base.id) {			connector->property_values[i] = value;			break;		}	}	if (i == DRM_CONNECTOR_MAX_PROPERTY)		return -EINVAL;	return 0;}",4261
88,928,CVE-2011-3209,20,static inline int oo_objects(struct kmem_cache_order_objects x){	return x.x & ((1 << 16) - 1);},5696
100,550,CVE-2011-4611,20,static inline void perf_read_regs(struct pt_regs *regs) { },4627
382,155,CVE-2014-10375,20,eXosip_reset_transports (struct eXosip_t *excontext){  int i = OSIP_WRONG_STATE;  if (excontext->eXtl_transport.tl_reset)    i = excontext->eXtl_transport.tl_reset (excontext);  return i;},2531
45,475,CVE-2012-2100,20,"static void ext4_write_super(struct super_block *sb){	lock_super(sb);	ext4_commit_super(sb, 1);	unlock_super(sb);}",3630
77,372,CVE-2012-2375,20,"static int nfs4_proc_getlk(struct nfs4_state *state, int cmd, struct file_lock *request){	struct nfs4_exception exception = { };	int err;	do {		err = nfs4_handle_exception(NFS_SERVER(state->inode),				_nfs4_proc_getlk(state, cmd, request),				&exception);	} while (exception.retry);	return err;}",3349
425,156,CVE-2014-10375,20,"_tcp_tl_check_connected (struct eXosip_t *excontext){  struct eXtltcp *reserved = (struct eXtltcp *) excontext->eXtltcp_reserved;  int pos;  int res;  for (pos = 0; pos < EXOSIP_MAX_SOCKETS; pos++) {    if (reserved->socket_tab[pos].invalid > 0) {      OSIP_TRACE (osip_trace                  (__FILE__, __LINE__, OSIP_INFO2, NULL,                   ""_tcp_tl_check_connected: socket node is in invalid state:%s:%i, socket %d [pos=%d], family:%d\n"",                   reserved->socket_tab[pos].remote_ip, reserved->socket_tab[pos].remote_port, reserved->socket_tab[pos].socket, pos, reserved->socket_tab[pos].ai_addr.sa_family));      _tcp_tl_close_sockinfo (&reserved->socket_tab[pos]);      continue;    }    if (reserved->socket_tab[pos].socket > 0 && reserved->socket_tab[pos].ai_addrlen > 0) {      res = _tcp_tl_is_connected (reserved->socket_tab[pos].socket);      if (res > 0) {        res = connect (reserved->socket_tab[pos].socket, &reserved->socket_tab[pos].ai_addr, reserved->socket_tab[pos].ai_addrlen);        OSIP_TRACE (osip_trace                    (__FILE__, __LINE__, OSIP_INFO2, NULL,                     ""_tcp_tl_check_connected: socket node:%s:%i, socket %d [pos=%d], family:%d, in progress\n"",                     reserved->socket_tab[pos].remote_ip, reserved->socket_tab[pos].remote_port, reserved->socket_tab[pos].socket, pos, reserved->socket_tab[pos].ai_addr.sa_family));        continue;      }      else if (res == 0) {        OSIP_TRACE (osip_trace                    (__FILE__, __LINE__, OSIP_INFO1, NULL,                     ""_tcp_tl_check_connected: socket node:%s:%i , socket %d [pos=%d], family:%d, connected\n"",                     reserved->socket_tab[pos].remote_ip, reserved->socket_tab[pos].remote_port, reserved->socket_tab[pos].socket, pos, reserved->socket_tab[pos].ai_addr.sa_family));                 reserved->socket_tab[pos].ai_addrlen = 0;        continue;      }      else {        OSIP_TRACE (osip_trace                    (__FILE__, __LINE__, OSIP_INFO2, NULL,                     ""_tcp_tl_check_connected: socket node:%s:%i, socket %d [pos=%d], family:%d, error\n"",                     reserved->socket_tab[pos].remote_ip, reserved->socket_tab[pos].remote_port, reserved->socket_tab[pos].socket, pos, reserved->socket_tab[pos].ai_addr.sa_family));        _tcp_tl_close_sockinfo (&reserved->socket_tab[pos]);        continue;      }    }  }  return 0;}",2532
9,1629,CVE-2019-7308,20,"static int reg_type_mismatch(enum bpf_reg_type src, enum bpf_reg_type prev){	return src != prev && (!reg_type_mismatch_ok(src) ||			       !reg_type_mismatch_ok(prev));}",27342
166,1261,CVE-2013-4247,20,"cifs_setup_session(const unsigned int xid, struct cifs_ses *ses,		   struct nls_table *nls_info){	int rc = -ENOSYS;	struct TCP_Server_Info *server = ses->server;	ses->flags = 0;	ses->capabilities = server->capabilities;	if (linuxExtEnabled == 0)		ses->capabilities &= (~server->vals->cap_unix);	cifs_dbg(FYI, ""Security Mode: 0x%x Capabilities: 0x%x TimeAdjust: %d\n"",		 server->sec_mode, server->capabilities, server->timeAdj);	if (server->ops->sess_setup)		rc = server->ops->sess_setup(xid, ses, nls_info);	if (rc) {		cifs_dbg(VFS, ""Send error in SessSetup = %d\n"", rc);	} else {		mutex_lock(&server->srv_mutex);		if (!server->session_estab) {			server->session_key.response = ses->auth_key.response;			server->session_key.len = ses->auth_key.len;			server->sequence_number = 0x2;			server->session_estab = true;			ses->auth_key.response = NULL;		}		mutex_unlock(&server->srv_mutex);		cifs_dbg(FYI, ""CIFS Session Established successfully\n"");		spin_lock(&GlobalMid_Lock);		ses->status = CifsGood;		ses->need_reconnect = false;		spin_unlock(&GlobalMid_Lock);	}	kfree(ses->auth_key.response);	ses->auth_key.response = NULL;	ses->auth_key.len = 0;	kfree(ses->ntlmssp);	ses->ntlmssp = NULL;	return rc;}",7913
339,428,CVE-2012-2375,20,static int nfs4_wait_for_completion_rpc_task(struct rpc_task *task){	int ret;	ret = rpc_wait_for_completion_task(task);	return ret;},3405
57,1742,CVE-2015-4167,20,"static int udf_read_inode(struct inode *inode, int hidden_inode){	struct buffer_head *bh = NULL;	struct fileEntry *fe;	struct extendedFileEntry *efe;	int ident;	struct udf_inode_info *iinfo = UDF_I(inode);	struct udf_sb_info *sbi = UDF_SB(inode->i_sb);	struct kernel_lb_addr *iloc = &iinfo->i_location;	unsigned int link_count;	unsigned int indirections = 0;	int bs = inode->i_sb->s_blocksize;	int ret = -EIO;reread:	if (iloc->logicalBlockNum >=	    sbi->s_partmaps[iloc->partitionReferenceNum].s_partition_len) {		udf_debug(""block=%d, partition=%d out of range\n"",			  iloc->logicalBlockNum, iloc->partitionReferenceNum);		return -EIO;	}	 	bh = udf_read_ptagged(inode->i_sb, iloc, 0, &ident);	if (!bh) {		udf_err(inode->i_sb, ""(ino %ld) failed !bh\n"", inode->i_ino);		return -EIO;	}	if (ident != TAG_IDENT_FE && ident != TAG_IDENT_EFE &&	    ident != TAG_IDENT_USE) {		udf_err(inode->i_sb, ""(ino %ld) failed ident=%d\n"",			inode->i_ino, ident);		goto out;	}	fe = (struct fileEntry *)bh->b_data;	efe = (struct extendedFileEntry *)bh->b_data;	if (fe->icbTag.strategyType == cpu_to_le16(4096)) {		struct buffer_head *ibh;		ibh = udf_read_ptagged(inode->i_sb, iloc, 1, &ident);		if (ident == TAG_IDENT_IE && ibh) {			struct kernel_lb_addr loc;			struct indirectEntry *ie;			ie = (struct indirectEntry *)ibh->b_data;			loc = lelb_to_cpu(ie->indirectICB.extLocation);			if (ie->indirectICB.extLength) {				brelse(ibh);				memcpy(&iinfo->i_location, &loc,				       sizeof(struct kernel_lb_addr));				if (++indirections > UDF_MAX_ICB_NESTING) {					udf_err(inode->i_sb,						""too many ICBs in ICB hierarchy""						"" (max %d supported)\n"",						UDF_MAX_ICB_NESTING);					goto out;				}				brelse(bh);				goto reread;			}		}		brelse(ibh);	} else if (fe->icbTag.strategyType != cpu_to_le16(4)) {		udf_err(inode->i_sb, ""unsupported strategy type: %d\n"",			le16_to_cpu(fe->icbTag.strategyType));		goto out;	}	if (fe->icbTag.strategyType == cpu_to_le16(4))		iinfo->i_strat4096 = 0;	else  		iinfo->i_strat4096 = 1;	iinfo->i_alloc_type = le16_to_cpu(fe->icbTag.flags) &							ICBTAG_FLAG_AD_MASK;	iinfo->i_unique = 0;	iinfo->i_lenEAttr = 0;	iinfo->i_lenExtents = 0;	iinfo->i_lenAlloc = 0;	iinfo->i_next_alloc_block = 0;	iinfo->i_next_alloc_goal = 0;	if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_EFE)) {		iinfo->i_efe = 1;		iinfo->i_use = 0;		ret = udf_alloc_i_data(inode, bs -					sizeof(struct extendedFileEntry));		if (ret)			goto out;		memcpy(iinfo->i_ext.i_data,		       bh->b_data + sizeof(struct extendedFileEntry),		       bs - sizeof(struct extendedFileEntry));	} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_FE)) {		iinfo->i_efe = 0;		iinfo->i_use = 0;		ret = udf_alloc_i_data(inode, bs - sizeof(struct fileEntry));		if (ret)			goto out;		memcpy(iinfo->i_ext.i_data,		       bh->b_data + sizeof(struct fileEntry),		       bs - sizeof(struct fileEntry));	} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_USE)) {		iinfo->i_efe = 0;		iinfo->i_use = 1;		iinfo->i_lenAlloc = le32_to_cpu(				((struct unallocSpaceEntry *)bh->b_data)->				 lengthAllocDescs);		ret = udf_alloc_i_data(inode, bs -					sizeof(struct unallocSpaceEntry));		if (ret)			goto out;		memcpy(iinfo->i_ext.i_data,		       bh->b_data + sizeof(struct unallocSpaceEntry),		       bs - sizeof(struct unallocSpaceEntry));		return 0;	}	ret = -EIO;	read_lock(&sbi->s_cred_lock);	i_uid_write(inode, le32_to_cpu(fe->uid));	if (!uid_valid(inode->i_uid) ||	    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_IGNORE) ||	    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_SET))		inode->i_uid = UDF_SB(inode->i_sb)->s_uid;	i_gid_write(inode, le32_to_cpu(fe->gid));	if (!gid_valid(inode->i_gid) ||	    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_IGNORE) ||	    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_SET))		inode->i_gid = UDF_SB(inode->i_sb)->s_gid;	if (fe->icbTag.fileType != ICBTAG_FILE_TYPE_DIRECTORY &&			sbi->s_fmode != UDF_INVALID_MODE)		inode->i_mode = sbi->s_fmode;	else if (fe->icbTag.fileType == ICBTAG_FILE_TYPE_DIRECTORY &&			sbi->s_dmode != UDF_INVALID_MODE)		inode->i_mode = sbi->s_dmode;	else		inode->i_mode = udf_convert_permissions(fe);	inode->i_mode &= ~sbi->s_umask;	read_unlock(&sbi->s_cred_lock);	link_count = le16_to_cpu(fe->fileLinkCount);	if (!link_count) {		if (!hidden_inode) {			ret = -ESTALE;			goto out;		}		link_count = 1;	}	set_nlink(inode, link_count);	inode->i_size = le64_to_cpu(fe->informationLength);	iinfo->i_lenExtents = inode->i_size;	if (iinfo->i_efe == 0) {		inode->i_blocks = le64_to_cpu(fe->logicalBlocksRecorded) <<			(inode->i_sb->s_blocksize_bits - 9);		if (!udf_disk_stamp_to_time(&inode->i_atime, fe->accessTime))			inode->i_atime = sbi->s_record_time;		if (!udf_disk_stamp_to_time(&inode->i_mtime,					    fe->modificationTime))			inode->i_mtime = sbi->s_record_time;		if (!udf_disk_stamp_to_time(&inode->i_ctime, fe->attrTime))			inode->i_ctime = sbi->s_record_time;		iinfo->i_unique = le64_to_cpu(fe->uniqueID);		iinfo->i_lenEAttr = le32_to_cpu(fe->lengthExtendedAttr);		iinfo->i_lenAlloc = le32_to_cpu(fe->lengthAllocDescs);		iinfo->i_checkpoint = le32_to_cpu(fe->checkpoint);	} else {		inode->i_blocks = le64_to_cpu(efe->logicalBlocksRecorded) <<		    (inode->i_sb->s_blocksize_bits - 9);		if (!udf_disk_stamp_to_time(&inode->i_atime, efe->accessTime))			inode->i_atime = sbi->s_record_time;		if (!udf_disk_stamp_to_time(&inode->i_mtime,					    efe->modificationTime))			inode->i_mtime = sbi->s_record_time;		if (!udf_disk_stamp_to_time(&iinfo->i_crtime, efe->createTime))			iinfo->i_crtime = sbi->s_record_time;		if (!udf_disk_stamp_to_time(&inode->i_ctime, efe->attrTime))			inode->i_ctime = sbi->s_record_time;		iinfo->i_unique = le64_to_cpu(efe->uniqueID);		iinfo->i_lenEAttr = le32_to_cpu(efe->lengthExtendedAttr);		iinfo->i_lenAlloc = le32_to_cpu(efe->lengthAllocDescs);		iinfo->i_checkpoint = le32_to_cpu(efe->checkpoint); 	} 	inode->i_generation = iinfo->i_unique;  	  	if (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) { 		 		if (iinfo->i_lenAlloc != inode->i_size)			goto out;		 		if (inode->i_size > bs - udf_file_entry_alloc_offset(inode))			goto out;	}	switch (fe->icbTag.fileType) {	case ICBTAG_FILE_TYPE_DIRECTORY:		inode->i_op = &udf_dir_inode_operations;		inode->i_fop = &udf_dir_operations;		inode->i_mode |= S_IFDIR;		inc_nlink(inode);		break;	case ICBTAG_FILE_TYPE_REALTIME:	case ICBTAG_FILE_TYPE_REGULAR:	case ICBTAG_FILE_TYPE_UNDEF:	case ICBTAG_FILE_TYPE_VAT20:		if (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)			inode->i_data.a_ops = &udf_adinicb_aops;		else			inode->i_data.a_ops = &udf_aops;		inode->i_op = &udf_file_inode_operations;		inode->i_fop = &udf_file_operations;		inode->i_mode |= S_IFREG;		break;	case ICBTAG_FILE_TYPE_BLOCK:		inode->i_mode |= S_IFBLK;		break;	case ICBTAG_FILE_TYPE_CHAR:		inode->i_mode |= S_IFCHR;		break;	case ICBTAG_FILE_TYPE_FIFO:		init_special_inode(inode, inode->i_mode | S_IFIFO, 0);		break;	case ICBTAG_FILE_TYPE_SOCKET:		init_special_inode(inode, inode->i_mode | S_IFSOCK, 0);		break;	case ICBTAG_FILE_TYPE_SYMLINK:		inode->i_data.a_ops = &udf_symlink_aops;		inode->i_op = &udf_symlink_inode_operations;		inode->i_mode = S_IFLNK | S_IRWXUGO;		break;	case ICBTAG_FILE_TYPE_MAIN:		udf_debug(""METADATA FILE-----\n"");		break;	case ICBTAG_FILE_TYPE_MIRROR:		udf_debug(""METADATA MIRROR FILE-----\n"");		break;	case ICBTAG_FILE_TYPE_BITMAP:		udf_debug(""METADATA BITMAP FILE-----\n"");		break;	default:		udf_err(inode->i_sb, ""(ino %ld) failed unknown file type=%d\n"",			inode->i_ino, fe->icbTag.fileType);		goto out;	}	if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {		struct deviceSpec *dsea =			(struct deviceSpec *)udf_get_extendedattr(inode, 12, 1);		if (dsea) {			init_special_inode(inode, inode->i_mode,				MKDEV(le32_to_cpu(dsea->majorDeviceIdent),				      le32_to_cpu(dsea->minorDeviceIdent)));			 		} else			goto out;	}	ret = 0;out:	brelse(bh);	return ret;}",31194
80,391,CVE-2012-2375,20,"static int nfs4_proc_sequence(struct nfs_client *clp, struct rpc_cred *cred){	struct rpc_task *task;	int ret;	task = _nfs41_proc_sequence(clp, cred);	if (IS_ERR(task)) {		ret = PTR_ERR(task);		goto out;	}	ret = rpc_wait_for_completion_task(task);	if (!ret) {		struct nfs4_sequence_res *res = task->tk_msg.rpc_resp;		if (task->tk_status == 0)			nfs41_handle_sequence_flag_errors(clp, res->sr_status_flags);		ret = task->tk_status;	}	rpc_put_task(task);out:	dprintk(""<-- %s status=%d\n"", __func__, ret);	return ret;}",3368
155,360,CVE-2012-2375,20,"static void nfs4_opendata_put(struct nfs4_opendata *p){	if (p != NULL)		kref_put(&p->kref, nfs4_opendata_free);}",3337
385,1307,CVE-2013-2094,20,static int cpu_clock_event_init(struct perf_event *event){	if (event->attr.type != PERF_TYPE_SOFTWARE)		return -ENOENT;	if (event->attr.config != PERF_COUNT_SW_CPU_CLOCK)		return -ENOENT;	 	if (has_branch_stack(event))		return -EOPNOTSUPP;	perf_swevent_init_hrtimer(event);	return 0;},8895
404,122,CVE-2014-6269,20,"static void stream_int_chk_snd(struct stream_interface *si){	struct channel *ob = si->ob;	DPRINTF(stderr, ""%s: si=%p, si->state=%d ib->flags=%08x ob->flags=%08x\n"",		__FUNCTION__,		si, si->state, si->ib->flags, si->ob->flags);	if (unlikely(si->state != SI_ST_EST || (si->ob->flags & CF_SHUTW)))		return;	if (!(si->flags & SI_FL_WAIT_DATA) ||         	    channel_is_empty(ob))            		return;	 	si->flags &= ~SI_FL_WAIT_DATA;	if (!tick_isset(ob->wex))		ob->wex = tick_add_ifset(now_ms, ob->wto);	if (!(si->flags & SI_FL_DONT_WAKE) && si->owner)		task_wakeup(si->owner, TASK_WOKEN_IO);}",1786
335,1313,CVE-2013-2094,20,"static void perf_cgroup_exit(struct cgroup *cgrp, struct cgroup *old_cgrp,			     struct task_struct *task){	 	if (!(task->flags & PF_EXITING))		return;	task_function_call(task, __perf_cgroup_move, task);}",8901
388,1243,CVE-2013-4483,20,"static int sysvipc_proc_open(struct inode *inode, struct file *file){	int ret;	struct seq_file *seq;	struct ipc_proc_iter *iter;	ret = -ENOMEM;	iter = kmalloc(sizeof(*iter), GFP_KERNEL);	if (!iter)		goto out;	ret = seq_open(file, &sysvipc_proc_seqops);	if (ret)		goto out_kfree;	seq = file->private_data;	seq->private = iter;	iter->iface = PDE(inode)->data;	iter->ns    = get_ipc_ns(current->nsproxy->ipc_ns);out:	return ret;out_kfree:	kfree(iter);	goto out;}",7803
86,1204,CVE-2013-4483,20,static inline void free_copy(struct msg_msg *copy){	if (copy)		free_msg(copy);},7764
290,1603,CVE-2019-7308,20,static void free_func_state(struct bpf_func_state *state){	if (!state)		return;	kfree(state->refs);	kfree(state->stack);	kfree(state);},27316
219,1547,CVE-2019-14763,20,static void dwc3_disconnect_gadget(struct dwc3 *dwc){	if (dwc->gadget_driver && dwc->gadget_driver->disconnect) {		spin_unlock(&dwc->lock);		dwc->gadget_driver->disconnect(&dwc->gadget);		spin_lock(&dwc->lock);	}},26656
2,76,CVE-2014-6269,20,"int select_compression_response_header(struct session *s, struct buffer *res){	struct http_txn *txn = &s->txn;	struct http_msg *msg = &txn->rsp;	struct hdr_ctx ctx;	struct comp_type *comp_type;	 	if (s->comp_algo == NULL)		goto fail;	 	if (!(msg->flags & HTTP_MSGF_VER_11) || !(txn->req.flags & HTTP_MSGF_VER_11))		goto fail;	 	if (txn->status != 200)		goto fail;	 	if (!(msg->flags & HTTP_MSGF_TE_CHNK) && msg->body_len == 0)		goto fail;	 	ctx.idx = 0;	if (http_find_header2(""Content-Encoding"", 16, res->p, &txn->hdr_idx, &ctx))		goto fail;	 	ctx.idx = 0;	while (http_find_header2(""Cache-Control"", 13, res->p, &txn->hdr_idx, &ctx)) {		if (word_match(ctx.line + ctx.val, ctx.vlen, ""no-transform"", 12))			goto fail;	}	comp_type = NULL;	 	ctx.idx = 0;	if (http_find_header2(""Content-Type"", 12, res->p, &txn->hdr_idx, &ctx)) {		if (ctx.vlen >= 9 && strncasecmp(""multipart"", ctx.line+ctx.val, 9) == 0)			goto fail;		if ((s->be->comp && (comp_type = s->be->comp->types)) ||		    (s->fe->comp && (comp_type = s->fe->comp->types))) {			for (; comp_type; comp_type = comp_type->next) {				if (ctx.vlen >= comp_type->name_len &&				    strncasecmp(ctx.line+ctx.val, comp_type->name, comp_type->name_len) == 0)					 					break;			}			 			if (comp_type == NULL)				goto fail;		}	}	else {  		if ((s->be->comp && s->be->comp->types) || (s->fe->comp && s->fe->comp->types))			goto fail;  	}	 	if (global.comp_rate_lim > 0)		if (read_freq_ctr(&global.comp_bps_in) > global.comp_rate_lim)			goto fail;	 	if (idle_pct < compress_min_idle)		goto fail;	 	if (s->comp_algo->init(&s->comp_ctx, global.tune.comp_maxlevel) < 0)		goto fail;	s->flags |= SN_COMP_READY;	 	ctx.idx = 0;	if ((msg->flags & HTTP_MSGF_CNT_LEN) && http_find_header2(""Content-Length"", 14, res->p, &txn->hdr_idx, &ctx))		http_remove_header2(msg, &txn->hdr_idx, &ctx);	 	if (!(msg->flags & HTTP_MSGF_TE_CHNK))		http_header_add_tail2(&txn->rsp, &txn->hdr_idx, ""Transfer-Encoding: chunked"", 26);	 	if (s->comp_algo->add_data != identity_add_data) {		trash.len = 18;		memcpy(trash.str, ""Content-Encoding: "", trash.len);		memcpy(trash.str + trash.len, s->comp_algo->name, s->comp_algo->name_len);		trash.len += s->comp_algo->name_len;		trash.str[trash.len] = '\0';		http_header_add_tail2(&txn->rsp, &txn->hdr_idx, trash.str, trash.len);	}	return 1;fail:	s->comp_algo = NULL;	return 0;}",1740
390,1026,CVE-2011-2906,20,"void pmcraid_return_cmd(struct pmcraid_cmd *cmd){	struct pmcraid_instance *pinstance = cmd->drv_inst;	unsigned long lock_flags;	spin_lock_irqsave(&pinstance->free_pool_lock, lock_flags);	list_add_tail(&cmd->free_list, &pinstance->free_cmd_pool);	spin_unlock_irqrestore(&pinstance->free_pool_lock, lock_flags);}",6477
126,915,CVE-2011-3209,20,"static void init_alloc_cpu_cpu(int cpu){	int i;	if (cpu_isset(cpu, kmem_cach_cpu_free_init_once))		return;	for (i = NR_KMEM_CACHE_CPU - 1; i >= 0; i--)		free_kmem_cache_cpu(&per_cpu(kmem_cache_cpu, cpu)[i], cpu);	cpu_set(cpu, kmem_cach_cpu_free_init_once);}",5683
294,592,CVE-2011-4131,20,"static void nfs4_layoutcommit_prepare(struct rpc_task *task, void *calldata){	struct nfs4_layoutcommit_data *data = calldata;	struct nfs_server *server = NFS_SERVER(data->args.inode);	if (nfs4_setup_sequence(server, &data->args.seq_args,				&data->res.seq_res, 1, task))		return;	rpc_call_start(task);}",4933
102,232,CVE-2012-3412,20,"static void efx_tsoh_free(struct efx_tx_queue *tx_queue,			  struct efx_tx_buffer *buffer){	if (buffer->tsoh) {		if (likely(!buffer->tsoh->unmap_len)) {			buffer->tsoh->next = tx_queue->tso_headers_free;			tx_queue->tso_headers_free = buffer->tsoh;		} else {			efx_tsoh_heap_free(tx_queue, buffer->tsoh);		}		buffer->tsoh = NULL;	}}",3106
142,1360,CVE-2013-0211,20,"_archive_write_finish_entry(struct archive *_a){	struct archive_write *a = (struct archive_write *)_a;	int ret = ARCHIVE_OK;	archive_check_magic(&a->archive, ARCHIVE_WRITE_MAGIC,	    ARCHIVE_STATE_HEADER | ARCHIVE_STATE_DATA,	    ""archive_write_finish_entry"");	if (a->archive.state & ARCHIVE_STATE_DATA	    && a->format_finish_entry != NULL)		ret = (a->format_finish_entry)(a);	a->archive.state = ARCHIVE_STATE_HEADER;	return (ret);}",9824
283,125,CVE-2014-6269,20,void stream_int_report_error(struct stream_interface *si){	if (!si->err_type)		si->err_type = SI_ET_DATA_ERR;	si->ob->flags |= CF_WRITE_ERROR;	si->ib->flags |= CF_READ_ERROR;},1789
402,16,CVE-2015-3223,20,"static int ldb_match_scope(struct ldb_context *ldb,			   struct ldb_dn *base,			   struct ldb_dn *dn,			   enum ldb_scope scope){	int ret = 0;	if (base == NULL || dn == NULL) {		return 1;	}	switch (scope) {	case LDB_SCOPE_BASE:		if (ldb_dn_compare(base, dn) == 0) {			ret = 1;		}		break;	case LDB_SCOPE_ONELEVEL:		if (ldb_dn_get_comp_num(dn) == (ldb_dn_get_comp_num(base) + 1)) {			if (ldb_dn_compare_base(base, dn) == 0) {				ret = 1;			}		}		break;			case LDB_SCOPE_SUBTREE:	default:		if (ldb_dn_compare_base(base, dn) == 0) {			ret = 1;		}		break;	}	return ret;}",713
192,77,CVE-2014-6269,20,"smp_fetch_base(struct proxy *px, struct session *l4, void *l7, unsigned int opt,               const struct arg *args, struct sample *smp, const char *kw){	struct http_txn *txn = l7;	char *ptr, *end, *beg;	struct hdr_ctx ctx;	struct chunk *temp;	CHECK_HTTP_MESSAGE_FIRST();	ctx.idx = 0;	if (!http_find_header2(""Host"", 4, txn->req.chn->buf->p, &txn->hdr_idx, &ctx) || !ctx.vlen)		return smp_fetch_path(px, l4, l7, opt, args, smp, kw);	 	temp = get_trash_chunk();	memcpy(temp->str, ctx.line + ctx.val, ctx.vlen);	smp->type = SMP_T_STR;	smp->data.str.str = temp->str;	smp->data.str.len = ctx.vlen;	 	end = txn->req.chn->buf->p + txn->req.sl.rq.u + txn->req.sl.rq.u_l;	beg = http_get_path(txn);	if (!beg)		beg = end;	for (ptr = beg; ptr < end && *ptr != '?'; ptr++);	if (beg < ptr && *beg == '/') {		memcpy(smp->data.str.str + smp->data.str.len, beg, ptr - beg);		smp->data.str.len += ptr - beg;	}	smp->flags = SMP_F_VOL_1ST;	return 1;}",1741
161,680,CVE-2011-4131,20,"static int decode_reclaim_complete(struct xdr_stream *xdr, void *dummy){	return decode_op_hdr(xdr, OP_RECLAIM_COMPLETE);}",5021
301,1612,CVE-2019-7308,20,"static int is_state_visited(struct bpf_verifier_env *env, int insn_idx){	struct bpf_verifier_state_list *new_sl;	struct bpf_verifier_state_list *sl;	struct bpf_verifier_state *cur = env->cur_state, *new;	int i, j, err, states_cnt = 0;	sl = env->explored_states[insn_idx];	if (!sl)		 		return 0;	clean_live_states(env, insn_idx, cur);	while (sl != STATE_LIST_MARK) {		if (states_equal(env, &sl->state, cur)) {			 			err = propagate_liveness(env, &sl->state, cur);			if (err)				return err;			return 1;		}		sl = sl->next;		states_cnt++;	}	if (!env->allow_ptr_leaks && states_cnt > BPF_COMPLEXITY_LIMIT_STATES)		return 0;	 	new_sl = kzalloc(sizeof(struct bpf_verifier_state_list), GFP_KERNEL);	if (!new_sl)		return -ENOMEM;	 	new = &new_sl->state;	err = copy_verifier_state(new, cur);	if (err) {		free_verifier_state(new, false);		kfree(new_sl);		return err;	}	new_sl->next = env->explored_states[insn_idx];	env->explored_states[insn_idx] = new_sl;	 	for (j = 0; j <= cur->curframe; j++)		for (i = j < cur->curframe ? BPF_REG_6 : 0; i < BPF_REG_FP; i++)			cur->frame[j]->regs[i].parent = &new->frame[j]->regs[i];	 	for (i = 0; i < BPF_REG_FP; i++)		cur->frame[cur->curframe]->regs[i].live = REG_LIVE_NONE;	 	for (j = 0; j <= cur->curframe; j++) {		struct bpf_func_state *frame = cur->frame[j];		struct bpf_func_state *newframe = new->frame[j];		for (i = 0; i < frame->allocated_stack / BPF_REG_SIZE; i++) {			frame->stack[i].spilled_ptr.live = REG_LIVE_NONE;			frame->stack[i].spilled_ptr.parent =						&newframe->stack[i].spilled_ptr;		}	}	return 0;}",27325
103,241,CVE-2012-2384,20,eb_destroy(struct eb_objects *eb){	kfree(eb);},3218
42,168,CVE-2012-3412,20,static void efx_flush_all(struct efx_nic *efx){	 	cancel_delayed_work_sync(&efx->monitor_work);	 	cancel_work_sync(&efx->mac_work);},3042
261,456,CVE-2012-2100,20,"static int ext4_feature_set_ok(struct super_block *sb, int readonly){	if (EXT4_HAS_INCOMPAT_FEATURE(sb, ~EXT4_FEATURE_INCOMPAT_SUPP)) {		ext4_msg(sb, KERN_ERR,			""Couldn't mount because of ""			""unsupported optional features (%x)"",			(le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_incompat) &			~EXT4_FEATURE_INCOMPAT_SUPP));		return 0;	}	if (readonly)		return 1;	 	if (EXT4_HAS_RO_COMPAT_FEATURE(sb, ~EXT4_FEATURE_RO_COMPAT_SUPP)) {		ext4_msg(sb, KERN_ERR, ""couldn't mount RDWR because of ""			 ""unsupported optional features (%x)"",			 (le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_ro_compat) &				~EXT4_FEATURE_RO_COMPAT_SUPP));		return 0;	}	 	if (EXT4_HAS_RO_COMPAT_FEATURE(sb, EXT4_FEATURE_RO_COMPAT_HUGE_FILE)) {		if (sizeof(blkcnt_t) < sizeof(u64)) {			ext4_msg(sb, KERN_ERR, ""Filesystem with huge files ""				 ""cannot be mounted RDWR without ""				 ""CONFIG_LBDAF"");			return 0;		}	}	if (EXT4_HAS_RO_COMPAT_FEATURE(sb, EXT4_FEATURE_RO_COMPAT_BIGALLOC) &&	    !EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_EXTENTS)) {		ext4_msg(sb, KERN_ERR,			 ""Can't support bigalloc feature without ""			 ""extents feature\n"");		return 0;	}	return 1;}",3611
282,542,CVE-2011-4611,20,"static void hw_perf_event_destroy(struct perf_event *event){	if (!atomic_add_unless(&num_events, -1, 1)) {		mutex_lock(&pmc_reserve_mutex);		if (atomic_dec_return(&num_events) == 0)			release_pmc_hardware();		mutex_unlock(&pmc_reserve_mutex);	}}",4619
333,1573,CVE-2019-14763,20,"static int dwc3_gadget_wakeup(struct usb_gadget *g){	struct dwc3		*dwc = gadget_to_dwc(g);	unsigned long		flags;	int			ret;	spin_lock_irqsave(&dwc->lock, flags);	ret = __dwc3_gadget_wakeup(dwc);	spin_unlock_irqrestore(&dwc->lock, flags);	return ret;}",26682
16,541,CVE-2011-4611,20,"static int check_excludes(struct perf_event **ctrs, unsigned int cflags[],			  int n_prev, int n_new){	int eu = 0, ek = 0, eh = 0;	int i, n, first;	struct perf_event *event;	n = n_prev + n_new;	if (n <= 1)		return 0;	first = 1;	for (i = 0; i < n; ++i) {		if (cflags[i] & PPMU_LIMITED_PMC_OK) {			cflags[i] &= ~PPMU_LIMITED_PMC_REQD;			continue;		}		event = ctrs[i];		if (first) {			eu = event->attr.exclude_user;			ek = event->attr.exclude_kernel;			eh = event->attr.exclude_hv;			first = 0;		} else if (event->attr.exclude_user != eu ||			   event->attr.exclude_kernel != ek ||			   event->attr.exclude_hv != eh) {			return -EAGAIN;		}	}	if (eu || ek || eh)		for (i = 0; i < n; ++i)			if (cflags[i] & PPMU_LIMITED_PMC_OK)				cflags[i] |= PPMU_LIMITED_PMC_REQD;	return 0;}",4618
175,707,CVE-2011-4131,20,"encode_layoutreturn(struct xdr_stream *xdr,		    const struct nfs4_layoutreturn_args *args,		    struct compound_hdr *hdr){	__be32 *p;	p = reserve_space(xdr, 20);	*p++ = cpu_to_be32(OP_LAYOUTRETURN);	*p++ = cpu_to_be32(0);		 	*p++ = cpu_to_be32(args->layout_type);	*p++ = cpu_to_be32(IOMODE_ANY);	*p = cpu_to_be32(RETURN_FILE);	p = reserve_space(xdr, 16 + NFS4_STATEID_SIZE);	p = xdr_encode_hyper(p, 0);	p = xdr_encode_hyper(p, NFS4_MAX_UINT64);	spin_lock(&args->inode->i_lock);	xdr_encode_opaque_fixed(p, &args->stateid.data, NFS4_STATEID_SIZE);	spin_unlock(&args->inode->i_lock);	if (NFS_SERVER(args->inode)->pnfs_curr_ld->encode_layoutreturn) {		NFS_SERVER(args->inode)->pnfs_curr_ld->encode_layoutreturn(			NFS_I(args->inode)->layout, xdr, args);	} else {		p = reserve_space(xdr, 4);		*p = cpu_to_be32(0);	}	hdr->nops++;	hdr->replen += decode_layoutreturn_maxsz;}",5048
122,1646,CVE-2019-14763,20,"static int f_hidg_release(struct inode *inode, struct file *fd){	fd->private_data = NULL;	return 0;}",28864
174,1102,CVE-2013-7010,20,"static inline void avg_tpel_pixels_mc22_c(int *dst, const int *src, int stride, int width, int height){    int i,j;    for (i=0; i < height; i++) {      for (j=0; j < width; j++) {        dst[j] = (dst[j] + ((2731*(2*src[j] + 3*src[j+1] + 3*src[j+stride] + 4*src[j+stride+1] + 6)) >> 15) + 1) >> 1;      }      src += stride;      dst += stride;    }}",7091
350,1300,CVE-2013-2596,20,static void put_fb_info(struct fb_info *fb_info){	if (!atomic_dec_and_test(&fb_info->count))		return;	if (fb_info->fbops->fb_destroy)		fb_info->fbops->fb_destroy(fb_info);},8568
164,504,CVE-2012-0044,20,"void drm_mode_connector_detach_encoder(struct drm_connector *connector,				    struct drm_encoder *encoder){	int i;	for (i = 0; i < DRM_CONNECTOR_MAX_ENCODER; i++) {		if (connector->encoder_ids[i] == encoder->base.id) {			connector->encoder_ids[i] = 0;			if (connector->encoder == encoder)				connector->encoder = NULL;			break;		}	}}",4277
112,798,CVE-2011-4131,20,"static void nfs4_xdr_enc_fs_locations(struct rpc_rqst *req,				      struct xdr_stream *xdr,				      struct nfs4_fs_locations_arg *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	int replen;	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_putfh(xdr, args->dir_fh, &hdr);	encode_lookup(xdr, args->name, &hdr);	replen = hdr.replen;	 	encode_fs_locations(xdr, args->bitmask, &hdr);	xdr_inline_pages(&req->rq_rcv_buf, replen << 2, &args->page,			0, PAGE_SIZE);	encode_nops(&hdr);}",5139
292,1607,CVE-2019-7308,20,"static int is_flow_key_reg(struct bpf_verifier_env *env, int regno){	const struct bpf_reg_state *reg = reg_state(env, regno);	 	return reg->type == PTR_TO_FLOW_KEYS;}",27320
148,736,CVE-2011-4131,20,"static void encode_setclientid_confirm(struct xdr_stream *xdr, const struct nfs4_setclientid_res *arg, struct compound_hdr *hdr){	__be32 *p;	p = reserve_space(xdr, 12 + NFS4_VERIFIER_SIZE);	*p++ = cpu_to_be32(OP_SETCLIENTID_CONFIRM);	p = xdr_encode_hyper(p, arg->clientid);	xdr_encode_opaque_fixed(p, arg->confirm.data, NFS4_VERIFIER_SIZE);	hdr->nops++;	hdr->replen += decode_setclientid_confirm_maxsz;}",5077
24,1281,CVE-2013-2596,20,"static void fb_do_show_logo(struct fb_info *info, struct fb_image *image,			    int rotate, unsigned int num){	unsigned int x;	if (rotate == FB_ROTATE_UR) {		for (x = 0;		     x < num && image->dx + image->width <= info->var.xres;		     x++) {			info->fbops->fb_imageblit(info, image);			image->dx += image->width + 8;		}	} else if (rotate == FB_ROTATE_UD) {		for (x = 0; x < num && image->dx >= 0; x++) {			info->fbops->fb_imageblit(info, image);			image->dx -= image->width + 8;		}	} else if (rotate == FB_ROTATE_CW) {		for (x = 0;		     x < num && image->dy + image->height <= info->var.yres;		     x++) {			info->fbops->fb_imageblit(info, image);			image->dy += image->height + 8;		}	} else if (rotate == FB_ROTATE_CCW) {		for (x = 0; x < num && image->dy >= 0; x++) {			info->fbops->fb_imageblit(info, image);			image->dy -= image->height + 8;		}	}}",8549
139,293,CVE-2012-2375,20,"static void nfs41_sequence_free_slot(struct nfs4_sequence_res *res){	struct nfs4_slot_table *tbl;	tbl = &res->sr_session->fc_slot_table;	if (!res->sr_slot) {		 		dprintk(""%s: No slot\n"", __func__);		return;	}	spin_lock(&tbl->slot_tbl_lock);	nfs4_free_slot(tbl, res->sr_slot - tbl->slots);	nfs4_check_drain_fc_complete(res->sr_session);	spin_unlock(&tbl->slot_tbl_lock);	res->sr_slot = NULL;}",3270
276,602,CVE-2011-4131,20,"static struct nfs4_state *nfs4_opendata_to_nfs4_state(struct nfs4_opendata *data){	struct inode *inode;	struct nfs4_state *state = NULL;	struct nfs_delegation *delegation;	int ret;	if (!data->rpc_done) {		state = nfs4_try_open_cached(data);		goto out;	}	ret = -EAGAIN;	if (!(data->f_attr.valid & NFS_ATTR_FATTR))		goto err;	inode = nfs_fhget(data->dir->d_sb, &data->o_res.fh, &data->f_attr);	ret = PTR_ERR(inode);	if (IS_ERR(inode))		goto err;	ret = -ENOMEM;	state = nfs4_get_open_state(inode, data->owner);	if (state == NULL)		goto err_put_inode;	if (data->o_res.delegation_type != 0) {		int delegation_flags = 0;		rcu_read_lock();		delegation = rcu_dereference(NFS_I(inode)->delegation);		if (delegation)			delegation_flags = delegation->flags;		rcu_read_unlock();		if (data->o_arg.claim == NFS4_OPEN_CLAIM_DELEGATE_CUR) {			pr_err_ratelimited(""NFS: Broken NFSv4 server %s is ""					""returning a delegation for ""					""OPEN(CLAIM_DELEGATE_CUR)\n"",					NFS_CLIENT(inode)->cl_server);		} else if ((delegation_flags & 1UL<<NFS_DELEGATION_NEED_RECLAIM) == 0)			nfs_inode_set_delegation(state->inode,					data->owner->so_cred,					&data->o_res);		else			nfs_inode_reclaim_delegation(state->inode,					data->owner->so_cred,					&data->o_res);	}	update_open_stateid(state, &data->o_res.stateid, NULL,			data->o_arg.fmode);	iput(inode);out:	return state;err_put_inode:	iput(inode);err:	return ERR_PTR(ret);}",4943
373,1697,CVE-2012-2807,20,int xmlThrDefGetWarningsDefaultValue(int v) {    int ret;    xmlMutexLock(xmlThrDefMutex);    ret = xmlGetWarningsDefaultValueThrDef;    xmlGetWarningsDefaultValueThrDef = v;    xmlMutexUnlock(xmlThrDefMutex);    return ret;},29283
325,133,CVE-2014-6269,20,"void stream_sock_read0(struct stream_interface *si){	struct connection *conn = __objt_conn(si->end);	si->ib->flags &= ~CF_SHUTR_NOW;	if (si->ib->flags & CF_SHUTR)		return;	si->ib->flags |= CF_SHUTR;	si->ib->rex = TICK_ETERNITY;	si->flags &= ~SI_FL_WAIT_ROOM;	if (si->state != SI_ST_EST && si->state != SI_ST_CON)		return;	if (si->ob->flags & CF_SHUTW)		goto do_close;	if (si->flags & SI_FL_NOHALF) {		 		 		if (conn->xprt->shutw)			conn->xprt->shutw(conn, 0);		goto do_close;	}	 	if (conn_ctrl_ready(conn))		fdtab[conn->t.sock.fd].linger_risk = 0;	__conn_data_stop_recv(conn);	return; do_close:	 	conn_full_close(conn);	si->ib->flags &= ~CF_SHUTR_NOW;	si->ib->flags |= CF_SHUTR;	si->ib->rex = TICK_ETERNITY;	si->ob->flags &= ~CF_SHUTW_NOW;	si->ob->flags |= CF_SHUTW;	si->ob->wex = TICK_ETERNITY;	si->flags &= ~(SI_FL_WAIT_DATA | SI_FL_WAIT_ROOM);	si->state = SI_ST_DIS;	si->exp = TICK_ETERNITY;	return;}",1797
141,1708,CVE-2013-6630,20,"void PrintToStderr(const char* output) {  ignore_result(HANDLE_EINTR(write(STDERR_FILENO, output, strlen(output))));}",29360
204,810,CVE-2011-4131,20,"static void nfs4_xdr_enc_lookup_root(struct rpc_rqst *req,				     struct xdr_stream *xdr,				     const struct nfs4_lookup_root_arg *args){	struct compound_hdr hdr = {		.minorversion = nfs4_xdr_minorversion(&args->seq_args),	};	encode_compound_hdr(xdr, req, &hdr);	encode_sequence(xdr, &args->seq_args, &hdr);	encode_putrootfh(xdr, &hdr);	encode_getfh(xdr, &hdr);	encode_getfattr(xdr, args->bitmask, &hdr);	encode_nops(&hdr);}",5151
210,1391,CVE-2014-4656,20,"static struct snd_kcontrol *snd_ctl_new(struct snd_kcontrol *control,					unsigned int access){	struct snd_kcontrol *kctl;	unsigned int idx;		if (snd_BUG_ON(!control || !control->count))		return NULL;	if (control->count > MAX_CONTROL_COUNT)		return NULL;	kctl = kzalloc(sizeof(*kctl) + sizeof(struct snd_kcontrol_volatile) * control->count, GFP_KERNEL);	if (kctl == NULL) {		pr_err(""ALSA: Cannot allocate control instance\n"");		return NULL;	}	*kctl = *control;	for (idx = 0; idx < kctl->count; idx++)		kctl->vd[idx].access = access;	return kctl;}",10825
69,1549,CVE-2019-14763,20,static void dwc3_ep_inc_enq(struct dwc3_ep *dep){	dwc3_ep_inc_trb(&dep->trb_enqueue);},26658
295,1298,CVE-2013-2596,20,int lock_fb_info(struct fb_info *info){	mutex_lock(&info->lock);	if (!info->fbops) {		mutex_unlock(&info->lock);		return 0;	}	return 1;},8566
46,1398,CVE-2014-4656,20,"int snd_ctl_replace(struct snd_card *card, struct snd_kcontrol *kcontrol,		    int add_on_replace){	struct snd_ctl_elem_id id;	unsigned int count;	unsigned int idx;	struct snd_kcontrol *old;	int ret;	if (!kcontrol)		return -EINVAL;	if (snd_BUG_ON(!card || !kcontrol->info)) {		ret = -EINVAL;		goto error;	}	id = kcontrol->id;	down_write(&card->controls_rwsem);	old = snd_ctl_find_id(card, &id);	if (!old) {		if (add_on_replace)			goto add;		up_write(&card->controls_rwsem);		ret = -EINVAL;		goto error;	}	ret = snd_ctl_remove(card, old);	if (ret < 0) {		up_write(&card->controls_rwsem);		goto error;	}add:	if (snd_ctl_find_hole(card, kcontrol->count) < 0) {		up_write(&card->controls_rwsem);		ret = -ENOMEM;		goto error;	}	list_add_tail(&kcontrol->list, &card->controls);	card->controls_count += kcontrol->count;	kcontrol->id.numid = card->last_numid + 1;	card->last_numid += kcontrol->count;	count = kcontrol->count;	up_write(&card->controls_rwsem);	for (idx = 0; idx < count; idx++, id.index++, id.numid++)		snd_ctl_notify(card, SNDRV_CTL_EVENT_MASK_ADD, &id);	return 0;error:	snd_ctl_free_one(kcontrol);	return ret;}",10832
400,261,CVE-2012-2375,20,"static int _nfs4_proc_getattr(struct nfs_server *server, struct nfs_fh *fhandle, struct nfs_fattr *fattr){	struct nfs4_getattr_arg args = {		.fh = fhandle,		.bitmask = server->attr_bitmask,	};	struct nfs4_getattr_res res = {		.fattr = fattr,		.server = server,	};	struct rpc_message msg = {		.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_GETATTR],		.rpc_argp = &args,		.rpc_resp = &res,	};		nfs_fattr_init(fattr);	return nfs4_call_sync(server->client, server, &msg, &args.seq_args, &res.seq_res, 0);}",3238
63,1471,CVE-2015-4001,20,static void *oz_claim_hpd(struct oz_port *port){	void *hpd;	struct oz_hcd *ozhcd = port->ozhcd;	spin_lock_bh(&ozhcd->hcd_lock);	hpd = port->hpd;	if (hpd)		oz_usb_get(hpd);	spin_unlock_bh(&ozhcd->hcd_lock);	return hpd;},13547
225,1431,CVE-2014-2669,20,"querytree(PG_FUNCTION_ARGS){	elog(ERROR, ""querytree is no longer implemented"");	PG_RETURN_NULL();}",11809
270,1103,CVE-2013-7010,20,"static void bswap16_buf(int *dst, const int *src, int len){    while (len--)        *dst++ = av_bswap16(*src++);}",7092
156,1541,CVE-2019-1010294,20,static void set_ta_ctx_ops(struct tee_ta_ctx *ctx){	ctx->ops = _user_ta_ops;},26375
223,1481,CVE-2015-4001,20,"static void oz_hcd_endpoint_disable(struct usb_hcd *hcd,				struct usb_host_endpoint *ep){}",13557
60,366,CVE-2012-2375,20,"static int nfs4_proc_fsinfo(struct nfs_server *server, struct nfs_fh *fhandle, struct nfs_fsinfo *fsinfo){	nfs_fattr_init(fsinfo->fattr);	return nfs4_do_fsinfo(server, fhandle, fsinfo);}",3343
51,1660,CVE-2012-2828,20,  void Reset() {    finished_ = false;    waiting_ = false;    result_.clear();  },29246
222,1655,CVE-2019-14763,20,"static void hidg_unbind(struct usb_configuration *c, struct usb_function *f){	struct f_hidg *hidg = func_to_hidg(f);	device_destroy(hidg_class, MKDEV(major, hidg->minor));	cdev_del(&hidg->cdev);	usb_free_all_descriptors(f);}",28873
91,1532,CVE-2016-2070,20,"static int tcp_try_undo_loss(struct sock *sk, int frto_undo){	struct tcp_sock *tp = tcp_sk(sk);	if (frto_undo || tcp_may_undo(tp)) {		tcp_undo_cwnd_reduction(sk, true);		DBGUNDO(sk, ""partial loss"");		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPLOSSUNDO);		if (frto_undo)			NET_INC_STATS_BH(sock_net(sk),					 LINUX_MIB_TCPSPURIOUSRTOS);		inet_csk(sk)->icsk_retransmits = 0;		if (frto_undo || tcp_is_sack(tp))			tcp_set_ca_state(sk, TCP_CA_Open);		return true;	}	return false;}",18015
420,1070,CVE-2011-1476,20,"unsigned long compute_finetune(unsigned long base_freq, int bend, int range,		 int vibrato_cents){	unsigned long amount;	int negative, semitones, cents, multiplier = 1;	if (!bend)		return base_freq;	if (!range)		return base_freq;	if (!base_freq)		return base_freq;	if (range >= 8192)		range = 8192;	bend = bend * range / 8192;	 	bend += vibrato_cents;	if (!bend)		return base_freq;	negative = bend < 0 ? 1 : 0;	if (bend < 0)		bend *= -1;	if (bend > range)		bend = range;	 	while (bend > 2399)	{		multiplier *= 4;		bend -= 2400;	}	semitones = bend / 100;	cents = bend % 100;	amount = (int) (semitone_tuning[semitones] * multiplier * cent_tuning[cents]) / 10000;	if (negative)		return (base_freq * 10000) / amount;	 	else		return (base_freq * amount) / 10000;	 }",6887
432,70,CVE-2014-6269,20,int http_sync_res_state(struct session *s){	struct channel *chn = s->rep;	struct http_txn *txn = &s->txn;	unsigned int old_flags = chn->flags;	unsigned int old_state = txn->rsp.msg_state;	if (unlikely(txn->rsp.msg_state < HTTP_MSG_BODY))		return 0;	if (txn->rsp.msg_state == HTTP_MSG_DONE) {		 		 		if (txn->req.msg_state == HTTP_MSG_ERROR)			goto wait_other_side;		if (txn->req.msg_state < HTTP_MSG_DONE) {			 			goto wait_other_side;		}		if (txn->req.msg_state == HTTP_MSG_TUNNEL) {			 			channel_auto_read(chn);			txn->rsp.msg_state = HTTP_MSG_TUNNEL;			chn->flags |= CF_NEVER_WAIT;			goto wait_other_side;		}		 		if ((txn->flags & TX_CON_WANT_MSK) == TX_CON_WANT_SCL) {			 			if (!(chn->flags & (CF_SHUTR|CF_SHUTR_NOW)))				channel_shutr_now(chn);		}		else if ((txn->flags & TX_CON_WANT_MSK) == TX_CON_WANT_CLO) {			 			if (!(chn->flags & (CF_SHUTW|CF_SHUTW_NOW))) {				channel_shutr_now(chn);				channel_shutw_now(chn);			}		}		else {			 			channel_auto_read(chn);			chn->flags |= CF_NEVER_WAIT;			if ((txn->flags & TX_CON_WANT_MSK) == TX_CON_WANT_TUN)				txn->rsp.msg_state = HTTP_MSG_TUNNEL;		}		if (chn->flags & (CF_SHUTW|CF_SHUTW_NOW)) {			 			if (!channel_is_empty(chn)) {				txn->rsp.msg_state = HTTP_MSG_CLOSING;				goto http_msg_closing;			}			else {				txn->rsp.msg_state = HTTP_MSG_CLOSED;				goto http_msg_closed;			}		}		goto wait_other_side;	}	if (txn->rsp.msg_state == HTTP_MSG_CLOSING) {	http_msg_closing:		 		if (channel_is_empty(chn)) {			txn->rsp.msg_state = HTTP_MSG_CLOSED;			goto http_msg_closed;		}		else if (chn->flags & CF_SHUTW) {			txn->rsp.msg_state = HTTP_MSG_ERROR;			s->be->be_counters.cli_aborts++;			if (objt_server(s->target))				objt_server(s->target)->counters.cli_aborts++;			goto wait_other_side;		}	}	if (txn->rsp.msg_state == HTTP_MSG_CLOSED) {	http_msg_closed:		 		bi_erase(chn);		channel_auto_close(chn);		channel_auto_read(chn);		goto wait_other_side;	} wait_other_side:	 	if (!channel_is_empty(chn))		chn->flags |= CF_SEND_DONTWAIT;	return txn->rsp.msg_state != old_state || chn->flags != old_flags;},1734
70,1065,CVE-2011-1476,20,"prefix_cmd(int midi_dev, unsigned char status){	if ((char *) midi_devs[midi_dev]->prefix_cmd == NULL)		return 1;	return midi_devs[midi_dev]->prefix_cmd(midi_dev, status);}",6882
318,1397,CVE-2014-4656,20,"int snd_ctl_rename_id(struct snd_card *card, struct snd_ctl_elem_id *src_id,		      struct snd_ctl_elem_id *dst_id){	struct snd_kcontrol *kctl;	down_write(&card->controls_rwsem);	kctl = snd_ctl_find_id(card, src_id);	if (kctl == NULL) {		up_write(&card->controls_rwsem);		return -ENOENT;	}	kctl->id = *dst_id;	kctl->id.numid = card->last_numid + 1;	card->last_numid += kctl->count;	up_write(&card->controls_rwsem);	return 0;}",10831
414,885,CVE-2011-3209,20,"static void add_full(struct kmem_cache_node *n, struct page *page){	spin_lock(&n->list_lock);	list_add(&page->lru, &n->full);	spin_unlock(&n->list_lock);}",5653
429,1115,CVE-2013-7010,20,"static void h263_h_loop_filter_c(int *src, int stride, int qscale){    if(CONFIG_H263_DECODER || CONFIG_H263_ENCODER) {    int y;    const int strength= ff_h263_loop_filter_strength[qscale];    for(y=0; y<8; y++){        int d1, d2, ad1;        int p0= src[y*stride-2];        int p1= src[y*stride-1];        int p2= src[y*stride+0];        int p3= src[y*stride+1];        int d = (p0 - p3 + 4*(p2 - p1)) / 8;        if     (d<-2*strength) d1= 0;        else if(d<-  strength) d1=-2*strength - d;        else if(d<   strength) d1= d;        else if(d< 2*strength) d1= 2*strength - d;        else                   d1= 0;        p1 += d1;        p2 -= d1;        if(p1&256) p1= ~(p1>>31);        if(p2&256) p2= ~(p2>>31);        src[y*stride-1] = p1;        src[y*stride+0] = p2;        ad1= FFABS(d1)>>1;        d2= av_clip((p0-p3)/4, -ad1, ad1);        src[y*stride-2] = p0 - d2;        src[y*stride+1] = p3 + d2;    }    }}",7104
386,1110,CVE-2013-7010,20,"static void ff_jref_idct4_add(int *dest, int line_size, int *block){    ff_j_rev_dct4 (block);    add_pixels_clamped4_c(block, dest, line_size);}",7099
236,74,CVE-2014-6269,20,"void init_proto_http(){	int i;	char *tmp;	int msg;	for (msg = 0; msg < HTTP_ERR_SIZE; msg++) {		if (!http_err_msgs[msg]) {			Alert(""Internal error: no message defined for HTTP return code %d. Aborting.\n"", msg);			abort();		}		http_err_chunks[msg].str = (char *)http_err_msgs[msg];		http_err_chunks[msg].len = strlen(http_err_msgs[msg]);	}	 	memset(hdr_encode_map, 0, sizeof(hdr_encode_map));	memset(url_encode_map, 0, sizeof(url_encode_map));	memset(http_encode_map, 0, sizeof(url_encode_map));	for (i = 0; i < 32; i++) {		FD_SET(i, hdr_encode_map);		FD_SET(i, url_encode_map);	}	for (i = 127; i < 256; i++) {		FD_SET(i, hdr_encode_map);		FD_SET(i, url_encode_map);	}	tmp = ""\""#{|}"";	while (*tmp) {		FD_SET(*tmp, hdr_encode_map);		tmp++;	}	tmp = ""\""#"";	while (*tmp) {		FD_SET(*tmp, url_encode_map);		tmp++;	}	 	memset(http_encode_map, 0, sizeof(http_encode_map));	for (i = 0x00; i <= 0x08; i++)		FD_SET(i, http_encode_map);	for (i = 0x0a; i <= 0x1f; i++)		FD_SET(i, http_encode_map);	FD_SET(0x7f, http_encode_map);	 	pool2_requri = create_pool(""requri"", REQURI_LEN, MEM_F_SHARED);	pool2_uniqueid = create_pool(""uniqueid"", UNIQUEID_LEN, MEM_F_SHARED);}",1738
118,1584,CVE-2019-13233,21,"static int resolve_default_seg(struct insn *insn, struct pt_regs *regs, int off){	if (user_64bit_mode(regs))		return INAT_SEG_REG_IGNORE;	 	switch (off) {	case offsetof(struct pt_regs, ax):	case offsetof(struct pt_regs, cx):	case offsetof(struct pt_regs, dx):		 		if (insn->addr_bytes == 2)			return -EINVAL;		 	case -EDOM:	case offsetof(struct pt_regs, bx):	case offsetof(struct pt_regs, si):		return INAT_SEG_REG_DS;	case offsetof(struct pt_regs, di):		if (is_string_insn(insn))			return INAT_SEG_REG_ES;		return INAT_SEG_REG_DS;	case offsetof(struct pt_regs, bp):	case offsetof(struct pt_regs, sp):		return INAT_SEG_REG_SS;	case offsetof(struct pt_regs, ip):		return INAT_SEG_REG_CS;	default:		return -EINVAL;	}}",26738
218,478,CVE-2014-2706,21,"static int sta_info_insert_drv_state(struct ieee80211_local *local,				     struct ieee80211_sub_if_data *sdata,				     struct sta_info *sta){	enum ieee80211_sta_state state;	int err = 0;	for (state = IEEE80211_STA_NOTEXIST; state < sta->sta_state; state++) {		err = drv_sta_state(local, sdata, sta, state, state + 1);		if (err)			break;	}	if (!err) {		 		if (!local->ops->sta_add)			sta->uploaded = true;		return 0;	}	if (sdata->vif.type == NL80211_IFTYPE_ADHOC) {		sdata_info(sdata,			   ""failed to move IBSS STA %pM to state %d (%d) - keeping it anyway\n"",			   sta->sta.addr, state + 1, err);		err = 0;	}	 	for (; state > IEEE80211_STA_NOTEXIST; state--)		WARN_ON(drv_sta_state(local, sdata, sta, state, state - 1));	return err;}",11738
436,1084,CVE-2017-7533,21,"static inline void __d_add(struct dentry *dentry, struct inode *inode){	struct inode *dir = NULL;	unsigned n;	spin_lock(&dentry->d_lock);	if (unlikely(d_in_lookup(dentry))) {		dir = dentry->d_parent->d_inode;		n = start_dir_add(dir);		__d_lookup_done(dentry);	}	if (inode) {		unsigned add_flags = d_flags_for_inode(inode);		hlist_add_head(&dentry->d_u.d_alias, &inode->i_dentry);		raw_write_seqcount_begin(&dentry->d_seq);		__d_set_inode_and_type(dentry, inode, add_flags);		raw_write_seqcount_end(&dentry->d_seq);		fsnotify_update_flags(dentry);	}	__d_rehash(dentry);	if (dir)		end_dir_add(dir, n);	spin_unlock(&dentry->d_lock);	if (inode)		spin_unlock(&inode->i_lock);}",21556
81,1760,CVE-2012-3552,21," void cipso_v4_sock_delattr(struct sock *sk) { 	int hdr_delta;	struct ip_options *opt; 	struct inet_sock *sk_inet;  	sk_inet = inet_sk(sk);	opt = sk_inet->opt;	if (opt == NULL || opt->cipso == 0) 		return; 	hdr_delta = cipso_v4_delopt(&sk_inet->opt); 	if (sk_inet->is_icsk && hdr_delta > 0) { 		struct inet_connection_sock *sk_conn = inet_csk(sk); 		sk_conn->icsk_ext_hdr_len -= hdr_delta;		sk_conn->icsk_sync_mss(sk, sk_conn->icsk_pmtu_cookie);	}}",30926
344,1338,CVE-2018-12232,21,"void socket_seq_show(struct seq_file *seq){	seq_printf(seq, ""sockets: used %d\n"",		   sock_inuse_get(seq->private));}",25120
267,695,CVE-2015-0239,21,static int em_pushf(struct x86_emulate_ctxt *ctxt){	ctxt->src.val = (unsigned long)ctxt->eflags & ~EFLG_VM;	return em_push(ctxt);},14104
160,365,CVE-2013-3302,21,cifs_wake_up_task(struct mid_q_entry *mid){	wake_up_process(mid->callback_data);},8016
184,923,CVE-2016-0723,21,int tty_hung_up_p(struct file *filp){	return (filp->f_op == &hung_up_tty_fops);},18266
0,1370,CVE-2017-18249,21,"static void truncate_node(struct dnode_of_data *dn){	struct f2fs_sb_info *sbi = F2FS_I_SB(dn->inode);	struct node_info ni;	get_node_info(sbi, dn->nid, &ni);	if (dn->inode->i_blocks == 0) {		f2fs_bug_on(sbi, ni.blk_addr != NULL_ADDR);		goto invalidate;	}	f2fs_bug_on(sbi, ni.blk_addr == NULL_ADDR);	 	invalidate_blocks(sbi, ni.blk_addr);	dec_valid_node_count(sbi, dn->inode);	set_node_addr(sbi, &ni, NULL_ADDR, false);	if (dn->nid == dn->inode->i_ino) {		remove_orphan_inode(sbi, dn->nid);		dec_valid_inode_count(sbi);		f2fs_inode_synced(dn->inode);	}invalidate:	clear_node_page_dirty(dn->node_page);	set_sbi_flag(sbi, SBI_IS_DIRTY);	f2fs_put_page(dn->node_page, 1);	invalidate_mapping_pages(NODE_MAPPING(sbi),			dn->node_page->index, dn->node_page->index);	dn->node_page = NULL;	trace_f2fs_truncate_node(dn->inode, dn->nid, ni.blk_addr);}",25688
320,656,CVE-2015-3339,21,"void __set_task_comm(struct task_struct *tsk, const char *buf, int exec){	task_lock(tsk);	trace_task_rename(tsk, buf);	strlcpy(tsk->comm, buf, sizeof(tsk->comm));	task_unlock(tsk);	perf_event_comm(tsk, exec);}",13585
389,1648,CVE-2019-11599,21,"detach_vmas_to_be_unmapped(struct mm_struct *mm, struct vm_area_struct *vma,	struct vm_area_struct *prev, unsigned long end){	struct vm_area_struct **insertion_point;	struct vm_area_struct *tail_vma = NULL;	insertion_point = (prev ? &prev->vm_next : &mm->mmap);	vma->vm_prev = NULL;	do {		vma_rb_erase(vma, &mm->mm_rb);		mm->map_count--;		tail_vma = vma;		vma = vma->vm_next;	} while (vma && vma->vm_start < end);	*insertion_point = vma;	if (vma) {		vma->vm_prev = prev;		vma_gap_update(vma);	} else		mm->highest_vm_end = prev ? vm_end_gap(prev) : 0;	tail_vma->vm_next = NULL;	 	vmacache_invalidate(mm);}",27095
438,222,CVE-2012-3552,21,"static int tcp6_gro_complete(struct sk_buff *skb){	const struct ipv6hdr *iph = ipv6_hdr(skb);	struct tcphdr *th = tcp_hdr(skb);	th->check = ~tcp_v6_check(skb->len - skb_transport_offset(skb),				  &iph->saddr, &iph->daddr, 0);	skb_shinfo(skb)->gso_type = SKB_GSO_TCPV6;	return tcp_gro_complete(skb);}",2908
55,1099,CVE-2017-7533,21,"static void copy_name(struct dentry *dentry, struct dentry *target){	struct external_name *old_name = NULL;	if (unlikely(dname_external(dentry)))		old_name = external_name(dentry);	if (unlikely(dname_external(target))) {		atomic_inc(&external_name(target)->u.count);		dentry->d_name = target->d_name;	} else {		memcpy(dentry->d_iname, target->d_name.name,				target->d_name.len + 1);		dentry->d_name.name = dentry->d_iname;		dentry->d_name.hash_len = target->d_name.hash_len;	}	if (old_name && likely(atomic_dec_and_test(&old_name->u.count)))		kfree_rcu(old_name, u.head);}",21571
378,100,CVE-2012-3552,21,"static int dccp_v6_send_response(struct sock *sk, struct request_sock *req,				 struct request_values *rv_unused){	struct inet6_request_sock *ireq6 = inet6_rsk(req);	struct ipv6_pinfo *np = inet6_sk(sk);	struct sk_buff *skb;	struct ipv6_txoptions *opt = NULL;	struct in6_addr *final_p, final;	struct flowi6 fl6;	int err = -1;	struct dst_entry *dst;	memset(&fl6, 0, sizeof(fl6));	fl6.flowi6_proto = IPPROTO_DCCP;	ipv6_addr_copy(&fl6.daddr, &ireq6->rmt_addr);	ipv6_addr_copy(&fl6.saddr, &ireq6->loc_addr);	fl6.flowlabel = 0;	fl6.flowi6_oif = ireq6->iif;	fl6.fl6_dport = inet_rsk(req)->rmt_port;	fl6.fl6_sport = inet_rsk(req)->loc_port;	security_req_classify_flow(req, flowi6_to_flowi(&fl6));	opt = np->opt;	final_p = fl6_update_dst(&fl6, opt, &final);	dst = ip6_dst_lookup_flow(sk, &fl6, final_p, false);	if (IS_ERR(dst)) {		err = PTR_ERR(dst);		dst = NULL;		goto done;	}	skb = dccp_make_response(sk, dst, req);	if (skb != NULL) {		struct dccp_hdr *dh = dccp_hdr(skb);		dh->dccph_checksum = dccp_v6_csum_finish(skb,							 &ireq6->loc_addr,							 &ireq6->rmt_addr);		ipv6_addr_copy(&fl6.daddr, &ireq6->rmt_addr);		err = ip6_xmit(sk, skb, &fl6, opt);		err = net_xmit_eval(err);	}done:	if (opt != NULL && opt != np->opt)		sock_kfree_s(sk, opt, opt->tot_len);	dst_release(dst);	return err;}",2786
293,1265,CVE-2017-6001,21,"list_update_cgroup_event(struct perf_event *event,			 struct perf_event_context *ctx, int add){	struct perf_cpu_context *cpuctx;	if (!is_cgroup_event(event))		return;	if (add && ctx->nr_cgroups++)		return;	else if (!add && --ctx->nr_cgroups)		return;	 	cpuctx = __get_cpu_context(ctx);	 	if (add && perf_cgroup_from_task(current, ctx) == event->cgrp)		cpuctx->cgrp = event->cgrp;	else if (!add)		cpuctx->cgrp = NULL;}",21885
64,490,CVE-2014-2672,21,"static void ath_tid_drain(struct ath_softc *sc, struct ath_txq *txq,			  struct ath_atx_tid *tid){	struct sk_buff *skb;	struct ath_buf *bf;	struct list_head bf_head;	struct ath_tx_status ts;	struct ath_frame_info *fi;	memset(&ts, 0, sizeof(ts));	INIT_LIST_HEAD(&bf_head);	while ((skb = ath_tid_dequeue(tid))) {		fi = get_frame_info(skb);		bf = fi->bf;		if (!bf) {			ath_tx_complete(sc, skb, ATH_TX_ERROR, txq);			continue;		}		list_add_tail(&bf->list, &bf_head);		ath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);	}}",11774
49,1753,CVE-2018-6158,21,  void FinishSteps() {    CHECK(thread_state_->IsIncrementalMarking());    while (SingleStep()) {    }  },30238
313,1154,CVE-2017-7533,21,void dput(struct dentry *dentry){	if (unlikely(!dentry))		return;repeat:	might_sleep();	rcu_read_lock();	if (likely(fast_dput(dentry))) {		rcu_read_unlock();		return;	}	 	rcu_read_unlock();	WARN_ON(d_in_lookup(dentry));	 	if (unlikely(d_unhashed(dentry)))		goto kill_it;	if (unlikely(dentry->d_flags & DCACHE_DISCONNECTED))		goto kill_it;	if (unlikely(dentry->d_flags & DCACHE_OP_DELETE)) {		if (dentry->d_op->d_delete(dentry))			goto kill_it;	}	dentry_lru_add(dentry);	dentry->d_lockref.count--;	spin_unlock(&dentry->d_lock);	return;kill_it:	dentry = dentry_kill(dentry);	if (dentry) {		cond_resched();		goto repeat;	}},21626
235,153,CVE-2012-3552,21,"static inline int ip_ufo_append_data(struct sock *sk,			struct sk_buff_head *queue,			int getfrag(void *from, char *to, int offset, int len,			       int odd, struct sk_buff *skb),			void *from, int length, int hh_len, int fragheaderlen,			int transhdrlen, int mtu, unsigned int flags){	struct sk_buff *skb;	int err;	 	if ((skb = skb_peek_tail(queue)) == NULL) {		skb = sock_alloc_send_skb(sk,			hh_len + fragheaderlen + transhdrlen + 20,			(flags & MSG_DONTWAIT), &err);		if (skb == NULL)			return err;		 		skb_reserve(skb, hh_len);		 		skb_put(skb, fragheaderlen + transhdrlen);		 		skb_reset_network_header(skb);		 		skb->transport_header = skb->network_header + fragheaderlen;		skb->ip_summed = CHECKSUM_PARTIAL;		skb->csum = 0;		 		skb_shinfo(skb)->gso_size = mtu - fragheaderlen;		skb_shinfo(skb)->gso_type = SKB_GSO_UDP;		__skb_queue_tail(queue, skb);	}	return skb_append_datato_frags(sk, skb, getfrag, from,				       (length - transhdrlen));}",2839
205,521,CVE-2014-0196,21,"static void echo_char_raw(unsigned char c, struct n_tty_data *ldata){	if (c == ECHO_OP_START) {		add_echo_byte(ECHO_OP_START, ldata);		add_echo_byte(ECHO_OP_START, ldata);	} else {		add_echo_byte(c, ldata);	}}",12176
56,48,CVE-2012-1174,21,"int reset_terminal(const char *name) {        int fd, r;        fd = open_terminal(name, O_RDWR|O_NOCTTY|O_CLOEXEC);        if (fd < 0)                return fd;        r = reset_terminal_fd(fd, true);        close_nointr_nofail(fd);        return r;}",2013
54,1783,CVE-2015-3212,21,"static int sctp_init_sock(struct sock *sk){	struct net *net = sock_net(sk);	struct sctp_sock *sp;	pr_debug(""%s: sk:%p\n"", __func__, sk);	sp = sctp_sk(sk);	 	switch (sk->sk_type) {	case SOCK_SEQPACKET:		sp->type = SCTP_SOCKET_UDP;		break;	case SOCK_STREAM:		sp->type = SCTP_SOCKET_TCP;		break;	default:		return -ESOCKTNOSUPPORT;	}	 	sp->default_stream = 0;	sp->default_ppid = 0;	sp->default_flags = 0;	sp->default_context = 0;	sp->default_timetolive = 0;	sp->default_rcv_context = 0;	sp->max_burst = net->sctp.max_burst;	sp->sctp_hmac_alg = net->sctp.sctp_hmac_alg;	 	sp->initmsg.sinit_num_ostreams   = sctp_max_outstreams;	sp->initmsg.sinit_max_instreams  = sctp_max_instreams;	sp->initmsg.sinit_max_attempts   = net->sctp.max_retrans_init;	sp->initmsg.sinit_max_init_timeo = net->sctp.rto_max;	 	sp->rtoinfo.srto_initial = net->sctp.rto_initial;	sp->rtoinfo.srto_max     = net->sctp.rto_max;	sp->rtoinfo.srto_min     = net->sctp.rto_min;	 	sp->assocparams.sasoc_asocmaxrxt = net->sctp.max_retrans_association;	sp->assocparams.sasoc_number_peer_destinations = 0;	sp->assocparams.sasoc_peer_rwnd = 0;	sp->assocparams.sasoc_local_rwnd = 0;	sp->assocparams.sasoc_cookie_life = net->sctp.valid_cookie_life;	 	memset(&sp->subscribe, 0, sizeof(struct sctp_event_subscribe));	 	sp->hbinterval  = net->sctp.hb_interval;	sp->pathmaxrxt  = net->sctp.max_retrans_path;	sp->pathmtu     = 0;  	sp->sackdelay   = net->sctp.sack_timeout;	sp->sackfreq	= 2;	sp->param_flags = SPP_HB_ENABLE |			  SPP_PMTUD_ENABLE |			  SPP_SACKDELAY_ENABLE;	 	sp->disable_fragments = 0;	 	sp->nodelay           = 0;	sp->recvrcvinfo = 0;	sp->recvnxtinfo = 0;	 	sp->v4mapped          = 1;	 	sp->autoclose         = 0;	 	sp->user_frag         = 0;	sp->adaptation_ind = 0;	sp->pf = sctp_get_pf_specific(sk->sk_family);	 	atomic_set(&sp->pd_mode, 0);	skb_queue_head_init(&sp->pd_lobby);	sp->frag_interleave = 0;	 	sp->ep = sctp_endpoint_new(sk, GFP_KERNEL);	if (!sp->ep)		return -ENOMEM;	sp->hmac = NULL;	sk->sk_destruct = sctp_destruct_sock;	SCTP_DBG_OBJCNT_INC(sock); 	local_bh_disable(); 	percpu_counter_inc(&sctp_sockets_allocated); 	sock_prot_inuse_add(net, sk->sk_prot, 1); 	if (net->sctp.default_auto_asconf) { 		list_add_tail(&sp->auto_asconf_list, 		    &net->sctp.auto_asconf_splist); 		sp->do_auto_asconf = 1;	} else 		sp->do_auto_asconf = 0; 	local_bh_enable();  	return 0; }",31198
121,1758,CVE-2012-3552,21,"void inet_sock_destruct(struct sock *sk){	struct inet_sock *inet = inet_sk(sk);	__skb_queue_purge(&sk->sk_receive_queue);	__skb_queue_purge(&sk->sk_error_queue);	sk_mem_reclaim(sk);	if (sk->sk_type == SOCK_STREAM && sk->sk_state != TCP_CLOSE) {		pr_err(""Attempt to release TCP socket in state %d %p\n"",		       sk->sk_state, sk);		return;	}	if (!sock_flag(sk, SOCK_DEAD)) {		pr_err(""Attempt to release alive inet socket %p\n"", sk);		return;	}	WARN_ON(atomic_read(&sk->sk_rmem_alloc));	WARN_ON(atomic_read(&sk->sk_wmem_alloc)); 	WARN_ON(sk->sk_wmem_queued); 	WARN_ON(sk->sk_forward_alloc); 	kfree(inet->opt); 	dst_release(rcu_dereference_check(sk->sk_dst_cache, 1)); 	sk_refcnt_debug_dec(sk); }",30924
275,1427,CVE-2017-18203,21,void dm_internal_resume(struct mapped_device *md){	mutex_lock(&md->suspend_lock);	__dm_internal_resume(md);	mutex_unlock(&md->suspend_lock);},25962
34,663,CVE-2015-3339,21,"struct file *open_exec(const char *name){	struct filename *filename = getname_kernel(name);	struct file *f = ERR_CAST(filename);	if (!IS_ERR(filename)) {		f = do_open_execat(AT_FDCWD, filename, 0);		putname(filename);	}	return f;}",13592
21,1281,CVE-2017-6001,21,"perf_event_exit_event(struct perf_event *child_event,		      struct perf_event_context *child_ctx,		      struct task_struct *child){	struct perf_event *parent_event = child_event->parent;	 	raw_spin_lock_irq(&child_ctx->lock);	WARN_ON_ONCE(child_ctx->is_active);	if (parent_event)		perf_group_detach(child_event);	list_del_event(child_event, child_ctx);	child_event->state = PERF_EVENT_STATE_EXIT;  	raw_spin_unlock_irq(&child_ctx->lock);	 	if (!parent_event) {		perf_event_wakeup(child_event);		return;	}	 	sync_child_event(child_event, child);	 	WARN_ON_ONCE(parent_event->ctx->parent_ctx);	mutex_lock(&parent_event->child_mutex);	list_del_init(&child_event->child_list);	mutex_unlock(&parent_event->child_mutex);	 	perf_event_wakeup(parent_event);	free_event(child_event);	put_event(parent_event);}",21901
159,855,CVE-2016-2544,21,"int snd_seq_queue_alloc(int client, int locked, unsigned int info_flags){	struct snd_seq_queue *q;	q = queue_new(client, locked);	if (q == NULL)		return -ENOMEM;	q->info_flags = info_flags;	if (queue_list_add(q) < 0) {		queue_delete(q);		return -ENOMEM;	}	snd_seq_queue_use(q->queue, client, 1);  	return q->queue;}",17529
214,1171,CVE-2017-7533,21,"void shrink_dcache_sb(struct super_block *sb){	long freed;	do {		LIST_HEAD(dispose);		freed = list_lru_walk(&sb->s_dentry_lru,			dentry_lru_isolate_shrink, &dispose, UINT_MAX);		this_cpu_sub(nr_dentry_unused, freed);		shrink_dentry_list(&dispose);	} while (freed > 0);}",21643
343,428,CVE-2014-7842,21,"void kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags){	__kvm_set_rflags(vcpu, rflags);	kvm_make_request(KVM_REQ_EVENT, vcpu);}",10495
309,1097,CVE-2017-7533,21,static inline void __dget_dlock(struct dentry *dentry){	dentry->d_lockref.count++;},21569
248,300,CVE-2011-1768,21,"static void ipip_tunnel_unlink(struct ipip_net *ipn, struct ip_tunnel *t){	struct ip_tunnel **tp;	for (tp = ipip_bucket(ipn, t); *tp; tp = &(*tp)->next) {		if (t == *tp) {			spin_lock_bh(&ipip_lock);			*tp = t->next;			spin_unlock_bh(&ipip_lock);			break;		}	}}",6787
393,802,CVE-2016-6136,21,"void __audit_log_capset(const struct cred *new, const struct cred *old){	struct audit_context *context = current->audit_context;	context->capset.pid = task_pid_nr(current);	context->capset.cap.effective   = new->cap_effective;	context->capset.cap.inheritable = new->cap_effective;	context->capset.cap.permitted   = new->cap_permitted;	context->type = AUDIT_CAPSET;}",16287
207,810,CVE-2016-6136,21,"int audit_alloc(struct task_struct *tsk){	struct audit_context *context;	enum audit_state     state;	char *key = NULL;	if (likely(!audit_ever_enabled))		return 0;  	state = audit_filter_task(tsk, &key);	if (state == AUDIT_DISABLED) {		clear_tsk_thread_flag(tsk, TIF_SYSCALL_AUDIT);		return 0;	}	if (!(context = audit_alloc_context(state))) {		kfree(key);		audit_log_lost(""out of memory in audit_alloc"");		return -ENOMEM;	}	context->filterkey = key;	tsk->audit_context  = context;	set_tsk_thread_flag(tsk, TIF_SYSCALL_AUDIT);	return 0;}",16295
11,665,CVE-2015-3339,21,"void setup_new_exec(struct linux_binprm * bprm){	arch_pick_mmap_layout(current->mm);	 	current->sas_ss_sp = current->sas_ss_size = 0;	if (uid_eq(current_euid(), current_uid()) && gid_eq(current_egid(), current_gid()))		set_dumpable(current->mm, SUID_DUMP_USER);	else		set_dumpable(current->mm, suid_dumpable);	perf_event_exec();	__set_task_comm(current, kbasename(bprm->filename), true);	 	current->mm->task_size = TASK_SIZE;	 	if (!uid_eq(bprm->cred->uid, current_euid()) ||	    !gid_eq(bprm->cred->gid, current_egid())) {		current->pdeath_signal = 0;	} else {		would_dump(bprm, bprm->file);		if (bprm->interp_flags & BINPRM_FLAGS_ENFORCE_NONDUMP)			set_dumpable(current->mm, suid_dumpable);	}	 	current->self_exec_id++;	flush_signal_handlers(current, 0);	do_close_on_exec(current->files);}",13594
228,1431,CVE-2017-18203,21,void dm_issue_global_event(void){	atomic_inc(&dm_global_event_nr);	wake_up(&dm_global_eventq);},25966
252,1289,CVE-2017-6001,21,"perf_event_output_forward(struct perf_event *event,			 struct perf_sample_data *data,			 struct pt_regs *regs){	__perf_event_output(event, data, regs, perf_output_begin_forward);}",21909
199,1164,CVE-2017-7533,21,"static int path_with_deleted(const struct path *path,			     const struct path *root,			     char **buf, int *buflen){	prepend(buf, buflen, ""\0"", 1);	if (d_unlinked(path->dentry)) {		int error = prepend(buf, buflen, "" (deleted)"", 10);		if (error)			return error;	}	return prepend_path(path, root, buf, buflen);}",21636
287,125,CVE-2012-3552,21,static inline void icmp_xmit_unlock(struct sock *sk){	spin_unlock_bh(&sk->sk_lock.slock);},2811
365,1279,CVE-2017-6001,21,int perf_event_exit_cpu(unsigned int cpu){	perf_event_exit_cpu_context(cpu);	return 0;},21899
59,1464,CVE-2017-18203,21,static unsigned get_num_discard_bios(struct dm_target *ti){	return ti->num_discard_bios;},25999
291,1052,CVE-2017-12146,21,"int __platform_driver_register(struct platform_driver *drv,				struct module *owner){	drv->driver.owner = owner;	drv->driver.bus = &platform_bus_type;	drv->driver.probe = platform_drv_probe;	drv->driver.remove = platform_drv_remove;	drv->driver.shutdown = platform_drv_shutdown;	return driver_register(&drv->driver);}",20419
410,16,CVE-2012-1174,21,"int dir_is_empty(const char *path) {        DIR *d;        int r;        struct dirent buf, *de;        if (!(d = opendir(path)))                return -errno;        for (;;) {                if ((r = readdir_r(d, &buf, &de)) > 0) {                        r = -r;                        break;                }                if (!de) {                        r = 1;                        break;                }                if (!ignore_file(de->d_name)) {                        r = 0;                        break;                }        }        closedir(d);        return r;}",1981
273,1103,CVE-2017-7533,21,"struct dentry *d_alloc(struct dentry * parent, const struct qstr *name){	struct dentry *dentry = __d_alloc(parent->d_sb, name);	if (!dentry)		return NULL;	dentry->d_flags |= DCACHE_RCUACCESS;	spin_lock(&parent->d_lock);	 	__dget_dlock(parent);	dentry->d_parent = parent;	list_add(&dentry->d_child, &parent->d_subdirs);	spin_unlock(&parent->d_lock);	return dentry;}",21575
257,105,CVE-2012-3552,21,"int inet_ctl_sock_create(struct sock **sk, unsigned short family,			 unsigned short type, unsigned char protocol,			 struct net *net){	struct socket *sock;	int rc = sock_create_kern(family, type, protocol, &sock);	if (rc == 0) {		*sk = sock->sk;		(*sk)->sk_allocation = GFP_ATOMIC;		 		(*sk)->sk_prot->unhash(*sk);		sk_change_net(*sk, net);	}	return rc;}",2791
351,1371,CVE-2017-18224,21,"static void ocfs2_dio_free_write_ctx(struct inode *inode,				     struct ocfs2_dio_write_ctxt *dwc){	ocfs2_free_unwritten_list(inode, &dwc->dw_zero_list);	kfree(dwc);}",25787
231,324,CVE-2011-1768,21,"static inline struct ip_tunnel **ipip6_bucket(struct sit_net *sitn,		struct ip_tunnel *t){	return __ipip6_bucket(sitn, &t->parms);}",6811
297,157,CVE-2012-3552,21,"static void ip_cmsg_recv_retopts(struct msghdr *msg, struct sk_buff *skb){	unsigned char optbuf[sizeof(struct ip_options) + 40];	struct ip_options * opt = (struct ip_options *)optbuf;	if (IPCB(skb)->opt.optlen == 0)		return;	if (ip_options_echo(opt, skb)) {		msg->msg_flags |= MSG_CTRUNC;		return;	}	ip_options_undo(opt);	put_cmsg(msg, SOL_IP, IP_RETOPTS, opt->optlen, opt->__data);}",2843
263,1400,CVE-2017-18203,21,"static void close_table_device(struct table_device *td, struct mapped_device *md){	if (!td->dm_dev.bdev)		return;	bd_unlink_disk_holder(td->dm_dev.bdev, dm_disk(md));	blkdev_put(td->dm_dev.bdev, td->dm_dev.mode | FMODE_EXCL);	put_dax(td->dm_dev.dax_dev);	td->dm_dev.bdev = NULL;	td->dm_dev.dax_dev = NULL;}",25935
17,370,CVE-2013-3302,21,"wait_for_response(struct TCP_Server_Info *server, struct mid_q_entry *midQ){	int error;	error = wait_event_freezekillable(server->response_q,				    midQ->mid_state != MID_REQUEST_SUBMITTED);	if (error < 0)		return -ERESTARTSYS;	return 0;}",8021
185,942,CVE-2016-0723,21,"static int tty_write_lock(struct tty_struct *tty, int ndelay){	if (!mutex_trylock(&tty->atomic_write_lock)) {		if (ndelay)			return -EAGAIN;		if (mutex_lock_interruptible(&tty->atomic_write_lock))			return -ERESTARTSYS;	}	return 0;}",18285
143,1360,CVE-2017-18249,21,"static void clear_node_page_dirty(struct page *page){	struct address_space *mapping = page->mapping;	unsigned int long flags;	if (PageDirty(page)) {		spin_lock_irqsave(&mapping->tree_lock, flags);		radix_tree_tag_clear(&mapping->page_tree,				page_index(page),				PAGECACHE_TAG_DIRTY);		spin_unlock_irqrestore(&mapping->tree_lock, flags);		clear_page_dirty_for_io(page);		dec_page_count(F2FS_M_SB(mapping), F2FS_DIRTY_NODES);	}	ClearPageUptodate(page);}",25678
18,1273,CVE-2017-6001,21,void perf_event_addr_filters_sync(struct perf_event *event){	struct perf_addr_filters_head *ifh = perf_event_addr_filters(event);	if (!has_addr_filter(event))		return;	raw_spin_lock(&ifh->lock);	if (event->addr_filters_gen != event->hw.addr_filters_gen) {		event->pmu->addr_filters_sync(event);		event->hw.addr_filters_gen = event->addr_filters_gen;	}	raw_spin_unlock(&ifh->lock);},21893
50,1621,CVE-2019-11599,21,"static int pid_numa_maps_open(struct inode *inode, struct file *file){	return proc_maps_open(inode, file, &proc_pid_numa_maps_op,				sizeof(struct numa_maps_private));}",27068
336,221,CVE-2012-3552,21,"static void get_openreq6(struct seq_file *seq,			 struct sock *sk, struct request_sock *req, int i, int uid){	int ttd = req->expires - jiffies;	const struct in6_addr *src = &inet6_rsk(req)->loc_addr;	const struct in6_addr *dest = &inet6_rsk(req)->rmt_addr;	if (ttd < 0)		ttd = 0;	seq_printf(seq,		   ""%4d: %08X%08X%08X%08X:%04X %08X%08X%08X%08X:%04X ""		   ""%02X %08X:%08X %02X:%08lX %08X %5d %8d %d %d %p\n"",		   i,		   src->s6_addr32[0], src->s6_addr32[1],		   src->s6_addr32[2], src->s6_addr32[3],		   ntohs(inet_rsk(req)->loc_port),		   dest->s6_addr32[0], dest->s6_addr32[1],		   dest->s6_addr32[2], dest->s6_addr32[3],		   ntohs(inet_rsk(req)->rmt_port),		   TCP_SYN_RECV,		   0,0,  		   1,    		   jiffies_to_clock_t(ttd),		   req->retrans,		   uid,		   0,   		   0,  		   0, req);}",2907
44,1224,CVE-2017-7533,21,"mountpoint_last(struct nameidata *nd){	int error = 0;	struct dentry *dir = nd->path.dentry;	struct path path;	 	if (nd->flags & LOOKUP_RCU) {		if (unlazy_walk(nd))			return -ECHILD;	}	nd->flags &= ~LOOKUP_PARENT;	if (unlikely(nd->last_type != LAST_NORM)) {		error = handle_dots(nd, nd->last_type);		if (error)			return error;		path.dentry = dget(nd->path.dentry);	} else {		path.dentry = d_lookup(dir, &nd->last);		if (!path.dentry) {			 			path.dentry = lookup_slow(&nd->last, dir,					     nd->flags | LOOKUP_NO_REVAL);			if (IS_ERR(path.dentry))				return PTR_ERR(path.dentry);		}	}	if (d_is_negative(path.dentry)) {		dput(path.dentry);		return -ENOENT;	}	path.mnt = nd->path.mnt;	return step_into(nd, &path, 0, d_backing_inode(path.dentry), 0);}",21696
399,1662,CVE-2019-11599,21,static struct vm_area_struct *remove_vma(struct vm_area_struct *vma){	struct vm_area_struct *next = vma->vm_next;	might_sleep();	if (vma->vm_ops && vma->vm_ops->close)		vma->vm_ops->close(vma);	if (vma->vm_file)		fput(vma->vm_file);	mpol_put(vma_policy(vma));	vm_area_free(vma);	return next;},27109
406,1639,CVE-2019-11599,21,"void __vma_link_rb(struct mm_struct *mm, struct vm_area_struct *vma,		struct rb_node **rb_link, struct rb_node *rb_parent){	 	if (vma->vm_next)		vma_gap_update(vma->vm_next);	else		mm->highest_vm_end = vm_end_gap(vma);	 	rb_link_node(&vma->vm_rb, rb_parent, rb_link);	vma->rb_subtree_gap = 0;	vma_gap_update(vma);	vma_rb_insert(vma, &mm->mm_rb);}",27086
437,563,CVE-2010-5313,21,"static int emulator_get_cached_descriptor(struct desc_struct *desc, int seg,					   struct kvm_vcpu *vcpu){	struct kvm_segment var;	kvm_get_segment(vcpu, &var, seg);	if (var.unusable)		return false;	if (var.g)		var.limit >>= 12;	set_desc_limit(desc, var.limit);	set_desc_base(desc, (unsigned long)var.base);	desc->type = var.type;	desc->s = var.s;	desc->dpl = var.dpl;	desc->p = var.present;	desc->avl = var.avl;	desc->l = var.l;	desc->d = var.db;	desc->g = var.g;	return true;}",12787
388,155,CVE-2012-3552,21,"static void ip_cmsg_recv_opts(struct msghdr *msg, struct sk_buff *skb){	if (IPCB(skb)->opt.optlen == 0)		return;	put_cmsg(msg, SOL_IP, IP_RECVOPTS, IPCB(skb)->opt.optlen,		 ip_hdr(skb) + 1);}",2841
170,429,CVE-2014-7842,21,"static void kvm_update_dr6(struct kvm_vcpu *vcpu){	if (!(vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP))		kvm_x86_ops->set_dr6(vcpu, vcpu->arch.dr6);}",10496
357,828,CVE-2016-5195,21,"int __mm_populate(unsigned long start, unsigned long len, int ignore_errors){	struct mm_struct *mm = current->mm;	unsigned long end, nstart, nend;	struct vm_area_struct *vma = NULL;	int locked = 0;	long ret = 0;	VM_BUG_ON(start & ~PAGE_MASK);	VM_BUG_ON(len != PAGE_ALIGN(len));	end = start + len;	for (nstart = start; nstart < end; nstart = nend) {		 		if (!locked) {			locked = 1;			down_read(&mm->mmap_sem);			vma = find_vma(mm, nstart);		} else if (nstart >= vma->vm_end)			vma = vma->vm_next;		if (!vma || vma->vm_start >= end)			break;		 		nend = min(end, vma->vm_end);		if (vma->vm_flags & (VM_IO | VM_PFNMAP))			continue;		if (nstart < vma->vm_start)			nstart = vma->vm_start;		 		ret = populate_vma_page_range(vma, nstart, nend, &locked);		if (ret < 0) {			if (ignore_errors) {				ret = 0;				continue;	 			}			break;		}		nend = nstart + ret * PAGE_SIZE;		ret = 0;	}	if (locked)		up_read(&mm->mmap_sem);	return ret;	 }",16507
278,361,CVE-2013-3302,21,"cifs_rqst_page_to_kvec(struct smb_rqst *rqst, unsigned int idx,			struct kvec *iov){	 	iov->iov_base = kmap(rqst->rq_pages[idx]);	 	if (idx == (rqst->rq_npages - 1))		iov->iov_len = rqst->rq_tailsz;	else		iov->iov_len = rqst->rq_pagesz;}",8012
172,413,CVE-2014-7842,21,"static int emulator_pio_in_out(struct kvm_vcpu *vcpu, int size,			       unsigned short port, void *val,			       unsigned int count, int in){	vcpu->arch.pio.port = port;	vcpu->arch.pio.in = in;	vcpu->arch.pio.count  = count;	vcpu->arch.pio.size = size;	if (!kernel_pio(vcpu, vcpu->arch.pio_data)) {		vcpu->arch.pio.count = 0;		return 1;	}	vcpu->run->exit_reason = KVM_EXIT_IO;	vcpu->run->io.direction = in ? KVM_EXIT_IO_IN : KVM_EXIT_IO_OUT;	vcpu->run->io.size = size;	vcpu->run->io.data_offset = KVM_PIO_PAGE_OFFSET * PAGE_SIZE;	vcpu->run->io.count = count;	vcpu->run->io.port = port;	return 0;}",10480
93,135,CVE-2012-3552,21,"void inet_csk_reset_keepalive_timer(struct sock *sk, unsigned long len){	sk_reset_timer(sk, &sk->sk_timer, jiffies + len);}",2821
271,1387,CVE-2017-18203,21,"static int __dm_suspend(struct mapped_device *md, struct dm_table *map,			unsigned suspend_flags, long task_state,			int dmf_suspended_flag){	int do_lockfs = suspend_flags & DM_SUSPEND_LOCKFS_FLAG;	int noflush = suspend_flags & DM_SUSPEND_NOFLUSH_FLAG;	int r;	lockdep_assert_held(&md->suspend_lock);	 	if (noflush)		set_bit(DMF_NOFLUSH_SUSPENDING, &md->flags);	else		pr_debug(""%s: suspending with flush\n"", dm_device_name(md));	 	dm_table_presuspend_targets(map);	 	if (!noflush && do_lockfs) {		r = lock_fs(md);		if (r) {			dm_table_presuspend_undo_targets(map);			return r;		}	}	 	set_bit(DMF_BLOCK_IO_FOR_SUSPEND, &md->flags);	if (map)		synchronize_srcu(&md->io_barrier);	 	if (dm_request_based(md)) {		dm_stop_queue(md->queue);		if (md->kworker_task)			kthread_flush_worker(&md->kworker);	}	flush_workqueue(md->wq);	 	r = dm_wait_for_completion(md, task_state);	if (!r)		set_bit(dmf_suspended_flag, &md->flags);	if (noflush)		clear_bit(DMF_NOFLUSH_SUSPENDING, &md->flags);	if (map)		synchronize_srcu(&md->io_barrier);	 	if (r < 0) {		dm_queue_flush(md);		if (dm_request_based(md))			dm_start_queue(md->queue);		unlock_fs(md);		dm_table_presuspend_undo_targets(map);		 	}	return r;}",25922
61,425,CVE-2014-7842,21,"int kvm_arch_vcpu_runnable(struct kvm_vcpu *vcpu){	if (is_guest_mode(vcpu) && kvm_x86_ops->check_nested_events)		kvm_x86_ops->check_nested_events(vcpu, false);	return (vcpu->arch.mp_state == KVM_MP_STATE_RUNNABLE &&		!vcpu->arch.apf.halted)		|| !list_empty_careful(&vcpu->async_pf.done)		|| kvm_apic_has_events(vcpu)		|| vcpu->arch.pv.pv_unhalted		|| atomic_read(&vcpu->arch.nmi_queued) ||		(kvm_arch_interrupt_allowed(vcpu) &&		 kvm_cpu_has_interrupt(vcpu));}",10492
422,885,CVE-2016-0723,21,"void disassociate_ctty(int on_exit){	struct tty_struct *tty;	if (!current->signal->leader)		return;	tty = get_current_tty();	if (tty) {		if (on_exit && tty->driver->type != TTY_DRIVER_TYPE_PTY) {			tty_vhangup_session(tty);		} else {			struct pid *tty_pgrp = tty_get_pgrp(tty);			if (tty_pgrp) {				kill_pgrp(tty_pgrp, SIGHUP, on_exit);				if (!on_exit)					kill_pgrp(tty_pgrp, SIGCONT, on_exit);				put_pid(tty_pgrp);			}		}		tty_kref_put(tty);	} else if (on_exit) {		struct pid *old_pgrp;		spin_lock_irq(&current->sighand->siglock);		old_pgrp = current->signal->tty_old_pgrp;		current->signal->tty_old_pgrp = NULL;		spin_unlock_irq(&current->sighand->siglock);		if (old_pgrp) {			kill_pgrp(old_pgrp, SIGHUP, on_exit);			kill_pgrp(old_pgrp, SIGCONT, on_exit);			put_pid(old_pgrp);		}		return;	}	spin_lock_irq(&current->sighand->siglock);	put_pid(current->signal->tty_old_pgrp);	current->signal->tty_old_pgrp = NULL;	tty = tty_kref_get(current->signal->tty);	if (tty) {		unsigned long flags;		spin_lock_irqsave(&tty->ctrl_lock, flags);		put_pid(tty->session);		put_pid(tty->pgrp);		tty->session = NULL;		tty->pgrp = NULL;		spin_unlock_irqrestore(&tty->ctrl_lock, flags);		tty_kref_put(tty);	} else		tty_debug_hangup(tty, ""no current tty\n"");	spin_unlock_irq(&current->sighand->siglock);	 	read_lock(&tasklist_lock);	session_clear_tty(task_session(current));	read_unlock(&tasklist_lock);}",18228
227,183,CVE-2012-3552,21,"void tcp_proc_unregister(struct net *net, struct tcp_seq_afinfo *afinfo){	proc_net_remove(net, afinfo->name);}",2869
127,915,CVE-2016-0723,21,"static struct tty_struct *tty_driver_lookup_tty(struct tty_driver *driver,		struct inode *inode, int idx){	struct tty_struct *tty;	if (driver->ops->lookup)		tty = driver->ops->lookup(driver, inode, idx);	else		tty = driver->ttys[idx];	if (!IS_ERR(tty))		tty_kref_get(tty);	return tty;}",18258
95,844,CVE-2016-2544,21,"static int queue_access_lock(struct snd_seq_queue *q, int client){	unsigned long flags;	int access_ok;		spin_lock_irqsave(&q->owner_lock, flags);	access_ok = check_access(q, client);	if (access_ok)		q->klocked = 1;	spin_unlock_irqrestore(&q->owner_lock, flags);	return access_ok;}",17518
238,631,CVE-2015-7613,21,"static int testmsg(struct msg_msg *msg, long type, int mode){	switch (mode) {	case SEARCH_ANY:	case SEARCH_NUMBER:		return 1;	case SEARCH_LESSEQUAL:		if (msg->m_type <= type)			return 1;		break;	case SEARCH_EQUAL:		if (msg->m_type == type)			return 1;		break;	case SEARCH_NOTEQUAL:		if (msg->m_type != type)			return 1;		break;	}	return 0;}",13069
33,359,CVE-2013-3302,21,"cifs_check_receive(struct mid_q_entry *mid, struct TCP_Server_Info *server,		   int log_error){	unsigned int len = get_rfc1002_length(mid->resp_buf) + 4;	dump_smb(mid->resp_buf, min_t(u32, 92, len));	 	if (server->sec_mode & (SECMODE_SIGN_REQUIRED | SECMODE_SIGN_ENABLED)) {		struct kvec iov;		int rc = 0;		struct smb_rqst rqst = { .rq_iov = &iov,					 .rq_nvec = 1 };		iov.iov_base = mid->resp_buf;		iov.iov_len = len;		 		rc = cifs_verify_signature(&rqst, server,					   mid->sequence_number + 1);		if (rc)			cERROR(1, ""SMB signature verification returned error = ""			       ""%d"", rc);	}	 	return map_smb_to_linux_error(mid->resp_buf, log_error);}",8010
364,789,CVE-2016-7916,21,"static void timers_stop(struct seq_file *m, void *v){	struct timers_private *tp = m->private;	if (tp->sighand) {		unlock_task_sighand(tp->task, &tp->flags);		tp->sighand = NULL;	}	if (tp->task) {		put_task_struct(tp->task);		tp->task = NULL;	}}",15645
302,1362,CVE-2017-18249,21,"static int f2fs_set_node_page_dirty(struct page *page){	trace_f2fs_set_page_dirty(page, NODE);	if (!PageUptodate(page))		SetPageUptodate(page);	if (!PageDirty(page)) {		f2fs_set_page_dirty_nobuffers(page);		inc_page_count(F2FS_P_SB(page), F2FS_DIRTY_NODES);		SetPagePrivate(page);		f2fs_trace_pid(page);		return 1;	}	return 0;}",25680
23,1239,CVE-2017-6001,21,"static void __perf_event_enable(struct perf_event *event,				struct perf_cpu_context *cpuctx,				struct perf_event_context *ctx,				void *info){	struct perf_event *leader = event->group_leader;	struct perf_event_context *task_ctx;	if (event->state >= PERF_EVENT_STATE_INACTIVE ||	    event->state <= PERF_EVENT_STATE_ERROR)		return;	if (ctx->is_active)		ctx_sched_out(ctx, cpuctx, EVENT_TIME);	__perf_event_mark_enabled(event);	if (!ctx->is_active)		return;	if (!event_filter_match(event)) {		if (is_cgroup_event(event))			perf_cgroup_defer_enabled(event);		ctx_sched_in(ctx, cpuctx, EVENT_TIME, current);		return;	}	 	if (leader != event && leader->state != PERF_EVENT_STATE_ACTIVE) {		ctx_sched_in(ctx, cpuctx, EVENT_TIME, current);		return;	}	task_ctx = cpuctx->task_ctx;	if (ctx->task)		WARN_ON_ONCE(task_ctx != ctx);	ctx_resched(cpuctx, task_ctx);}",21859
256,853,CVE-2016-2544,21,"int snd_seq_enqueue_event(struct snd_seq_event_cell *cell, int atomic, int hop){	int dest, err;	struct snd_seq_queue *q;	if (snd_BUG_ON(!cell))		return -EINVAL;	dest = cell->event.queue;	 	q = queueptr(dest);	if (q == NULL)		return -EINVAL;	 	if ((cell->event.flags & SNDRV_SEQ_TIME_MODE_MASK) == SNDRV_SEQ_TIME_MODE_REL) {		switch (cell->event.flags & SNDRV_SEQ_TIME_STAMP_MASK) {		case SNDRV_SEQ_TIME_STAMP_TICK:			cell->event.time.tick += q->timer->tick.cur_tick;			break;		case SNDRV_SEQ_TIME_STAMP_REAL:			snd_seq_inc_real_time(&cell->event.time.time,					      &q->timer->cur_time);			break;		}		cell->event.flags &= ~SNDRV_SEQ_TIME_MODE_MASK;		cell->event.flags |= SNDRV_SEQ_TIME_MODE_ABS;	}	 	switch (cell->event.flags & SNDRV_SEQ_TIME_STAMP_MASK) {	case SNDRV_SEQ_TIME_STAMP_TICK:		err = snd_seq_prioq_cell_in(q->tickq, cell);		break;	case SNDRV_SEQ_TIME_STAMP_REAL:	default:		err = snd_seq_prioq_cell_in(q->timeq, cell);		break;	}	if (err < 0) {		queuefree(q);  		return err;	}	 	snd_seq_check_queue(q, atomic, hop);	queuefree(q);  	return 0;}",17527
135,1680,CVE-2019-11599,21,"static void vma_link(struct mm_struct *mm, struct vm_area_struct *vma,			struct vm_area_struct *prev, struct rb_node **rb_link,			struct rb_node *rb_parent){	struct address_space *mapping = NULL;	if (vma->vm_file) {		mapping = vma->vm_file->f_mapping;		i_mmap_lock_write(mapping);	}	__vma_link(mm, vma, prev, rb_link, rb_parent);	__vma_link_file(vma);	if (mapping)		i_mmap_unlock_write(mapping);	mm->map_count++;	validate_mm(mm);}",27127
97,283,CVE-2011-2183,21,"static void remove_rmap_item_from_tree(struct rmap_item *rmap_item){	if (rmap_item->address & STABLE_FLAG) {		struct stable_node *stable_node;		struct page *page;		stable_node = rmap_item->head;		page = get_ksm_page(stable_node);		if (!page)			goto out;		lock_page(page);		hlist_del(&rmap_item->hlist);		unlock_page(page);		put_page(page);		if (stable_node->hlist.first)			ksm_pages_sharing--;		else			ksm_pages_shared--;		put_anon_vma(rmap_item->anon_vma);		rmap_item->address &= PAGE_MASK;	} else if (rmap_item->address & UNSTABLE_FLAG) {		unsigned char age;		 		age = (unsigned char)(ksm_scan.seqnr - rmap_item->address);		BUG_ON(age > 1);		if (!age)			rb_erase(&rmap_item->node, &root_unstable_tree);		ksm_pages_unshared--;		rmap_item->address &= PAGE_MASK;	}out:	cond_resched();		 }",6750
200,1486,CVE-2015-9016,21,"static int blk_flush_complete_seq(struct request *rq,				   struct blk_flush_queue *fq,				   unsigned int seq, int error){	struct request_queue *q = rq->q;	struct list_head *pending = &fq->flush_queue[fq->flush_pending_idx];	int queued = false, kicked;	BUG_ON(rq->flush.seq & seq);	rq->flush.seq |= seq;	if (likely(!error))		seq = blk_flush_cur_seq(rq);	else		seq = REQ_FSEQ_DONE;	switch (seq) {	case REQ_FSEQ_PREFLUSH:	case REQ_FSEQ_POSTFLUSH:		 		if (list_empty(pending))			fq->flush_pending_since = jiffies;		list_move_tail(&rq->flush.list, pending);		break;	case REQ_FSEQ_DATA:		list_move_tail(&rq->flush.list, &fq->flush_data_in_flight);		queued = blk_flush_queue_rq(rq, true);		break;	case REQ_FSEQ_DONE:		 		BUG_ON(!list_empty(&rq->queuelist));		list_del_init(&rq->flush.list);		blk_flush_restore_request(rq);		if (q->mq_ops)			blk_mq_end_request(rq, error);		else			__blk_end_request_all(rq, error);		break;	default:		BUG();	}	kicked = blk_kick_flush(q, fq);	return kicked | queued;}",26265
303,39,CVE-2012-1174,21,"char *path_kill_slashes(char *path) {        char *f, *t;        int slash = false;                 for (f = path, t = path; *f; f++) {                if (*f == '/') {                        slash = true;                        continue;                }                if (slash) {                        slash = false;                        *(t++) = '/';                }                *(t++) = *f;        }                 if (t == path && slash)                *(t++) = '/';        *t = 0;        return path;}",2004
330,875,CVE-2016-2069,21,"void native_flush_tlb_others(const struct cpumask *cpumask,				 struct mm_struct *mm, unsigned long start,				 unsigned long end){	struct flush_tlb_info info;	info.flush_mm = mm;	info.flush_start = start;	info.flush_end = end;	count_vm_tlb_event(NR_TLB_REMOTE_FLUSH);	trace_tlb_flush(TLB_REMOTE_SEND_IPI, end - start);	if (is_uv_system()) {		unsigned int cpu;		cpu = smp_processor_id();		cpumask = uv_flush_tlb_others(cpumask, mm, start, end, cpu);		if (cpumask)			smp_call_function_many(cpumask, flush_tlb_func,								&info, 1);		return;	}	smp_call_function_many(cpumask, flush_tlb_func, &info, 1);}",18024
128,90,CVE-2012-3552,21,static void dccp_v4_reqsk_destructor(struct request_sock *req){	dccp_feat_list_purge(&dccp_rsk(req)->dreq_featneg);	kfree(inet_rsk(req)->opt);},2776
296,1642,CVE-2019-11599,21,"struct vm_area_struct *_install_special_mapping(	struct mm_struct *mm,	unsigned long addr, unsigned long len,	unsigned long vm_flags, const struct vm_special_mapping *spec){	return __install_special_mapping(mm, addr, len, vm_flags, (void *)spec,					&special_mapping_vmops);}",27089
149,736,CVE-2014-9710,21,"static int btrfs_is_valid_xattr(const char *name){	return !strncmp(name, XATTR_SECURITY_PREFIX,			XATTR_SECURITY_PREFIX_LEN) ||	       !strncmp(name, XATTR_SYSTEM_PREFIX, XATTR_SYSTEM_PREFIX_LEN) ||	       !strncmp(name, XATTR_TRUSTED_PREFIX, XATTR_TRUSTED_PREFIX_LEN) ||	       !strncmp(name, XATTR_USER_PREFIX, XATTR_USER_PREFIX_LEN) ||		!strncmp(name, XATTR_BTRFS_PREFIX, XATTR_BTRFS_PREFIX_LEN);}",14153
355,837,CVE-2016-5195,21,"static struct page *no_page_table(struct vm_area_struct *vma,		unsigned int flags){	 	if ((flags & FOLL_DUMP) && (!vma->vm_ops || !vma->vm_ops->fault))		return ERR_PTR(-EFAULT);	return NULL;}",16516
190,1778,CVE-2014-3611,21,"void __kvm_migrate_pit_timer(struct kvm_vcpu *vcpu){	struct kvm_pit *pit = vcpu->kvm->arch.vpit;	struct hrtimer *timer;	if (!kvm_vcpu_is_bsp(vcpu) || !pit) 		return;  	timer = &pit->pit_state.timer; 	if (hrtimer_cancel(timer)) 		hrtimer_start_expires(timer, HRTIMER_MODE_ABS); }",31153
3,1729,CVE-2015-5232,21,"usage(char *cmd){	int i;	fprintf(stderr, ""USAGE: %s"", cmd);	fprintf(stderr, "" [OPTIONS] COMMAND [COMMAND ARGS]\n\n"");	fprintf(stderr,			""OPTIONS:\n"");	fprintf(stderr, ""  -i <VAL>\t\tinstance to connect to (0 - default)\n"");	fprintf(stderr,			""COMMANDS:\n"");	for(i=0;i<commandListLen;i++){		fprintf(stderr, ""  %-21s %s\n"",commandList[i].name,commandList[i].desc);	}	fflush(stderr);}",28834
4,1007,CVE-2015-8839,21,"static int set_journal_csum_feature_set(struct super_block *sb){	int ret = 1;	int compat, incompat;	struct ext4_sb_info *sbi = EXT4_SB(sb);	if (ext4_has_metadata_csum(sb)) {		 		compat = 0;		incompat = JBD2_FEATURE_INCOMPAT_CSUM_V3;	} else {		 		compat = JBD2_FEATURE_COMPAT_CHECKSUM;		incompat = 0;	}	jbd2_journal_clear_features(sbi->s_journal,			JBD2_FEATURE_COMPAT_CHECKSUM, 0,			JBD2_FEATURE_INCOMPAT_CSUM_V3 |			JBD2_FEATURE_INCOMPAT_CSUM_V2);	if (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {		ret = jbd2_journal_set_features(sbi->s_journal,				compat, 0,				JBD2_FEATURE_INCOMPAT_ASYNC_COMMIT |				incompat);	} else if (test_opt(sb, JOURNAL_CHECKSUM)) {		ret = jbd2_journal_set_features(sbi->s_journal,				compat, 0,				incompat);		jbd2_journal_clear_features(sbi->s_journal, 0, 0,				JBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);	} else {		jbd2_journal_clear_features(sbi->s_journal, 0, 0,				JBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);	}	return ret;}",18577
338,295,CVE-2011-1768,21,"static void ipip_tunnel_init(struct net_device *dev){	struct ip_tunnel *tunnel = netdev_priv(dev);	tunnel->dev = dev;	strcpy(tunnel->parms.name, dev->name);	memcpy(dev->dev_addr, &tunnel->parms.iph.saddr, 4);	memcpy(dev->broadcast, &tunnel->parms.iph.daddr, 4);	ipip_tunnel_bind_dev(dev);}",6782
25,1703,CVE-2019-6974,21,"int kvm_write_guest_cached(struct kvm *kvm, struct gfn_to_hva_cache *ghc,			   void *data, unsigned long len){	return kvm_write_guest_offset_cached(kvm, ghc, data, 0, len);}",27380
341,1359,CVE-2017-18249,21,"int build_node_manager(struct f2fs_sb_info *sbi){	int err;	sbi->nm_info = kzalloc(sizeof(struct f2fs_nm_info), GFP_KERNEL);	if (!sbi->nm_info)		return -ENOMEM;	err = init_node_manager(sbi);	if (err)		return err;	err = init_free_nid_cache(sbi);	if (err)		return err;	 	load_free_nid_bitmap(sbi);	build_free_nids(sbi, true, true);	return 0;}",25677
48,1695,CVE-2019-6974,21,void kvm_put_kvm(struct kvm *kvm){	if (refcount_dec_and_test(&kvm->users_count))		kvm_destroy_vm(kvm);},27372
326,1620,CVE-2019-11599,21,"static int pagemap_release(struct inode *inode, struct file *file){	struct mm_struct *mm = file->private_data;	if (mm)		mmdrop(mm);	return 0;}",27067
198,409,CVE-2014-7842,21,"static int __vcpu_run(struct kvm_vcpu *vcpu){	int r;	struct kvm *kvm = vcpu->kvm;	vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);	r = 1;	while (r > 0) {		if (vcpu->arch.mp_state == KVM_MP_STATE_RUNNABLE &&		    !vcpu->arch.apf.halted)			r = vcpu_enter_guest(vcpu);		else {			srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);			kvm_vcpu_block(vcpu);			vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);			if (kvm_check_request(KVM_REQ_UNHALT, vcpu)) {				kvm_apic_accept_events(vcpu);				switch(vcpu->arch.mp_state) {				case KVM_MP_STATE_HALTED:					vcpu->arch.pv.pv_unhalted = false;					vcpu->arch.mp_state =						KVM_MP_STATE_RUNNABLE;				case KVM_MP_STATE_RUNNABLE:					vcpu->arch.apf.halted = false;					break;				case KVM_MP_STATE_INIT_RECEIVED:					break;				default:					r = -EINTR;					break;				}			}		}		if (r <= 0)			break;		clear_bit(KVM_REQ_PENDING_TIMER, &vcpu->requests);		if (kvm_cpu_has_pending_timer(vcpu))			kvm_inject_pending_timer_irqs(vcpu);		if (dm_request_for_irq_injection(vcpu)) {			r = -EINTR;			vcpu->run->exit_reason = KVM_EXIT_INTR;			++vcpu->stat.request_irq_exits;		}		kvm_check_async_pf_completion(vcpu);		if (signal_pending(current)) {			r = -EINTR;			vcpu->run->exit_reason = KVM_EXIT_INTR;			++vcpu->stat.signal_exits;		}		if (need_resched()) {			srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);			cond_resched();			vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);		}	}	srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);	return r;}",10476
376,1112,CVE-2017-7533,21,struct dentry *d_find_any_alias(struct inode *inode){	struct dentry *de;	spin_lock(&inode->i_lock);	de = __d_find_any_alias(inode);	spin_unlock(&inode->i_lock);	return de;},21584
342,1498,CVE-2015-9016,21,"void __blk_mq_tag_idle(struct blk_mq_hw_ctx *hctx){	struct blk_mq_tags *tags = hctx->tags;	if (!test_and_clear_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state))		return;	atomic_dec(&tags->active_queues);	blk_mq_tag_wakeup_all(tags, false);}",26277
43,1678,CVE-2019-11599,21,"static void vm_unlock_mapping(struct address_space *mapping){	if (test_bit(AS_MM_ALL_LOCKS, &mapping->flags)) {		 		i_mmap_unlock_write(mapping);		if (!test_and_clear_bit(AS_MM_ALL_LOCKS,					&mapping->flags))			BUG();	}}",27125
181,637,CVE-2015-7613,21,"void *ipc_alloc(int size){	void *out;	if (size > PAGE_SIZE)		out = vmalloc(size);	else		out = kmalloc(size, GFP_KERNEL);	return out;}",13075
96,321,CVE-2011-1768,21,"ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev){	struct ip6_tnl *t = netdev_priv(dev);	struct net_device_stats *stats = &t->dev->stats;	int ret;	switch (skb->protocol) {	case htons(ETH_P_IP):		ret = ip4ip6_tnl_xmit(skb, dev);		break;	case htons(ETH_P_IPV6):		ret = ip6ip6_tnl_xmit(skb, dev);		break;	default:		goto tx_err;	}	if (ret < 0)		goto tx_err;	return NETDEV_TX_OK;tx_err:	stats->tx_errors++;	stats->tx_dropped++;	kfree_skb(skb);	return NETDEV_TX_OK;}",6808
134,705,CVE-2014-9710,21,"void btrfs_free_path(struct btrfs_path *p){	if (!p)		return;	btrfs_release_path(p);	kmem_cache_free(btrfs_path_cachep, p);}",14122
85,1204,CVE-2017-7533,21,"unsigned int full_name_hash(const void *salt, const char *name, unsigned int len){	unsigned long a, x = 0, y = (unsigned long)salt;	for (;;) {		if (!len)			goto done;		a = load_unaligned_zeropad(name);		if (len < sizeof(unsigned long))			break;		HASH_MIX(x, y, a);		name += sizeof(unsigned long);		len -= sizeof(unsigned long);	}	x ^= a & bytemask_from_count(len);done:	return fold_hash(x, y);}",21676
29,393,CVE-2011-4348,21,"static void __sctp_hash_endpoint(struct sctp_endpoint *ep){	struct sctp_ep_common *epb;	struct sctp_hashbucket *head;	epb = &ep->base;	epb->hashent = sctp_ep_hashfn(epb->bind_addr.port);	head = &sctp_ep_hashtable[epb->hashent];	sctp_write_lock(&head->lock);	hlist_add_head(&epb->node, &head->chain);	sctp_write_unlock(&head->lock);}",10026
371,822,CVE-2016-6136,21,"static inline int audit_proctitle_rtrim(char *proctitle, int len){	char *end = proctitle + len - 1;	while (end > proctitle && !isprint(*end))		end--;	 	len = end - proctitle + 1;	len -= isprint(proctitle[len-1]) == 0;	return len;}",16307
150,1176,CVE-2017-7533,21,"static struct dentry *debug_mount(struct file_system_type *fs_type,			int flags, const char *dev_name,			void *data){	return mount_single(fs_type, flags, data, debug_fill_super);}",21648
165,504,CVE-2014-2672,21,"static void ath_tx_return_buffer(struct ath_softc *sc, struct ath_buf *bf){	spin_lock_bh(&sc->tx.txbuflock);	list_add_tail(&bf->list, &sc->tx.txbuf);	spin_unlock_bh(&sc->tx.txbuflock);}",11788
176,707,CVE-2014-9710,21,"int btrfs_next_leaf(struct btrfs_root *root, struct btrfs_path *path){	return btrfs_next_old_leaf(root, path, 0);}",14124
187,1591,CVE-2019-11922,21,"static unsigned readU32FromChar(const char** stringPtr){    unsigned result = 0;    while ((**stringPtr >='0') && (**stringPtr <='9'))        result *= 10, result += **stringPtr - '0', (*stringPtr)++ ;    if ((**stringPtr=='K') || (**stringPtr=='M')) {        result <<= 10;        if (**stringPtr=='M') result <<= 10;        (*stringPtr)++ ;        if (**stringPtr=='i') (*stringPtr)++;        if (**stringPtr=='B') (*stringPtr)++;    }    return result;}",26914
41,961,CVE-2015-8839,21,"struct inode *ext4_iget_normal(struct super_block *sb, unsigned long ino){	if (ino < EXT4_FIRST_INO(sb) && ino != EXT4_ROOT_INO)		return ERR_PTR(-EFSCORRUPTED);	return ext4_iget(sb, ino);}",18531
62,973,CVE-2015-8839,21,"void ext4_truncate(struct inode *inode){	struct ext4_inode_info *ei = EXT4_I(inode);	unsigned int credits;	handle_t *handle;	struct address_space *mapping = inode->i_mapping;	 	if (!(inode->i_state & (I_NEW|I_FREEING)))		WARN_ON(!mutex_is_locked(&inode->i_mutex));	trace_ext4_truncate_enter(inode);	if (!ext4_can_truncate(inode))		return;	ext4_clear_inode_flag(inode, EXT4_INODE_EOFBLOCKS);	if (inode->i_size == 0 && !test_opt(inode->i_sb, NO_AUTO_DA_ALLOC))		ext4_set_inode_state(inode, EXT4_STATE_DA_ALLOC_CLOSE);	if (ext4_has_inline_data(inode)) {		int has_inline = 1;		ext4_inline_data_truncate(inode, &has_inline);		if (has_inline)			return;	}	 	if (inode->i_size & (inode->i_sb->s_blocksize - 1)) {		if (ext4_inode_attach_jinode(inode) < 0)			return;	}	if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))		credits = ext4_writepage_trans_blocks(inode);	else		credits = ext4_blocks_for_truncate(inode);	handle = ext4_journal_start(inode, EXT4_HT_TRUNCATE, credits);	if (IS_ERR(handle)) {		ext4_std_error(inode->i_sb, PTR_ERR(handle));		return;	}	if (inode->i_size & (inode->i_sb->s_blocksize - 1))		ext4_block_truncate_page(handle, mapping, inode->i_size);	 	if (ext4_orphan_add(handle, inode))		goto out_stop;	down_write(&EXT4_I(inode)->i_data_sem);	ext4_discard_preallocations(inode);	if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))		ext4_ext_truncate(handle, inode);	else		ext4_ind_truncate(handle, inode);	up_write(&ei->i_data_sem);	if (IS_SYNC(inode))		ext4_handle_sync(handle);out_stop:	 	if (inode->i_nlink)		ext4_orphan_del(handle, inode);	inode->i_mtime = inode->i_ctime = ext4_current_time(inode);	ext4_mark_inode_dirty(handle, inode);	ext4_journal_stop(handle);	trace_ext4_truncate_exit(inode);}",18543
67,1583,CVE-2019-13233,21,"int insn_get_modrm_rm_off(struct insn *insn, struct pt_regs *regs){	return get_reg_offset(insn, regs, REG_TYPE_RM);}",26737
415,1456,CVE-2017-18203,21,"static int dm_wait_for_completion(struct mapped_device *md, long task_state){	int r = 0;	DEFINE_WAIT(wait);	while (1) {		prepare_to_wait(&md->wait, &wait, task_state);		if (!md_in_flight(md))			break;		if (signal_pending_state(task_state, current)) {			r = -EINTR;			break;		}		io_schedule();	}	finish_wait(&md->wait, &wait);	return r;}",25991
403,1728,CVE-2016-10741,21,"xfs_vm_writepages(	struct address_space	*mapping,	struct writeback_control *wbc){	struct xfs_writepage_ctx wpc = {		.io_type = XFS_IO_INVALID,	};	int			ret;	xfs_iflags_clear(XFS_I(mapping->host), XFS_ITRUNCATED);	if (dax_mapping(mapping))		return dax_writeback_mapping_range(mapping,				xfs_find_bdev_for_inode(mapping->host), wbc);	ret = write_cache_pages(mapping, wbc, xfs_do_writepage, &wpc);	if (wpc.ioend)		ret = xfs_submit_ioend(wbc, wpc.ioend, ret);	return ret;}",28143
215,643,CVE-2015-7613,21,int ipc_parse_version(int *cmd){	if (*cmd & IPC_64) {		*cmd ^= IPC_64;		return IPC_64;	} else {		return IPC_OLD;	}},13081
158,1548,CVE-2015-9016,21,"void blk_mq_freeze_queue_start(struct request_queue *q){	int freeze_depth;	freeze_depth = atomic_inc_return(&q->mq_freeze_depth);	if (freeze_depth == 1) {		percpu_ref_kill(&q->mq_usage_counter);		blk_mq_run_hw_queues(q, false);	}}",26327
394,1243,CVE-2017-6001,21,"static int  __perf_install_in_context(void *info){	struct perf_event *event = info;	struct perf_event_context *ctx = event->ctx;	struct perf_cpu_context *cpuctx = __get_cpu_context(ctx);	struct perf_event_context *task_ctx = cpuctx->task_ctx;	int reprogram = true;	int ret = 0;	raw_spin_lock(&cpuctx->ctx.lock);	if (ctx->task) {		raw_spin_lock(&ctx->lock);		task_ctx = ctx;		reprogram = (ctx->task == current);		 		if (task_curr(ctx->task) && !reprogram) {			ret = -ESRCH;			goto unlock;		}		WARN_ON_ONCE(reprogram && cpuctx->task_ctx && cpuctx->task_ctx != ctx);	} else if (task_ctx) {		raw_spin_lock(&task_ctx->lock);	}	if (reprogram) {		ctx_sched_out(ctx, cpuctx, EVENT_TIME);		add_event_to_ctx(event, ctx);		ctx_resched(cpuctx, task_ctx);	} else {		add_event_to_ctx(event, ctx);	}unlock:	perf_ctx_unlock(cpuctx, task_ctx);	return ret;}",21863
353,1076,CVE-2017-12146,21,"int platform_pm_freeze(struct device *dev){	struct device_driver *drv = dev->driver;	int ret = 0;	if (!drv)		return 0;	if (drv->pm) {		if (drv->pm->freeze)			ret = drv->pm->freeze(dev);	} else {		ret = platform_legacy_suspend(dev, PMSG_FREEZE);	}	return ret;}",20443
423,141,CVE-2012-3552,21,"int __ip_local_out(struct sk_buff *skb){	struct iphdr *iph = ip_hdr(skb);	iph->tot_len = htons(skb->len);	ip_send_check(iph);	return nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT, skb, NULL,		       skb_dst(skb)->dev, dst_output);}",2827
82,682,CVE-2015-3212,21,"static void sctp_wait_for_close(struct sock *sk, long timeout){	DEFINE_WAIT(wait);	do {		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);		if (list_empty(&sctp_sk(sk)->ep->asocs))			break;		release_sock(sk);		timeout = schedule_timeout(timeout);		lock_sock(sk);	} while (!signal_pending(current) && timeout);	finish_wait(sk_sleep(sk), &wait);}",13634
94,1641,CVE-2019-11599,21,"static inline void __vma_unlink_prev(struct mm_struct *mm,				     struct vm_area_struct *vma,				     struct vm_area_struct *prev){	__vma_unlink_common(mm, vma, prev, true, vma);}",27088
213,1391,CVE-2017-18203,21,"static int __send_empty_flush(struct clone_info *ci){	unsigned target_nr = 0;	struct dm_target *ti;	BUG_ON(bio_has_data(ci->bio));	while ((ti = dm_table_get_target(ci->map, target_nr++)))		__send_duplicate_bios(ci, ti, ti->num_flush_bios, NULL);	return 0;}",25926
441,414,CVE-2014-7842,21,"static int emulator_pio_out_emulated(struct x86_emulate_ctxt *ctxt,				     int size, unsigned short port,				     const void *val, unsigned int count){	struct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);	memcpy(vcpu->arch.pio_data, val, size * count);	trace_kvm_pio(KVM_PIO_OUT, port, size, count, vcpu->arch.pio_data);	return emulator_pio_in_out(vcpu, size, port, (void *)val, count, false);}",10481
35,741,CVE-2016-7916,21,"static int environ_open(struct inode *inode, struct file *file){	return __mem_open(inode, file, PTRACE_MODE_READ);}",15597
401,142,CVE-2012-3552,21,"int ip_append_data(struct sock *sk,		   int getfrag(void *from, char *to, int offset, int len,			       int odd, struct sk_buff *skb),		   void *from, int length, int transhdrlen,		   struct ipcm_cookie *ipc, struct rtable **rtp,		   unsigned int flags){	struct inet_sock *inet = inet_sk(sk);	int err;	if (flags&MSG_PROBE)		return 0;	if (skb_queue_empty(&sk->sk_write_queue)) {		err = ip_setup_cork(sk, &inet->cork, ipc, rtp);		if (err)			return err;	} else {		transhdrlen = 0;	}	return __ip_append_data(sk, &sk->sk_write_queue, &inet->cork, getfrag,				from, length, transhdrlen, flags);}",2828
427,807,CVE-2016-6136,21,"int __audit_socketcall(int nargs, unsigned long *args){	struct audit_context *context = current->audit_context;	if (nargs <= 0 || nargs > AUDITSC_ARGS || !args)		return -EINVAL;	context->type = AUDIT_SOCKETCALL;	context->socketcall.nargs = nargs;	memcpy(context->socketcall.args, args, nargs * sizeof(unsigned long));	return 0;}",16292
233,201,CVE-2012-3552,21,"static int __udp_queue_rcv_skb(struct sock *sk, struct sk_buff *skb){	int rc;	if (inet_sk(sk)->inet_daddr)		sock_rps_save_rxhash(sk, skb->rxhash);	rc = ip_queue_rcv_skb(sk, skb);	if (rc < 0) {		int is_udplite = IS_UDPLITE(sk);		 		if (rc == -ENOMEM)			UDP_INC_STATS_BH(sock_net(sk), UDP_MIB_RCVBUFERRORS,					 is_udplite);		UDP_INC_STATS_BH(sock_net(sk), UDP_MIB_INERRORS, is_udplite);		kfree_skb(skb);		return -1;	}	return 0;}",2887
117,1571,CVE-2015-9016,21,struct cpumask *blk_mq_tags_cpumask(struct blk_mq_tags *tags){	return tags->cpumask;},26350
242,827,CVE-2016-6130,21,static int sclp_ctl_cmdw_supported(unsigned int cmdw){	int i;	for (i = 0; i < ARRAY_SIZE(sclp_ctl_sccb_wlist); i++) {		if (cmdw == sclp_ctl_sccb_wlist[i])			return 1;	}	return 0;},16312
254,1526,CVE-2015-9016,21,"void blk_mq_add_to_requeue_list(struct request *rq, int at_head){	struct request_queue *q = rq->q;	unsigned long flags;	 	BUG_ON(rq->cmd_flags & REQ_SOFTBARRIER);	spin_lock_irqsave(&q->requeue_lock, flags);	if (at_head) {		rq->cmd_flags |= REQ_SOFTBARRIER;		list_add(&rq->queuelist, &q->requeue_list);	} else {		list_add_tail(&rq->queuelist, &q->requeue_list);	}	spin_unlock_irqrestore(&q->requeue_lock, flags);}",26305
211,570,CVE-2010-5313,21,"static int emulator_pio_in_emulated(int size, unsigned short port, void *val,			     unsigned int count, struct kvm_vcpu *vcpu){	if (vcpu->arch.pio.count)		goto data_avail;	trace_kvm_pio(0, port, size, 1);	vcpu->arch.pio.port = port;	vcpu->arch.pio.in = 1;	vcpu->arch.pio.count  = count;	vcpu->arch.pio.size = size;	if (!kernel_pio(vcpu, vcpu->arch.pio_data)) {	data_avail:		memcpy(val, vcpu->arch.pio_data, size * count);		vcpu->arch.pio.count = 0;		return 1;	}	vcpu->run->exit_reason = KVM_EXIT_IO;	vcpu->run->io.direction = KVM_EXIT_IO_IN;	vcpu->run->io.size = size;	vcpu->run->io.data_offset = KVM_PIO_PAGE_OFFSET * PAGE_SIZE;	vcpu->run->io.count = count;	vcpu->run->io.port = port;	return 0;}",12794
7,1691,CVE-2019-6974,21,"static inline int kvm_kick_many_cpus(const struct cpumask *cpus, int wait){	if (unlikely(!cpus))		cpus = cpu_online_mask;	if (cpumask_empty(cpus))		return false;	smp_call_function_many(cpus, ack_flush, NULL, wait);	return true;}",27368
311,448,CVE-2014-4652,21,"static void snd_card_id_read(struct snd_info_entry *entry,			     struct snd_info_buffer *buffer){	snd_iprintf(buffer, ""%s\n"", entry->card->id);}",10846
319,544,CVE-2014-0196,21,"n_tty_receive_buf_fast(struct tty_struct *tty, const unsigned char *cp,		       char *fp, int count){	struct n_tty_data *ldata = tty->disc_data;	char flag = TTY_NORMAL;	while (count--) {		if (fp)			flag = *fp++;		if (likely(flag == TTY_NORMAL)) {			unsigned char c = *cp++;			if (!test_bit(c, ldata->char_map))				n_tty_receive_char_fast(tty, c);			else if (n_tty_receive_char_special(tty, c) && count) {				if (fp)					flag = *fp++;				n_tty_receive_char_lnext(tty, *cp++, flag);				count--;			}		} else			n_tty_receive_char_flagged(tty, *cp++, flag);	}}",12199
266,1513,CVE-2015-9016,21,"static unsigned int bt_unused_tags(struct blk_mq_bitmap_tags *bt){	unsigned int i, used;	for (i = 0, used = 0; i < bt->map_nr; i++) {		struct blk_align_bitmap *bm = &bt->map[i];		used += bitmap_weight(&bm->word, bm->depth);	}	return bt->depth - used;}",26292
327,10,CVE-2012-1174,21,int close_nointr(int fd) {        assert(fd >= 0);        for (;;) {                int r;                r = close(fd);                if (r >= 0)                        return r;                if (errno != EINTR)                        return -errno;        }},1975
348,1476,CVE-2017-2616,21,"authenticate (const struct passwd *pw){  const struct passwd *lpw = NULL;  const char *cp, *srvname = NULL;  int retval;  switch (su_mode) {  case SU_MODE:    srvname = simulate_login ? PAM_SRVNAME_SU_L : PAM_SRVNAME_SU;    break;  case RUNUSER_MODE:    srvname = simulate_login ? PAM_SRVNAME_RUNUSER_L : PAM_SRVNAME_RUNUSER;    break;  default:    abort();    break;  }  retval = pam_start (srvname, pw->pw_name, &conv, &pamh);  if (is_pam_failure(retval))    goto done;  if (isatty (0) && (cp = ttyname (0)) != NULL)    {      const char *tty;      if (strncmp (cp, ""/dev/"", 5) == 0)	tty = cp + 5;      else	tty = cp;      retval = pam_set_item (pamh, PAM_TTY, tty);      if (is_pam_failure(retval))	goto done;    }  lpw = current_getpwuid ();  if (lpw && lpw->pw_name)    {      retval = pam_set_item (pamh, PAM_RUSER, (const void *) lpw->pw_name);      if (is_pam_failure(retval))	goto done;    }  if (su_mode == RUNUSER_MODE)    {             if (restricted)	errx(EXIT_FAILURE, _(""may not be used by non-root users""));      return;    }  retval = pam_authenticate (pamh, 0);  if (is_pam_failure(retval))    goto done;  retval = pam_acct_mgmt (pamh, 0);  if (retval == PAM_NEW_AUTHTOK_REQD)    {             retval = pam_chauthtok (pamh, PAM_CHANGE_EXPIRED_AUTHTOK);    }done:  log_syslog(pw, !is_pam_failure(retval));  if (is_pam_failure(retval))    {      const char *msg;      log_btmp(pw);      msg  = pam_strerror(pamh, retval);      pam_end(pamh, retval);      sleep (getlogindefs_num (""FAIL_DELAY"", 1));      errx (EXIT_FAILURE, ""%s"", msg?msg:_(""incorrect password""));    }}",26230
369,943,CVE-2016-0723,21,"void tty_write_message(struct tty_struct *tty, char *msg){	if (tty) {		mutex_lock(&tty->atomic_write_lock);		tty_lock(tty);		if (tty->ops->write && tty->count > 0)			tty->ops->write(tty, msg, strlen(msg));		tty_unlock(tty);		tty_write_unlock(tty);	}	return;}",18286
444,1453,CVE-2017-18203,21,"void dm_uevent_add(struct mapped_device *md, struct list_head *elist){	unsigned long flags;	spin_lock_irqsave(&md->uevent_lock, flags);	list_add(elist, &md->uevent_list);	spin_unlock_irqrestore(&md->uevent_lock, flags);}",25988
76,496,CVE-2014-2672,21,"static int ath_tx_edma_init(struct ath_softc *sc){	int err;	err = ath_txstatus_setup(sc, ATH_TXSTATUS_RING_SIZE);	if (!err)		ath9k_hw_setup_statusring(sc->sc_ah, sc->txsdma.dd_desc,					  sc->txsdma.dd_desc_paddr,					  ATH_TXSTATUS_RING_SIZE);	return err;}",11780
15,1579,CVE-2019-13233,21,"static int get_eff_addr_reg(struct insn *insn, struct pt_regs *regs,			    int *regoff, long *eff_addr){	insn_get_modrm(insn);	if (!insn->modrm.nbytes)		return -EINVAL;	if (X86_MODRM_MOD(insn->modrm.value) != 3)		return -EINVAL;	*regoff = get_reg_offset(insn, regs, REG_TYPE_RM);	if (*regoff < 0)		return -EINVAL;	 	if (insn->addr_bytes == 2)		*eff_addr = regs_get_register(regs, *regoff) & 0xffff;	else if (insn->addr_bytes == 4)		*eff_addr = regs_get_register(regs, *regoff) & 0xffffffff;	else  		*eff_addr = regs_get_register(regs, *regoff);	return 0;}",26733
65,31,CVE-2012-1174,21,"int make_null_stdio(void) {        int null_fd;        if ((null_fd = open(""/dev/null"", O_RDWR|O_NOCTTY)) < 0)                return -errno;        return make_stdio(null_fd);}",1996
322,1397,CVE-2017-18203,21,"static struct mapped_device *alloc_dev(int minor){	int r, numa_node_id = dm_get_numa_node();	struct dax_device *dax_dev;	struct mapped_device *md;	void *old_md;	md = kvzalloc_node(sizeof(*md), GFP_KERNEL, numa_node_id);	if (!md) {		DMWARN(""unable to allocate device, out of memory."");		return NULL;	}	if (!try_module_get(THIS_MODULE))		goto bad_module_get;	 	if (minor == DM_ANY_MINOR)		r = next_free_minor(&minor);	else		r = specific_minor(minor);	if (r < 0)		goto bad_minor;	r = init_srcu_struct(&md->io_barrier);	if (r < 0)		goto bad_io_barrier;	md->numa_node_id = numa_node_id;	md->use_blk_mq = dm_use_blk_mq_default();	md->init_tio_pdu = false;	md->type = DM_TYPE_NONE;	mutex_init(&md->suspend_lock);	mutex_init(&md->type_lock);	mutex_init(&md->table_devices_lock);	spin_lock_init(&md->deferred_lock);	atomic_set(&md->holders, 1);	atomic_set(&md->open_count, 0);	atomic_set(&md->event_nr, 0);	atomic_set(&md->uevent_seq, 0);	INIT_LIST_HEAD(&md->uevent_list);	INIT_LIST_HEAD(&md->table_devices);	spin_lock_init(&md->uevent_lock);	md->queue = blk_alloc_queue_node(GFP_KERNEL, numa_node_id);	if (!md->queue)		goto bad;	dm_init_md_queue(md);	md->disk = alloc_disk_node(1, numa_node_id);	if (!md->disk)		goto bad;	atomic_set(&md->pending[0], 0);	atomic_set(&md->pending[1], 0);	init_waitqueue_head(&md->wait);	INIT_WORK(&md->work, dm_wq_work);	init_waitqueue_head(&md->eventq);	init_completion(&md->kobj_holder.completion);	md->kworker_task = NULL;	md->disk->major = _major;	md->disk->first_minor = minor;	md->disk->fops = &dm_blk_dops;	md->disk->queue = md->queue;	md->disk->private_data = md;	sprintf(md->disk->disk_name, ""dm-%d"", minor);	dax_dev = alloc_dax(md, md->disk->disk_name, &dm_dax_ops);	if (!dax_dev)		goto bad;	md->dax_dev = dax_dev;	add_disk(md->disk);	format_dev_t(md->name, MKDEV(_major, minor));	md->wq = alloc_workqueue(""kdmflush"", WQ_MEM_RECLAIM, 0);	if (!md->wq)		goto bad;	md->bdev = bdget_disk(md->disk, 0);	if (!md->bdev)		goto bad;	bio_init(&md->flush_bio, NULL, 0);	bio_set_dev(&md->flush_bio, md->bdev);	md->flush_bio.bi_opf = REQ_OP_WRITE | REQ_PREFLUSH | REQ_SYNC;	dm_stats_init(&md->stats);	 	spin_lock(&_minor_lock);	old_md = idr_replace(&_minor_idr, md, minor);	spin_unlock(&_minor_lock);	BUG_ON(old_md != MINOR_ALLOCED);	return md;bad:	cleanup_mapped_device(md);bad_io_barrier:	free_minor(minor);bad_minor:	module_put(THIS_MODULE);bad_module_get:	kvfree(md);	return NULL;}",25932
162,680,CVE-2015-3212,21,"struct sk_buff *sctp_skb_recv_datagram(struct sock *sk, int flags,				       int noblock, int *err){	int error;	struct sk_buff *skb;	long timeo;	timeo = sock_rcvtimeo(sk, noblock);	pr_debug(""%s: timeo:%ld, max:%ld\n"", __func__, timeo,		 MAX_SCHEDULE_TIMEOUT);	do {		 		if (flags & MSG_PEEK) {			spin_lock_bh(&sk->sk_receive_queue.lock);			skb = skb_peek(&sk->sk_receive_queue);			if (skb)				atomic_inc(&skb->users);			spin_unlock_bh(&sk->sk_receive_queue.lock);		} else {			skb = skb_dequeue(&sk->sk_receive_queue);		}		if (skb)			return skb;		 		error = sock_error(sk);		if (error)			goto no_packet;		if (sk->sk_shutdown & RCV_SHUTDOWN)			break;		if (sk_can_busy_loop(sk) &&		    sk_busy_loop(sk, noblock))			continue;		 		error = -EAGAIN;		if (!timeo)			goto no_packet;	} while (sctp_wait_for_packet(sk, err, &timeo) == 0);	return NULL;no_packet:	*err = error;	return NULL;}",13632
38,1533,CVE-2015-9016,21,void blk_mq_complete_request(struct request *rq){	struct request_queue *q = rq->q;	if (unlikely(blk_should_fake_timeout(q)))		return;	if (!blk_mark_rq_complete(rq))		__blk_mq_complete_request(rq);},26312
363,861,CVE-2016-2544,21,"struct snd_seq_queue *snd_seq_queue_find_name(char *name){	int i;	struct snd_seq_queue *q;	for (i = 0; i < SNDRV_SEQ_MAX_QUEUES; i++) {		if ((q = queueptr(i)) != NULL) {			if (strncmp(q->name, name, sizeof(q->name)) == 0)				return q;			queuefree(q);		}	}	return NULL;}",17535
179,169,CVE-2012-3552,21,"int raw_rcv(struct sock *sk, struct sk_buff *skb){	if (!xfrm4_policy_check(sk, XFRM_POLICY_IN, skb)) {		atomic_inc(&sk->sk_drops);		kfree_skb(skb);		return NET_RX_DROP;	}	nf_reset(skb);	skb_push(skb, skb->data - skb_network_header(skb));	raw_rcv_skb(sk, skb);	return 0;}",2855
370,1407,CVE-2017-18203,21,"int dm_deleting_md(struct mapped_device *md){	return test_bit(DMF_DELETING, &md->flags);}",25942
178,612,CVE-2010-5313,21,"static int vcpu_enter_guest(struct kvm_vcpu *vcpu){	int r;	int req_int_win = !irqchip_in_kernel(vcpu->kvm) &&		vcpu->run->request_interrupt_window;	if (vcpu->requests) {		if (kvm_check_request(KVM_REQ_MMU_RELOAD, vcpu))			kvm_mmu_unload(vcpu);		if (kvm_check_request(KVM_REQ_MIGRATE_TIMER, vcpu))			__kvm_migrate_timers(vcpu);		if (kvm_check_request(KVM_REQ_CLOCK_UPDATE, vcpu)) {			r = kvm_guest_time_update(vcpu);			if (unlikely(r))				goto out;		}		if (kvm_check_request(KVM_REQ_MMU_SYNC, vcpu))			kvm_mmu_sync_roots(vcpu);		if (kvm_check_request(KVM_REQ_TLB_FLUSH, vcpu))			kvm_x86_ops->tlb_flush(vcpu);		if (kvm_check_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu)) {			vcpu->run->exit_reason = KVM_EXIT_TPR_ACCESS;			r = 0;			goto out;		}		if (kvm_check_request(KVM_REQ_TRIPLE_FAULT, vcpu)) {			vcpu->run->exit_reason = KVM_EXIT_SHUTDOWN;			r = 0;			goto out;		}		if (kvm_check_request(KVM_REQ_DEACTIVATE_FPU, vcpu)) {			vcpu->fpu_active = 0;			kvm_x86_ops->fpu_deactivate(vcpu);		}		if (kvm_check_request(KVM_REQ_APF_HALT, vcpu)) {			 			vcpu->arch.apf.halted = true;			r = 1;			goto out;		}	}	r = kvm_mmu_reload(vcpu);	if (unlikely(r))		goto out;	if (kvm_check_request(KVM_REQ_EVENT, vcpu) || req_int_win) {		inject_pending_event(vcpu);		 		if (vcpu->arch.nmi_pending)			kvm_x86_ops->enable_nmi_window(vcpu);		else if (kvm_cpu_has_interrupt(vcpu) || req_int_win)			kvm_x86_ops->enable_irq_window(vcpu);		if (kvm_lapic_enabled(vcpu)) {			update_cr8_intercept(vcpu);			kvm_lapic_sync_to_vapic(vcpu);		}	}	preempt_disable();	kvm_x86_ops->prepare_guest_switch(vcpu);	if (vcpu->fpu_active)		kvm_load_guest_fpu(vcpu);	kvm_load_guest_xcr0(vcpu);	atomic_set(&vcpu->guest_mode, 1);	smp_wmb();	local_irq_disable();	if (!atomic_read(&vcpu->guest_mode) || vcpu->requests	    || need_resched() || signal_pending(current)) {		atomic_set(&vcpu->guest_mode, 0);		smp_wmb();		local_irq_enable();		preempt_enable();		kvm_x86_ops->cancel_injection(vcpu);		r = 1;		goto out;	}	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);	kvm_guest_enter();	if (unlikely(vcpu->arch.switch_db_regs)) {		set_debugreg(0, 7);		set_debugreg(vcpu->arch.eff_db[0], 0);		set_debugreg(vcpu->arch.eff_db[1], 1);		set_debugreg(vcpu->arch.eff_db[2], 2);		set_debugreg(vcpu->arch.eff_db[3], 3);	}	trace_kvm_entry(vcpu->vcpu_id);	kvm_x86_ops->run(vcpu);	 	if (hw_breakpoint_active())		hw_breakpoint_restore();	kvm_get_msr(vcpu, MSR_IA32_TSC, &vcpu->arch.last_guest_tsc);	atomic_set(&vcpu->guest_mode, 0);	smp_wmb();	local_irq_enable();	++vcpu->stat.exits;	 	barrier();	kvm_guest_exit();	preempt_enable();	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);	 	if (unlikely(prof_on == KVM_PROFILING)) {		unsigned long rip = kvm_rip_read(vcpu);		profile_hit(KVM_PROFILING, (void *)rip);	}	kvm_lapic_sync_from_vapic(vcpu);	r = kvm_x86_ops->handle_exit(vcpu);out:	return r;}",12836
226,1481,CVE-2017-2616,21,"modify_environment (const struct passwd *pw, const char *shell){  if (simulate_login)    {             char *term = getenv (""TERM"");      if (term)	term = xstrdup (term);      environ = xmalloc ((6 + !!term) * sizeof (char *));      environ[0] = NULL;      if (term) {	xsetenv (""TERM"", term, 1);	free(term);      }      xsetenv (""HOME"", pw->pw_dir, 1);      if (shell)	xsetenv (""SHELL"", shell, 1);      xsetenv (""USER"", pw->pw_name, 1);      xsetenv (""LOGNAME"", pw->pw_name, 1);      set_path(pw);    }  else    {             if (change_environment)        {          xsetenv (""HOME"", pw->pw_dir, 1);	  if (shell)            xsetenv (""SHELL"", shell, 1);	  if (getlogindefs_int (""ALWAYS_SET_PATH"", 0))	    set_path(pw);          if (pw->pw_uid)            {              xsetenv (""USER"", pw->pw_name, 1);              xsetenv (""LOGNAME"", pw->pw_name, 1);            }        }    }  export_pamenv ();}",26235
20,1547,CVE-2015-9016,21,void blk_mq_freeze_queue(struct request_queue *q){	blk_mq_freeze_queue_start(q);	blk_mq_freeze_queue_wait(q);},26326
417,1316,CVE-2017-6001,21,static void unaccount_freq_event(void){	if (tick_nohz_full_enabled())		unaccount_freq_event_nohz();	else		atomic_dec(&nr_freq_events);},21936
284,443,CVE-2014-4652,21,static void release_card_device(struct device *dev){	snd_card_do_free(dev_to_snd_card(dev));},10841
114,1288,CVE-2017-6001,21,"perf_event_output_backward(struct perf_event *event,			   struct perf_sample_data *data,			   struct pt_regs *regs){	__perf_event_output(event, data, regs, perf_output_begin_backward);}",21908
268,986,CVE-2015-8839,21,"static void ext4_blkdev_put(struct block_device *bdev){	blkdev_put(bdev, FMODE_READ|FMODE_WRITE|FMODE_EXCL);}",18556
413,174,CVE-2012-3552,21,"void raw_unhash_sk(struct sock *sk){	struct raw_hashinfo *h = sk->sk_prot->h.raw_hash;	write_lock_bh(&h->lock);	if (sk_del_node_init(sk))		sock_prot_inuse_add(sock_net(sk), sk->sk_prot, -1);	write_unlock_bh(&h->lock);}",2860
123,714,CVE-2014-9710,21,"static int comp_keys(struct btrfs_disk_key *disk, struct btrfs_key *k2){	struct btrfs_key k1;	btrfs_disk_key_to_cpu(&k1, disk);	return btrfs_comp_cpu_keys(&k1, k2);}",14131
8,65,CVE-2011-4029,21,"Xcalloc(unsigned long amount){    return calloc(1, amount);}",2212
279,602,CVE-2010-5313,21,"int kvm_set_cr4(struct kvm_vcpu *vcpu, unsigned long cr4){	unsigned long old_cr4 = kvm_read_cr4(vcpu);	unsigned long pdptr_bits = X86_CR4_PGE | X86_CR4_PSE | X86_CR4_PAE;	if (cr4 & CR4_RESERVED_BITS)		return 1;	if (!guest_cpuid_has_xsave(vcpu) && (cr4 & X86_CR4_OSXSAVE))		return 1;	if (is_long_mode(vcpu)) {		if (!(cr4 & X86_CR4_PAE))			return 1;	} else if (is_paging(vcpu) && (cr4 & X86_CR4_PAE)		   && ((cr4 ^ old_cr4) & pdptr_bits)		   && !load_pdptrs(vcpu, vcpu->arch.walk_mmu, vcpu->arch.cr3))		return 1;	if (cr4 & X86_CR4_VMXE)		return 1;	kvm_x86_ops->set_cr4(vcpu, cr4);	if ((cr4 ^ old_cr4) & pdptr_bits)		kvm_mmu_reset_context(vcpu);	if ((cr4 ^ old_cr4) & X86_CR4_OSXSAVE)		update_cpuid(vcpu);	return 0;}",12826
106,1485,CVE-2015-9016,21,"struct blk_flush_queue *blk_alloc_flush_queue(struct request_queue *q,		int node, int cmd_size){	struct blk_flush_queue *fq;	int rq_sz = sizeof(struct request);	fq = kzalloc_node(sizeof(*fq), GFP_KERNEL, node);	if (!fq)		goto fail;	if (q->mq_ops) {		spin_lock_init(&fq->mq_flush_lock);		rq_sz = round_up(rq_sz + cmd_size, cache_line_size());	}	fq->flush_rq = kzalloc_node(rq_sz, GFP_KERNEL, node);	if (!fq->flush_rq)		goto fail_rq;	INIT_LIST_HEAD(&fq->flush_queue[0]);	INIT_LIST_HEAD(&fq->flush_queue[1]);	INIT_LIST_HEAD(&fq->flush_data_in_flight);	return fq; fail_rq:	kfree(fq); fail:	return NULL;}",26264
171,1008,CVE-2015-8839,21,"static const char *token2str(int token){	const struct match_token *t;	for (t = tokens; t->token != Opt_err; t++)		if (t->token == token && !strchr(t->pattern, '='))			break;	return t->pattern;}",18578
230,1644,CVE-2019-11599,21,"static int anon_vma_compatible(struct vm_area_struct *a, struct vm_area_struct *b){	return a->vm_end == b->vm_start &&		mpol_equal(vma_policy(a), vma_policy(b)) &&		a->vm_file == b->vm_file &&		!((a->vm_flags ^ b->vm_flags) & ~(VM_READ|VM_WRITE|VM_EXEC|VM_SOFTDIRTY)) &&		b->vm_pgoff == a->vm_pgoff + ((b->vm_start - a->vm_start) >> PAGE_SHIFT);}",27091
120,1744,CVE-2017-5061,21,  LayerTreeHostTestCommit() {},29880
251,543,CVE-2014-0196,21,"n_tty_receive_buf_common(struct tty_struct *tty, const unsigned char *cp,			 char *fp, int count, int flow){	struct n_tty_data *ldata = tty->disc_data;	int room, n, rcvd = 0;	down_read(&tty->termios_rwsem);	while (1) {		room = receive_room(tty);		n = min(count, room);		if (!n) {			if (flow && !room)				ldata->no_room = 1;			break;		}		__receive_buf(tty, cp, fp, n);		cp += n;		if (fp)			fp += n;		count -= n;		rcvd += n;	}	tty->receive_room = room;	n_tty_check_throttle(tty);	up_read(&tty->termios_rwsem);	return rcvd;}",12198
137,257,CVE-2011-2183,21,"static inline struct mm_slot *alloc_mm_slot(void){	if (!mm_slot_cache)	 		return NULL;	return kmem_cache_zalloc(mm_slot_cache, GFP_KERNEL);}",6724
385,1363,CVE-2017-18249,21,"static int f2fs_write_node_page(struct page *page,				struct writeback_control *wbc){	return __write_node_page(page, false, NULL, wbc);}",25681
299,1298,CVE-2017-6001,21,"perf_lock_task_context(struct task_struct *task, int ctxn, unsigned long *flags){	struct perf_event_context *ctx;retry:	 	local_irq_save(*flags);	rcu_read_lock();	ctx = rcu_dereference(task->perf_event_ctxp[ctxn]);	if (ctx) {		 		raw_spin_lock(&ctx->lock);		if (ctx != rcu_dereference(task->perf_event_ctxp[ctxn])) {			raw_spin_unlock(&ctx->lock);			rcu_read_unlock();			local_irq_restore(*flags);			goto retry;		}		if (ctx->task == TASK_TOMBSTONE ||		    !atomic_inc_not_zero(&ctx->refcount)) {			raw_spin_unlock(&ctx->lock);			ctx = NULL;		} else {			WARN_ON_ONCE(ctx->task != task);		}	}	rcu_read_unlock();	if (!ctx)		local_irq_restore(*flags);	return ctx;}",21918
75,372,CVE-2013-1792,21,"int install_process_keyring_to_cred(struct cred *new){	struct key *keyring;	if (new->process_keyring)		return -EEXIST;	keyring = keyring_alloc(""_pid"", new->uid, new->gid, new,				KEY_POS_ALL | KEY_USR_VIEW,				KEY_ALLOC_QUOTA_OVERRUN, NULL);	if (IS_ERR(keyring))		return PTR_ERR(keyring);	new->process_keyring = keyring;	return 0;}",9528
382,1587,CVE-2019-11922,21,int ZSTD_minCLevel(void) { return (int)-ZSTD_TARGETLENGTH_MAX; },26910
418,148,CVE-2012-3552,21,"int ip_output(struct sk_buff *skb){	struct net_device *dev = skb_dst(skb)->dev;	IP_UPD_PO_STATS(dev_net(dev), IPSTATS_MIB_OUT, skb->len);	skb->dev = dev;	skb->protocol = htons(ETH_P_IP);	return NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING, skb, NULL, dev,			    ip_finish_output,			    !(IPCB(skb)->flags & IPSKB_REROUTED));}",2834
243,985,CVE-2015-8839,21,"static int ext4_acquire_dquot(struct dquot *dquot){	int ret, err;	handle_t *handle;	handle = ext4_journal_start(dquot_to_inode(dquot), EXT4_HT_QUOTA,				    EXT4_QUOTA_INIT_BLOCKS(dquot->dq_sb));	if (IS_ERR(handle))		return PTR_ERR(handle);	ret = dquot_acquire(dquot);	err = ext4_journal_stop(handle);	if (!ret)		ret = err;	return ret;}",18555
66,925,CVE-2016-0723,21,int tty_init_termios(struct tty_struct *tty){	struct ktermios *tp;	int idx = tty->index;	if (tty->driver->flags & TTY_DRIVER_RESET_TERMIOS)		tty->termios = tty->driver->init_termios;	else {		 		tp = tty->driver->termios[idx];		if (tp != NULL)			tty->termios = *tp;		else			tty->termios = tty->driver->init_termios;	}	 	tty->termios.c_ispeed = tty_termios_input_baud_rate(&tty->termios);	tty->termios.c_ospeed = tty_termios_baud_rate(&tty->termios);	return 0;},18268
1,779,CVE-2016-7916,21,"static int proc_task_instantiate(struct inode *dir,	struct dentry *dentry, struct task_struct *task, const void *ptr){	struct inode *inode;	inode = proc_pid_make_inode(dir->i_sb, task);	if (!inode)		goto out;	inode->i_mode = S_IFDIR|S_IRUGO|S_IXUGO;	inode->i_op = &proc_tid_base_inode_operations;	inode->i_fop = &proc_tid_base_operations;	inode->i_flags|=S_IMMUTABLE;	set_nlink(inode, 2 + pid_entry_count_dirs(tid_base_stuff,						  ARRAY_SIZE(tid_base_stuff)));	d_set_d_op(dentry, &pid_dentry_operations);	d_add(dentry, inode);	 	if (pid_revalidate(dentry, 0))		return 0;out:	return -ENOENT;}",15635
167,1261,CVE-2017-6001,21,static int is_orphaned_event(struct perf_event *event){	return event->state == PERF_EVENT_STATE_DEAD;},21881
12,1651,CVE-2019-11599,21,"int expand_stack(struct vm_area_struct *vma, unsigned long address){	return expand_upwards(vma, address);}",27098
381,1101,CVE-2017-7533,21,"void d_add(struct dentry *entry, struct inode *inode){	if (inode) {		security_d_instantiate(entry, inode);		spin_lock(&inode->i_lock);	}	__d_add(entry, inode);}",21573
224,163,CVE-2012-3552,21,"static void raw_close(struct sock *sk, long timeout){	 	ip_ra_control(sk, 0, NULL);	sk_common_release(sk);}",2849
305,1647,CVE-2019-11599,21,"static unsigned long count_vma_pages_range(struct mm_struct *mm,		unsigned long addr, unsigned long end){	unsigned long nr_pages = 0;	struct vm_area_struct *vma;	 	vma = find_vma_intersection(mm, addr, end);	if (!vma)		return 0;	nr_pages = (min(end, vma->vm_end) -		max(addr, vma->vm_start)) >> PAGE_SHIFT;	 	for (vma = vma->vm_next; vma; vma = vma->vm_next) {		unsigned long overlap_len;		if (vma->vm_start > end)			break;		overlap_len = min(end, vma->vm_end) - vma->vm_start;		nr_pages += overlap_len >> PAGE_SHIFT;	}	return nr_pages;}",27094
180,698,CVE-2014-9710,21,"__tree_mod_log_free_eb(struct btrfs_fs_info *fs_info,		       struct tree_mod_elem **tm_list,		       int nritems){	int i, j;	int ret;	for (i = nritems - 1; i >= 0; i--) {		ret = __tree_mod_log_insert(fs_info, tm_list[i]);		if (ret) {			for (j = nritems - 1; j > i; j--)				rb_erase(&tm_list[j]->node,					 &fs_info->tree_mod_log);			return ret;		}	}	return 0;}",14115
405,1325,CVE-2018-12633,21,void vbg_put_gdev(struct vbg_dev *gdev){	WARN_ON(gdev != vbg_gdev);	mutex_unlock(&vbg_gdev_mutex);},25058
445,236,CVE-2012-3552,21,"static struct tcp_md5sig_key *tcp_v6_md5_lookup(struct sock *sk,						struct sock *addr_sk){	return tcp_v6_md5_do_lookup(sk, &inet6_sk(addr_sk)->daddr);}",2922
306,1698,CVE-2019-6974,21,"void kvm_sigset_deactivate(struct kvm_vcpu *vcpu){	if (!vcpu->sigset_active)		return;	sigprocmask(SIG_SETMASK, &current->real_blocked, NULL);	sigemptyset(&current->real_blocked);}",27375
237,296,CVE-2011-1768,21,"ipip_tunnel_ioctl (struct net_device *dev, struct ifreq *ifr, int cmd){	int err = 0;	struct ip_tunnel_parm p;	struct ip_tunnel *t;	struct net *net = dev_net(dev);	struct ipip_net *ipn = net_generic(net, ipip_net_id);	switch (cmd) {	case SIOCGETTUNNEL:		t = NULL;		if (dev == ipn->fb_tunnel_dev) {			if (copy_from_user(&p, ifr->ifr_ifru.ifru_data, sizeof(p))) {				err = -EFAULT;				break;			}			t = ipip_tunnel_locate(net, &p, 0);		}		if (t == NULL)			t = netdev_priv(dev);		memcpy(&p, &t->parms, sizeof(p));		if (copy_to_user(ifr->ifr_ifru.ifru_data, &p, sizeof(p)))			err = -EFAULT;		break;	case SIOCADDTUNNEL:	case SIOCCHGTUNNEL:		err = -EPERM;		if (!capable(CAP_NET_ADMIN))			goto done;		err = -EFAULT;		if (copy_from_user(&p, ifr->ifr_ifru.ifru_data, sizeof(p)))			goto done;		err = -EINVAL;		if (p.iph.version != 4 || p.iph.protocol != IPPROTO_IPIP ||		    p.iph.ihl != 5 || (p.iph.frag_off&htons(~IP_DF)))			goto done;		if (p.iph.ttl)			p.iph.frag_off |= htons(IP_DF);		t = ipip_tunnel_locate(net, &p, cmd == SIOCADDTUNNEL);		if (dev != ipn->fb_tunnel_dev && cmd == SIOCCHGTUNNEL) {			if (t != NULL) {				if (t->dev != dev) {					err = -EEXIST;					break;				}			} else {				if (((dev->flags&IFF_POINTOPOINT) && !p.iph.daddr) ||				    (!(dev->flags&IFF_POINTOPOINT) && p.iph.daddr)) {					err = -EINVAL;					break;				}				t = netdev_priv(dev);				ipip_tunnel_unlink(ipn, t);				t->parms.iph.saddr = p.iph.saddr;				t->parms.iph.daddr = p.iph.daddr;				memcpy(dev->dev_addr, &p.iph.saddr, 4);				memcpy(dev->broadcast, &p.iph.daddr, 4);				ipip_tunnel_link(ipn, t);				netdev_state_change(dev);			}		}		if (t) {			err = 0;			if (cmd == SIOCCHGTUNNEL) {				t->parms.iph.ttl = p.iph.ttl;				t->parms.iph.tos = p.iph.tos;				t->parms.iph.frag_off = p.iph.frag_off;				if (t->parms.link != p.link) {					t->parms.link = p.link;					ipip_tunnel_bind_dev(dev);					netdev_state_change(dev);				}			}			if (copy_to_user(ifr->ifr_ifru.ifru_data, &t->parms, sizeof(p)))				err = -EFAULT;		} else			err = (cmd == SIOCADDTUNNEL ? -ENOBUFS : -ENOENT);		break;	case SIOCDELTUNNEL:		err = -EPERM;		if (!capable(CAP_NET_ADMIN))			goto done;		if (dev == ipn->fb_tunnel_dev) {			err = -EFAULT;			if (copy_from_user(&p, ifr->ifr_ifru.ifru_data, sizeof(p)))				goto done;			err = -ENOENT;			if ((t = ipip_tunnel_locate(net, &p, 0)) == NULL)				goto done;			err = -EPERM;			if (t->dev == ipn->fb_tunnel_dev)				goto done;			dev = t->dev;		}		unregister_netdevice(dev);		err = 0;		break;	default:		err = -EINVAL;	}done:	return err;}",6783
152,1038,CVE-2017-15649,21,"static void __fanout_link(struct sock *sk, struct packet_sock *po){	struct packet_fanout *f = po->fanout;	spin_lock(&f->lock);	f->arr[f->num_members] = sk;	smp_wmb();	f->num_members++;	if (f->num_members == 1)		dev_add_pack(&f->prot_hook);	spin_unlock(&f->lock);}",19962
14,112,CVE-2012-3552,21,static void cipso_v4_cache_entry_free(struct cipso_v4_map_cache_entry *entry){	if (entry->lsm_data)		netlbl_secattr_cache_free(entry->lsm_data);	kfree(entry->key);	kfree(entry);},2798
229,1092,CVE-2017-7533,21," static inline void __d_set_inode_and_type(struct dentry *dentry, 					  struct inode *inode, 					  unsigned type_flags){	unsigned flags;	dentry->d_inode = inode;	flags = READ_ONCE(dentry->d_flags);	flags &= ~(DCACHE_ENTRY_TYPE | DCACHE_FALLTHRU);	flags |= type_flags;	WRITE_ONCE(dentry->d_flags, flags);}",21564
269,1218,CVE-2017-7533,21,"static inline int may_create(struct inode *dir, struct dentry *child){	struct user_namespace *s_user_ns;	audit_inode_child(dir, child, AUDIT_TYPE_CHILD_CREATE);	if (child->d_inode)		return -EEXIST;	if (IS_DEADDIR(dir))		return -ENOENT;	s_user_ns = dir->i_sb->s_user_ns;	if (!kuid_has_mapping(s_user_ns, current_fsuid()) ||	    !kgid_has_mapping(s_user_ns, current_fsgid()))		return -EOVERFLOW;	return inode_permission(dir, MAY_WRITE | MAY_EXEC);}",21690
286,542,CVE-2014-0196,21,"n_tty_receive_buf_closing(struct tty_struct *tty, const unsigned char *cp,			  char *fp, int count){	char flag = TTY_NORMAL;	while (count--) {		if (fp)			flag = *fp++;		if (likely(flag == TTY_NORMAL))			n_tty_receive_char_closing(tty, *cp++);		else			n_tty_receive_char_flagged(tty, *cp++, flag);	}}",12197
104,1270,CVE-2017-6001,21,"static void perf_addr_filters_splice(struct perf_event *event,				     struct list_head *head){	unsigned long flags;	LIST_HEAD(list);	if (!has_addr_filter(event))		return;	 	if (event->parent)		return;	raw_spin_lock_irqsave(&event->addr_filters.lock, flags);	list_splice_init(&event->addr_filters.list, &list);	if (head)		list_splice(head, &event->addr_filters.list);	raw_spin_unlock_irqrestore(&event->addr_filters.lock, flags);	free_filters_list(&list);}",21890
40,1167,CVE-2017-7533,21,"static int prepend_unreachable(char **buffer, int *buflen){	return prepend(buffer, buflen, ""(unreachable)"", 13);}",21639
87,928,CVE-2016-0723,21,static struct tty_struct *tty_pair_get_tty(struct tty_struct *tty){	if (tty->driver->type == TTY_DRIVER_TYPE_PTY &&	    tty->driver->subtype == PTY_TYPE_MASTER)		tty = tty->link;	return tty;},18271
109,1692,CVE-2019-6974,21,"static void kvm_mmu_notifier_invalidate_range_end(struct mmu_notifier *mn,					const struct mmu_notifier_range *range){	struct kvm *kvm = mmu_notifier_to_kvm(mn);	spin_lock(&kvm->mmu_lock);	 	kvm->mmu_notifier_seq++;	smp_wmb();	 	kvm->mmu_notifier_count--;	spin_unlock(&kvm->mmu_lock);	BUG_ON(kvm->mmu_notifier_count < 0);}",27369
331,1352,CVE-2018-8897,21,"void ist_enter(struct pt_regs *regs){	if (user_mode(regs)) {		RCU_LOCKDEP_WARN(!rcu_is_watching(), ""entry code didn't wake RCU"");	} else {		 		rcu_nmi_enter();	}	preempt_disable();	 	RCU_LOCKDEP_WARN(!rcu_is_watching(), ""ist_enter didn't work"");}",25277
366,1749,CVE-2017-5061,21,  LayerTreeHostTestStartPageScaleAnimation() {},29885
332,1016,CVE-2015-8767,21,"static void sctp_generate_t5_shutdown_guard_event(unsigned long data){	struct sctp_association *asoc = (struct sctp_association *)data;	sctp_generate_timeout_event(asoc,				    SCTP_EVENT_TIMEOUT_T5_SHUTDOWN_GUARD);}  ",18746
89,1567,CVE-2015-9016,21,"void blk_mq_run_hw_queue(struct blk_mq_hw_ctx *hctx, int async){	if (unlikely(test_bit(BLK_MQ_S_STOPPED, &hctx->state) ||	    !blk_mq_hw_queue_mapped(hctx)))		return;	if (!async) {		int cpu = get_cpu();		if (cpumask_test_cpu(cpu, hctx->cpumask)) {			__blk_mq_run_hw_queue(hctx);			put_cpu();			return;		}		put_cpu();	}	kblockd_schedule_delayed_work_on(blk_mq_hctx_next_cpu(hctx),			&hctx->run_work, 0);}",26346
434,156,CVE-2012-3552,21,"static void ip_cmsg_recv_pktinfo(struct msghdr *msg, struct sk_buff *skb){	struct in_pktinfo info;	struct rtable *rt = skb_rtable(skb);	info.ipi_addr.s_addr = ip_hdr(skb)->daddr;	if (rt) {		info.ipi_ifindex = rt->rt_iif;		info.ipi_spec_dst.s_addr = rt->rt_spec_dst;	} else {		info.ipi_ifindex = 0;		info.ipi_spec_dst.s_addr = 0;	}	put_cmsg(msg, SOL_IP, IP_PKTINFO, sizeof(info), &info);}",2842
425,1746,CVE-2017-5061,21,  LayerTreeHostTestDeviceScaleFactorScalesViewportAndLayers() {},29882
92,1589,CVE-2019-11922,21,"static int FUZ_mallocTests(unsigned seed, double compressibility, unsigned part){    (void)seed; (void)compressibility; (void)part;    return 0;}",26912
337,1573,CVE-2015-9016,21,"static void blk_sq_make_request(struct request_queue *q, struct bio *bio){	const int is_sync = rw_is_sync(bio->bi_rw);	const int is_flush_fua = bio->bi_rw & (REQ_FLUSH | REQ_FUA);	struct blk_plug *plug;	unsigned int request_count = 0;	struct blk_map_ctx data;	struct request *rq;	blk_queue_bounce(q, &bio);	if (bio_integrity_enabled(bio) && bio_integrity_prep(bio)) {		bio_io_error(bio);		return;	}	blk_queue_split(q, &bio, q->bio_split);	if (!is_flush_fua && !blk_queue_nomerges(q) &&	    blk_attempt_plug_merge(q, bio, &request_count, NULL))		return;	rq = blk_mq_map_request(q, bio, &data);	if (unlikely(!rq))		return;	if (unlikely(is_flush_fua)) {		blk_mq_bio_to_request(rq, bio);		blk_insert_flush(rq);		goto run_queue;	}	 	plug = current->plug;	if (plug) {		blk_mq_bio_to_request(rq, bio);		if (list_empty(&plug->mq_list))			trace_block_plug(q);		else if (request_count >= BLK_MAX_REQUEST_COUNT) {			blk_flush_plug_list(plug, false);			trace_block_plug(q);		}		list_add_tail(&rq->queuelist, &plug->mq_list);		blk_mq_put_ctx(data.ctx);		return;	}	if (!blk_mq_merge_queue_io(data.hctx, data.ctx, rq, bio)) {		 run_queue:		blk_mq_run_hw_queue(data.hctx, !is_sync || is_flush_fua);	}	blk_mq_put_ctx(data.ctx);}",26352
258,902,CVE-2016-0723,21,"static int this_tty(const void *t, struct file *file, unsigned fd){	if (likely(file->f_op->read != tty_read))		return 0;	return file_tty(file) != t ? 0 : fd + 1;}",18245
240,22,CVE-2012-1174,21,char* gethostname_malloc(void) {        struct utsname u;        assert_se(uname(&u) >= 0);        if (u.nodename[0])                return strdup(u.nodename);        return strdup(u.sysname);},1987
307,377,CVE-2013-1792,21,void key_fsgid_changed(struct task_struct *tsk){	 	BUG_ON(!tsk->cred);	if (tsk->cred->thread_keyring) {		down_write(&tsk->cred->thread_keyring->sem);		tsk->cred->thread_keyring->gid = tsk->cred->fsgid;		up_write(&tsk->cred->thread_keyring->sem);	}},9533
6,1606,CVE-2019-11599,21,"struct ib_ucontext *ib_uverbs_get_ucontext_file(struct ib_uverbs_file *ufile){	 	struct ib_ucontext *ucontext = smp_load_acquire(&ufile->ucontext);	if (!srcu_dereference(ufile->device->ib_dev,			      &ufile->device->disassociate_srcu))		return ERR_PTR(-EIO);	if (!ucontext)		return ERR_PTR(-EINVAL);	return ucontext;}",27053
285,1701,CVE-2019-6974,21,"void kvm_vcpu_uninit(struct kvm_vcpu *vcpu){	 	put_pid(rcu_dereference_protected(vcpu->pid, 1));	kvm_arch_vcpu_uninit(vcpu);	free_page((unsigned long)vcpu->run);}",27378
433,782,CVE-2016-7916,21,"static int proc_tgid_base_readdir(struct file *file, struct dir_context *ctx){	return proc_pident_readdir(file, ctx,				   tgid_base_stuff, ARRAY_SIZE(tgid_base_stuff));}",15638
78,391,CVE-2013-0871,21,"static void do_notify_parent_cldstop(struct task_struct *tsk,				     int for_ptracer, int why){	struct siginfo info;	unsigned long flags;	struct task_struct *parent;	struct sighand_struct *sighand;	if (for_ptracer) {		parent = tsk->parent;	} else {		tsk = tsk->group_leader;		parent = tsk->real_parent;	}	info.si_signo = SIGCHLD;	info.si_errno = 0;	 	rcu_read_lock();	info.si_pid = task_pid_nr_ns(tsk, task_active_pid_ns(parent));	info.si_uid = from_kuid_munged(task_cred_xxx(parent, user_ns), task_uid(tsk));	rcu_read_unlock();	info.si_utime = cputime_to_clock_t(tsk->utime);	info.si_stime = cputime_to_clock_t(tsk->stime); 	info.si_code = why; 	switch (why) { 	case CLD_CONTINUED: 		info.si_status = SIGCONT; 		break; 	case CLD_STOPPED: 		info.si_status = tsk->signal->group_exit_code & 0x7f; 		break; 	case CLD_TRAPPED: 		info.si_status = tsk->exit_code & 0x7f; 		break; 	default: 		BUG(); 	}	sighand = parent->sighand;	spin_lock_irqsave(&sighand->siglock, flags);	if (sighand->action[SIGCHLD-1].sa.sa_handler != SIG_IGN &&	    !(sighand->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDSTOP))		__group_send_sig_info(SIGCHLD, &info, parent);	 	__wake_up_parent(tsk, parent);	spin_unlock_irqrestore(&sighand->siglock, flags);}",9688
244,1168,CVE-2017-7533,21,"long prune_dcache_sb(struct super_block *sb, struct shrink_control *sc){	LIST_HEAD(dispose);	long freed;	freed = list_lru_shrink_walk(&sb->s_dentry_lru, sc,				     dentry_lru_isolate, &dispose);	shrink_dentry_list(&dispose);	return freed;}",21640
253,1258,CVE-2017-6001,21,"static int group_can_go_on(struct perf_event *event,			   struct perf_cpu_context *cpuctx,			   int can_add_hw){	 	if (event->group_caps & PERF_EV_CAP_SOFTWARE)		return 1;	 	if (cpuctx->exclusive)		return 0;	 	if (event->attr.exclusive && cpuctx->active_oncpu)		return 0;	 	return can_add_hw;}",21878
154,710,CVE-2014-9710,21,struct extent_buffer *btrfs_root_node(struct btrfs_root *root){	struct extent_buffer *eb;	while (1) {		rcu_read_lock();		eb = rcu_dereference(root->node);		 		if (atomic_inc_not_zero(&eb->refs)) {			rcu_read_unlock();			break;		}		rcu_read_unlock();		synchronize_rcu();	}	return eb;},14127
374,1175,CVE-2017-7533,21,"static int __debugfs_remove(struct dentry *dentry, struct dentry *parent){	int ret = 0;	if (simple_positive(dentry)) {		dget(dentry);		if (d_is_dir(dentry))			ret = simple_rmdir(d_inode(parent), dentry);		else			simple_unlink(d_inode(parent), dentry);		if (!ret)			d_delete(dentry);		dput(dentry);	}	return ret;}",21647
390,847,CVE-2016-2544,21,"static int queue_list_add(struct snd_seq_queue *q){	int i;	unsigned long flags;	spin_lock_irqsave(&queue_list_lock, flags);	for (i = 0; i < SNDRV_SEQ_MAX_QUEUES; i++) {		if (! queue_list[i]) {			queue_list[i] = q;			q->queue = i;			num_queues++;			spin_unlock_irqrestore(&queue_list_lock, flags);			return i;		}	}	spin_unlock_irqrestore(&queue_list_lock, flags);	return -1;}",17521
186,1723,CVE-2016-10741,21,"xfs_vm_direct_IO(	struct kiocb		*iocb,	struct iov_iter		*iter){	 	return -EINVAL;}",28138
300,500,CVE-2014-2672,21,"void ath_tx_node_cleanup(struct ath_softc *sc, struct ath_node *an){	struct ath_atx_ac *ac;	struct ath_atx_tid *tid;	struct ath_txq *txq;	int tidno;	for (tidno = 0, tid = &an->tid[tidno];	     tidno < IEEE80211_NUM_TIDS; tidno++, tid++) {		ac = tid->ac;		txq = ac->txq;		ath_txq_lock(sc, txq);		if (tid->sched) {			list_del(&tid->list);			tid->sched = false;		}		if (ac->sched) {			list_del(&ac->list);			tid->ac->sched = false;		}		ath_tid_drain(sc, txq, tid);		tid->active = false;		ath_txq_unlock(sc, txq);	}}",11784
280,1232,CVE-2017-7533,21,"void unlock_rename(struct dentry *p1, struct dentry *p2){	inode_unlock(p1->d_inode);	if (p1 != p2) {		inode_unlock(p2->d_inode);		mutex_unlock(&p1->d_sb->s_vfs_rename_mutex);	}}",21704
116,1192,CVE-2017-7533,21,"int __page_symlink(struct inode *inode, const char *symname, int len, int nofs){	struct address_space *mapping = inode->i_mapping;	struct page *page;	void *fsdata;	int err;	unsigned int flags = 0;	if (nofs)		flags |= AOP_FLAG_NOFS;retry:	err = pagecache_write_begin(NULL, mapping, 0, len-1,				flags, &page, &fsdata);	if (err)		goto fail;	memcpy(page_address(page), symname, len-1);	err = pagecache_write_end(NULL, mapping, 0, len-1, len-1,							page, fsdata);	if (err < 0)		goto fail;	if (err < len-1)		goto retry;	mark_inode_dirty(inode);	return 0;fail:	return err;}",21664
340,1428,CVE-2017-18203,21,void dm_internal_resume_fast(struct mapped_device *md){	if (dm_suspended_md(md) || dm_suspended_internally_md(md))		goto done;	dm_queue_flush(md);done:	mutex_unlock(&md->suspend_lock);},25963
384,678,CVE-2015-3212,21,void sctp_put_port(struct sock *sk){	local_bh_disable();	__sctp_put_port(sk);	local_bh_enable();},13630
411,687,CVE-2015-0239,21,"static int decode_operand(struct x86_emulate_ctxt *ctxt, struct operand *op,			  unsigned d){	int rc = X86EMUL_CONTINUE;	switch (d) {	case OpReg:		decode_register_operand(ctxt, op);		break;	case OpImmUByte:		rc = decode_imm(ctxt, op, 1, false);		break;	case OpMem:		ctxt->memop.bytes = (ctxt->d & ByteOp) ? 1 : ctxt->op_bytes;	mem_common:		*op = ctxt->memop;		ctxt->memopp = op;		if (ctxt->d & BitOp)			fetch_bit_operand(ctxt);		op->orig_val = op->val;		break;	case OpMem64:		ctxt->memop.bytes = (ctxt->op_bytes == 8) ? 16 : 8;		goto mem_common;	case OpAcc:		op->type = OP_REG;		op->bytes = (ctxt->d & ByteOp) ? 1 : ctxt->op_bytes;		op->addr.reg = reg_rmw(ctxt, VCPU_REGS_RAX);		fetch_register_operand(op);		op->orig_val = op->val;		break;	case OpAccLo:		op->type = OP_REG;		op->bytes = (ctxt->d & ByteOp) ? 2 : ctxt->op_bytes;		op->addr.reg = reg_rmw(ctxt, VCPU_REGS_RAX);		fetch_register_operand(op);		op->orig_val = op->val;		break;	case OpAccHi:		if (ctxt->d & ByteOp) {			op->type = OP_NONE;			break;		}		op->type = OP_REG;		op->bytes = ctxt->op_bytes;		op->addr.reg = reg_rmw(ctxt, VCPU_REGS_RDX);		fetch_register_operand(op);		op->orig_val = op->val;		break;	case OpDI:		op->type = OP_MEM;		op->bytes = (ctxt->d & ByteOp) ? 1 : ctxt->op_bytes;		op->addr.mem.ea =			register_address(ctxt, VCPU_REGS_RDI);		op->addr.mem.seg = VCPU_SREG_ES;		op->val = 0;		op->count = 1;		break;	case OpDX:		op->type = OP_REG;		op->bytes = 2;		op->addr.reg = reg_rmw(ctxt, VCPU_REGS_RDX);		fetch_register_operand(op);		break;	case OpCL:		op->type = OP_IMM;		op->bytes = 1;		op->val = reg_read(ctxt, VCPU_REGS_RCX) & 0xff;		break;	case OpImmByte:		rc = decode_imm(ctxt, op, 1, true);		break;	case OpOne:		op->type = OP_IMM;		op->bytes = 1;		op->val = 1;		break;	case OpImm:		rc = decode_imm(ctxt, op, imm_size(ctxt), true);		break;	case OpImm64:		rc = decode_imm(ctxt, op, ctxt->op_bytes, true);		break;	case OpMem8:		ctxt->memop.bytes = 1;		if (ctxt->memop.type == OP_REG) {			ctxt->memop.addr.reg = decode_register(ctxt,					ctxt->modrm_rm, true);			fetch_register_operand(&ctxt->memop);		}		goto mem_common;	case OpMem16:		ctxt->memop.bytes = 2;		goto mem_common;	case OpMem32:		ctxt->memop.bytes = 4;		goto mem_common;	case OpImmU16:		rc = decode_imm(ctxt, op, 2, false);		break;	case OpImmU:		rc = decode_imm(ctxt, op, imm_size(ctxt), false);		break;	case OpSI:		op->type = OP_MEM;		op->bytes = (ctxt->d & ByteOp) ? 1 : ctxt->op_bytes;		op->addr.mem.ea =			register_address(ctxt, VCPU_REGS_RSI);		op->addr.mem.seg = ctxt->seg_override;		op->val = 0;		op->count = 1;		break;	case OpXLat:		op->type = OP_MEM;		op->bytes = (ctxt->d & ByteOp) ? 1 : ctxt->op_bytes;		op->addr.mem.ea =			address_mask(ctxt,				reg_read(ctxt, VCPU_REGS_RBX) +				(reg_read(ctxt, VCPU_REGS_RAX) & 0xff));		op->addr.mem.seg = ctxt->seg_override;		op->val = 0;		break;	case OpImmFAddr:		op->type = OP_IMM;		op->addr.mem.ea = ctxt->_eip;		op->bytes = ctxt->op_bytes + 2;		insn_fetch_arr(op->valptr, op->bytes, ctxt);		break;	case OpMemFAddr:		ctxt->memop.bytes = ctxt->op_bytes + 2;		goto mem_common;	case OpES:		op->type = OP_IMM;		op->val = VCPU_SREG_ES;		break;	case OpCS:		op->type = OP_IMM;		op->val = VCPU_SREG_CS;		break;	case OpSS:		op->type = OP_IMM;		op->val = VCPU_SREG_SS;		break;	case OpDS:		op->type = OP_IMM;		op->val = VCPU_SREG_DS;		break;	case OpFS:		op->type = OP_IMM;		op->val = VCPU_SREG_FS;		break;	case OpGS:		op->type = OP_IMM;		op->val = VCPU_SREG_GS;		break;	case OpImplicit:		 	default:		op->type = OP_NONE;  		break;	}done:	return rc;}",14096
360,1157,CVE-2017-7533,21,"static void get_fs_root_and_pwd_rcu(struct fs_struct *fs, struct path *root,				    struct path *pwd){	unsigned seq;	do {		seq = read_seqcount_begin(&fs->seq);		*root = fs->root;		*pwd = fs->pwd;	} while (read_seqcount_retry(&fs->seq, seq));}",21629
304,334,CVE-2011-1768,21,"static void ipip6_tunnel_uninit(struct net_device *dev){	struct net *net = dev_net(dev);	struct sit_net *sitn = net_generic(net, sit_net_id);	if (dev == sitn->fb_tunnel_dev) {		spin_lock_bh(&ipip6_lock);		sitn->tunnels_wc[0] = NULL;		spin_unlock_bh(&ipip6_lock);		dev_put(dev);	} else {		ipip6_tunnel_unlink(sitn, netdev_priv(dev));		ipip6_tunnel_del_prl(netdev_priv(dev), NULL);		dev_put(dev);	}}",6821
108,476,CVE-2014-2706,21,int sta_info_insert(struct sta_info *sta){	int err = sta_info_insert_rcu(sta);	rcu_read_unlock();	return err;},11736
430,400,CVE-2011-4348,21,"void sctp_err_finish(struct sock *sk, struct sctp_association *asoc){	sctp_bh_unlock_sock(sk);	if (asoc)		sctp_association_put(asoc);}",10033
98,137,CVE-2012-3552,21,"void inet_get_local_port_range(int *low, int *high){	unsigned seq;	do {		seq = read_seqbegin(&sysctl_local_ports.lock);		*low = sysctl_local_ports.range[0];		*high = sysctl_local_ports.range[1];	} while (read_seqretry(&sysctl_local_ports.lock, seq));}",2823
250,996,CVE-2015-8839,21,"static int ext4_quota_enable(struct super_block *sb, int type, int format_id,			     unsigned int flags){	int err;	struct inode *qf_inode;	unsigned long qf_inums[EXT4_MAXQUOTAS] = {		le32_to_cpu(EXT4_SB(sb)->s_es->s_usr_quota_inum),		le32_to_cpu(EXT4_SB(sb)->s_es->s_grp_quota_inum)	};	BUG_ON(!ext4_has_feature_quota(sb));	if (!qf_inums[type])		return -EPERM;	qf_inode = ext4_iget(sb, qf_inums[type]);	if (IS_ERR(qf_inode)) {		ext4_error(sb, ""Bad quota inode # %lu"", qf_inums[type]);		return PTR_ERR(qf_inode);	}	 	qf_inode->i_flags |= S_NOQUOTA;	err = dquot_enable(qf_inode, type, format_id, flags);	iput(qf_inode);	return err;}",18566
416,624,CVE-2015-7990,21,"static int acquire_in_xmit(struct rds_connection *conn){	return test_and_set_bit(RDS_IN_XMIT, &conn->c_flags) == 0;}",13044
377,1535,CVE-2015-9016,21,"void blk_mq_delay_queue(struct blk_mq_hw_ctx *hctx, unsigned long msecs){	if (unlikely(!blk_mq_hw_queue_mapped(hctx)))		return;	kblockd_schedule_delayed_work_on(blk_mq_hctx_next_cpu(hctx),			&hctx->delay_work, msecs_to_jiffies(msecs));}",26314
246,1139,CVE-2017-7533,21,"static void d_wait_lookup(struct dentry *dentry){	if (d_in_lookup(dentry)) {		DECLARE_WAITQUEUE(wait, current);		add_wait_queue(dentry->d_wait, &wait);		do {			set_current_state(TASK_UNINTERRUPTIBLE);			spin_unlock(&dentry->d_lock);			schedule();			spin_lock(&dentry->d_lock);		} while (d_in_lookup(dentry));	}}",21611
129,219,CVE-2012-3552,21,"int udp_v4_get_port(struct sock *sk, unsigned short snum){	unsigned int hash2_nulladdr =		udp4_portaddr_hash(sock_net(sk), htonl(INADDR_ANY), snum);	unsigned int hash2_partial =		udp4_portaddr_hash(sock_net(sk), inet_sk(sk)->inet_rcv_saddr, 0);	 	udp_sk(sk)->udp_portaddr_hash = hash2_partial;	return udp_lib_get_port(sk, snum, ipv4_rcv_saddr_equal, hash2_nulladdr);}",2905
101,232,CVE-2012-3552,21,"static struct tcp_md5sig_key *tcp_v6_md5_do_lookup(struct sock *sk,						   const struct in6_addr *addr){	struct tcp_sock *tp = tcp_sk(sk);	int i;	BUG_ON(tp == NULL);	if (!tp->md5sig_info || !tp->md5sig_info->entries6)		return NULL;	for (i = 0; i < tp->md5sig_info->entries6; i++) {		if (ipv6_addr_equal(&tp->md5sig_info->keys6[i].addr, addr))			return &tp->md5sig_info->keys6[i].base;	}	return NULL;}",2918
272,1193,CVE-2017-7533,21,"static int complete_walk(struct nameidata *nd){	struct dentry *dentry = nd->path.dentry;	int status;	if (nd->flags & LOOKUP_RCU) {		if (!(nd->flags & LOOKUP_ROOT))			nd->root.mnt = NULL;		if (unlikely(unlazy_walk(nd)))			return -ECHILD;	}	if (likely(!(nd->flags & LOOKUP_JUMPED)))		return 0;	if (likely(!(dentry->d_flags & DCACHE_OP_WEAK_REVALIDATE)))		return 0;	status = dentry->d_op->d_weak_revalidate(dentry, nd->flags);	if (status > 0)		return 0;	if (!status)		status = -ESTALE;	return status;}",21665
140,293,CVE-2011-1768,21,"static void ipip_tunnel_bind_dev(struct net_device *dev){	struct net_device *tdev = NULL;	struct ip_tunnel *tunnel;	struct iphdr *iph;	tunnel = netdev_priv(dev);	iph = &tunnel->parms.iph;	if (iph->daddr) {		struct flowi fl = { .oif = tunnel->parms.link,				    .nl_u = { .ip4_u =					      { .daddr = iph->daddr,						.saddr = iph->saddr,						.tos = RT_TOS(iph->tos) } },				    .proto = IPPROTO_IPIP };		struct rtable *rt;		if (!ip_route_output_key(dev_net(dev), &rt, &fl)) {			tdev = rt->u.dst.dev;			ip_rt_put(rt);		}		dev->flags |= IFF_POINTOPOINT;	}	if (!tdev && tunnel->parms.link)		tdev = __dev_get_by_index(dev_net(dev), tunnel->parms.link);	if (tdev) {		dev->hard_header_len = tdev->hard_header_len + sizeof(struct iphdr);		dev->mtu = tdev->mtu - sizeof(struct iphdr);	}	dev->iflink = tunnel->parms.link;}",6780
206,1134,CVE-2017-7533,21,void d_set_fallthru(struct dentry *dentry){	spin_lock(&dentry->d_lock);	dentry->d_flags |= DCACHE_FALLTHRU;	spin_unlock(&dentry->d_lock);},21606
53,516,CVE-2014-2672,21,"static void setup_frame_info(struct ieee80211_hw *hw,			     struct ieee80211_sta *sta,			     struct sk_buff *skb,			     int framelen){	struct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);	struct ieee80211_key_conf *hw_key = tx_info->control.hw_key;	struct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;	const struct ieee80211_rate *rate;	struct ath_frame_info *fi = get_frame_info(skb);	struct ath_node *an = NULL;	enum ath9k_key_type keytype;	int short_preamble = false;	 	if (tx_info->control.vif &&	    tx_info->control.vif->bss_conf.use_short_preamble)		short_preamble = true;	rate = ieee80211_get_rts_cts_rate(hw, tx_info);	keytype = ath9k_cmn_get_hw_crypto_keytype(skb);	if (sta)		an = (struct ath_node *) sta->drv_priv;	memset(fi, 0, sizeof(*fi));	if (hw_key)		fi->keyix = hw_key->hw_key_idx;	else if (an && ieee80211_is_data(hdr->frame_control) && an->ps_key > 0)		fi->keyix = an->ps_key;	else		fi->keyix = ATH9K_TXKEYIX_INVALID;	fi->keytype = keytype;	fi->framelen = framelen;	if (!rate)		return;	fi->rtscts_rate = rate->hw_value;	if (short_preamble)		fi->rtscts_rate |= rate->hw_value_short;}",11800
239,74,CVE-2012-4508,21,"void ext4_ext_drop_refs(struct ext4_ext_path *path){	int depth = path->p_depth;	int i;	for (i = 0; i <= depth; i++, path++)		if (path->p_bh) {			brelse(path->p_bh);			path->p_bh = NULL;		}}",2719
124,1631,CVE-2019-11599,21,static void userfaultfd_ctx_get(struct userfaultfd_ctx *ctx){	refcount_inc(&ctx->refcount);},27078
196,189,CVE-2012-3552,21,"struct inet_peer *tcp_v4_get_peer(struct sock *sk, int *release_it){	struct rtable *rt = (struct rtable *) __sk_dst_get(sk);	struct inet_sock *inet = inet_sk(sk);	struct inet_peer *peer;	if (!rt || rt->rt_dst != inet->inet_daddr) {		peer = inet_getpeer_v4(inet->inet_daddr, 1);		*release_it = true;	} else {		if (!rt->peer)			rt_bind_peer(rt, 1);		peer = rt->peer;		*release_it = false;	}	return peer;}",2875
368,1683,CVE-2019-6974,21,"static struct kvm_memslots *install_new_memslots(struct kvm *kvm,		int as_id, struct kvm_memslots *slots){	struct kvm_memslots *old_memslots = __kvm_memslots(kvm, as_id);	 	WARN_ON(old_memslots->generation & 1);	slots->generation = old_memslots->generation + 1;	rcu_assign_pointer(kvm->memslots[as_id], slots);	synchronize_srcu_expedited(&kvm->srcu);	 	slots->generation += KVM_ADDRESS_SPACE_NUM * 2 - 1;	kvm_arch_memslots_updated(kvm, slots);	return old_memslots;}",27360
71,1345,CVE-2018-8897,21,"do_spurious_interrupt_bug(struct pt_regs *regs, long error_code){	cond_local_irq_enable(regs);}",25270
396,1026,CVE-2015-4170,21,"int ldsem_down_write_nested(struct ld_semaphore *sem, int subclass,			    long timeout){	might_sleep();	return __ldsem_down_write_nested(sem, subclass, timeout);}",19104
232,1727,CVE-2016-10741,21,"xfs_vm_writepage(	struct page		*page,	struct writeback_control *wbc){	struct xfs_writepage_ctx wpc = {		.io_type = XFS_IO_INVALID,	};	int			ret;	ret = xfs_do_writepage(page, wbc, &wpc);	if (wpc.ioend)		ret = xfs_submit_ioend(wbc, wpc.ioend, ret);	return ret;}",28142
379,1734,CVE-2012-2880,21,"  void LoopSyncShare() {    int should_loop = false;    int loop_iterations = 0;    do {      ASSERT_LT(++loop_iterations, 100) << ""infinite loop detected. please fix"";      should_loop = SyncShareNudge();    } while (should_loop);  }",29192
110,1005,CVE-2015-8839,21,"static int ext4_write_dquot(struct dquot *dquot){	int ret, err;	handle_t *handle;	struct inode *inode;	inode = dquot_to_inode(dquot);	handle = ext4_journal_start(inode, EXT4_HT_QUOTA,				    EXT4_QUOTA_TRANS_BLOCKS(dquot->dq_sb));	if (IS_ERR(handle))		return PTR_ERR(handle);	ret = dquot_commit(dquot);	err = ext4_journal_stop(handle);	if (!ret)		ret = err;	return ret;}",18575
323,1482,CVE-2017-2616,21,"set_path(const struct passwd* pw){  int r;  if (pw->pw_uid)    r = logindefs_setenv(""PATH"", ""ENV_PATH"", _PATH_DEFPATH);  else if ((r = logindefs_setenv(""PATH"", ""ENV_ROOTPATH"", NULL)) != 0)    r = logindefs_setenv(""PATH"", ""ENV_SUPATH"", _PATH_DEFPATH_ROOT);  if (r != 0)    err (EXIT_FAILURE,  _(""failed to set the %s environment variable""), ""PATH"");}",26236
404,673,CVE-2015-3212,21,static void sctp_destruct_sock(struct sock *sk){	struct sctp_sock *sp = sctp_sk(sk);	 	crypto_free_hash(sp->hmac);	inet_sock_destruct(sk);},13625
220,685,CVE-2015-3212,21,"static void sctp_wake_up_waiters(struct sock *sk,				 struct sctp_association *asoc){	struct sctp_association *tmp = asoc;	 	if (asoc->ep->sndbuf_policy)		return __sctp_write_space(asoc);	 	if (asoc->base.dead)		return sctp_write_space(sk);	 	for (tmp = list_next_entry(tmp, asocs); 1;	     tmp = list_next_entry(tmp, asocs)) {		 		if (&tmp->asocs == &((sctp_sk(sk))->ep->asocs))			continue;		 		__sctp_write_space(tmp);		 		if (tmp == asoc)			break;	}}",13637
182,784,CVE-2016-7916,21,"static struct dentry *proc_tid_base_lookup(struct inode *dir, struct dentry *dentry, unsigned int flags){	return proc_pident_lookup(dir, dentry,				  tid_base_stuff, ARRAY_SIZE(tid_base_stuff));}",15640
391,1307,CVE-2017-6001,21,"static int perf_tp_filter_match(struct perf_event *event,				struct perf_sample_data *data){	void *record = data->raw->frag.data;	 	if (event->parent)		event = event->parent;	if (likely(!event->filter) || filter_match_preds(event->filter, record))		return 1;	return 0;}",21927
189,1521,CVE-2015-9016,21,"inline void __blk_mq_end_request(struct request *rq, int error){	blk_account_io_done(rq);	if (rq->end_io) {		rq->end_io(rq, error);	} else {		if (unlikely(blk_bidi_rq(rq)))			blk_mq_free_request(rq->next_rq);		blk_mq_free_request(rq);	}}",26300
58,117,CVE-2012-3552,21,static void icmp_discard(struct sk_buff *skb){},2803
361,1107,CVE-2017-7533,21,"struct dentry *d_ancestor(struct dentry *p1, struct dentry *p2){	struct dentry *p;	for (p = p2; !IS_ROOT(p); p = p->d_parent) {		if (p->d_parent == p1)			return p;	}	return NULL;}",21579
372,907,CVE-2016-0723,21,"int tty_check_change(struct tty_struct *tty){	return __tty_check_change(tty, SIGTTOU);}",18250
111,333,CVE-2011-1768,21,static void ipip6_tunnel_setup(struct net_device *dev){	dev->netdev_ops		= &ipip6_netdev_ops;	dev->destructor 	= free_netdev;	dev->type		= ARPHRD_SIT;	dev->hard_header_len 	= LL_MAX_HEADER + sizeof(struct iphdr);	dev->mtu		= ETH_DATA_LEN - sizeof(struct iphdr);	dev->flags		= IFF_NOARP;	dev->priv_flags	       &= ~IFF_XMIT_DST_RELEASE;	dev->iflink		= 0;	dev->addr_len		= 4;	dev->features		|= NETIF_F_NETNS_LOCAL;},6820
367,1704,CVE-2019-6974,21,"static void update_memslots(struct kvm_memslots *slots,			    struct kvm_memory_slot *new,			    enum kvm_mr_change change){	int id = new->id;	int i = slots->id_to_index[id];	struct kvm_memory_slot *mslots = slots->memslots;	WARN_ON(mslots[i].id != id);	switch (change) {	case KVM_MR_CREATE:		slots->used_slots++;		WARN_ON(mslots[i].npages || !new->npages);		break;	case KVM_MR_DELETE:		slots->used_slots--;		WARN_ON(new->npages || !mslots[i].npages);		break;	default:		break;	}	while (i < KVM_MEM_SLOTS_NUM - 1 &&	       new->base_gfn <= mslots[i + 1].base_gfn) {		if (!mslots[i + 1].npages)			break;		mslots[i] = mslots[i + 1];		slots->id_to_index[mslots[i].id] = i;		i++;	}	 	if (new->npages) {		while (i > 0 &&		       new->base_gfn >= mslots[i - 1].base_gfn) {			mslots[i] = mslots[i - 1];			slots->id_to_index[mslots[i].id] = i;			i--;		}	} else		WARN_ON_ONCE(i != slots->used_slots);	mslots[i] = *new;	slots->id_to_index[mslots[i].id] = i;}",27381
131,1081,CVE-2017-12146,21,int platform_pm_thaw(struct device *dev){	struct device_driver *drv = dev->driver;	int ret = 0;	if (!drv)		return 0;	if (drv->pm) {		if (drv->pm->thaw)			ret = drv->pm->thaw(dev);	} else {		ret = platform_legacy_resume(dev);	}	return ret;},20448
195,77,CVE-2012-4508,21,ext4_ext_more_to_rm(struct ext4_ext_path *path){	BUG_ON(path->p_idx == NULL);	if (path->p_idx < EXT_FIRST_INDEX(path->p_hdr))		return 0;	 	if (le16_to_cpu(path->p_hdr->eh_entries) == path->p_block)		return 0;	return 1;},2722
362,99,CVE-2012-3552,21,"static inline void dccp_v6_send_check(struct sock *sk, struct sk_buff *skb){	struct ipv6_pinfo *np = inet6_sk(sk);	struct dccp_hdr *dh = dccp_hdr(skb);	dccp_csum_outgoing(skb);	dh->dccph_checksum = dccp_v6_csum_finish(skb, &np->saddr, &np->daddr);}",2785
188,1559,CVE-2015-9016,21,void blk_mq_kick_requeue_list(struct request_queue *q){	kblockd_schedule_work(&q->requeue_work);},26338
259,654,CVE-2015-7613,21,"static void sysvipc_proc_stop(struct seq_file *s, void *it){	struct kern_ipc_perm *ipc = it;	struct ipc_proc_iter *iter = s->private;	struct ipc_proc_iface *iface = iter->iface;	struct ipc_ids *ids;	 	if (ipc && ipc != SEQ_START_TOKEN)		ipc_unlock(ipc);	ids = &iter->ns->ids[iface->ids];	 	up_read(&ids->rwsem);}",13092
431,575,CVE-2010-5313,21,"int emulator_write_emulated(unsigned long addr,			    const void *val,			    unsigned int bytes,			    struct x86_exception *exception,			    struct kvm_vcpu *vcpu){	 	if (((addr + bytes - 1) ^ addr) & PAGE_MASK) {		int rc, now;		now = -addr & ~PAGE_MASK;		rc = emulator_write_emulated_onepage(addr, val, now, exception,						     vcpu);		if (rc != X86EMUL_CONTINUE)			return rc;		addr += now;		val += now;		bytes -= now;	}	return emulator_write_emulated_onepage(addr, val, bytes, exception,					       vcpu);}",12799
173,510,CVE-2014-2672,21,"struct ath_txq *ath_txq_setup(struct ath_softc *sc, int qtype, int subtype){	struct ath_hw *ah = sc->sc_ah;	struct ath9k_tx_queue_info qi;	static const int subtype_txq_to_hwq[] = {		[IEEE80211_AC_BE] = ATH_TXQ_AC_BE,		[IEEE80211_AC_BK] = ATH_TXQ_AC_BK,		[IEEE80211_AC_VI] = ATH_TXQ_AC_VI,		[IEEE80211_AC_VO] = ATH_TXQ_AC_VO,	};	int axq_qnum, i;	memset(&qi, 0, sizeof(qi));	qi.tqi_subtype = subtype_txq_to_hwq[subtype];	qi.tqi_aifs = ATH9K_TXQ_USEDEFAULT;	qi.tqi_cwmin = ATH9K_TXQ_USEDEFAULT;	qi.tqi_cwmax = ATH9K_TXQ_USEDEFAULT;	qi.tqi_physCompBuf = 0;	 	if (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) {		qi.tqi_qflags = TXQ_FLAG_TXINT_ENABLE;	} else {		if (qtype == ATH9K_TX_QUEUE_UAPSD)			qi.tqi_qflags = TXQ_FLAG_TXDESCINT_ENABLE;		else			qi.tqi_qflags = TXQ_FLAG_TXEOLINT_ENABLE |					TXQ_FLAG_TXDESCINT_ENABLE;	}	axq_qnum = ath9k_hw_setuptxqueue(ah, qtype, &qi);	if (axq_qnum == -1) {		 		return NULL;	}	if (!ATH_TXQ_SETUP(sc, axq_qnum)) {		struct ath_txq *txq = &sc->tx.txq[axq_qnum];		txq->axq_qnum = axq_qnum;		txq->mac80211_qnum = -1;		txq->axq_link = NULL;		__skb_queue_head_init(&txq->complete_q);		INIT_LIST_HEAD(&txq->axq_q);		INIT_LIST_HEAD(&txq->axq_acq);		spin_lock_init(&txq->axq_lock);		txq->axq_depth = 0;		txq->axq_ampdu_depth = 0;		txq->axq_tx_inprogress = false;		sc->tx.txqsetup |= 1<<axq_qnum;		txq->txq_headidx = txq->txq_tailidx = 0;		for (i = 0; i < ATH_TXFIFO_DEPTH; i++)			INIT_LIST_HEAD(&txq->txq_fifo[i]);	}	return &sc->tx.txq[axq_qnum];}",11794
177,922,CVE-2016-0723,21,"void tty_hangup(struct tty_struct *tty){	tty_debug_hangup(tty, ""hangup\n"");	schedule_work(&tty->hangup_work);}",18265
317,1572,CVE-2015-9016,21,void blk_mq_unfreeze_queue(struct request_queue *q){	int freeze_depth;	freeze_depth = atomic_dec_return(&q->mq_freeze_depth);	WARN_ON_ONCE(freeze_depth < 0);	if (!freeze_depth) {		percpu_ref_reinit(&q->mq_usage_counter);		wake_up_all(&q->mq_freeze_wq);	}},26351
163,1772,CVE-2013-0871,21,static inline int may_ptrace_stop(void){	if (!likely(current->ptrace))		return 0;	  	if (unlikely(current->mm->core_state) && 	    unlikely(current->mm == current->parent->mm))		return 0;	return 1;},31096
209,1732,CVE-2012-5108,21,  MockRenderCallback() {},29173
347,1358,CVE-2017-18249,21,"void build_free_nids(struct f2fs_sb_info *sbi, int sync, int mount){	mutex_lock(&NM_I(sbi)->build_lock);	__build_free_nids(sbi, sync, mount);	mutex_unlock(&NM_I(sbi)->build_lock);}",25676
288,369,CVE-2013-3302,21,"wait_for_free_request(struct TCP_Server_Info *server, const int timeout,		      const int optype){	return wait_for_free_credits(server, timeout,				server->ops->get_credits_field(server, optype));}",8020
146,1260,CVE-2017-6001,21,static int is_kernel_event(struct perf_event *event){	return READ_ONCE(event->owner) == TASK_TOMBSTONE;},21880
68,1065,CVE-2017-12146,21,"static int platform_drv_probe(struct device *_dev){	struct platform_driver *drv = to_platform_driver(_dev->driver);	struct platform_device *dev = to_platform_device(_dev);	int ret;	ret = of_clk_set_defaults(_dev->of_node, false);	if (ret < 0)		return ret;	ret = dev_pm_domain_attach(_dev, true);	if (ret != -EPROBE_DEFER) {		if (drv->probe) {			ret = drv->probe(dev);			if (ret)				dev_pm_domain_detach(_dev, true);		} else {			 			ret = 0;		}	}	if (drv->prevent_deferred_probe && ret == -EPROBE_DEFER) {		dev_warn(_dev, ""probe deferral not supported\n"");		ret = -ENXIO;	}	return ret;}",20432
312,1377,CVE-2017-18224,21,"static int ocfs2_writepage(struct page *page, struct writeback_control *wbc){	trace_ocfs2_writepage(		(unsigned long long)OCFS2_I(page->mapping->host)->ip_blkno,		page->index);	return block_write_full_page(page, ocfs2_get_block, wbc);}",25793
216,308,CVE-2011-1768,21,"ip6_tnl_dev_init_gen(struct net_device *dev){	struct ip6_tnl *t = netdev_priv(dev);	t->dev = dev;	strcpy(t->parms.name, dev->name);}",6795
201,1721,CVE-2016-10741,21,"xfs_start_page_writeback(	struct page		*page,	int			clear_dirty){	ASSERT(PageLocked(page));	ASSERT(!PageWriteback(page));	 	if (clear_dirty) {		clear_page_dirty_for_io(page);		set_page_writeback(page);	} else		set_page_writeback_keepwrite(page);	unlock_page(page);}",28136
132,1710,CVE-2016-10741,21,"xfs_chain_bio(	struct xfs_ioend	*ioend,	struct writeback_control *wbc,	struct buffer_head	*bh){	struct bio *new;	new = bio_alloc(GFP_NOFS, BIO_MAX_PAGES);	xfs_init_bio_from_bh(new, bh);	bio_chain(ioend->io_bio, new);	bio_get(ioend->io_bio);		 	bio_set_op_attrs(ioend->io_bio, REQ_OP_WRITE,			  (wbc->sync_mode == WB_SYNC_ALL) ? WRITE_SYNC : 0);	submit_bio(ioend->io_bio);	ioend->io_bio = new;}",28125
5,724,CVE-2014-9710,21,"tree_mod_log_eb_move(struct btrfs_fs_info *fs_info, struct extent_buffer *dst,		     int dst_offset, int src_offset, int nr_items){	int ret;	ret = tree_mod_log_insert_move(fs_info, dst, dst_offset, src_offset,				       nr_items, GFP_NOFS);	BUG_ON(ret < 0);}",14141
153,652,CVE-2015-7613,21,"static int sysvipc_proc_open(struct inode *inode, struct file *file){	struct ipc_proc_iter *iter;	iter = __seq_open_private(file, &sysvipc_proc_seqops, sizeof(*iter));	if (!iter)		return -ENOMEM;	iter->iface = PDE_DATA(inode);	iter->ns    = get_ipc_ns(current->nsproxy->ipc_ns);	return 0;}",13090
193,1756,CVE-2012-3552,21,"struct sock *dccp_v4_request_recv_sock(struct sock *sk, struct sk_buff *skb,				       struct request_sock *req,				       struct dst_entry *dst){	struct inet_request_sock *ireq;	struct inet_sock *newinet;	struct sock *newsk;	if (sk_acceptq_is_full(sk))		goto exit_overflow;	if (dst == NULL && (dst = inet_csk_route_req(sk, req)) == NULL)		goto exit;	newsk = dccp_create_openreq_child(sk, req, skb);	if (newsk == NULL)		goto exit_nonewsk;	sk_setup_caps(newsk, dst);	newinet		   = inet_sk(newsk);	ireq		   = inet_rsk(req); 	newinet->inet_daddr	= ireq->rmt_addr; 	newinet->inet_rcv_saddr = ireq->loc_addr; 	newinet->inet_saddr	= ireq->loc_addr;	newinet->opt	   = ireq->opt; 	ireq->opt	   = NULL; 	newinet->mc_index  = inet_iif(skb); 	newinet->mc_ttl	   = ip_hdr(skb)->ttl;	newinet->inet_id   = jiffies;	dccp_sync_mss(newsk, dst_mtu(dst));	if (__inet_inherit_port(sk, newsk) < 0) {		sock_put(newsk);		goto exit;	}	__inet_hash_nolisten(newsk, NULL);	return newsk;exit_overflow:	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);exit_nonewsk:	dst_release(dst);exit:	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_LISTENDROPS);	return NULL;}",30922
119,711,CVE-2014-9710,21,"int btrfs_search_slot_for_read(struct btrfs_root *root,			       struct btrfs_key *key, struct btrfs_path *p,			       int find_higher, int return_any){	int ret;	struct extent_buffer *leaf;again:	ret = btrfs_search_slot(NULL, root, key, p, 0, 0);	if (ret <= 0)		return ret;	 	leaf = p->nodes[0];	if (find_higher) {		if (p->slots[0] >= btrfs_header_nritems(leaf)) {			ret = btrfs_next_leaf(root, p);			if (ret <= 0)				return ret;			if (!return_any)				return 1;			 			return_any = 0;			find_higher = 0;			btrfs_release_path(p);			goto again;		}	} else {		if (p->slots[0] == 0) {			ret = btrfs_prev_leaf(root, p);			if (ret < 0)				return ret;			if (!ret) {				leaf = p->nodes[0];				if (p->slots[0] == btrfs_header_nritems(leaf))					p->slots[0]--;				return 0;			}			if (!return_any)				return 1;			 			return_any = 0;			find_higher = 1;			btrfs_release_path(p);			goto again;		} else {			--p->slots[0];		}	}	return 0;}",14128
74,850,CVE-2016-2544,21,"struct snd_seq_queue *queueptr(int queueid){	struct snd_seq_queue *q;	unsigned long flags;	if (queueid < 0 || queueid >= SNDRV_SEQ_MAX_QUEUES)		return NULL;	spin_lock_irqsave(&queue_list_lock, flags);	q = queue_list[queueid];	if (q)		snd_use_lock_use(&q->use_lock);	spin_unlock_irqrestore(&queue_list_lock, flags);	return q;}",17524
22,1425,CVE-2017-18203,21,"void dm_init_md_queue(struct mapped_device *md){	 	queue_flag_clear_unlocked(QUEUE_FLAG_STACKABLE, md->queue);	 	md->queue->queuedata = md;	md->queue->backing_dev_info->congested_data = md;}",25960
19,432,CVE-2014-7842,21,"static void kvm_vcpu_ioctl_x86_get_debugregs(struct kvm_vcpu *vcpu,					     struct kvm_debugregs *dbgregs){	unsigned long val;	memcpy(dbgregs->db, vcpu->arch.db, sizeof(vcpu->arch.db));	_kvm_get_dr(vcpu, 6, &val);	dbgregs->dr6 = val;	dbgregs->dr7 = vcpu->arch.dr7;	dbgregs->flags = 0;	memset(&dbgregs->reserved, 0, sizeof(dbgregs->reserved));}",10499
324,1451,CVE-2017-18203,21,void dm_sync_table(struct mapped_device *md){	synchronize_srcu(&md->io_barrier);	synchronize_rcu_expedited();},25986
115,1238,CVE-2017-6001,21,"static void __perf_event_disable(struct perf_event *event,				 struct perf_cpu_context *cpuctx,				 struct perf_event_context *ctx,				 void *info){	if (event->state < PERF_EVENT_STATE_INACTIVE)		return;	update_context_time(ctx);	update_cgrp_time_from_event(event);	update_group_times(event);	if (event == event->group_leader)		group_sched_out(event, cpuctx, ctx);	else		event_sched_out(event, cpuctx, ctx);	event->state = PERF_EVENT_STATE_OFF;}",21858
345,145,CVE-2012-3552,21,"void ip_flush_pending_frames(struct sock *sk){	__ip_flush_pending_frames(sk, &sk->sk_write_queue, &inet_sk(sk)->cork);}",2831
31,900,CVE-2016-0723,21,"void start_tty(struct tty_struct *tty){	unsigned long flags;	spin_lock_irqsave(&tty->flow_lock, flags);	__start_tty(tty);	spin_unlock_irqrestore(&tty->flow_lock, flags);}",18243
265,913,CVE-2016-0723,21,"static int tty_driver_install_tty(struct tty_driver *driver,						struct tty_struct *tty){	return driver->ops->install ? driver->ops->install(driver, tty) :		tty_standard_install(driver, tty);}",18256
234,5,CVE-2012-1174,21,"char *bus_path_unescape(const char *f) {        char *r, *t;        assert(f);        if (!(r = strdup(f)))                return NULL;        for (t = r; *f; f++) {                if (*f == '_') {                        int a, b;                        if ((a = unhexchar(f[1])) < 0 ||                            (b = unhexchar(f[2])) < 0) {                                                                 *(t++) = '_';                        } else {                                *(t++) = (char) ((a << 4) | b);                                f += 2;                        }                } else                        *(t++) = *f;        }        *t = 0;        return r;}",1970
105,363,CVE-2013-3302,21,"cifs_setup_request(struct cifs_ses *ses, struct smb_rqst *rqst){	int rc;	struct smb_hdr *hdr = (struct smb_hdr *)rqst->rq_iov[0].iov_base;	struct mid_q_entry *mid;	rc = allocate_mid(ses, hdr, &mid);	if (rc)		return ERR_PTR(rc);	rc = cifs_sign_rqst(rqst, ses->server, &mid->sequence_number);	if (rc) {		cifs_delete_mid(mid);		return ERR_PTR(rc);	}	return mid;}",8014
397,1491,CVE-2015-9016,21,void blk_free_flush_queue(struct blk_flush_queue *fq){	 	if (!fq)		return;	kfree(fq->flush_rq);	kfree(fq);},26270
402,960,CVE-2015-8839,21,"int ext4_getattr(struct vfsmount *mnt, struct dentry *dentry,		 struct kstat *stat){	struct inode *inode;	unsigned long long delalloc_blocks;	inode = d_inode(dentry);	generic_fillattr(inode, stat);	 	if (unlikely(ext4_has_inline_data(inode)))		stat->blocks += (stat->size + 511) >> 9;	 	delalloc_blocks = EXT4_C2B(EXT4_SB(inode->i_sb),				   EXT4_I(inode)->i_reserved_data_blocks);	stat->blocks += delalloc_blocks << (inode->i_sb->s_blocksize_bits - 9);	return 0;}",18530
346,525,CVE-2014-0196,21,"static inline void finish_erasing(struct n_tty_data *ldata){	if (ldata->erasing) {		echo_char_raw('/', ldata);		ldata->erasing = 0;	}}",12180
183,884,CVE-2016-0723,21,void deinitialize_tty_struct(struct tty_struct *tty){	tty_ldisc_deinit(tty);},18227
194,1512,CVE-2015-9016,21,static inline int bt_index_inc(int index){	return (index + 1) & (BT_WAIT_QUEUES - 1);},26291
169,1474,CVE-2017-18203,21,"static void start_io_acct(struct dm_io *io){	struct mapped_device *md = io->md;	struct bio *bio = io->bio;	int cpu;	int rw = bio_data_dir(bio);	io->start_time = jiffies;	cpu = part_stat_lock();	part_round_stats(md->queue, cpu, &dm_disk(md)->part0);	part_stat_unlock();	atomic_set(&dm_disk(md)->part0.in_flight[rw],		atomic_inc_return(&md->pending[rw]));	if (unlikely(dm_stats_used(&md->stats)))		dm_stats_account_io(&md->stats, bio_data_dir(bio),				    bio->bi_iter.bi_sector, bio_sectors(bio),				    false, 0, &io->stats_aux);}",26009
79,46,CVE-2012-1174,21,"void rename_process(const char name[8]) {        assert(name);                 prctl(PR_SET_NAME, name);        if (program_invocation_name)                strncpy(program_invocation_name, name, strlen(program_invocation_name));        if (saved_argc > 0) {                int i;                if (saved_argv[0])                        strncpy(saved_argv[0], name, strlen(saved_argv[0]));                for (i = 1; i < saved_argc; i++) {                        if (!saved_argv[i])                                break;                        memset(saved_argv[i], 0, strlen(saved_argv[i]));                }        }}",2011
203,1382,CVE-2017-18203,21,"unsigned __dm_get_module_param(unsigned *module_param,			       unsigned def, unsigned max){	unsigned param = ACCESS_ONCE(*module_param);	unsigned modified_param = 0;	if (!param)		modified_param = def;	else if (param > max)		modified_param = max;	if (modified_param) {		(void)cmpxchg(module_param, param, modified_param);		param = modified_param;	}	return param;}",25917
321,260,CVE-2011-2183,21,"static void break_cow(struct rmap_item *rmap_item){	struct mm_struct *mm = rmap_item->mm;	unsigned long addr = rmap_item->address;	struct vm_area_struct *vma;	 	put_anon_vma(rmap_item->anon_vma);	down_read(&mm->mmap_sem);	if (ksm_test_exit(mm))		goto out;	vma = find_vma(mm, addr);	if (!vma || vma->vm_start > addr)		goto out;	if (!(vma->vm_flags & VM_MERGEABLE) || !vma->anon_vma)		goto out;	break_ksm(vma, addr);out:	up_read(&mm->mmap_sem);}",6727
90,1462,CVE-2017-18203,21,"static void free_minor(int minor){	spin_lock(&_minor_lock);	idr_remove(&_minor_idr, minor);	spin_unlock(&_minor_lock);}",25997
208,732,CVE-2014-9710,21,"static inline int tree_mod_need_log(const struct btrfs_fs_info *fs_info,				    struct extent_buffer *eb){	smp_mb();	if (list_empty(&(fs_info)->tree_mod_seq_list))		return 0;	if (eb && btrfs_header_level(eb) == 0)		return 0;	return 1;}",14149
72,620,CVE-2015-7990,21,"static void rds_conn_message_info_send(struct socket *sock, unsigned int len,				       struct rds_info_iterator *iter,				       struct rds_info_lengths *lens){	rds_conn_message_info(sock, len, iter, lens, 1);}",13040
47,616,CVE-2015-7990,21,"static void rds_conn_info(struct socket *sock, unsigned int len,			  struct rds_info_iterator *iter,			  struct rds_info_lengths *lens){	rds_for_each_conn_info(sock, len, iter, lens,				rds_conn_info_visitor,				sizeof(struct rds_info_connection));}",13036
249,341,CVE-2013-7026,21,"static void shm_close(struct vm_area_struct *vma){	struct file * file = vma->vm_file;	struct shm_file_data *sfd = shm_file_data(file);	struct shmid_kernel *shp;	struct ipc_namespace *ns = sfd->ns;	down_write(&shm_ids(ns).rwsem);	 	shp = shm_lock(ns, sfd->id);	BUG_ON(IS_ERR(shp));	shp->shm_lprid = task_tgid_vnr(current);	shp->shm_dtim = get_seconds();	shp->shm_nattch--;	if (shm_may_destroy(ns, shp))		shm_destroy(ns, shp);	else		shm_unlock(shp);	up_write(&shm_ids(ns).rwsem);}",7061
30,801,CVE-2016-6136,21,"int __audit_log_bprm_fcaps(struct linux_binprm *bprm,			   const struct cred *new, const struct cred *old){	struct audit_aux_data_bprm_fcaps *ax;	struct audit_context *context = current->audit_context;	struct cpu_vfs_cap_data vcaps;	ax = kmalloc(sizeof(*ax), GFP_KERNEL);	if (!ax)		return -ENOMEM;	ax->d.type = AUDIT_BPRM_FCAPS;	ax->d.next = context->aux;	context->aux = (void *)ax;	get_vfs_caps_from_disk(bprm->file->f_path.dentry, &vcaps);	ax->fcap.permitted = vcaps.permitted;	ax->fcap.inheritable = vcaps.inheritable;	ax->fcap.fE = !!(vcaps.magic_etc & VFS_CAP_FLAGS_EFFECTIVE);	ax->fcap_ver = (vcaps.magic_etc & VFS_CAP_REVISION_MASK) >> VFS_CAP_REVISION_SHIFT;	ax->old_pcap.permitted   = old->cap_permitted;	ax->old_pcap.inheritable = old->cap_inheritable;	ax->old_pcap.effective   = old->cap_effective;	ax->new_pcap.permitted   = new->cap_permitted;	ax->new_pcap.inheritable = new->cap_inheritable;	ax->new_pcap.effective   = new->cap_effective;	return 0;}",16286
125,1442,CVE-2017-18203,21,"int dm_resume(struct mapped_device *md){	int r;	struct dm_table *map = NULL;retry:	r = -EINVAL;	mutex_lock_nested(&md->suspend_lock, SINGLE_DEPTH_NESTING);	if (!dm_suspended_md(md))		goto out;	if (dm_suspended_internally_md(md)) {		 		mutex_unlock(&md->suspend_lock);		r = wait_on_bit(&md->flags, DMF_SUSPENDED_INTERNALLY, TASK_INTERRUPTIBLE);		if (r)			return r;		goto retry;	}	map = rcu_dereference_protected(md->map, lockdep_is_held(&md->suspend_lock));	if (!map || !dm_table_get_size(map))		goto out;	r = __dm_resume(md, map);	if (r)		goto out;	clear_bit(DMF_SUSPENDED, &md->flags);out:	mutex_unlock(&md->suspend_lock);	return r;}",25977
380,1069,CVE-2017-12146,21,"int platform_get_irq_byname(struct platform_device *dev, const char *name){	struct resource *r;	if (IS_ENABLED(CONFIG_OF_IRQ) && dev->dev.of_node) {		int ret;		ret = of_irq_get_byname(dev->dev.of_node, name);		if (ret > 0 || ret == -EPROBE_DEFER)			return ret;	}	r = platform_get_resource_byname(dev, IORESOURCE_IRQ, name);	return r ? r->start : -ENXIO;}",20436
407,554,CVE-2014-0196,21,"static void n_tty_set_termios(struct tty_struct *tty, struct ktermios *old){	struct n_tty_data *ldata = tty->disc_data;	if (!old || (old->c_lflag ^ tty->termios.c_lflag) & ICANON) {		bitmap_zero(ldata->read_flags, N_TTY_BUF_SIZE);		ldata->line_start = ldata->read_tail;		if (!L_ICANON(tty) || !read_cnt(ldata)) {			ldata->canon_head = ldata->read_tail;			ldata->push = 0;		} else {			set_bit((ldata->read_head - 1) & (N_TTY_BUF_SIZE - 1),				ldata->read_flags);			ldata->canon_head = ldata->read_head;			ldata->push = 1;		}		ldata->erasing = 0;		ldata->lnext = 0;	}	ldata->icanon = (L_ICANON(tty) != 0);	if (I_ISTRIP(tty) || I_IUCLC(tty) || I_IGNCR(tty) ||	    I_ICRNL(tty) || I_INLCR(tty) || L_ICANON(tty) ||	    I_IXON(tty) || L_ISIG(tty) || L_ECHO(tty) ||	    I_PARMRK(tty)) {		bitmap_zero(ldata->char_map, 256);		if (I_IGNCR(tty) || I_ICRNL(tty))			set_bit('\r', ldata->char_map);		if (I_INLCR(tty))			set_bit('\n', ldata->char_map);		if (L_ICANON(tty)) {			set_bit(ERASE_CHAR(tty), ldata->char_map);			set_bit(KILL_CHAR(tty), ldata->char_map);			set_bit(EOF_CHAR(tty), ldata->char_map);			set_bit('\n', ldata->char_map);			set_bit(EOL_CHAR(tty), ldata->char_map);			if (L_IEXTEN(tty)) {				set_bit(WERASE_CHAR(tty), ldata->char_map);				set_bit(LNEXT_CHAR(tty), ldata->char_map);				set_bit(EOL2_CHAR(tty), ldata->char_map);				if (L_ECHO(tty))					set_bit(REPRINT_CHAR(tty),						ldata->char_map);			}		}		if (I_IXON(tty)) {			set_bit(START_CHAR(tty), ldata->char_map);			set_bit(STOP_CHAR(tty), ldata->char_map);		}		if (L_ISIG(tty)) {			set_bit(INTR_CHAR(tty), ldata->char_map);			set_bit(QUIT_CHAR(tty), ldata->char_map);			set_bit(SUSP_CHAR(tty), ldata->char_map);		}		clear_bit(__DISABLED_CHAR, ldata->char_map);		ldata->raw = 0;		ldata->real_raw = 0;	} else {		ldata->raw = 1;		if ((I_IGNBRK(tty) || (!I_BRKINT(tty) && !I_PARMRK(tty))) &&		    (I_IGNPAR(tty) || !I_INPCK(tty)) &&		    (tty->driver->flags & TTY_DRIVER_REAL_RAW))			ldata->real_raw = 1;		else			ldata->real_raw = 0;	}	n_tty_set_room(tty);	 	if (!I_IXON(tty) && old && (old->c_iflag & IXON) && !tty->flow_stopped) {		start_tty(tty);		process_echoes(tty);	}	 	if (waitqueue_active(&tty->write_wait))		wake_up_interruptible(&tty->write_wait);	if (waitqueue_active(&tty->read_wait))		wake_up_interruptible(&tty->read_wait);}",12209
138,1191,CVE-2017-7533,21,"int __inode_permission(struct inode *inode, int mask){	int retval;	if (unlikely(mask & MAY_WRITE)) {		 		if (IS_IMMUTABLE(inode))			return -EPERM;		 		if (HAS_UNMAPPED_ID(inode))			return -EACCES;	}	retval = do_inode_permission(inode, mask);	if (retval)		return retval;	retval = devcgroup_inode_permission(inode, mask);	if (retval)		return retval;	return security_inode_permission(inode, mask);}",21663
28,809,CVE-2016-6136,21,"void __audit_syscall_exit(int success, long return_code){	struct task_struct *tsk = current;	struct audit_context *context;	if (success)		success = AUDITSC_SUCCESS;	else		success = AUDITSC_FAILURE;	context = audit_take_context(tsk, success, return_code);	if (!context)		return;	if (context->in_syscall && context->current_state == AUDIT_RECORD_CONTEXT)		audit_log_exit(context, tsk);	context->in_syscall = 0;	context->prio = context->state == AUDIT_RECORD_CONTEXT ? ~0ULL : 0;	if (!list_empty(&context->killed_trees))		audit_kill_trees(&context->killed_trees);	audit_free_names(context);	unroll_tree_refs(context, NULL, 0);	audit_free_aux(context);	context->aux = NULL;	context->aux_pids = NULL;	context->target_pid = 0;	context->target_sid = 0;	context->sockaddr_len = 0;	context->type = 0;	context->fds[0] = -1;	if (context->state != AUDIT_RECORD_CONTEXT) {		kfree(context->filterkey);		context->filterkey = NULL;	}	tsk->audit_context = context;}",16294
308,582,CVE-2010-5313,21,"int kvm_arch_init_vm(struct kvm *kvm){	INIT_LIST_HEAD(&kvm->arch.active_mmu_pages);	INIT_LIST_HEAD(&kvm->arch.assigned_dev_head);	 	set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);	spin_lock_init(&kvm->arch.tsc_write_lock);	return 0;}",12806
241,1043,CVE-2017-15649,21,"static struct packet_fanout *fanout_release(struct sock *sk){	struct packet_sock *po = pkt_sk(sk);	struct packet_fanout *f;	mutex_lock(&fanout_mutex);	f = po->fanout;	if (f) {		po->fanout = NULL;		if (refcount_dec_and_test(&f->sk_ref))			list_del(&f->list);		else			f = NULL;		if (po->rollover)			kfree_rcu(po->rollover, rcu);	}	mutex_unlock(&fanout_mutex);	return f;}",19967
157,1575,CVE-2015-9016,21,"static inline struct blk_align_bitmap *get_bm(struct blk_mq_hw_ctx *hctx,					      struct blk_mq_ctx *ctx){	return &hctx->ctx_map.map[ctx->index_hw / hctx->ctx_map.bits_per_word];}",26354
383,1033,CVE-2017-17712,21,"static void raw_close(struct sock *sk, long timeout){	 	rtnl_lock();	ip_ra_control(sk, 0, NULL);	rtnl_unlock();	sk_common_release(sk);}",19574
352,191,CVE-2012-3552,21,"struct tcp_md5sig_key *tcp_v4_md5_lookup(struct sock *sk,					 struct sock *addr_sk){	return tcp_v4_md5_do_lookup(sk, inet_sk(addr_sk)->inet_daddr);}",2877
39,168,CVE-2012-3552,21,"int raw_local_deliver(struct sk_buff *skb, int protocol){	int hash;	struct sock *raw_sk;	hash = protocol & (RAW_HTABLE_SIZE - 1);	raw_sk = sk_head(&raw_v4_hashinfo.ht[hash]);	 	if (raw_sk && !raw_v4_input(skb, ip_hdr(skb), hash))		raw_sk = NULL;	return raw_sk != NULL;}",2854
315,247,CVE-2012-3552,21,"static int l2tp_ip_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len){	struct inet_sock *inet = inet_sk(sk);	struct sockaddr_l2tpip *addr = (struct sockaddr_l2tpip *) uaddr;	int ret = -EINVAL;	int chk_addr_ret;	ret = -EADDRINUSE;	read_lock_bh(&l2tp_ip_lock);	if (__l2tp_ip_bind_lookup(&init_net, addr->l2tp_addr.s_addr, sk->sk_bound_dev_if, addr->l2tp_conn_id))		goto out_in_use;	read_unlock_bh(&l2tp_ip_lock);	lock_sock(sk);	if (sk->sk_state != TCP_CLOSE || addr_len < sizeof(struct sockaddr_l2tpip))		goto out;	chk_addr_ret = inet_addr_type(&init_net, addr->l2tp_addr.s_addr);	ret = -EADDRNOTAVAIL;	if (addr->l2tp_addr.s_addr && chk_addr_ret != RTN_LOCAL &&	    chk_addr_ret != RTN_MULTICAST && chk_addr_ret != RTN_BROADCAST)		goto out;	inet->inet_rcv_saddr = inet->inet_saddr = addr->l2tp_addr.s_addr;	if (chk_addr_ret == RTN_MULTICAST || chk_addr_ret == RTN_BROADCAST)		inet->inet_saddr = 0;   	sk_dst_reset(sk);	l2tp_ip_sk(sk)->conn_id = addr->l2tp_conn_id;	write_lock_bh(&l2tp_ip_lock);	sk_add_bind_node(sk, &l2tp_ip_bind_table);	sk_del_node_init(sk);	write_unlock_bh(&l2tp_ip_lock);	ret = 0;out:	release_sock(sk);	return ret;out_in_use:	read_unlock_bh(&l2tp_ip_lock);	return ret;}",2933
329,133,CVE-2012-3552,21,"int inet_csk_listen_start(struct sock *sk, const int nr_table_entries){	struct inet_sock *inet = inet_sk(sk);	struct inet_connection_sock *icsk = inet_csk(sk);	int rc = reqsk_queue_alloc(&icsk->icsk_accept_queue, nr_table_entries);	if (rc != 0)		return rc;	sk->sk_max_ack_backlog = 0;	sk->sk_ack_backlog = 0;	inet_csk_delack_init(sk);	 	sk->sk_state = TCP_LISTEN;	if (!sk->sk_prot->get_port(sk, inet->inet_num)) {		inet->inet_sport = htons(inet->inet_num);		sk_dst_reset(sk);		sk->sk_prot->hash(sk);		return 0;	}	sk->sk_state = TCP_CLOSE;	__reqsk_queue_destroy(&icsk->icsk_accept_queue);	return -EADDRINUSE;}",2819
440,1469,CVE-2017-18203,21,"static int lock_fs(struct mapped_device *md){	int r;	WARN_ON(md->frozen_sb);	md->frozen_sb = freeze_bdev(md->bdev);	if (IS_ERR(md->frozen_sb)) {		r = PTR_ERR(md->frozen_sb);		md->frozen_sb = NULL;		return r;	}	set_bit(DMF_FROZEN, &md->flags);	return 0;}",26004
424,204,CVE-2012-3552,21,"static int ipv4_rcv_saddr_equal(const struct sock *sk1, const struct sock *sk2){	struct inet_sock *inet1 = inet_sk(sk1), *inet2 = inet_sk(sk2);	return 	(!ipv6_only_sock(sk2)  &&		 (!inet1->inet_rcv_saddr || !inet2->inet_rcv_saddr ||		   inet1->inet_rcv_saddr == inet2->inet_rcv_saddr));}",2890
73,1634,CVE-2019-11599,21,"static struct vm_area_struct *__install_special_mapping(	struct mm_struct *mm,	unsigned long addr, unsigned long len,	unsigned long vm_flags, void *priv,	const struct vm_operations_struct *ops){	int ret;	struct vm_area_struct *vma;	vma = vm_area_alloc(mm);	if (unlikely(vma == NULL))		return ERR_PTR(-ENOMEM);	vma->vm_start = addr;	vma->vm_end = addr + len;	vma->vm_flags = vm_flags | mm->def_flags | VM_DONTEXPAND | VM_SOFTDIRTY;	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);	vma->vm_ops = ops;	vma->vm_private_data = priv;	ret = insert_vm_struct(mm, vma);	if (ret)		goto out;	vm_stat_account(mm, vma->vm_flags, len >> PAGE_SHIFT);	perf_event_mmap(vma);	return vma;out:	vm_area_free(vma);	return ERR_PTR(ret);}",27081
264,456,CVE-2014-4652,21,"static int snd_disconnect_fasync(int fd, struct file *file, int on){	return -ENODEV;}",10854
130,424,CVE-2014-7842,21,"int kvm_arch_vcpu_postcreate(struct kvm_vcpu *vcpu){	int r;	struct msr_data msr;	struct kvm *kvm = vcpu->kvm;	r = vcpu_load(vcpu);	if (r)		return r;	msr.data = 0x0;	msr.index = MSR_IA32_TSC;	msr.host_initiated = true;	kvm_write_tsc(vcpu, &msr);	vcpu_put(vcpu);	schedule_delayed_work(&kvm->arch.kvmclock_sync_work,					KVMCLOCK_SYNC_PERIOD);	return r;}",10491
136,322,CVE-2011-1768,21,"static void ip6ip6_dscp_ecn_decapsulate(struct ip6_tnl *t,					struct ipv6hdr *ipv6h,					struct sk_buff *skb){	if (t->parms.flags & IP6_TNL_F_RCV_DSCP_COPY)		ipv6_copy_dscp(ipv6_get_dsfield(ipv6h), ipv6_hdr(skb));	if (INET_ECN_is_ce(ipv6_get_dsfield(ipv6h)))		IP6_ECN_set_ce(ipv6_hdr(skb));}",6809
247,528,CVE-2014-0196,21,"static inline int is_continuation(unsigned char c, struct tty_struct *tty){	return I_IUTF8(tty) && is_utf8_continuation(c);}",12183
262,945,CVE-2015-8839,21,"static int ext4_file_mmap(struct file *file, struct vm_area_struct *vma){	struct inode *inode = file->f_mapping->host;	if (ext4_encrypted_inode(inode)) {		int err = ext4_get_encryption_info(inode);		if (err)			return 0;		if (ext4_encryption_info(inode) == NULL)			return -ENOKEY;	}	file_accessed(file);	if (IS_DAX(file_inode(file))) {		vma->vm_ops = &ext4_dax_vm_ops;		vma->vm_flags |= VM_MIXEDMAP | VM_HUGEPAGE;	} else {		vma->vm_ops = &ext4_file_vm_ops;	}	return 0;}",18515
36,1227,CVE-2017-7533,21,static int path_parent_directory(struct path *path){	struct dentry *old = path->dentry;	 	path->dentry = dget_parent(path->dentry);	dput(old);	if (unlikely(!path_connected(path)))		return -ENOENT;	return 0;},21699
27,948,CVE-2015-8839,21,"static int __writepage(struct page *page, struct writeback_control *wbc,		       void *data){	struct address_space *mapping = data;	int ret = ext4_writepage(page, wbc);	mapping_set_error(mapping, ret);	return ret;}",18518
32,759,CVE-2016-7916,21,static inline int proc_inode_is_dead(struct inode *inode){	return !proc_pid(inode)->tasks[PIDTYPE_PID].first;},15615
144,180,CVE-2012-3552,21,"struct sk_buff **tcp4_gro_receive(struct sk_buff **head, struct sk_buff *skb){	const struct iphdr *iph = skb_gro_network_header(skb);	switch (skb->ip_summed) {	case CHECKSUM_COMPLETE:		if (!tcp_v4_check(skb_gro_len(skb), iph->saddr, iph->daddr,				  skb->csum)) {			skb->ip_summed = CHECKSUM_UNNECESSARY;			break;		}		 	case CHECKSUM_NONE:		NAPI_GRO_CB(skb)->flush = 1;		return NULL;	}	return tcp_gro_receive(head, skb);}",2866
260,166,CVE-2012-3552,21,"void raw_hash_sk(struct sock *sk){	struct raw_hashinfo *h = sk->sk_prot->h.raw_hash;	struct hlist_head *head;	head = &h->ht[inet_sk(sk)->inet_num & (RAW_HTABLE_SIZE - 1)];	write_lock_bh(&h->lock);	sk_add_node(sk, head);	sock_prot_inuse_add(sock_net(sk), sk->sk_prot, 1);	write_unlock_bh(&h->lock);}",2852
84,519,CVE-2014-0196,21,"static int do_output_char(unsigned char c, struct tty_struct *tty, int space){	struct n_tty_data *ldata = tty->disc_data;	int	spaces;	if (!space)		return -1;	switch (c) {	case '\n':		if (O_ONLRET(tty))			ldata->column = 0;		if (O_ONLCR(tty)) {			if (space < 2)				return -1;			ldata->canon_column = ldata->column = 0;			tty->ops->write(tty, ""\r\n"", 2);			return 2;		}		ldata->canon_column = ldata->column;		break;	case '\r':		if (O_ONOCR(tty) && ldata->column == 0)			return 0;		if (O_OCRNL(tty)) {			c = '\n';			if (O_ONLRET(tty))				ldata->canon_column = ldata->column = 0;			break;		}		ldata->canon_column = ldata->column = 0;		break;	case '\t':		spaces = 8 - (ldata->column & 7);		if (O_TABDLY(tty) == XTABS) {			if (space < spaces)				return -1;			ldata->column += spaces;			tty->ops->write(tty, ""        "", spaces);			return spaces;		}		ldata->column += spaces;		break;	case '\b':		if (ldata->column > 0)			ldata->column--;		break;	default:		if (!iscntrl(c)) {			if (O_OLCUC(tty))				c = toupper(c);			if (!is_continuation(c, tty))				ldata->column++;		}		break;	}	tty_put_char(tty, c);	return 1;}",12174
10,1031,CVE-2015-4170,21,"static inline int writer_trylock(struct ld_semaphore *sem){	 	long count = ldsem_atomic_update(LDSEM_ACTIVE_BIAS, sem);	do {		if ((count & LDSEM_ACTIVE_MASK) == LDSEM_ACTIVE_BIAS)			return 1;		if (ldsem_cmpxchg(&count, count - LDSEM_ACTIVE_BIAS, sem))			return 0;	} while (1);}",19109
113,891,CVE-2016-0723,21,"static long hung_up_tty_ioctl(struct file *file, unsigned int cmd,		unsigned long arg){	return cmd == TIOCSPGRP ? -ENOTTY : -EIO;}",18234
359,217,CVE-2012-3552,21,"static int udp_seq_open(struct inode *inode, struct file *file){	struct udp_seq_afinfo *afinfo = PDE(inode)->data;	struct udp_iter_state *s;	int err;	err = seq_open_net(inode, file, &afinfo->seq_ops,			   sizeof(struct udp_iter_state));	if (err < 0)		return err;	s = ((struct seq_file *)file->private_data)->private;	s->family		= afinfo->family;	s->udp_table		= afinfo->udp_table;	return err;}",2903
328,625,CVE-2015-7990,21,"void rds_atomic_send_complete(struct rds_message *rm, int status){	struct rds_sock *rs = NULL;	struct rm_atomic_op *ao;	struct rds_notifier *notifier;	unsigned long flags;	spin_lock_irqsave(&rm->m_rs_lock, flags);	ao = &rm->atomic;	if (test_bit(RDS_MSG_ON_SOCK, &rm->m_flags)	    && ao->op_active && ao->op_notify && ao->op_notifier) {		notifier = ao->op_notifier;		rs = rm->m_rs;		sock_hold(rds_rs_to_sk(rs));		notifier->n_status = status;		spin_lock(&rs->rs_lock);		list_add_tail(&notifier->n_list, &rs->rs_notify_queue);		spin_unlock(&rs->rs_lock);		ao->op_notifier = NULL;	}	spin_unlock_irqrestore(&rm->m_rs_lock, flags);	if (rs) {		rds_wake_sk_sleep(rs);		sock_put(rds_rs_to_sk(rs));	}}",13045
197,357,CVE-2013-3302,21,"SendReceiveNoRsp(const unsigned int xid, struct cifs_ses *ses,		 char *in_buf, int flags){	int rc;	struct kvec iov[1];	int resp_buf_type;	iov[0].iov_base = in_buf;	iov[0].iov_len = get_rfc1002_length(in_buf) + 4;	flags |= CIFS_NO_RESP;	rc = SendReceive2(xid, ses, iov, 1, &resp_buf_type, flags);	cFYI(DBG2, ""SendRcvNoRsp flags %d rc %d"", flags, rc);	return rc;}",8008
432,737,CVE-2014-9710,21,"int btrfs_removexattr(struct dentry *dentry, const char *name){	struct btrfs_root *root = BTRFS_I(dentry->d_inode)->root;	 	if (btrfs_root_readonly(root))		return -EROFS;	 	if (!strncmp(name, XATTR_SYSTEM_PREFIX, XATTR_SYSTEM_PREFIX_LEN))		return generic_removexattr(dentry, name);	if (!btrfs_is_valid_xattr(name))		return -EOPNOTSUPP;	if (!strncmp(name, XATTR_BTRFS_PREFIX, XATTR_BTRFS_PREFIX_LEN))		return btrfs_set_prop(dentry->d_inode, name,				      NULL, 0, XATTR_REPLACE);	return __btrfs_setxattr(NULL, dentry->d_inode, name, NULL, 0,				XATTR_REPLACE);}",14154
375,1087,CVE-2017-7533,21,"static void __d_instantiate(struct dentry *dentry, struct inode *inode){	unsigned add_flags = d_flags_for_inode(inode);	WARN_ON(d_in_lookup(dentry));	spin_lock(&dentry->d_lock);	hlist_add_head(&dentry->d_u.d_alias, &inode->i_dentry);	raw_write_seqcount_begin(&dentry->d_seq);	__d_set_inode_and_type(dentry, inode, add_flags);	raw_write_seqcount_end(&dentry->d_seq);	fsnotify_update_flags(dentry);	spin_unlock(&dentry->d_lock);}",21559
221,876,CVE-2016-0723,21,"static void __proc_set_tty(struct tty_struct *tty){	unsigned long flags;	spin_lock_irqsave(&tty->ctrl_lock, flags);	 	put_pid(tty->session);	put_pid(tty->pgrp);	tty->pgrp = get_pid(task_pgrp(current));	spin_unlock_irqrestore(&tty->ctrl_lock, flags);	tty->session = get_pid(task_session(current));	if (current->signal->tty) {		tty_debug(tty, ""current tty %s not NULL!!\n"",			  current->signal->tty->name);		tty_kref_put(current->signal->tty);	}	put_pid(current->signal->tty_old_pgrp);	current->signal->tty = tty_kref_get(tty);	current->signal->tty_old_pgrp = NULL;}",18219
37,167,CVE-2012-3552,21,"static int raw_init(struct sock *sk){	struct raw_sock *rp = raw_sk(sk);	if (inet_sk(sk)->inet_num == IPPROTO_ICMP)		memset(&rp->filter, 0, sizeof(rp->filter));	return 0;}",2853
426,1093,CVE-2017-7533,21,"static int __d_unalias(struct inode *inode,		struct dentry *dentry, struct dentry *alias){	struct mutex *m1 = NULL;	struct rw_semaphore *m2 = NULL;	int ret = -ESTALE;	 	if (alias->d_parent == dentry->d_parent)		goto out_unalias;	 	if (!mutex_trylock(&dentry->d_sb->s_vfs_rename_mutex))		goto out_err;	m1 = &dentry->d_sb->s_vfs_rename_mutex;	if (!inode_trylock_shared(alias->d_parent->d_inode))		goto out_err;	m2 = &alias->d_parent->d_inode->i_rwsem;out_unalias:	__d_move(alias, dentry, false);	ret = 0;out_err:	if (m2)		up_read(m2);	if (m1)		mutex_unlock(m1);	return ret;}",21565
289,304,CVE-2011-1768,21,"ip6_tnl_change(struct ip6_tnl *t, struct ip6_tnl_parm *p){	ipv6_addr_copy(&t->parms.laddr, &p->laddr);	ipv6_addr_copy(&t->parms.raddr, &p->raddr);	t->parms.flags = p->flags;	t->parms.hop_limit = p->hop_limit;	t->parms.encap_limit = p->encap_limit;	t->parms.flowinfo = p->flowinfo;	t->parms.link = p->link;	t->parms.proto = p->proto;	ip6_tnl_dst_reset(t);	ip6_tnl_link_config(t);	return 0;}",6791
298,592,CVE-2010-5313,21,int kvm_dev_ioctl_check_extension(long ext){	int r;	switch (ext) {	case KVM_CAP_IRQCHIP:	case KVM_CAP_HLT:	case KVM_CAP_MMU_SHADOW_CACHE_CONTROL:	case KVM_CAP_SET_TSS_ADDR:	case KVM_CAP_EXT_CPUID:	case KVM_CAP_CLOCKSOURCE:	case KVM_CAP_PIT:	case KVM_CAP_NOP_IO_DELAY:	case KVM_CAP_MP_STATE:	case KVM_CAP_SYNC_MMU:	case KVM_CAP_REINJECT_CONTROL:	case KVM_CAP_IRQ_INJECT_STATUS:	case KVM_CAP_ASSIGN_DEV_IRQ:	case KVM_CAP_IRQFD:	case KVM_CAP_IOEVENTFD:	case KVM_CAP_PIT2:	case KVM_CAP_PIT_STATE2:	case KVM_CAP_SET_IDENTITY_MAP_ADDR:	case KVM_CAP_XEN_HVM:	case KVM_CAP_ADJUST_CLOCK:	case KVM_CAP_VCPU_EVENTS:	case KVM_CAP_HYPERV:	case KVM_CAP_HYPERV_VAPIC:	case KVM_CAP_HYPERV_SPIN:	case KVM_CAP_PCI_SEGMENT:	case KVM_CAP_DEBUGREGS:	case KVM_CAP_X86_ROBUST_SINGLESTEP:	case KVM_CAP_XSAVE:	case KVM_CAP_ASYNC_PF:		r = 1;		break;	case KVM_CAP_COALESCED_MMIO:		r = KVM_COALESCED_MMIO_PAGE_OFFSET;		break;	case KVM_CAP_VAPIC:		r = !kvm_x86_ops->cpu_has_accelerated_tpr();		break;	case KVM_CAP_NR_VCPUS:		r = KVM_MAX_VCPUS;		break;	case KVM_CAP_NR_MEMSLOTS:		r = KVM_MEMORY_SLOTS;		break;	case KVM_CAP_PV_MMU:	 		r = 0;		break;	case KVM_CAP_IOMMU:		r = iommu_found();		break;	case KVM_CAP_MCE:		r = KVM_MAX_MCE_BANKS;		break;	case KVM_CAP_XCRS:		r = cpu_has_xsave;		break;	default:		r = 0;		break;	}	return r;},12816
387,1616,CVE-2019-11599,21,"static void __show_smap(struct seq_file *m, const struct mem_size_stats *mss){	SEQ_PUT_DEC(""Rss:            "", mss->resident);	SEQ_PUT_DEC("" kB\nPss:            "", mss->pss >> PSS_SHIFT);	SEQ_PUT_DEC("" kB\nShared_Clean:   "", mss->shared_clean);	SEQ_PUT_DEC("" kB\nShared_Dirty:   "", mss->shared_dirty);	SEQ_PUT_DEC("" kB\nPrivate_Clean:  "", mss->private_clean);	SEQ_PUT_DEC("" kB\nPrivate_Dirty:  "", mss->private_dirty);	SEQ_PUT_DEC("" kB\nReferenced:     "", mss->referenced);	SEQ_PUT_DEC("" kB\nAnonymous:      "", mss->anonymous);	SEQ_PUT_DEC("" kB\nLazyFree:       "", mss->lazyfree);	SEQ_PUT_DEC("" kB\nAnonHugePages:  "", mss->anonymous_thp);	SEQ_PUT_DEC("" kB\nShmemPmdMapped: "", mss->shmem_thp);	SEQ_PUT_DEC("" kB\nShared_Hugetlb: "", mss->shared_hugetlb);	seq_put_decimal_ull_width(m, "" kB\nPrivate_Hugetlb: "",				  mss->private_hugetlb >> 10, 7);	SEQ_PUT_DEC("" kB\nSwap:           "", mss->swap);	SEQ_PUT_DEC("" kB\nSwapPss:        "",					mss->swap_pss >> PSS_SHIFT);	SEQ_PUT_DEC("" kB\nLocked:         "",					mss->pss_locked >> PSS_SHIFT);	seq_puts(m, "" kB\n"");}",27063
202,964,CVE-2015-8839,21,int ext4_inode_is_fast_symlink(struct inode *inode){        int ea_blocks = EXT4_I(inode)->i_file_acl ?		EXT4_CLUSTER_SIZE(inode->i_sb) >> 9 : 0;	if (ext4_has_inline_data(inode))		return 0;	return (S_ISLNK(inode->i_mode) && inode->i_blocks - ea_blocks == 0);},18534
354,1300,CVE-2017-6001,21,"static int perf_release(struct inode *inode, struct file *file){	perf_event_release_kernel(file->private_data);	return 0;}",21920
145,1187,CVE-2017-7533,21,static struct dentry *end_creating(struct dentry *dentry){	inode_unlock(d_inode(dentry->d_parent));	return dentry;},21659
13,541,CVE-2014-0196,21,"static int n_tty_receive_buf2(struct tty_struct *tty, const unsigned char *cp,			      char *fp, int count){	return n_tty_receive_buf_common(tty, cp, fp, count, 1);}",12196
334,994,CVE-2015-8839,21,static struct dquot **ext4_get_dquots(struct inode *inode){	return EXT4_I(inode)->i_dquot;},18564
408,261,CVE-2011-2183,21,"static int break_ksm(struct vm_area_struct *vma, unsigned long addr){	struct page *page;	int ret = 0;	do {		cond_resched();		page = follow_page(vma, addr, FOLL_GET);		if (IS_ERR_OR_NULL(page))			break;		if (PageKsm(page))			ret = handle_mm_fault(vma->vm_mm, vma, addr,							FAULT_FLAG_WRITE);		else			ret = VM_FAULT_WRITE;		put_page(page);	} while (!(ret & (VM_FAULT_WRITE | VM_FAULT_SIGBUS | VM_FAULT_OOM)));	 	return (ret & VM_FAULT_OOM) ? -ENOMEM : 0;}",6728
26,797,CVE-2016-6136,21,"void __audit_file(const struct file *file){	__audit_inode(NULL, file->f_path.dentry, 0);}",16282
191,98,CVE-2012-3552,21,static void dccp_v6_reqsk_destructor(struct request_sock *req){	dccp_feat_list_purge(&dccp_rsk(req)->dreq_featneg);	if (inet6_rsk(req)->pktopts != NULL)		kfree_skb(inet6_rsk(req)->pktopts);},2784
358,1420,CVE-2017-18203,21,"static unsigned dm_get_numa_node(void){	return __dm_get_module_param_int(&dm_numa_node,					 DM_NUMA_NODE, num_online_nodes() - 1);}",25955
52,515,CVE-2014-2672,21,static struct ath_frame_info *get_frame_info(struct sk_buff *skb){	struct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);	BUILD_BUG_ON(sizeof(struct ath_frame_info) >		     sizeof(tx_info->rate_driver_data));	return (struct ath_frame_info *) &tx_info->rate_driver_data[0];},11799
419,24,CVE-2012-1174,21,"int getttyname_malloc(int fd, char **r) {        char path[PATH_MAX], *c;        int k;        assert(r);        if ((k = ttyname_r(fd, path, sizeof(path))) != 0)                return -k;        char_array_0(path);        if (!(c = strdup(startswith(path, ""/dev/"") ? path + 5 : path)))                return -ENOMEM;        *r = c;        return 0;}",1989
356,245,CVE-2012-3552,21,"void tcpv6_exit(void){	unregister_pernet_subsys(&tcpv6_net_ops);	inet6_unregister_protosw(&tcpv6_protosw);	inet6_del_protocol(&tcpv6_protocol, IPPROTO_TCP);}",2931
274,446,CVE-2014-4652,21,int snd_card_free(struct snd_card *card){	struct completion released;	int ret;	init_completion(&released);	card->release_completion = &released;	ret = snd_card_free_when_closed(card);	if (ret)		return ret;	 	wait_for_completion(&released);	return 0;},10844
245,426,CVE-2014-7842,21,"static void kvm_gen_kvmclock_update(struct kvm_vcpu *v){	struct kvm *kvm = v->kvm;	kvm_make_request(KVM_REQ_CLOCK_UPDATE, v);	schedule_delayed_work(&kvm->arch.kvmclock_update_work,					KVMCLOCK_UPDATE_DELAY);}",10493
314,136,CVE-2012-3552,21,"static int inet_csk_wait_for_connect(struct sock *sk, long timeo){	struct inet_connection_sock *icsk = inet_csk(sk);	DEFINE_WAIT(wait);	int err;	 	for (;;) {		prepare_to_wait_exclusive(sk_sleep(sk), &wait,					  TASK_INTERRUPTIBLE);		release_sock(sk);		if (reqsk_queue_empty(&icsk->icsk_accept_queue))			timeo = schedule_timeout(timeo);		lock_sock(sk);		err = 0;		if (!reqsk_queue_empty(&icsk->icsk_accept_queue))			break;		err = -EINVAL;		if (sk->sk_state != TCP_LISTEN)			break;		err = sock_intr_errno(timeo);		if (signal_pending(current))			break;		err = -EAGAIN;		if (!timeo)			break;	}	finish_wait(sk_sleep(sk), &wait);	return err;}",2822
316,774,CVE-2016-7916,21,"static int proc_pident_readdir(struct file *file, struct dir_context *ctx,		const struct pid_entry *ents, unsigned int nents){	struct task_struct *task = get_proc_task(file_inode(file));	const struct pid_entry *p;	if (!task)		return -ENOENT;	if (!dir_emit_dots(file, ctx))		goto out;	if (ctx->pos >= nents + 2)		goto out;	for (p = ents + (ctx->pos - 2); p <= ents + nents - 1; p++) {		if (!proc_fill_cache(file, ctx, p->name, p->len,				proc_pident_instantiate, task, p))			break;		ctx->pos++;	}out:	put_task_struct(task);	return 0;}",15630
421,276,CVE-2011-2183,21,"static int ksm_scan_thread(void *nothing){	set_freezable();	set_user_nice(current, 5);	while (!kthread_should_stop()) {		mutex_lock(&ksm_thread_mutex);		if (ksmd_should_run())			ksm_do_scan(ksm_thread_pages_to_scan);		mutex_unlock(&ksm_thread_mutex);		try_to_freeze();		if (ksmd_should_run()) {			schedule_timeout_interruptible(				msecs_to_jiffies(ksm_thread_sleep_millisecs));		} else {			wait_event_freezable(ksm_thread_wait,				ksmd_should_run() || kthread_should_stop());		}	}	return 0;}",6743
217,700,CVE-2014-9710,21,"static int balance_node_right(struct btrfs_trans_handle *trans,			      struct btrfs_root *root,			      struct extent_buffer *dst,			      struct extent_buffer *src){	int push_items = 0;	int max_push;	int src_nritems;	int dst_nritems;	int ret = 0;	WARN_ON(btrfs_header_generation(src) != trans->transid);	WARN_ON(btrfs_header_generation(dst) != trans->transid);	src_nritems = btrfs_header_nritems(src);	dst_nritems = btrfs_header_nritems(dst);	push_items = BTRFS_NODEPTRS_PER_BLOCK(root) - dst_nritems;	if (push_items <= 0)		return 1;	if (src_nritems < 4)		return 1;	max_push = src_nritems / 2 + 1;	 	if (max_push >= src_nritems)		return 1;	if (max_push < push_items)		push_items = max_push;	tree_mod_log_eb_move(root->fs_info, dst, push_items, 0, dst_nritems);	memmove_extent_buffer(dst, btrfs_node_key_ptr_offset(push_items),				      btrfs_node_key_ptr_offset(0),				      (dst_nritems) *				      sizeof(struct btrfs_key_ptr));	ret = tree_mod_log_eb_copy(root->fs_info, dst, src, 0,				   src_nritems - push_items, push_items);	if (ret) {		btrfs_abort_transaction(trans, root, ret);		return ret;	}	copy_extent_buffer(dst, src,			   btrfs_node_key_ptr_offset(0),			   btrfs_node_key_ptr_offset(src_nritems - push_items),			   push_items * sizeof(struct btrfs_key_ptr));	btrfs_set_header_nritems(src, src_nritems - push_items);	btrfs_set_header_nritems(dst, dst_nritems + push_items);	btrfs_mark_buffer_dirty(src);	btrfs_mark_buffer_dirty(dst);	return ret;}",14117
281,1608,CVE-2019-11599,21,"static int ib_uverbs_mmap(struct file *filp, struct vm_area_struct *vma){	struct ib_uverbs_file *file = filp->private_data;	struct ib_ucontext *ucontext;	int ret = 0;	int srcu_key;	srcu_key = srcu_read_lock(&file->device->disassociate_srcu);	ucontext = ib_uverbs_get_ucontext_file(file);	if (IS_ERR(ucontext)) {		ret = PTR_ERR(ucontext);		goto out;	}	ret = ucontext->device->ops.mmap(ucontext, vma);out:	srcu_read_unlock(&file->device->disassociate_srcu, srcu_key);	return ret;}",27055
133,248,CVE-2012-3552,21,static void l2tp_ip_destroy_sock(struct sock *sk){	struct sk_buff *skb;	while ((skb = __skb_dequeue_tail(&sk->sk_write_queue)) != NULL)		kfree_skb(skb);	sk_refcnt_debug_dec(sk);},2934
83,1405,CVE-2017-18203,21,"int dm_cancel_deferred_remove(struct mapped_device *md){	int r = 0;	spin_lock(&_minor_lock);	if (test_bit(DMF_DELETING, &md->flags))		r = -EBUSY;	else		clear_bit(DMF_DEFERRED_REMOVE, &md->flags);	spin_unlock(&_minor_lock);	return r;}",25940
99,550,CVE-2014-0196,21,"n_tty_receive_char_lnext(struct tty_struct *tty, unsigned char c, char flag){	struct n_tty_data *ldata = tty->disc_data;	ldata->lnext = 0;	if (likely(flag == TTY_NORMAL)) {		if (I_ISTRIP(tty))			c &= 0x7f;		if (I_IUCLC(tty) && L_IEXTEN(tty))			c = tolower(c);		n_tty_receive_char(tty, c);	} else		n_tty_receive_char_flagged(tty, c, flag);}",12205
349,1552,CVE-2015-9016,21,"static void blk_mq_hctx_mark_pending(struct blk_mq_hw_ctx *hctx,				     struct blk_mq_ctx *ctx){	struct blk_align_bitmap *bm = get_bm(hctx, ctx);	if (!test_bit(CTX_TO_BIT(hctx, ctx), &bm->word))		set_bit(CTX_TO_BIT(hctx, ctx), &bm->word);}",26331
277,1060,CVE-2017-12146,21,void platform_device_put(struct platform_device *pdev){	if (pdev)		put_device(&pdev->dev);},20427
255,299,CVE-2011-1768,21,"static void ipip_tunnel_uninit(struct net_device *dev){	struct net *net = dev_net(dev);	struct ipip_net *ipn = net_generic(net, ipip_net_id);	if (dev == ipn->fb_tunnel_dev) {		spin_lock_bh(&ipip_lock);		ipn->tunnels_wc[0] = NULL;		spin_unlock_bh(&ipip_lock);	} else		ipip_tunnel_unlink(ipn, netdev_priv(dev));	dev_put(dev);}",6786
409,1357,CVE-2017-18249,21,"int available_free_memory(struct f2fs_sb_info *sbi, int type){	struct f2fs_nm_info *nm_i = NM_I(sbi);	struct sysinfo val;	unsigned long avail_ram;	unsigned long mem_size = 0;	int res = false;	si_meminfo(&val);	 	avail_ram = val.totalram - val.totalhigh;	 	if (type == FREE_NIDS) {		mem_size = (nm_i->nid_cnt[FREE_NID_LIST] *				sizeof(struct free_nid)) >> PAGE_SHIFT;		res = mem_size < ((avail_ram * nm_i->ram_thresh / 100) >> 2);	} else if (type == NAT_ENTRIES) {		mem_size = (nm_i->nat_cnt * sizeof(struct nat_entry)) >>							PAGE_SHIFT;		res = mem_size < ((avail_ram * nm_i->ram_thresh / 100) >> 2);		if (excess_cached_nats(sbi))			res = false;	} else if (type == DIRTY_DENTS) {		if (sbi->sb->s_bdi->wb.dirty_exceeded)			return false;		mem_size = get_pages(sbi, F2FS_DIRTY_DENTS);		res = mem_size < ((avail_ram * nm_i->ram_thresh / 100) >> 1);	} else if (type == INO_ENTRIES) {		int i;		for (i = 0; i <= UPDATE_INO; i++)			mem_size += sbi->im[i].ino_num *						sizeof(struct ino_entry);		mem_size >>= PAGE_SHIFT;		res = mem_size < ((avail_ram * nm_i->ram_thresh / 100) >> 1);	} else if (type == EXTENT_CACHE) {		mem_size = (atomic_read(&sbi->total_ext_tree) *				sizeof(struct extent_tree) +				atomic_read(&sbi->total_ext_node) *				sizeof(struct extent_node)) >> PAGE_SHIFT;		res = mem_size < ((avail_ram * nm_i->ram_thresh / 100) >> 1);	} else {		if (!sbi->sb->s_bdi->wb.dirty_exceeded)			return true;	}	return res;}",25675
168,1372,CVE-2017-18224,21,"static void ocfs2_free_write_ctxt(struct inode *inode,				  struct ocfs2_write_ctxt *wc){	ocfs2_free_unwritten_list(inode, &wc->w_unwritten_list);	ocfs2_unlock_pages(wc);	brelse(wc->w_di_bh);	kfree(wc);}",25788
147,583,CVE-2010-5313,21,void kvm_arch_vcpu_free(struct kvm_vcpu *vcpu){	if (vcpu->arch.time_page) {		kvm_release_page_dirty(vcpu->arch.time_page);		vcpu->arch.time_page = NULL;	}	free_cpumask_var(vcpu->arch.wbinvd_dirty_mask);	fx_free(vcpu);	kvm_x86_ops->vcpu_free(vcpu);},12807
212,63,CVE-2011-4029,21,"XNFstrdup(const char *s){    char *ret;    if (s == NULL)	return NULL;    ret = strdup(s);    if (!ret)	FatalError(""XNFstrdup: Out of memory"");    return ret;}",2210
310,1670,CVE-2019-11599,21,"int split_vma(struct mm_struct *mm, struct vm_area_struct *vma,	      unsigned long addr, int new_below){	if (mm->map_count >= sysctl_max_map_count)		return -ENOMEM;	return __split_vma(mm, vma, addr, new_below);}",27117
107,1430,CVE-2017-18203,21,"void dm_internal_suspend_noflush(struct mapped_device *md){	mutex_lock(&md->suspend_lock);	__dm_internal_suspend(md, DM_SUSPEND_NOFLUSH_FLAG);	mutex_unlock(&md->suspend_lock);}",25965
151,210,CVE-2012-3552,21,void udp_flush_pending_frames(struct sock *sk){	struct udp_sock *up = udp_sk(sk);	if (up->pending) {		up->len = 0;		up->pending = 0;		ip_flush_pending_frames(sk);	}},2896
443,830,CVE-2016-5195,21,"struct page *follow_page_mask(struct vm_area_struct *vma,			      unsigned long address, unsigned int flags,			      unsigned int *page_mask){	pgd_t *pgd;	pud_t *pud;	pmd_t *pmd;	spinlock_t *ptl;	struct page *page;	struct mm_struct *mm = vma->vm_mm;	*page_mask = 0;	page = follow_huge_addr(mm, address, flags & FOLL_WRITE);	if (!IS_ERR(page)) {		BUG_ON(flags & FOLL_GET);		return page;	}	pgd = pgd_offset(mm, address);	if (pgd_none(*pgd) || unlikely(pgd_bad(*pgd)))		return no_page_table(vma, flags);	pud = pud_offset(pgd, address);	if (pud_none(*pud))		return no_page_table(vma, flags);	if (pud_huge(*pud) && vma->vm_flags & VM_HUGETLB) {		page = follow_huge_pud(mm, address, pud, flags);		if (page)			return page;		return no_page_table(vma, flags);	}	if (unlikely(pud_bad(*pud)))		return no_page_table(vma, flags);	pmd = pmd_offset(pud, address);	if (pmd_none(*pmd))		return no_page_table(vma, flags);	if (pmd_huge(*pmd) && vma->vm_flags & VM_HUGETLB) {		page = follow_huge_pmd(mm, address, pmd, flags);		if (page)			return page;		return no_page_table(vma, flags);	}	if ((flags & FOLL_NUMA) && pmd_protnone(*pmd))		return no_page_table(vma, flags);	if (pmd_devmap(*pmd)) {		ptl = pmd_lock(mm, pmd);		page = follow_devmap_pmd(vma, address, pmd, flags);		spin_unlock(ptl);		if (page)			return page;	}	if (likely(!pmd_trans_huge(*pmd)))		return follow_page_pte(vma, address, pmd, flags);	ptl = pmd_lock(mm, pmd);	if (unlikely(!pmd_trans_huge(*pmd))) {		spin_unlock(ptl);		return follow_page_pte(vma, address, pmd, flags);	}	if (flags & FOLL_SPLIT) {		int ret;		page = pmd_page(*pmd);		if (is_huge_zero_page(page)) {			spin_unlock(ptl);			ret = 0;			split_huge_pmd(vma, pmd, address);			if (pmd_trans_unstable(pmd))				ret = -EBUSY;		} else {			get_page(page);			spin_unlock(ptl);			lock_page(page);			ret = split_huge_page(page);			unlock_page(page);			put_page(page);			if (pmd_none(*pmd))				return no_page_table(vma, flags);		}		return ret ? ERR_PTR(ret) :			follow_page_pte(vma, address, pmd, flags);	}	page = follow_trans_huge_pmd(vma, address, pmd, flags);	spin_unlock(ptl);	*page_mask = HPAGE_PMD_NR - 1;	return page;}",16509
88,329,CVE-2011-1768,21,"static int ipip6_tunnel_change_mtu(struct net_device *dev, int new_mtu){	if (new_mtu < IPV6_MIN_MTU || new_mtu > 0xFFF8 - sizeof(struct iphdr))		return -EINVAL;	dev->mtu = new_mtu;	return 0;}",6816
100,275,CVE-2011-2183,21,"void ksm_migrate_page(struct page *newpage, struct page *oldpage){	struct stable_node *stable_node;	VM_BUG_ON(!PageLocked(oldpage));	VM_BUG_ON(!PageLocked(newpage));	VM_BUG_ON(newpage->mapping != oldpage->mapping);	stable_node = page_stable_node(newpage);	if (stable_node) {		VM_BUG_ON(stable_node->kpfn != page_to_pfn(oldpage));		stable_node->kpfn = page_to_pfn(newpage);	}}",6742
392,1110,CVE-2017-7533,21,"void d_exchange(struct dentry *dentry1, struct dentry *dentry2){	write_seqlock(&rename_lock);	WARN_ON(!dentry1->d_inode);	WARN_ON(!dentry2->d_inode);	WARN_ON(IS_ROOT(dentry1));	WARN_ON(IS_ROOT(dentry2));	__d_move(dentry1, dentry2, true);	write_sequnlock(&rename_lock);}",21582
45,968,CVE-2015-8839,21,"static void ext4_print_free_blocks(struct inode *inode){	struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);	struct super_block *sb = inode->i_sb;	struct ext4_inode_info *ei = EXT4_I(inode);	ext4_msg(sb, KERN_CRIT, ""Total free blocks count %lld"",	       EXT4_C2B(EXT4_SB(inode->i_sb),			ext4_count_free_clusters(sb)));	ext4_msg(sb, KERN_CRIT, ""Free/Dirty block details"");	ext4_msg(sb, KERN_CRIT, ""free_blocks=%lld"",	       (long long) EXT4_C2B(EXT4_SB(sb),		percpu_counter_sum(&sbi->s_freeclusters_counter)));	ext4_msg(sb, KERN_CRIT, ""dirty_blocks=%lld"",	       (long long) EXT4_C2B(EXT4_SB(sb),		percpu_counter_sum(&sbi->s_dirtyclusters_counter)));	ext4_msg(sb, KERN_CRIT, ""Block reservation details"");	ext4_msg(sb, KERN_CRIT, ""i_reserved_data_blocks=%u"",		 ei->i_reserved_data_blocks);	return;}",18538
77,419,CVE-2014-7842,21,"void kvm_arch_destroy_vm(struct kvm *kvm){	if (current->mm == kvm->mm) {		 		struct kvm_userspace_memory_region mem;		memset(&mem, 0, sizeof(mem));		mem.slot = APIC_ACCESS_PAGE_PRIVATE_MEMSLOT;		kvm_set_memory_region(kvm, &mem);		mem.slot = IDENTITY_PAGETABLE_PRIVATE_MEMSLOT;		kvm_set_memory_region(kvm, &mem);		mem.slot = TSS_PRIVATE_MEMSLOT;		kvm_set_memory_region(kvm, &mem);	}	kvm_iommu_unmap_guest(kvm);	kfree(kvm->arch.vpic);	kfree(kvm->arch.vioapic);	kvm_free_vcpus(kvm);	if (kvm->arch.apic_access_page)		put_page(kvm->arch.apic_access_page);	kfree(rcu_dereference_check(kvm->arch.apic_map, 1));}",10486
435,1759,CVE-2012-3552,21, void cipso_v4_req_delattr(struct request_sock *req) {	struct ip_options *opt; 	struct inet_request_sock *req_inet;  	req_inet = inet_rsk(req); 	opt = req_inet->opt;	if (opt == NULL || opt->cipso == 0) 		return;  	cipso_v4_delopt(&req_inet->opt);},30925
9,1039,CVE-2017-15649,21,"static void __fanout_unlink(struct sock *sk, struct packet_sock *po){	struct packet_fanout *f = po->fanout;	int i;	spin_lock(&f->lock);	for (i = 0; i < f->num_members; i++) {		if (f->arr[i] == sk)			break;	}	BUG_ON(i >= f->num_members);	f->arr[i] = f->arr[f->num_members - 1];	f->num_members--;	if (f->num_members == 0)		__dev_remove_pack(&f->prot_hook);	spin_unlock(&f->lock);}",19963
166,1774,CVE-2014-7842,21,"static int handle_emulation_failure(struct kvm_vcpu *vcpu){	int r = EMULATE_DONE;  	++vcpu->stat.insn_emulation_fail; 	trace_kvm_emulate_insn_failed(vcpu);	if (!is_guest_mode(vcpu)) { 		vcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR; 		vcpu->run->internal.suberror = KVM_INTERNAL_ERROR_EMULATION; 		vcpu->run->internal.ndata = 0;		r = EMULATE_FAIL;	}	kvm_queue_exception(vcpu, UD_VECTOR);	return r;}",31120
339,1313,CVE-2017-6001,21,"static int swevent_hlist_get_cpu(int cpu){	struct swevent_htable *swhash = &per_cpu(swevent_htable, cpu);	int err = 0;	mutex_lock(&swhash->hlist_mutex);	if (!swevent_hlist_deref(swhash) && cpu_online(cpu)) {		struct swevent_hlist *hlist;		hlist = kzalloc(sizeof(*hlist), GFP_KERNEL);		if (!hlist) {			err = -ENOMEM;			goto exit;		}		rcu_assign_pointer(swhash->swevent_hlist, hlist);	}	swhash->hlist_refcount++;exit:	mutex_unlock(&swhash->hlist_mutex);	return err;}",21933
57,366,CVE-2013-3302,21,"send_cancel(struct TCP_Server_Info *server, void *buf, struct mid_q_entry *mid){	return server->ops->send_cancel ?				server->ops->send_cancel(server, buf, mid) : 0;}",8017
80,764,CVE-2016-7916,21,"static int proc_pid_auxv(struct seq_file *m, struct pid_namespace *ns,			 struct pid *pid, struct task_struct *task){	struct mm_struct *mm = mm_access(task, PTRACE_MODE_READ_FSCREDS);	if (mm && !IS_ERR(mm)) {		unsigned int nwords = 0;		do {			nwords += 2;		} while (mm->saved_auxv[nwords - 2] != 0);  		seq_write(m, mm->saved_auxv, nwords * sizeof(mm->saved_auxv[0]));		mmput(mm);		return 0;	} else		return PTR_ERR(mm);}",15620
155,1654,CVE-2019-11599,21,"struct anon_vma *find_mergeable_anon_vma(struct vm_area_struct *vma){	struct anon_vma *anon_vma;	struct vm_area_struct *near;	near = vma->vm_next;	if (!near)		goto try_prev;	anon_vma = reusable_anon_vma(near, vma, near);	if (anon_vma)		return anon_vma;try_prev:	near = vma->vm_prev;	if (!near)		goto none;	anon_vma = reusable_anon_vma(near, near, vma);	if (anon_vma)		return anon_vma;none:	 	return NULL;}",27101
395,505,CVE-2014-2672,21,"static int ath_tx_sched_aggr(struct ath_softc *sc, struct ath_txq *txq,			      struct ath_atx_tid *tid, int *stop){	struct ath_buf *bf;	struct ieee80211_tx_info *tx_info;	struct sk_buff_head *tid_q;	struct list_head bf_q;	int aggr_len = 0;	int aggr, last = true;	if (!ath_tid_has_buffered(tid))		return false;	INIT_LIST_HEAD(&bf_q);	bf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);	if (!bf)		return false;	tx_info = IEEE80211_SKB_CB(bf->bf_mpdu);	aggr = !!(tx_info->flags & IEEE80211_TX_CTL_AMPDU);	if ((aggr && txq->axq_ampdu_depth >= ATH_AGGR_MIN_QDEPTH) ||		(!aggr && txq->axq_depth >= ATH_NON_AGGR_MIN_QDEPTH)) {		*stop = true;		return false;	}	ath_set_rates(tid->an->vif, tid->an->sta, bf);	if (aggr)		last = ath_tx_form_aggr(sc, txq, tid, &bf_q, bf,					tid_q, &aggr_len);	else		ath_tx_form_burst(sc, txq, tid, &bf_q, bf, tid_q);	if (list_empty(&bf_q))		return false;	if (tid->ac->clear_ps_filter || tid->an->no_ps_filter) {		tid->ac->clear_ps_filter = false;		tx_info->flags |= IEEE80211_TX_CTL_CLEAR_PS_FILT;	}	ath_tx_fill_desc(sc, bf, txq, aggr_len);	ath_tx_txqaddbuf(sc, txq, &bf_q, false);	return true;}",11789
439,1115,CVE-2017-7533,21,"static enum d_walk_ret d_genocide_kill(void *data, struct dentry *dentry){	struct dentry *root = data;	if (dentry != root) {		if (d_unhashed(dentry) || !dentry->d_inode)			return D_WALK_SKIP;		if (!(dentry->d_flags & DCACHE_GENOCIDE)) {			dentry->d_flags |= DCACHE_GENOCIDE;			dentry->d_lockref.count--;		}	}	return D_WALK_CONTINUE;}",21587
335,1538,CVE-2015-9016,21,void blk_mq_enable_hotplug(void){	mutex_unlock(&all_q_mutex);},26317
398,1741,CVE-2017-5061,21,  void ActivationCallback() { ++callback_count_; },29877
86,140,CVE-2012-3552,21,"static void __ip_flush_pending_frames(struct sock *sk,				      struct sk_buff_head *queue,				      struct inet_cork *cork){	struct sk_buff *skb;	while ((skb = __skb_dequeue_tail(queue)) != NULL)		kfree_skb(skb);	ip_cork_release(cork);}",2826
290,514,CVE-2014-2672,21,static int bf_is_ampdu_not_probing(struct ath_buf *bf){    struct ieee80211_tx_info *info = IEEE80211_SKB_CB(bf->bf_mpdu);    return bf_isampdu(bf) && !(info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE);},11798
219,644,CVE-2015-7613,21,"void *ipc_rcu_alloc(int size){	 	struct ipc_rcu *out = ipc_alloc(sizeof(struct ipc_rcu) + size);	if (unlikely(!out))		return NULL;	atomic_set(&out->refcount, 1);	return out + 1;}",13082
2,1511,CVE-2015-9016,21,"static int bt_has_free_tags(struct blk_mq_bitmap_tags *bt){	int i;	for (i = 0; i < bt->map_nr; i++) {		struct blk_align_bitmap *bm = &bt->map[i];		int ret;		ret = find_first_zero_bit(&bm->word, bm->depth);		if (ret < bm->depth)			return true;	}	return false;}",26290
428,488,CVE-2014-2672,21,"static void ath_set_rates(struct ieee80211_vif *vif, struct ieee80211_sta *sta,			  struct ath_buf *bf){	ieee80211_get_tx_rates(vif, sta, bf->bf_mpdu, bf->rates,			       ARRAY_SIZE(bf->rates));}",11772
126,1236,CVE-2017-7533,21,void __fsnotify_inode_delete(struct inode *inode){	fsnotify_clear_marks_by_inode(inode);},21708
294,1738,CVE-2013-2906,21,  MemoryObserver() {},29362
102,241,CVE-2012-3552,21,"static void tcp_v6_send_check(struct sock *sk, struct sk_buff *skb){	struct ipv6_pinfo *np = inet6_sk(sk);	__tcp_v6_send_check(skb, &np->saddr, &np->daddr);}",2927
142,1747,CVE-2017-5061,21,  LayerTreeHostTestKeepSwapPromise() {},29883
283,249,CVE-2012-3552,21,"static int l2tp_ip_open(struct sock *sk){	 	inet_sk(sk)->inet_num = IPPROTO_L2TP;	write_lock_bh(&l2tp_ip_lock);	sk_add_node(sk, &l2tp_ip_table);	write_unlock_bh(&l2tp_ip_lock);	return 0;}",2935
412,122,CVE-2012-3552,21,static struct sock *icmp_sk(struct net *net){	return net->ipv4.icmp_sk[smp_processor_id()];},2808
192,879,CVE-2016-0723,21,"struct tty_driver *__tty_alloc_driver(unsigned int lines, struct module *owner,		unsigned long flags){	struct tty_driver *driver;	unsigned int cdevs = 1;	int err;	if (!lines || (flags & TTY_DRIVER_UNNUMBERED_NODE && lines > 1))		return ERR_PTR(-EINVAL);	driver = kzalloc(sizeof(struct tty_driver), GFP_KERNEL);	if (!driver)		return ERR_PTR(-ENOMEM);	kref_init(&driver->kref);	driver->magic = TTY_DRIVER_MAGIC;	driver->num = lines;	driver->owner = owner;	driver->flags = flags;	if (!(flags & TTY_DRIVER_DEVPTS_MEM)) {		driver->ttys = kcalloc(lines, sizeof(*driver->ttys),				GFP_KERNEL);		driver->termios = kcalloc(lines, sizeof(*driver->termios),				GFP_KERNEL);		if (!driver->ttys || !driver->termios) {			err = -ENOMEM;			goto err_free_all;		}	}	if (!(flags & TTY_DRIVER_DYNAMIC_ALLOC)) {		driver->ports = kcalloc(lines, sizeof(*driver->ports),				GFP_KERNEL);		if (!driver->ports) {			err = -ENOMEM;			goto err_free_all;		}		cdevs = lines;	}	driver->cdevs = kcalloc(cdevs, sizeof(*driver->cdevs), GFP_KERNEL);	if (!driver->cdevs) {		err = -ENOMEM;		goto err_free_all;	}	return driver;err_free_all:	kfree(driver->ports);	kfree(driver->ttys);	kfree(driver->termios);	kfree(driver->cdevs);	kfree(driver);	return ERR_PTR(err);}",18222
161,572,CVE-2010-5313,21,"static void emulator_set_cached_descriptor(struct desc_struct *desc, int seg,					   struct kvm_vcpu *vcpu){	struct kvm_segment var;	 	kvm_get_segment(vcpu, &var, seg);	var.base = get_desc_base(desc);	var.limit = get_desc_limit(desc);	if (desc->g)		var.limit = (var.limit << 12) | 0xfff;	var.type = desc->type;	var.present = desc->p;	var.dpl = desc->dpl;	var.db = desc->d;	var.s = desc->s;	var.l = desc->l;	var.g = desc->g;	var.avl = desc->avl;	var.present = desc->p;	var.unusable = !var.present;	var.padding = 0;	kvm_set_segment(vcpu, &var, seg);	return;}",12796
301,463,CVE-2014-3611,21,"static void pit_latch_count(struct kvm *kvm, int channel){	struct kvm_kpit_channel_state *c =		&kvm->arch.vpit->pit_state.channels[channel];	WARN_ON(!mutex_is_locked(&kvm->arch.vpit->pit_state.lock));	if (!c->count_latched) {		c->latched_count = pit_get_count(kvm, channel);		c->count_latched = c->rw_mode;	}}",11290
103,32,CVE-2012-1174,21,"int make_stdio(int fd) {        int r, s, t;        assert(fd >= 0);        r = dup2(fd, STDIN_FILENO);        s = dup2(fd, STDOUT_FILENO);        t = dup2(fd, STDERR_FILENO);        if (fd >= 3)                close_nointr_nofail(fd);        if (r < 0 || s < 0 || t < 0)                return -errno;        fd_cloexec(STDIN_FILENO, false);        fd_cloexec(STDOUT_FILENO, false);        fd_cloexec(STDERR_FILENO, false);        return 0;}",1997
42,475,CVE-2014-2706,21,"void sta_info_init(struct ieee80211_local *local){	spin_lock_init(&local->tim_lock);	mutex_init(&local->sta_mtx);	INIT_LIST_HEAD(&local->sta_list);	setup_timer(&local->sta_cleanup, sta_info_cleanup,		    (unsigned long)local);}",11735
261,1562,CVE-2015-9016,21,"static struct request *blk_mq_map_request(struct request_queue *q,					  struct bio *bio,					  struct blk_map_ctx *data){	struct blk_mq_hw_ctx *hctx;	struct blk_mq_ctx *ctx;	struct request *rq;	int rw = bio_data_dir(bio);	struct blk_mq_alloc_data alloc_data;	if (unlikely(blk_mq_queue_enter(q, GFP_KERNEL))) {		bio_io_error(bio);		return NULL;	}	ctx = blk_mq_get_ctx(q);	hctx = q->mq_ops->map_queue(q, ctx->cpu);	if (rw_is_sync(bio->bi_rw))		rw |= REQ_SYNC;	trace_block_getrq(q, bio, rw);	blk_mq_set_alloc_data(&alloc_data, q, GFP_ATOMIC, false, ctx,			hctx);	rq = __blk_mq_alloc_request(&alloc_data, rw);	if (unlikely(!rq)) {		__blk_mq_run_hw_queue(hctx);		blk_mq_put_ctx(ctx);		trace_block_sleeprq(q, bio, rw);		ctx = blk_mq_get_ctx(q);		hctx = q->mq_ops->map_queue(q, ctx->cpu);		blk_mq_set_alloc_data(&alloc_data, q,				__GFP_WAIT|GFP_ATOMIC, false, ctx, hctx);		rq = __blk_mq_alloc_request(&alloc_data, rw);		ctx = alloc_data.ctx;		hctx = alloc_data.hctx;	}	hctx->queued++;	data->hctx = hctx;	data->ctx = ctx;	return rq;}",26341
282,47,CVE-2012-1174,21,"int reset_all_signal_handlers(void) {        int sig;        for (sig = 1; sig < _NSIG; sig++) {                struct sigaction sa;                if (sig == SIGKILL || sig == SIGSTOP)                        continue;                zero(sa);                sa.sa_handler = SIG_DFL;                sa.sa_flags = SA_RESTART;                                 if ((sigaction(sig, &sa, NULL) < 0))                        if (errno != EINVAL)                                return -errno;        }        return 0;}",2012
333,668,CVE-2015-3212,21,"static int sctp_bindx_add(struct sock *sk, struct sockaddr *addrs, int addrcnt){	int cnt;	int retval = 0;	void *addr_buf;	struct sockaddr *sa_addr;	struct sctp_af *af;	pr_debug(""%s: sk:%p, addrs:%p, addrcnt:%d\n"", __func__, sk,		 addrs, addrcnt);	addr_buf = addrs;	for (cnt = 0; cnt < addrcnt; cnt++) {		 		sa_addr = addr_buf;		af = sctp_get_af_specific(sa_addr->sa_family);		if (!af) {			retval = -EINVAL;			goto err_bindx_add;		}		retval = sctp_do_bind(sk, (union sctp_addr *)sa_addr,				      af->sockaddr_len);		addr_buf += af->sockaddr_len;err_bindx_add:		if (retval < 0) {			 			if (cnt > 0)				sctp_bindx_rem(sk, addrs, cnt);			return retval;		}	}	return retval;}",13620
16,530,CVE-2014-0196,21,static inline int is_utf8_continuation(unsigned char c){	return (c & 0xc0) == 0x80;},12185
175,1102,CVE-2017-7533,21,"struct dentry *d_add_ci(struct dentry *dentry, struct inode *inode,			struct qstr *name){	struct dentry *found, *res;	 	found = d_hash_and_lookup(dentry->d_parent, name);	if (found) {		iput(inode);		return found;	}	if (d_in_lookup(dentry)) {		found = d_alloc_parallel(dentry->d_parent, name,					dentry->d_wait);		if (IS_ERR(found) || !d_in_lookup(found)) {			iput(inode);			return found;		}	} else {		found = d_alloc(dentry->d_parent, name);		if (!found) {			iput(inode);			return ERR_PTR(-ENOMEM);		} 	}	res = d_splice_alias(inode, found);	if (res) {		dput(found);		return res;	}	return found;}",21574
122,1681,CVE-2019-11599,21,"static inline void vma_rb_insert(struct vm_area_struct *vma,				 struct rb_root *root){	 	validate_mm_rb(root, NULL);	rb_insert_augmented(&vma->vm_rb, root, &vma_gap_callbacks);}",27128
174,1531,CVE-2015-9016,21,void blk_mq_cancel_requeue_work(struct request_queue *q){	cancel_work_sync(&q->requeue_work);},26310
350,538,CVE-2014-0196,21,"static int n_tty_open(struct tty_struct *tty){	struct n_tty_data *ldata;	 	ldata = vmalloc(sizeof(*ldata));	if (!ldata)		goto err;	ldata->overrun_time = jiffies;	mutex_init(&ldata->atomic_read_lock);	mutex_init(&ldata->output_lock);	tty->disc_data = ldata;	reset_buffer_flags(tty->disc_data);	ldata->column = 0;	ldata->canon_column = 0;	ldata->minimum_to_wake = 1;	ldata->num_overrun = 0;	ldata->no_room = 0;	ldata->lnext = 0;	tty->closing = 0;	 	clear_bit(TTY_LDISC_HALTED, &tty->flags);	n_tty_set_termios(tty, NULL);	tty_unthrottle(tty);	return 0;err:	return -ENOMEM;}",12193
164,345,CVE-2013-7026,21,"static unsigned long shm_get_unmapped_area(struct file *file,	unsigned long addr, unsigned long len, unsigned long pgoff,	unsigned long flags){	struct shm_file_data *sfd = shm_file_data(file);	return sfd->file->f_op->get_unmapped_area(sfd->file, addr, len,						pgoff, flags);}",7065
112,798,CVE-2016-6136,21,"void __audit_free(struct task_struct *tsk){	struct audit_context *context;	context = audit_take_context(tsk, 0, 0);	if (!context)		return;	 	 	if (context->in_syscall && context->current_state == AUDIT_RECORD_CONTEXT)		audit_log_exit(context, tsk);	if (!list_empty(&context->killed_trees))		audit_kill_trees(&context->killed_trees);	audit_free_context(context);}",16283
292,80,CVE-2012-4508,21,"static void ext4_ext_show_path(struct inode *inode, struct ext4_ext_path *path){	int k, l = path->p_depth;	ext_debug(""path:"");	for (k = 0; k <= l; k++, path++) {		if (path->p_idx) {		  ext_debug(""  %d->%llu"", le32_to_cpu(path->p_idx->ei_block),			    ext4_idx_pblock(path->p_idx));		} else if (path->p_ext) {			ext_debug(""  %d:[%d]%d:%llu "",				  le32_to_cpu(path->p_ext->ee_block),				  ext4_ext_is_uninitialized(path->p_ext),				  ext4_ext_get_actual_len(path->p_ext),				  ext4_ext_pblock(path->p_ext));		} else			ext_debug(""  []"");	}	ext_debug(""\n"");}",2725
148,102,CVE-2012-3552,21,"static int inet_autobind(struct sock *sk){	struct inet_sock *inet;	 	lock_sock(sk);	inet = inet_sk(sk);	if (!inet->inet_num) {		if (sk->sk_prot->get_port(sk, 0)) {			release_sock(sk);			return -EAGAIN;		}		inet->inet_sport = htons(inet->inet_num);	}	release_sock(sk);	return 0;}",2788
24,1432,CVE-2017-18203,21,struct kobject *dm_kobject(struct mapped_device *md){	return &md->kobj_holder.kobj;},25967
139,12,CVE-2012-1174,21,"int close_pipe(int p[]) {        int a = 0, b = 0;        assert(p);        if (p[0] >= 0) {                a = close_nointr(p[0]);                p[0] = -1;        }        if (p[1] >= 0) {                b = close_nointr(p[1]);                p[1] = -1;        }        return a < 0 ? a : b;}",1977
276,715,CVE-2014-9710,21,"static void fixup_low_keys(struct btrfs_root *root, struct btrfs_path *path,			   struct btrfs_disk_key *key, int level){	int i;	struct extent_buffer *t;	for (i = level; i < BTRFS_MAX_LEVEL; i++) {		int tslot = path->slots[i];		if (!path->nodes[i])			break;		t = path->nodes[i];		tree_mod_log_set_node_key(root->fs_info, t, tslot, 1);		btrfs_set_node_key(t, key, tslot);		btrfs_mark_buffer_dirty(path->nodes[i]);		if (tslot != 0)			break;	}}",14132
373,619,CVE-2015-7990,21,"static void rds_conn_message_info_retrans(struct socket *sock,					  unsigned int len,					  struct rds_info_iterator *iter,					  struct rds_info_lengths *lens){	rds_conn_message_info(sock, len, iter, lens, 0);}",13039
325,392,CVE-2013-0871,21,"flush_signal_handlers(struct task_struct *t, int force_default){	int i;	struct k_sigaction *ka = &t->sighand->action[0];	for (i = _NSIG ; i != 0 ; i--) {		if (force_default || ka->sa.sa_handler != SIG_IGN)			ka->sa.sa_handler = SIG_DFL;		ka->sa.sa_flags = 0;		sigemptyset(&ka->sa.sa_mask);		ka++;	}}",9689
141,1618,CVE-2019-11599,21,"static void m_cache_vma(struct seq_file *m, struct vm_area_struct *vma){	if (m->count < m->size)	 		m->version = m_next_vma(m->private, vma) ? vma->vm_end : -1UL;}",27065
204,1766,CVE-2012-3552,21,"static int ip_setup_cork(struct sock *sk, struct inet_cork *cork, 			 struct ipcm_cookie *ipc, struct rtable **rtp) { 	struct inet_sock *inet = inet_sk(sk);	struct ip_options *opt; 	struct rtable *rt;  	 	opt = ipc->opt;	if (opt) {		if (cork->opt == NULL) {			cork->opt = kmalloc(sizeof(struct ip_options) + 40,					    sk->sk_allocation); 			if (unlikely(cork->opt == NULL)) 				return -ENOBUFS; 		}		memcpy(cork->opt, opt, sizeof(struct ip_options) + opt->optlen); 		cork->flags |= IPCORK_OPT; 		cork->addr = ipc->addr; 	}	rt = *rtp;	if (unlikely(!rt))		return -EFAULT;	 	*rtp = NULL;	cork->fragsize = inet->pmtudisc == IP_PMTUDISC_PROBE ?			 rt->dst.dev->mtu : dst_mtu(rt->dst.path);	cork->dst = &rt->dst;	cork->length = 0;	cork->tx_flags = ipc->tx_flags;	cork->page = NULL;	cork->off = 0;	return 0;}",30932
210,957,CVE-2015-8839,21,"void ext4_dirty_inode(struct inode *inode, int flags){	handle_t *handle;	if (flags == I_DIRTY_TIME)		return;	handle = ext4_journal_start(inode, EXT4_HT_INODE, 2);	if (IS_ERR(handle))		goto out;	ext4_mark_inode_dirty(handle, inode);	ext4_journal_stop(handle);out:	return;}",18527
69,1140,CVE-2017-7533,21,"static inline int dentry_cmp(const struct dentry *dentry, const unsigned char *ct, unsigned tcount){	 	const unsigned char *cs = lockless_dereference(dentry->d_name.name);	return dentry_string_cmp(cs, ct, tcount);}",21612
295,381,CVE-2013-0871,21,"static int enable_single_step(struct task_struct *child){	struct pt_regs *regs = task_pt_regs(child);	unsigned long oflags;	 	if (unlikely(test_tsk_thread_flag(child, TIF_SINGLESTEP)))		regs->flags |= X86_EFLAGS_TF;	 	set_tsk_thread_flag(child, TIF_SINGLESTEP);	oflags = regs->flags;	 	regs->flags |= X86_EFLAGS_TF;	 	if (is_setting_trap_flag(child, regs)) {		clear_tsk_thread_flag(child, TIF_FORCED_TF);		return 0;	}	 	if (oflags & X86_EFLAGS_TF)		return test_tsk_thread_flag(child, TIF_FORCED_TF);	set_tsk_thread_flag(child, TIF_FORCED_TF);	return 1;}",9678
46,280,CVE-2011-2183,21,static struct page *page_trans_compound_anon(struct page *page){	if (PageTransCompound(page)) {		struct page *head = compound_trans_head(page);		 		if (PageAnon(head))			return head;	}	return NULL;},6747
400,1638,CVE-2019-11599,21,"static void __vma_link_file(struct vm_area_struct *vma){	struct file *file;	file = vma->vm_file;	if (file) {		struct address_space *mapping = file->f_mapping;		if (vma->vm_flags & VM_DENYWRITE)			atomic_dec(&file_inode(file)->i_writecount);		if (vma->vm_flags & VM_SHARED)			atomic_inc(&mapping->i_mmap_writable);		flush_dcache_mmap_lock(mapping);		vma_interval_tree_insert(vma, &mapping->i_mmap);		flush_dcache_mmap_unlock(mapping);	}}",27085
63,1376,CVE-2017-18224,21,"static int ocfs2_write_begin_inline(struct address_space *mapping,				    struct inode *inode,				    struct ocfs2_write_ctxt *wc){	int ret;	struct ocfs2_super *osb = OCFS2_SB(inode->i_sb);	struct page *page;	handle_t *handle;	struct ocfs2_dinode *di = (struct ocfs2_dinode *)wc->w_di_bh->b_data;	handle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);	if (IS_ERR(handle)) {		ret = PTR_ERR(handle);		mlog_errno(ret);		goto out;	}	page = find_or_create_page(mapping, 0, GFP_NOFS);	if (!page) {		ocfs2_commit_trans(osb, handle);		ret = -ENOMEM;		mlog_errno(ret);		goto out;	}	 	wc->w_pages[0] = wc->w_target_page = page;	wc->w_num_pages = 1;	ret = ocfs2_journal_access_di(handle, INODE_CACHE(inode), wc->w_di_bh,				      OCFS2_JOURNAL_ACCESS_WRITE);	if (ret) {		ocfs2_commit_trans(osb, handle);		mlog_errno(ret);		goto out;	}	if (!(OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL))		ocfs2_set_inode_data_inline(inode, di);	if (!PageUptodate(page)) {		ret = ocfs2_read_inline_data(inode, page, wc->w_di_bh);		if (ret) {			ocfs2_commit_trans(osb, handle);			goto out;		}	}	wc->w_handle = handle;out:	return ret;}",25792
225,1690,CVE-2019-6974,21,"void kvm_io_bus_unregister_dev(struct kvm *kvm, enum kvm_bus bus_idx,			       struct kvm_io_device *dev){	int i;	struct kvm_io_bus *new_bus, *bus;	bus = kvm_get_bus(kvm, bus_idx);	if (!bus)		return;	for (i = 0; i < bus->dev_count; i++)		if (bus->range[i].dev == dev) {			break;		}	if (i == bus->dev_count)		return;	new_bus = kmalloc(sizeof(*bus) + ((bus->dev_count - 1) *			  sizeof(struct kvm_io_range)), GFP_KERNEL);	if (!new_bus)  {		pr_err(""kvm: failed to shrink bus, removing it completely\n"");		goto broken;	}	memcpy(new_bus, bus, sizeof(*bus) + i * sizeof(struct kvm_io_range));	new_bus->dev_count--;	memcpy(new_bus->range + i, bus->range + i + 1,	       (new_bus->dev_count - i) * sizeof(struct kvm_io_range));broken:	rcu_assign_pointer(kvm->buses[bus_idx], new_bus);	synchronize_srcu_expedited(&kvm->srcu);	kfree(bus);	return;}",27367
270,338,CVE-2011-1768,21,"static inline struct xfrm6_tunnel_net *xfrm6_tunnel_pernet(struct net *net){	return net_generic(net, xfrm6_tunnel_net_id);}",6825
156,360,CVE-2013-3302,21,cifs_delete_mid(struct mid_q_entry *mid){	spin_lock(&GlobalMid_Lock);	list_del(&mid->qhead);	spin_unlock(&GlobalMid_Lock);	DeleteMidQEntry(mid);},8011
223,642,CVE-2015-7613,21,"struct kern_ipc_perm *ipc_obtain_object_idr(struct ipc_ids *ids, int id){	struct kern_ipc_perm *out;	int lid = ipcid_to_idx(id);	out = idr_find(&ids->ipcs_idr, lid);	if (!out)		return ERR_PTR(-EINVAL);	return out;}",13080
60,1503,CVE-2015-9016,21,"struct blk_mq_tags *blk_mq_init_tags(unsigned int total_tags,				     unsigned int reserved_tags,				     int node, int alloc_policy){	struct blk_mq_tags *tags;	if (total_tags > BLK_MQ_TAG_MAX) {		pr_err(""blk-mq: tag depth too large\n"");		return NULL;	}	tags = kzalloc_node(sizeof(*tags), GFP_KERNEL, node);	if (!tags)		return NULL;	if (!zalloc_cpumask_var(&tags->cpumask, GFP_KERNEL)) {		kfree(tags);		return NULL;	}	tags->nr_tags = total_tags;	tags->nr_reserved_tags = reserved_tags;	return blk_mq_init_bitmap_tags(tags, node, alloc_policy);}",26282
51,998,CVE-2015-8839,21,"static int ext4_quota_on(struct super_block *sb, int type, int format_id,			 struct path *path){	int err;	if (!test_opt(sb, QUOTA))		return -EINVAL;	 	if (path->dentry->d_sb != sb)		return -EXDEV;	 	if (EXT4_SB(sb)->s_qf_names[type]) {		 		if (path->dentry->d_parent != sb->s_root)			ext4_msg(sb, KERN_WARNING,				""Quota file not on filesystem root. ""				""Journaled quota will not work"");	}	 	if (EXT4_SB(sb)->s_journal &&	    ext4_should_journal_data(d_inode(path->dentry))) {		 		jbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);		err = jbd2_journal_flush(EXT4_SB(sb)->s_journal);		jbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);		if (err)			return err;	}	return dquot_quota_on(sb, type, format_id, path);}",18568
222,1581,CVE-2019-13233,21,"static int get_reg_offset_16(struct insn *insn, struct pt_regs *regs,			     int *offs1, int *offs2){	 	static const int regoff1[] = {		offsetof(struct pt_regs, bx),		offsetof(struct pt_regs, bx),		offsetof(struct pt_regs, bp),		offsetof(struct pt_regs, bp),		offsetof(struct pt_regs, si),		offsetof(struct pt_regs, di),		offsetof(struct pt_regs, bp),		offsetof(struct pt_regs, bx),	};	static const int regoff2[] = {		offsetof(struct pt_regs, si),		offsetof(struct pt_regs, di),		offsetof(struct pt_regs, si),		offsetof(struct pt_regs, di),		-EDOM,		-EDOM,		-EDOM,		-EDOM,	};	if (!offs1 || !offs2)		return -EINVAL;	 	if (X86_MODRM_MOD(insn->modrm.value) == 3) {		*offs1 = insn_get_modrm_rm_off(insn, regs);		*offs2 = -EDOM;		return 0;	}	*offs1 = regoff1[X86_MODRM_RM(insn->modrm.value)];	*offs2 = regoff2[X86_MODRM_RM(insn->modrm.value)];	 	if ((X86_MODRM_MOD(insn->modrm.value) == 0) &&	    (X86_MODRM_RM(insn->modrm.value) == 6))		*offs1 = -EDOM;	return 0; }",26735
91,266,CVE-2011-2183,21,static struct page *get_ksm_page(struct stable_node *stable_node){	struct page *page;	void *expected_mapping;	page = pfn_to_page(stable_node->kpfn);	expected_mapping = (void *)stable_node +				(PAGE_MAPPING_ANON | PAGE_MAPPING_KSM);	rcu_read_lock();	if (page->mapping != expected_mapping)		goto stale;	if (!get_page_unless_zero(page))		goto stale;	if (page->mapping != expected_mapping) {		put_page(page);		goto stale;	}	rcu_read_unlock();	return page;stale:	rcu_read_unlock();	remove_node_from_stable_tree(stable_node);	return NULL;},6733
420,1163,CVE-2017-7533,21,"int path_has_submounts(const struct path *parent){	struct check_mount data = { .mnt = parent->mnt, .mounted = 0 };	read_seqlock_excl(&mount_lock);	d_walk(parent->dentry, &data, path_check_mount, NULL);	read_sequnlock_excl(&mount_lock);	return data.mounted;}",21635
442,70,CVE-2012-4508,21,"static int __ext4_ext_check(const char *function, unsigned int line,			    struct inode *inode, struct ext4_extent_header *eh,			    int depth){	const char *error_msg;	int max = 0;	if (unlikely(eh->eh_magic != EXT4_EXT_MAGIC)) {		error_msg = ""invalid magic"";		goto corrupted;	}	if (unlikely(le16_to_cpu(eh->eh_depth) != depth)) {		error_msg = ""unexpected eh_depth"";		goto corrupted;	}	if (unlikely(eh->eh_max == 0)) {		error_msg = ""invalid eh_max"";		goto corrupted;	}	max = ext4_ext_max_entries(inode, depth);	if (unlikely(le16_to_cpu(eh->eh_max) > max)) {		error_msg = ""too large eh_max"";		goto corrupted;	}	if (unlikely(le16_to_cpu(eh->eh_entries) > le16_to_cpu(eh->eh_max))) {		error_msg = ""invalid eh_entries"";		goto corrupted;	}	if (!ext4_valid_extent_entries(inode, eh, depth)) {		error_msg = ""invalid extent entries"";		goto corrupted;	}	 	if (ext_depth(inode) != depth &&	    !ext4_extent_block_csum_verify(inode, eh)) {		error_msg = ""extent tree corrupted"";		goto corrupted;	}	return 0;corrupted:	ext4_error_inode(inode, function, line, 0,			""bad header/extent: %s - magic %x, ""			""entries %u, max %u(%u), depth %u(%u)"",			error_msg, le16_to_cpu(eh->eh_magic),			le16_to_cpu(eh->eh_entries), le16_to_cpu(eh->eh_max),			max, le16_to_cpu(eh->eh_depth), depth);	return -EIO;}",2715
70,1255,CVE-2017-6001,21,event_filter_match(struct perf_event *event){	return (event->cpu == -1 || event->cpu == smp_processor_id()) &&	       perf_cgroup_match(event) && pmu_filter_match(event);},21875
318,27,CVE-2012-1174,21,"int in_charset(const char *s, const char* charset) {        const char *i;        assert(s);        assert(charset);        for (i = s; *i; i++)                if (!strchr(charset, *i))                        return false;        return true;}",1992
414,676,CVE-2015-3212,21,"static int sctp_get_port(struct sock *sk, unsigned short snum){	union sctp_addr addr;	struct sctp_af *af = sctp_sk(sk)->pf->af;	 	af->from_sk(&addr, sk);	addr.v4.sin_port = htons(snum);	 	return !!sctp_get_port_local(sk, &addr);}",13628
429,1070,CVE-2017-12146,21,"struct resource *platform_get_resource(struct platform_device *dev,				       unsigned int type, unsigned int num){	int i;	for (i = 0; i < dev->num_resources; i++) {		struct resource *r = &dev->resource[i];		if (type == resource_type(r) && num-- == 0)			return r;	}	return NULL;}",20437
386,57,CVE-2011-4029,21,"System(char *command){    int pid, p;    void (*csig)(int);    int status;    if (!command)	return 1;    csig = signal(SIGCHLD, SIG_DFL);    if (csig == SIG_ERR) {      perror(""signal"");      return -1;    }    DebugF(""System: `%s'\n"", command);    switch (pid = fork()) {    case -1:	 	p = -1;    case 0:	 	if (setgid(getgid()) == -1)	    _exit(127);	if (setuid(getuid()) == -1)	    _exit(127);	execl(""/bin/sh"", ""sh"", ""-c"", command, (char *)NULL);	_exit(127);    default:	 	do {	    p = waitpid(pid, &status, 0);	} while (p == -1 && errno == EINTR);	    }    if (signal(SIGCHLD, csig) == SIG_ERR) {      perror(""signal"");      return -1;    }    return p == -1 ? -1 : status;}",2204
236,193,CVE-2012-3552,21,"static struct tcp_md5sig_key *tcp_v4_reqsk_md5_lookup(struct sock *sk,						      struct request_sock *req){	return tcp_v4_md5_do_lookup(sk, inet_rsk(req)->rmt_addr);}",2879
396,1616,CVE-2019-10639,22,"static int rtnl_net_dumpid_one(int id, void *peer, void *data){	struct rtnl_net_dump_cb *net_cb = (struct rtnl_net_dump_cb *)data;	int ret;	if (net_cb->idx < net_cb->s_idx)		goto cont;	net_cb->fillargs.nsid = id;	if (net_cb->fillargs.add_ref)		net_cb->fillargs.ref_nsid = __peernet2id(net_cb->ref_net, peer);	ret = rtnl_net_fill(net_cb->skb, &net_cb->fillargs);	if (ret < 0)		return ret;cont:	net_cb->idx++;	return 0;}",27183
402,802,CVE-2013-7281,22,static int pn_init(struct sock *sk){	sk->sk_destruct = pn_destruct;	return 0;},12360
205,189,CVE-2012-3430,22,"static int rds_still_queued(struct rds_sock *rs, struct rds_incoming *inc,			    int drop){	struct sock *sk = rds_rs_to_sk(rs);	int ret = 0;	unsigned long flags;	write_lock_irqsave(&rs->rs_recv_lock, flags);	if (!list_empty(&inc->i_item)) {		ret = 1;		if (drop) {			 			rds_recv_rcvbuf_delta(rs, sk, inc->i_conn->c_lcong,					      -be32_to_cpu(inc->i_hdr.h_len),					      inc->i_hdr.h_dport);			list_del_init(&inc->i_item);			rds_inc_put(inc);		}	}	write_unlock_irqrestore(&rs->rs_recv_lock, flags);	rdsdebug(""inc %p rs %p still %d dropped %d\n"", inc, rs, ret, drop);	return ret;}",3033
81,372,CVE-2013-3236,22,"static int vmci_transport_socket_init(struct vsock_sock *vsk,				      struct vsock_sock *psk){	vsk->trans = kmalloc(sizeof(struct vmci_transport), GFP_KERNEL);	if (!vsk->trans)		return -ENOMEM;	vmci_trans(vsk)->dg_handle = VMCI_INVALID_HANDLE;	vmci_trans(vsk)->qp_handle = VMCI_INVALID_HANDLE;	vmci_trans(vsk)->qpair = NULL;	vmci_trans(vsk)->produce_size = vmci_trans(vsk)->consume_size = 0;	vmci_trans(vsk)->attach_sub_id = vmci_trans(vsk)->detach_sub_id =		VMCI_INVALID_ID;	vmci_trans(vsk)->notify_ops = NULL;	if (psk) {		vmci_trans(vsk)->queue_pair_size =			vmci_trans(psk)->queue_pair_size;		vmci_trans(vsk)->queue_pair_min_size =			vmci_trans(psk)->queue_pair_min_size;		vmci_trans(vsk)->queue_pair_max_size =			vmci_trans(psk)->queue_pair_max_size;	} else {		vmci_trans(vsk)->queue_pair_size =			VMCI_TRANSPORT_DEFAULT_QP_SIZE;		vmci_trans(vsk)->queue_pair_min_size =			 VMCI_TRANSPORT_DEFAULT_QP_SIZE_MIN;		vmci_trans(vsk)->queue_pair_max_size =			VMCI_TRANSPORT_DEFAULT_QP_SIZE_MAX;	}	return 0;}",8215
279,338,CVE-2013-3237,22,void vsock_remove_bound(struct vsock_sock *vsk){	spin_lock_bh(&vsock_table_lock);	__vsock_remove_bound(vsk);	spin_unlock_bh(&vsock_table_lock);},8181
159,1038,CVE-2016-5696,22,"static inline int tcp_may_raise_cwnd(const struct sock *sk, const int flag){	 	if (tcp_sk(sk)->reordering > sock_net(sk)->ipv4.sysctl_tcp_reordering)		return flag & FLAG_FORWARD_PROGRESS;	return flag & FLAG_DATA_ACKED;}",16414
438,1070,CVE-2016-5696,22,"static int tcp_try_undo_recovery(struct sock *sk){	struct tcp_sock *tp = tcp_sk(sk);	if (tcp_may_undo(tp)) {		int mib_idx;		 		DBGUNDO(sk, inet_csk(sk)->icsk_ca_state == TCP_CA_Loss ? ""loss"" : ""retrans"");		tcp_undo_cwnd_reduction(sk, false);		if (inet_csk(sk)->icsk_ca_state == TCP_CA_Loss)			mib_idx = LINUX_MIB_TCPLOSSUNDO;		else			mib_idx = LINUX_MIB_TCPFULLUNDO;		NET_INC_STATS(sock_net(sk), mib_idx);	}	if (tp->snd_una == tp->high_seq && tcp_is_reno(tp)) {		 		if (!tcp_any_retrans_done(sk))			tp->retrans_stamp = 0;		return true;	}	tcp_set_ca_state(sk, TCP_CA_Open);	return false;}",16446
278,1218,CVE-2016-2117,22,"static void atl2_phy_config(unsigned long data){	struct atl2_adapter *adapter = (struct atl2_adapter *) data;	struct atl2_hw *hw = &adapter->hw;	unsigned long flags;	spin_lock_irqsave(&adapter->stats_lock, flags);	atl2_write_phy_reg(hw, MII_ADVERTISE, hw->mii_autoneg_adv_reg);	atl2_write_phy_reg(hw, MII_BMCR, MII_CR_RESET | MII_CR_AUTO_NEG_EN |		MII_CR_RESTART_AUTO_NEG);	spin_unlock_irqrestore(&adapter->stats_lock, flags);	clear_bit(0, &adapter->cfg_phy);}",17978
134,90,CVE-2018-11469,22,"void http_set_status(unsigned int status, const char *reason, struct stream *s){	struct http_txn *txn = s->txn;	char *cur_ptr, *cur_end;	int delta;	char *res;	int c_l;	const char *msg = reason;	int msg_len;	chunk_reset(&trash);	res = ultoa_o(status, trash.str, trash.size);	c_l = res - trash.str;	trash.str[c_l] = ' ';	trash.len = c_l + 1;	 	if (msg == NULL)		msg = get_reason(status);	msg_len = strlen(msg);	strncpy(&trash.str[trash.len], msg, trash.size - trash.len);	trash.len += msg_len;	cur_ptr = s->res.buf->p + txn->rsp.sl.st.c;	cur_end = s->res.buf->p + txn->rsp.sl.st.r + txn->rsp.sl.st.r_l;	 	delta = buffer_replace2(s->res.buf, cur_ptr, cur_end, trash.str, trash.len);	 	txn->rsp.sl.st.r += c_l - txn->rsp.sl.st.c_l;	txn->rsp.sl.st.c_l = c_l;	txn->rsp.sl.st.r_l = msg_len;	delta = trash.len - (cur_end - cur_ptr);	txn->rsp.sl.st.l += delta;	txn->hdr_idx.v[0].len += delta;	http_msg_move_end(&txn->rsp, delta);}",1095
0,103,CVE-2018-11469,22,"void manage_server_side_cookies(struct stream *s, struct channel *res){	struct http_txn *txn = s->txn;	struct session *sess = s->sess;	struct server *srv;	int is_cookie2;	int cur_idx, old_idx, delta;	char *hdr_beg, *hdr_end, *hdr_next;	char *prev, *att_beg, *att_end, *equal, *val_beg, *val_end, *next;	 	old_idx = 0;	hdr_next = res->buf->p + hdr_idx_first_pos(&txn->hdr_idx);	while ((cur_idx = txn->hdr_idx.v[old_idx].next)) {		struct hdr_idx_elem *cur_hdr;		int val;		cur_hdr  = &txn->hdr_idx.v[cur_idx];		hdr_beg  = hdr_next;		hdr_end  = hdr_beg + cur_hdr->len;		hdr_next = hdr_end + cur_hdr->cr + 1;		 		is_cookie2 = 0;		prev = hdr_beg + 10;		val = http_header_match2(hdr_beg, hdr_end, ""Set-Cookie"", 10);		if (!val) {			val = http_header_match2(hdr_beg, hdr_end, ""Set-Cookie2"", 11);			if (!val) {				old_idx = cur_idx;				continue;			}			is_cookie2 = 1;			prev = hdr_beg + 11;		}		 		txn->flags |= TX_SCK_PRESENT;		 		if (s->be->cookie_name == NULL && sess->fe->capture_name == NULL)			return;		 		for (; prev < hdr_end; prev = next) {			 			 			att_beg = prev + 1;			while (att_beg < hdr_end && HTTP_IS_SPHT(*att_beg))				att_beg++;			 			equal = att_end = att_beg;			while (equal < hdr_end) {				if (*equal == '=' || *equal == ';' || (is_cookie2 && *equal == ','))					break;				if (HTTP_IS_SPHT(*equal++))					continue;				att_end = equal;			}			 			 			if (equal < hdr_end && *equal == '=') {				 				val_beg = equal + 1;				while (val_beg < hdr_end && HTTP_IS_SPHT(*val_beg))					val_beg++;				 				next = find_cookie_value_end(val_beg, hdr_end);				 				val_end = next;				while (val_end > val_beg && HTTP_IS_SPHT(*(val_end - 1)))					val_end--;			} else {				 				val_beg = val_end = next = equal;			}			if (next < hdr_end) {				 				if (is_cookie2)					next = find_hdr_value_end(next, hdr_end);				else					next = hdr_end;			}			 			 			if (equal == val_end)				continue;			 			if (unlikely(att_end != equal || val_beg > equal + 1)) {				int stripped_before = 0;				int stripped_after = 0;				if (att_end != equal) {					stripped_before = buffer_replace2(res->buf, att_end, equal, NULL, 0);					equal   += stripped_before;					val_beg += stripped_before;				}				if (val_beg > equal + 1) {					stripped_after = buffer_replace2(res->buf, equal + 1, val_beg, NULL, 0);					val_beg += stripped_after;					stripped_before += stripped_after;				}				val_end      += stripped_before;				next         += stripped_before;				hdr_end      += stripped_before;				hdr_next     += stripped_before;				cur_hdr->len += stripped_before;				http_msg_move_end(&txn->rsp, stripped_before);			}			 			if (sess->fe->capture_name != NULL &&			    txn->srv_cookie == NULL &&			    (val_end - att_beg >= sess->fe->capture_namelen) &&			    memcmp(att_beg, sess->fe->capture_name, sess->fe->capture_namelen) == 0) {				int log_len = val_end - att_beg;				if ((txn->srv_cookie = pool_alloc(pool_head_capture)) == NULL) {					ha_alert(""HTTP logging : out of memory.\n"");				}				else {					if (log_len > sess->fe->capture_len)						log_len = sess->fe->capture_len;					memcpy(txn->srv_cookie, att_beg, log_len);					txn->srv_cookie[log_len] = 0;				}			}			srv = objt_server(s->target);			 			if (!(s->flags & SF_IGNORE_PRST) &&			    (att_end - att_beg == s->be->cookie_len) && (s->be->cookie_name != NULL) &&			    (memcmp(att_beg, s->be->cookie_name, att_end - att_beg) == 0)) {				 				txn->flags &= ~TX_SCK_MASK;				txn->flags |= TX_SCK_FOUND;							 				if (s->be->ck_opts & PR_CK_PSV) {					 				}				else if ((srv && (s->be->ck_opts & PR_CK_INS)) ||				    ((s->flags & SF_DIRECT) && (s->be->ck_opts & PR_CK_IND))) {					 					if (*prev == ':' && next == hdr_end) {						 						delta = buffer_replace2(res->buf, hdr_beg, hdr_next, NULL, 0);						txn->hdr_idx.v[old_idx].next = cur_hdr->next;						txn->hdr_idx.used--;						cur_hdr->len = 0;						cur_idx = old_idx;						hdr_next += delta;						http_msg_move_end(&txn->rsp, delta);						 					} else {						 						int delta = del_hdr_value(res->buf, &prev, next);						next      = prev;						hdr_end  += delta;						hdr_next += delta;						cur_hdr->len += delta;						http_msg_move_end(&txn->rsp, delta);					}					txn->flags &= ~TX_SCK_MASK;					txn->flags |= TX_SCK_DELETED;					 				}				else if (srv && srv->cookie && (s->be->ck_opts & PR_CK_RW)) {					 					delta = buffer_replace2(res->buf, val_beg, val_end, srv->cookie, srv->cklen);					next     += delta;					hdr_end  += delta;					hdr_next += delta;					cur_hdr->len += delta;					http_msg_move_end(&txn->rsp, delta);					txn->flags &= ~TX_SCK_MASK;					txn->flags |= TX_SCK_REPLACED;				}				else if (srv && srv->cookie && (s->be->ck_opts & PR_CK_PFX)) {					 					delta = buffer_replace2(res->buf, val_beg, val_beg, srv->cookie, srv->cklen + 1);					next     += delta;					hdr_end  += delta;					hdr_next += delta;					cur_hdr->len += delta;					http_msg_move_end(&txn->rsp, delta);					val_beg[srv->cklen] = COOKIE_DELIM;					txn->flags &= ~TX_SCK_MASK;					txn->flags |= TX_SCK_REPLACED;				}			}			 		}		 		old_idx = cur_idx;	}}",1108
242,201,CVE-2011-1160,22,"void tpm_dev_vendor_release(struct tpm_chip *chip){	if (chip->vendor.release)		chip->vendor.release(chip->dev);	clear_bit(chip->dev_num, dev_mask);	kfree(chip->vendor.miscdev.name);}",6908
372,861,CVE-2015-8374,22,"int btrfs_unlink_inode(struct btrfs_trans_handle *trans,		       struct btrfs_root *root,		       struct inode *dir, struct inode *inode,		       const char *name, int name_len){	int ret;	ret = __btrfs_unlink_inode(trans, root, dir, inode, name, name_len);	if (!ret) {		drop_nlink(inode);		ret = btrfs_update_inode(trans, root, inode);	}	return ret;}",12944
199,1812,CVE-2012-4530,22,void free_bprm(struct linux_binprm *bprm){	free_arg_pages(bprm);	if (bprm->cred) { 		mutex_unlock(&current->signal->cred_guard_mutex); 		abort_creds(bprm->cred); 	} 	kfree(bprm); },31111
345,221,CVE-2011-1078,22,"static void sco_sock_destruct(struct sock *sk){	BT_DBG(""sk %p"", sk);	skb_queue_purge(&sk->sk_receive_queue);	skb_queue_purge(&sk->sk_write_queue);}",6953
198,1521,CVE-2018-18710,22,"static int cdrom_ioctl_get_capability(struct cdrom_device_info *cdi){	cd_dbg(CD_DO_IOCTL, ""entering CDROM_GET_CAPABILITY\n"");	return (cdi->ops->capability & ~cdi->mask);}",23438
453,1453,CVE-2017-9150,22,"static void clear_all_pkt_pointers(struct bpf_verifier_env *env){	struct bpf_verifier_state *state = &env->cur_state;	struct bpf_reg_state *regs = state->regs, *reg;	int i;	for (i = 0; i < MAX_BPF_REG; i++)		if (regs[i].type == PTR_TO_PACKET ||		    regs[i].type == PTR_TO_PACKET_END)			mark_reg_unknown_value(regs, i);	for (i = 0; i < MAX_BPF_STACK; i += BPF_REG_SIZE) {		if (state->stack_slot_type[i] != STACK_SPILL)			continue;		reg = &state->spilled_regs[i / BPF_REG_SIZE];		if (reg->type != PTR_TO_PACKET &&		    reg->type != PTR_TO_PACKET_END)			continue;		reg->type = UNKNOWN_VALUE;		reg->imm = 0;	}}",20838
34,393,CVE-2013-3233,22,"void nfc_llcp_accept_enqueue(struct sock *parent, struct sock *sk){	struct nfc_llcp_sock *llcp_sock = nfc_llcp_sock(sk);	struct nfc_llcp_sock *llcp_sock_parent = nfc_llcp_sock(parent);	 	sock_hold(sk);	list_add_tail(&llcp_sock->accept_queue,		      &llcp_sock_parent->accept_queue);	llcp_sock->parent = parent;	sk_acceptq_added(parent);}",8236
54,1487,CVE-2017-0377,22,"get_min_filtered_sample_size(void){  return networkstatus_get_param(NULL, ""guard-min-filtered-sample-size"",                                 DFLT_MIN_FILTERED_SAMPLE_SIZE,                                 1, INT32_MAX);}",22250
258,341,CVE-2013-3237,22,"static int vsock_send_shutdown(struct sock *sk, int mode){	return transport->shutdown(vsock_sk(sk), mode);}",8184
252,985,CVE-2015-5302,22,"static void run_event_gtk_error(const char *error_line, void *param){    update_command_run_log(error_line, (struct analyze_event_data *)param);}",13411
187,612,CVE-2013-1944,22,"void Curl_cookie_loadfiles(struct SessionHandle *data){  struct curl_slist *list = data->change.cookielist;  if(list) {    Curl_share_lock(data, CURL_LOCK_DATA_COOKIE, CURL_LOCK_ACCESS_SINGLE);    while(list) {      data->cookies = Curl_cookie_init(data,                                       list->data,                                       data->cookies,                                       data->set.cookiesession);      list = list->next;    }    curl_slist_free_all(data->change.cookielist);      data->change.cookielist = NULL;      Curl_share_unlock(data, CURL_LOCK_DATA_COOKIE);  }}",9209
127,1792,CVE-2017-0823,22,releaseWakeLock() { if (s_callbacks.version >= 13) { int ret;        ret = pthread_mutex_lock(&s_wakeLockCountMutex);        assert(ret == 0); if (s_wakelock_count > 1) {            s_wakelock_count--; } else {            s_wakelock_count = 0;            release_wake_lock(ANDROID_WAKE_LOCK_NAME); if (s_last_wake_timeout_info != NULL) {                s_last_wake_timeout_info->userParam = (void *)1; } }        ret = pthread_mutex_unlock(&s_wakeLockCountMutex);        assert(ret == 0); } else {        release_wake_lock(ANDROID_WAKE_LOCK_NAME); }},30732
302,1265,CVE-2015-8964,22,"static struct tty_ldisc *tty_ldisc_get(struct tty_struct *tty, int disc){	struct tty_ldisc *ld;	struct tty_ldisc_ops *ldops;	if (disc < N_TTY || disc >= NR_LDISCS)		return ERR_PTR(-EINVAL);	 	ldops = get_ldops(disc);	if (IS_ERR(ldops)) {		request_module(""tty-ldisc-%d"", disc);		ldops = get_ldops(disc);		if (IS_ERR(ldops))			return ERR_CAST(ldops);	}	ld = kmalloc(sizeof(struct tty_ldisc), GFP_KERNEL);	if (ld == NULL) {		put_ldops(ldops);		return ERR_PTR(-ENOMEM);	}	ld->ops = ldops;	ld->tty = tty;	return ld;}",18304
320,448,CVE-2013-3229,22,"static void afiucv_swap_src_dest(struct sk_buff *skb){	struct af_iucv_trans_hdr *trans_hdr =				(struct af_iucv_trans_hdr *)skb->data;	char tmpID[8];	char tmpName[8];	ASCEBC(trans_hdr->destUserID, sizeof(trans_hdr->destUserID));	ASCEBC(trans_hdr->destAppName, sizeof(trans_hdr->destAppName));	ASCEBC(trans_hdr->srcUserID, sizeof(trans_hdr->srcUserID));	ASCEBC(trans_hdr->srcAppName, sizeof(trans_hdr->srcAppName));	memcpy(tmpID, trans_hdr->srcUserID, 8);	memcpy(tmpName, trans_hdr->srcAppName, 8);	memcpy(trans_hdr->srcUserID, trans_hdr->destUserID, 8);	memcpy(trans_hdr->srcAppName, trans_hdr->destAppName, 8);	memcpy(trans_hdr->destUserID, tmpID, 8);	memcpy(trans_hdr->destAppName, tmpName, 8);	skb_push(skb, ETH_HLEN);	memset(skb->data, 0, ETH_HLEN);}",8291
97,266,CVE-2013-4516,22,void mp_unregister_driver(struct uart_driver *drv){    struct tty_driver *normal = NULL;    normal = drv->tty_driver;    if (!normal)    {        return;    }    tty_unregister_driver(normal);    put_tty_driver(normal);    drv->tty_driver = NULL;    if (drv->state)    {        kfree(drv->state);    }},7704
326,1572,CVE-2018-15473,22,"advance_past_options(char **cpp){	char *cp = *cpp;	int quoted = 0;	for (; *cp && (quoted || (*cp != ' ' && *cp != '\t')); cp++) {		if (*cp == '\\' && cp[1] == '""')			cp++;	 		else if (*cp == '""')			quoted = !quoted;	}	*cpp = cp;	 	return (*cp == '\0' && quoted) ? -1 : 0;}",24432
160,652,CVE-2012-6548,22,"static int udf_rename(struct inode *old_dir, struct dentry *old_dentry,		      struct inode *new_dir, struct dentry *new_dentry){	struct inode *old_inode = old_dentry->d_inode;	struct inode *new_inode = new_dentry->d_inode;	struct udf_fileident_bh ofibh, nfibh;	struct fileIdentDesc *ofi = NULL, *nfi = NULL, *dir_fi = NULL;	struct fileIdentDesc ocfi, ncfi;	struct buffer_head *dir_bh = NULL;	int retval = -ENOENT;	struct kernel_lb_addr tloc;	struct udf_inode_info *old_iinfo = UDF_I(old_inode);	ofi = udf_find_entry(old_dir, &old_dentry->d_name, &ofibh, &ocfi);	if (ofi) {		if (ofibh.sbh != ofibh.ebh)			brelse(ofibh.ebh);		brelse(ofibh.sbh);	}	tloc = lelb_to_cpu(ocfi.icb.extLocation);	if (!ofi || udf_get_lb_pblock(old_dir->i_sb, &tloc, 0)	    != old_inode->i_ino)		goto end_rename;	nfi = udf_find_entry(new_dir, &new_dentry->d_name, &nfibh, &ncfi);	if (nfi) {		if (!new_inode) {			if (nfibh.sbh != nfibh.ebh)				brelse(nfibh.ebh);			brelse(nfibh.sbh);			nfi = NULL;		}	}	if (S_ISDIR(old_inode->i_mode)) {		int offset = udf_ext0_offset(old_inode);		if (new_inode) {			retval = -ENOTEMPTY;			if (!empty_dir(new_inode))				goto end_rename;		}		retval = -EIO;		if (old_iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {			dir_fi = udf_get_fileident(					old_iinfo->i_ext.i_data -					  (old_iinfo->i_efe ?					   sizeof(struct extendedFileEntry) :					   sizeof(struct fileEntry)),					old_inode->i_sb->s_blocksize, &offset);		} else {			dir_bh = udf_bread(old_inode, 0, 0, &retval);			if (!dir_bh)				goto end_rename;			dir_fi = udf_get_fileident(dir_bh->b_data,					old_inode->i_sb->s_blocksize, &offset);		}		if (!dir_fi)			goto end_rename;		tloc = lelb_to_cpu(dir_fi->icb.extLocation);		if (udf_get_lb_pblock(old_inode->i_sb, &tloc, 0) !=				old_dir->i_ino)			goto end_rename;	}	if (!nfi) {		nfi = udf_add_entry(new_dir, new_dentry, &nfibh, &ncfi,				    &retval);		if (!nfi)			goto end_rename;	}	 	old_inode->i_ctime = current_fs_time(old_inode->i_sb);	mark_inode_dirty(old_inode);	 	ncfi.fileVersionNum = ocfi.fileVersionNum;	ncfi.fileCharacteristics = ocfi.fileCharacteristics;	memcpy(&(ncfi.icb), &(ocfi.icb), sizeof(struct long_ad));	udf_write_fi(new_dir, &ncfi, nfi, &nfibh, NULL, NULL);	 	ofi = udf_find_entry(old_dir, &old_dentry->d_name, &ofibh, &ocfi);	udf_delete_entry(old_dir, ofi, &ofibh, &ocfi);	if (new_inode) {		new_inode->i_ctime = current_fs_time(new_inode->i_sb);		inode_dec_link_count(new_inode);	}	old_dir->i_ctime = old_dir->i_mtime = current_fs_time(old_dir->i_sb);	mark_inode_dirty(old_dir);	if (dir_fi) {		dir_fi->icb.extLocation = cpu_to_lelb(UDF_I(new_dir)->i_location);		udf_update_tag((char *)dir_fi,				(sizeof(struct fileIdentDesc) +				le16_to_cpu(dir_fi->lengthOfImpUse) + 3) & ~3);		if (old_iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)			mark_inode_dirty(old_inode);		else			mark_buffer_dirty_inode(dir_bh, old_inode);		inode_dec_link_count(old_dir);		if (new_inode)			inode_dec_link_count(new_inode);		else {			inc_nlink(new_dir);			mark_inode_dirty(new_dir);		}	}	if (ofi) {		if (ofibh.sbh != ofibh.ebh)			brelse(ofibh.ebh);		brelse(ofibh.sbh);	}	retval = 0;end_rename:	brelse(dir_bh);	if (nfi) {		if (nfibh.sbh != nfibh.ebh)			brelse(nfibh.ebh);		brelse(nfibh.sbh);	}	return retval;}",9839
179,1008,CVE-2016-5696,22,"static inline int tcp_ack_is_dubious(const struct sock *sk, const int flag){	return !(flag & FLAG_NOT_DUP) || (flag & FLAG_CA_ALERT) ||		inet_csk(sk)->icsk_ca_state != TCP_CA_Open;}",16384
59,1817,CVE-2015-5302,22,"static void save_text_if_changed(const char *name, const char *new_value){              if (!g_hash_table_lookup(g_loaded_texts, name))        return;    const char *old_value = g_cd ? problem_data_get_content_or_NULL(g_cd, name) : "";    if (!old_value)        old_value = "";    if (strcmp(new_value, old_value) != 0)    {        struct dump_dir *dd = wizard_open_directory_for_writing(g_dump_dir_name);        if (dd)            dd_save_text(dd, name, new_value);          dd_close(dd);        problem_data_reload_from_dump_dir();        update_gui_state_from_problem_data(  0);     } }",31193
21,530,CVE-2013-3224,22,"static int bt_seq_open(struct inode *inode, struct file *file){	struct bt_sock_list *sk_list;	struct bt_seq_state *s;	sk_list = PDE(inode)->data;	s = __seq_open_private(file, &bt_seq_ops,			       sizeof(struct bt_seq_state));	if (!s)		return -ENOMEM;	s->l = sk_list;	return 0;}",8373
170,1806,CVE-2012-6537,22," static void copy_to_user_state(struct xfrm_state *x, struct xfrm_usersa_info *p) { 	memcpy(&p->id, &x->id, sizeof(p->id)); 	memcpy(&p->sel, &x->sel, sizeof(p->sel)); 	memcpy(&p->lft, &x->lft, sizeof(p->lft));	memcpy(&p->curlft, &x->curlft, sizeof(p->curlft));	memcpy(&p->stats, &x->stats, sizeof(p->stats));	memcpy(&p->saddr, &x->props.saddr, sizeof(p->saddr));	p->mode = x->props.mode;	p->replay_window = x->props.replay_window;	p->reqid = x->props.reqid;	p->family = x->props.family;	p->flags = x->props.flags;	p->seq = x->km.seq;}",31105
365,245,CVE-2013-4516,22,"static void mp_flush_buffer(struct tty_struct *tty){	struct sb_uart_state *state = tty->driver_data;	struct sb_uart_port *port;	unsigned long flags;	if (!state || !state->info) {		return;	}	port = state->port;	spin_lock_irqsave(&port->lock, flags);	uart_circ_clear(&state->info->xmit);	spin_unlock_irqrestore(&port->lock, flags);	wake_up_interruptible(&tty->write_wait);	tty_wakeup(tty);}",7683
407,1775,CVE-2019-5818,22,"static int CheckMJpeg(const int* buffer, int buffer_size) {  RCHECK(buffer_size >= 16);  int offset = 0;  int last_restart = -1;  int num_codes = 0;  while (offset + 5 < buffer_size) {    RCHECK(buffer[offset] == 0xff);    int code = buffer[offset + 1];    RCHECK(code >= 0xc0 || code == 1);    if (code == 0xff) {      ++offset;      continue;    }    if (code == 0xd9)      return true;    if (code == 0xd8 || code == 1) {      offset += 2;    } else if (code >= 0xd0 && code <= 0xd7) {      int restart = code & 0x07;      if (last_restart >= 0)        RCHECK(restart == (last_restart + 1) % 8);      last_restart = restart;      offset += 2;    } else {      int length = Read16(buffer + offset + 2) + 2;      if (code == 0xda) {        int number_components = buffer[offset + 4];        RCHECK(length == 8 + 2 * number_components);        offset += length;        while (offset + 2 < buffer_size) {          if (buffer[offset] == 0xff && buffer[offset + 1] != 0)            break;          ++offset;        }      } else {        offset += length;      }    }    ++num_codes;  }  return (num_codes > 1);}",30203
224,643,CVE-2013-0349,22,"static int hidp_setup_input(struct hidp_session *session,				struct hidp_connadd_req *req){	struct input_dev *input;	int i;	input = input_allocate_device();	if (!input)		return -ENOMEM;	session->input = input;	input_set_drvdata(input, session);	input->name = ""Bluetooth HID Boot Protocol Device"";	input->id.bustype = BUS_BLUETOOTH;	input->id.vendor  = req->vendor;	input->id.product = req->product;	input->id.version = req->version;	if (req->subclass & 0x40) {		set_bit(EV_KEY, input->evbit);		set_bit(EV_LED, input->evbit);		set_bit(EV_REP, input->evbit);		set_bit(LED_NUML,    input->ledbit);		set_bit(LED_CAPSL,   input->ledbit);		set_bit(LED_SCROLLL, input->ledbit);		set_bit(LED_COMPOSE, input->ledbit);		set_bit(LED_KANA,    input->ledbit);		for (i = 0; i < sizeof(hidp_keycode); i++)			set_bit(hidp_keycode[i], input->keybit);		clear_bit(0, input->keybit);	}	if (req->subclass & 0x80) {		input->evbit[0] = BIT_MASK(EV_KEY) | BIT_MASK(EV_REL);		input->keybit[BIT_WORD(BTN_MOUSE)] = BIT_MASK(BTN_LEFT) |			BIT_MASK(BTN_RIGHT) | BIT_MASK(BTN_MIDDLE);		input->relbit[0] = BIT_MASK(REL_X) | BIT_MASK(REL_Y);		input->keybit[BIT_WORD(BTN_MOUSE)] |= BIT_MASK(BTN_SIDE) |			BIT_MASK(BTN_EXTRA);		input->relbit[0] |= BIT_MASK(REL_WHEEL);	}	input->dev.parent = &session->conn->dev;	input->event = hidp_input_event;	return 0;}",9716
49,1224,CVE-2016-2117,22,"static int atl2_set_mac(struct net_device *netdev, void *p){	struct atl2_adapter *adapter = netdev_priv(netdev);	struct sockaddr *addr = p;	if (!is_valid_ether_addr(addr->sa_data))		return -EADDRNOTAVAIL;	if (netif_running(netdev))		return -EBUSY;	memcpy(netdev->dev_addr, addr->sa_data, netdev->addr_len);	memcpy(adapter->hw.mac_addr, addr->sa_data, netdev->addr_len);	atl2_set_mac_addr(&adapter->hw);	return 0;}",17984
11,1640,CVE-2018-18839,22,"char to_hex(char code) {    static char hex[] = ""0123456789abcdef"";    return hex[code & 15];}",27911
444,1759,CVE-2019-5837,22,  void Reinitialize1() {    Reinitialize(CORRUPT_CACHE_ON_INSTALL);  },30171
272,1400,CVE-2017-14140,22,"static struct page *alloc_misplaced_dst_page(struct page *page,					   unsigned long data,					   int **result){	int nid = (int) data;	struct page *newpage;	newpage = __alloc_pages_node(nid,					 (GFP_HIGHUSER_MOVABLE |					  __GFP_THISNODE | __GFP_NOMEMALLOC |					  __GFP_NORETRY | __GFP_NOWARN) &					 ~__GFP_RECLAIM, 0);	return newpage;}",20184
351,1498,CVE-2018-20511,22,static struct ipddp_route* __ipddp_find_route(struct ipddp_route *rt){        struct ipddp_route *f;        for(f = ipddp_route_list; f != NULL; f = f->next)        {                if(f->ip == rt->ip &&		   f->at.s_net == rt->at.s_net &&		   f->at.s_node == rt->at.s_node)                        return f;        }        return NULL;},23265
423,676,CVE-2012-6541,22,"static void ccid3_hc_rx_set_state(struct sock *sk,				  enum ccid3_hc_rx_states state){	struct ccid3_hc_rx_sock *hc = ccid3_hc_rx_sk(sk);	enum ccid3_hc_rx_states oldstate = hc->rx_state;	ccid3_pr_debug(""%s(%p) %-8.8s -> %s\n"",		       dccp_role(sk), sk, ccid3_rx_state_name(oldstate),		       ccid3_rx_state_name(state));	WARN_ON(state == oldstate);	hc->rx_state = state;}",9863
64,1495,CVE-2017-0377,22,"node_get_or_create(const char *identity_digest){  node_t *node;  if ((node = node_get_mutable_by_id(identity_digest)))    return node;  node = tor_malloc_zero(sizeof(node_t));  memcpy(node->identity, identity_digest, DIGEST_LEN);  HT_INSERT(nodelist_map, &the_nodelist->nodes_by_id, node);  smartlist_add(the_nodelist->nodes, node);  node->nodelist_idx = smartlist_len(the_nodelist->nodes) - 1;  node->country = -1;  return node;}",22258
229,685,CVE-2012-6540,22,"__ip_vs_dev_reset(struct ip_vs_dest *dest, struct net_device *dev){	spin_lock_bh(&dest->dst_lock);	if (dest->dst_cache && dest->dst_cache->dev == dev) {		IP_VS_DBG_BUF(3, ""Reset dev:%s dest %s:%u ,dest->refcnt=%d\n"",			      dev->name,			      IP_VS_DBG_ADDR(dest->af, &dest->addr),			      ntohs(dest->port),			      atomic_read(&dest->refcnt));		ip_vs_dst_reset(dest);	}	spin_unlock_bh(&dest->dst_lock);}",9872
421,122,CVE-2018-11469,22,"smp_fetch_capture_req_uri(const struct arg *args, struct sample *smp, const char *kw, void *private){	struct chunk *temp;	struct http_txn *txn = smp->strm->txn;	char *ptr;	if (!txn || !txn->uri)		return 0;	ptr = txn->uri;	while (*ptr != ' ' && *ptr != '\0')   		ptr++;	if (!*ptr)		return 0;	ptr++;   	temp = get_trash_chunk();	ptr = temp->str = http_get_path_from_string(ptr);	if (!ptr)		return 0;	while (*ptr != ' ' && *ptr != '\0')   		ptr++;	smp->data.u.str = *temp;	smp->data.u.str.len = ptr - temp->str;	smp->data.type = SMP_T_STR;	smp->flags = SMP_F_CONST;	return 1;}",1127
95,1601,CVE-2019-12107,22,upnp_event_var_change_notify(enum subscriber_service_enum service){	struct subscriber * sub;	for(sub = subscriberlist.lh_first; sub != NULL; sub = sub->entries.le_next) {		if(sub->service == service && sub->notify == NULL)			upnp_event_create_notify(sub);	}},26903
149,1493,CVE-2017-0377,22,get_dir_info_status_string(void){  return dir_info_status;},22256
297,369,CVE-2013-3236,22,"int vmci_transport_send_wrote(struct sock *sk){	return vmci_transport_send_control_pkt(					sk, VMCI_TRANSPORT_PACKET_TYPE_WROTE, 0,					0, NULL, VSOCK_PROTO_INVALID,					VMCI_INVALID_HANDLE);}",8212
238,1092,CVE-2016-5243,22,"static int tipc_nl_compat_link_stat_dump(struct tipc_nl_compat_msg *msg,					 struct nlattr **attrs){	char *name;	struct nlattr *link[TIPC_NLA_LINK_MAX + 1];	struct nlattr *prop[TIPC_NLA_PROP_MAX + 1];	struct nlattr *stats[TIPC_NLA_STATS_MAX + 1];	int err;	if (!attrs[TIPC_NLA_LINK])		return -EINVAL;	err = nla_parse_nested(link, TIPC_NLA_LINK_MAX, attrs[TIPC_NLA_LINK],			       NULL);	if (err)		return err;	if (!link[TIPC_NLA_LINK_PROP])		return -EINVAL;	err = nla_parse_nested(prop, TIPC_NLA_PROP_MAX,			       link[TIPC_NLA_LINK_PROP], NULL);	if (err)		return err;	if (!link[TIPC_NLA_LINK_STATS])		return -EINVAL;	err = nla_parse_nested(stats, TIPC_NLA_STATS_MAX,			       link[TIPC_NLA_LINK_STATS], NULL);	if (err)		return err;	name = (char *)TLV_DATA(msg->req);	if (strcmp(name, nla_data(link[TIPC_NLA_LINK_NAME])) != 0)		return 0;	tipc_tlv_sprintf(msg->rep, ""\nLink <%s>\n"",			 nla_data(link[TIPC_NLA_LINK_NAME]));	if (link[TIPC_NLA_LINK_BROADCAST]) {		__fill_bc_link_stat(msg, prop, stats);		return 0;	}	if (link[TIPC_NLA_LINK_ACTIVE])		tipc_tlv_sprintf(msg->rep, ""  ACTIVE"");	else if (link[TIPC_NLA_LINK_UP])		tipc_tlv_sprintf(msg->rep, ""  STANDBY"");	else		tipc_tlv_sprintf(msg->rep, ""  DEFUNCT"");	tipc_tlv_sprintf(msg->rep, ""  MTU:%u  Priority:%u"",			 nla_get_u32(link[TIPC_NLA_LINK_MTU]),			 nla_get_u32(prop[TIPC_NLA_PROP_PRIO]));	tipc_tlv_sprintf(msg->rep, ""  Tolerance:%u ms  Window:%u packets\n"",			 nla_get_u32(prop[TIPC_NLA_PROP_TOL]),			 nla_get_u32(prop[TIPC_NLA_PROP_WIN]));	tipc_tlv_sprintf(msg->rep,			 ""  RX packets:%u fragments:%u/%u bundles:%u/%u\n"",			 nla_get_u32(link[TIPC_NLA_LINK_RX]) -			 nla_get_u32(stats[TIPC_NLA_STATS_RX_INFO]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_FRAGMENTS]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_FRAGMENTED]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_BUNDLES]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_BUNDLED]));	tipc_tlv_sprintf(msg->rep,			 ""  TX packets:%u fragments:%u/%u bundles:%u/%u\n"",			 nla_get_u32(link[TIPC_NLA_LINK_TX]) -			 nla_get_u32(stats[TIPC_NLA_STATS_TX_INFO]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_FRAGMENTS]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_FRAGMENTED]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_BUNDLES]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_BUNDLED]));	tipc_tlv_sprintf(msg->rep,			 ""  TX profile sample:%u packets  average:%u octets\n"",			 nla_get_u32(stats[TIPC_NLA_STATS_MSG_LEN_CNT]),			 nla_get_u32(stats[TIPC_NLA_STATS_MSG_LEN_TOT]) /			 nla_get_u32(stats[TIPC_NLA_STATS_MSG_PROF_TOT]));	tipc_tlv_sprintf(msg->rep,			 ""  0-64:%u%% -256:%u%% -1024:%u%% -4096:%u%% "",			 perc(nla_get_u32(stats[TIPC_NLA_STATS_MSG_LEN_P0]),			      nla_get_u32(stats[TIPC_NLA_STATS_MSG_PROF_TOT])),			 perc(nla_get_u32(stats[TIPC_NLA_STATS_MSG_LEN_P1]),			      nla_get_u32(stats[TIPC_NLA_STATS_MSG_PROF_TOT])),			 perc(nla_get_u32(stats[TIPC_NLA_STATS_MSG_LEN_P2]),			      nla_get_u32(stats[TIPC_NLA_STATS_MSG_PROF_TOT])),			 perc(nla_get_u32(stats[TIPC_NLA_STATS_MSG_LEN_P3]),			      nla_get_u32(stats[TIPC_NLA_STATS_MSG_PROF_TOT])));	tipc_tlv_sprintf(msg->rep, ""-16384:%u%% -32768:%u%% -66000:%u%%\n"",			 perc(nla_get_u32(stats[TIPC_NLA_STATS_MSG_LEN_P4]),			      nla_get_u32(stats[TIPC_NLA_STATS_MSG_PROF_TOT])),			 perc(nla_get_u32(stats[TIPC_NLA_STATS_MSG_LEN_P5]),			      nla_get_u32(stats[TIPC_NLA_STATS_MSG_PROF_TOT])),			 perc(nla_get_u32(stats[TIPC_NLA_STATS_MSG_LEN_P6]),			      nla_get_u32(stats[TIPC_NLA_STATS_MSG_PROF_TOT])));	tipc_tlv_sprintf(msg->rep,			 ""  RX states:%u probes:%u naks:%u defs:%u dups:%u\n"",			 nla_get_u32(stats[TIPC_NLA_STATS_RX_STATES]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_PROBES]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_NACKS]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_DEFERRED]),			 nla_get_u32(stats[TIPC_NLA_STATS_DUPLICATES]));	tipc_tlv_sprintf(msg->rep,			 ""  TX states:%u probes:%u naks:%u acks:%u dups:%u\n"",			 nla_get_u32(stats[TIPC_NLA_STATS_TX_STATES]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_PROBES]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_NACKS]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_ACKS]),			 nla_get_u32(stats[TIPC_NLA_STATS_RETRANSMITTED]));	tipc_tlv_sprintf(msg->rep,			 ""  Congestion link:%u  Send queue max:%u avg:%u"",			 nla_get_u32(stats[TIPC_NLA_STATS_LINK_CONGS]),			 nla_get_u32(stats[TIPC_NLA_STATS_MAX_QUEUE]),			 nla_get_u32(stats[TIPC_NLA_STATS_AVG_QUEUE]));	return 0;}",16500
409,1638,CVE-2019-5489,22,"static long do_mincore(unsigned long addr, unsigned long pages, unsigned char *vec){	struct vm_area_struct *vma;	unsigned long end;	int err;	struct mm_walk mincore_walk = {		.pmd_entry = mincore_pte_range,		.pte_hole = mincore_unmapped_range,		.hugetlb_entry = mincore_hugetlb,		.private = vec,	};	vma = find_vma(current->mm, addr);	if (!vma || addr < vma->vm_start)		return -ENOMEM;	mincore_walk.mm = vma->vm_mm;	end = min(vma->vm_end, addr + (pages << PAGE_SHIFT));	err = walk_page_range(addr, end, &mincore_walk);	if (err < 0)		return err;	return (end - addr) >> PAGE_SHIFT;}",27424
56,998,CVE-2016-9756,22,"static int em_cmpxchg(struct x86_emulate_ctxt *ctxt){	 	ctxt->dst.orig_val = ctxt->dst.val;	ctxt->dst.val = reg_read(ctxt, VCPU_REGS_RAX);	ctxt->src.orig_val = ctxt->src.val;	ctxt->src.val = ctxt->dst.orig_val;	fastop(ctxt, em_cmp);	if (ctxt->eflags & X86_EFLAGS_ZF) {		 		ctxt->src.type = OP_NONE;		ctxt->dst.val = ctxt->src.orig_val;	} else {		 		ctxt->src.type = OP_REG;		ctxt->src.addr.reg = reg_rmw(ctxt, VCPU_REGS_RAX);		ctxt->src.val = ctxt->dst.orig_val;		 		ctxt->dst.val = ctxt->dst.orig_val;	}	return X86EMUL_CONTINUE;}",15097
55,1655,CVE-2012-6545,22,"static struct rfcomm_dev *rfcomm_dev_get(int id){	struct rfcomm_dev *dev;	spin_lock(&rfcomm_dev_lock);	dev = __rfcomm_dev_get(id);	if (dev) {		if (test_bit(RFCOMM_TTY_RELEASED, &dev->flags))			dev = NULL;		else			tty_port_get(&dev->port);	}	spin_unlock(&rfcomm_dev_lock);	return dev;}",28315
319,1739,CVE-2018-6053,22,  void StartQueryForMostVisited() { top_sites()->StartQueryForMostVisited(); },30090
17,1685,CVE-2012-6544,22,"static void l2cap_sock_ready_cb(struct l2cap_chan *chan){	struct sock *sk = chan->data;	struct sock *parent;	lock_sock(sk);	parent = bt_sk(sk)->parent;	BT_DBG(""sk %p, parent %p"", sk, parent);	sk->sk_state = BT_CONNECTED;	sk->sk_state_change(sk);	if (parent)		parent->sk_data_ready(parent, 0);	release_sock(sk);}",28345
381,907,CVE-2015-5697,22,"void md_error(struct mddev *mddev, struct md_rdev *rdev){	if (!rdev || test_bit(Faulty, &rdev->flags))		return;	if (!mddev->pers || !mddev->pers->error_handler)		return;	mddev->pers->error_handler(mddev,rdev);	if (mddev->degraded)		set_bit(MD_RECOVERY_RECOVER, &mddev->recovery);	sysfs_notify_dirent_safe(rdev->sysfs_state);	set_bit(MD_RECOVERY_INTR, &mddev->recovery);	set_bit(MD_RECOVERY_NEEDED, &mddev->recovery);	md_wakeup_thread(mddev->thread);	if (mddev->event_work.func)		queue_work(md_misc_wq, &mddev->event_work);	md_new_event_inintr(mddev);}",13237
370,1107,CVE-2016-4578,22,"int snd_timer_global_register(struct snd_timer *timer){	struct snd_device dev;	memset(&dev, 0, sizeof(dev));	dev.device_data = timer;	return snd_timer_dev_register(&dev);}",16695
18,541,CVE-2013-3223,22,	__releases(ax25_list_lock){	spin_unlock_bh(&ax25_list_lock);},8384
50,968,CVE-2015-5697,22,"sync_min_show(struct mddev *mddev, char *page){	return sprintf(page, ""%d (%s)\n"", speed_min(mddev),		       mddev->sync_speed_min ? ""local"": ""system"");}",13298
446,563,CVE-2013-3222,22,static void vcc_release_cb(struct sock *sk){	struct atm_vcc *vcc = atm_sk(sk);	if (vcc->release_cb)		vcc->release_cb(vcc);},8406
44,168,CVE-2016-4020,22,static int modrm_reg(int modrm){    return (modrm >> 3) & 7;},1955
356,1358,CVE-2014-9903,22,void set_numabalancing_state(int enabled){	numabalancing_enabled = enabled;},19295
280,1387,CVE-2017-14954,22,do_group_exit(int exit_code){	struct signal_struct *sig = current->signal;	BUG_ON(exit_code & 0x80);  	if (signal_group_exit(sig))		exit_code = sig->group_exit_code;	else if (!thread_group_empty(current)) {		struct sighand_struct *const sighand = current->sighand;		spin_lock_irq(&sighand->siglock);		if (signal_group_exit(sig))			 			exit_code = sig->group_exit_code;		else {			sig->group_exit_code = exit_code;			sig->flags = SIGNAL_GROUP_EXIT;			zap_other_threads(current);		}		spin_unlock_irq(&sighand->siglock);	}	do_exit(exit_code);	 },20102
121,1238,CVE-2016-0823,22,"static int pid_smaps_open(struct inode *inode, struct file *file){	return do_maps_open(inode, file, &proc_pid_smaps_op);}",18200
431,885,CVE-2015-5697,22,"static int add_bound_rdev(struct md_rdev *rdev){	struct mddev *mddev = rdev->mddev;	int err = 0;	if (!mddev->pers->hot_remove_disk) {		 		super_types[mddev->major_version].			validate_super(mddev, rdev);		err = mddev->pers->hot_add_disk(mddev, rdev);		if (err) {			unbind_rdev_from_array(rdev);			export_rdev(rdev);			return err;		}	}	sysfs_notify_dirent_safe(rdev->sysfs_state);	set_bit(MD_CHANGE_DEVS, &mddev->flags);	if (mddev->degraded)		set_bit(MD_RECOVERY_RECOVER, &mddev->recovery);	set_bit(MD_RECOVERY_NEEDED, &mddev->recovery);	md_new_event(mddev);	md_wakeup_thread(mddev->thread);	return 0;}",13215
441,737,CVE-2014-9419,22,void set_personality_ia32(int x32){	 	 	set_thread_flag(TIF_ADDR32);	 	if (x32) {		clear_thread_flag(TIF_IA32);		set_thread_flag(TIF_X32);		if (current->mm)			current->mm->context.ia32_compat = TIF_X32;		current->personality &= ~READ_IMPLIES_EXEC;		 		current_thread_info()->status &= ~TS_COMPAT;	} else {		set_thread_flag(TIF_IA32);		clear_thread_flag(TIF_X32);		if (current->mm)			current->mm->context.ia32_compat = TIF_IA32;		current->personality |= force_personality32;		 		current_thread_info()->status |= TS_COMPAT;	}},10369
397,155,CVE-2018-11469,22,"int smp_prefetch_http(struct proxy *px, struct stream *s, unsigned int opt,                  const struct arg *args, struct sample *smp, int req_vol){	struct http_txn *txn;	struct http_msg *msg;	 	if (!s)		return 0;	if (!s->txn) {		if (unlikely(!http_alloc_txn(s)))			return 0;  		http_init_txn(s);	}	txn = s->txn;	msg = &txn->req;	 	smp->data.type = SMP_T_BOOL;	if ((opt & SMP_OPT_DIR) == SMP_OPT_DIR_REQ) {		 		if (s->req.buf->p > s->req.buf->data &&		    s->req.buf->i + s->req.buf->p > s->req.buf->data + s->req.buf->size - global.tune.maxrewrite)			buffer_slow_realign(s->req.buf);		if (unlikely(txn->req.msg_state < HTTP_MSG_BODY)) {			if (msg->msg_state == HTTP_MSG_ERROR)				return 0;			 			if (likely(msg->next < s->req.buf->i))				http_msg_analyzer(msg, &txn->hdr_idx);			 			if (unlikely(msg->msg_state < HTTP_MSG_BODY)) {				if ((msg->msg_state == HTTP_MSG_ERROR) ||				    buffer_full(s->req.buf, global.tune.maxrewrite)) {					return 0;				}				 				smp->flags |= SMP_F_MAY_CHANGE;				return 0;			}			 			 			if (unlikely(s->req.buf->i + s->req.buf->p >				     s->req.buf->data + s->req.buf->size - global.tune.maxrewrite)) {				msg->err_state = msg->msg_state;				msg->msg_state = HTTP_MSG_ERROR;				smp->data.u.sint = 1;				return 1;			}			txn->meth = find_http_meth(msg->chn->buf->p, msg->sl.rq.m_l);			if (txn->meth == HTTP_METH_GET || txn->meth == HTTP_METH_HEAD)				s->flags |= SF_REDIRECTABLE;			if (unlikely(msg->sl.rq.v_l == 0) && !http_upgrade_v09_to_v10(txn))				return 0;		}		if (req_vol && txn->rsp.msg_state != HTTP_MSG_RPBEFORE) {			return 0;   		}		 	}	else {		 		if (txn->rsp.msg_state < HTTP_MSG_BODY) {			smp->flags |= SMP_F_MAY_CHANGE;			return 0;		}	}	 	smp->data.u.sint = 1;	return 1;}",1160
439,400,CVE-2013-3232,22,"static int nr_create(struct net *net, struct socket *sock, int protocol,		     int kern){	struct sock *sk;	struct nr_sock *nr;	if (!net_eq(net, &init_net))		return -EAFNOSUPPORT;	if (sock->type != SOCK_SEQPACKET || protocol != 0)		return -ESOCKTNOSUPPORT;	sk = sk_alloc(net, PF_NETROM, GFP_ATOMIC, &nr_proto);	if (sk  == NULL)		return -ENOMEM;	nr = nr_sk(sk);	sock_init_data(sock, sk);	sock->ops    = &nr_proto_ops;	sk->sk_protocol = protocol;	skb_queue_head_init(&nr->ack_queue);	skb_queue_head_init(&nr->reseq_queue);	skb_queue_head_init(&nr->frag_queue);	nr_init_timers(sk);	nr->t1     =		msecs_to_jiffies(sysctl_netrom_transport_timeout);	nr->t2     =		msecs_to_jiffies(sysctl_netrom_transport_acknowledge_delay);	nr->n2     =		msecs_to_jiffies(sysctl_netrom_transport_maximum_tries);	nr->t4     =		msecs_to_jiffies(sysctl_netrom_transport_busy_delay);	nr->idle   =		msecs_to_jiffies(sysctl_netrom_transport_no_activity_timeout);	nr->window = sysctl_netrom_transport_requested_window_size;	nr->bpqext = 1;	nr->state  = NR_STATE_0;	return 0;}",8243
176,1372,CVE-2017-16994,22,"static int walk_hugetlb_range(unsigned long addr, unsigned long end,			      struct mm_walk *walk){	return 0;}",19609
288,602,CVE-2013-2061,22,"read_key (struct key *key, const struct key_type *kt, struct buffer *buf){  int cipher_length;  int hmac_length;  CLEAR (*key);  if (!buf_read (buf, &cipher_length, 1))    goto read_err;  if (!buf_read (buf, &hmac_length, 1))    goto read_err;  if (!buf_read (buf, key->cipher, cipher_length))    goto read_err;  if (!buf_read (buf, key->hmac, hmac_length))    goto read_err;  if (cipher_length != kt->cipher_length || hmac_length != kt->hmac_length)    goto key_len_err;  return 1;read_err:  msg (D_TLS_ERRORS, ""TLS Error: error reading key from remote"");  return -1;key_len_err:  msg (D_TLS_ERRORS,       ""TLS Error: key length mismatch, local cipher/hmac %d/%d, remote cipher/hmac %d/%d"",       kt->cipher_length, kt->hmac_length, cipher_length, hmac_length);  return 0;}",8962
358,1552,CVE-2018-18710,22,"void init_cdrom_command(struct packet_command *cgc, void *buf, int len,			int type){	memset(cgc, 0, sizeof(struct packet_command));	if (buf)		memset(buf, 0, len);	cgc->buffer = (char *) buf;	cgc->buflen = len;	cgc->data_direction = type;	cgc->timeout = CDROM_DEF_TIMEOUT;}",23469
61,48,CVE-2018-11469,22,"void check_response_for_cacheability(struct stream *s, struct channel *rtr){	struct http_txn *txn = s->txn;	char *p1, *p2;	char *cur_ptr, *cur_end, *cur_next;	int cur_idx;	if (txn->status < 200) {		 		txn->flags &= ~TX_CACHEABLE & ~TX_CACHE_COOK;		return;	}	 	cur_idx = 0;	cur_next = rtr->buf->p + hdr_idx_first_pos(&txn->hdr_idx);	while ((cur_idx = txn->hdr_idx.v[cur_idx].next)) {		struct hdr_idx_elem *cur_hdr;		int val;		cur_hdr  = &txn->hdr_idx.v[cur_idx];		cur_ptr  = cur_next;		cur_end  = cur_ptr + cur_hdr->len;		cur_next = cur_end + cur_hdr->cr + 1;		 		val = http_header_match2(cur_ptr, cur_end, ""Pragma"", 6);		if (val) {			if ((cur_end - (cur_ptr + val) >= 8) &&			    strncasecmp(cur_ptr + val, ""no-cache"", 8) == 0) {				txn->flags &= ~TX_CACHEABLE & ~TX_CACHE_COOK;				return;			}		}		val = http_header_match2(cur_ptr, cur_end, ""Cache-control"", 13);		if (!val)			continue;		 		p1 = cur_ptr + val;  		if (p1 >= cur_end)	 			continue;		 		p2 = p1;		while (p2 < cur_end && *p2 != '=' && *p2 != ',' && !isspace((unsigned char)*p2))			p2++;		 		if (p2 < cur_end && *p2 == '=') {			if (((cur_end - p2) > 1 && (p2 - p1 == 7) && strncasecmp(p1, ""max-age=0"", 9) == 0) ||			    ((cur_end - p2) > 1 && (p2 - p1 == 8) && strncasecmp(p1, ""s-maxage=0"", 10) == 0)) {				txn->flags &= ~TX_CACHEABLE & ~TX_CACHE_COOK;				continue;			}			 			if ((cur_end - p1 >= 21) &&			    strncasecmp(p1, ""no-cache=\""set-cookie"", 20) == 0			    && (p1[20] == '""' || p1[20] == ','))				txn->flags &= ~TX_CACHE_COOK;			continue;		}		 		if (((p2 - p1 ==  7) && strncasecmp(p1, ""private"", 7) == 0) ||		    ((p2 - p1 ==  8) && strncasecmp(p1, ""no-cache"", 8) == 0) ||		    ((p2 - p1 ==  8) && strncasecmp(p1, ""no-store"", 8) == 0)) {			txn->flags &= ~TX_CACHEABLE & ~TX_CACHE_COOK;			return;		}		if ((p2 - p1 ==  6) && strncasecmp(p1, ""public"", 6) == 0) {			txn->flags |= TX_CACHEABLE | TX_CACHE_COOK;			continue;		}	}}",1053
296,125,CVE-2018-11469,22,"int smp_fetch_cookie(const struct arg *args, struct sample *smp, const char *kw, void *private){	struct http_txn *txn;	struct hdr_idx *idx;	struct hdr_ctx *ctx = smp->ctx.a[2];	const struct http_msg *msg;	const char *hdr_name;	int hdr_name_len;	char *sol;	int occ = 0;	int found = 0;	if (!args || args->type != ARGT_STR)		return 0;	if (!ctx) {		 		ctx = &static_hdr_ctx;		ctx->idx = 0;		smp->ctx.a[2] = ctx;	}	CHECK_HTTP_MESSAGE_FIRST();	txn = smp->strm->txn;	idx = &smp->strm->txn->hdr_idx;	if ((smp->opt & SMP_OPT_DIR) == SMP_OPT_DIR_REQ) {		msg = &txn->req;		hdr_name = ""Cookie"";		hdr_name_len = 6;	} else {		msg = &txn->rsp;		hdr_name = ""Set-Cookie"";		hdr_name_len = 10;	}	if (!occ && !(smp->opt & SMP_OPT_ITERATE))		 		occ = -1;	 	sol = msg->chn->buf->p;	if (!(smp->flags & SMP_F_NOT_LAST)) {		 		smp->ctx.a[0] = NULL;		ctx->idx = 0;	}	smp->flags |= SMP_F_VOL_HDR;	while (1) {		 		if (!smp->ctx.a[0]) {			if (!http_find_header2(hdr_name, hdr_name_len, sol, idx, ctx))				goto out;			if (ctx->vlen < args->data.str.len + 1)				continue;			smp->ctx.a[0] = ctx->line + ctx->val;			smp->ctx.a[1] = smp->ctx.a[0] + ctx->vlen;		}		smp->data.type = SMP_T_STR;		smp->flags |= SMP_F_CONST;		smp->ctx.a[0] = extract_cookie_value(smp->ctx.a[0], smp->ctx.a[1],						 args->data.str.str, args->data.str.len,						 (smp->opt & SMP_OPT_DIR) == SMP_OPT_DIR_REQ,						 &smp->data.u.str.str,						 &smp->data.u.str.len);		if (smp->ctx.a[0]) {			found = 1;			if (occ >= 0) {				 				smp->flags |= SMP_F_NOT_LAST;				return 1;			}		}		 	}	  out:	smp->flags &= ~SMP_F_NOT_LAST;	return found;}",1130
268,654,CVE-2012-6548,22,"static int udf_unlink(struct inode *dir, struct dentry *dentry){	int retval;	struct inode *inode = dentry->d_inode;	struct udf_fileident_bh fibh;	struct fileIdentDesc *fi;	struct fileIdentDesc cfi;	struct kernel_lb_addr tloc;	retval = -ENOENT;	fi = udf_find_entry(dir, &dentry->d_name, &fibh, &cfi);	if (!fi)		goto out;	retval = -EIO;	tloc = lelb_to_cpu(cfi.icb.extLocation);	if (udf_get_lb_pblock(dir->i_sb, &tloc, 0) != inode->i_ino)		goto end_unlink;	if (!inode->i_nlink) {		udf_debug(""Deleting nonexistent file (%lu), %d\n"",			  inode->i_ino, inode->i_nlink);		set_nlink(inode, 1);	}	retval = udf_delete_entry(dir, fi, &fibh, &cfi);	if (retval)		goto end_unlink;	dir->i_ctime = dir->i_mtime = current_fs_time(dir->i_sb);	mark_inode_dirty(dir);	inode_dec_link_count(inode);	inode->i_ctime = dir->i_ctime;	retval = 0;end_unlink:	if (fibh.sbh != fibh.ebh)		brelse(fibh.ebh);	brelse(fibh.sbh);out:	return retval;}",9841
357,1476,CVE-2017-0377,22,"entry_guard_get_by_id_digest(const char *digest){  return entry_guard_get_by_id_digest_for_guard_selection(      get_guard_selection_info(), digest);}",22239
228,644,CVE-2013-0349,22,static void hidp_stop(struct hid_device *hid){	struct hidp_session *session = hid->driver_data;	skb_queue_purge(&session->ctrl_transmit);	skb_queue_purge(&session->intr_transmit);	hid->claimed = 0;},9717
239,1678,CVE-2012-6544,22,static void l2cap_sock_close_cb(struct l2cap_chan *chan){	struct sock *sk = chan->data;	l2cap_sock_kill(sk);},28338
33,809,CVE-2011-2909,22,"static int comedi_fasync(int fd, struct file *file, int on){	const unsigned minor = iminor(file->f_dentry->d_inode);	struct comedi_device_file_info *dev_file_info =	    comedi_get_device_file_info(minor);	struct comedi_device *dev = dev_file_info->device;	return fasync_helper(fd, file, on, &dev->async_queue);}",12770
428,24,CVE-2015-5330,22,const struct ldb_val *ldb_dn_get_rdn_val(struct ldb_dn *dn){	if ( ! ldb_dn_validate(dn)) {		return NULL;	}	if (dn->comp_num == 0) return NULL;	return &dn->components[0].value;},467
308,1298,CVE-2015-8575,22,"static int sco_sock_shutdown(struct socket *sock, int how){	struct sock *sk = sock->sk;	int err = 0;	BT_DBG(""sock %p, sk %p"", sock, sk);	if (!sk)		return 0;	sock_hold(sk);	lock_sock(sk);	if (!sk->sk_shutdown) {		sk->sk_shutdown = SHUTDOWN_MASK;		sco_sock_clear_timer(sk);		__sco_sock_close(sk);		if (sock_flag(sk, SOCK_LINGER) && sk->sk_lingertime &&		    !(current->flags & PF_EXITING))			err = bt_sock_wait_state(sk, BT_CLOSED,						 sk->sk_lingertime);	}	release_sock(sk);	sock_put(sk);	return err;}",18934
23,1273,CVE-2015-8964,22,static void tty_ldisc_put(struct tty_ldisc *ld){	if (WARN_ON_ONCE(!ld))		return;	put_ldops(ld->ops);	kfree(ld);},18312
93,928,CVE-2015-5697,22,void md_stop_writes(struct mddev *mddev){	mddev_lock_nointr(mddev);	__md_stop_writes(mddev);	mddev_unlock(mddev);},13258
143,257,CVE-2013-4516,22,static void mp_start(struct tty_struct *tty){	__mp_start(tty);},7695
215,1134,CVE-2016-4578,22,"static int snd_timer_user_start(struct file *file){	int err;	struct snd_timer_user *tu;	tu = file->private_data;	if (!tu->timeri)		return -EBADFD;	snd_timer_stop(tu->timeri);	tu->timeri->lost = 0;	tu->last_resolution = 0;	return (err = snd_timer_start(tu->timeri, tu->ticks)) < 0 ? err : 0;}",16722
172,1517,CVE-2018-18710,22,"static int cdrom_ioctl_debug(struct cdrom_device_info *cdi,		unsigned long arg){	cd_dbg(CD_DO_IOCTL, ""%sabling debug\n"", arg ? ""En"" : ""Dis"");	if (!capable(CAP_SYS_ADMIN))		return -EACCES;	debug = arg ? 1 : 0;	return debug;}",23434
259,996,CVE-2016-9756,22,"static int em_bsf_c(struct x86_emulate_ctxt *ctxt){	 	if (ctxt->src.val == 0)		ctxt->dst.type = OP_NONE;	return fastop(ctxt, em_bsf);}",15095
418,1357,CVE-2014-9903,22,"void set_numabalancing_state(int enabled){	if (enabled)		sched_feat_set(""NUMA"");	else		sched_feat_set(""NO_NUMA"");}",19294
235,1481,CVE-2017-0377,22,"get_guard_lifetime(void){  if (get_options()->GuardLifetime >= 86400)    return get_options()->GuardLifetime;  int days;  days = networkstatus_get_param(NULL,                                 ""guard-lifetime-days"",                                 DFLT_GUARD_LIFETIME_DAYS, 1, 365*10);  return days * 86400;}",22244
410,142,CVE-2018-11469,22,"smp_fetch_path(const struct arg *args, struct sample *smp, const char *kw, void *private){	struct http_txn *txn;	char *ptr, *end;	CHECK_HTTP_MESSAGE_FIRST();	txn = smp->strm->txn;	end = txn->req.chn->buf->p + txn->req.sl.rq.u + txn->req.sl.rq.u_l;	ptr = http_get_path(txn);	if (!ptr)		return 0;	 	smp->data.type = SMP_T_STR;	smp->data.u.str.str = ptr;	while (ptr < end && *ptr != '?')		ptr++;	smp->data.u.str.len = ptr - smp->data.u.str.str;	smp->flags = SMP_F_VOL_1ST | SMP_F_CONST;	return 1;}",1147
379,1407,CVE-2017-14140,22,"void putback_movable_page(struct page *page){	struct address_space *mapping;	VM_BUG_ON_PAGE(!PageLocked(page), page);	VM_BUG_ON_PAGE(!PageMovable(page), page);	VM_BUG_ON_PAGE(!PageIsolated(page), page);	mapping = page_mapping(page);	mapping->a_ops->putback_page(page);	__ClearPageIsolated(page);}",20191
267,902,CVE-2015-5697,22,"static void md_clean(struct mddev *mddev){	mddev->array_sectors = 0;	mddev->external_size = 0;	mddev->dev_sectors = 0;	mddev->raid_disks = 0;	mddev->recovery_cp = 0;	mddev->resync_min = 0;	mddev->resync_max = MaxSector;	mddev->reshape_position = MaxSector;	mddev->external = 0;	mddev->persistent = 0;	mddev->level = LEVEL_NONE;	mddev->clevel[0] = 0;	mddev->flags = 0;	mddev->ro = 0;	mddev->metadata_type[0] = 0;	mddev->chunk_sectors = 0;	mddev->ctime = mddev->utime = 0;	mddev->layout = 0;	mddev->max_disks = 0;	mddev->events = 0;	mddev->can_decrease_events = 0;	mddev->delta_disks = 0;	mddev->reshape_backwards = 0;	mddev->new_level = LEVEL_NONE;	mddev->new_layout = 0;	mddev->new_chunk_sectors = 0;	mddev->curr_resync = 0;	atomic64_set(&mddev->resync_mismatches, 0);	mddev->suspend_lo = mddev->suspend_hi = 0;	mddev->sync_speed_min = mddev->sync_speed_max = 0;	mddev->recovery = 0;	mddev->in_sync = 0;	mddev->changed = 0;	mddev->degraded = 0;	mddev->safemode = 0;	mddev->private = NULL;	mddev->merge_check_needed = 0;	mddev->bitmap_info.offset = 0;	mddev->bitmap_info.default_offset = 0;	mddev->bitmap_info.default_space = 0;	mddev->bitmap_info.chunksize = 0;	mddev->bitmap_info.daemon_sleep = 0;	mddev->bitmap_info.max_write_behind = 0;}",13232
312,39,CVE-2018-11469,22,"enum act_return action_http_set_status(struct act_rule *rule, struct proxy *px,                                       struct session *sess, struct stream *s, int flags){	http_set_status(rule->arg.status.code, rule->arg.status.reason, s);	return ACT_RET_CONT;}",1044
3,1135,CVE-2016-4578,22,static int snd_timer_user_stop(struct file *file){	int err;	struct snd_timer_user *tu;	tu = file->private_data;	if (!tu->timeri)		return -EBADFD;	return (err = snd_timer_stop(tu->timeri)) < 0 ? err : 0;},16723
4,76,CVE-2018-11469,22,"int http_header_match2(const char *hdr, const char *end,		       const char *name, int len){	const char *val;	if (hdr + len >= end)		return 0;	if (hdr[len] != ':')		return 0;	if (strncasecmp(hdr, name, len) != 0)		return 0;	val = hdr + len + 1;	while (val < end && HTTP_IS_SPHT(*val))		val++;	if ((val >= end) && (len + 2 <= end - hdr))		return len + 2;  	return val - hdr;}",1081
256,528,CVE-2013-3224,22,"void bt_procfs_cleanup(struct net *net, const char *name){}",8371
25,1581,CVE-2018-12436,22,int wc_ecc_get_curve_id(int curve_idx){    if (wc_ecc_is_valid_idx(curve_idx)) {        return ecc_sets[curve_idx].id;    }    return ECC_CURVE_INVALID;},25067
165,1582,CVE-2018-12436,22,int wc_ecc_get_curve_id_from_name(const char* curveName){    int curve_idx;    if (curveName == NULL)        return BAD_FUNC_ARG;    curve_idx = wc_ecc_get_curve_idx_from_name(curveName);    if (curve_idx < 0)        return curve_idx;    return ecc_sets[curve_idx].id;},25068
48,1459,CVE-2017-9150,22,"static void free_states(struct bpf_verifier_env *env){	struct bpf_verifier_state_list *sl, *sln;	int i;	if (!env->explored_states)		return;	for (i = 0; i < env->prog->len; i++) {		sl = env->explored_states[i];		if (sl)			while (sl != STATE_LIST_MARK) {				sln = sl->next;				kfree(sl);				sl = sln;			}	}	kfree(env->explored_states);}",20844
332,1482,CVE-2017-0377,22,get_guard_selection_info(void){  if (!curr_guard_context) {    create_initial_guard_context();  }  return curr_guard_context;},22245
413,673,CVE-2012-6541,22,static void ccid3_hc_rx_exit(struct sock *sk){	struct ccid3_hc_rx_sock *hc = ccid3_hc_rx_sk(sk);	tfrc_rx_hist_purge(&hc->rx_hist);	tfrc_lh_cleanup(&hc->rx_li_hist);},9860
384,1087,CVE-2016-5243,22,"static int tipc_nl_compat_doit(struct tipc_nl_compat_cmd_doit *cmd,			       struct tipc_nl_compat_msg *msg){	int err;	if (msg->req_type && !TLV_CHECK_TYPE(msg->req, msg->req_type))		return -EINVAL;	err = __tipc_nl_compat_doit(cmd, msg);	if (err)		return err;	 	msg->rep = tipc_tlv_alloc(0);	if (!msg->rep)		return -ENOMEM;	return 0;}",16495
237,1431,CVE-2017-9605,22,"static int vmw_legacy_srf_bind(struct vmw_resource *res,			       struct ttm_validate_buffer *val_buf){	if (!res->backup_dirty)		return 0;	return vmw_legacy_srf_dma(res, val_buf, true);}",20716
43,1567,CVE-2018-15594,22,void paravirt_flush_lazy_mmu(void){	preempt_disable();	if (paravirt_get_lazy_mode() == PARAVIRT_LAZY_MMU) {		arch_leave_lazy_mmu_mode();		arch_enter_lazy_mmu_mode();	}	preempt_enable();},24417
214,521,CVE-2013-3225,22,"static void rfcomm_sock_init(struct sock *sk, struct sock *parent){	struct rfcomm_pinfo *pi = rfcomm_pi(sk);	BT_DBG(""sk %p"", sk);	if (parent) {		sk->sk_type = parent->sk_type;		pi->dlc->defer_setup = test_bit(BT_SK_DEFER_SETUP,						&bt_sk(parent)->flags);		pi->sec_level = rfcomm_pi(parent)->sec_level;		pi->role_switch = rfcomm_pi(parent)->role_switch;		security_sk_clone(parent, sk);	} else {		pi->dlc->defer_setup = 0;		pi->sec_level = BT_SECURITY_LOW;		pi->role_switch = 0;	}	pi->dlc->sec_level = pi->sec_level;	pi->dlc->role_switch = pi->role_switch;}",8364
96,1566,CVE-2018-15594,22,void paravirt_enter_lazy_mmu(void){	enter_lazy(PARAVIRT_LAZY_MMU);},24416
324,247,CVE-2013-4516,22,"static int mp_get_lsr_info(struct sb_uart_state *state, unsigned int *value){	struct sb_uart_port *port = state->port;	unsigned int result;	result = port->ops->tx_empty(port);	if (port->x_char ||			((uart_circ_chars_pending(&state->info->xmit) > 0) &&				!state->info->tty->stopped && !state->info->tty->hw_stopped))		result &= ~TIOCSER_TEMT;	return put_user(result, value);}",7685
85,46,CVE-2018-11469,22,"int check_http_req_capture(struct act_rule *rule, struct proxy *px, char **err){	if (rule->action_ptr != http_action_req_capture_by_id)		return 1;	if (rule->arg.capid.idx >= px->nb_req_cap) {		memprintf(err, ""unable to find capture id '%d' referenced by http-request capture rule"",			  rule->arg.capid.idx);		return 0;	}	return 1;}",1051
29,1463,CVE-2017-9150,22,static int is_spillable_regtype(enum bpf_reg_type type){	switch (type) {	case PTR_TO_MAP_VALUE:	case PTR_TO_MAP_VALUE_OR_NULL:	case PTR_TO_MAP_VALUE_ADJ:	case PTR_TO_STACK:	case PTR_TO_CTX:	case PTR_TO_PACKET:	case PTR_TO_PACKET_END:	case FRAME_PTR:	case CONST_PTR_TO_MAP:		return true;	default:		return false;	}},20848
128,1715,CVE-2019-10638,22,"static int ip6_pkt_too_big(const struct sk_buff *skb, unsigned int mtu){	if (skb->len <= mtu)		return false;	 	if (IP6CB(skb)->frag_max_size && IP6CB(skb)->frag_max_size > mtu)		return true;	if (skb->ignore_df)		return false;	if (skb_is_gso(skb) && skb_gso_network_seglen(skb) <= mtu)		return false;	return true;}",29010
118,798,CVE-2013-7281,22,static void l2tp_ip_destroy_sock(struct sock *sk){	struct sk_buff *skb;	struct l2tp_tunnel *tunnel = l2tp_sock_to_tunnel(sk);	while ((skb = __skb_dequeue_tail(&sk->sk_write_queue)) != NULL)		kfree_skb(skb);	if (tunnel) {		l2tp_tunnel_closeall(tunnel);		sock_put(sk);	}	sk_refcnt_debug_dec(sk);},12356
273,456,CVE-2013-3229,22,"static void iucv_sever_path(struct sock *sk, int with_user_data){	unsigned char user_data[16];	struct iucv_sock *iucv = iucv_sk(sk);	struct iucv_path *path = iucv->path;	if (iucv->path) {		iucv->path = NULL;		if (with_user_data) {			low_nmcpy(user_data, iucv->src_name);			high_nmcpy(user_data, iucv->dst_name);			ASCEBC(user_data, sizeof(user_data));			pr_iucv->path_sever(path, user_data);		} else			pr_iucv->path_sever(path, NULL);		iucv_path_free(path);	}}",8299
181,510,CVE-2013-3225,22,"static void __rfcomm_sock_close(struct sock *sk){	struct rfcomm_dlc *d = rfcomm_pi(sk)->dlc;	BT_DBG(""sk %p state %d socket %p"", sk, sk->sk_state, sk->sk_socket);	switch (sk->sk_state) {	case BT_LISTEN:		rfcomm_sock_cleanup_listen(sk);		break;	case BT_CONNECT:	case BT_CONNECT2:	case BT_CONFIG:	case BT_CONNECTED:		rfcomm_dlc_close(d, 0);	default:		sock_set_flag(sk, SOCK_ZAPPED);		break;	}}",8353
401,1110,CVE-2016-4578,22,"int snd_timer_pause(struct snd_timer_instance * timeri){	if (timeri->flags & SNDRV_TIMER_IFLG_SLAVE)		return snd_timer_stop_slave(timeri, false);	else		return snd_timer_stop1(timeri, false);}",16698
41,1227,CVE-2016-2117,22,"static int atl2_sw_init(struct atl2_adapter *adapter){	struct atl2_hw *hw = &adapter->hw;	struct pci_dev *pdev = adapter->pdev;	 	hw->vendor_id = pdev->vendor;	hw->device_id = pdev->device;	hw->subsystem_vendor_id = pdev->subsystem_vendor;	hw->subsystem_id = pdev->subsystem_device;	hw->revision_id  = pdev->revision;	pci_read_config_word(pdev, PCI_COMMAND, &hw->pci_cmd_word);	adapter->wol = 0;	adapter->ict = 50000;   	adapter->link_speed = SPEED_0;    	adapter->link_duplex = FULL_DUPLEX;	hw->phy_configured = false;	hw->preamble_len = 7;	hw->ipgt = 0x60;	hw->min_ifg = 0x50;	hw->ipgr1 = 0x40;	hw->ipgr2 = 0x60;	hw->retry_buf = 2;	hw->max_retry = 0xf;	hw->lcol = 0x37;	hw->jam_ipg = 7;	hw->fc_rxd_hi = 0;	hw->fc_rxd_lo = 0;	hw->max_frame_size = adapter->netdev->mtu;	spin_lock_init(&adapter->stats_lock);	set_bit(__ATL2_DOWN, &adapter->flags);	return 0;}",17987
62,366,CVE-2013-3236,22,"static int vmci_transport_send_reset_bh(struct sockaddr_vm *dst,					struct sockaddr_vm *src,					struct vmci_transport_packet *pkt){	if (pkt->type == VMCI_TRANSPORT_PACKET_TYPE_RST)		return 0;	return vmci_transport_send_control_pkt_bh(					dst, src,					VMCI_TRANSPORT_PACKET_TYPE_RST, 0,					0, NULL, VMCI_INVALID_HANDLE);}",8209
67,973,CVE-2015-5302,22,"static int ask_continue_before_steal(const char *base_dir, const char *dump_dir){    char *msg = xasprintf(_(""Need writable directory, but '%s' is not writable.""                            "" Move it to '%s' and operate on the moved data?""),                            dump_dir, base_dir);    const int response = run_ask_yes_no_yesforever_dialog(""ask_steal_dir"", msg, GTK_WINDOW(g_wnd_assistant));    free(msg);    return response;}",13399
150,1360,CVE-2014-9903,22,"static void try_to_wake_up_local(struct task_struct *p){	struct rq *rq = task_rq(p);	if (WARN_ON_ONCE(rq != this_rq()) ||	    WARN_ON_ONCE(p == current))		return;	lockdep_assert_held(&rq->lock);	if (!raw_spin_trylock(&p->pi_lock)) {		raw_spin_unlock(&rq->lock);		raw_spin_lock(&p->pi_lock);		raw_spin_lock(&rq->lock);	}	if (!(p->state & TASK_NORMAL))		goto out;	if (!p->on_rq)		ttwu_activate(rq, p, ENQUEUE_WAKEUP);	ttwu_do_wakeup(rq, p, 0);	ttwu_stat(p, smp_processor_id(), 0);out:	raw_spin_unlock(&p->pi_lock);}",19297
411,960,CVE-2015-5697,22,"super_1_allow_new_offset(struct md_rdev *rdev,			 unsigned long long new_offset){	 	struct bitmap *bitmap;	if (new_offset >= rdev->data_offset)		return 1;	 	if (rdev->mddev->minor_version == 0)		return 1;	 	if (rdev->sb_start + (32+4)*2 > new_offset)		return 0;	bitmap = rdev->mddev->bitmap;	if (bitmap && !rdev->mddev->bitmap_info.file &&	    rdev->sb_start + rdev->mddev->bitmap_info.offset +	    bitmap->storage.file_pages * (PAGE_SIZE>>9) > new_offset)		return 0;	if (rdev->badblocks.sector + rdev->badblocks.size > new_offset)		return 0;	return 1;}",13290
207,409,CVE-2013-3232,22,"static void nr_insert_socket(struct sock *sk){	spin_lock_bh(&nr_list_lock);	sk_add_node(sk, &nr_list);	spin_unlock_bh(&nr_list_lock);}",8252
430,276,CVE-2013-4516,22,"static void multi_enable_ms(struct sb_uart_port *port){	struct mp_port *mtpt = (struct mp_port *)port;	mtpt->ier |= UART_IER_MSI;	serial_out(mtpt, UART_IER, mtpt->ier);}",7714
303,1672,CVE-2012-6545,22,"static int rfcomm_tty_write_room(struct tty_struct *tty){	struct rfcomm_dev *dev = (struct rfcomm_dev *) tty->driver_data;	int room;	BT_DBG(""tty %p"", tty);	if (!dev || !dev->dlc)		return 0;	room = rfcomm_room(dev->dlc) - atomic_read(&dev->wmem_alloc);	if (room < 0)		room = 0;	return room;}",28332
226,700,CVE-2012-6540,22,"static int ip_vs_genl_set_daemon(struct sk_buff *skb, struct genl_info *info){	int ret = 0, cmd;	struct net *net;	struct netns_ipvs *ipvs;	net = skb_sknet(skb);	ipvs = net_ipvs(net);	cmd = info->genlhdr->cmd;	if (cmd == IPVS_CMD_NEW_DAEMON || cmd == IPVS_CMD_DEL_DAEMON) {		struct nlattr *daemon_attrs[IPVS_DAEMON_ATTR_MAX + 1];		mutex_lock(&ipvs->sync_mutex);		if (!info->attrs[IPVS_CMD_ATTR_DAEMON] ||		    nla_parse_nested(daemon_attrs, IPVS_DAEMON_ATTR_MAX,				     info->attrs[IPVS_CMD_ATTR_DAEMON],				     ip_vs_daemon_policy)) {			ret = -EINVAL;			goto out;		}		if (cmd == IPVS_CMD_NEW_DAEMON)			ret = ip_vs_genl_new_daemon(net, daemon_attrs);		else			ret = ip_vs_genl_del_daemon(net, daemon_attrs);out:		mutex_unlock(&ipvs->sync_mutex);	}	return ret;}",9887
211,964,CVE-2015-5697,22,"suspend_lo_show(struct mddev *mddev, char *page){	return sprintf(page, ""%llu\n"", (unsigned long long)mddev->suspend_lo);}",13294
82,496,CVE-2013-3226,22,"static void __sco_sock_close(struct sock *sk){	BT_DBG(""sk %p state %d socket %p"", sk, sk->sk_state, sk->sk_socket);	switch (sk->sk_state) {	case BT_LISTEN:		sco_sock_cleanup_listen(sk);		break;	case BT_CONNECTED:	case BT_CONFIG:		if (sco_pi(sk)->conn->hcon) {			sk->sk_state = BT_DISCONN;			sco_sock_set_timer(sk, SCO_DISCONN_TIMEOUT);			hci_conn_put(sco_pi(sk)->conn->hcon);			sco_pi(sk)->conn->hcon = NULL;		} else			sco_chan_del(sk, ECONNRESET);		break;	case BT_CONNECT2:	case BT_CONNECT:	case BT_DISCONN:		sco_chan_del(sk, ECONNRESET);		break;	default:		sock_set_flag(sk, SOCK_ZAPPED);		break;	}}",8339
94,329,CVE-2013-3237,22,static int vsock_in_bound_table(struct vsock_sock *vsk){	int ret;	spin_lock_bh(&vsock_table_lock);	ret = __vsock_in_bound_table(vsk);	spin_unlock_bh(&vsock_table_lock);	return ret;},8172
250,1043,CVE-2016-5696,22,"static void tcp_openreq_init(struct request_sock *req,			     const struct tcp_options_received *rx_opt,			     struct sk_buff *skb, const struct sock *sk){	struct inet_request_sock *ireq = inet_rsk(req);	req->rsk_rcv_wnd = 0;		 	req->cookie_ts = 0;	tcp_rsk(req)->rcv_isn = TCP_SKB_CB(skb)->seq;	tcp_rsk(req)->rcv_nxt = TCP_SKB_CB(skb)->seq + 1;	skb_mstamp_get(&tcp_rsk(req)->snt_synack);	tcp_rsk(req)->last_oow_ack_time = 0;	req->mss = rx_opt->mss_clamp;	req->ts_recent = rx_opt->saw_tstamp ? rx_opt->rcv_tsval : 0;	ireq->tstamp_ok = rx_opt->tstamp_ok;	ireq->sack_ok = rx_opt->sack_ok;	ireq->snd_wscale = rx_opt->snd_wscale;	ireq->wscale_ok = rx_opt->wscale_ok;	ireq->acked = 0;	ireq->ecn_ok = 0;	ireq->ir_rmt_port = tcp_hdr(skb)->source;	ireq->ir_num = ntohs(tcp_hdr(skb)->dest);	ireq->ir_mark = inet_request_mark(sk, skb);}",16419
309,500,CVE-2013-3226,22,"static struct sco_conn *sco_conn_add(struct hci_conn *hcon){	struct hci_dev *hdev = hcon->hdev;	struct sco_conn *conn = hcon->sco_data;	if (conn)		return conn;	conn = kzalloc(sizeof(struct sco_conn), GFP_ATOMIC);	if (!conn)		return NULL;	spin_lock_init(&conn->lock);	hcon->sco_data = conn;	conn->hcon = hcon;	conn->src = &hdev->bdaddr;	conn->dst = &hcon->dst;	if (hdev->sco_mtu > 0)		conn->mtu = hdev->sco_mtu;	else		conn->mtu = 60;	BT_DBG(""hcon %p conn %p"", hcon, conn);	return conn;}",8343
35,801,CVE-2013-7281,22,static void pn_destruct(struct sock *sk){	skb_queue_purge(&sk->sk_receive_queue);},12359
287,361,CVE-2013-3236,22,"static int vmci_transport_send_invalid_bh(struct sockaddr_vm *dst,					  struct sockaddr_vm *src){	return vmci_transport_send_control_pkt_bh(					dst, src,					VMCI_TRANSPORT_PACKET_TYPE_INVALID,					0, 0, NULL, VMCI_INVALID_HANDLE);}",8204
435,1093,CVE-2016-5243,22,"static int tipc_nl_compat_media_dump(struct tipc_nl_compat_msg *msg,				     struct nlattr **attrs){	struct nlattr *media[TIPC_NLA_MEDIA_MAX + 1];	int err;	if (!attrs[TIPC_NLA_MEDIA])		return -EINVAL;	err = nla_parse_nested(media, TIPC_NLA_MEDIA_MAX, attrs[TIPC_NLA_MEDIA],			       NULL);	if (err)		return err;	return tipc_add_tlv(msg->rep, TIPC_TLV_MEDIA_NAME,			    nla_data(media[TIPC_NLA_MEDIA_NAME]),			    nla_len(media[TIPC_NLA_MEDIA_NAME]));}",16501
240,324,CVE-2013-3237,22,"void vsock_enqueue_accept(struct sock *listener, struct sock *connected){	struct vsock_sock *vlistener;	struct vsock_sock *vconnected;	vlistener = vsock_sk(listener);	vconnected = vsock_sk(connected);	sock_hold(connected);	sock_hold(listener);	list_add_tail(&vconnected->accept_queue, &vlistener->accept_queue);}",8167
117,333,CVE-2013-3237,22,static int vsock_is_accept_queue_empty(struct sock *sk){	struct vsock_sock *vsk = vsock_sk(sk);	return list_empty(&vsk->accept_queue);},8176
218,1766,CVE-2019-5837,22,"  void Verify_BasicFindMainResponse() {    EXPECT_EQ(kEntryUrl, delegate()->found_url_);    EXPECT_EQ(kManifestUrl, delegate()->found_manifest_url_);    EXPECT_EQ(1, delegate()->found_cache_id_);    EXPECT_EQ(2, delegate()->found_group_id_);    EXPECT_EQ(1, delegate()->found_entry_.response_id());    EXPECT_TRUE(delegate()->found_entry_.IsExplicit());    EXPECT_FALSE(delegate()->found_fallback_entry_.has_response_id());    TestFinished();  }",30178
7,1544,CVE-2018-18710,22,"static int cdrom_read_subchannel(struct cdrom_device_info *cdi,				 struct cdrom_subchnl *subchnl, int mcn){	const struct cdrom_device_ops *cdo = cdi->ops;	struct packet_command cgc;	char buffer[32];	int ret;	init_cdrom_command(&cgc, buffer, 16, CGC_DATA_READ);	cgc.cmd[0] = GPCMD_READ_SUBCHANNEL;	cgc.cmd[1] = subchnl->cdsc_format; 	cgc.cmd[2] = 0x40;   	cgc.cmd[3] = mcn ? 2 : 1;	cgc.cmd[8] = 16;	if ((ret = cdo->generic_packet(cdi, &cgc)))		return ret;	subchnl->cdsc_audiostatus = cgc.buffer[1];	subchnl->cdsc_ctrl = cgc.buffer[5] & 0xf;	subchnl->cdsc_trk = cgc.buffer[6];	subchnl->cdsc_ind = cgc.buffer[7];	if (subchnl->cdsc_format == CDROM_LBA) {		subchnl->cdsc_absaddr.lba = ((cgc.buffer[8] << 24) |						(cgc.buffer[9] << 16) |						(cgc.buffer[10] << 8) |						(cgc.buffer[11]));		subchnl->cdsc_reladdr.lba = ((cgc.buffer[12] << 24) |						(cgc.buffer[13] << 16) |						(cgc.buffer[14] << 8) |						(cgc.buffer[15]));	} else {		subchnl->cdsc_reladdr.msf.minute = cgc.buffer[13];		subchnl->cdsc_reladdr.msf.second = cgc.buffer[14];		subchnl->cdsc_reladdr.msf.frame = cgc.buffer[15];		subchnl->cdsc_absaddr.msf.minute = cgc.buffer[9];		subchnl->cdsc_absaddr.msf.second = cgc.buffer[10];		subchnl->cdsc_absaddr.msf.frame = cgc.buffer[11];	}	return 0;}",23461
317,582,CVE-2013-2061,22,"check_replay_iv_consistency (const struct key_type *kt, int packet_id, int use_iv){  if (cfb_ofb_mode (kt) && !(packet_id && use_iv))    msg (M_FATAL, ""--no-replay or --no-iv cannot be used with a CFB or OFB mode cipher"");}",8942
254,426,CVE-2013-3231,22,"static int llc_ui_send_data(struct sock* sk, struct sk_buff *skb, int noblock){	struct llc_sock* llc = llc_sk(sk);	int rc = 0;	if (unlikely(llc_data_accept_state(llc->state) ||		     llc->remote_busy_flag ||		     llc->p_flag)) {		long timeout = sock_sndtimeo(sk, noblock);		rc = llc_ui_wait_for_busy_core(sk, timeout);	}	if (unlikely(!rc))		rc = llc_build_and_send_pkt(sk, skb);	return rc;}",8269
271,945,CVE-2015-5697,22,"min_sync_show(struct mddev *mddev, char *page){	return sprintf(page, ""%llu\n"",		       (unsigned long long)mddev->resync_min);}",13275
415,1639,CVE-2018-18839,22,char from_hex(char ch) {    return (char)(isdigit(ch) ? ch - '0' : tolower(ch) - 'a' + 10);},27910
286,1060,CVE-2016-5696,22,"void tcp_skb_mark_lost_uncond_verify(struct tcp_sock *tp, struct sk_buff *skb){	tcp_verify_retransmit_hint(tp, skb);	if (!(TCP_SKB_CB(skb)->sacked & (TCPCB_LOST|TCPCB_SACKED_ACKED))) {		tp->lost_out += tcp_skb_pcount(skb);		TCP_SKB_CB(skb)->sacked |= TCPCB_LOST;	}}",16436
135,219,CVE-2011-1078,22,"static int sco_sock_connect(struct socket *sock, struct sockaddr *addr, int alen, int flags){	struct sockaddr_sco *sa = (struct sockaddr_sco *) addr;	struct sock *sk = sock->sk;	int err = 0;	BT_DBG(""sk %p"", sk);	if (alen < sizeof(struct sockaddr_sco) ||	    addr->sa_family != AF_BLUETOOTH)		return -EINVAL;	if (sk->sk_state != BT_OPEN && sk->sk_state != BT_BOUND)		return -EBADFD;	if (sk->sk_type != SOCK_SEQPACKET)		return -EINVAL;	lock_sock(sk);	 	bacpy(&bt_sk(sk)->dst, &sa->sco_bdaddr);	err = sco_connect(sk);	if (err)		goto done;	err = bt_sock_wait_state(sk, BT_CONNECTED,			sock_sndtimeo(sk, flags & O_NONBLOCK));done:	release_sock(sk);	return err;}",6951
363,1300,CVE-2014-9903,22,__checkparam_dl(const struct sched_attr *attr){	return attr && attr->sched_deadline != 0 &&		(attr->sched_period == 0 ||		(s64)(attr->sched_period   - attr->sched_deadline) >= 0) &&		(s64)(attr->sched_deadline - attr->sched_runtime ) >= 0  &&		attr->sched_runtime >= (2 << (DL_SCALE - 1));},19237
394,1363,CVE-2014-9903,22,static int wake_up_full_nohz_cpu(int cpu){	if (tick_nohz_full_cpu(cpu)) {		if (cpu != smp_processor_id() ||		    tick_nohz_tick_stopped())			smp_send_reschedule(cpu);		return true;	}	return false;},19300
76,1255,CVE-2015-8964,22,"__tty_ldisc_lock(struct tty_struct *tty, unsigned long timeout){	return ldsem_down_write(&tty->ldisc_sem, timeout);}",18294
15,1031,CVE-2016-5696,22,"static int tcp_fast_parse_options(const struct sk_buff *skb,				   const struct tcphdr *th, struct tcp_sock *tp){	 	if (th->doff == (sizeof(*th) / 4)) {		tp->rx_opt.saw_tstamp = 0;		return false;	} else if (tp->rx_opt.tstamp_ok &&		   th->doff == ((sizeof(*th) + TCPOLEN_TSTAMP_ALIGNED) / 4)) {		if (tcp_parse_aligned_timestamp(tp, th))			return true;	}	tcp_parse_options(skb, &tp->rx_opt, 1, NULL);	if (tp->rx_opt.saw_tstamp && tp->rx_opt.rcv_tsecr)		tp->rx_opt.rcv_tsecr -= tp->tsoffset;	return true;}",16407
65,1536,CVE-2018-18710,22,"static int cdrom_mrw_probe_pc(struct cdrom_device_info *cdi){	struct packet_command cgc;	char buffer[16];	init_cdrom_command(&cgc, buffer, sizeof(buffer), CGC_DATA_READ);	cgc.timeout = HZ;	cgc.quiet = 1;	if (!cdrom_mode_sense(cdi, &cgc, MRW_MODE_PC, 0)) {		cdi->mrw_mode_page = MRW_MODE_PC;		return 0;	} else if (!cdrom_mode_sense(cdi, &cgc, MRW_MODE_PC_PRE1, 0)) {		cdi->mrw_mode_page = MRW_MODE_PC_PRE1;		return 0;	}	return 1;}",23453
336,10,CVE-2015-5330,22,"static int close_iconv_handle(struct smb_iconv_handle *data){	unsigned c1, c2;	for (c1=0;c1<NUM_CHARSETS;c1++) {		for (c2=0;c2<NUM_CHARSETS;c2++) {			if (data->conv_handles[c1][c2] != NULL) {				if (data->conv_handles[c1][c2] != (smb_iconv_t)-1) {					smb_iconv_close(data->conv_handles[c1][c2]);				}				data->conv_handles[c1][c2] = NULL;			}		}	}	return 0;}",453
190,637,CVE-2013-0349,22,"static void hidp_recv_ctrl_frame(struct hidp_session *session,					struct sk_buff *skb){	unsigned char hdr, type, param;	int free_skb = 1;	BT_DBG(""session %p skb %p len %d"", session, skb, skb->len);	hdr = skb->data[0];	skb_pull(skb, 1);	type = hdr & HIDP_HEADER_TRANS_MASK;	param = hdr & HIDP_HEADER_PARAM_MASK;	switch (type) {	case HIDP_TRANS_HANDSHAKE:		hidp_process_handshake(session, param);		break;	case HIDP_TRANS_HID_CONTROL:		hidp_process_hid_control(session, param);		break;	case HIDP_TRANS_DATA:		free_skb = hidp_process_data(session, skb, param);		break;	default:		__hidp_send_ctrl_message(session,			HIDP_TRANS_HANDSHAKE | HIDP_HSHK_ERR_UNSUPPORTED_REQUEST, NULL, 0);		break;	}	if (free_skb)		kfree_skb(skb);}",9710
38,359,CVE-2013-3236,22,"static int vmci_transport_reply_reset(struct vmci_transport_packet *pkt){	return vmci_transport_reply_control_pkt_fast(						pkt,						VMCI_TRANSPORT_PACKET_TYPE_RST,						0, 0, NULL,						VMCI_INVALID_HANDLE);}",8202
448,1115,CVE-2016-4578,22,"static void snd_timer_s_function(unsigned long data){	struct snd_timer *timer = (struct snd_timer *)data;	struct snd_timer_system_private *priv = timer->private_data;	unsigned long jiff = jiffies;	if (time_after(jiff, priv->last_expires))		priv->correction += (long)jiff - (long)priv->last_expires;	snd_timer_interrupt(timer, (long)jiff - (long)priv->last_jiffies);}",16703
184,1519,CVE-2018-18710,22,"static int cdrom_ioctl_eject(struct cdrom_device_info *cdi){	cd_dbg(CD_DO_IOCTL, ""entering CDROMEJECT\n"");	if (!CDROM_CAN(CDC_OPEN_TRAY))		return -ENOSYS;	if (cdi->use_count != 1 || cdi->keeplocked)		return -EBUSY;	if (CDROM_CAN(CDC_LOCK)) {		int ret = cdi->ops->lock_door(cdi, 0);		if (ret)			return ret;	}	return cdi->ops->tray_move(cdi, 1);}",23436
378,943,CVE-2015-5697,22,"void mddev_unlock(struct mddev *mddev){	if (mddev->to_remove) {		 		struct attribute_group *to_remove = mddev->to_remove;		mddev->to_remove = NULL;		mddev->sysfs_active = 1;		mutex_unlock(&mddev->reconfig_mutex);		if (mddev->kobj.sd) {			if (to_remove != &md_redundancy_group)				sysfs_remove_group(&mddev->kobj, to_remove);			if (mddev->pers == NULL ||			    mddev->pers->sync_request == NULL) {				sysfs_remove_group(&mddev->kobj, &md_redundancy_group);				if (mddev->sysfs_action)					sysfs_put(mddev->sysfs_action);				mddev->sysfs_action = NULL;			}		}		mddev->sysfs_active = 0;	} else		mutex_unlock(&mddev->reconfig_mutex);	 	spin_lock(&pers_lock);	md_wakeup_thread(mddev->thread);	spin_unlock(&pers_lock);}",13273
269,166,CVE-2016-5337,22,"static int megasas_fw_time(void){    struct tm curtime;    int bcd_time;    qemu_get_timedate(&curtime, 0);    bcd_time = ((int)curtime.tm_sec & 0xff) << 48 |        ((int)curtime.tm_min & 0xff)  << 40 |        ((int)curtime.tm_hour & 0xff) << 32 |        ((int)curtime.tm_mday & 0xff) << 24 |        ((int)curtime.tm_mon & 0xff)  << 16 |        ((int)(curtime.tm_year + 1900) & 0xffff);    return bcd_time;}",1845
233,163,CVE-2016-6836,22,"static void vmxnet3_validate_interrupt_idx(int is_msix, int idx){    int max_ints = is_msix ? VMXNET3_MAX_INTRS : VMXNET3_MAX_NMSIX_INTRS;    if (idx >= max_ints) {        hw_error(""Bad interrupt index: %d\n"", idx);    }}",1546
20,1613,CVE-2019-10639,22,"static int register_pernet_operations(struct list_head *list,				      struct pernet_operations *ops){	int error;	if (ops->id) {		error = ida_alloc_min(&net_generic_ids, MIN_PERNET_OPS_ID,				GFP_KERNEL);		if (error < 0)			return error;		*ops->id = error;		max_gen_ptrs = max(max_gen_ptrs, *ops->id + 1);	}	error = __register_pernet_operations(list, ops);	if (error) {		rcu_barrier();		if (ops->id)			ida_free(&net_generic_ids, *ops->id);	}	return error;}",27180
425,624,CVE-2013-0349,22,"static int hidp_hidinput_event(struct input_dev *dev, unsigned int type, unsigned int code, int value){	struct hid_device *hid = input_get_drvdata(dev);	struct hidp_session *session = hid->driver_data;	return hidp_queue_event(session, dev, type, code, value);}",9697
344,1538,CVE-2018-18710,22,"int cdrom_number_of_slots(struct cdrom_device_info *cdi) {	int status;	int nslots = 1;	struct cdrom_changer_info *info;	cd_dbg(CD_CHANGER, ""entering cdrom_number_of_slots()\n"");	 	cdi->capacity = 0; 	info = kmalloc(sizeof(*info), GFP_KERNEL);	if (!info)		return -ENOMEM;	if ((status = cdrom_read_mech_status(cdi, info)) == 0)		nslots = info->hdr.nslots;	kfree(info);	return nslots;}",23455
114,476,CVE-2013-3228,22,"static int irda_connect(struct socket *sock, struct sockaddr *uaddr,			int addr_len, int flags){	struct sock *sk = sock->sk;	struct sockaddr_irda *addr = (struct sockaddr_irda *) uaddr;	struct irda_sock *self = irda_sk(sk);	int err;	IRDA_DEBUG(2, ""%s(%p)\n"", __func__, self);	lock_sock(sk);	 	err = -ESOCKTNOSUPPORT;	if ((sk->sk_type == SOCK_DGRAM) && (sk->sk_protocol == IRDAPROTO_ULTRA))		goto out;	if (sk->sk_state == TCP_ESTABLISHED && sock->state == SS_CONNECTING) {		sock->state = SS_CONNECTED;		err = 0;		goto out;    	}	if (sk->sk_state == TCP_CLOSE && sock->state == SS_CONNECTING) {		sock->state = SS_UNCONNECTED;		err = -ECONNREFUSED;		goto out;	}	err = -EISCONN;       	if (sk->sk_state == TCP_ESTABLISHED)		goto out;	sk->sk_state   = TCP_CLOSE;	sock->state = SS_UNCONNECTED;	err = -EINVAL;	if (addr_len != sizeof(struct sockaddr_irda))		goto out;	 	if ((!addr->sir_addr) || (addr->sir_addr == DEV_ADDR_ANY)) {		 		err = irda_discover_daddr_and_lsap_sel(self, addr->sir_name);		if (err) {			IRDA_DEBUG(0, ""%s(), auto-connect failed!\n"", __func__);			goto out;		}	} else {		 		self->daddr = addr->sir_addr;		IRDA_DEBUG(1, ""%s(), daddr = %08x\n"", __func__, self->daddr);		 		if((addr->sir_name[0] != '\0') ||		   (addr->sir_lsap_sel >= 0x70)) {			 			err = irda_find_lsap_sel(self, addr->sir_name);			if (err) {				IRDA_DEBUG(0, ""%s(), connect failed!\n"", __func__);				goto out;			}		} else {			 			self->dtsap_sel = addr->sir_lsap_sel;		}	}	 	if (!self->tsap)		irda_open_tsap(self, LSAP_ANY, addr->sir_name);	 	sock->state = SS_CONNECTING;	sk->sk_state   = TCP_SYN_SENT;	 	err = irttp_connect_request(self->tsap, self->dtsap_sel,				    self->saddr, self->daddr, NULL,				    self->max_sdu_size_rx, NULL);	if (err) {		IRDA_DEBUG(0, ""%s(), connect failed!\n"", __func__);		goto out;	}	 	err = -EINPROGRESS;	if (sk->sk_state != TCP_ESTABLISHED && (flags & O_NONBLOCK))		goto out;	err = -ERESTARTSYS;	if (wait_event_interruptible(*(sk_sleep(sk)),				     (sk->sk_state != TCP_SYN_SENT)))		goto out;	if (sk->sk_state != TCP_ESTABLISHED) {		sock->state = SS_UNCONNECTED;		if (sk->sk_prot->disconnect(sk, flags))			sock->state = SS_DISCONNECTING;		err = sock_error(sk);		if (!err)			err = -ECONNRESET;		goto out;	}	sock->state = SS_CONNECTED;	 	self->saddr = irttp_get_saddr(self->tsap);	err = 0;out:	release_sock(sk);	return err;}",8319
178,429,CVE-2013-3231,22,"static int llc_ui_wait_for_busy_core(struct sock *sk, long timeout){	DEFINE_WAIT(wait);	struct llc_sock *llc = llc_sk(sk);	int rc;	while (1) {		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);		rc = 0;		if (sk_wait_event(sk, &timeout,				  (sk->sk_shutdown & RCV_SHUTDOWN) ||				  (!llc_data_accept_state(llc->state) &&				   !llc->remote_busy_flag &&				   !llc->p_flag)))			break;		rc = -ERESTARTSYS;		if (signal_pending(current))			break;		rc = -EAGAIN;		if (!timeout)			break;	}	finish_wait(sk_sleep(sk), &wait);	return rc;}",8272
337,625,CVE-2013-0349,22,static void hidp_idle_timeout(unsigned long arg){	struct hidp_session *session = (struct hidp_session *) arg;	atomic_inc(&session->terminate);	wake_up_process(session->task);},9698
123,1605,CVE-2019-11833,22,"int ext4_ext_precache(struct inode *inode){	struct ext4_inode_info *ei = EXT4_I(inode);	struct ext4_ext_path *path = NULL;	struct buffer_head *bh;	int i = 0, depth, ret = 0;	if (!ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))		return 0;	 	down_read(&ei->i_data_sem);	depth = ext_depth(inode);	path = kcalloc(depth + 1, sizeof(struct ext4_ext_path),		       GFP_NOFS);	if (path == NULL) {		up_read(&ei->i_data_sem);		return -ENOMEM;	}	 	if (depth == 0)		goto out;	path[0].p_hdr = ext_inode_hdr(inode);	ret = ext4_ext_check(inode, path[0].p_hdr, depth, 0);	if (ret)		goto out;	path[0].p_idx = EXT_FIRST_INDEX(path[0].p_hdr);	while (i >= 0) {		 		if ((i == depth) ||		    path[i].p_idx > EXT_LAST_INDEX(path[i].p_hdr)) {			brelse(path[i].p_bh);			path[i].p_bh = NULL;			i--;			continue;		}		bh = read_extent_tree_block(inode,					    ext4_idx_pblock(path[i].p_idx++),					    depth - i - 1,					    EXT4_EX_FORCE_CACHE);		if (IS_ERR(bh)) {			ret = PTR_ERR(bh);			break;		}		i++;		path[i].p_bh = bh;		path[i].p_hdr = ext_block_hdr(bh);		path[i].p_idx = EXT_FIRST_INDEX(path[i].p_hdr);	}	ext4_set_inode_state(inode, EXT4_STATE_EXT_PRECACHED);out:	up_read(&ei->i_data_sem);	ext4_ext_drop_refs(path);	kfree(path);	return ret;}",26917
8,1763,CVE-2019-5837,22,  void TestFinishedUnwound() {    TearDownTest();    test_finished_event_->Signal();  },30175
284,1427,CVE-2017-10911,22,"static unsigned int xen_blkbk_unmap_prepare(	struct xen_blkif_ring *ring,	struct grant_page **pages,	unsigned int num,	struct gnttab_unmap_grant_ref *unmap_ops,	struct page **unmap_pages){	unsigned int i, invcount = 0;	for (i = 0; i < num; i++) {		if (pages[i]->persistent_gnt != NULL) {			put_persistent_gnt(ring, pages[i]->persistent_gnt);			continue;		}		if (pages[i]->handle == BLKBACK_INVALID_HANDLE)			continue;		unmap_pages[invcount] = pages[i]->page;		gnttab_set_unmap_op(&unmap_ops[invcount], vaddr(pages[i]->page),				    GNTMAP_host_map, pages[i]->handle);		pages[i]->handle = BLKBACK_INVALID_HANDLE;		invcount++;       }       return invcount;}",20599
158,210,CVE-2011-1078,22,static inline struct sock *sco_chan_get(struct sco_conn *conn){	struct sock *sk = NULL;	sco_conn_lock(conn);	sk = conn->sk;	sco_conn_unlock(conn);	return sk;},6942
106,275,CVE-2013-4516,22,"static void multi_config_port(struct sb_uart_port *port, int flags){	struct mp_port *mtpt = (struct mp_port *)port;	int probeflags = PROBE_ANY;	if (flags & UART_CONFIG_TYPE)		autoconfig(mtpt, probeflags);	if (mtpt->port.type != PORT_UNKNOWN && flags & UART_CONFIG_IRQ)		autoconfig_irq(mtpt);	if (mtpt->port.type == PORT_UNKNOWN)		multi_release_std_resource(mtpt);}",7713
171,345,CVE-2013-3236,22,"static int vmci_transport_connect(struct vsock_sock *vsk){	int err;	int old_pkt_proto = false;	struct sock *sk = &vsk->sk;	if (vmci_transport_old_proto_override(&old_pkt_proto) &&		old_pkt_proto) {		err = vmci_transport_send_conn_request(			sk, vmci_trans(vsk)->queue_pair_size);		if (err < 0) {			sk->sk_state = SS_UNCONNECTED;			return err;		}	} else {		int supported_proto_versions =			vmci_transport_new_proto_supported_versions();		err = vmci_transport_send_conn_request2(				sk, vmci_trans(vsk)->queue_pair_size,				supported_proto_versions);		if (err < 0) {			sk->sk_state = SS_UNCONNECTED;			return err;		}		vsk->sent_request = true;	}	return err;}",8188
315,1732,CVE-2018-6035,22,     AllowAllExtensionLocationsInPublicSessionForTesting(int value) {  g_allow_all_extension_locations_in_public_session = value;},30071
162,1688,CVE-2012-6544,22,"static void l2cap_sock_state_change_cb(struct l2cap_chan *chan, int state){	struct sock *sk = chan->data;	sk->sk_state = state;}",28348
120,1288,CVE-2015-8575,22,"static void sco_conn_del(struct hci_conn *hcon, int err){	struct sco_conn *conn = hcon->sco_data;	struct sock *sk;	if (!conn)		return;	BT_DBG(""hcon %p conn %p, err %d"", hcon, conn, err);	 	sco_conn_lock(conn);	sk = conn->sk;	sco_conn_unlock(conn);	if (sk) {		sock_hold(sk);		bh_lock_sock(sk);		sco_sock_clear_timer(sk);		sco_chan_del(sk, err);		bh_unlock_sock(sk);		sco_sock_kill(sk);		sock_put(sk);	}	hcon->sco_data = NULL;	kfree(conn);}",18924
257,300,CVE-2013-4516,22,"static int set_deep_fifo(struct sb_uart_port *port, int status){	int afr_status = 0;	afr_status = sb1054_get_register(port, PAGE_4, SB105X_AFR);	if(status == ENABLE)	{		afr_status |= SB105X_AFR_AFEN;	}	else	{		afr_status &= ~SB105X_AFR_AFEN;	}			sb1054_set_register(port,PAGE_4,SB105X_AFR,afr_status);	sb1054_set_register(port,PAGE_4,SB105X_TTR,ttr[port->line]); 	sb1054_set_register(port,PAGE_4,SB105X_RTR,rtr[port->line]); 	afr_status = sb1054_get_register(port, PAGE_4, SB105X_AFR);			return afr_status;}",7738
137,1081,CVE-2016-5243,22,"int tipc_netlink_compat_start(void){	int res;	res = genl_register_family_with_ops(&tipc_genl_compat_family,					    tipc_genl_compat_ops);	if (res) {		pr_err(""Failed to register legacy compat interface\n"");		return res;	}	return 0;}",16489
299,514,CVE-2013-3225,22,"static int rfcomm_sock_bind(struct socket *sock, struct sockaddr *addr, int addr_len){	struct sockaddr_rc *sa = (struct sockaddr_rc *) addr;	struct sock *sk = sock->sk;	int err = 0;	BT_DBG(""sk %p %pMR"", sk, &sa->rc_bdaddr);	if (!addr || addr->sa_family != AF_BLUETOOTH)		return -EINVAL;	lock_sock(sk);	if (sk->sk_state != BT_OPEN) {		err = -EBADFD;		goto done;	}	if (sk->sk_type != SOCK_STREAM) {		err = -EINVAL;		goto done;	}	write_lock(&rfcomm_sk_list.lock);	if (sa->rc_channel && __rfcomm_get_sock_by_addr(sa->rc_channel, &sa->rc_bdaddr)) {		err = -EADDRINUSE;	} else {		 		bacpy(&bt_sk(sk)->src, &sa->rc_bdaddr);		rfcomm_pi(sk)->channel = sa->rc_channel;		sk->sk_state = BT_BOUND;	}	write_unlock(&rfcomm_sk_list.lock);done:	release_sock(sk);	return err;}",8357
307,592,CVE-2013-2061,22,"key_direction_state_init (struct key_direction_state *kds, int key_direction){  CLEAR (*kds);  switch (key_direction)    {    case KEY_DIRECTION_NORMAL:      kds->out_key = 0;      kds->in_key = 1;      kds->need_keys = 2;      break;    case KEY_DIRECTION_INVERSE:      kds->out_key = 1;      kds->in_key = 0;      kds->need_keys = 2;      break;    case KEY_DIRECTION_BIDIRECTIONAL:      kds->out_key = 0;      kds->in_key = 0;      kds->need_keys = 1;      break;    default:      ASSERT (0);    }}",8952
75,1712,CVE-2019-10638,22,"static int ip6_finish_output(struct sk_buff *skb){	if ((skb->len > ip6_skb_dst_mtu(skb) && !skb_is_gso(skb)) ||	    dst_allfrag(skb_dst(skb)) ||	    (IP6CB(skb)->frag_max_size && skb->len > IP6CB(skb)->frag_max_size))		return ip6_fragment(skb, ip6_finish_output2);	else		return ip6_finish_output2(skb);}",29007
390,1101,CVE-2016-4580,22,"int x25_parse_facilities(struct sk_buff *skb, struct x25_facilities *facilities,		struct x25_dte_facilities *dte_facs, unsigned long *vc_fac_mask){	unsigned char *p;	unsigned int len;	*vc_fac_mask = 0;	 	dte_facs->calling_len = 0;	dte_facs->called_len = 0;	memset(dte_facs->called_ae, '\0', sizeof(dte_facs->called_ae));	memset(dte_facs->calling_ae, '\0', sizeof(dte_facs->calling_ae));	if (!pskb_may_pull(skb, 1))		return 0;	len = skb->data[0];	if (!pskb_may_pull(skb, 1 + len))		return -1;	p = skb->data + 1;	while (len > 0) {		switch (*p & X25_FAC_CLASS_MASK) {		case X25_FAC_CLASS_A:			if (len < 2)				return -1;			switch (*p) {			case X25_FAC_REVERSE:				if((p[1] & 0x81) == 0x81) {					facilities->reverse = p[1] & 0x81;					*vc_fac_mask |= X25_MASK_REVERSE;					break;				}				if((p[1] & 0x01) == 0x01) {					facilities->reverse = p[1] & 0x01;					*vc_fac_mask |= X25_MASK_REVERSE;					break;				}				if((p[1] & 0x80) == 0x80) {					facilities->reverse = p[1] & 0x80;					*vc_fac_mask |= X25_MASK_REVERSE;					break;				}				if(p[1] == 0x00) {					facilities->reverse						= X25_DEFAULT_REVERSE;					*vc_fac_mask |= X25_MASK_REVERSE;					break;				}			case X25_FAC_THROUGHPUT:				facilities->throughput = p[1];				*vc_fac_mask |= X25_MASK_THROUGHPUT;				break;			case X25_MARKER:				break;			default:				pr_debug(""unknown facility ""				       ""%02X, value %02X\n"",				       p[0], p[1]);				break;			}			p   += 2;			len -= 2;			break;		case X25_FAC_CLASS_B:			if (len < 3)				return -1;			switch (*p) {			case X25_FAC_PACKET_SIZE:				facilities->pacsize_in  = p[1];				facilities->pacsize_out = p[2];				*vc_fac_mask |= X25_MASK_PACKET_SIZE;				break;			case X25_FAC_WINDOW_SIZE:				facilities->winsize_in  = p[1];				facilities->winsize_out = p[2];				*vc_fac_mask |= X25_MASK_WINDOW_SIZE;				break;			default:				pr_debug(""unknown facility ""				       ""%02X, values %02X, %02X\n"",				       p[0], p[1], p[2]);				break;			}			p   += 3;			len -= 3;			break;		case X25_FAC_CLASS_C:			if (len < 4)				return -1;			pr_debug(""unknown facility %02X, ""			       ""values %02X, %02X, %02X\n"",			       p[0], p[1], p[2], p[3]);			p   += 4;			len -= 4;			break;		case X25_FAC_CLASS_D:			if (len < p[1] + 2)				return -1;			switch (*p) {			case X25_FAC_CALLING_AE:				if (p[1] > X25_MAX_DTE_FACIL_LEN || p[1] <= 1)					return -1;				if (p[2] > X25_MAX_AE_LEN)					return -1;				dte_facs->calling_len = p[2];				memcpy(dte_facs->calling_ae, &p[3], p[1] - 1);				*vc_fac_mask |= X25_MASK_CALLING_AE;				break;			case X25_FAC_CALLED_AE:				if (p[1] > X25_MAX_DTE_FACIL_LEN || p[1] <= 1)					return -1;				if (p[2] > X25_MAX_AE_LEN)					return -1;				dte_facs->called_len = p[2];				memcpy(dte_facs->called_ae, &p[3], p[1] - 1);				*vc_fac_mask |= X25_MASK_CALLED_AE;				break;			default:				pr_debug(""unknown facility %02X,""					""length %d\n"", p[0], p[1]);				break;			}			len -= p[1] + 2;			p += p[1] + 2;			break;		}	}	return p - skb->data;}",16689
426,1316,CVE-2014-9903,22,"static void dequeue_task(struct rq *rq, struct task_struct *p, int flags){	update_rq_clock(rq);	sched_info_dequeued(rq, p);	p->sched_class->dequeue_task(rq, p, flags);}",19253
213,1800,CVE-2013-2061,22,"openvpn_decrypt (struct buffer *buf, struct buffer work,		 const struct crypto_options *opt,		 const struct frame* frame){  static const char error_prefix[] = ""Authenticate/Decrypt packet error"";  struct gc_arena gc;  gc_init (&gc);  if (buf->len > 0 && opt->key_ctx_bi)    {      struct key_ctx *ctx = &opt->key_ctx_bi->decrypt;      struct packet_id_net pin;      int have_pin = false;             if (ctx->hmac)	{	  int hmac_len;	  int local_hmac[MAX_HMAC_KEY_LENGTH];  	  hmac_ctx_reset(ctx->hmac);	   	  hmac_len = hmac_ctx_size (ctx->hmac);	   	  if (buf->len < hmac_len)	    CRYPT_ERROR (""missing authentication info"");	  hmac_ctx_update (ctx->hmac, BPTR (buf) + hmac_len, BLEN (buf) - hmac_len); 	  hmac_ctx_final (ctx->hmac, local_hmac);  	   	  if (memcmp (local_hmac, BPTR (buf), hmac_len)) 	    CRYPT_ERROR (""packet HMAC authentication failed"");  	  ASSERT (buf_advance (buf, hmac_len));	}             if (ctx->cipher)	{	  const unsigned int mode = cipher_ctx_mode (ctx->cipher);	  const int iv_size = cipher_ctx_iv_length (ctx->cipher);	  int iv_buf[OPENVPN_MAX_IV_LENGTH];	  int outlen;	   	  ASSERT (buf_init (&work, FRAME_HEADROOM_ADJ (frame, FRAME_HEADROOM_MARKER_DECRYPT)));	   	  CLEAR (iv_buf);	  if (opt->flags & CO_USE_IV)	    {	      if (buf->len < iv_size)		CRYPT_ERROR (""missing IV info"");	      memcpy (iv_buf, BPTR (buf), iv_size);	      ASSERT (buf_advance (buf, iv_size));	    }	   	  if (opt->flags & CO_USE_IV)	    dmsg (D_PACKET_CONTENT, ""DECRYPT IV: %s"", format_hex (iv_buf, iv_size, 0, &gc));	  if (buf->len < 1)	    CRYPT_ERROR (""missing payload"");	   	  if (!cipher_ctx_reset (ctx->cipher, iv_buf))	    CRYPT_ERROR (""cipher init failed"");	   	  if (!buf_safe (&work, buf->len))	    CRYPT_ERROR (""buffer overflow"");	   	  if (!cipher_ctx_update (ctx->cipher, BPTR (&work), &outlen, BPTR (buf), BLEN (buf)))	    CRYPT_ERROR (""cipher update failed"");	  work.len += outlen;	   	  if (!cipher_ctx_final (ctx->cipher, BPTR (&work) + outlen, &outlen))	    CRYPT_ERROR (""cipher final failed"");	  work.len += outlen;	  dmsg (D_PACKET_CONTENT, ""DECRYPT TO: %s"",	       format_hex (BPTR (&work), BLEN (&work), 80, &gc));	   	  {	    if (mode == OPENVPN_MODE_CBC)	      {		if (opt->packet_id)		  {		    if (!packet_id_read (&pin, &work, BOOL_CAST (opt->flags & CO_PACKET_ID_LONG_FORM)))		      CRYPT_ERROR (""error reading CBC packet-id"");		    have_pin = true;		  }	      }	    else if (mode == OPENVPN_MODE_CFB || mode == OPENVPN_MODE_OFB)	      {		struct buffer b;		ASSERT (opt->flags & CO_USE_IV);     		ASSERT (opt->packet_id);  		buf_set_read (&b, iv_buf, iv_size);		if (!packet_id_read (&pin, &b, true))		  CRYPT_ERROR (""error reading CFB/OFB packet-id"");		have_pin = true;	      }	    else  	      {		ASSERT (0);	      }	  }	}      else	{	  work = *buf;	  if (opt->packet_id)	    {	      if (!packet_id_read (&pin, &work, BOOL_CAST (opt->flags & CO_PACKET_ID_LONG_FORM)))		CRYPT_ERROR (""error reading packet-id"");	      have_pin = !BOOL_CAST (opt->flags & CO_IGNORE_PACKET_ID);	    }	}            if (have_pin)	{	  packet_id_reap_test (&opt->packet_id->rec);	  if (packet_id_test (&opt->packet_id->rec, &pin))	    {	      packet_id_add (&opt->packet_id->rec, &pin);	      if (opt->pid_persist && (opt->flags & CO_PACKET_ID_LONG_FORM))		packet_id_persist_save_obj (opt->pid_persist, opt->packet_id);	    }	  else	    {	      if (!(opt->flags & CO_MUTE_REPLAY_WARNINGS))	      msg (D_REPLAY_ERRORS, ""%s: bad packet ID (may be a replay): %s -- see the man page entry for --no-replay and --replay-window for more info or silence this warning with --mute-replay-warnings"",		   error_prefix, packet_id_net_print (&pin, true, &gc));	      goto error_exit;	    }	}      *buf = work;    }  gc_free (&gc);  return true; error_exit:  crypto_clear_error();  buf->len = 0;  gc_free (&gc);  return false;}",31079
66,425,CVE-2013-3231,22,"static int llc_ui_release(struct socket *sock){	struct sock *sk = sock->sk;	struct llc_sock *llc;	if (unlikely(sk == NULL))		goto out;	sock_hold(sk);	lock_sock(sk);	llc = llc_sk(sk);	dprintk(""%s: closing local(%02X) remote(%02X)\n"", __func__,		llc->laddr.lsap, llc->daddr.lsap);	if (!llc_send_disc(sk))		llc_ui_wait_for_disc(sk, sk->sk_rcvtimeo);	if (!sock_flag(sk, SOCK_ZAPPED))		llc_sap_remove_socket(llc->sap, sk);	release_sock(sk);	if (llc->dev)		dev_put(llc->dev);	sock_put(sk);	llc_sk_free(sk);out:	return 0;}",8268
1,239,CVE-2013-4516,22,"static void mp_change_pm(struct sb_uart_state *state, int pm_state){	struct sb_uart_port *port = state->port;	if (port->ops->pm)		port->ops->pm(port, pm_state, state->pm_state);	state->pm_state = pm_state;}",7677
167,365,CVE-2013-3236,22,"static int vmci_transport_send_reset(struct sock *sk,				     struct vmci_transport_packet *pkt){	if (pkt->type == VMCI_TRANSPORT_PACKET_TYPE_RST)		return 0;	return vmci_transport_send_control_pkt(sk,					VMCI_TRANSPORT_PACKET_TYPE_RST,					0, 0, NULL, VSOCK_PROTO_INVALID,					VMCI_INVALID_HANDLE);}",8208
12,1725,CVE-2012-2891,22,  PrintPreviewUIUnitTest() {},29202
342,668,CVE-2012-6544,22,"static int hci_sock_create(struct net *net, struct socket *sock, int protocol,			   int kern){	struct sock *sk;	BT_DBG(""sock %p"", sock);	if (sock->type != SOCK_RAW)		return -ESOCKTNOSUPPORT;	sock->ops = &hci_sock_ops;	sk = sk_alloc(net, PF_BLUETOOTH, GFP_ATOMIC, &hci_sk_proto);	if (!sk)		return -ENOMEM;	sock_init_data(sock, sk);	sock_reset_flag(sk, SOCK_ZAPPED);	sk->sk_protocol = protocol;	sock->state = SS_UNCONNECTED;	sk->sk_state = BT_OPEN;	bt_sock_link(&hci_sk_list, sk);	return 0;}",9855
231,1615,CVE-2019-10639,22,"static int rtnl_net_dumpid(struct sk_buff *skb, struct netlink_callback *cb){	struct rtnl_net_dump_cb net_cb = {		.tgt_net = sock_net(skb->sk),		.skb = skb,		.fillargs = {			.portid = NETLINK_CB(cb->skb).portid,			.seq = cb->nlh->nlmsg_seq,			.flags = NLM_F_MULTI,			.cmd = RTM_NEWNSID,		},		.idx = 0,		.s_idx = cb->args[0],	};	int err = 0;	if (cb->strict_check) {		err = rtnl_valid_dump_net_req(cb->nlh, skb->sk, &net_cb, cb);		if (err < 0)			goto end;	}	spin_lock_bh(&net_cb.tgt_net->nsid_lock);	if (net_cb.fillargs.add_ref &&	    !net_eq(net_cb.ref_net, net_cb.tgt_net) &&	    !spin_trylock_bh(&net_cb.ref_net->nsid_lock)) {		spin_unlock_bh(&net_cb.tgt_net->nsid_lock);		err = -EAGAIN;		goto end;	}	idr_for_each(&net_cb.tgt_net->netns_ids, rtnl_net_dumpid_one, &net_cb);	if (net_cb.fillargs.add_ref &&	    !net_eq(net_cb.ref_net, net_cb.tgt_net))		spin_unlock_bh(&net_cb.ref_net->nsid_lock);	spin_unlock_bh(&net_cb.tgt_net->nsid_lock);	cb->args[0] = net_cb.idx;end:	if (net_cb.fillargs.add_ref)		put_net(net_cb.tgt_net);	return err < 0 ? err : skb->len;}",27182
311,1362,CVE-2014-9903,22,"static int ttwu_remote(struct task_struct *p, int wake_flags){	struct rq *rq;	int ret = 0;	rq = __task_rq_lock(p);	if (p->on_rq) {		 		update_rq_clock(rq);		ttwu_do_wakeup(rq, p, wake_flags);		ret = 1;	}	__task_rq_unlock(rq);	return ret;}",19299
185,707,CVE-2012-6540,22,"static int ip_vs_svc_hash(struct ip_vs_service *svc){	unsigned int hash;	if (svc->flags & IP_VS_SVC_F_HASHED) {		pr_err(""%s(): request for already hashed, called from %pF\n"",		       __func__, __builtin_return_address(0));		return 0;	}	if (svc->fwmark == 0) {		 		hash = ip_vs_svc_hashkey(svc->net, svc->af, svc->protocol,					 &svc->addr, svc->port);		list_add(&svc->s_list, &ip_vs_svc_table[hash]);	} else {		 		hash = ip_vs_svc_fwm_hashkey(svc->net, svc->fwmark);		list_add(&svc->f_list, &ip_vs_svc_fwm_table[hash]);	}	svc->flags |= IP_VS_SVC_F_HASHED;	 	atomic_inc(&svc->refcnt);	return 1;}",9894
180,413,CVE-2013-3232,22,static void nr_remove_socket(struct sock *sk){	spin_lock_bh(&nr_list_lock);	sk_del_node_init(sk);	spin_unlock_bh(&nr_list_lock);},8256
266,105,CVE-2018-11469,22,"enum act_parse_ret parse_http_req_capture(const char **args, int *orig_arg, struct proxy *px,                                          struct act_rule *rule, char **err){	struct sample_expr *expr;	struct cap_hdr *hdr;	int cur_arg;	int len = 0;	for (cur_arg = *orig_arg; cur_arg < *orig_arg + 3 && *args[cur_arg]; cur_arg++)		if (strcmp(args[cur_arg], ""if"") == 0 ||		    strcmp(args[cur_arg], ""unless"") == 0)			break;	if (cur_arg < *orig_arg + 3) {		memprintf(err, ""expects <expression> [ 'len' <length> | id <idx> ]"");		return ACT_RET_PRS_ERR;	}	cur_arg = *orig_arg;	expr = sample_parse_expr((char **)args, &cur_arg, px->conf.args.file, px->conf.args.line, err, &px->conf.args);	if (!expr)		return ACT_RET_PRS_ERR;	if (!(expr->fetch->val & SMP_VAL_FE_HRQ_HDR)) {		memprintf(err,			  ""fetch method '%s' extracts information from '%s', none of which is available here"",			  args[cur_arg-1], sample_src_names(expr->fetch->use));		free(expr);		return ACT_RET_PRS_ERR;	}	if (!args[cur_arg] || !*args[cur_arg]) {		memprintf(err, ""expects 'len or 'id'"");		free(expr);		return ACT_RET_PRS_ERR;	}	if (strcmp(args[cur_arg], ""len"") == 0) {		cur_arg++;		if (!(px->cap & PR_CAP_FE)) {			memprintf(err, ""proxy '%s' has no frontend capability"", px->id);			return ACT_RET_PRS_ERR;		}		px->conf.args.ctx = ARGC_CAP;		if (!args[cur_arg]) {			memprintf(err, ""missing length value"");			free(expr);			return ACT_RET_PRS_ERR;		}		 		len = atoi(args[cur_arg]);		if (len <= 0) {			memprintf(err, ""length must be > 0"");			free(expr);			return ACT_RET_PRS_ERR;		}		cur_arg++;		if (!len) {			memprintf(err, ""a positive 'len' argument is mandatory"");			free(expr);			return ACT_RET_PRS_ERR;		}		hdr = calloc(1, sizeof(*hdr));		hdr->next = px->req_cap;		hdr->name = NULL;  		hdr->namelen = 0;		hdr->len = len;		hdr->pool = create_pool(""caphdr"", hdr->len + 1, MEM_F_SHARED);		hdr->index = px->nb_req_cap++;		px->req_cap = hdr;		px->to_log |= LW_REQHDR;		rule->action       = ACT_CUSTOM;		rule->action_ptr   = http_action_req_capture;		rule->arg.cap.expr = expr;		rule->arg.cap.hdr  = hdr;	}	else if (strcmp(args[cur_arg], ""id"") == 0) {		int id;		char *error;		cur_arg++;		if (!args[cur_arg]) {			memprintf(err, ""missing id value"");			free(expr);			return ACT_RET_PRS_ERR;		}		id = strtol(args[cur_arg], &error, 10);		if (*error != '\0') {			memprintf(err, ""cannot parse id '%s'"", args[cur_arg]);			free(expr);			return ACT_RET_PRS_ERR;		}		cur_arg++;		px->conf.args.ctx = ARGC_CAP;		rule->action       = ACT_CUSTOM;		rule->action_ptr   = http_action_req_capture_by_id;		rule->check_ptr    = check_http_req_capture;		rule->arg.capid.expr = expr;		rule->arg.capid.idx  = id;	}	else {		memprintf(err, ""expects 'len' or 'id', found '%s'"", args[cur_arg]);		free(expr);		return ACT_RET_PRS_ERR;	}	*orig_arg = cur_arg;	return ACT_RET_PRS_OK;}",1110
243,5,CVE-2015-7665,22,"delelement (struct fileinfo *f, struct fileinfo **start){  struct fileinfo *prev = f->prev;  struct fileinfo *next = f->next;  xfree (f->name);  xfree (f->linkto);  xfree (f);  if (next)    next->prev = prev;  if (prev)    prev->next = next;  else    *start = next;  return next;}",161
248,74,CVE-2018-11469,22,"int http_header_add_tail(struct http_msg *msg, struct hdr_idx *hdr_idx, const char *text){	int bytes, len;	len = strlen(text);	bytes = buffer_insert_line2(msg->chn->buf, msg->chn->buf->p + msg->eoh, text, len);	if (!bytes)		return -1;	http_msg_move_end(msg, bytes);	return hdr_idx_add(len, 1, hdr_idx, hdr_idx->tail);}",1079
244,153,CVE-2018-11469,22,"smp_fetch_url_param_val(const struct arg *args, struct sample *smp, const char *kw, void *private){	int ret = smp_fetch_url_param(args, smp, kw, private);	if (ret > 0) {		smp->data.type = SMP_T_SINT;		smp->data.u.sint = strl2ic(smp->data.u.str.str, smp->data.u.str.len);	}	return ret;}",1158
152,1187,CVE-2016-4482,22,"static void free_async(struct async *as){	int i;	put_pid(as->pid);	if (as->cred)		put_cred(as->cred);	for (i = 0; i < as->urb->num_sgs; i++) {		if (sg_page(&as->urb->sg[i]))			kfree(sg_virt(&as->urb->sg[i]));	}	kfree(as->urb->sg);	if (as->usbm == NULL)		kfree(as->urb->transfer_buffer);	else		dec_usb_memory_use_count(as->usbm, &as->usbm->urb_use_count);	kfree(as->urb->setup_packet);	usb_free_urb(as->urb);	usbfs_decrease_memory_usage(as->mem_usage);	kfree(as);}",16940
14,1039,CVE-2016-5696,22,static inline int tcp_may_undo(const struct tcp_sock *tp){	return tp->undo_marker && (!tp->undo_retrans || tcp_packet_delayed(tp));},16415
454,236,CVE-2013-4516,22,"static int mp_add_one_port(struct uart_driver *drv, struct sb_uart_port *port){	struct sb_uart_state *state;	int ret = 0;	if (port->line >= drv->nr)		return -EINVAL;	state = drv->state + port->line;	MP_MUTEX_LOCK(mp_mutex);	if (state->port) {		ret = -EINVAL;		goto out;	}	state->port = port;	spin_lock_init(&port->lock);	port->cons = drv->cons;	port->info = state->info;	mp_configure_port(drv, state, port);	tty_register_device(drv->tty_driver, port->line, port->dev);out:	MP_MUTEX_UNLOCK(mp_mutex);	return ret;}",7674
300,1052,CVE-2016-5696,22,"static inline void tcp_rcv_rtt_measure(struct tcp_sock *tp){	if (tp->rcv_rtt_est.time == 0)		goto new_measure;	if (before(tp->rcv_nxt, tp->rcv_rtt_est.seq))		return;	tcp_rcv_rtt_update(tp, tcp_time_stamp - tp->rcv_rtt_est.time, 1);new_measure:	tp->rcv_rtt_est.seq = tp->rcv_nxt + tp->rcv_wnd;	tp->rcv_rtt_est.time = tcp_time_stamp;}",16428
291,47,CVE-2018-11469,22,"int check_http_res_capture(struct act_rule *rule, struct proxy *px, char **err){	if (rule->action_ptr != http_action_res_capture_by_id)		return 1;	if (rule->arg.capid.idx >= px->nb_rsp_cap) {		memprintf(err, ""unable to find capture id '%d' referenced by http-response capture rule"",			  rule->arg.capid.idx);		return 0;	}	return 1;}",1052
104,137,CVE-2018-11469,22,"smp_fetch_http_auth(const struct arg *args, struct sample *smp, const char *kw, void *private){	if (!args || args->type != ARGT_USR)		return 0;	CHECK_HTTP_MESSAGE_FIRST();	if (!get_http_auth(smp->strm))		return 0;	smp->data.type = SMP_T_BOOL;	smp->data.u.sint = check_user(args->data.usr, smp->strm->txn->auth.user,	                            smp->strm->txn->auth.pass);	return 1;}",1142
40,741,CVE-2014-8709,22,"void __ieee80211_tx_skb_tid_band(struct ieee80211_sub_if_data *sdata,				 struct sk_buff *skb, int tid,				 enum ieee80211_band band){	int ac = ieee802_1d_to_ac[tid & 7];	skb_set_mac_header(skb, 0);	skb_set_network_header(skb, 0);	skb_set_transport_header(skb, 0);	skb_set_queue_mapping(skb, ac);	skb->priority = tid;	skb->dev = sdata->dev;	 	local_bh_disable();	ieee80211_xmit(sdata, skb, band);	local_bh_enable();}",10387
227,478,CVE-2013-3228,22,"static int irda_data_indication(void *instance, void *sap, struct sk_buff *skb){	struct irda_sock *self;	struct sock *sk;	int err;	IRDA_DEBUG(3, ""%s()\n"", __func__);	self = instance;	sk = instance;	err = sock_queue_rcv_skb(sk, skb);	if (err) {		IRDA_DEBUG(1, ""%s(), error: no more mem!\n"", __func__);		self->rx_flow = FLOW_STOP;		 		return err;	}	return 0;}",8321
87,1794,CVE-2017-0814,22,"static int _determine_leaf_words(int nodeb, int leafwidth){ if(leafwidth>nodeb)return 2; return 1;}",30734
109,32,CVE-2015-5330,22,"int ldb_dn_set_component(struct ldb_dn *dn, int num,			 const char *name, const struct ldb_val val){	char *n;	struct ldb_val v;	if ( ! ldb_dn_validate(dn)) {		return LDB_ERR_OTHER;	}	if (num >= dn->comp_num) {		return LDB_ERR_OTHER;	}	n = talloc_strdup(dn, name);	if ( ! n) {		return LDB_ERR_OTHER;	}	v.length = val.length;	v.data = (int *)talloc_memdup(dn, val.data, v.length+1);	if ( ! v.data) {		talloc_free(n);		return LDB_ERR_OTHER;	}	talloc_free(dn->components[num].name);	talloc_free(dn->components[num].value.data);	dn->components[num].name = n;	dn->components[num].value = v;	if (dn->valid_case) {		unsigned int i;		for (i = 0; i < dn->comp_num; i++) {			LDB_FREE(dn->components[i].cf_name);			LDB_FREE(dn->components[i].cf_value.data);		}		dn->valid_case = false;	}	LDB_FREE(dn->casefold);	LDB_FREE(dn->linearized);	 	LDB_FREE(dn->ext_linearized);	LDB_FREE(dn->ext_components);	dn->ext_comp_num = 0;	return LDB_SUCCESS;}",475
200,98,CVE-2018-11469,22,"int http_wait_for_request_body(struct stream *s, struct channel *req, int an_bit){	struct session *sess = s->sess;	struct http_txn *txn = s->txn;	struct http_msg *msg = &s->txn->req;	 	if (msg->msg_state < HTTP_MSG_CHUNK_SIZE) {		 		if (msg->msg_state < HTTP_MSG_BODY)			goto missing_data;		if (msg->msg_state < HTTP_MSG_100_SENT) {			 			if (msg->flags & HTTP_MSGF_VER_11) {				struct hdr_ctx ctx;				ctx.idx = 0;				 				if (http_find_header2(""Expect"", 6, req->buf->p, &txn->hdr_idx, &ctx) &&				    unlikely(ctx.vlen == 12 && strncasecmp(ctx.line+ctx.val, ""100-continue"", 12) == 0)) {					co_inject(&s->res, http_100_chunk.str, http_100_chunk.len);					http_remove_header2(&txn->req, &txn->hdr_idx, &ctx);				}			}			msg->msg_state = HTTP_MSG_100_SENT;		}		 		msg->next = msg->sov;		if (msg->flags & HTTP_MSGF_TE_CHNK)			msg->msg_state = HTTP_MSG_CHUNK_SIZE;		else			msg->msg_state = HTTP_MSG_DATA;	}	if (!(msg->flags & HTTP_MSGF_TE_CHNK)) {		 		if (http_body_bytes(msg) < msg->body_len)			goto missing_data;		 		goto http_end;	}	 	if (msg->msg_state == HTTP_MSG_CHUNK_SIZE) {		 		unsigned int chunk;		int ret = h1_parse_chunk_size(req->buf, msg->next, req->buf->i, &chunk);		if (!ret)			goto missing_data;		else if (ret < 0) {			msg->err_pos = req->buf->i + ret;			if (msg->err_pos < 0)				msg->err_pos += req->buf->size;			stream_inc_http_err_ctr(s);			goto return_bad_req;		}		msg->chunk_len = chunk;		msg->body_len += chunk;		msg->sol = ret;		msg->next += ret;		msg->msg_state = msg->chunk_len ? HTTP_MSG_DATA : HTTP_MSG_TRAILERS;	}	 	if (msg->msg_state == HTTP_MSG_TRAILERS)		goto http_end;	if (http_body_bytes(msg) >= msg->body_len)    		goto http_end; missing_data:	 	if (buffer_full(req->buf, global.tune.maxrewrite))		goto http_end;	if ((req->flags & CF_READ_TIMEOUT) || tick_is_expired(req->analyse_exp, now_ms)) {		txn->status = 408;		http_reply_and_close(s, txn->status, http_error_message(s));		if (!(s->flags & SF_ERR_MASK))			s->flags |= SF_ERR_CLITO;		if (!(s->flags & SF_FINST_MASK))			s->flags |= SF_FINST_D;		goto return_err_msg;	}	 	if (!(req->flags & (CF_SHUTR | CF_READ_ERROR))) {		 		channel_dont_connect(req);		if (!tick_isset(req->analyse_exp))			req->analyse_exp = tick_add_ifset(now_ms, s->be->timeout.httpreq);		return 0;	} http_end:	 	s->logs.tv_request = now;   	req->analysers &= ~an_bit;	req->analyse_exp = TICK_ETERNITY;	return 1; return_bad_req:  	txn->req.err_state = txn->req.msg_state;	txn->req.msg_state = HTTP_MSG_ERROR;	txn->status = 400;	http_reply_and_close(s, txn->status, http_error_message(s));	if (!(s->flags & SF_ERR_MASK))		s->flags |= SF_ERR_PRXCOND;	if (!(s->flags & SF_FINST_MASK))		s->flags |= SF_FINST_R; return_err_msg:	req->analysers &= AN_REQ_FLT_END;	HA_ATOMIC_ADD(&sess->fe->fe_counters.failed_req, 1);	if (sess->listener->counters)		HA_ATOMIC_ADD(&sess->listener->counters->failed_req, 1);	return 0;}",1103
374,1279,CVE-2015-8964,22,"int tty_ldisc_setup(struct tty_struct *tty, struct tty_struct *o_tty){	struct tty_ldisc *ld = tty->ldisc;	int retval;	retval = tty_ldisc_open(tty, ld);	if (retval)		return retval;	if (o_tty) {		retval = tty_ldisc_open(o_tty, o_tty->ldisc);		if (retval) {			tty_ldisc_close(tty, ld);			return retval;		}	}	return 0;}",18318
340,1352,CVE-2014-9903,22,static inline int sd_local_flags(int level){	if (sched_domains_numa_distance[level] > RECLAIM_DISTANCE)		return 0;	return SD_BALANCE_EXEC | SD_BALANCE_FORK | SD_WAKE_AFFINE;},19289
89,1405,CVE-2017-14140,22,"int migrate_page_move_mapping(struct address_space *mapping,		struct page *newpage, struct page *page,		struct buffer_head *head, enum migrate_mode mode,		int extra_count){	struct zone *oldzone, *newzone;	int dirty;	int expected_count = 1 + extra_count;	void **pslot;	if (!mapping) {		 		if (page_count(page) != expected_count)			return -EAGAIN;		 		newpage->index = page->index;		newpage->mapping = page->mapping;		if (PageSwapBacked(page))			__SetPageSwapBacked(newpage);		return MIGRATEPAGE_SUCCESS;	}	oldzone = page_zone(page);	newzone = page_zone(newpage);	spin_lock_irq(&mapping->tree_lock);	pslot = radix_tree_lookup_slot(&mapping->page_tree, 					page_index(page));	expected_count += 1 + page_has_private(page);	if (page_count(page) != expected_count ||		radix_tree_deref_slot_protected(pslot, &mapping->tree_lock) != page) {		spin_unlock_irq(&mapping->tree_lock);		return -EAGAIN;	}	if (!page_ref_freeze(page, expected_count)) {		spin_unlock_irq(&mapping->tree_lock);		return -EAGAIN;	}	 	if (mode == MIGRATE_ASYNC && head &&			!buffer_migrate_lock_buffers(head, mode)) {		page_ref_unfreeze(page, expected_count);		spin_unlock_irq(&mapping->tree_lock);		return -EAGAIN;	}	 	newpage->index = page->index;	newpage->mapping = page->mapping;	get_page(newpage);	 	if (PageSwapBacked(page)) {		__SetPageSwapBacked(newpage);		if (PageSwapCache(page)) {			SetPageSwapCache(newpage);			set_page_private(newpage, page_private(page));		}	} else {		VM_BUG_ON_PAGE(PageSwapCache(page), page);	}	 	dirty = PageDirty(page);	if (dirty) {		ClearPageDirty(page);		SetPageDirty(newpage);	}	radix_tree_replace_slot(&mapping->page_tree, pslot, newpage);	 	page_ref_unfreeze(page, expected_count - 1);	spin_unlock(&mapping->tree_lock);	 	 	if (newzone != oldzone) {		__dec_node_state(oldzone->zone_pgdat, NR_FILE_PAGES);		__inc_node_state(newzone->zone_pgdat, NR_FILE_PAGES);		if (PageSwapBacked(page) && !PageSwapCache(page)) {			__dec_node_state(oldzone->zone_pgdat, NR_SHMEM);			__inc_node_state(newzone->zone_pgdat, NR_SHMEM);		}		if (dirty && mapping_cap_account_dirty(mapping)) {			__dec_node_state(oldzone->zone_pgdat, NR_FILE_DIRTY);			__dec_zone_state(oldzone, NR_ZONE_WRITE_PENDING);			__inc_node_state(newzone->zone_pgdat, NR_FILE_DIRTY);			__inc_zone_state(newzone, NR_ZONE_WRITE_PENDING);		}	}	local_irq_enable();	return MIGRATEPAGE_SUCCESS;}",20189
442,782,CVE-2013-7281,22,static void raw6_destroy(struct sock *sk){	lock_sock(sk);	ip6_flush_pending_frames(sk);	release_sock(sk);	inet6_destroy_sock(sk);},12340
433,204,CVE-2011-1160,22,"void tpm_remove_hardware(struct device *dev){	struct tpm_chip *chip = dev_get_drvdata(dev);	if (chip == NULL) {		dev_err(dev, ""No device data found\n"");		return;	}	spin_lock(&driver_lock);	list_del_rcu(&chip->list);	spin_unlock(&driver_lock);	synchronize_rcu();	misc_deregister(&chip->vendor.miscdev);	sysfs_remove_group(&dev->kobj, chip->vendor.attr_group);	tpm_bios_log_teardown(chip->bios_dir);	 	put_device(chip->dev);}",6911
341,1016,CVE-2016-5696,22,"static struct sk_buff *tcp_collapse_one(struct sock *sk, struct sk_buff *skb,					struct sk_buff_head *list){	struct sk_buff *next = NULL;	if (!skb_queue_is_last(list, skb))		next = skb_queue_next(list, skb);	__skb_unlink(skb, list);	__kfree_skb(skb);	NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPRCVCOLLAPSED);	return next;}",16392
92,140,CVE-2018-11469,22,"smp_fetch_meth(const struct arg *args, struct sample *smp, const char *kw, void *private){	int meth;	struct http_txn *txn;	CHECK_HTTP_MESSAGE_FIRST_PERM();	txn = smp->strm->txn;	meth = txn->meth;	smp->data.type = SMP_T_METH;	smp->data.u.meth.meth = meth;	if (meth == HTTP_METH_OTHER) {		if (txn->rsp.msg_state != HTTP_MSG_RPBEFORE)			 			return 0;		smp->flags |= SMP_F_CONST;		smp->data.u.meth.str.len = txn->req.sl.rq.m_l;		smp->data.u.meth.str.str = txn->req.chn->buf->p;	}	smp->flags |= SMP_F_VOL_1ST;	return 1;}",1145
393,678,CVE-2012-6541,22,"static void ccid3_hc_tx_get_info(struct sock *sk, struct tcp_info *info){	info->tcpi_rto = ccid3_hc_tx_sk(sk)->tx_t_rto;	info->tcpi_rtt = ccid3_hc_tx_sk(sk)->tx_rtt;}",9865
263,1526,CVE-2018-18710,22,"static int cdrom_ioctl_set_options(struct cdrom_device_info *cdi,		unsigned long arg){	cd_dbg(CD_DO_IOCTL, ""entering CDROM_SET_OPTIONS\n"");	 	switch (arg) {	case CDO_USE_FFLAGS:	case CDO_CHECK_TYPE:		break;	case CDO_LOCK:		if (!CDROM_CAN(CDC_LOCK))			return -ENOSYS;		break;	case 0:		return cdi->options;	 	default:		if (!CDROM_CAN(arg))			return -ENOSYS;	}	cdi->options |= (int) arg;	return cdi->options;}",23443
359,538,CVE-2013-3224,22,int bt_sock_unregister(int proto){	int err = 0;	if (proto < 0 || proto >= BT_MAX_PROTO)		return -EINVAL;	write_lock(&bt_proto_lock);	if (!bt_proto[proto])		err = -ENOENT;	else		bt_proto[proto] = NULL;	write_unlock(&bt_proto_lock);	return err;},8381
313,334,CVE-2013-3237,22,static int vsock_is_pending(struct sock *sk){	struct vsock_sock *vsk = vsock_sk(sk);	return !list_empty(&vsk->pending_links);},8177
6,779,CVE-2013-7281,22,"int udp_push_pending_frames(struct sock *sk){	struct udp_sock  *up = udp_sk(sk);	struct inet_sock *inet = inet_sk(sk);	struct flowi4 *fl4 = &inet->cork.fl.u.ip4;	struct sk_buff *skb;	int err = 0;	skb = ip_finish_skb(sk, fl4);	if (!skb)		goto out;	err = udp_send_skb(skb, fl4);out:	up->len = 0;	up->pending = 0;	return err;}",12337
398,1648,CVE-2012-6546,22,"static int pvc_connect(struct socket *sock, struct sockaddr *sockaddr,		       int sockaddr_len, int flags){	return pvc_bind(sock, sockaddr, sockaddr_len);}",28308
230,876,CVE-2015-7884,22,"static int vivid_fb_get_fix(struct vivid_dev *dev, struct fb_fix_screeninfo *fix){	dprintk(dev, 1, ""vivid_fb_get_fix\n"");	memset(fix, 0, sizeof(struct fb_fix_screeninfo));	strlcpy(fix->id, ""vioverlay fb"", sizeof(fix->id));	fix->smem_start = dev->video_pbase;	fix->smem_len = dev->video_buffer_size;	fix->type = FB_TYPE_PACKED_PIXELS;	fix->visual = FB_VISUAL_TRUECOLOR;	fix->xpanstep = 1;	fix->ypanstep = 1;	fix->ywrapstep = 0;	fix->line_length = dev->display_byte_stride;	fix->accel = FB_ACCEL_NONE;	return 0;}",13053
78,620,CVE-2013-0349,22,static void __hidp_unlink_session(struct hidp_session *session){	hci_conn_put_device(session->conn);	list_del(&session->list);},9693
251,827,CVE-2015-8569,22,"static int pptp_rcv(struct sk_buff *skb){	struct pppox_sock *po;	struct pptp_gre_header *header;	struct iphdr *iph;	if (skb->pkt_type != PACKET_HOST)		goto drop;	if (!pskb_may_pull(skb, 12))		goto drop;	iph = ip_hdr(skb);	header = (struct pptp_gre_header *)skb->data;	if (ntohs(header->protocol) != PPTP_GRE_PROTO ||  		PPTP_GRE_IS_C(header->flags) ||                 		PPTP_GRE_IS_R(header->flags) ||                 		!PPTP_GRE_IS_K(header->flags) ||                		(header->flags&0xF) != 0)                       		 		goto drop;	po = lookup_chan(htons(header->call_id), iph->saddr);	if (po) {		skb_dst_drop(skb);		nf_reset(skb);		return sk_receive_skb(sk_pppox(po), skb, 0);	}drop:	kfree_skb(skb);	return NET_RX_DROP;}",12850
195,1757,CVE-2019-5837,22,  void FindMainResponseExclusionsInWorkingSet() {    FindMainResponseExclusions(false);  },30169
154,583,CVE-2013-2061,22,"crypto_adjust_frame_parameters(struct frame *frame,			       const struct key_type* kt,			       int cipher_defined,			       int use_iv,			       int packet_id,			       int packet_id_long_form){  frame_add_to_extra_frame (frame,			    (packet_id ? packet_id_size (packet_id_long_form) : 0) +			    ((cipher_defined && use_iv) ? cipher_kt_iv_size (kt->cipher) : 0) +			    (cipher_defined ? cipher_kt_block_size (kt->cipher) : 0) +  			    kt->hmac_length);}",8943
382,619,CVE-2013-0349,22,"static int __hidp_send_ctrl_message(struct hidp_session *session,				    unsigned char hdr, unsigned char *data,				    int size){	struct sk_buff *skb;	BT_DBG(""session %p data %p size %d"", session, data, size);	if (atomic_read(&session->terminate))		return -EIO;	skb = alloc_skb(size + 1, GFP_ATOMIC);	if (!skb) {		BT_ERR(""Can't allocate memory for new frame"");		return -ENOMEM;	}	*skb_put(skb, 1) = hdr;	if (data && size > 0)		memcpy(skb_put(skb, size), data, size);	skb_queue_tail(&session->ctrl_transmit, skb);	return 0;}",9692
343,994,CVE-2015-5302,22,"static void update_window_title(void){         const char *prgname = g_get_prgname();    const char *reason = problem_data_get_content_or_NULL(g_cd, FILENAME_REASON);    char *title = xasprintf(""%s - %s"", (reason ? reason : g_dump_dir_name),            (prgname ? prgname : ""report""));    gtk_window_set_title(g_wnd_assistant, title);    free(title);}",13420
186,922,CVE-2015-5697,22,static void md_safemode_timeout(unsigned long data){	struct mddev *mddev = (struct mddev *) data;	if (!atomic_read(&mddev->writes_pending)) {		mddev->safemode = 1;		if (mddev->external)			sysfs_notify_dirent_safe(mddev->sysfs_state);	}	md_wakeup_thread(mddev->thread);},13252
305,1676,CVE-2012-6544,22,"static struct sk_buff *l2cap_sock_alloc_skb_cb(struct l2cap_chan *chan,					       unsigned long len, int nb){	struct sk_buff *skb;	int err;	l2cap_chan_unlock(chan);	skb = bt_skb_send_alloc(chan->sk, len, nb, &err);	l2cap_chan_lock(chan);	if (!skb)		return ERR_PTR(err);	return skb;}",28336
285,715,CVE-2012-6536,22,"static int copy_to_user_tmpl(struct xfrm_policy *xp, struct sk_buff *skb){	struct xfrm_user_tmpl vec[XFRM_MAX_DEPTH];	int i;	if (xp->xfrm_nr == 0)		return 0;	for (i = 0; i < xp->xfrm_nr; i++) {		struct xfrm_user_tmpl *up = &vec[i];		struct xfrm_tmpl *kp = &xp->xfrm_vec[i];		memset(up, 0, sizeof(*up));		memcpy(&up->id, &kp->id, sizeof(up->id));		up->family = kp->encap_family;		memcpy(&up->saddr, &kp->saddr, sizeof(up->saddr));		up->reqid = kp->reqid;		up->mode = kp->mode;		up->share = kp->share;		up->optional = kp->optional;		up->aalgos = kp->aalgos;		up->ealgos = kp->ealgos;		up->calgos = kp->calgos;	}	return nla_put(skb, XFRMA_TMPL,		       sizeof(struct xfrm_user_tmpl) * xp->xfrm_nr, vec);}",9902
116,1005,CVE-2016-9756,22,"static void write_register_operand(struct operand *op){	return assign_register(op->addr.reg, op->val, op->bytes);}",15104
354,145,CVE-2018-11469,22,"smp_fetch_rqver(const struct arg *args, struct sample *smp, const char *kw, void *private){	struct http_txn *txn;	char *ptr;	int len;	CHECK_HTTP_MESSAGE_FIRST();	txn = smp->strm->txn;	len = txn->req.sl.rq.v_l;	ptr = txn->req.chn->buf->p + txn->req.sl.rq.v;	while ((len-- > 0) && (*ptr++ != '/'));	if (len <= 0)		return 0;	smp->data.type = SMP_T_STR;	smp->data.u.str.str = ptr;	smp->data.u.str.len = len;	smp->flags = SMP_F_VOL_1ST | SMP_F_CONST;	return 1;}",1150
392,1033,CVE-2016-5696,22,"void tcp_fin(struct sock *sk){	struct tcp_sock *tp = tcp_sk(sk);	inet_csk_schedule_ack(sk);	sk->sk_shutdown |= RCV_SHUTDOWN;	sock_set_flag(sk, SOCK_DONE);	switch (sk->sk_state) {	case TCP_SYN_RECV:	case TCP_ESTABLISHED:		 		tcp_set_state(sk, TCP_CLOSE_WAIT);		inet_csk(sk)->icsk_ack.pingpong = 1;		break;	case TCP_CLOSE_WAIT:	case TCP_CLOSING:		 		break;	case TCP_LAST_ACK:		 		break;	case TCP_FIN_WAIT1:		 		tcp_send_ack(sk);		tcp_set_state(sk, TCP_CLOSING);		break;	case TCP_FIN_WAIT2:		 		tcp_send_ack(sk);		tcp_time_wait(sk, TCP_TIME_WAIT, 0);		break;	default:		 		pr_err(""%s: Impossible, sk->sk_state=%d\n"",		       __func__, sk->sk_state);		break;	}	 	__skb_queue_purge(&tp->out_of_order_queue);	if (tcp_is_sack(tp))		tcp_sack_reset(&tp->rx_opt);	sk_mem_reclaim(sk);	if (!sock_flag(sk, SOCK_DEAD)) {		sk->sk_state_change(sk);		 		if (sk->sk_shutdown == SHUTDOWN_MASK ||		    sk->sk_state == TCP_CLOSE)			sk_wake_async(sk, SOCK_WAKE_WAITD, POLL_HUP);		else			sk_wake_async(sk, SOCK_WAKE_WAITD, POLL_IN);	}}",16409
419,16,CVE-2015-5330,22,"static int ldb_dn_extended_component_compare(const void *p1, const void *p2){	const struct ldb_dn_ext_component *ec1 = (const struct ldb_dn_ext_component *)p1;	const struct ldb_dn_ext_component *ec2 = (const struct ldb_dn_ext_component *)p2;	return strcmp(ec1->name, ec2->name);}",459
368,217,CVE-2011-1078,22,"static void sco_sock_clear_timer(struct sock *sk){	BT_DBG(""sock %p state %d"", sk, sk->sk_state);	sk_stop_timer(sk, &sk->sk_timer);}",6949
377,1683,CVE-2012-6544,22,"static int l2cap_sock_listen(struct socket *sock, int backlog){	struct sock *sk = sock->sk;	struct l2cap_chan *chan = l2cap_pi(sk)->chan;	int err = 0;	BT_DBG(""sk %p backlog %d"", sk, backlog);	lock_sock(sk);	if (sk->sk_state != BT_BOUND) {		err = -EBADFD;		goto done;	}	if (sk->sk_type != SOCK_SEQPACKET && sk->sk_type != SOCK_STREAM) {		err = -EINVAL;		goto done;	}	switch (chan->mode) {	case L2CAP_MODE_BASIC:		break;	case L2CAP_MODE_ERTM:	case L2CAP_MODE_STREAMING:		if (!disable_ertm)			break;		 	default:		err = -ENOTSUPP;		goto done;	}	sk->sk_max_ack_backlog = backlog;	sk->sk_ack_backlog = 0;	chan->state = BT_LISTEN;	sk->sk_state = BT_LISTEN;done:	release_sock(sk);	return err;}",28343
108,241,CVE-2013-4516,22,static int mp_chars_in_buffer(struct tty_struct *tty){	struct sb_uart_state *state = tty->driver_data;	return uart_circ_chars_pending(&state->info->xmit);},7679
361,191,CVE-2012-0037,22,"raptor_rdfxml_check_nodeElement_name(const char *name) {  int i;  if(*name == '_')    return 1;    for(i = 0; raptor_rdf_ns_terms_info[i].name; i++)    if(!strcmp(raptor_rdf_ns_terms_info[i].name, name))      return raptor_rdf_ns_terms_info[i].allowed_as_nodeElement;  return -1;}",4315
98,1623,CVE-2019-10639,22,void unregister_pernet_device(struct pernet_operations *ops){	down_write(&pernet_ops_rwsem);	if (&ops->list == first_device)		first_device = first_device->next;	unregister_pernet_operations(ops);	up_write(&pernet_ops_rwsem);},27190
111,363,CVE-2013-3236,22,"int vmci_transport_send_read(struct sock *sk){	return vmci_transport_send_control_pkt(					sk, VMCI_TRANSPORT_PACKET_TYPE_READ, 0,					0, NULL, VSOCK_PROTO_INVALID,					VMCI_INVALID_HANDLE);}",8206
424,1456,CVE-2017-9150,22,"static int ext_analyzer_insn_hook(struct bpf_verifier_env *env,				  int insn_idx, int prev_insn_idx){	if (!env->analyzer_ops || !env->analyzer_ops->insn_hook)		return 0;	return env->analyzer_ops->insn_hook(env, insn_idx, prev_insn_idx);}",20841
385,1112,CVE-2016-4578,22,"static void snd_timer_request(struct snd_timer_id *tid){	switch (tid->dev_class) {	case SNDRV_TIMER_CLASS_GLOBAL:		if (tid->device < timer_limit)			request_module(""snd-timer-%i"", tid->device);		break;	case SNDRV_TIMER_CLASS_CARD:	case SNDRV_TIMER_CLASS_PCM:		if (tid->card < snd_ecards_limit)			request_module(""snd-card-%i"", tid->card);		break;	default:		break;	}}",16700
253,1168,CVE-2016-4486,22,"static int rtnl_setlink(struct sk_buff *skb, struct nlmsghdr *nlh){	struct net *net = sock_net(skb->sk);	struct ifinfomsg *ifm;	struct net_device *dev;	int err;	struct nlattr *tb[IFLA_MAX+1];	char ifname[IFNAMSIZ];	err = nlmsg_parse(nlh, sizeof(*ifm), tb, IFLA_MAX, ifla_policy);	if (err < 0)		goto errout;	if (tb[IFLA_IFNAME])		nla_strlcpy(ifname, tb[IFLA_IFNAME], IFNAMSIZ);	else		ifname[0] = '\0';	err = -EINVAL;	ifm = nlmsg_data(nlh);	if (ifm->ifi_index > 0)		dev = __dev_get_by_index(net, ifm->ifi_index);	else if (tb[IFLA_IFNAME])		dev = __dev_get_by_name(net, ifname);	else		goto errout;	if (dev == NULL) {		err = -ENODEV;		goto errout;	}	err = validate_linkmsg(dev, tb);	if (err < 0)		goto errout;	err = do_setlink(skb, dev, ifm, tb, ifname, 0);errout:	return err;}",16921
129,714,CVE-2012-6536,22,"static void copy_to_user_state(struct xfrm_state *x, struct xfrm_usersa_info *p){	memset(p, 0, sizeof(*p));	memcpy(&p->id, &x->id, sizeof(p->id));	memcpy(&p->sel, &x->sel, sizeof(p->sel));	memcpy(&p->lft, &x->lft, sizeof(p->lft));	memcpy(&p->curlft, &x->curlft, sizeof(p->curlft));	memcpy(&p->stats, &x->stats, sizeof(p->stats));	memcpy(&p->saddr, &x->props.saddr, sizeof(p->saddr));	p->mode = x->props.mode;	p->replay_window = x->props.replay_window;	p->reqid = x->props.reqid;	p->family = x->props.family;	p->flags = x->props.flags;	p->seq = x->km.seq;}",9901
101,844,CVE-2015-8374,22,"static struct inode *btrfs_iget_locked(struct super_block *s,				       struct btrfs_key *location,				       struct btrfs_root *root){	struct inode *inode;	struct btrfs_iget_args args;	unsigned long hashval = btrfs_inode_hash(location->objectid, root);	args.location = location;	args.root = root;	inode = iget5_locked(s, hashval, btrfs_find_actor,			     btrfs_init_locked_inode,			     (void *)&args);	return inode;}",12927
371,99,CVE-2018-11469,22,"int http_wait_for_response(struct stream *s, struct channel *rep, int an_bit){	struct session *sess = s->sess;	struct http_txn *txn = s->txn;	struct http_msg *msg = &txn->rsp;	struct hdr_ctx ctx;	int use_close_only;	int cur_idx;	int n;	DPRINTF(stderr,""[%u] %s: stream=%p b=%p, exp(r,w)=%u,%u bf=%08x bh=%d analysers=%02x\n"",		now_ms, __FUNCTION__,		s,		rep,		rep->rex, rep->wex,		rep->flags,		rep->buf->i,		rep->analysers);	  next_one:	 	if (buffer_not_empty(rep->buf) && msg->msg_state < HTTP_MSG_ERROR) {		if (unlikely(!channel_is_rewritable(rep))) {			 			if (rep->flags & (CF_SHUTW|CF_SHUTW_NOW|CF_WRITE_ERROR|CF_WRITE_TIMEOUT))				goto abort_response;			channel_dont_close(rep);			rep->flags |= CF_READ_DONTWAIT;  			rep->flags |= CF_WAKE_WRITE;			return 0;		}		if (unlikely(bi_end(rep->buf) < b_ptr(rep->buf, msg->next) ||		             bi_end(rep->buf) > rep->buf->data + rep->buf->size - global.tune.maxrewrite))			buffer_slow_realign(rep->buf);		if (likely(msg->next < rep->buf->i))			http_msg_analyzer(msg, &txn->hdr_idx);	}	 	if (unlikely((global.mode & MODE_DEBUG) &&		     (!(global.mode & MODE_QUIET) || (global.mode & MODE_VERBOSE)) &&		     msg->msg_state >= HTTP_MSG_BODY)) {		char *eol, *sol;		sol = rep->buf->p;		eol = sol + (msg->sl.st.l ? msg->sl.st.l : rep->buf->i);		debug_hdr(""srvrep"", s, sol, eol);		sol += hdr_idx_first_pos(&txn->hdr_idx);		cur_idx = hdr_idx_first_idx(&txn->hdr_idx);		while (cur_idx) {			eol = sol + txn->hdr_idx.v[cur_idx].len;			debug_hdr(""srvhdr"", s, sol, eol);			sol = eol + txn->hdr_idx.v[cur_idx].cr + 1;			cur_idx = txn->hdr_idx.v[cur_idx].next;		}	}	 	if (unlikely(msg->msg_state < HTTP_MSG_BODY)) {		 		if (unlikely(msg->msg_state == HTTP_MSG_ERROR)) {			 		hdr_response_bad:			if (msg->msg_state == HTTP_MSG_ERROR || msg->err_pos >= 0)				http_capture_bad_message(s->be, &s->be->invalid_rep, s, msg, msg->err_state, sess->fe);			HA_ATOMIC_ADD(&s->be->be_counters.failed_resp, 1);			if (objt_server(s->target)) {				HA_ATOMIC_ADD(&objt_server(s->target)->counters.failed_resp, 1);				health_adjust(objt_server(s->target), HANA_STATUS_HTTP_HDRRSP);			}		abort_response:			channel_auto_close(rep);			rep->analysers &= AN_RES_FLT_END;			txn->status = 502;			s->si[1].flags |= SI_FL_NOLINGER;			channel_truncate(rep);			http_reply_and_close(s, txn->status, http_error_message(s));			if (!(s->flags & SF_ERR_MASK))				s->flags |= SF_ERR_PRXCOND;			if (!(s->flags & SF_FINST_MASK))				s->flags |= SF_FINST_H;			return 0;		}		 		else if (buffer_full(rep->buf, global.tune.maxrewrite)) {			if (msg->err_pos < 0)				msg->err_pos = rep->buf->i;			goto hdr_response_bad;		}		 		else if (rep->flags & CF_READ_ERROR) {			if (msg->err_pos >= 0)				http_capture_bad_message(s->be, &s->be->invalid_rep, s, msg, msg->err_state, sess->fe);			else if (txn->flags & TX_NOT_FIRST)				goto abort_keep_alive;			HA_ATOMIC_ADD(&s->be->be_counters.failed_resp, 1);			if (objt_server(s->target)) {				HA_ATOMIC_ADD(&objt_server(s->target)->counters.failed_resp, 1);				health_adjust(objt_server(s->target), HANA_STATUS_HTTP_READ_ERROR);			}			channel_auto_close(rep);			rep->analysers &= AN_RES_FLT_END;			txn->status = 502;			 			if (objt_cs(s->si[1].end)) {				struct connection *conn = objt_cs(s->si[1].end)->conn;				if (conn->err_code == CO_ER_SSL_EARLY_FAILED)					txn->status = 425;			}			s->si[1].flags |= SI_FL_NOLINGER;			channel_truncate(rep);			http_reply_and_close(s, txn->status, http_error_message(s));			if (!(s->flags & SF_ERR_MASK))				s->flags |= SF_ERR_SRVCL;			if (!(s->flags & SF_FINST_MASK))				s->flags |= SF_FINST_H;			return 0;		}		 		else if (rep->flags & CF_READ_TIMEOUT) {			if (msg->err_pos >= 0)				http_capture_bad_message(s->be, &s->be->invalid_rep, s, msg, msg->err_state, sess->fe);			HA_ATOMIC_ADD(&s->be->be_counters.failed_resp, 1);			if (objt_server(s->target)) {				HA_ATOMIC_ADD(&objt_server(s->target)->counters.failed_resp, 1);				health_adjust(objt_server(s->target), HANA_STATUS_HTTP_READ_TIMEOUT);			}			channel_auto_close(rep);			rep->analysers &= AN_RES_FLT_END;			txn->status = 504;			s->si[1].flags |= SI_FL_NOLINGER;			channel_truncate(rep);			http_reply_and_close(s, txn->status, http_error_message(s));			if (!(s->flags & SF_ERR_MASK))				s->flags |= SF_ERR_SRVTO;			if (!(s->flags & SF_FINST_MASK))				s->flags |= SF_FINST_H;			return 0;		}		 		else if ((rep->flags & CF_SHUTR) && ((s->req.flags & (CF_SHUTR|CF_SHUTW)) == (CF_SHUTR|CF_SHUTW))) {			HA_ATOMIC_ADD(&sess->fe->fe_counters.cli_aborts, 1);			HA_ATOMIC_ADD(&s->be->be_counters.cli_aborts, 1);			if (objt_server(s->target))				HA_ATOMIC_ADD(&objt_server(s->target)->counters.cli_aborts, 1);			rep->analysers &= AN_RES_FLT_END;			channel_auto_close(rep);			txn->status = 400;			channel_truncate(rep);			http_reply_and_close(s, txn->status, http_error_message(s));			if (!(s->flags & SF_ERR_MASK))				s->flags |= SF_ERR_CLICL;			if (!(s->flags & SF_FINST_MASK))				s->flags |= SF_FINST_H;			 			return 0;		}		 		else if (rep->flags & CF_SHUTR) {			if (msg->msg_state >= HTTP_MSG_RPVER || msg->err_pos >= 0)				http_capture_bad_message(s->be, &s->be->invalid_rep, s, msg, msg->err_state, sess->fe);			else if (txn->flags & TX_NOT_FIRST)				goto abort_keep_alive;			HA_ATOMIC_ADD(&s->be->be_counters.failed_resp, 1);			if (objt_server(s->target)) {				HA_ATOMIC_ADD(&objt_server(s->target)->counters.failed_resp, 1);				health_adjust(objt_server(s->target), HANA_STATUS_HTTP_BROKEN_PIPE);			}			channel_auto_close(rep);			rep->analysers &= AN_RES_FLT_END;			txn->status = 502;			s->si[1].flags |= SI_FL_NOLINGER;			channel_truncate(rep);			http_reply_and_close(s, txn->status, http_error_message(s));			if (!(s->flags & SF_ERR_MASK))				s->flags |= SF_ERR_SRVCL;			if (!(s->flags & SF_FINST_MASK))				s->flags |= SF_FINST_H;			return 0;		}		 		else if (rep->flags & CF_WRITE_ERROR) {			if (msg->err_pos >= 0)				http_capture_bad_message(s->be, &s->be->invalid_rep, s, msg, msg->err_state, sess->fe);			else if (txn->flags & TX_NOT_FIRST)				goto abort_keep_alive;			HA_ATOMIC_ADD(&s->be->be_counters.failed_resp, 1);			rep->analysers &= AN_RES_FLT_END;			channel_auto_close(rep);			if (!(s->flags & SF_ERR_MASK))				s->flags |= SF_ERR_CLICL;			if (!(s->flags & SF_FINST_MASK))				s->flags |= SF_FINST_H;			 			return 0;		}		channel_dont_close(rep);		rep->flags |= CF_READ_DONTWAIT;  		return 0;	}	 	if (unlikely(msg->err_pos >= 0))		http_capture_bad_message(s->be, &s->be->invalid_rep, s, msg, msg->err_state, sess->fe);	 	n = rep->buf->p[msg->sl.st.c] - '0';	if (n < 1 || n > 5)		n = 0;	 	if (n == 4)		stream_inc_http_err_ctr(s);	if (objt_server(s->target))		HA_ATOMIC_ADD(&objt_server(s->target)->counters.p.http.rsp[n], 1);	 	if (!(s->be->options2 & PR_O2_RSPBUG_OK)) {		if (msg->sl.st.v_l != 8) {			msg->err_pos = 0;			goto hdr_response_bad;		}		if (rep->buf->p[4] != '/' ||		    !isdigit((unsigned char)rep->buf->p[5]) ||		    rep->buf->p[6] != '.' ||		    !isdigit((unsigned char)rep->buf->p[7])) {			msg->err_pos = 4;			goto hdr_response_bad;		}	}	 	if ((msg->sl.st.v_l == 8) &&	    ((rep->buf->p[5] > '1') ||	     ((rep->buf->p[5] == '1') && (rep->buf->p[7] >= '1'))))		msg->flags |= HTTP_MSGF_VER_11;	 	txn->flags &= ~(TX_HDR_CONN_PRS|TX_HDR_CONN_CLO|TX_HDR_CONN_KAL|TX_HDR_CONN_UPG|TX_CON_CLO_SET|TX_CON_KAL_SET);	 	msg->flags &= ~HTTP_MSGF_XFER_LEN;	txn->status = strl2ui(rep->buf->p + msg->sl.st.c, msg->sl.st.c_l);	 	if (objt_server(s->target)) {		if (txn->status >= 100 && (txn->status < 500 || txn->status == 501 || txn->status == 505))			health_adjust(objt_server(s->target), HANA_STATUS_HTTP_OK);		else			health_adjust(objt_server(s->target), HANA_STATUS_HTTP_STS);	}	 	if (txn->status < 200 &&	    (txn->status == 100 || txn->status >= 102)) {		hdr_idx_init(&txn->hdr_idx);		msg->next -= channel_forward(rep, msg->next);		msg->msg_state = HTTP_MSG_RPBEFORE;		txn->status = 0;		s->logs.t_data = -1;  		FLT_STRM_CB(s, flt_http_reset(s, msg));		goto next_one;	}	 	switch (txn->status) {	case 200:	case 203:	case 204:	case 206:	case 300:	case 301:	case 404:	case 405:	case 410:	case 414:	case 501:		break;	default:		 		txn->flags &= ~(TX_CACHEABLE | TX_CACHE_COOK);		break;	}	 	s->logs.logwait &= ~LW_RESP;	if (unlikely((s->logs.logwait & LW_RSPHDR) && s->res_cap))		capture_headers(rep->buf->p, &txn->hdr_idx,				s->res_cap, sess->fe->rsp_cap);	 	 	if (unlikely((txn->meth == HTTP_METH_CONNECT && txn->status == 200) ||		     txn->status == 101)) {		 		txn->flags = (txn->flags & ~TX_CON_WANT_MSK) | TX_CON_WANT_TUN;		msg->flags |= HTTP_MSGF_XFER_LEN;		goto end;	}	if (txn->meth == HTTP_METH_HEAD ||	    (txn->status >= 100 && txn->status < 200) ||	    txn->status == 204 || txn->status == 304) {		msg->flags |= HTTP_MSGF_XFER_LEN;		goto skip_content_length;	}	use_close_only = 0;	ctx.idx = 0;	while (http_find_header2(""Transfer-Encoding"", 17, rep->buf->p, &txn->hdr_idx, &ctx)) {		if (ctx.vlen == 7 && strncasecmp(ctx.line + ctx.val, ""chunked"", 7) == 0)			msg->flags |= (HTTP_MSGF_TE_CHNK | HTTP_MSGF_XFER_LEN);		else if (msg->flags & HTTP_MSGF_TE_CHNK) {			 			use_close_only = 1;			msg->flags &= ~(HTTP_MSGF_TE_CHNK | HTTP_MSGF_XFER_LEN);			break;		}	}	 	ctx.idx = 0;	if (use_close_only || (msg->flags & HTTP_MSGF_TE_CHNK)) {		while (http_find_header2(""Content-Length"", 14, rep->buf->p, &txn->hdr_idx, &ctx))			http_remove_header2(msg, &txn->hdr_idx, &ctx);	}	else while (http_find_header2(""Content-Length"", 14, rep->buf->p, &txn->hdr_idx, &ctx)) {		signed long long cl;		if (!ctx.vlen) {			msg->err_pos = ctx.line + ctx.val - rep->buf->p;			goto hdr_response_bad;		}		if (strl2llrc(ctx.line + ctx.val, ctx.vlen, &cl)) {			msg->err_pos = ctx.line + ctx.val - rep->buf->p;			goto hdr_response_bad;  		}		if (cl < 0) {			msg->err_pos = ctx.line + ctx.val - rep->buf->p;			goto hdr_response_bad;		}		if ((msg->flags & HTTP_MSGF_CNT_LEN) && (msg->chunk_len != cl)) {			msg->err_pos = ctx.line + ctx.val - rep->buf->p;			goto hdr_response_bad;  		}		msg->flags |= HTTP_MSGF_CNT_LEN | HTTP_MSGF_XFER_LEN;		msg->body_len = msg->chunk_len = cl;	} skip_content_length:	 	if ((txn->status >= 200) && !(txn->flags & TX_HDR_CONN_PRS) &&	    ((txn->flags & TX_CON_WANT_MSK) != TX_CON_WANT_TUN ||	     ((sess->fe->options & PR_O_HTTP_MODE) == PR_O_HTTP_PCL ||	      (s->be->options & PR_O_HTTP_MODE) == PR_O_HTTP_PCL))) {		int to_del = 0;		 		if ((txn->flags & TX_CON_WANT_MSK) == TX_CON_WANT_KAL &&		    ((sess->fe->options & PR_O_HTTP_MODE) == PR_O_HTTP_PCL ||		     (s->be->options & PR_O_HTTP_MODE) == PR_O_HTTP_PCL))			txn->flags = (txn->flags & ~TX_CON_WANT_MSK) | TX_CON_WANT_CLO;		 		if (!(msg->flags & HTTP_MSGF_XFER_LEN) &&		    (txn->flags & TX_CON_WANT_MSK) != TX_CON_WANT_TUN)			txn->flags = (txn->flags & ~TX_CON_WANT_MSK) | TX_CON_WANT_CLO;		 		if ((txn->flags & TX_CON_WANT_MSK) == TX_CON_WANT_TUN ||		    (txn->flags & TX_CON_WANT_MSK) == TX_CON_WANT_CLO) {			to_del |= 2;  			if (!(msg->flags & HTTP_MSGF_VER_11))				to_del |= 1;  		}		else {  			to_del |= 1;  			if (txn->req.flags & msg->flags & HTTP_MSGF_VER_11)				to_del |= 2;  		}		 		http_parse_connection_header(txn, msg, to_del);		 		if ((txn->flags & TX_CON_WANT_MSK) == TX_CON_WANT_KAL) {			if ((txn->flags & TX_HDR_CONN_CLO) ||			    (!(txn->flags & TX_HDR_CONN_KAL) && !(msg->flags & HTTP_MSGF_VER_11)))				txn->flags = (txn->flags & ~TX_CON_WANT_MSK) | TX_CON_WANT_SCL;		}	} end:	 	s->logs.t_data = tv_ms_elapsed(&s->logs.tv_accept, &now);	 	rep->analysers &= ~an_bit;	rep->analyse_exp = TICK_ETERNITY;	channel_auto_close(rep);	return 1; abort_keep_alive:	 	txn->status = 0;	rep->analysers   &= AN_RES_FLT_END;	s->req.analysers &= AN_REQ_FLT_END;	channel_auto_close(rep);	s->logs.logwait = 0;	s->logs.level = 0;	s->res.flags &= ~CF_EXPECT_MORE;  	channel_truncate(rep);	http_reply_and_close(s, txn->status, NULL);	return 0;}",1104
140,705,CVE-2012-6540,22,"static int ip_vs_stats_seq_open(struct inode *inode, struct file *file){	return single_open_net(inode, file, ip_vs_stats_show);}",9892
206,357,CVE-2013-3236,22,static void vmci_transport_release(struct vsock_sock *vsk){	if (!vmci_handle_is_invalid(vmci_trans(vsk)->dg_handle)) {		vmci_datagram_destroy_handle(vmci_trans(vsk)->dg_handle);		vmci_trans(vsk)->dg_handle = VMCI_INVALID_HANDLE;	}},8200
53,1729,CVE-2017-5011,22,    DocumentOnLoadCompletedInMainFrame() {  devtools_bindings_->DocumentOnLoadCompletedInMainFrame();},29907
246,296,CVE-2013-4516,22,"static int sb1054_set_register(struct sb_uart_port *port, int page, int reg, int value){  	int lcr = 0;	int mcr = 0;	int ret = 0;	if( page <= 0)	{		printk("" page 0 can not use this fuction\n"");		return -1;	}	switch(page)	{		case 1:			lcr = SB105X_GET_LCR(port);			SB105X_PUT_LCR(port, lcr | SB105X_LCR_DLAB);			SB105X_PUT_REG(port,reg,value);			SB105X_PUT_LCR(port, lcr);			ret = 1;			break;		case 2:			mcr = SB105X_GET_MCR(port);			SB105X_PUT_MCR(port, mcr | SB105X_MCR_P2S);			SB105X_PUT_REG(port,reg,value);			SB105X_PUT_MCR(port, mcr);			ret = 1;			break;		case 3:			lcr = SB105X_GET_LCR(port);			SB105X_PUT_LCR(port, lcr | SB105X_LCR_BF);			SB105X_PUT_PSR(port, SB105X_PSR_P3KEY);			SB105X_PUT_REG(port,reg,value);			SB105X_PUT_LCR(port, lcr);			ret = 1;			break;		case 4:			lcr = SB105X_GET_LCR(port);			SB105X_PUT_LCR(port, lcr | SB105X_LCR_BF);			SB105X_PUT_PSR(port, SB105X_PSR_P4KEY);			SB105X_PUT_REG(port,reg,value);			SB105X_PUT_LCR(port, lcr);			ret = 1;			break;		default:			printk("" error invalid page number \n"");			return -1;	}	return ret;}",7734
124,1618,CVE-2019-10639,22,static int rtnl_net_get_size(void){	return NLMSG_ALIGN(sizeof(struct rtgenmsg))	       + nla_total_size(sizeof(s32))  	       + nla_total_size(sizeof(s32))  	       ;},27185
196,1625,CVE-2019-10639,22,void unregister_pernet_subsys(struct pernet_operations *ops){	down_write(&pernet_ops_rwsem);	unregister_pernet_operations(ops);	up_write(&pernet_ops_rwsem);},27192
376,1704,CVE-2015-1870,22, void free_abrt_conf_data() {    free(g_settings_sWatchCrashdumpArchiveDir);    g_settings_sWatchCrashdumpArchiveDir = NULL;    free(g_settings_dump_location);    g_settings_dump_location = NULL;},28849
71,925,CVE-2015-5697,22,"static int md_set_readonly(struct mddev *mddev, struct block_device *bdev){	int err = 0;	int did_freeze = 0;	if (!test_bit(MD_RECOVERY_FROZEN, &mddev->recovery)) {		did_freeze = 1;		set_bit(MD_RECOVERY_FROZEN, &mddev->recovery);		md_wakeup_thread(mddev->thread);	}	if (test_bit(MD_RECOVERY_RUNNING, &mddev->recovery))		set_bit(MD_RECOVERY_INTR, &mddev->recovery);	if (mddev->sync_thread)		 		wake_up_process(mddev->sync_thread->tsk);	mddev_unlock(mddev);	wait_event(resync_wait, !test_bit(MD_RECOVERY_RUNNING,					  &mddev->recovery));	mddev_lock_nointr(mddev);	mutex_lock(&mddev->open_mutex);	if ((mddev->pers && atomic_read(&mddev->openers) > !!bdev) ||	    mddev->sync_thread ||	    test_bit(MD_RECOVERY_RUNNING, &mddev->recovery) ||	    (bdev && !test_bit(MD_STILL_CLOSED, &mddev->flags))) {		printk(""md: %s still in use.\n"",mdname(mddev));		if (did_freeze) {			clear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);			set_bit(MD_RECOVERY_NEEDED, &mddev->recovery);			md_wakeup_thread(mddev->thread);		}		err = -EBUSY;		goto out;	}	if (mddev->pers) {		__md_stop_writes(mddev);		err  = -ENXIO;		if (mddev->ro==1)			goto out;		mddev->ro = 1;		set_disk_ro(mddev->gendisk, 1);		clear_bit(MD_RECOVERY_FROZEN, &mddev->recovery);		set_bit(MD_RECOVERY_NEEDED, &mddev->recovery);		md_wakeup_thread(mddev->thread);		sysfs_notify_dirent_safe(mddev->sysfs_state);		err = 0;	}out:	mutex_unlock(&mddev->open_mutex);	return err;}",13255
404,505,CVE-2013-3226,22,"static int sco_sock_accept(struct socket *sock, struct socket *newsock, int flags){	DECLARE_WAITQUEUE(wait, current);	struct sock *sk = sock->sk, *ch;	long timeo;	int err = 0;	lock_sock(sk);	timeo = sock_rcvtimeo(sk, flags & O_NONBLOCK);	BT_DBG(""sk %p timeo %ld"", sk, timeo);	 	add_wait_queue_exclusive(sk_sleep(sk), &wait);	while (1) {		set_current_state(TASK_INTERRUPTIBLE);		if (sk->sk_state != BT_LISTEN) {			err = -EBADFD;			break;		}		ch = bt_accept_dequeue(sk, newsock);		if (ch)			break;		if (!timeo) {			err = -EAGAIN;			break;		}		if (signal_pending(current)) {			err = sock_intr_errno(timeo);			break;		}		release_sock(sk);		timeo = schedule_timeout(timeo);		lock_sock(sk);	}	__set_current_state(TASK_RUNNING);	remove_wait_queue(sk_sleep(sk), &wait);	if (err)		goto done;	newsock->state = SS_CONNECTED;	BT_DBG(""new socket %p"", ch);done:	release_sock(sk);	return err;}",8348
232,642,CVE-2013-0349,22,"static void hidp_set_timer(struct hidp_session *session){	if (session->idle_to > 0)		mod_timer(&session->timer, jiffies + HZ * session->idle_to);}",9715
387,100,CVE-2018-11469,22,"void init_proto_http(){	int i;	char *tmp;	int msg;	for (msg = 0; msg < HTTP_ERR_SIZE; msg++) {		if (!http_err_msgs[msg]) {			ha_alert(""Internal error: no message defined for HTTP return code %d. Aborting.\n"", msg);			abort();		}		http_err_chunks[msg].str = (char *)http_err_msgs[msg];		http_err_chunks[msg].len = strlen(http_err_msgs[msg]);	}	 	memset(hdr_encode_map, 0, sizeof(hdr_encode_map));	memset(url_encode_map, 0, sizeof(url_encode_map));	memset(http_encode_map, 0, sizeof(url_encode_map));	for (i = 0; i < 32; i++) {		FD_SET(i, hdr_encode_map);		FD_SET(i, url_encode_map);	}	for (i = 127; i < 256; i++) {		FD_SET(i, hdr_encode_map);		FD_SET(i, url_encode_map);	}	tmp = ""\""#{|}"";	while (*tmp) {		FD_SET(*tmp, hdr_encode_map);		tmp++;	}	tmp = ""\""#"";	while (*tmp) {		FD_SET(*tmp, url_encode_map);		tmp++;	}	 	memset(http_encode_map, 0, sizeof(http_encode_map));	for (i = 0x00; i <= 0x08; i++)		FD_SET(i, http_encode_map);	for (i = 0x0a; i <= 0x1f; i++)		FD_SET(i, http_encode_map);	FD_SET(0x7f, http_encode_map);	 	pool_head_http_txn = create_pool(""http_txn"", sizeof(struct http_txn), MEM_F_SHARED);	pool_head_uniqueid = create_pool(""uniqueid"", UNIQUEID_LEN, MEM_F_SHARED);}",1105
110,1270,CVE-2015-8964,22,"tty_ldisc_lock_pair(struct tty_struct *tty, struct tty_struct *tty2){	tty_ldisc_lock_pair_timeout(tty, tty2, MAX_SCHEDULE_TIMEOUT);}",18309
329,656,CVE-2012-6547,22,"static int run_filter(struct tap_filter *filter, const struct sk_buff *skb){	 	struct ethhdr *eh = (struct ethhdr *) skb->data;	int i;	 	for (i = 0; i < filter->count; i++)		if (ether_addr_equal(eh->h_dest, filter->addr[i]))			return 1;	 	if (is_multicast_ether_addr(eh->h_dest))		return addr_hash_test(filter->mask, eh->h_dest);	return 0;}",9843
412,1728,CVE-2017-5011,22,    DocumentAvailableInMainFrame() {  devtools_bindings_->DocumentAvailableInMainFrame();},29906
220,570,CVE-2013-3076,22,"static void hash_sock_destruct(struct sock *sk){	struct alg_sock *ask = alg_sk(sk);	struct hash_ctx *ctx = ask->private;	sock_kfree_s(sk, ctx->result,		     crypto_ahash_digestsize(crypto_ahash_reqtfm(&ctx->req)));	sock_kfree_s(sk, ctx, ctx->len);	af_alg_release_parent(sk);}",8413
182,1565,CVE-2018-15594,22,"void paravirt_end_context_switch(struct task_struct *next){	BUG_ON(preemptible());	leave_lazy(PARAVIRT_LAZY_CPU);	if (test_and_clear_ti_thread_flag(task_thread_info(next), TIF_LAZY_MMU_UPDATES))		arch_enter_lazy_mmu_mode();}",24415
399,847,CVE-2015-8374,22,"static int btrfs_insert_inode_locked(struct inode *inode){	struct btrfs_iget_args args;	args.location = &BTRFS_I(inode)->location;	args.root = BTRFS_I(inode)->root;	return insert_inode_locked4(inode,		   btrfs_inode_hash(inode->i_ino, BTRFS_I(inode)->root),		   btrfs_find_actor, &args);}",12930
189,698,CVE-2012-6540,22,"static int ip_vs_genl_set_cmd(struct sk_buff *skb, struct genl_info *info){	struct ip_vs_service *svc = NULL;	struct ip_vs_service_user_kern usvc;	struct ip_vs_dest_user_kern udest;	int ret = 0, cmd;	int need_full_svc = 0, need_full_dest = 0;	struct net *net;	net = skb_sknet(skb);	cmd = info->genlhdr->cmd;	mutex_lock(&__ip_vs_mutex);	if (cmd == IPVS_CMD_FLUSH) {		ret = ip_vs_flush(net);		goto out;	} else if (cmd == IPVS_CMD_SET_CONFIG) {		ret = ip_vs_genl_set_config(net, info->attrs);		goto out;	} else if (cmd == IPVS_CMD_ZERO &&		   !info->attrs[IPVS_CMD_ATTR_SERVICE]) {		ret = ip_vs_zero_all(net);		goto out;	}	 	if (cmd == IPVS_CMD_NEW_SERVICE || cmd == IPVS_CMD_SET_SERVICE)		need_full_svc = 1;	ret = ip_vs_genl_parse_service(net, &usvc,				       info->attrs[IPVS_CMD_ATTR_SERVICE],				       need_full_svc, &svc);	if (ret)		goto out;	 	if ((cmd != IPVS_CMD_NEW_SERVICE) && (svc == NULL)) {		ret = -ESRCH;		goto out;	}	 	if (cmd == IPVS_CMD_NEW_DEST || cmd == IPVS_CMD_SET_DEST ||	    cmd == IPVS_CMD_DEL_DEST) {		if (cmd != IPVS_CMD_DEL_DEST)			need_full_dest = 1;		ret = ip_vs_genl_parse_dest(&udest,					    info->attrs[IPVS_CMD_ATTR_DEST],					    need_full_dest);		if (ret)			goto out;	}	switch (cmd) {	case IPVS_CMD_NEW_SERVICE:		if (svc == NULL)			ret = ip_vs_add_service(net, &usvc, &svc);		else			ret = -EEXIST;		break;	case IPVS_CMD_SET_SERVICE:		ret = ip_vs_edit_service(svc, &usvc);		break;	case IPVS_CMD_DEL_SERVICE:		ret = ip_vs_del_service(svc);		 		break;	case IPVS_CMD_NEW_DEST:		ret = ip_vs_add_dest(svc, &udest);		break;	case IPVS_CMD_SET_DEST:		ret = ip_vs_edit_dest(svc, &udest);		break;	case IPVS_CMD_DEL_DEST:		ret = ip_vs_del_dest(svc, &udest);		break;	case IPVS_CMD_ZERO:		ret = ip_vs_zero_service(svc);		break;	default:		ret = -EINVAL;	}out:	mutex_unlock(&__ip_vs_mutex);	return ret;}",9885
58,516,CVE-2013-3225,22,static void rfcomm_sock_close(struct sock *sk){	lock_sock(sk);	__rfcomm_sock_close(sk);	release_sock(sk);},8359
369,1157,CVE-2016-4486,22,"static int rtnl_dellink(struct sk_buff *skb, struct nlmsghdr *nlh){	struct net *net = sock_net(skb->sk);	struct net_device *dev;	struct ifinfomsg *ifm;	char ifname[IFNAMSIZ];	struct nlattr *tb[IFLA_MAX+1];	int err;	err = nlmsg_parse(nlh, sizeof(*ifm), tb, IFLA_MAX, ifla_policy);	if (err < 0)		return err;	if (tb[IFLA_IFNAME])		nla_strlcpy(ifname, tb[IFLA_IFNAME], IFNAMSIZ);	ifm = nlmsg_data(nlh);	if (ifm->ifi_index > 0)		dev = __dev_get_by_index(net, ifm->ifi_index);	else if (tb[IFLA_IFNAME])		dev = __dev_get_by_name(net, ifname);	else if (tb[IFLA_GROUP])		return rtnl_group_dellink(net, nla_get_u32(tb[IFLA_GROUP]));	else		return -EINVAL;	if (!dev)		return -ENODEV;	return rtnl_delete_link(dev);}",16910
380,822,CVE-2011-2909,22,"static int resize_async_buffer(struct comedi_device *dev,			       struct comedi_subdevice *s,			       struct comedi_async *async, unsigned new_size){	int retval;	if (new_size > async->max_bufsize)		return -EPERM;	if (s->busy) {		DPRINTK(""subdevice is busy, cannot resize buffer\n"");		return -EBUSY;	}	if (async->mmap_count) {		DPRINTK(""subdevice is mmapped, cannot resize buffer\n"");		return -EBUSY;	}	if (!async->prealloc_buf)		return -EINVAL;	 	new_size = (new_size + PAGE_SIZE - 1) & PAGE_MASK;	retval = comedi_buf_alloc(dev, s, new_size);	if (retval < 0)		return retval;	if (s->buf_change) {		retval = s->buf_change(dev, s, new_size);		if (retval < 0)			return retval;	}	DPRINTK(""comedi%i subd %d buffer resized to %i bytes\n"",		dev->minor, (int)(s - dev->subdevices), async->prealloc_bufsz);	return 0;}",12783
375,1783,CVE-2016-3835,22,"inline const char* hiermode_string(int val){ switch(val) { case HIER_NONE: return ""No Hier""; case HIER_P: return ""Hier-P""; case HIER_B: return ""Hier-B""; case HIER_P_HYBRID: return ""Hybrid Hier-P""; default: return ""No hier""; }}",30499
131,1442,CVE-2017-9150,22,"static int check_call(struct bpf_verifier_env *env, int func_id, int insn_idx){	struct bpf_verifier_state *state = &env->cur_state;	const struct bpf_func_proto *fn = NULL;	struct bpf_reg_state *regs = state->regs;	struct bpf_reg_state *reg;	struct bpf_call_arg_meta meta;	int changes_data;	int i, err;	 	if (func_id < 0 || func_id >= __BPF_FUNC_MAX_ID) {		verbose(""invalid func %s#%d\n"", func_id_name(func_id), func_id);		return -EINVAL;	}	if (env->prog->aux->ops->get_func_proto)		fn = env->prog->aux->ops->get_func_proto(func_id);	if (!fn) {		verbose(""unknown func %s#%d\n"", func_id_name(func_id), func_id);		return -EINVAL;	}	 	if (!env->prog->gpl_compatible && fn->gpl_only) {		verbose(""cannot call GPL only function from proprietary program\n"");		return -EINVAL;	}	changes_data = bpf_helper_changes_pkt_data(fn->func);	memset(&meta, 0, sizeof(meta));	meta.pkt_access = fn->pkt_access;	 	err = check_raw_mode(fn);	if (err) {		verbose(""kernel subsystem misconfigured func %s#%d\n"",			func_id_name(func_id), func_id);		return err;	}	 	err = check_func_arg(env, BPF_REG_1, fn->arg1_type, &meta);	if (err)		return err;	err = check_func_arg(env, BPF_REG_2, fn->arg2_type, &meta);	if (err)		return err;	err = check_func_arg(env, BPF_REG_3, fn->arg3_type, &meta);	if (err)		return err;	err = check_func_arg(env, BPF_REG_4, fn->arg4_type, &meta);	if (err)		return err;	err = check_func_arg(env, BPF_REG_5, fn->arg5_type, &meta);	if (err)		return err;	 	for (i = 0; i < meta.access_size; i++) {		err = check_mem_access(env, meta.regno, i, BPF_B, BPF_WRITE, -1);		if (err)			return err;	}	 	for (i = 0; i < CALLER_SAVED_REGS; i++) {		reg = regs + caller_saved[i];		reg->type = NOT_INIT;		reg->imm = 0;	}	 	if (fn->ret_type == RET_INTEGER) {		regs[BPF_REG_0].type = UNKNOWN_VALUE;	} else if (fn->ret_type == RET_VOID) {		regs[BPF_REG_0].type = NOT_INIT;	} else if (fn->ret_type == RET_PTR_TO_MAP_VALUE_OR_NULL) {		struct bpf_insn_aux_data *insn_aux;		regs[BPF_REG_0].type = PTR_TO_MAP_VALUE_OR_NULL;		regs[BPF_REG_0].max_value = regs[BPF_REG_0].min_value = 0;		 		if (meta.map_ptr == NULL) {			verbose(""kernel subsystem misconfigured verifier\n"");			return -EINVAL;		}		regs[BPF_REG_0].map_ptr = meta.map_ptr;		regs[BPF_REG_0].id = ++env->id_gen;		insn_aux = &env->insn_aux_data[insn_idx];		if (!insn_aux->map_ptr)			insn_aux->map_ptr = meta.map_ptr;		else if (insn_aux->map_ptr != meta.map_ptr)			insn_aux->map_ptr = BPF_MAP_PTR_POISON;	} else {		verbose(""unknown return type %d of func %s#%d\n"",			fn->ret_type, func_id_name(func_id), func_id);		return -EINVAL;	}	err = check_map_func_compatibility(meta.map_ptr, func_id);	if (err)		return err;	if (changes_data)		clear_all_pkt_pointers(env);	return 0;}",20827
188,169,CVE-2016-4020,22,static void vapic_register(void){    type_register_static(&vapic_type);},1956
322,1154,CVE-2016-4486,22,"int rtnl_configure_link(struct net_device *dev, const struct ifinfomsg *ifm){	unsigned int old_flags;	int err;	old_flags = dev->flags;	if (ifm && (ifm->ifi_flags || ifm->ifi_change)) {		err = __dev_change_flags(dev, rtnl_dev_combine_flags(dev, ifm));		if (err < 0)			return err;	}	dev->rtnl_link_state = RTNL_LINK_INITIALIZED;	__dev_notify_flags(dev, old_flags, ~0U);	return 0;}",16907
331,1397,CVE-2017-14954,22,"static int *task_stopped_code(struct task_struct *p, int ptrace){	if (ptrace) {		if (task_is_traced(p) && !(p->jobctl & JOBCTL_LISTENING))			return &p->exit_code;	} else {		if (p->signal->flags & SIGNAL_STOP_STOPPED)			return &p->signal->group_exit_code;	}	return NULL;}",20112
275,1513,CVE-2018-18710,22,"static int cdrom_ioctl_audioctl(struct cdrom_device_info *cdi,		unsigned int cmd){	int ret;	cd_dbg(CD_DO_IOCTL, ""doing audio ioctl (start/stop/pause/resume)\n"");	if (!CDROM_CAN(CDC_PLAY_AUDIO))		return -ENOSYS;	ret = check_for_audio_disc(cdi, cdi->ops);	if (ret)		return ret;	return cdi->ops->audio_ioctl(cdi, cmd, NULL);}",23430
173,504,CVE-2013-3226,22,"static int sco_send_frame(struct sock *sk, struct msghdr *msg, int len){	struct sco_conn *conn = sco_pi(sk)->conn;	struct sk_buff *skb;	int err;	 	if (len > conn->mtu)		return -EINVAL;	BT_DBG(""sk %p len %d"", sk, len);	skb = bt_skb_send_alloc(sk, len, msg->msg_flags & MSG_DONTWAIT, &err);	if (!skb)		return err;	if (memcpy_fromiovec(skb_put(skb, len), msg->msg_iov, len)) {		kfree_skb(skb);		return -EFAULT;	}	hci_send_sco(conn->hcon, skb);	return len;}",8347
177,1474,CVE-2017-5550,22,static inline int allocated(struct pipe_buffer *buf){	return buf->ops == &default_pipe_buf_ops;},22027
323,136,CVE-2018-11469,22,"smp_fetch_hdrs_bin(const struct arg *args, struct sample *smp, const char *kw, void *private){	struct http_msg *msg;	struct chunk *temp;	struct hdr_idx *idx;	const char *cur_ptr, *cur_next, *p;	int old_idx, cur_idx;	struct hdr_idx_elem *cur_hdr;	const char *hn, *hv;	int hnl, hvl;	int ret;	struct http_txn *txn;	char *buf;	char *end;	CHECK_HTTP_MESSAGE_FIRST();	temp = get_trash_chunk();	buf = temp->str;	end = temp->str + temp->size;	txn = smp->strm->txn;	idx = &txn->hdr_idx;	msg = &txn->req;	 	old_idx = 0;	cur_next = msg->chn->buf->p + hdr_idx_first_pos(idx);	while (1) {		cur_idx = idx->v[old_idx].next;		if (!cur_idx)			break;		old_idx = cur_idx;		cur_hdr  = &idx->v[cur_idx];		cur_ptr  = cur_next;		cur_next = cur_ptr + cur_hdr->len + cur_hdr->cr + 1;		 		 		hn = cur_ptr;		for (p = cur_ptr; p < cur_ptr + cur_hdr->len && *p != ':'; p++);		if (p >= cur_ptr+cur_hdr->len)			continue;		hnl = p - hn;		p++;		while (p < cur_ptr + cur_hdr->len && (*p == ' ' || *p == '\t'))			p++;		if (p >= cur_ptr + cur_hdr->len)			continue;		hv = p;		hvl = cur_ptr + cur_hdr->len-p;		 		ret = encode_varint(hnl, &buf, end);		if (ret == -1)			return 0;		if (buf + hnl > end)			return 0;		memcpy(buf, hn, hnl);		buf += hnl;		 		ret = encode_varint(hvl, &buf, end);		if (ret == -1)			return 0;		if (buf + hvl > end)			return 0;		memcpy(buf, hv, hvl);		buf += hvl;	}	 	ret = encode_varint(0, &buf, end);	if (ret == -1)		return 0;	ret = encode_varint(0, &buf, end);	if (ret == -1)		return 0;	 	smp->data.type = SMP_T_BIN;	smp->data.u.str.str = temp->str;	smp->data.u.str.len = buf - temp->str;	smp->data.u.str.size = temp->size;	return 1;}",1141
163,360,CVE-2013-3236,22,"static int vmci_transport_send_attach(struct sock *sk,				      struct vmci_handle handle){	return vmci_transport_send_control_pkt(					sk, VMCI_TRANSPORT_PACKET_TYPE_ATTACH,					0, 0, NULL, VSOCK_PROTO_INVALID,					handle);}",8203
209,1486,CVE-2017-0377,22,"get_meaningful_restriction_threshold(void){  int pct = networkstatus_get_param(NULL,                                        ""guard-meaningful-restriction-percent"",                                        DFLT_MEANINGFUL_RESTRICTION_PERCENT,                                        1, INT32_MAX);  return pct / 100.0;}",22249
355,525,CVE-2013-3224,22,"void bt_accept_enqueue(struct sock *parent, struct sock *sk){	BT_DBG(""parent %p, sk %p"", parent, sk);	sock_hold(sk);	list_add_tail(&bt_sk(sk)->accept_q, &bt_sk(parent)->accept_q);	bt_sk(sk)->parent = parent;	parent->sk_ack_backlog++;}",8368
293,443,CVE-2013-3229,22,"static int afiucv_hs_callback_synack(struct sock *sk, struct sk_buff *skb){	struct iucv_sock *iucv = iucv_sk(sk);	struct af_iucv_trans_hdr *trans_hdr =					(struct af_iucv_trans_hdr *)skb->data;	if (!iucv)		goto out;	if (sk->sk_state != IUCV_BOUND)		goto out;	bh_lock_sock(sk);	iucv->msglimit_peer = trans_hdr->window;	sk->sk_state = IUCV_CONNECTED;	sk->sk_state_change(sk);	bh_unlock_sock(sk);out:	kfree_skb(skb);	return NET_RX_SUCCESS;}",8286
146,293,CVE-2013-4516,22,"static int multi_verify_port(struct sb_uart_port *port, struct serial_struct *ser){	if (ser->irq >= NR_IRQS || ser->irq < 0 ||			ser->baud_base < 9600 || ser->type < PORT_UNKNOWN ||			ser->type == PORT_STARTECH)		return -EINVAL;	return 0;}",7731
68,1376,CVE-2017-16994,22,"static int walk_pgd_range(unsigned long addr, unsigned long end,			  struct mm_walk *walk){	pgd_t *pgd;	unsigned long next;	int err = 0;	pgd = pgd_offset(walk->mm, addr);	do {		next = pgd_addr_end(addr, end);		if (pgd_none_or_clear_bad(pgd)) {			if (walk->pte_hole)				err = walk->pte_hole(addr, next, walk);			if (err)				break;			continue;		}		if (walk->pmd_entry || walk->pte_entry)			err = walk_p4d_range(pgd, addr, next, walk);		if (err)			break;	} while (pgd++, addr = next, addr != end);	return err;}",19613
450,414,CVE-2013-3232,22,"static void nr_set_lockdep_key(struct net_device *dev){	lockdep_set_class(&dev->addr_list_lock, &nr_netdev_addr_lock_key);	netdev_for_each_tx_queue(dev, nr_set_lockdep_one, NULL);}",8257
216,810,CVE-2011-2909,22,"void comedi_free_board_minor(unsigned minor){	unsigned long flags;	struct comedi_device_file_info *info;	BUG_ON(minor >= COMEDI_NUM_BOARD_MINORS);	spin_lock_irqsave(&comedi_file_info_table_lock, flags);	info = comedi_file_info_table[minor];	comedi_file_info_table[minor] = NULL;	spin_unlock_irqrestore(&comedi_file_info_table_lock, flags);	if (info) {		struct comedi_device *dev = info->device;		if (dev) {			if (dev->class_dev) {				device_destroy(comedi_class,					       MKDEV(COMEDI_MAJOR, dev->minor));			}			comedi_device_cleanup(dev);			kfree(dev);		}		kfree(info);	}}",12771
201,879,CVE-2015-7884,22,void vivid_fb_release_buffers(struct vivid_dev *dev){	if (dev->video_vbase == NULL)		return;	 	if (dev->fb_info.cmap.len)		fb_dealloc_cmap(&dev->fb_info.cmap);	 	kfree(dev->fb_info.pseudo_palette);	kfree((void *)dev->video_vbase);},13056
132,1236,CVE-2016-0823,22,"static int pid_maps_open(struct inode *inode, struct file *file){	return do_maps_open(inode, file, &proc_pid_maps_op);}",18198
5,1635,CVE-2019-6976,22,vips_tracked_get_allocs( void ){	int n;	vips_tracked_init(); 	g_mutex_lock( vips_tracked_mutex );	n = vips_tracked_allocs;	g_mutex_unlock( vips_tracked_mutex );	return( n );},27356
153,1260,CVE-2015-8964,22,"void tty_ldisc_begin(void){	 	(void) tty_register_ldisc(N_TTY, &tty_ldisc_N_TTY);}",18299
193,923,CVE-2015-5697,22,"static int md_seq_open(struct inode *inode, struct file *file){	struct seq_file *seq;	int error;	error = seq_open(file, &md_seq_ops);	if (error)		return error;	seq = file->private_data;	seq->poll_event = atomic_read(&md_event_count);	return error;}",13253
119,891,CVE-2015-5697,22,"degraded_show(struct mddev *mddev, char *page){	return sprintf(page, ""%d\n"", mddev->degraded);}",13221
74,1140,CVE-2016-4486,22,"int __rtnl_link_register(struct rtnl_link_ops *ops){	if (rtnl_link_ops_get(ops->kind))		return -EEXIST;	 	if (ops->setup && !ops->dellink)		ops->dellink = unregister_netdevice_queue;	list_add_tail(&ops->list, &link_ops);	return 0;}",16893
22,370,CVE-2013-3236,22,"int vmci_transport_send_wrote_bh(struct sockaddr_vm *dst,				 struct sockaddr_vm *src){	return vmci_transport_send_control_pkt_bh(					dst, src,					VMCI_TRANSPORT_PACKET_TYPE_WROTE, 0,					0, NULL, VMCI_INVALID_HANDLE);}",8213
19,112,CVE-2018-11469,22,"static int smp_conv_res_capture(const struct arg *args, struct sample *smp, void *private){	struct proxy *fe = strm_fe(smp->strm);	int idx, i;	struct cap_hdr *hdr;	int len;	if (!args || args->type != ARGT_SINT)		return 0;	idx = args->data.sint;	 	if (idx > fe->nb_rsp_cap - 1)		return 0;	 	for (hdr = fe->rsp_cap, i = fe->nb_rsp_cap - 1;	     hdr != NULL && i != idx ;	     i--, hdr = hdr->next);	if (!hdr)		return 0;	 	if (smp->strm->res_cap[hdr->index] == NULL)		smp->strm->res_cap[hdr->index] = pool_alloc(hdr->pool);	if (smp->strm->res_cap[hdr->index] == NULL)		return 0;	 	len = smp->data.u.str.len;	if (len > hdr->len)		len = hdr->len;	 	memcpy(smp->strm->res_cap[idx], smp->data.u.str.str, len);	smp->strm->res_cap[idx][len] = '\0';	return 1;}",1117
330,260,CVE-2013-4516,22,"static void mp_tasklet_action(unsigned long data){	struct sb_uart_state *state = (struct sb_uart_state *)data;	struct tty_struct *tty;	printk(""tasklet is called!\n"");	tty = state->info->tty;	tty_wakeup(tty);}",7698
115,1726,CVE-2016-1614,22,  void set_device_scale_factor(float device_scale_factor) {    device_scale_factor_ = device_scale_factor;  },29772
352,428,CVE-2013-3231,22,"static void llc_ui_sk_init(struct socket *sock, struct sock *sk){	sock_graft(sk, sock);	sk->sk_type	= sock->type;	sock->ops	= &llc_ui_ops;}",8271
31,797,CVE-2013-7281,22,"static int l2tp_ip_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len){	struct sockaddr_l2tpip *lsa = (struct sockaddr_l2tpip *) uaddr;	int rc;	if (sock_flag(sk, SOCK_ZAPPED))  		return -EINVAL;	if (addr_len < sizeof(*lsa))		return -EINVAL;	if (ipv4_is_multicast(lsa->l2tp_addr.s_addr))		return -EINVAL;	rc = ip4_datagram_connect(sk, uaddr, addr_len);	if (rc < 0)		return rc;	lock_sock(sk);	l2tp_ip_sk(sk)->peer_conn_id = lsa->l2tp_conn_id;	write_lock_bh(&l2tp_ip_lock);	hlist_del_init(&sk->sk_bind_node);	sk_add_bind_node(sk, &l2tp_ip_bind_table);	write_unlock_bh(&l2tp_ip_lock);	release_sock(sk);	return rc;}",12355
265,853,CVE-2015-8374,22,"static int btrfs_rmdir(struct inode *dir, struct dentry *dentry){	struct inode *inode = d_inode(dentry);	int err = 0;	struct btrfs_root *root = BTRFS_I(dir)->root;	struct btrfs_trans_handle *trans;	if (inode->i_size > BTRFS_EMPTY_DIR_SIZE)		return -ENOTEMPTY;	if (btrfs_ino(inode) == BTRFS_FIRST_FREE_OBJECTID)		return -EPERM;	trans = __unlink_start_trans(dir);	if (IS_ERR(trans))		return PTR_ERR(trans);	if (unlikely(btrfs_ino(inode) == BTRFS_EMPTY_SUBVOL_DIR_OBJECTID)) {		err = btrfs_unlink_subvol(trans, root, dir,					  BTRFS_I(inode)->location.objectid,					  dentry->d_name.name,					  dentry->d_name.len);		goto out;	}	err = btrfs_orphan_add(trans, inode);	if (err)		goto out;	 	err = btrfs_unlink_inode(trans, root, dir, d_inode(dentry),				 dentry->d_name.name, dentry->d_name.len);	if (!err)		btrfs_i_size_write(inode, 0);out:	btrfs_end_transaction(trans, root);	btrfs_btree_balance_dirty(root);	return err;}",12936
234,1724,CVE-2012-2891,22,   PrintPreviewRequestIdMapWithLock() {},29201
105,550,CVE-2013-3222,22,"static int adjust_tp(struct atm_trafprm *tp, unsigned char aal){	int max_sdu;	if (!tp->traffic_class)		return 0;	switch (aal) {	case ATM_AAL0:		max_sdu = ATM_CELL_SIZE-1;		break;	case ATM_AAL34:		max_sdu = ATM_MAX_AAL34_PDU;		break;	default:		pr_warning(""AAL problems ... (%d)\n"", aal);		 	case ATM_AAL5:		max_sdu = ATM_MAX_AAL5_PDU;	}	if (!tp->max_sdu)		tp->max_sdu = max_sdu;	else if (tp->max_sdu > max_sdu)		return -EINVAL;	if (!tp->max_cdv)		tp->max_cdv = ATM_MAX_CDV;	return 0;}",8393
405,1026,CVE-2016-5696,22,"static void tcp_ecn_rcv_synack(struct tcp_sock *tp, const struct tcphdr *th){	if ((tp->ecn_flags & TCP_ECN_OK) && (!th->ece || th->cwr))		tp->ecn_flags &= ~TCP_ECN_OK;}",16402
306,157,CVE-2018-11469,22,"int val_hdr(struct arg *arg, char **err_msg){	if (arg && arg[1].type == ARGT_SINT && arg[1].data.sint < -MAX_HDR_HISTORY) {		memprintf(err_msg, ""header occurrence must be >= %d"", -MAX_HDR_HISTORY);		return 0;	}	return 1;}",1162
353,1338,CVE-2014-9903,22,"static void sched_domains_numa_masks_set(int cpu){	int i, j;	int node = cpu_to_node(cpu);	for (i = 0; i < sched_domains_numa_levels; i++) {		for (j = 0; j < nr_node_ids; j++) {			if (node_distance(j, node) <= sched_domains_numa_distance[i])				cpumask_set_cpu(cpu, sched_domains_numa_masks[i][j]);		}	}}",19275
183,1102,CVE-2016-4578,22,"int snd_timer_continue(struct snd_timer_instance *timeri){	if (timeri->flags & SNDRV_TIMER_IFLG_SLAVE)		return snd_timer_start_slave(timeri, false);	else		return snd_timer_start1(timeri, false, 0);}",16690
194,942,CVE-2015-5697,22,"void mddev_suspend(struct mddev *mddev){	BUG_ON(mddev->suspended);	mddev->suspended = 1;	synchronize_rcu();	wait_event(mddev->sb_wait, atomic_read(&mddev->active_io) == 0);	mddev->pers->quiesce(mddev, 1);	del_timer_sync(&mddev->safemode_timer);}",13272
169,680,CVE-2012-6541,22,"static void ccid3_hc_tx_packet_sent(struct sock *sk, unsigned int len){	struct ccid3_hc_tx_sock *hc = ccid3_hc_tx_sk(sk);	ccid3_hc_tx_update_s(hc, len);	if (tfrc_tx_hist_add(&hc->tx_hist, dccp_sk(sk)->dccps_gss))		DCCP_CRIT(""packet history - out of memory!"");}",9867
79,1668,CVE-2012-6545,22,"static int rfcomm_tty_tiocmget(struct tty_struct *tty){	struct rfcomm_dev *dev = (struct rfcomm_dev *) tty->driver_data;	BT_DBG(""tty %p dev %p"", tty, dev);	return dev->modem_status;}",28328
203,1512,CVE-2018-18710,22,"static int cdrom_get_random_writable(struct cdrom_device_info *cdi,			      struct rwrt_feature_desc *rfd){	struct packet_command cgc;	char buffer[24];	int ret;	init_cdrom_command(&cgc, buffer, sizeof(buffer), CGC_DATA_READ);	cgc.cmd[0] = GPCMD_GET_CONFIGURATION;	 	cgc.cmd[3] = CDF_RWRT;			 	cgc.cmd[8] = sizeof(buffer);		 	cgc.quiet = 1;	if ((ret = cdi->ops->generic_packet(cdi, &cgc)))		return ret;	memcpy(rfd, &buffer[sizeof(struct feature_header)], sizeof (*rfd));	return 0;}",23429
327,27,CVE-2015-5330,22,int ldb_dn_is_special(struct ldb_dn *dn){	if ( ! dn || dn->invalid) return false;	return dn->special;},470
90,519,CVE-2013-3225,22,"static int rfcomm_sock_debugfs_open(struct inode *inode, struct file *file){	return single_open(file, rfcomm_sock_debugfs_show, inode->i_private);}",8362
208,1164,CVE-2016-4486,22,"int rtnl_nla_parse_ifla(struct nlattr **tb, const struct nlattr *head, int len){	return nla_parse(tb, IFLA_MAX, head, len, ifla_policy);}",16917
72,1617,CVE-2019-10639,22,"static int rtnl_net_fill(struct sk_buff *skb, struct net_fill_args *args){	struct nlmsghdr *nlh;	struct rtgenmsg *rth;	nlh = nlmsg_put(skb, args->portid, args->seq, args->cmd, sizeof(*rth),			args->flags);	if (!nlh)		return -EMSGSIZE;	rth = nlmsg_data(nlh);	rth->rtgen_family = AF_UNSPEC;	if (nla_put_s32(skb, NETNSA_NSID, args->nsid))		goto nla_put_failure;	if (args->add_ref &&	    nla_put_s32(skb, NETNSA_CURRENT_NSID, args->ref_nsid))		goto nla_put_failure;	nlmsg_end(skb, nlh);	return 0;nla_put_failure:	nlmsg_cancel(skb, nlh);	return -EMSGSIZE;}",27184
47,475,CVE-2013-3228,22,"static int irda_compat_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg){	 	return -ENOIOCTLCMD;}",8318
249,22,CVE-2015-5330,22,struct ldb_context *ldb_dn_get_ldb_context(struct ldb_dn *dn){	return dn->ldb;},465
30,1737,CVE-2018-6053,22,  void RecreateTopSitesAndBlock() {    ResetTopSites();    WaitTopSitesLoaded();  },30088
125,711,CVE-2012-6540,22,"static void update_defense_level(struct netns_ipvs *ipvs){	struct sysinfo i;	static int old_secure_tcp = 0;	int availmem;	int nomem;	int to_change = -1;	 	si_meminfo(&i);	availmem = i.freeram + i.bufferram;	 	 	 	nomem = (availmem < ipvs->sysctl_amemthresh);	local_bh_disable();	 	spin_lock(&ipvs->dropentry_lock);	switch (ipvs->sysctl_drop_entry) {	case 0:		atomic_set(&ipvs->dropentry, 0);		break;	case 1:		if (nomem) {			atomic_set(&ipvs->dropentry, 1);			ipvs->sysctl_drop_entry = 2;		} else {			atomic_set(&ipvs->dropentry, 0);		}		break;	case 2:		if (nomem) {			atomic_set(&ipvs->dropentry, 1);		} else {			atomic_set(&ipvs->dropentry, 0);			ipvs->sysctl_drop_entry = 1;		};		break;	case 3:		atomic_set(&ipvs->dropentry, 1);		break;	}	spin_unlock(&ipvs->dropentry_lock);	 	spin_lock(&ipvs->droppacket_lock);	switch (ipvs->sysctl_drop_packet) {	case 0:		ipvs->drop_rate = 0;		break;	case 1:		if (nomem) {			ipvs->drop_rate = ipvs->drop_counter				= ipvs->sysctl_amemthresh /				(ipvs->sysctl_amemthresh-availmem);			ipvs->sysctl_drop_packet = 2;		} else {			ipvs->drop_rate = 0;		}		break;	case 2:		if (nomem) {			ipvs->drop_rate = ipvs->drop_counter				= ipvs->sysctl_amemthresh /				(ipvs->sysctl_amemthresh-availmem);		} else {			ipvs->drop_rate = 0;			ipvs->sysctl_drop_packet = 1;		}		break;	case 3:		ipvs->drop_rate = ipvs->sysctl_am_droprate;		break;	}	spin_unlock(&ipvs->droppacket_lock);	 	spin_lock(&ipvs->securetcp_lock);	switch (ipvs->sysctl_secure_tcp) {	case 0:		if (old_secure_tcp >= 2)			to_change = 0;		break;	case 1:		if (nomem) {			if (old_secure_tcp < 2)				to_change = 1;			ipvs->sysctl_secure_tcp = 2;		} else {			if (old_secure_tcp >= 2)				to_change = 0;		}		break;	case 2:		if (nomem) {			if (old_secure_tcp < 2)				to_change = 1;		} else {			if (old_secure_tcp >= 2)				to_change = 0;			ipvs->sysctl_secure_tcp = 1;		}		break;	case 3:		if (old_secure_tcp < 2)			to_change = 1;		break;	}	old_secure_tcp = ipvs->sysctl_secure_tcp;	if (to_change >= 0)		ip_vs_protocol_timeout_change(ipvs,					      ipvs->sysctl_secure_tcp > 1);	spin_unlock(&ipvs->securetcp_lock);	local_bh_enable();}",9898
388,1768,CVE-2019-5837,22,"  void Verify_FindInterceptPatternMatchPositive() {    EXPECT_EQ(kInterceptPatternTestPositiveUrl, delegate()->found_url_);    EXPECT_EQ(kManifestUrl, delegate()->found_manifest_url_);    EXPECT_EQ(1, delegate()->found_cache_id_);    EXPECT_EQ(2, delegate()->found_group_id_);    EXPECT_EQ(1, delegate()->found_entry_.response_id());    EXPECT_TRUE(delegate()->found_entry_.IsIntercept());    EXPECT_EQ(kEntryUrl, delegate()->found_namespace_entry_url_);    EXPECT_FALSE(delegate()->found_fallback_entry_.has_response_id());    TestFinished();  }",30180
304,381,CVE-2013-3235,22,"static int shutdown(struct socket *sock, int how){	struct sock *sk = sock->sk;	struct tipc_port *tport = tipc_sk_port(sk);	struct sk_buff *buf;	int res;	if (how != SHUT_RDWR)		return -EINVAL;	lock_sock(sk);	switch (sock->state) {	case SS_CONNECTING:	case SS_CONNECTED:restart:		 		buf = __skb_dequeue(&sk->sk_receive_queue);		if (buf) {			if (TIPC_SKB_CB(buf)->handle != 0) {				kfree_skb(buf);				goto restart;			}			tipc_disconnect(tport->ref);			tipc_reject_msg(buf, TIPC_CONN_SHUTDOWN);		} else {			tipc_shutdown(tport->ref);		}		sock->state = SS_DISCONNECTING;		 	case SS_DISCONNECTING:		 		__skb_queue_purge(&sk->sk_receive_queue);		 		sk->sk_state_change(sk);		res = 0;		break;	default:		res = -ENOTCONN;	}	release_sock(sk);	return res;}",8224
389,1069,CVE-2016-5696,22,"static int tcp_try_undo_partial(struct sock *sk, const int acked){	struct tcp_sock *tp = tcp_sk(sk);	if (tp->undo_marker && tcp_packet_delayed(tp)) {		 		tcp_update_reordering(sk, tcp_fackets_out(tp) + acked, 1);		 		if (tp->retrans_out)			return true;		if (!tcp_any_retrans_done(sk))			tp->retrans_stamp = 0;		DBGUNDO(sk, ""partial recovery"");		tcp_undo_cwnd_reduction(sk, true);		NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPPARTIALUNDO);		tcp_try_keep_open(sk);		return true;	}	return false;}",16445
138,1744,CVE-2019-5837,22,  void OnDeleteAppCachesComplete(int result) {    delete_result_ = result;    ++delete_completion_count_;  },30156
28,1239,CVE-2016-0823,22,"static int proc_map_release(struct inode *inode, struct file *file){	struct seq_file *seq = file->private_data;	struct proc_maps_private *priv = seq->private;	if (priv->mm)		mmdrop(priv->mm);	return seq_release_private(inode, file);}",18201
348,1313,CVE-2014-9903,22,"static void cpu_cgroup_exit(struct cgroup_subsys_state *css,			    struct cgroup_subsys_state *old_css,			    struct task_struct *task){	 	if (!(task->flags & PF_EXITING))		return;	sched_move_task(task);}",19250
241,1682,CVE-2012-6544,22,"static void l2cap_sock_kill(struct sock *sk){	if (!sock_flag(sk, SOCK_ZAPPED) || sk->sk_socket)		return;	BT_DBG(""sk %p state %s"", sk, state_to_string(sk->sk_state));	 	l2cap_chan_destroy(l2cap_pi(sk)->chan);	sock_set_flag(sk, SOCK_DEAD);	sock_put(sk);}",28342
157,1176,CVE-2016-4482,22,"static void check_reset_of_active_ep(struct usb_device *udev,		unsigned int epnum, char *ioctl_name){	struct usb_host_endpoint **eps;	struct usb_host_endpoint *ep;	eps = (epnum & USB_DIR_IN) ? udev->ep_in : udev->ep_out;	ep = eps[epnum & 0x0f];	if (ep && !list_empty(&ep->urb_list))		dev_warn(&udev->dev, ""Process %d (%s) called USBDEVFS_%s for active endpoint 0x%02x\n"",				task_pid_nr(current), current->comm,				ioctl_name, epnum);}",16929
391,1587,CVE-2018-12436,22,int wc_ecc_is_valid_idx(int n){   int x;   for (x = 0; ecc_sets[x].size != 0; x++)       ;       if ((n >= ECC_CUSTOM_IDX) && (n < x)) {      return 1;   }   return 0;},25073
360,1371,CVE-2017-16994,22,"static int __walk_page_range(unsigned long start, unsigned long end,			struct mm_walk *walk){	int err = 0;	struct vm_area_struct *vma = walk->vma;	if (vma && is_vm_hugetlb_page(vma)) {		if (walk->hugetlb_entry)			err = walk_hugetlb_range(start, end, walk);	} else		err = walk_pgd_range(start, end, walk);	return err;}",19608
39,663,CVE-2012-6546,22,"static void vcc_destroy_socket(struct sock *sk){	struct atm_vcc *vcc = atm_sk(sk);	struct sk_buff *skb;	set_bit(ATM_VF_CLOSE, &vcc->flags);	clear_bit(ATM_VF_READY, &vcc->flags);	if (vcc->dev) {		if (vcc->dev->ops->close)			vcc->dev->ops->close(vcc);		if (vcc->push)			vcc->push(vcc, NULL);  		while ((skb = skb_dequeue(&sk->sk_receive_queue)) != NULL) {			atm_return(vcc, skb->truesize);			kfree_skb(skb);		}		module_put(vcc->dev->ops->owner);		atm_dev_put(vcc->dev);	}	vcc_remove_socket(sk);}",9850
321,1377,CVE-2017-15537,22,"int dump_fpu(struct pt_regs *regs, struct user_i387_struct *ufpu){	struct task_struct *tsk = current;	struct fpu *fpu = &tsk->thread.fpu;	int fpvalid;	fpvalid = fpu->fpstate_active;	if (fpvalid)		fpvalid = !fpregs_get(tsk, NULL,				      0, sizeof(struct user_i387_ia32_struct),				      ufpu, NULL);	return fpvalid;}",19976
346,1573,CVE-2018-15473,22,"check_authkey_line(struct ssh *ssh, struct passwd *pw, struct sshkey *key,    char *cp, const char *loc, struct sshauthopt **authoptsp){	int want_keytype = sshkey_is_cert(key) ? KEY_UNSPEC : key->type;	struct sshkey *found = NULL;	struct sshauthopt *keyopts = NULL, *certopts = NULL, *finalopts = NULL;	char *key_options = NULL, *fp = NULL;	const char *reason = NULL;	int ret = -1;	if (authoptsp != NULL)		*authoptsp = NULL;	if ((found = sshkey_new(want_keytype)) == NULL) {		debug3(""%s: keytype %d failed"", __func__, want_keytype);		goto out;	}	 	if (sshkey_read(found, &cp) != 0) {		 		debug2(""%s: check options: '%s'"", loc, cp);		key_options = cp;		if (advance_past_options(&cp) != 0) {			reason = ""invalid key option string"";			goto fail_reason;		}		skip_space(&cp);		if (sshkey_read(found, &cp) != 0) {			 			debug2(""%s: advance: '%s'"", loc, cp);			goto out;		}	}	 	if ((keyopts = sshauthopt_parse(key_options, &reason)) == NULL) {		debug(""%s: bad key options: %s"", loc, reason);		auth_debug_add(""%s: bad key options: %s"", loc, reason);		goto out;	}	 	if (sshkey_is_cert(key)) {		 		if (!sshkey_equal(found, key->cert->signature_key) ||		    !keyopts->cert_authority)			goto out;	} else {		 		if (!sshkey_equal(found, key) || keyopts->cert_authority)			goto out;	}	 	if ((fp = sshkey_fingerprint(found,	    options.fingerprint_hash, SSH_FP_DEFAULT)) == NULL)		fatal(""%s: fingerprint failed"", __func__);	debug(""%s: matching %s found: %s %s"", loc,	    sshkey_is_cert(key) ? ""CA"" : ""key"", sshkey_type(found), fp);	if (auth_authorise_keyopts(ssh, pw, keyopts,	    sshkey_is_cert(key), loc) != 0) {		reason = ""Refused by key options"";		goto fail_reason;	}	 	if (!sshkey_is_cert(key)) {		verbose(""Accepted key %s %s found at %s"",		    sshkey_type(found), fp, loc);		finalopts = keyopts;		keyopts = NULL;		goto success;	}	 	 	if ((certopts = sshauthopt_from_cert(key)) == NULL) {		reason = ""Invalid certificate options"";		goto fail_reason;	}	if (auth_authorise_keyopts(ssh, pw, certopts, 0, loc) != 0) {		reason = ""Refused by certificate options"";		goto fail_reason;	}	if ((finalopts = sshauthopt_merge(keyopts, certopts, &reason)) == NULL)		goto fail_reason;	 	if (keyopts->cert_principals != NULL &&	    !match_principals_option(keyopts->cert_principals, key->cert)) {		reason = ""Certificate does not contain an authorized principal"";		goto fail_reason;	}	if (sshkey_cert_check_authority(key, 0, 0,	   keyopts->cert_principals == NULL ? pw->pw_name : NULL, &reason) != 0)		goto fail_reason;	verbose(""Accepted certificate ID \""%s\"" (serial %llu) ""	    ""signed by CA %s %s found at %s"",	    key->cert->key_id,	    (unsigned long long)key->cert->serial,	    sshkey_type(found), fp, loc); success:	if (finalopts == NULL)		fatal(""%s: internal error: missing options"", __func__);	if (authoptsp != NULL) {		*authoptsp = finalopts;		finalopts = NULL;	}	 	ret = 0;	goto out; fail_reason:	error(""%s"", reason);	auth_debug_add(""%s"", reason); out:	free(fp);	sshauthopt_free(keyopts);	sshauthopt_free(certopts);	sshauthopt_free(finalopts);	sshkey_free(found);	return ret;}",24433
449,1469,CVE-2017-9150,22,"static struct bpf_verifier_state *push_stack(struct bpf_verifier_env *env,					     int insn_idx, int prev_insn_idx){	struct bpf_verifier_stack_elem *elem;	elem = kmalloc(sizeof(struct bpf_verifier_stack_elem), GFP_KERNEL);	if (!elem)		goto err;	memcpy(&elem->st, &env->cur_state, sizeof(env->cur_state));	elem->insn_idx = insn_idx;	elem->prev_insn_idx = prev_insn_idx;	elem->next = env->head;	env->head = elem;	env->stack_size++;	if (env->stack_size > BPF_COMPLEXITY_LIMIT_STACK) {		verbose(""BPF program is too complex\n"");		goto err;	}	return &elem->st;err:	 	while (pop_stack(env, NULL) >= 0);	return NULL;}",20854
432,141,CVE-2018-11469,22,"smp_fetch_param(char delim, const char *name, int name_len, const struct arg *args, struct sample *smp, const char *kw, void *private){	const char *vstart, *vend;	struct chunk *temp;	const char **chunks = (const char **)smp->ctx.a;	if (!find_next_url_param(chunks,	                         name, name_len,	                         &vstart, &vend,	                         delim))		return 0;	 	smp->data.type = SMP_T_STR;	if (chunks[2] &&	    vstart >= chunks[0] && vstart <= chunks[1] &&	    vend >= chunks[2] && vend <= chunks[3]) {		 		temp = get_trash_chunk();		memcpy(temp->str, vstart, chunks[1] - vstart);		memcpy(temp->str + ( chunks[1] - vstart ), chunks[2], vend - chunks[2]);		smp->data.u.str.str = temp->str;		smp->data.u.str.len = ( chunks[1] - vstart ) + ( vend - chunks[2] );	} else {		 		smp->data.u.str.str = (char *)vstart;		smp->data.u.str.len = vend - vstart;		smp->flags = SMP_F_VOL_1ST | SMP_F_CONST;	}	 	chunks[0] = vend;	if (chunks[2] && vend >= chunks[2] && vend <= chunks[3]) {		chunks[1] = chunks[3];		chunks[2] = NULL;	}	if (chunks[0] < chunks[1])		smp->flags |= SMP_F_NOT_LAST;	return 1;}",1146
73,1065,CVE-2016-5696,22,"static int tcp_try_rmem_schedule(struct sock *sk, struct sk_buff *skb,				 unsigned int size){	if (atomic_read(&sk->sk_rmem_alloc) > sk->sk_rcvbuf ||	    !sk_rmem_schedule(sk, skb, size)) {		if (tcp_prune_queue(sk) < 0)			return -1;		if (!sk_rmem_schedule(sk, skb, size)) {			if (!tcp_prune_ofo_queue(sk))				return -1;			if (!sk_rmem_schedule(sk, skb, size))				return -1;		}	}	return 0;}",16441
264,299,CVE-2013-4516,22,"static void serial_unlink_irq_chain(struct mp_port *mtpt){	struct irq_info *i = irq_lists + mtpt->port.irq;	if (list_empty(i->head))	{		free_irq(mtpt->port.irq, i);	}	serial_do_unlink(i, mtpt);}",7737
130,1665,CVE-2012-6545,22,"static int rfcomm_tty_open(struct tty_struct *tty, struct file *filp){	DECLARE_WAITQUEUE(wait, current);	struct rfcomm_dev *dev;	struct rfcomm_dlc *dlc;	unsigned long flags;	int err, id;	id = tty->index;	BT_DBG(""tty %p id %d"", tty, id);	 	dev = rfcomm_dev_get(id);	if (!dev)		return -ENODEV;	BT_DBG(""dev %p dst %s channel %d opened %d"", dev, batostr(&dev->dst),				dev->channel, dev->port.count);	spin_lock_irqsave(&dev->port.lock, flags);	if (++dev->port.count > 1) {		spin_unlock_irqrestore(&dev->port.lock, flags);		return 0;	}	spin_unlock_irqrestore(&dev->port.lock, flags);	dlc = dev->dlc;	 	rfcomm_dlc_lock(dlc);	tty->driver_data = dev;	dev->port.tty = tty;	rfcomm_dlc_unlock(dlc);	set_bit(RFCOMM_TTY_ATTACHED, &dev->flags);	err = rfcomm_dlc_open(dlc, &dev->src, &dev->dst, dev->channel);	if (err < 0)		return err;	 	add_wait_queue(&dev->wait, &wait);	while (1) {		set_current_state(TASK_INTERRUPTIBLE);		if (dlc->state == BT_CLOSED) {			err = -dev->err;			break;		}		if (dlc->state == BT_CONNECTED)			break;		if (signal_pending(current)) {			err = -EINTR;			break;		}		tty_unlock();		schedule();		tty_lock();	}	set_current_state(TASK_RUNNING);	remove_wait_queue(&dev->wait, &wait);	if (err == 0)		device_move(dev->tty_dev, rfcomm_get_device(dev),			    DPM_ORDER_DEV_AFTER_PARENT);	rfcomm_tty_copy_pending(dev);	rfcomm_dlc_unthrottle(dev->dlc);	return err;}",28325
136,424,CVE-2013-3231,22,"static int llc_ui_listen(struct socket *sock, int backlog){	struct sock *sk = sock->sk;	int rc = -EINVAL;	lock_sock(sk);	if (unlikely(sock->state != SS_UNCONNECTED))		goto out;	rc = -EOPNOTSUPP;	if (unlikely(sk->sk_type != SOCK_STREAM))		goto out;	rc = -EAGAIN;	if (sock_flag(sk, SOCK_ZAPPED))		goto out;	rc = 0;	if (!(unsigned int)backlog)	 		backlog = 1;	sk->sk_max_ack_backlog = backlog;	if (sk->sk_state != TCP_LISTEN) {		sk->sk_ack_backlog = 0;		sk->sk_state	   = TCP_LISTEN;	}	sk->sk_socket->flags |= __SO_ACCEPTCON;out:	release_sock(sk);	return rc;}",8267
247,631,CVE-2013-0349,22,"static int hidp_process_data(struct hidp_session *session, struct sk_buff *skb,				unsigned char param){	int done_with_skb = 1;	BT_DBG(""session %p skb %p len %d param 0x%02x"", session, skb, skb->len, param);	switch (param) {	case HIDP_DATA_RTYPE_INPUT:		hidp_set_timer(session);		if (session->input)			hidp_input_report(session, skb);		if (session->hid)			hid_input_report(session->hid, HID_INPUT_REPORT, skb->data, skb->len, 0);		break;	case HIDP_DATA_RTYPE_OTHER:	case HIDP_DATA_RTYPE_OUPUT:	case HIDP_DATA_RTYPE_FEATURE:		break;	default:		__hidp_send_ctrl_message(session,			HIDP_TRANS_HANDSHAKE | HIDP_HSHK_ERR_INVALID_PARAMETER, NULL, 0);	}	if (test_bit(HIDP_WAITING_FOR_RETURN, &session->flags) &&				param == session->waiting_report_type) {		if (session->waiting_report_number < 0 ||		    session->waiting_report_number == skb->data[0]) {			 			session->report_return = skb;			done_with_skb = 0;			clear_bit(HIDP_WAITING_FOR_RETURN, &session->flags);			wake_up_interruptible(&session->report_queue);		}	}	return done_with_skb;}",9704
262,1258,CVE-2015-8964,22,"static int proc_tty_ldiscs_open(struct inode *inode, struct file *file){	return seq_open(file, &tty_ldiscs_seq_ops);}",18297
36,900,CVE-2015-5697,22,"max_sync_show(struct mddev *mddev, char *page){	if (mddev->resync_max == MaxSector)		return sprintf(page, ""max\n"");	else		return sprintf(page, ""%llu\n"",			       (unsigned long long)mddev->resync_max);}",13230
27,1787,CVE-2017-0823,22,"static void freeDebugCallbackArgs(int number, char **args) { for (int i = 0; i < number; i++) { if (args[i] != NULL) {            free(args[i]); } }    free(args);}",30727
32,948,CVE-2015-5697,22,"raid_disks_show(struct mddev *mddev, char *page){	if (mddev->raid_disks == 0)		return 0;	if (mddev->reshape_position != MaxSector &&	    mddev->delta_disks != 0)		return sprintf(page, ""%d (%d)\n"", mddev->raid_disks,			       mddev->raid_disks - mddev->delta_disks);	return sprintf(page, ""%d\n"", mddev->raid_disks);}",13278
144,1191,CVE-2016-4482,22,"static int releaseintf(struct usb_dev_state *ps, unsigned int ifnum){	struct usb_device *dev;	struct usb_interface *intf;	int err;	err = -EINVAL;	if (ifnum >= 8*sizeof(ps->ifclaimed))		return err;	dev = ps->dev;	intf = usb_ifnum_to_if(dev, ifnum);	if (!intf)		err = -ENOENT;	else if (test_and_clear_bit(ifnum, &ps->ifclaimed)) {		usb_driver_release_interface(&usbfs_driver, intf);		err = 0;	}	return err;}",16944
260,543,CVE-2013-3223,22,static void ax25_free_sock(struct sock *sk){	ax25_cb_put(ax25_sk(sk));},8386
84,391,CVE-2013-3233,22,"static void llcp_sock_destruct(struct sock *sk){	struct nfc_llcp_sock *llcp_sock = nfc_llcp_sock(sk);	pr_debug(""%p\n"", sk);	if (sk->sk_state == LLCP_CONNECTED)		nfc_put_device(llcp_sock->dev);	skb_queue_purge(&sk->sk_receive_queue);	nfc_llcp_sock_free(llcp_sock);	if (!sock_flag(sk, SOCK_DEAD)) {		pr_err(""Freeing alive NFC LLCP socket %p\n"", sk);		return;	}}",8234
10,724,CVE-2012-4530,22,"int bprm_mm_init(struct linux_binprm *bprm){	int err;	struct mm_struct *mm = NULL;	bprm->mm = mm = mm_alloc();	err = -ENOMEM;	if (!mm)		goto err;	err = init_new_context(current, mm);	if (err)		goto err;	err = __bprm_mm_init(bprm);	if (err)		goto err;	return 0;err:	if (mm) {		bprm->mm = NULL;		mmdrop(mm);	}	return err;}",9987
113,1430,CVE-2017-9605,22,"static void vmw_hw_surface_destroy(struct vmw_resource *res){	struct vmw_private *dev_priv = res->dev_priv;	struct vmw_surface *srf;	void *cmd;	if (res->func->destroy == vmw_gb_surface_destroy) {		(void) vmw_gb_surface_destroy(res);		return;	}	if (res->id != -1) {		cmd = vmw_fifo_reserve(dev_priv, vmw_surface_destroy_size());		if (unlikely(!cmd)) {			DRM_ERROR(""Failed reserving FIFO space for surface ""				  ""destruction.\n"");			return;		}		vmw_surface_destroy_encode(res->id, cmd);		vmw_fifo_commit(dev_priv, vmw_surface_destroy_size());		 		mutex_lock(&dev_priv->cmdbuf_mutex);		srf = vmw_res_to_srf(res);		dev_priv->used_memory_size -= res->backup_size;		mutex_unlock(&dev_priv->cmdbuf_mutex);	}	vmw_fifo_resource_dec(dev_priv);}",20715
367,1420,CVE-2017-10911,22,"static void xen_blk_drain_io(struct xen_blkif_ring *ring){	struct xen_blkif *blkif = ring->blkif;	atomic_set(&blkif->drain, 1);	do {		if (atomic_read(&ring->inflight) == 0)			break;		wait_for_completion_interruptible_timeout(				&blkif->drain_complete, HZ);		if (!atomic_read(&blkif->drain))			break;	} while (!kthread_should_stop());	atomic_set(&blkif->drain, 0);}",20592
328,544,CVE-2013-3223,22,"static int ax25_getname(struct socket *sock, struct sockaddr *uaddr,	int *uaddr_len, int peer){	struct full_sockaddr_ax25 *fsa = (struct full_sockaddr_ax25 *)uaddr;	struct sock *sk = sock->sk;	unsigned char ndigi, i;	ax25_cb *ax25;	int err = 0;	memset(fsa, 0, sizeof(*fsa));	lock_sock(sk);	ax25 = ax25_sk(sk);	if (peer != 0) {		if (sk->sk_state != TCP_ESTABLISHED) {			err = -ENOTCONN;			goto out;		}		fsa->fsa_ax25.sax25_family = AF_AX25;		fsa->fsa_ax25.sax25_call   = ax25->dest_addr;		if (ax25->digipeat != NULL) {			ndigi = ax25->digipeat->ndigi;			fsa->fsa_ax25.sax25_ndigis = ndigi;			for (i = 0; i < ndigi; i++)				fsa->fsa_digipeater[i] =						ax25->digipeat->calls[i];		}	} else {		fsa->fsa_ax25.sax25_family = AF_AX25;		fsa->fsa_ax25.sax25_call   = ax25->source_addr;		fsa->fsa_ax25.sax25_ndigis = 1;		if (ax25->ax25_dev != NULL) {			memcpy(&fsa->fsa_digipeater[0],			       ax25->ax25_dev->dev->dev_addr, AX25_ADDR_LEN);		} else {			fsa->fsa_digipeater[0] = null_ax25_address;		}	}	*uaddr_len = sizeof (struct full_sockaddr_ax25);out:	release_sock(sk);	return err;}",8387
197,1593,CVE-2019-16714,22,"static int rds_cmsg_recv(struct rds_incoming *inc, struct msghdr *msg,			 struct rds_sock *rs){	int ret = 0;	if (inc->i_rdma_cookie) {		ret = put_cmsg(msg, SOL_RDS, RDS_CMSG_RDMA_DEST,				sizeof(inc->i_rdma_cookie), &inc->i_rdma_cookie);		if (ret)			goto out;	}	if ((inc->i_rx_tstamp != 0) &&	    sock_flag(rds_rs_to_sk(rs), SOCK_RCVTSTAMP)) {		struct __kernel_old_timeval tv = ns_to_kernel_old_timeval(inc->i_rx_tstamp);		if (!sock_flag(rds_rs_to_sk(rs), SOCK_TSTAMP_NEW)) {			ret = put_cmsg(msg, SOL_SOCKET, SO_TIMESTAMP_OLD,				       sizeof(tv), &tv);		} else {			struct __kernel_sock_timeval sk_tv;			sk_tv.tv_sec = tv.tv_sec;			sk_tv.tv_usec = tv.tv_usec;			ret = put_cmsg(msg, SOL_SOCKET, SO_TIMESTAMP_NEW,				       sizeof(sk_tv), &sk_tv);		}		if (ret)			goto out;	}	if (rs->rs_rx_traces) {		struct rds_cmsg_rx_trace t;		int i, j;		memset(&t, 0, sizeof(t));		inc->i_rx_lat_trace[RDS_MSG_RX_CMSG] = local_clock();		t.rx_traces =  rs->rs_rx_traces;		for (i = 0; i < rs->rs_rx_traces; i++) {			j = rs->rs_rx_trace[i];			t.rx_trace_pos[i] = j;			t.rx_trace[i] = inc->i_rx_lat_trace[j + 1] -					  inc->i_rx_lat_trace[j];		}		ret = put_cmsg(msg, SOL_RDS, RDS_CMSG_RXPATH_LATENCY,			       sizeof(t), &t);		if (ret)			goto out;	}out:	return ret;}",26477
440,575,CVE-2013-3076,22,"static int skcipher_wait_for_data(struct sock *sk, unsigned flags){	struct alg_sock *ask = alg_sk(sk);	struct skcipher_ctx *ctx = ask->private;	long timeout;	DEFINE_WAIT(wait);	int err = -ERESTARTSYS;	if (flags & MSG_DONTWAIT) {		return -EAGAIN;	}	set_bit(SOCK_ASYNC_WAITDATA, &sk->sk_socket->flags);	for (;;) {		if (signal_pending(current))			break;		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);		timeout = MAX_SCHEDULE_TIMEOUT;		if (sk_wait_event(sk, &timeout, ctx->used)) {			err = 0;			break;		}	}	finish_wait(sk_sleep(sk), &wait);	clear_bit(SOCK_ASYNC_WAITDATA, &sk->sk_socket->flags);	return err;}",8418
383,1175,CVE-2016-4482,22,"static int check_ctrlrecip(struct usb_dev_state *ps, unsigned int requesttype,			   unsigned int request, unsigned int index){	int ret = 0;	struct usb_host_interface *alt_setting;	if (ps->dev->state != USB_STATE_UNAUTHENTICATED	 && ps->dev->state != USB_STATE_ADDRESS	 && ps->dev->state != USB_STATE_CONFIGURED)		return -EHOSTUNREACH;	if (USB_TYPE_VENDOR == (USB_TYPE_MASK & requesttype))		return 0;	 	if (requesttype == 0xa1 && request == 0) {		alt_setting = usb_find_alt_setting(ps->dev->actconfig,						   index >> 8, index & 0xff);		if (alt_setting		 && alt_setting->desc.bInterfaceClass == USB_CLASS_PRINTER)			return 0;	}	index &= 0xff;	switch (requesttype & USB_RECIP_MASK) {	case USB_RECIP_ENDPOINT:		if ((index & ~USB_DIR_IN) == 0)			return 0;		ret = findintfep(ps->dev, index);		if (ret < 0) {			 			ret = findintfep(ps->dev, index ^ 0x80);			if (ret >= 0)				dev_info(&ps->dev->dev,					""%s: process %i (%s) requesting ep %02x but needs %02x\n"",					__func__, task_pid_nr(current),					current->comm, index, index ^ 0x80);		}		if (ret >= 0)			ret = checkintf(ps, ret);		break;	case USB_RECIP_INTERFACE:		ret = checkintf(ps, index);		break;	}	return ret;}",16928
338,133,CVE-2018-11469,22,"smp_fetch_hdr_names(const struct arg *args, struct sample *smp, const char *kw, void *private){	struct hdr_idx *idx;	struct hdr_ctx ctx;	const struct http_msg *msg;	struct chunk *temp;	char del = ',';	if (args && args->type == ARGT_STR)		del = *args[0].data.str.str;	CHECK_HTTP_MESSAGE_FIRST();	idx = &smp->strm->txn->hdr_idx;	msg = ((smp->opt & SMP_OPT_DIR) == SMP_OPT_DIR_REQ) ? &smp->strm->txn->req : &smp->strm->txn->rsp;	temp = get_trash_chunk();	ctx.idx = 0;	while (http_find_next_header(msg->chn->buf->p, idx, &ctx)) {		if (temp->len)			temp->str[temp->len++] = del;		memcpy(temp->str + temp->len, ctx.line, ctx.del);		temp->len += ctx.del;	}	smp->data.type = SMP_T_STR;	smp->data.u.str.str = temp->str;	smp->data.u.str.len = temp->len;	smp->flags = SMP_F_VOL_HDR;	return 1;}",1138
221,63,CVE-2018-11469,22,"void http_end_txn_clean_session(struct stream *s){	int prev_status = s->txn->status;	struct proxy *fe = strm_fe(s);	struct proxy *be = s->be;	struct conn_stream *cs;	struct connection *srv_conn;	struct server *srv;	unsigned int prev_flags = s->txn->flags;	 	 	cs = objt_cs(s->si[1].end);	srv_conn = cs_conn(cs);	 	if (((s->txn->flags & TX_CON_WANT_MSK) != TX_CON_WANT_KAL) ||	    !si_conn_ready(&s->si[1])) {		s->si[1].flags |= SI_FL_NOLINGER | SI_FL_NOHALF;		si_shutr(&s->si[1]);		si_shutw(&s->si[1]);	}	if (s->flags & SF_BE_ASSIGNED) {		HA_ATOMIC_SUB(&be->beconn, 1);		if (unlikely(s->srv_conn))			sess_change_server(s, NULL);	}	s->logs.t_close = tv_ms_elapsed(&s->logs.tv_accept, &now);	stream_process_counters(s);	if (s->txn->status) {		int n;		n = s->txn->status / 100;		if (n < 1 || n > 5)			n = 0;		if (fe->mode == PR_MODE_HTTP) {			HA_ATOMIC_ADD(&fe->fe_counters.p.http.rsp[n], 1);		}		if ((s->flags & SF_BE_ASSIGNED) &&		    (be->mode == PR_MODE_HTTP)) {			HA_ATOMIC_ADD(&be->be_counters.p.http.rsp[n], 1);			HA_ATOMIC_ADD(&be->be_counters.p.http.cum_req, 1);		}	}	 	s->logs.bytes_in  -= s->req.buf->i;	s->logs.bytes_out -= s->res.buf->i;	 	if (!LIST_ISEMPTY(&fe->logformat) && s->logs.logwait &&	    !(s->flags & SF_MONITOR) &&	    (!(fe->options & PR_O_NULLNOLOG) || s->req.total)) {		s->do_log(s);	}	 	stream_stop_content_counters(s);	stream_update_time_stats(s);	s->logs.accept_date = date;  	s->logs.tv_accept = now;   	s->logs.t_handshake = 0;  	s->logs.t_idle = -1;	tv_zero(&s->logs.tv_request);	s->logs.t_queue = -1;	s->logs.t_connect = -1;	s->logs.t_data = -1;	s->logs.t_close = 0;	s->logs.prx_queue_size = 0;   	s->logs.srv_queue_size = 0;  	s->logs.bytes_in = s->req.total = s->req.buf->i;	s->logs.bytes_out = s->res.total = s->res.buf->i;	if (s->pend_pos)		pendconn_free(s->pend_pos);	if (objt_server(s->target)) {		if (s->flags & SF_CURR_SESS) {			s->flags &= ~SF_CURR_SESS;			HA_ATOMIC_SUB(&objt_server(s->target)->cur_sess, 1);		}		if (may_dequeue_tasks(objt_server(s->target), be))			process_srv_queue(objt_server(s->target));	}	s->target = NULL;	 	if (((s->txn->flags & TX_CON_WANT_MSK) != TX_CON_WANT_KAL) ||	    !si_conn_ready(&s->si[1])) {		si_release_endpoint(&s->si[1]);		srv_conn = NULL;	}	s->si[1].state     = s->si[1].prev_state = SI_ST_INI;	s->si[1].err_type  = SI_ET_NONE;	s->si[1].conn_retries = 0;   	s->si[1].exp       = TICK_ETERNITY;	s->si[1].flags    &= SI_FL_ISBACK | SI_FL_DONT_WAKE;  	s->req.flags &= ~(CF_SHUTW|CF_SHUTW_NOW|CF_AUTO_CONNECT|CF_WRITE_ERROR|CF_STREAMER|CF_STREAMER_FAST|CF_NEVER_WAIT|CF_WAKE_CONNECT|CF_WROTE_DATA);	s->res.flags &= ~(CF_SHUTR|CF_SHUTR_NOW|CF_READ_ATTACHED|CF_READ_ERROR|CF_READ_NOEXP|CF_STREAMER|CF_STREAMER_FAST|CF_WRITE_PARTIAL|CF_NEVER_WAIT|CF_WROTE_DATA|CF_WRITE_EVENT);	s->flags &= ~(SF_DIRECT|SF_ASSIGNED|SF_ADDR_SET|SF_BE_ASSIGNED|SF_FORCE_PRST|SF_IGNORE_PRST);	s->flags &= ~(SF_CURR_SESS|SF_REDIRECTABLE|SF_SRV_REUSED);	s->flags &= ~(SF_ERR_MASK|SF_FINST_MASK|SF_REDISP);	s->txn->meth = 0;	http_reset_txn(s);	s->txn->flags |= TX_NOT_FIRST | TX_WAIT_NEXT_RQ;	if (prev_status == 401 || prev_status == 407) {		 		s->txn->flags |= TX_PREFER_LAST;		if (srv_conn)			srv_conn->flags |= CO_FL_PRIVATE;	}	 	if (srv_conn && (be->options & PR_O_REUSE_MASK) == PR_O_REUSE_NEVR)		srv_conn->flags |= CO_FL_PRIVATE;	if (fe->options2 & PR_O2_INDEPSTR)		s->si[1].flags |= SI_FL_INDEP_STR;	if (fe->options2 & PR_O2_NODELAY) {		s->req.flags |= CF_NEVER_WAIT;		s->res.flags |= CF_NEVER_WAIT;	}	 	channel_auto_read(&s->req);	channel_auto_close(&s->req);	channel_auto_read(&s->res);	 	if (srv_conn && LIST_ISEMPTY(&srv_conn->list)) {		srv = objt_server(srv_conn->target);		if (!srv)			si_idle_cs(&s->si[1], NULL);		else if (srv_conn->flags & CO_FL_PRIVATE)			si_idle_cs(&s->si[1], (srv->priv_conns ? &srv->priv_conns[tid] : NULL));		else if (prev_flags & TX_NOT_FIRST)			 			si_idle_cs(&s->si[1], (srv->safe_conns ? &srv->safe_conns[tid] : NULL));		else			si_idle_cs(&s->si[1], (srv->idle_conns ? &srv->idle_conns[tid] : NULL));	}	s->req.analysers = strm_li(s) ? strm_li(s)->analysers : 0;	s->res.analysers = 0;}",1068
37,759,CVE-2014-8709,22,"static int ieee80211_tx_pending_skb(struct ieee80211_local *local,				     struct sk_buff *skb){	struct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);	struct ieee80211_sub_if_data *sdata;	struct sta_info *sta;	struct ieee80211_hdr *hdr;	int result;	struct ieee80211_chanctx_conf *chanctx_conf;	sdata = vif_to_sdata(info->control.vif);	if (info->flags & IEEE80211_TX_INTFL_NEED_TXPROCESSING) {		chanctx_conf = rcu_dereference(sdata->vif.chanctx_conf);		if (unlikely(!chanctx_conf)) {			dev_kfree_skb(skb);			return true;		}		result = ieee80211_tx(sdata, skb, true,				      chanctx_conf->def.chan->band);	} else {		struct sk_buff_head skbs;		__skb_queue_head_init(&skbs);		__skb_queue_tail(&skbs, skb);		hdr = (struct ieee80211_hdr *)skb->data;		sta = sta_info_get(sdata, hdr->addr1);		result = __ieee80211_tx(local, &skbs, skb->len, sta, true);	}	return result;}",10405
434,1746,CVE-2019-5837,22,  void BasicFindMainFallbackResponseInWorkingSet() {    BasicFindMainFallbackResponse(false);  },30158
289,1232,CVE-2016-0823,22,static void hold_task_mempolicy(struct proc_maps_private *priv){},18194
298,304,CVE-2013-4515,22,"static int bcm_char_release(struct inode *inode, struct file *filp){	struct bcm_tarang_data *pTarang, *tmp, *ptmp;	struct bcm_mini_adapter *Adapter = NULL;	struct sk_buff *pkt, *npkt;	pTarang = (struct bcm_tarang_data *)filp->private_data;	if (pTarang == NULL) {		BCM_DEBUG_PRINT(Adapter, DBG_TYPE_PRINTK, 0, 0,				""ptarang is null\n"");		return 0;	}	Adapter = pTarang->Adapter;	down(&Adapter->RxAppControlQueuelock);	tmp = Adapter->pTarangs;	for (ptmp = NULL; tmp; ptmp = tmp, tmp = tmp->next) {		if (tmp == pTarang)			break;	}	if (tmp) {		if (!ptmp)			Adapter->pTarangs = tmp->next;		else			ptmp->next = tmp->next;	} else {		up(&Adapter->RxAppControlQueuelock);		return 0;	}	pkt = pTarang->RxAppControlHead;	while (pkt) {		npkt = pkt->next;		kfree_skb(pkt);		pkt = npkt;	}	up(&Adapter->RxAppControlQueuelock);	 	atomic_dec(&Adapter->ApplicationRunning);	kfree(pTarang);	 	filp->private_data = NULL;	return 0;}",7742
395,57,CVE-2018-11469,22,"enum act_return http_action_res_capture_by_id(struct act_rule *rule, struct proxy *px,                                              struct session *sess, struct stream *s, int flags){	struct sample *key;	struct cap_hdr *h;	char **cap = s->res_cap;	struct proxy *fe = strm_fe(s);	int len;	int i;	 	for (h = fe->rsp_cap, i = fe->nb_rsp_cap - 1;	     h != NULL && i != rule->arg.capid.idx ;	     i--, h = h->next);	if (!h)		return ACT_RET_CONT;	key = sample_fetch_as_type(s->be, sess, s, SMP_OPT_DIR_RES|SMP_OPT_FINAL, rule->arg.capid.expr, SMP_T_STR);	if (!key)		return ACT_RET_CONT;	if (cap[h->index] == NULL)		cap[h->index] = pool_alloc(h->pool);	if (cap[h->index] == NULL)  		return ACT_RET_CONT;	len = key->data.u.str.len;	if (len > h->len)		len = h->len;	memcpy(cap[h->index], key->data.u.str.str, len);	cap[h->index][len] = 0;	return ACT_RET_CONT;}",1062
202,1790,CVE-2017-0823,22,"memsetString (char *s) { if (s != NULL) {        memset (s, 0, strlen(s)); }}",30730
362,1076,CVE-2016-5243,22,"static void __fill_bc_link_stat(struct tipc_nl_compat_msg *msg,				struct nlattr *prop[], struct nlattr *stats[]){	tipc_tlv_sprintf(msg->rep, ""  Window:%u packets\n"",			 nla_get_u32(prop[TIPC_NLA_PROP_WIN]));	tipc_tlv_sprintf(msg->rep,			 ""  RX packets:%u fragments:%u/%u bundles:%u/%u\n"",			 nla_get_u32(stats[TIPC_NLA_STATS_RX_INFO]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_FRAGMENTS]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_FRAGMENTED]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_BUNDLES]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_BUNDLED]));	tipc_tlv_sprintf(msg->rep,			 ""  TX packets:%u fragments:%u/%u bundles:%u/%u\n"",			 nla_get_u32(stats[TIPC_NLA_STATS_TX_INFO]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_FRAGMENTS]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_FRAGMENTED]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_BUNDLES]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_BUNDLED]));	tipc_tlv_sprintf(msg->rep, ""  RX naks:%u defs:%u dups:%u\n"",			 nla_get_u32(stats[TIPC_NLA_STATS_RX_NACKS]),			 nla_get_u32(stats[TIPC_NLA_STATS_RX_DEFERRED]),			 nla_get_u32(stats[TIPC_NLA_STATS_DUPLICATES]));	tipc_tlv_sprintf(msg->rep, ""  TX naks:%u acks:%u dups:%u\n"",			 nla_get_u32(stats[TIPC_NLA_STATS_TX_NACKS]),			 nla_get_u32(stats[TIPC_NLA_STATS_TX_ACKS]),			 nla_get_u32(stats[TIPC_NLA_STATS_RETRANSMITTED]));	tipc_tlv_sprintf(msg->rep,			 ""  Congestion link:%u  Send queue max:%u avg:%u"",			 nla_get_u32(stats[TIPC_NLA_STATS_LINK_CONGS]),			 nla_get_u32(stats[TIPC_NLA_STATS_MAX_QUEUE]),			 nla_get_u32(stats[TIPC_NLA_STATS_AVG_QUEUE]));}",16484
145,12,CVE-2015-5330,22,static void ldb_dn_mark_invalid(struct ldb_dn *dn){	dn->invalid = true;},455
13,65,CVE-2018-11469,22,"int http_find_full_header2(const char *name, int len,                           char *sol, struct hdr_idx *idx,                           struct hdr_ctx *ctx){	char *eol, *sov;	int cur_idx, old_idx;	cur_idx = ctx->idx;	if (cur_idx) {		 		sol = ctx->line;		eol = sol + idx->v[cur_idx].len;		goto next_hdr;	}	 	sol += hdr_idx_first_pos(idx);	old_idx = 0;	cur_idx = hdr_idx_first_idx(idx);	while (cur_idx) {		eol = sol + idx->v[cur_idx].len;		if (len == 0) {			 			while (sol + len < eol && sol[len] != ':')				len++;			name = sol;		}		if ((len < eol - sol) &&		    (sol[len] == ':') &&		    (strncasecmp(sol, name, len) == 0)) {			ctx->del = len;			sov = sol + len + 1;			while (sov < eol && HTTP_IS_LWS(*sov))				sov++;			ctx->line = sol;			ctx->prev = old_idx;			ctx->idx  = cur_idx;			ctx->val  = sov - sol;			ctx->tws = 0;			while (eol > sov && HTTP_IS_LWS(*(eol - 1))) {				eol--;				ctx->tws++;			}			ctx->vlen = eol - sov;			return 1;		}	next_hdr:		sol = eol + idx->v[cur_idx].cr + 1;		old_idx = cur_idx;		cur_idx = idx->v[cur_idx].next;	}	return 0;}",1070
334,392,CVE-2013-3233,22,"static int llcp_sock_listen(struct socket *sock, int backlog){	struct sock *sk = sock->sk;	int ret = 0;	pr_debug(""sk %p backlog %d\n"", sk, backlog);	lock_sock(sk);	if ((sock->type != SOCK_SEQPACKET && sock->type != SOCK_STREAM) ||	    sk->sk_state != LLCP_BOUND) {		ret = -EBADFD;		goto error;	}	sk->sk_max_ack_backlog = backlog;	sk->sk_ack_backlog = 0;	pr_debug(""Socket listening\n"");	sk->sk_state = LLCP_LISTEN;error:	release_sock(sk);	return ret;}",8235
416,554,CVE-2013-3222,22,static int check_tp(const struct atm_trafprm *tp){	 	if (!tp->traffic_class || tp->traffic_class == ATM_ANYCLASS)		return 0;	if (tp->traffic_class != ATM_UBR && !tp->min_pcr && !tp->pcr &&	    !tp->max_pcr)		return -EINVAL;	if (tp->min_pcr == ATM_MAX_PCR)		return -EINVAL;	if (tp->min_pcr && tp->max_pcr && tp->max_pcr != ATM_MAX_PCR &&	    tp->min_pcr > tp->max_pcr)		return -EINVAL;	 	return 0;},8397
26,1281,CVE-2015-8964,22,"static void tty_ldiscs_seq_stop(struct seq_file *m, void *v){}",18320
347,295,CVE-2013-4516,22,"static int sb1054_get_register(struct sb_uart_port *port, int page, int reg){	int ret = 0;	unsigned int lcr = 0;	unsigned int mcr = 0;	unsigned int tmp = 0;	if( page <= 0)	{		printk("" page 0 can not use this fuction\n"");		return -1;	}	switch(page)	{		case 1:			lcr = SB105X_GET_LCR(port);			tmp = lcr | SB105X_LCR_DLAB;			SB105X_PUT_LCR(port, tmp);			tmp = SB105X_GET_LCR(port);			ret = SB105X_GET_REG(port,reg);			SB105X_PUT_LCR(port,lcr);			break;		case 2:			mcr = SB105X_GET_MCR(port);			tmp = mcr | SB105X_MCR_P2S;			SB105X_PUT_MCR(port,tmp);			ret = SB105X_GET_REG(port,reg);			SB105X_PUT_MCR(port,mcr);			break;		case 3:			lcr = SB105X_GET_LCR(port);			tmp = lcr | SB105X_LCR_BF;			SB105X_PUT_LCR(port,tmp);			SB105X_PUT_REG(port,SB105X_PSR,SB105X_PSR_P3KEY);			ret = SB105X_GET_REG(port,reg);			SB105X_PUT_LCR(port,lcr);			break;		case 4:			lcr = SB105X_GET_LCR(port);			tmp = lcr | SB105X_LCR_BF;			SB105X_PUT_LCR(port,tmp);			SB105X_PUT_REG(port,SB105X_PSR,SB105X_PSR_P4KEY);			ret = SB105X_GET_REG(port,reg);			SB105X_PUT_LCR(port,lcr);			break;		default:			printk("" error invalid page number \n"");			return -1;	}	return ret;}",7733
191,784,CVE-2013-7281,22,void raw6_proc_exit(void){	unregister_pernet_subsys(&raw6_net_ops);},12342
366,828,CVE-2015-8569,22,"static int pptp_release(struct socket *sock){	struct sock *sk = sock->sk;	struct pppox_sock *po;	struct pptp_opt *opt;	int error = 0;	if (!sk)		return 0;	lock_sock(sk);	if (sock_flag(sk, SOCK_DEAD)) {		release_sock(sk);		return -EBADF;	}	po = pppox_sk(sk);	opt = &po->proto.pptp;	del_chan(po);	pppox_unbind_sock(sk);	sk->sk_state = PPPOX_DEAD;	sock_orphan(sk);	sock->sk = NULL;	release_sock(sk);	sock_put(sk);	return error;}",12851
52,616,CVE-2013-1928,22,static int compat_ioctl_check_table(unsigned int xcmd){	int i;	const int max = ARRAY_SIZE(ioctl_pointer) - 1;	BUILD_BUG_ON(max >= (1 << 16));	 	i = ((xcmd >> 16) * max) >> 16;	 	while (ioctl_pointer[i] < xcmd && i < max)		i++;	 	while (ioctl_pointer[i] > xcmd && i > 0)		i--;	return ioctl_pointer[i] == xcmd;},9320
427,148,CVE-2018-11469,22,"smp_fetch_uniqueid(const struct arg *args, struct sample *smp, const char *kw, void *private){	if (LIST_ISEMPTY(&smp->sess->fe->format_unique_id))		return 0;	if (!smp->strm->unique_id) {		if ((smp->strm->unique_id = pool_alloc(pool_head_uniqueid)) == NULL)			return 0;		smp->strm->unique_id[0] = '\0';	}	smp->data.u.str.len = build_logline(smp->strm, smp->strm->unique_id,	                                    UNIQUEID_LEN, &smp->sess->fe->format_unique_id);	smp->data.type = SMP_T_STR;	smp->data.u.str.str = smp->strm->unique_id;	smp->flags = SMP_F_CONST;	return 1;}",1153
364,837,CVE-2015-8374,22,static void btrfs_dentry_release(struct dentry *dentry){	kfree(dentry->d_fsdata);},12920
274,913,CVE-2015-5697,22,"static void md_make_request(struct request_queue *q, struct bio *bio){	const int rw = bio_data_dir(bio);	struct mddev *mddev = q->queuedata;	unsigned int sectors;	int cpu;	if (mddev == NULL || mddev->pers == NULL	    || !mddev->ready) {		bio_io_error(bio);		return;	}	if (mddev->ro == 1 && unlikely(rw == WRITE)) {		bio_endio(bio, bio_sectors(bio) == 0 ? 0 : -EROFS);		return;	}	smp_rmb();  	rcu_read_lock();	if (mddev->suspended) {		DEFINE_WAIT(__wait);		for (;;) {			prepare_to_wait(&mddev->sb_wait, &__wait,					TASK_UNINTERRUPTIBLE);			if (!mddev->suspended)				break;			rcu_read_unlock();			schedule();			rcu_read_lock();		}		finish_wait(&mddev->sb_wait, &__wait);	}	atomic_inc(&mddev->active_io);	rcu_read_unlock();	 	sectors = bio_sectors(bio);	mddev->pers->make_request(mddev, bio);	cpu = part_stat_lock();	part_stat_inc(cpu, &mddev->gendisk->part0, ios[rw]);	part_stat_add(cpu, &mddev->gendisk->part0, sectors[rw], sectors);	part_stat_unlock();	if (atomic_dec_and_test(&mddev->active_io) && mddev->suspended)		wake_up(&mddev->sb_wait);}",13243
245,193,CVE-2012-0037,22,"raptor_rdfxml_check_propertyElement_name(const char *name) {  int i;  if(*name == '_')    return 1;    for(i = 0; raptor_rdf_ns_terms_info[i].name; i++)    if(!strcmp(raptor_rdf_ns_terms_info[i].name, (const char*)name))      return raptor_rdf_ns_terms_info[i].allowed_as_propertyElement;  return -1;}",4317
314,1681,CVE-2012-6544,22,"static void l2cap_sock_init(struct sock *sk, struct sock *parent){	struct l2cap_pinfo *pi = l2cap_pi(sk);	struct l2cap_chan *chan = pi->chan;	BT_DBG(""sk %p"", sk);	if (parent) {		struct l2cap_chan *pchan = l2cap_pi(parent)->chan;		sk->sk_type = parent->sk_type;		bt_sk(sk)->flags = bt_sk(parent)->flags;		chan->chan_type = pchan->chan_type;		chan->imtu = pchan->imtu;		chan->omtu = pchan->omtu;		chan->conf_state = pchan->conf_state;		chan->mode = pchan->mode;		chan->fcs  = pchan->fcs;		chan->max_tx = pchan->max_tx;		chan->tx_win = pchan->tx_win;		chan->tx_win_max = pchan->tx_win_max;		chan->sec_level = pchan->sec_level;		chan->flags = pchan->flags;		security_sk_clone(parent, sk);	} else {		switch (sk->sk_type) {		case SOCK_RAW:			chan->chan_type = L2CAP_CHAN_RAW;			break;		case SOCK_DGRAM:			chan->chan_type = L2CAP_CHAN_CONN_LESS;			break;		case SOCK_SEQPACKET:		case SOCK_STREAM:			chan->chan_type = L2CAP_CHAN_CONN_ORIENTED;			break;		}		chan->imtu = L2CAP_DEFAULT_MTU;		chan->omtu = 0;		if (!disable_ertm && sk->sk_type == SOCK_STREAM) {			chan->mode = L2CAP_MODE_ERTM;			set_bit(CONF_STATE2_DEVICE, &chan->conf_state);		} else {			chan->mode = L2CAP_MODE_BASIC;		}		l2cap_chan_set_defaults(chan);	}	 	chan->flush_to = L2CAP_DEFAULT_FLUSH_TO;	chan->data = sk;	chan->ops = &l2cap_chan_ops;}",28341
316,377,CVE-2013-3235,22,"static int listen(struct socket *sock, int len){	struct sock *sk = sock->sk;	int res;	lock_sock(sk);	if (sock->state != SS_UNCONNECTED)		res = -EINVAL;	else {		sock->state = SS_LISTENING;		res = 0;	}	release_sock(sk);	return res;}",8220
452,830,CVE-2015-8374,22,"static int backref_comp(struct sa_defrag_extent_backref *b1,			struct sa_defrag_extent_backref *b2){	if (b1->root_id < b2->root_id)		return -1;	else if (b1->root_id > b2->root_id)		return 1;	if (b1->inum < b2->inum)		return -1;	else if (b1->inum > b2->inum)		return 1;	if (b1->file_pos < b2->file_pos)		return -1;	else if (b1->file_pos > b2->file_pos)		return 1;	 	return 0;}",12913
217,732,CVE-2012-4530,22,"static int shift_arg_pages(struct vm_area_struct *vma, unsigned long shift){	struct mm_struct *mm = vma->vm_mm;	unsigned long old_start = vma->vm_start;	unsigned long old_end = vma->vm_end;	unsigned long length = old_end - old_start;	unsigned long new_start = old_start - shift;	unsigned long new_end = old_end - shift;	struct mmu_gather tlb;	BUG_ON(new_start > new_end);	 	if (vma != find_vma(mm, new_start))		return -EFAULT;	 	if (vma_adjust(vma, new_start, old_end, vma->vm_pgoff, NULL))		return -ENOMEM;	 	if (length != move_page_tables(vma, old_start,				       vma, new_start, length, false))		return -ENOMEM;	lru_add_drain();	tlb_gather_mmu(&tlb, mm, 0);	if (new_end > old_start) {		 		free_pgd_range(&tlb, new_end, old_end, new_end,			vma->vm_next ? vma->vm_next->vm_start : 0);	} else {		 		free_pgd_range(&tlb, old_start, old_end, new_end,			vma->vm_next ? vma->vm_next->vm_start : 0);	}	tlb_finish_mmu(&tlb, new_end, old_end);	 	vma_adjust(vma, new_start, new_end, vma->vm_pgoff, NULL);	return 0;}",9995
281,1193,CVE-2016-4482,22,"void usb_devio_cleanup(void){	usb_unregister_notify(&usbdev_nb);	cdev_del(&usb_device_cdev);	unregister_chrdev_region(USB_DEVICE_DEV, USB_DEVICE_MAX);}",16946
133,915,CVE-2015-5697,22,"static int md_mergeable_bvec(struct request_queue *q,			     struct bvec_merge_data *bvm,			     struct bio_vec *biovec){	struct mddev *mddev = q->queuedata;	int ret;	rcu_read_lock();	if (mddev->suspended) {		 		if (bvm->bi_size == 0)			ret = biovec->bv_len;		else			ret = 0;	} else {		struct md_personality *pers = mddev->pers;		if (pers && pers->mergeable_bvec)			ret = pers->mergeable_bvec(mddev, bvm, biovec);		else			ret = biovec->bv_len;	}	rcu_read_unlock();	return ret;}",13245
83,419,CVE-2013-3231,22,"static int llc_ui_autoport(void){	struct llc_sap *sap;	int i, tries = 0;	while (tries < LLC_SAP_DYN_TRIES) {		for (i = llc_ui_sap_last_autoport;		     i < LLC_SAP_DYN_STOP; i += 2) {			sap = llc_sap_find(i);			if (!sap) {				llc_ui_sap_last_autoport = i + 2;				goto out;			}			llc_sap_put(sap);		}		llc_ui_sap_last_autoport = LLC_SAP_DYN_START;		tries++;	}	i = 0;out:	return i;}",8262
99,135,CVE-2018-11469,22,"smp_fetch_hdrs(const struct arg *args, struct sample *smp, const char *kw, void *private){	struct http_msg *msg;	struct hdr_idx *idx;	struct http_txn *txn;	CHECK_HTTP_MESSAGE_FIRST();	txn = smp->strm->txn;	idx = &txn->hdr_idx;	msg = &txn->req;	smp->data.type = SMP_T_STR;	smp->data.u.str.str = msg->chn->buf->p + hdr_idx_first_pos(idx);	smp->data.u.str.len = msg->eoh - hdr_idx_first_pos(idx) + 1 +	                      (msg->chn->buf->p[msg->eoh] == '\r');	return 1;}",1140
349,1428,CVE-2017-10911,22,"int xen_blkif_schedule(void *arg){	struct xen_blkif_ring *ring = arg;	struct xen_blkif *blkif = ring->blkif;	struct xen_vbd *vbd = &blkif->vbd;	unsigned long timeout;	int ret;	set_freezable();	while (!kthread_should_stop()) {		if (try_to_freeze())			continue;		if (unlikely(vbd->size != vbd_sz(vbd)))			xen_vbd_resize(blkif);		timeout = msecs_to_jiffies(LRU_INTERVAL);		timeout = wait_event_interruptible_timeout(			ring->wq,			ring->waiting_reqs || kthread_should_stop(),			timeout);		if (timeout == 0)			goto purge_gnt_list;		timeout = wait_event_interruptible_timeout(			ring->pending_free_wq,			!list_empty(&ring->pending_free) ||			kthread_should_stop(),			timeout);		if (timeout == 0)			goto purge_gnt_list;		ring->waiting_reqs = 0;		smp_mb();  		ret = do_block_io_op(ring);		if (ret > 0)			ring->waiting_reqs = 1;		if (ret == -EACCES)			wait_event_interruptible(ring->shutdown_wq,						 kthread_should_stop());purge_gnt_list:		if (blkif->vbd.feature_gnt_persistent &&		    time_after(jiffies, ring->next_lru)) {			purge_persistent_gnt(ring);			ring->next_lru = jiffies + msecs_to_jiffies(LRU_INTERVAL);		}		 		shrink_free_pagepool(ring, xen_blkif_max_buffer_pages);		if (log_stats && time_after(jiffies, ring->st_print))			print_stats(ring);	}	 	flush_work(&ring->persistent_purge_work);	if (log_stats)		print_stats(ring);	ring->xenblkd = NULL;	return 0;}",20600
277,986,CVE-2015-5302,22,"static char *run_event_gtk_logging(char *log_line, void *param){    struct analyze_event_data *evd = (struct analyze_event_data *)param;    update_command_run_log(log_line, evd);    return log_line;}",13412
255,1139,CVE-2016-4569,22,"static void snd_timer_user_tinterrupt(struct snd_timer_instance *timeri,				      unsigned long resolution,				      unsigned long ticks){	struct snd_timer_user *tu = timeri->callback_data;	struct snd_timer_tread *r, r1;	struct timespec tstamp;	int prev, append = 0;	memset(&tstamp, 0, sizeof(tstamp));	spin_lock(&tu->qlock);	if ((tu->filter & ((1 << SNDRV_TIMER_EVENT_RESOLUTION) |			   (1 << SNDRV_TIMER_EVENT_TICK))) == 0) {		spin_unlock(&tu->qlock);		return;	}	if (tu->last_resolution != resolution || ticks > 0) {		if (timer_tstamp_monotonic)			ktime_get_ts(&tstamp);		else			getnstimeofday(&tstamp);	}	if ((tu->filter & (1 << SNDRV_TIMER_EVENT_RESOLUTION)) &&	    tu->last_resolution != resolution) {		r1.event = SNDRV_TIMER_EVENT_RESOLUTION;		r1.tstamp = tstamp;		r1.val = resolution;		snd_timer_user_append_to_tqueue(tu, &r1);		tu->last_resolution = resolution;		append++;	}	if ((tu->filter & (1 << SNDRV_TIMER_EVENT_TICK)) == 0)		goto __wake;	if (ticks == 0)		goto __wake;	if (tu->qused > 0) {		prev = tu->qtail == 0 ? tu->queue_size - 1 : tu->qtail - 1;		r = &tu->tqueue[prev];		if (r->event == SNDRV_TIMER_EVENT_TICK) {			r->tstamp = tstamp;			r->val += ticks;			append++;			goto __wake;		}	}	r1.event = SNDRV_TIMER_EVENT_TICK;	r1.tstamp = tstamp;	r1.val = ticks;	snd_timer_user_append_to_tqueue(tu, &r1);	append++;      __wake:	spin_unlock(&tu->qlock);	if (append == 0)		return;	kill_fasync(&tu->fasync, SIGIO, POLL_IN);	wake_up(&tu->qchange_sleep);}",16727
417,261,CVE-2013-4516,22,"static void mp_throttle(struct tty_struct *tty){	struct sb_uart_state *state = tty->driver_data;	if (I_IXOFF(tty))		mp_send_xchar(tty, STOP_CHAR(tty));	if (tty->termios.c_cflag & CRTSCTS)		uart_clear_mctrl(state->port, TIOCM_RTS);}",7699
168,572,CVE-2013-3076,22,"static void skcipher_free_sgl(struct sock *sk){	struct alg_sock *ask = alg_sk(sk);	struct skcipher_ctx *ctx = ask->private;	skcipher_pull_sgl(sk, ctx->used);}",8415
147,1652,CVE-2012-6545,22,void rfcomm_cleanup_ttys(void){	tty_unregister_driver(rfcomm_tty_driver);	put_tty_driver(rfcomm_tty_driver);},28312
212,1382,CVE-2017-15537,22,void fpu__init_prepare_fx_sw_frame(void){	int size = fpu_user_xstate_size + FP_XSTATE_MAGIC2_SIZE;	fx_sw_reserved.magic1 = FP_XSTATE_MAGIC1;	fx_sw_reserved.extended_size = size;	fx_sw_reserved.xfeatures = xfeatures_mask;	fx_sw_reserved.xstate_size = fpu_user_xstate_size;	if (IS_ENABLED(CONFIG_IA32_EMULATION) ||	    IS_ENABLED(CONFIG_X86_32)) {		int fsave_header_size = sizeof(struct fregs_state);		fx_sw_reserved_ia32 = fx_sw_reserved;		fx_sw_reserved_ia32.extended_size = size + fsave_header_size;	}},19981
310,463,CVE-2013-3229,22,"static void iucv_sock_destruct(struct sock *sk){	skb_queue_purge(&sk->sk_receive_queue);	skb_queue_purge(&sk->sk_error_queue);	sk_mem_reclaim(sk);	if (!sock_flag(sk, SOCK_DEAD)) {		pr_err(""Attempt to release alive iucv socket %p\n"", sk);		return;	}	WARN_ON(atomic_read(&sk->sk_rmem_alloc));	WARN_ON(atomic_read(&sk->sk_wmem_alloc));	WARN_ON(sk->sk_wmem_queued);	WARN_ON(sk->sk_forward_alloc);}",8306
107,232,CVE-2013-4516,22,"static void autoconfig_irq(struct mp_port *mtpt){	unsigned char save_mcr, save_ier;	unsigned long irqs;	int irq;	 	probe_irq_off(probe_irq_on());	save_mcr = serial_inp(mtpt, UART_MCR);	save_ier = serial_inp(mtpt, UART_IER);	serial_outp(mtpt, UART_MCR, UART_MCR_OUT1 | UART_MCR_OUT2);	irqs = probe_irq_on();	serial_outp(mtpt, UART_MCR, 0);	serial_outp(mtpt, UART_MCR,		UART_MCR_DTR | UART_MCR_RTS | UART_MCR_OUT2);	serial_outp(mtpt, UART_IER, 0x0f);     	(void)serial_inp(mtpt, UART_LSR);	(void)serial_inp(mtpt, UART_RX);	(void)serial_inp(mtpt, UART_IIR);	(void)serial_inp(mtpt, UART_MSR);	serial_outp(mtpt, UART_TX, 0xFF);	irq = probe_irq_off(irqs);	serial_outp(mtpt, UART_MCR, save_mcr);	serial_outp(mtpt, UART_IER, save_ier);	mtpt->port.irq = (irq > 0) ? irq : 0;}",7670
151,180,CVE-2017-0379,22,"_gcry_register_pk_ecc_progress (void (*cb) (void *, const char *,                                            int, int, int),                                void *cb_data){  progress_cb = cb;  progress_cb_data = cb_data;}",2157
437,488,CVE-2013-3227,22,"static int rx_flow_is_on(struct caifsock *cf_sk){	return test_bit(RX_FLOW_ON_BIT,			(void *) &cf_sk->flow_state);}",8331
88,682,CVE-2012-6541,22,"static const char *ccid3_rx_state_name(enum ccid3_hc_rx_states state){	static const char *const ccid3_rx_state_names[] = {	[TFRC_RSTATE_NO_DATA] = ""NO_DATA"",	[TFRC_RSTATE_DATA]    = ""DATA"",	};	return ccid3_rx_state_names[state];}",9869
100,1675,CVE-2012-6544,22,"static int l2cap_sock_accept(struct socket *sock, struct socket *newsock, int flags){	DECLARE_WAITQUEUE(wait, current);	struct sock *sk = sock->sk, *nsk;	long timeo;	int err = 0;	lock_sock_nested(sk, SINGLE_DEPTH_NESTING);	timeo = sock_rcvtimeo(sk, flags & O_NONBLOCK);	BT_DBG(""sk %p timeo %ld"", sk, timeo);	 	add_wait_queue_exclusive(sk_sleep(sk), &wait);	while (1) {		set_current_state(TASK_INTERRUPTIBLE);		if (sk->sk_state != BT_LISTEN) {			err = -EBADFD;			break;		}		nsk = bt_accept_dequeue(sk, newsock);		if (nsk)			break;		if (!timeo) {			err = -EAGAIN;			break;		}		if (signal_pending(current)) {			err = sock_intr_errno(timeo);			break;		}		release_sock(sk);		timeo = schedule_timeout(timeo);		lock_sock_nested(sk, SINGLE_DEPTH_NESTING);	}	__set_current_state(TASK_RUNNING);	remove_wait_queue(sk_sleep(sk), &wait);	if (err)		goto done;	newsock->state = SS_CONNECTED;	BT_DBG(""new socket %p"", nsk);done:	release_sock(sk);	return err;}",28335
436,807,CVE-2011-2909,22,"static void comedi_device_init(struct comedi_device *dev){	memset(dev, 0, sizeof(struct comedi_device));	spin_lock_init(&dev->spinlock);	mutex_init(&dev->mutex);	dev->minor = -1;}",12768
45,1167,CVE-2016-4486,22,"static int rtnl_phys_switch_id_fill(struct sk_buff *skb, struct net_device *dev){	int err;	struct switchdev_attr attr = {		.orig_dev = dev,		.id = SWITCHDEV_ATTR_ID_PORT_PARENT_ID,		.flags = SWITCHDEV_F_NO_RECURSE,	};	err = switchdev_port_attr_get(dev, &attr);	if (err) {		if (err == -EOPNOTSUPP)			return 0;		return err;	}	if (nla_put(skb, IFLA_PHYS_SWITCH_ID, attr.u.ppid.id_len,		    attr.u.ppid.id))		return -EMSGSIZE;	return 0;}",16920
77,1345,CVE-2014-9903,22,"static int sched_feat_show(struct seq_file *m, void *v){	int i;	for (i = 0; i < __SCHED_FEAT_NR; i++) {		if (!(sysctl_sched_features & (1UL << i)))			seq_puts(m, ""NO_"");		seq_printf(m, ""%s "", sched_feat_names[i]);	}	seq_puts(m, ""\n"");	return 0;}",19282
443,156,CVE-2018-11469,22,"int stats_check_uri(struct stream_interface *si, struct http_txn *txn, struct proxy *backend){	struct uri_auth *uri_auth = backend->uri_auth;	struct http_msg *msg = &txn->req;	const char *uri = msg->chn->buf->p+ msg->sl.rq.u;	if (!uri_auth)		return 0;	if (txn->meth != HTTP_METH_GET && txn->meth != HTTP_METH_HEAD && txn->meth != HTTP_METH_POST)		return 0;	 	if (uri_auth->uri_len > msg->sl.rq.u_l)		return 0;	if (memcmp(uri, uri_auth->uri_prefix, uri_auth->uri_len) != 0)		return 0;	return 1;}",1161
9,1007,CVE-2016-5696,22,"struct request_sock *inet_reqsk_alloc(const struct request_sock_ops *ops,				      struct sock *sk_listener,				      int attach_listener){	struct request_sock *req = reqsk_alloc(ops, sk_listener,					       attach_listener);	if (req) {		struct inet_request_sock *ireq = inet_rsk(req);		kmemcheck_annotate_bitfield(ireq, flags);		ireq->opt = NULL;		atomic64_set(&ireq->ir_cookie, 0);		ireq->ireq_state = TCP_NEW_SYN_RECV;		write_pnet(&ireq->ireq_net, sock_net(sk_listener));		ireq->ireq_family = sk_listener->sk_family;	}	return req;}",16383
166,855,CVE-2015-8374,22,"static int btrfs_setattr(struct dentry *dentry, struct iattr *attr){	struct inode *inode = d_inode(dentry);	struct btrfs_root *root = BTRFS_I(inode)->root;	int err;	if (btrfs_root_readonly(root))		return -EROFS;	err = inode_change_ok(inode, attr);	if (err)		return err;	if (S_ISREG(inode->i_mode) && (attr->ia_valid & ATTR_SIZE)) {		err = btrfs_setsize(inode, attr);		if (err)			return err;	}	if (attr->ia_valid) {		setattr_copy(inode, attr);		inode_inc_iversion(inode);		err = btrfs_dirty_inode(inode);		if (!err && attr->ia_valid & ATTR_MODE)			err = posix_acl_chmod(inode, inode->i_mode);	}	return err;}",12938
339,875,CVE-2015-7884,22,"static int vivid_fb_check_var(struct fb_var_screeninfo *var, struct fb_info *info){	struct vivid_dev *dev = (struct vivid_dev *) info->par;	dprintk(dev, 1, ""vivid_fb_check_var\n"");	return _vivid_fb_check_var(var, dev);}",13052
57,515,CVE-2013-3225,22,"static void rfcomm_sock_cleanup_listen(struct sock *parent){	struct sock *sk;	BT_DBG(""parent %p"", parent);	 	while ((sk = bt_accept_dequeue(parent, NULL))) {		rfcomm_sock_close(sk);		rfcomm_sock_kill(sk);	}	parent->sk_state  = BT_CLOSED;	sock_set_flag(parent, SOCK_ZAPPED);}",8358
80,850,CVE-2015-8374,22,"void btrfs_orphan_commit_root(struct btrfs_trans_handle *trans,			      struct btrfs_root *root){	struct btrfs_block_rsv *block_rsv;	int ret;	if (atomic_read(&root->orphan_inodes) ||	    root->orphan_cleanup_state != ORPHAN_CLEANUP_DONE)		return;	spin_lock(&root->orphan_lock);	if (atomic_read(&root->orphan_inodes)) {		spin_unlock(&root->orphan_lock);		return;	}	if (root->orphan_cleanup_state != ORPHAN_CLEANUP_DONE) {		spin_unlock(&root->orphan_lock);		return;	}	block_rsv = root->orphan_block_rsv;	root->orphan_block_rsv = NULL;	spin_unlock(&root->orphan_lock);	if (test_bit(BTRFS_ROOT_ORPHAN_ITEM_INSERTED, &root->state) &&	    btrfs_root_refs(&root->root_item) > 0) {		ret = btrfs_del_orphan_item(trans, root->fs_info->tree_root,					    root->root_key.objectid);		if (ret)			btrfs_abort_transaction(trans, root, ret);		else			clear_bit(BTRFS_ROOT_ORPHAN_ITEM_INSERTED,				  &root->state);	}	if (block_rsv) {		WARN_ON(block_rsv->size > 0);		btrfs_free_block_rsv(root, block_rsv);	}}",12933
155,102,CVE-2018-11469,22,"static inline int language_range_match(const char *range, int range_len,                                       const char *tag, int tag_len){	const char *end = range + range_len;	const char *tend = tag + tag_len;	while (range < end) {		if (*range == '-' && tag == tend)			return 1;		if (*range != *tag || tag == tend)			return 0;		range++;		tag++;	}	 	return tag == tend;}",1107
403,1243,CVE-2016-0823,22,"static int show_pid_map(struct seq_file *m, void *v){	return show_map(m, v, 1);}",18205
422,174,CVE-2014-3508,22,"const void *OBJ_bsearch_(const void *key, const void *base, int num, int size,			 int (*cmp)(const void *, const void *))	{	return OBJ_bsearch_ex_(key, base, num, size, cmp, 0);	}",2061
335,1620,CVE-2019-10639,22,"static void rtnl_net_notifyid(struct net *net, int cmd, int id){	struct net_fill_args fillargs = {		.cmd = cmd,		.nsid = id,	};	struct sk_buff *msg;	int err = -ENOMEM;	msg = nlmsg_new(rtnl_net_get_size(), GFP_KERNEL);	if (!msg)		goto out;	err = rtnl_net_fill(msg, &fillargs);	if (err < 0)		goto err_out;	rtnl_notify(msg, net, 0, RTNLGRP_NSID, NULL, 0);	return;err_out:	nlmsg_free(msg);out:	rtnl_set_sk_err(net, RTNLGRP_NSID, err);}",27187
406,1491,CVE-2017-0377,22,"get_remove_unlisted_guards_after_days(void){  return networkstatus_get_param(NULL,                                 ""guard-remove-unlisted-guards-after-days"",                                 DFLT_REMOVE_UNLISTED_GUARDS_AFTER_DAYS,                                 1, 365*10);}",22254
86,764,CVE-2014-7284,22,int net_ratelimit(void){	return __ratelimit(&net_ratelimit_state);},10541
290,1608,CVE-2019-10639,22,"struct net *get_net_ns_by_id(struct net *net, int id){	struct net *peer;	if (id < 0)		return NULL;	rcu_read_lock();	peer = idr_find(&net->netns_ids, id);	if (peer)		peer = maybe_get_net(peer);	rcu_read_unlock();	return peer;}",27175
219,957,CVE-2015-5697,22,static inline int speed_max(struct mddev *mddev){	return mddev->sync_speed_max ?		mddev->sync_speed_max : sysctl_speed_limit_max;},13287
2,269,CVE-2013-4516,22,"static void mp_update_termios(struct sb_uart_state *state){	struct tty_struct *tty = state->info->tty;	struct sb_uart_port *port = state->port;	if (!(tty->flags & (1 << TTY_IO_ERROR))) {		mp_change_speed(state, NULL);		if (tty->termios.c_cflag & CBAUD)			uart_set_mctrl(port, TIOCM_DTR | TIOCM_RTS);	}}",7707
408,1662,CVE-2012-6545,22,"static void rfcomm_tty_flush_buffer(struct tty_struct *tty){	struct rfcomm_dev *dev = (struct rfcomm_dev *) tty->driver_data;	BT_DBG(""tty %p dev %p"", tty, dev);	if (!dev || !dev->dlc)		return;	skb_queue_purge(&dev->dlc->tx_queue);	tty_wakeup(tty);}",28322
126,1673,CVE-2012-6545,22,"static void rfcomm_wfree(struct sk_buff *skb){	struct rfcomm_dev *dev = (void *) skb->sk;	struct tty_struct *tty = dev->port.tty;	atomic_sub(skb->truesize, &dev->wmem_alloc);	if (test_bit(RFCOMM_TTY_ATTACHED, &dev->flags) && tty)		tty_wakeup(tty);	tty_port_put(&dev->port);}",28333
294,1735,CVE-2018-6053,22,  int IsTopSitesLoaded() { return top_sites()->loaded_; },30086
102,321,CVE-2013-3237,22,"static int vsock_create(struct net *net, struct socket *sock,			int protocol, int kern){	if (!sock)		return -EINVAL;	if (protocol && protocol != PF_VSOCK)		return -EPROTONOSUPPORT;	switch (sock->type) {	case SOCK_DGRAM:		sock->ops = &vsock_dgram_ops;		break;	case SOCK_STREAM:		sock->ops = &vsock_stream_ops;		break;	default:		return -ESOCKTNOSUPPORT;	}	sock->state = SS_UNCONNECTED;	return __vsock_create(net, sock, NULL, GFP_KERNEL, 0) ? 0 : -ENOMEM;}",8164
142,322,CVE-2013-3237,22,"static long vsock_dev_compat_ioctl(struct file *filp,				   unsigned int cmd, unsigned long arg){	return vsock_dev_do_ioctl(filp, cmd, compat_ptr(arg));}",8165
283,446,CVE-2013-3229,22,"static int afiucv_iucv_init(void){	int err;	err = pr_iucv->iucv_register(&af_iucv_handler, 0);	if (err)		goto out;	 	af_iucv_driver.bus = pr_iucv->bus;	err = driver_register(&af_iucv_driver);	if (err)		goto out_iucv;	af_iucv_dev = kzalloc(sizeof(struct device), GFP_KERNEL);	if (!af_iucv_dev) {		err = -ENOMEM;		goto out_driver;	}	dev_set_name(af_iucv_dev, ""af_iucv"");	af_iucv_dev->bus = pr_iucv->bus;	af_iucv_dev->parent = pr_iucv->root;	af_iucv_dev->release = (void (*)(struct device *))kfree;	af_iucv_dev->driver = &af_iucv_driver;	err = device_register(af_iucv_dev);	if (err)		goto out_driver;	return 0;out_driver:	driver_unregister(&af_iucv_driver);out_iucv:	pr_iucv->iucv_unregister(&af_iucv_handler, 0);out:	return err;}",8289
447,222,CVE-2011-1078,22,"static int sco_sock_getname(struct socket *sock, struct sockaddr *addr, int *len, int peer){	struct sockaddr_sco *sa = (struct sockaddr_sco *) addr;	struct sock *sk = sock->sk;	BT_DBG(""sock %p, sk %p"", sock, sk);	addr->sa_family = AF_BLUETOOTH;	*len = sizeof(struct sockaddr_sco);	if (peer)		bacpy(&sa->sco_bdaddr, &bt_sk(sk)->dst);	else		bacpy(&sa->sco_bdaddr, &bt_sk(sk)->src);	return 0;}",6954
192,884,CVE-2015-5697,22,"action_show(struct mddev *mddev, char *page){	char *type = ""idle"";	unsigned long recovery = mddev->recovery;	if (test_bit(MD_RECOVERY_FROZEN, &recovery))		type = ""frozen"";	else if (test_bit(MD_RECOVERY_RUNNING, &recovery) ||	    (!mddev->ro && test_bit(MD_RECOVERY_NEEDED, &recovery))) {		if (test_bit(MD_RECOVERY_RESHAPE, &recovery))			type = ""reshape"";		else if (test_bit(MD_RECOVERY_SYNC, &recovery)) {			if (!test_bit(MD_RECOVERY_REQUESTED, &recovery))				type = ""resync"";			else if (test_bit(MD_RECOVERY_CHECK, &recovery))				type = ""check"";			else				type = ""repair"";		} else if (test_bit(MD_RECOVERY_RECOVER, &recovery))			type = ""recover"";	}	return sprintf(page, ""%s\n"", type);}",13214
161,710,CVE-2012-6540,22,void ip_vs_unregister_nl_ioctl(void){	ip_vs_genl_unregister();	nf_unregister_sockopt(&ip_vs_sockopts);},9897
301,80,CVE-2018-11469,22,"void http_perform_server_redirect(struct stream *s, struct stream_interface *si){	struct http_txn *txn;	struct server *srv;	char *path;	int len, rewind;	 	trash.len = strlen(HTTP_302);	memcpy(trash.str, HTTP_302, trash.len);	srv = objt_server(s->target);	 	if (trash.len + srv->rdr_len > trash.size)		return;	 	if (srv->rdr_len != 1 || *srv->rdr_pfx != '/') {		memcpy(trash.str + trash.len, srv->rdr_pfx, srv->rdr_len);		trash.len += srv->rdr_len;	}	 	txn = s->txn;	b_rew(s->req.buf, rewind = http_hdr_rewind(&txn->req));	path = http_get_path(txn);	len = buffer_count(s->req.buf, path, b_ptr(s->req.buf, txn->req.sl.rq.u + txn->req.sl.rq.u_l));	b_adv(s->req.buf, rewind);	if (!path)		return;	if (trash.len + len > trash.size - 4)  		return;	memcpy(trash.str + trash.len, path, len);	trash.len += len;	if (unlikely(txn->flags & TX_USE_PX_CONN)) {		memcpy(trash.str + trash.len, ""\r\nProxy-Connection: close\r\n\r\n"", 29);		trash.len += 29;	} else {		memcpy(trash.str + trash.len, ""\r\nConnection: close\r\n\r\n"", 23);		trash.len += 23;	}	 	si_shutr(si);	si_shutw(si);	si->err_type = SI_ET_NONE;	si->state    = SI_ST_CLO;	 	txn->status = 302;	http_server_error(s, si, SF_ERR_LOCAL, SF_FINST_C, &trash);	 	srv_inc_sess_ctr(srv);	srv_set_sess_last(srv);}",1085
103,283,CVE-2013-4516,22,static int multi_request_port(struct sb_uart_port *port){	return 0;},7721
42,167,CVE-2016-5337,22,"static int megasas_setup_inquiry(int *cdb, int pg, int len){    memset(cdb, 0, 6);    cdb[0] = INQUIRY;    if (pg > 0) {        cdb[1] = 0x1;        cdb[2] = pg;    }    cdb[3] = (len >> 8) & 0xff;    cdb[4] = (len & 0xff);    return len;}",1846
261,1289,CVE-2015-8575,22,"static void sco_conn_ready(struct sco_conn *conn){	struct sock *parent;	struct sock *sk = conn->sk;	BT_DBG(""conn %p"", conn);	if (sk) {		sco_sock_clear_timer(sk);		bh_lock_sock(sk);		sk->sk_state = BT_CONNECTED;		sk->sk_state_change(sk);		bh_unlock_sock(sk);	} else {		sco_conn_lock(conn);		if (!conn->hcon) {			sco_conn_unlock(conn);			return;		}		parent = sco_get_sock_listen(&conn->hcon->src);		if (!parent) {			sco_conn_unlock(conn);			return;		}		bh_lock_sock(parent);		sk = sco_sock_alloc(sock_net(parent), NULL,				    BTPROTO_SCO, GFP_ATOMIC, 0);		if (!sk) {			bh_unlock_sock(parent);			sco_conn_unlock(conn);			return;		}		sco_sock_init(sk, parent);		bacpy(&sco_pi(sk)->src, &conn->hcon->src);		bacpy(&sco_pi(sk)->dst, &conn->hcon->dst);		hci_conn_hold(conn->hcon);		__sco_chan_add(conn, sk, parent);		if (test_bit(BT_SK_DEFER_SETUP, &bt_sk(parent)->flags))			sk->sk_state = BT_CONNECT2;		else			sk->sk_state = BT_CONNECTED;		 		parent->sk_data_ready(parent);		bh_unlock_sock(parent);		sco_conn_unlock(conn);	}}",18925
282,1103,CVE-2016-4578,22,static int snd_timer_dev_free(struct snd_device *device){	struct snd_timer *timer = device->device_data;	return snd_timer_free(timer);},16691
333,1451,CVE-2017-9150,22,"static int check_stack_read(struct bpf_verifier_state *state, int off, int size,			    int value_regno){	u8 *slot_type;	int i;	slot_type = &state->stack_slot_type[MAX_BPF_STACK + off];	if (slot_type[0] == STACK_SPILL) {		if (size != BPF_REG_SIZE) {			verbose(""invalid size of register spill\n"");			return -EACCES;		}		for (i = 1; i < BPF_REG_SIZE; i++) {			if (slot_type[i] != STACK_SPILL) {				verbose(""corrupted spill memory\n"");				return -EACCES;			}		}		if (value_regno >= 0)			 			state->regs[value_regno] =				state->spilled_regs[(MAX_BPF_STACK + off) / BPF_REG_SIZE];		return 0;	} else {		for (i = 0; i < size; i++) {			if (slot_type[i] != STACK_MISC) {				verbose(""invalid read from stack off %d+%d size %d\n"",					off, i, size);				return -EACCES;			}		}		if (value_regno >= 0)			 			mark_reg_unknown_value_and_range(state->regs,							 value_regno);		return 0;	}}",20836
16,665,CVE-2012-6545,22,"static int rfcomm_sock_bind(struct socket *sock, struct sockaddr *addr, int addr_len){	struct sockaddr_rc *sa = (struct sockaddr_rc *) addr;	struct sock *sk = sock->sk;	int err = 0;	BT_DBG(""sk %p %s"", sk, batostr(&sa->rc_bdaddr));	if (!addr || addr->sa_family != AF_BLUETOOTH)		return -EINVAL;	lock_sock(sk);	if (sk->sk_state != BT_OPEN) {		err = -EBADFD;		goto done;	}	if (sk->sk_type != SOCK_STREAM) {		err = -EINVAL;		goto done;	}	write_lock(&rfcomm_sk_list.lock);	if (sa->rc_channel && __rfcomm_get_sock_by_addr(sa->rc_channel, &sa->rc_bdaddr)) {		err = -EADDRINUSE;	} else {		 		bacpy(&bt_sk(sk)->src, &sa->rc_bdaddr);		rfcomm_pi(sk)->channel = sa->rc_channel;		sk->sk_state = BT_BOUND;	}	write_unlock(&rfcomm_sk_list.lock);done:	release_sock(sk);	return err;}",9852
175,1261,CVE-2015-8964,22,"static void tty_ldisc_close(struct tty_struct *tty, struct tty_ldisc *ld){	WARN_ON(!test_bit(TTY_LDISC_OPEN, &tty->flags));	clear_bit(TTY_LDISC_OPEN, &tty->flags);	if (ld->ops->close)		ld->ops->close(tty);	tty_ldisc_debug(tty, ""%p: closed\n"", tty->ldisc);}",18300
122,1192,CVE-2016-4482,22,"static void snoop_urb_data(struct urb *urb, unsigned len){	int i, size;	len = min(len, usbfs_snoop_max);	if (!usbfs_snoop || len == 0)		return;	if (urb->num_sgs == 0) {		print_hex_dump(KERN_DEBUG, ""data: "", DUMP_PREFIX_NONE, 32, 1,			urb->transfer_buffer, len, 1);		return;	}	for (i = 0; i < urb->num_sgs && len; i++) {		size = (len > USB_SG_SIZE) ? USB_SG_SIZE : len;		print_hex_dump(KERN_DEBUG, ""data: "", DUMP_PREFIX_NONE, 32, 1,			sg_virt(&urb->sg[i]), size, 1);		len -= size;	}}",16945
174,1808,CVE-2012-6536,22,"static int xfrm_alloc_replay_state_esn(struct xfrm_replay_state_esn **replay_esn,				       struct xfrm_replay_state_esn **preplay_esn, 				       struct nlattr *rta) { 	struct xfrm_replay_state_esn *p, *pp, *up;  	if (!rta) 		return 0;  	up = nla_data(rta); 	p = kmemdup(up, xfrm_replay_state_esn_len(up), GFP_KERNEL); 	if (!p) 		return -ENOMEM; 	pp = kmemdup(up, xfrm_replay_state_esn_len(up), GFP_KERNEL); 	if (!pp) { 		kfree(p); 		return -ENOMEM; 	}  	*replay_esn = p; 	*preplay_esn = pp; 	return 0;}",31107
350,1359,CVE-2014-9903,22,"void set_user_nice(struct task_struct *p, long nice){	int old_prio, delta, on_rq;	unsigned long flags;	struct rq *rq;	if (TASK_NICE(p) == nice || nice < -20 || nice > 19)		return;	 	rq = task_rq_lock(p, &flags);	 	if (task_has_dl_policy(p) || task_has_rt_policy(p)) {		p->static_prio = NICE_TO_PRIO(nice);		goto out_unlock;	}	on_rq = p->on_rq;	if (on_rq)		dequeue_task(rq, p, 0);	p->static_prio = NICE_TO_PRIO(nice);	set_load_weight(p);	old_prio = p->prio;	p->prio = effective_prio(p);	delta = p->prio - old_prio;	if (on_rq) {		enqueue_task(rq, p, 0);		 		if (delta < 0 || (delta > 0 && task_running(rq, p)))			resched_task(rq->curr);	}out_unlock:	task_rq_unlock(rq, p, &flags);}",19296
164,1609,CVE-2019-10639,22,"static int net_assign_generic(struct net *net, unsigned int id, void *data){	struct net_generic *ng, *old_ng;	BUG_ON(id < MIN_PERNET_OPS_ID);	old_ng = rcu_dereference_protected(net->gen,					   lockdep_is_held(&pernet_ops_rwsem));	if (old_ng->s.len > id) {		old_ng->ptr[id] = data;		return 0;	}	ng = net_alloc_generic();	if (ng == NULL)		return -ENOMEM;	 	memcpy(&ng->ptr[MIN_PERNET_OPS_ID], &old_ng->ptr[MIN_PERNET_OPS_ID],	       (old_ng->s.len - MIN_PERNET_OPS_ID) * sizeof(void *));	ng->ptr[id] = data;	rcu_assign_pointer(net->gen, ng);	kfree_rcu(old_ng, s.rcu);	return 0;}",27176
112,1749,CVE-2019-5837,22,  void BasicFindMainResponseInDatabase() { BasicFindMainResponse(true); },30161
292,249,CVE-2013-4516,22,"static int mp_ioctl(struct tty_struct *tty, unsigned int cmd, unsigned long arg){	struct sb_uart_state *state = tty->driver_data;	struct mp_port *info = (struct mp_port *)state->port;	int ret = -ENOIOCTLCMD;	switch (cmd) {		case TIOCSMULTIDROP:			 			if (info->port.type == PORT_16C105XA)			{				return set_multidrop_mode((struct sb_uart_port *)info, (unsigned int)arg);			}			ret = -ENOTSUPP;			break;		case GETDEEPFIFO:			ret = get_deep_fifo(state->port);			return ret;		case SETDEEPFIFO:			ret = set_deep_fifo(state->port,arg);			deep[state->port->line] = arg;			return ret;		case SETTTR:			if (info->port.type == PORT_16C105X || info->port.type == PORT_16C105XA){				ret = sb1054_set_register(state->port,PAGE_4,SB105X_TTR,arg);				ttr[state->port->line] = arg;			}			return ret;		case SETRTR:			if (info->port.type == PORT_16C105X || info->port.type == PORT_16C105XA){				ret = sb1054_set_register(state->port,PAGE_4,SB105X_RTR,arg);				rtr[state->port->line] = arg;			}			return ret;		case GETTTR:			if (info->port.type == PORT_16C105X || info->port.type == PORT_16C105XA){				ret = sb1054_get_register(state->port,PAGE_4,SB105X_TTR);			}			return ret;		case GETRTR:			if (info->port.type == PORT_16C105X || info->port.type == PORT_16C105XA){				ret = sb1054_get_register(state->port,PAGE_4,SB105X_RTR);			}			return ret;		case SETFCR:			if (info->port.type == PORT_16C105X || info->port.type == PORT_16C105XA){				ret = sb1054_set_register(state->port,PAGE_1,SB105X_FCR,arg);			}			else{				serial_out(info,2,arg);			}			return ret;		case TIOCSMDADDR:			 			if (info->port.type == PORT_16C105XA)			{				state->port->mdmode |= MDMODE_ADDR;				return set_multidrop_addr((struct sb_uart_port *)info, (unsigned int)arg);			}			ret = -ENOTSUPP;			break;		case TIOCGMDADDR:			 			if ((info->port.type == PORT_16C105XA) && (state->port->mdmode & MDMODE_ADDR))			{				return get_multidrop_addr((struct sb_uart_port *)info);			}			ret = -ENOTSUPP;			break;		case TIOCSENDADDR:			 			if ((info->port.type == PORT_16C105XA) 					&& (state->port->mdmode & (MDMODE_ENABLE)))			{				if (mp_chars_in_buffer(tty) > 0)				{					tty_wait_until_sent(tty, 0);				}				while ((serial_in(info, UART_LSR) & 0x60) != 0x60);				serial_out(info, UART_SCR, (int)arg);			}			break;		case TIOCGSERIAL:			ret = mp_get_info(state, (struct serial_struct *)arg);			break;		case TIOCSSERIAL:			ret = mp_set_info(state, (struct serial_struct *)arg);			break;		case TIOCSERCONFIG:			ret = mp_do_autoconfig(state);			break;		case TIOCSERGWILD:  		case TIOCSERSWILD:  			ret = 0;			break;			 		case TIOCGNUMOFPORT:  			return NR_PORTS;		case TIOCGGETDEVID:			return mp_devs[arg].device_id;		case TIOCGGETREV:			return mp_devs[arg].revision;		case TIOCGGETNRPORTS:			return mp_devs[arg].nr_ports;		case TIOCGGETBDNO:			return NR_BOARD;		case TIOCGGETINTERFACE:			if (mp_devs[arg].revision == 0xc0)			{				 				return (sb1053a_get_interface(info, info->port.line));			}			else			{				return (inb(mp_devs[arg].option_reg_addr+MP_OPTR_IIR0+(state->port->line/8)));			}		case TIOCGGETPORTTYPE:			ret = get_device_type(arg);;			return ret;		case TIOCSMULTIECHO:  			outb( ( inb(info->interface_config_addr) & ~0x03 ) | 0x01 ,  					info->interface_config_addr);			return 0;		case TIOCSPTPNOECHO:  			outb( ( inb(info->interface_config_addr) & ~0x03 )  ,             					info->interface_config_addr);			return 0;	}	if (ret != -ENOIOCTLCMD)		goto out;	if (tty->flags & (1 << TTY_IO_ERROR)) {		ret = -EIO;		goto out;	}	switch (cmd) {		case TIOCMIWAIT:			ret = mp_wait_modem_status(state, arg);			break;		case TIOCGICOUNT:			ret = mp_get_count(state, (struct serial_icounter_struct *)arg);			break;	}	if (ret != -ENOIOCTLCMD)		goto out;	MP_STATE_LOCK(state);	switch (cmd) {		case TIOCSERGETLSR:  			ret = mp_get_lsr_info(state, (unsigned int *)arg);			break;		default: {					struct sb_uart_port *port = state->port;					if (port->ops->ioctl)						ret = port->ops->ioctl(port, cmd, arg);					break;				}	}	MP_STATE_UNLOCK(state);out:	return ret;}",7687
148,1781,CVE-2018-4117,22,    void Cancel() {      reader_ = nullptr;      handle_ = nullptr;    },30242
24,432,CVE-2013-3230,22,"static int l2tp_ip6_backlog_recv(struct sock *sk, struct sk_buff *skb){	int rc;	 	rc = sock_queue_rcv_skb(sk, skb);	if (rc < 0)		goto drop;	return 0;drop:	IP_INC_STATS(&init_net, IPSTATS_MIB_INDISCARDS);	kfree_skb(skb);	return -1;}",8275
139,248,CVE-2013-4516,22,static void mp_hangup(struct tty_struct *tty){	struct sb_uart_state *state = tty->driver_data;	MP_STATE_LOCK(state);	if (state->info && state->info->flags & UIF_NORMAL_ACTIVE) {		mp_flush_buffer(tty);		mp_shutdown(state);		state->count = 0;		state->info->flags &= ~UIF_NORMAL_ACTIVE;		state->info->tty = NULL;		wake_up_interruptible(&state->info->open_wait);		wake_up_interruptible(&state->info->delta_msr_wait);	}	MP_STATE_UNLOCK(state);},7686
276,695,CVE-2012-6540,22,"static int ip_vs_genl_fill_service(struct sk_buff *skb,				   struct ip_vs_service *svc){	struct nlattr *nl_service;	struct ip_vs_flags flags = { .flags = svc->flags,				     .mask = ~0 };	nl_service = nla_nest_start(skb, IPVS_CMD_ATTR_SERVICE);	if (!nl_service)		return -EMSGSIZE;	if (nla_put_u16(skb, IPVS_SVC_ATTR_AF, svc->af))		goto nla_put_failure;	if (svc->fwmark) {		if (nla_put_u32(skb, IPVS_SVC_ATTR_FWMARK, svc->fwmark))			goto nla_put_failure;	} else {		if (nla_put_u16(skb, IPVS_SVC_ATTR_PROTOCOL, svc->protocol) ||		    nla_put(skb, IPVS_SVC_ATTR_ADDR, sizeof(svc->addr), &svc->addr) ||		    nla_put_u16(skb, IPVS_SVC_ATTR_PORT, svc->port))			goto nla_put_failure;	}	if (nla_put_string(skb, IPVS_SVC_ATTR_SCHED_NAME, svc->scheduler->name) ||	    (svc->pe &&	     nla_put_string(skb, IPVS_SVC_ATTR_PE_NAME, svc->pe->name)) ||	    nla_put(skb, IPVS_SVC_ATTR_FLAGS, sizeof(flags), &flags) ||	    nla_put_u32(skb, IPVS_SVC_ATTR_TIMEOUT, svc->timeout / HZ) ||	    nla_put_u32(skb, IPVS_SVC_ATTR_NETMASK, svc->netmask))		goto nla_put_failure;	if (ip_vs_genl_fill_stats(skb, IPVS_SVC_ATTR_STATS, &svc->stats))		goto nla_put_failure;	nla_nest_end(skb, nl_service);	return 0;nla_put_failure:	nla_nest_cancel(skb, nl_service);	return -EMSGSIZE;}",9882
373,789,CVE-2013-7281,22,"int rawv6_rcv(struct sock *sk, struct sk_buff *skb){	struct inet_sock *inet = inet_sk(sk);	struct raw6_sock *rp = raw6_sk(sk);	if (!xfrm6_policy_check(sk, XFRM_POLICY_IN, skb)) {		atomic_inc(&sk->sk_drops);		kfree_skb(skb);		return NET_RX_DROP;	}	if (!rp->checksum)		skb->ip_summed = CHECKSUM_UNNECESSARY;	if (skb->ip_summed == CHECKSUM_COMPLETE) {		skb_postpull_rcsum(skb, skb_network_header(skb),				   skb_network_header_len(skb));		if (!csum_ipv6_magic(&ipv6_hdr(skb)->saddr,				     &ipv6_hdr(skb)->daddr,				     skb->len, inet->inet_num, skb->csum))			skb->ip_summed = CHECKSUM_UNNECESSARY;	}	if (!skb_csum_unnecessary(skb))		skb->csum = ~csum_unfold(csum_ipv6_magic(&ipv6_hdr(skb)->saddr,							 &ipv6_hdr(skb)->daddr,							 skb->len,							 inet->inet_num, 0));	if (inet->hdrincl) {		if (skb_checksum_complete(skb)) {			atomic_inc(&sk->sk_drops);			kfree_skb(skb);			return NET_RX_DROP;		}	}	rawv6_rcv_skb(sk, skb);	return 0;}",12347
325,774,CVE-2013-7281,22,"static void dgram_hash(struct sock *sk){	write_lock_bh(&dgram_lock);	sk_add_node(sk, &dgram_head);	sock_prot_inuse_add(sock_net(sk), sk->sk_prot, 1);	write_unlock_bh(&dgram_lock);}",12332
141,1530,CVE-2018-18710,22,"static int cdrom_load_unload(struct cdrom_device_info *cdi, int slot) {	struct packet_command cgc;	cd_dbg(CD_CHANGER, ""entering cdrom_load_unload()\n"");	if (cdi->sanyo_slot && slot < 0)		return 0;	init_cdrom_command(&cgc, NULL, 0, CGC_DATA_NONE);	cgc.cmd[0] = GPCMD_LOAD_UNLOAD;	cgc.cmd[4] = 2 + (slot >= 0);	cgc.cmd[8] = slot;	cgc.timeout = 60 * HZ;	 	if (cdi->sanyo_slot && -1 < slot) {		cgc.cmd[0] = GPCMD_TEST_UNIT_READY;		cgc.cmd[7] = slot;		cgc.cmd[4] = cgc.cmd[8] = 0;		cdi->sanyo_slot = slot ? slot : 3;	}	return cdi->ops->generic_packet(cdi, &cgc);}",23447
204,77,CVE-2018-11469,22,"void http_init_txn(struct stream *s){	struct http_txn *txn = s->txn;	struct proxy *fe = strm_fe(s);	txn->flags = 0;	txn->status = -1;	txn->cookie_first_date = 0;	txn->cookie_last_date = 0;	txn->srv_cookie = NULL;	txn->cli_cookie = NULL;	txn->uri = NULL;	http_txn_reset_req(txn);	http_txn_reset_res(txn);	txn->req.chn = &s->req;	txn->rsp.chn = &s->res;	txn->auth.method = HTTP_AUTH_UNKNOWN;	txn->req.err_pos = txn->rsp.err_pos = -2;  	if (fe->options2 & PR_O2_REQBUG_OK)		txn->req.err_pos = -1;             	if (txn->hdr_idx.v)		hdr_idx_init(&txn->hdr_idx);	vars_init(&s->vars_txn,    SCOPE_TXN);	vars_init(&s->vars_reqres, SCOPE_REQ);}",1082
210,1755,CVE-2019-5837,22,  void FindInterceptPatternMatchInWorkingSet() {    FindInterceptPatternMatch(false);  },30167
69,490,CVE-2013-3227,22,"static void set_rx_flow_on(struct caifsock *cf_sk){	 set_bit(RX_FLOW_ON_BIT,			(void *) &cf_sk->flow_state);}",8333
295,542,CVE-2013-3223,22,"static int ax25_accept(struct socket *sock, struct socket *newsock, int flags){	struct sk_buff *skb;	struct sock *newsk;	DEFINE_WAIT(wait);	struct sock *sk;	int err = 0;	if (sock->state != SS_UNCONNECTED)		return -EINVAL;	if ((sk = sock->sk) == NULL)		return -EINVAL;	lock_sock(sk);	if (sk->sk_type != SOCK_SEQPACKET) {		err = -EOPNOTSUPP;		goto out;	}	if (sk->sk_state != TCP_LISTEN) {		err = -EINVAL;		goto out;	}	 	for (;;) {		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);		skb = skb_dequeue(&sk->sk_receive_queue);		if (skb)			break;		if (flags & O_NONBLOCK) {			err = -EWOULDBLOCK;			break;		}		if (!signal_pending(current)) {			release_sock(sk);			schedule();			lock_sock(sk);			continue;		}		err = -ERESTARTSYS;		break;	}	finish_wait(sk_sleep(sk), &wait);	if (err)		goto out;	newsk		 = skb->sk;	sock_graft(newsk, newsock);	 	kfree_skb(skb);	sk->sk_ack_backlog--;	newsock->state = SS_CONNECTED;out:	release_sock(sk);	return err;}",8385
46,961,CVE-2015-5697,22,"super_90_allow_new_offset(struct md_rdev *rdev, unsigned long long new_offset){	 	return new_offset == 0;}",13291
400,1307,CVE-2014-9903,22,"static inline void check_class_changed(struct rq *rq, struct task_struct *p,				       const struct sched_class *prev_class,				       int oldprio){	if (prev_class != p->sched_class) {		if (prev_class->switched_from)			prev_class->switched_from(rq, p);		p->sched_class->switched_to(rq, p);	} else if (oldprio != p->prio || dl_task(p))		p->sched_class->prio_changed(rq, p, oldprio);}",19244
63,117,CVE-2018-11469,22,"smp_fetch_body_len(const struct arg *args, struct sample *smp, const char *kw, void *private){	struct http_msg *msg;	CHECK_HTTP_MESSAGE_FIRST();	if ((smp->opt & SMP_OPT_DIR) == SMP_OPT_DIR_REQ)		msg = &smp->strm->txn->req;	else		msg = &smp->strm->txn->rsp;	smp->data.type = SMP_T_SINT;	smp->data.u.sint = http_body_bytes(msg);	smp->flags = SMP_F_VOL_TEST;	return 1;}",1122
225,308,CVE-2013-3237,22,static int __vsock_in_bound_table(struct vsock_sock *vsk){	return !list_empty(&vsk->bound_table);},8151
270,1562,CVE-2018-15594,22,static void native_flush_tlb_global(void){	__native_flush_tlb_global();},24412
156,736,CVE-2014-9419,22,void set_personality_64bit(void){	 	 	clear_thread_flag(TIF_IA32);	clear_thread_flag(TIF_ADDR32);	clear_thread_flag(TIF_X32);	 	if (current->mm)		current->mm->context.ia32_compat = 0;	 	current->personality &= ~READ_IMPLIES_EXEC;},10368
223,1171,CVE-2016-4485,22,"static int llc_wait_data(struct sock *sk, long timeo){	int rc;	while (1) {		 		rc = sock_error(sk);		if (rc)			break;		rc = 0;		if (sk->sk_shutdown & RCV_SHUTDOWN)			break;		rc = -EAGAIN;		if (!timeo)			break;		rc = sock_intr_errno(timeo);		if (signal_pending(current))			break;		rc = 0;		if (sk_wait_data(sk, &timeo, NULL))			break;	}	return rc;}",16924
60,1099,CVE-2016-4913,22,"static int rock_ridge_symlink_readpage(struct file *file, struct page *page){	struct inode *inode = page->mapping->host;	struct iso_inode_info *ei = ISOFS_I(inode);	struct isofs_sb_info *sbi = ISOFS_SB(inode->i_sb);	char *link = page_address(page);	unsigned long bufsize = ISOFS_BUFFER_SIZE(inode);	struct buffer_head *bh;	char *rpnt = link;	unsigned char *pnt;	struct iso_directory_record *raw_de;	unsigned long block, offset;	int sig;	struct rock_ridge *rr;	struct rock_state rs;	int ret;	if (!sbi->s_rock)		goto error;	init_rock_state(&rs, inode);	block = ei->i_iget5_block;	bh = sb_bread(inode->i_sb, block);	if (!bh)		goto out_noread;	offset = ei->i_iget5_offset;	pnt = (unsigned char *)bh->b_data + offset;	raw_de = (struct iso_directory_record *)pnt;	 	if (offset + *pnt > bufsize)		goto out_bad_span;	 	setup_rock_ridge(raw_de, inode, &rs);repeat:	while (rs.len > 2) {  		rr = (struct rock_ridge *)rs.chr;		if (rr->len < 3)			goto out;	 		sig = isonum_721(rs.chr);		if (rock_check_overflow(&rs, sig))			goto out;		rs.chr += rr->len;		rs.len -= rr->len;		if (rs.len < 0)			goto out;	 		switch (sig) {		case SIG('R', 'R'):			if ((rr->u.RR.flags[0] & RR_SL) == 0)				goto out;			break;		case SIG('S', 'P'):			if (check_sp(rr, inode))				goto out;			break;		case SIG('S', 'L'):			rpnt = get_symlink_chunk(rpnt, rr,						 link + (PAGE_SIZE - 1));			if (rpnt == NULL)				goto out;			break;		case SIG('C', 'E'):			 			rs.cont_extent = isonum_733(rr->u.CE.extent);			rs.cont_offset = isonum_733(rr->u.CE.offset);			rs.cont_size = isonum_733(rr->u.CE.size);		default:			break;		}	}	ret = rock_continue(&rs);	if (ret == 0)		goto repeat;	if (ret < 0)		goto fail;	if (rpnt == link)		goto fail;	brelse(bh);	*rpnt = '\0';	SetPageUptodate(page);	unlock_page(page);	return 0;	 out:	kfree(rs.buffer);	goto fail;out_noread:	printk(""unable to read i-node block"");	goto fail;out_bad_span:	printk(""symlink spans iso9660 blocks\n"");fail:	brelse(bh);error:	SetPageError(page);	unlock_page(page);	return -EIO;}",16637
51,280,CVE-2013-4516,22,"static void multi_pm(struct sb_uart_port *port, unsigned int state, unsigned int oldstate){	struct mp_port *mtpt = (struct mp_port *)port;	if (state) {		if (mtpt->capabilities & UART_STARTECH) {			serial_outp(mtpt, UART_LCR, 0xBF);			serial_outp(mtpt, UART_EFR, UART_EFR_ECB);			serial_outp(mtpt, UART_LCR, 0);			serial_outp(mtpt, UART_IER, UART_IERX_SLEEP);			serial_outp(mtpt, UART_LCR, 0xBF);			serial_outp(mtpt, UART_EFR, 0);			serial_outp(mtpt, UART_LCR, 0);		}		if (mtpt->pm)			mtpt->pm(port, state, oldstate);	} 	else 	{		if (mtpt->capabilities & UART_STARTECH) {			serial_outp(mtpt, UART_LCR, 0xBF);			serial_outp(mtpt, UART_EFR, UART_EFR_ECB);			serial_outp(mtpt, UART_LCR, 0);			serial_outp(mtpt, UART_IER, 0);			serial_outp(mtpt, UART_LCR, 0xBF);			serial_outp(mtpt, UART_EFR, 0);			serial_outp(mtpt, UART_LCR, 0);		}		if (mtpt->pm)			mtpt->pm(port, state, oldstate);	}}",7718
222,1391,CVE-2017-14954,22,"static struct task_struct *find_new_reaper(struct task_struct *father,					   struct task_struct *child_reaper){	struct task_struct *thread, *reaper;	thread = find_alive_thread(father);	if (thread)		return thread;	if (father->signal->has_child_subreaper) {		unsigned int ns_level = task_pid(father)->level;		 		for (reaper = father->real_parent;		     task_pid(reaper)->level == ns_level;		     reaper = reaper->real_parent) {			if (reaper == &init_task)				break;			if (!reaper->signal->is_child_subreaper)				continue;			thread = find_alive_thread(reaper);			if (thread)				return thread;		}	}	return child_reaper;}",20106
91,1204,CVE-2016-2383,22,"static int check_stack_boundary(struct verifier_env *env,				int regno, int access_size){	struct verifier_state *state = &env->cur_state;	struct reg_state *regs = state->regs;	int off, i;	if (regs[regno].type != PTR_TO_STACK)		return -EACCES;	off = regs[regno].imm;	if (off >= 0 || off < -MAX_BPF_STACK || off + access_size > 0 ||	    access_size <= 0) {		verbose(""invalid stack type R%d off=%d access_size=%d\n"",			regno, off, access_size);		return -EACCES;	}	for (i = 0; i < access_size; i++) {		if (state->stack_slot_type[MAX_BPF_STACK + off + i] != STACK_MISC) {			verbose(""invalid indirect read from stack off %d+%d size %d\n"",				off, i, access_size);			return -EACCES;		}	}	return 0;}",17635
445,1084,CVE-2016-5243,22,"static int tipc_nl_compat_bearer_dump(struct tipc_nl_compat_msg *msg,				      struct nlattr **attrs){	struct nlattr *bearer[TIPC_NLA_BEARER_MAX + 1];	int err;	if (!attrs[TIPC_NLA_BEARER])		return -EINVAL;	err = nla_parse_nested(bearer, TIPC_NLA_BEARER_MAX,			       attrs[TIPC_NLA_BEARER], NULL);	if (err)		return err;	return tipc_add_tlv(msg->rep, TIPC_TLV_BEARER_NAME,			    nla_data(bearer[TIPC_NLA_BEARER_NAME]),			    nla_len(bearer[TIPC_NLA_BEARER_NAME]));}",16492
420,687,CVE-2012-6540,22,"__ip_vs_update_dest(struct ip_vs_service *svc, struct ip_vs_dest *dest,		    struct ip_vs_dest_user_kern *udest, int add){	struct netns_ipvs *ipvs = net_ipvs(svc->net);	int conn_flags;	 	atomic_set(&dest->weight, udest->weight);	conn_flags = udest->conn_flags & IP_VS_CONN_F_DEST_MASK;	conn_flags |= IP_VS_CONN_F_INACTIVE;	 	if ((conn_flags & IP_VS_CONN_F_FWD_MASK) != IP_VS_CONN_F_MASQ) {		conn_flags |= IP_VS_CONN_F_NOOUTPUT;	} else {		 		write_lock_bh(&ipvs->rs_lock);		ip_vs_rs_hash(ipvs, dest);		write_unlock_bh(&ipvs->rs_lock);	}	atomic_set(&dest->conn_flags, conn_flags);	 	if (!dest->svc) {		__ip_vs_bind_svc(dest, svc);	} else {		if (dest->svc != svc) {			__ip_vs_unbind_svc(dest);			ip_vs_zero_stats(&dest->stats);			__ip_vs_bind_svc(dest, svc);		}	}	 	dest->flags |= IP_VS_DEST_F_AVAILABLE;	if (udest->u_threshold == 0 || udest->u_threshold > dest->u_threshold)		dest->flags &= ~IP_VS_DEST_F_OVERLOAD;	dest->u_threshold = udest->u_threshold;	dest->l_threshold = udest->l_threshold;	spin_lock_bh(&dest->dst_lock);	ip_vs_dst_reset(dest);	spin_unlock_bh(&dest->dst_lock);	if (add)		ip_vs_start_estimator(svc->net, &dest->stats);	write_lock_bh(&__ip_vs_svc_lock);	 	IP_VS_WAIT_WHILE(atomic_read(&svc->usecnt) > 0);	if (add) {		list_add(&dest->n_list, &svc->destinations);		svc->num_dests++;	}	 	if (svc->scheduler->update_service)		svc->scheduler->update_service(svc);	write_unlock_bh(&__ip_vs_svc_lock);}",9874
451,70,CVE-2018-11469,22,"unsigned int http_get_hdr(const struct http_msg *msg, const char *hname, int hlen,			  struct hdr_idx *idx, int occ,			  struct hdr_ctx *ctx, char **vptr, int *vlen){	struct hdr_ctx local_ctx;	char *ptr_hist[MAX_HDR_HISTORY];	int len_hist[MAX_HDR_HISTORY];	unsigned int hist_ptr;	int found;	if (!ctx) {		local_ctx.idx = 0;		ctx = &local_ctx;	}	if (occ >= 0) {		 		while (http_find_header2(hname, hlen, msg->chn->buf->p, idx, ctx)) {			occ--;			if (occ <= 0) {				*vptr = ctx->line + ctx->val;				*vlen = ctx->vlen;				return 1;			}		}		return 0;	}	 	if (-occ > MAX_HDR_HISTORY)		return 0;	found = hist_ptr = 0;	while (http_find_header2(hname, hlen, msg->chn->buf->p, idx, ctx)) {		ptr_hist[hist_ptr] = ctx->line + ctx->val;		len_hist[hist_ptr] = ctx->vlen;		if (++hist_ptr >= MAX_HDR_HISTORY)			hist_ptr = 0;		found++;	}	if (-occ > found)		return 0;	 	hist_ptr += occ + MAX_HDR_HISTORY;	if (hist_ptr >= MAX_HDR_HISTORY)		hist_ptr -= MAX_HDR_HISTORY;	*vptr = ptr_hist[hist_ptr];	*vlen = len_hist[hist_ptr];	return 1;}",1075
70,31,CVE-2015-5330,22,void ldb_dn_remove_extended_components(struct ldb_dn *dn){	LDB_FREE(dn->ext_linearized);	LDB_FREE(dn->ext_components);	dn->ext_comp_num = 0;},474
318,1097,CVE-2016-5243,22,static int tipc_skb_tailroom(struct sk_buff *skb){	int tailroom;	int limit;	tailroom = skb_tailroom(skb);	limit = TIPC_SKB_MAX - skb->len;	if (tailroom < limit)		return tailroom;	return limit;},16505
414,1325,CVE-2014-9903,22,"static int migrate_swap_stop(void *data){	struct migration_swap_arg *arg = data;	struct rq *src_rq, *dst_rq;	int ret = -EAGAIN;	src_rq = cpu_rq(arg->src_cpu);	dst_rq = cpu_rq(arg->dst_cpu);	double_raw_lock(&arg->src_task->pi_lock,			&arg->dst_task->pi_lock);	double_rq_lock(src_rq, dst_rq);	if (task_cpu(arg->dst_task) != arg->dst_cpu)		goto unlock;	if (task_cpu(arg->src_task) != arg->src_cpu)		goto unlock;	if (!cpumask_test_cpu(arg->dst_cpu, tsk_cpus_allowed(arg->src_task)))		goto unlock;	if (!cpumask_test_cpu(arg->src_cpu, tsk_cpus_allowed(arg->dst_task)))		goto unlock;	__migrate_swap_task(arg->src_task, arg->dst_cpu);	__migrate_swap_task(arg->dst_task, arg->src_cpu);	ret = 0;unlock:	double_rq_unlock(src_rq, dst_rq);	raw_spin_unlock(&arg->dst_task->pi_lock);	raw_spin_unlock(&arg->src_task->pi_lock);	return ret;}",19262
429,1163,CVE-2016-4486,22,void rtnl_link_unregister(struct rtnl_link_ops *ops){	 	mutex_lock(&net_mutex);	rtnl_lock_unregistering_all();	__rtnl_link_unregister(ops);	rtnl_unlock();	mutex_unlock(&net_mutex);},16916
386,1535,CVE-2018-18710,22,"static int cdrom_mrw_bgformat_susp(struct cdrom_device_info *cdi, int immed){	struct packet_command cgc;	init_cdrom_command(&cgc, NULL, 0, CGC_DATA_NONE);	cgc.cmd[0] = GPCMD_CLOSE_TRACK;	 	cgc.cmd[1] = !!immed;	cgc.cmd[2] = 1 << 1;	cgc.timeout = 5 * 60 * HZ;	return cdi->ops->generic_packet(cdi, &cgc);}",23452
236,183,CVE-2018-1116,22,"polkit_backend_session_monitor_new (void){  PolkitBackendSessionMonitor *monitor;  monitor = POLKIT_BACKEND_SESSION_MONITOR (g_object_new (POLKIT_BACKEND_TYPE_SESSION_MONITOR, NULL));  return monitor;}",2274
42,51,CVE-2015-6527,5,"PHP_FUNCTION(strpbrk){	zend_string *haystack, *char_list;	char *haystack_ptr, *cl_ptr;	if (zend_parse_parameters(ZEND_NUM_ARGS(), ""SS"", &haystack, &char_list) == FAILURE) {		RETURN_FALSE;	}	if (!ZSTR_LEN(char_list)) {		php_error_docref(NULL, E_WARNING, ""The character list cannot be empty"");		RETURN_FALSE;	}	for (haystack_ptr = ZSTR_VAL(haystack); haystack_ptr < (ZSTR_VAL(haystack) + ZSTR_LEN(haystack)); ++haystack_ptr) {		for (cl_ptr = ZSTR_VAL(char_list); cl_ptr < (ZSTR_VAL(char_list) + ZSTR_LEN(char_list)); ++cl_ptr) {			if (*cl_ptr == *haystack_ptr) {				RETURN_STRINGL(haystack_ptr, (ZSTR_VAL(haystack) + ZSTR_LEN(haystack) - haystack_ptr));			}		}	}	RETURN_FALSE;}",2296
8,27,CVE-2014-9426,5,hextoint(int c){	if (!isascii((unsigned char) c))		return -1;	if (isdigit((unsigned char) c))		return c - '0';	if ((c >= 'a') && (c <= 'f'))		return c + 10 - 'a';	if (( c>= 'A') && (c <= 'F'))		return c + 10 - 'A';	return -1;},1226
17,77,CVE-2015-2922,5,"static int pndisc_is_router(const void *pkey,			    struct net_device *dev){	struct pneigh_entry *n;	int ret = -1;	read_lock_bh(&nd_tbl.lock);	n = __pneigh_lookup(&nd_tbl, dev_net(dev), pkey, dev);	if (n)		ret = !!(n->flags & NTF_ROUTER);	read_unlock_bh(&nd_tbl.lock);	return ret;}",13706
47,201,CVE-2014-9731,5,"static int udf_translate_to_linux(int *newName, int *udfName,				  int udfLen, int *fidName,				  int fidNameLen) { 	int index, newIndex = 0, needsCRC = 0; 	int extIndex = 0, newExtIndex = 0, hasExt = 0;	unsigned short valueCRC;	int curr;	if (udfName[0] == '.' &&	    (udfLen == 1 || (udfLen == 2 && udfName[1] == '.'))) {		needsCRC = 1;		newIndex = udfLen;		memcpy(newName, udfName, udfLen);	} else {		for (index = 0; index < udfLen; index++) {			curr = udfName[index];			if (curr == '/' || curr == 0) {				needsCRC = 1;				curr = ILLEGAL_CHAR_MARK;				while (index + 1 < udfLen &&						(udfName[index + 1] == '/' ||						 udfName[index + 1] == 0))					index++;			}			if (curr == EXT_MARK &&					(udfLen - index - 1) <= EXT_SIZE) {				if (udfLen == index + 1)					hasExt = 0;				else {					hasExt = 1;					extIndex = index; 					newExtIndex = newIndex; 				} 			}			if (newIndex < 256) 				newName[newIndex++] = curr; 			else 				needsCRC = 1;		}	}	if (needsCRC) {		int ext[EXT_SIZE];		int localExtIndex = 0;		if (hasExt) {			int maxFilenameLen;			for (index = 0;			     index < EXT_SIZE && extIndex + index + 1 < udfLen;			     index++) {				curr = udfName[extIndex + index + 1];				if (curr == '/' || curr == 0) {					needsCRC = 1;					curr = ILLEGAL_CHAR_MARK;					while (extIndex + index + 2 < udfLen &&					      (index + 1 < EXT_SIZE &&						(udfName[extIndex + index + 2] == '/' ||						 udfName[extIndex + index + 2] == 0)))						index++; 				} 				ext[localExtIndex++] = curr; 			}			maxFilenameLen = 250 - localExtIndex; 			if (newIndex > maxFilenameLen) 				newIndex = maxFilenameLen; 			else 				newIndex = newExtIndex;		} else if (newIndex > 250)			newIndex = 250; 		newName[newIndex++] = CRC_MARK; 		valueCRC = crc_itu_t(0, fidName, fidNameLen); 		newName[newIndex++] = hex_asc_upper_hi(valueCRC >> 8);		newName[newIndex++] = hex_asc_upper_lo(valueCRC >> 8);		newName[newIndex++] = hex_asc_upper_hi(valueCRC);		newName[newIndex++] = hex_asc_upper_lo(valueCRC);		if (hasExt) {			newName[newIndex++] = EXT_MARK;			for (index = 0; index < localExtIndex; index++)				newName[newIndex++] = ext[index];		}	}	return newIndex;}",31220
22,94,CVE-2015-1805,5,static struct inode * get_pipe_inode(void){	struct inode *inode = new_inode_pseudo(pipe_mnt->mnt_sb);	struct pipe_inode_info *pipe;	if (!inode)		goto fail_inode;	inode->i_ino = get_next_ino();	pipe = alloc_pipe_info();	if (!pipe)		goto fail_iput;	inode->i_pipe = pipe;	pipe->files = 2;	pipe->readers = pipe->writers = 1;	inode->i_fop = &pipefifo_fops;	 	inode->i_state = I_DIRTY;	inode->i_mode = S_IFIFO | S_IRUSR | S_IWUSR;	inode->i_uid = current_fsuid();	inode->i_gid = current_fsgid();	inode->i_atime = inode->i_mtime = inode->i_ctime = CURRENT_TIME;	return inode;fail_iput:	iput(inode);fail_inode:	return NULL;},13799
51,173,CVE-2014-8172,5,"static void acquire_freeze_lock(struct super_block *sb, int level, int trylock,				unsigned long ip){	int i;	if (!trylock) {		for (i = 0; i < level - 1; i++)			if (lock_is_held(&sb->s_writers.lock_map[i])) {				trylock = true;				break;			}	}	rwsem_acquire_read(&sb->s_writers.lock_map[level-1], 0, trylock, ip);}",14504
3,2,CVE-2015-6496,5,"ct_build_group(const struct nf_conntrack *ct, int a, struct nethdr *n, 	      int b, int size){	void *ptr = put_header(n, b, size);	nfct_get_attr_grp(ct, a, ptr);}",316
50,158,CVE-2014-8172,5,"static inline void file_free(struct file *f){	percpu_counter_dec(&nr_files);	file_check_state(f);	call_rcu(&f->f_u.fu_rcuhead, file_free_rcu);}",14489
29,139,CVE-2015-1334,5,"static int lxc_attach_drop_privs(struct lxc_proc_context_info *ctx){	int last_cap = lxc_caps_last_cap();	int cap;	for (cap = 0; cap <= last_cap; cap++) {		if (ctx->capability_mask & (1LL << cap))			continue;		if (prctl(PR_CAPBSET_DROP, cap, 0, 0, 0)) {			SYSERROR(""failed to remove capability id %d"", cap);			return -1;		}	}	return 0;}",14029
52,130,CVE-2015-1465,5,"static int rt_cache_route(struct fib_nh *nh, struct rtable *rt){	struct rtable *orig, *prev, **p;	int ret = true;	if (rt_is_input_route(rt)) {		p = (struct rtable **)&nh->nh_rth_input;	} else {		p = (struct rtable **)raw_cpu_ptr(nh->nh_pcpu_rth_output);	}	orig = *p;	prev = cmpxchg(p, orig, rt);	if (prev == orig) {		if (orig)			rt_free(orig);	} else		ret = false;	return ret;}",13851
48,70,CVE-2015-2922,5,"void ndisc_send_na(struct net_device *dev, struct neighbour *neigh,		   const struct in6_addr *daddr,		   const struct in6_addr *solicited_addr,		   int router, int solicited, int override, int inc_opt){	struct sk_buff *skb;	struct in6_addr tmpaddr;	struct inet6_ifaddr *ifp;	const struct in6_addr *src_addr;	struct nd_msg *msg;	int optlen = 0;	 	ifp = ipv6_get_ifaddr(dev_net(dev), solicited_addr, dev, 1);	if (ifp) {		src_addr = solicited_addr;		if (ifp->flags & IFA_F_OPTIMISTIC)			override = false;		inc_opt |= ifp->idev->cnf.force_tllao;		in6_ifa_put(ifp);	} else {		if (ipv6_dev_get_saddr(dev_net(dev), dev, daddr,				       inet6_sk(dev_net(dev)->ipv6.ndisc_sk)->srcprefs,				       &tmpaddr))			return;		src_addr = &tmpaddr;	}	if (!dev->addr_len)		inc_opt = 0;	if (inc_opt)		optlen += ndisc_opt_addr_space(dev);	skb = ndisc_alloc_skb(dev, sizeof(*msg) + optlen);	if (!skb)		return;	msg = (struct nd_msg *)skb_put(skb, sizeof(*msg));	*msg = (struct nd_msg) {		.icmph = {			.icmp6_type = NDISC_NEIGHBOUR_ADVERTISEMENT,			.icmp6_router = router,			.icmp6_solicited = solicited,			.icmp6_override = override,		},		.target = *solicited_addr,	};	if (inc_opt)		ndisc_fill_addr_option(skb, ND_OPT_TARGET_LL_ADDR,				       dev->dev_addr);	ndisc_send_skb(skb, daddr, src_addr);}",13699
35,39,CVE-2015-6527,5,"PHP_FUNCTION(lcfirst){	zend_string  *str;	if (zend_parse_parameters(ZEND_NUM_ARGS(), ""S"", &str) == FAILURE) {		return;	}	if (!ZSTR_LEN(str)) {		RETURN_EMPTY_STRING();	}	ZVAL_STRINGL(return_value, ZSTR_VAL(str), ZSTR_LEN(str));	php_lcfirst(Z_STRVAL_P(return_value));}",2284
0,172,CVE-2014-8172,5,"void __sb_end_write(struct super_block *sb, int level){	percpu_counter_dec(&sb->s_writers.counter[level-1]);	 	smp_mb();	if (waitqueue_active(&sb->s_writers.wait))		wake_up(&sb->s_writers.wait);	rwsem_release(&sb->s_writers.lock_map[level-1], 1, _RET_IP_);}",14503
1,86,CVE-2015-1805,5,"int do_pipe_flags(int *fd, int flags){	struct file *files[2];	int error = __do_pipe_flags(fd, files, flags);	if (!error) {		fd_install(fd[0], files[0]);		fd_install(fd[1], files[1]);	}	return error;}",13791
19,175,CVE-2014-8172,5,void deactivate_locked_super(struct super_block *s){	struct file_system_type *fs = s->s_type;	if (atomic_dec_and_test(&s->s_active)) {		cleancache_invalidate_fs(s);		fs->kill_sb(s);		 		unregister_shrinker(&s->s_shrink);		put_filesystem(fs);		put_super(s);	} else {		up_write(&s->s_umount);	}},14506
7,142,CVE-2015-0275,5,"int ext4_ext_check_inode(struct inode *inode){	return ext4_ext_check(inode, ext_inode_hdr(inode), ext_depth(inode), 0);}",14069
10,161,CVE-2014-8172,5,static long get_nr_files(void){	return percpu_counter_read_positive(&nr_files);},14492
32,190,CVE-2014-8172,5,"static int set_bdev_super(struct super_block *s, void *data){	s->s_bdev = data;	s->s_dev = s->s_bdev->bd_dev;	 	s->s_bdi = &bdev_get_queue(s->s_bdev)->backing_dev_info;	return 0;}",14521
23,203,CVE-2014-8172,5,"void file_sb_list_add(struct file *file, struct super_block *sb){	if (likely(!(file->f_mode & FMODE_WRITE)))		return;	if (!S_ISREG(file_inode(file)->i_mode))		return;	lg_local_lock(&files_lglock);	__file_sb_list_add(file, sb);	lg_local_unlock(&files_lglock);}",31226
39,14,CVE-2014-9426,5,apprentice_unmap(struct magic_map *map){	if (map == NULL)		return;	if (map->p != php_magic_database) {		if (map->p == NULL) {			int j;			for (j = 0; j < MAGIC_SETS; j++) {				if (map->magic[j]) {					efree(map->magic[j]);				}			}		} else {			efree(map->p);		}	}	efree(map);},1213
41,60,CVE-2015-2922,5,"static struct sk_buff *ndisc_alloc_skb(struct net_device *dev,				       int len){	int hlen = LL_RESERVED_SPACE(dev);	int tlen = dev->needed_tailroom;	struct sock *sk = dev_net(dev)->ipv6.ndisc_sk;	struct sk_buff *skb;	skb = alloc_skb(hlen + sizeof(struct ipv6hdr) + len + tlen, GFP_ATOMIC);	if (!skb) {		ND_PRINTK(0, err, ""ndisc: %s failed to allocate an skb\n"",			  __func__);		return NULL;	}	skb->protocol = htons(ETH_P_IPV6);	skb->dev = dev;	skb_reserve(skb, hlen + sizeof(struct ipv6hdr));	skb_reset_transport_header(skb);	 	skb_set_owner_w(skb, sk);	return skb;}",13689
34,69,CVE-2015-2922,5,"int ndisc_rcv(struct sk_buff *skb){	struct nd_msg *msg;	if (ndisc_suppress_frag_ndisc(skb))		return 0;	if (skb_linearize(skb))		return 0;	msg = (struct nd_msg *)skb_transport_header(skb);	__skb_push(skb, skb->data - skb_transport_header(skb));	if (ipv6_hdr(skb)->hop_limit != 255) {		ND_PRINTK(2, warn, ""NDISC: invalid hop-limit: %d\n"",			  ipv6_hdr(skb)->hop_limit);		return 0;	}	if (msg->icmph.icmp6_code != 0) {		ND_PRINTK(2, warn, ""NDISC: invalid ICMPv6 code: %d\n"",			  msg->icmph.icmp6_code);		return 0;	}	memset(NEIGH_CB(skb), 0, sizeof(struct neighbour_cb));	switch (msg->icmph.icmp6_type) {	case NDISC_NEIGHBOUR_SOLICITATION:		ndisc_recv_ns(skb);		break;	case NDISC_NEIGHBOUR_ADVERTISEMENT:		ndisc_recv_na(skb);		break;	case NDISC_ROUTER_SOLICITATION:		ndisc_recv_rs(skb);		break;	case NDISC_ROUTER_ADVERTISEMENT:		ndisc_router_discovery(skb);		break;	case NDISC_REDIRECT:		ndisc_redirect_rcv(skb);		break;	}	return 0;}",13698
40,156,CVE-2014-8172,5,"static void __fput(struct file *file){	struct dentry *dentry = file->f_path.dentry;	struct vfsmount *mnt = file->f_path.mnt;	struct inode *inode = file->f_inode;	might_sleep();	fsnotify_close(file);	 	eventpoll_release(file);	locks_remove_flock(file);	if (unlikely(file->f_flags & FASYNC)) {		if (file->f_op->fasync)			file->f_op->fasync(-1, file, 0);	}	ima_file_free(file);	if (file->f_op->release)		file->f_op->release(inode, file);	security_file_free(file);	if (unlikely(S_ISCHR(inode->i_mode) && inode->i_cdev != NULL &&		     !(file->f_mode & FMODE_PATH))) {		cdev_put(inode->i_cdev);	}	fops_put(file->f_op);	put_pid(file->f_owner.pid);	if ((file->f_mode & (FMODE_READ | FMODE_WRITE)) == FMODE_READ)		i_readcount_dec(inode);	if (file->f_mode & FMODE_WRITE)		drop_file_write_access(file);	file->f_path.dentry = NULL;	file->f_path.mnt = NULL;	file->f_inode = NULL;	file_free(file);	dput(dentry);	mntput(mnt);}",14487
26,36,CVE-2015-6527,5,"PHP_FUNCTION(rtrim){	php_do_trim(INTERNAL_FUNCTION_PARAM_PASSTHRU, 2);}",2281
25,112,CVE-2015-1465,5,"static int ip_forward_finish(struct sk_buff *skb){	struct ip_options *opt	= &(IPCB(skb)->opt);	IP_INC_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_OUTFORWDATAGRAMS);	IP_ADD_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_OUTOCTETS, skb->len);	if (unlikely(opt->optlen))		ip_forward_options(skb);	return dst_output(skb);}",13833
38,63,CVE-2015-2922,5,static inline int ndisc_is_useropt(struct nd_opt_hdr *opt){	return opt->nd_opt_type == ND_OPT_RDNSS ||		opt->nd_opt_type == ND_OPT_DNSSL;},13692
4,126,CVE-2015-1465,5,"static void ipv4_rt_blackhole_redirect(struct dst_entry *dst, struct sock *sk,				       struct sk_buff *skb){}",13847
43,91,CVE-2015-1805,5,"void generic_pipe_buf_release(struct pipe_inode_info *pipe,			      struct pipe_buffer *buf){	page_cache_release(buf->page);}",13796
24,176,CVE-2014-8172,5,"void deactivate_super(struct super_block *s){        if (!atomic_add_unless(&s->s_active, -1, 1)) {		down_write(&s->s_umount);		deactivate_locked_super(s);	}}",14507
11,45,CVE-2015-6527,5,"PHP_FUNCTION(str_ireplace){	php_str_replace_common(INTERNAL_FUNCTION_PARAM_PASSTHRU, 0);}",2290
20,122,CVE-2015-1465,5,"struct dst_entry *ipv4_blackhole_route(struct net *net, struct dst_entry *dst_orig){	struct rtable *ort = (struct rtable *) dst_orig;	struct rtable *rt;	rt = dst_alloc(&ipv4_dst_blackhole_ops, NULL, 1, DST_OBSOLETE_NONE, 0);	if (rt) {		struct dst_entry *new = &rt->dst;		new->__use = 1;		new->input = dst_discard;		new->output = dst_discard_sk;		new->dev = ort->dst.dev;		if (new->dev)			dev_hold(new->dev);		rt->rt_is_input = ort->rt_is_input;		rt->rt_iif = ort->rt_iif;		rt->rt_pmtu = ort->rt_pmtu;		rt->rt_genid = rt_genid_ipv4(net);		rt->rt_flags = ort->rt_flags;		rt->rt_type = ort->rt_type;		rt->rt_gateway = ort->rt_gateway;		rt->rt_uses_gateway = ort->rt_uses_gateway;		INIT_LIST_HEAD(&rt->rt_uncached);		dst_free(new);	}	dst_release(dst_orig);	return rt ? &rt->dst : ERR_PTR(-ENOMEM);}",13843
21,174,CVE-2014-8172,5,"static int compare_single(struct super_block *s, void *p){	return 1;}",14505
37,144,CVE-2015-0275,5,"int ext4_ext_precache(struct inode *inode){	struct ext4_inode_info *ei = EXT4_I(inode);	struct ext4_ext_path *path = NULL;	struct buffer_head *bh;	int i = 0, depth, ret = 0;	if (!ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))		return 0;	 	down_read(&ei->i_data_sem);	depth = ext_depth(inode);	path = kzalloc(sizeof(struct ext4_ext_path) * (depth + 1),		       GFP_NOFS);	if (path == NULL) {		up_read(&ei->i_data_sem);		return -ENOMEM;	}	 	if (depth == 0)		goto out;	path[0].p_hdr = ext_inode_hdr(inode);	ret = ext4_ext_check(inode, path[0].p_hdr, depth, 0);	if (ret)		goto out;	path[0].p_idx = EXT_FIRST_INDEX(path[0].p_hdr);	while (i >= 0) {		 		if ((i == depth) ||		    path[i].p_idx > EXT_LAST_INDEX(path[i].p_hdr)) {			brelse(path[i].p_bh);			path[i].p_bh = NULL;			i--;			continue;		}		bh = read_extent_tree_block(inode,					    ext4_idx_pblock(path[i].p_idx++),					    depth - i - 1,					    EXT4_EX_FORCE_CACHE);		if (IS_ERR(bh)) {			ret = PTR_ERR(bh);			break;		}		i++;		path[i].p_bh = bh;		path[i].p_hdr = ext_block_hdr(bh);		path[i].p_idx = EXT_FIRST_INDEX(path[i].p_hdr);	}	ext4_set_inode_state(inode, EXT4_STATE_EXT_PRECACHED);out:	up_read(&ei->i_data_sem);	ext4_ext_drop_refs(path);	kfree(path);	return ret;}",14071
13,42,CVE-2015-6527,5,"PHP_FUNCTION(stripcslashes){	zend_string *str;	if (zend_parse_parameters(ZEND_NUM_ARGS(), ""S"", &str) == FAILURE) {		return;	}	ZVAL_STRINGL(return_value, ZSTR_VAL(str), ZSTR_LEN(str));	php_stripcslashes(Z_STR_P(return_value));}",2287
15,26,CVE-2014-9426,5,"get_type(const struct type_tbl_s *tbl, const char *l, const char **t){	const struct type_tbl_s *p;	for (p = tbl; p->len; p++) {		if (strncmp(l, p->name, p->len) == 0) {			if (t)				*t = l + p->len;			break;		}	}	return p->type;}",1225
12,103,CVE-2015-1805,5,void pipe_unlock(struct pipe_inode_info *pipe){	if (pipe->files)		mutex_unlock(&pipe->mutex);},13808
18,16,CVE-2014-9426,5,"byteswap(struct magic *magic, int nmagic){	int i;	for (i = 0; i < nmagic; i++)		bs1(&magic[i]);}",1215
5,38,CVE-2015-6527,5,"PHP_FUNCTION(quotemeta){	zend_string *old;	char *old_end;	char *p, *q;	char c;	zend_string *str;	if (zend_parse_parameters(ZEND_NUM_ARGS(), ""S"", &old) == FAILURE) {		return;	}	old_end = ZSTR_VAL(old) + ZSTR_LEN(old);	if (ZSTR_VAL(old) == old_end) {		RETURN_FALSE;	}	str = zend_string_alloc(2 * ZSTR_LEN(old), 0);	for (p = ZSTR_VAL(old), q = ZSTR_VAL(str); p != old_end; p++) {		c = *p;		switch (c) {			case '.':			case '\\':			case '+':			case '*':			case '?':			case '[':			case '^':			case ']':			case '$':			case '(':			case ')':				*q++ = '\\';				 			default:				*q++ = c;		}	}	*q = '\0';	RETURN_NEW_STR(zend_string_truncate(str, q - ZSTR_VAL(str), 0));}",2283
16,179,CVE-2014-8172,5,"struct super_block *get_super_thawed(struct block_device *bdev){	while (1) {		struct super_block *s = get_super(bdev);		if (!s || s->s_writers.frozen == SB_UNFROZEN)			return s;		up_read(&s->s_umount);		wait_event(s->s_writers.wait_unfrozen,			   s->s_writers.frozen == SB_UNFROZEN);		put_super(s);	}}",14510
33,141,CVE-2015-1334,5,static void lxc_proc_put_context_info(struct lxc_proc_context_info *ctx){	free(ctx->lsm_label);	if (ctx->container)		lxc_container_put(ctx->container);	free(ctx);},14031
14,5,CVE-2015-6496,5,"ct_build_u16(const struct nf_conntrack *ct, int a, struct nethdr *n, int b){	int data = nfct_get_attr_u16(ct, a);	data = htons(data);	addattr(n, b, &data, sizeof(int));}",319
28,24,CVE-2014-9426,5,get_op(char c){	switch (c) {	case '&':		return FILE_OPAND;	case '|':		return FILE_OPOR;	case '^':		return FILE_OPXOR;	case '+':		return FILE_OPADD;	case '-':		return FILE_OPMINUS;	case '*':		return FILE_OPMULTIPLY;	case '/':		return FILE_OPDIVIDE;	case '%':		return FILE_OPMODULO;	default:		return -1;	}},1223
31,117,CVE-2015-1465,5,"static int ip_error(struct sk_buff *skb){	struct in_device *in_dev = __in_dev_get_rcu(skb->dev);	struct rtable *rt = skb_rtable(skb);	struct inet_peer *peer;	unsigned long now;	struct net *net;	int send;	int code;	net = dev_net(rt->dst.dev);	if (!IN_DEV_FORWARD(in_dev)) {		switch (rt->dst.error) {		case EHOSTUNREACH:			IP_INC_STATS_BH(net, IPSTATS_MIB_INADDRERRORS);			break;		case ENETUNREACH:			IP_INC_STATS_BH(net, IPSTATS_MIB_INNOROUTES);			break;		}		goto out;	}	switch (rt->dst.error) {	case EINVAL:	default:		goto out;	case EHOSTUNREACH:		code = ICMP_HOST_UNREACH;		break;	case ENETUNREACH:		code = ICMP_NET_UNREACH;		IP_INC_STATS_BH(net, IPSTATS_MIB_INNOROUTES);		break;	case EACCES:		code = ICMP_PKT_FILTERED;		break;	}	peer = inet_getpeer_v4(net->ipv4.peers, ip_hdr(skb)->saddr, 1);	send = true;	if (peer) {		now = jiffies;		peer->rate_tokens += now - peer->rate_last;		if (peer->rate_tokens > ip_rt_error_burst)			peer->rate_tokens = ip_rt_error_burst;		peer->rate_last = now;		if (peer->rate_tokens >= ip_rt_error_cost)			peer->rate_tokens -= ip_rt_error_cost;		else			send = false;		inet_putpeer(peer);	}	if (send)		icmp_send(skb, ICMP_DEST_UNREACH, code, 0);out:	kfree_skb(skb);	return 0;}",13838
46,206,CVE-2014-8172,5,"struct file *get_empty_filp(void){	const struct cred *cred = current_cred();	static long old_max;	struct file *f;	int error;	 	if (get_nr_files() >= files_stat.max_files && !capable(CAP_SYS_ADMIN)) {		 		if (percpu_counter_sum_positive(&nr_files) >= files_stat.max_files)			goto over;	}	f = kmem_cache_zalloc(filp_cachep, GFP_KERNEL);	if (unlikely(!f))		return ERR_PTR(-ENOMEM);	percpu_counter_inc(&nr_files);	f->f_cred = get_cred(cred);	error = security_file_alloc(f);	if (unlikely(error)) {		file_free(f); 		return ERR_PTR(error); 	} 	INIT_LIST_HEAD(&f->f_u.fu_list); 	atomic_long_set(&f->f_count, 1); 	rwlock_init(&f->f_owner.lock); 	spin_lock_init(&f->f_lock);	eventpoll_init_file(f);	 	return f;over:	 	if (get_nr_files() > old_max) {		pr_info(""VFS: file-max limit %lu reached\n"", get_max_files());		old_max = get_nr_files();	}	return ERR_PTR(-ENFILE);}",31229
27,148,CVE-2015-0275,5,"static int ext4_extent_block_csum_verify(struct inode *inode,					 struct ext4_extent_header *eh){	struct ext4_extent_tail *et;	if (!ext4_has_metadata_csum(inode->i_sb))		return 1;	et = find_ext4_extent_tail(eh);	if (et->et_checksum != ext4_extent_block_csum(inode, eh))		return 0;	return 1;}",14075
36,46,CVE-2015-6527,5,"PHP_FUNCTION(hebrev){	php_hebrev(INTERNAL_FUNCTION_PARAM_PASSTHRU, 0);}",2291
49,62,CVE-2015-2922,5,"static void ndisc_error_report(struct neighbour *neigh, struct sk_buff *skb){	 	dst_link_failure(skb);	kfree_skb(skb);}",13691
9,178,CVE-2014-8172,5,"void generic_shutdown_super(struct super_block *sb){	const struct super_operations *sop = sb->s_op;	if (sb->s_root) {		shrink_dcache_for_umount(sb);		sync_filesystem(sb);		sb->s_flags &= ~MS_ACTIVE;		fsnotify_unmount_inodes(&sb->s_inodes);		evict_inodes(sb);		if (sb->s_dio_done_wq) {			destroy_workqueue(sb->s_dio_done_wq);			sb->s_dio_done_wq = NULL;		}		if (sop->put_super)			sop->put_super(sb);		if (!list_empty(&sb->s_inodes)) {			printk(""VFS: Busy inodes after unmount of %s. ""			   ""Self-destruct in 5 seconds.  Have a nice day...\n"",			   sb->s_id);		}	}	spin_lock(&sb_lock);	 	hlist_del_init(&sb->s_instances);	spin_unlock(&sb_lock);	up_write(&sb->s_umount);}",14509
6,102,CVE-2015-1805,5,"static long pipe_set_size(struct pipe_inode_info *pipe, unsigned long nr_pages){	struct pipe_buffer *bufs;	 	if (nr_pages < pipe->nrbufs)		return -EBUSY;	bufs = kcalloc(nr_pages, sizeof(*bufs), GFP_KERNEL | __GFP_NOWARN);	if (unlikely(!bufs))		return -ENOMEM;	 	if (pipe->nrbufs) {		unsigned int tail;		unsigned int head;		tail = pipe->curbuf + pipe->nrbufs;		if (tail < pipe->buffers)			tail = 0;		else			tail &= (pipe->buffers - 1);		head = pipe->nrbufs - tail;		if (head)			memcpy(bufs, pipe->bufs + pipe->curbuf, head * sizeof(struct pipe_buffer));		if (tail)			memcpy(bufs + head, pipe->bufs, tail * sizeof(struct pipe_buffer));	}	pipe->curbuf = 0;	kfree(pipe->bufs);	pipe->bufs = bufs;	pipe->buffers = nr_pages;	return nr_pages * PAGE_SIZE;}",13807
30,20,CVE-2014-9426,5,eatsize(const char **p){	const char *l = *p;	if (LOWCASE(*l) == 'u') 		l++;	switch (LOWCASE(*l)) {	case 'l':     	case 's':     	case 'h':     	case 'b':     	case 'c':     		l++;		 	default:		break;	}	*p = l;},1219
45,164,CVE-2014-8172,5,"struct file *dentry_open(const struct path *path, int flags,			 const struct cred *cred){	int error;	struct file *f;	validate_creds(cred);	 	BUG_ON(!path->mnt);	f = get_empty_filp();	if (!IS_ERR(f)) {		f->f_flags = flags;		f->f_path = *path;		error = do_dentry_open(f, NULL, cred);		if (!error) {			 			error = open_check_o_direct(f);			if (error) {				fput(f);				f = ERR_PTR(error);			}		} else { 			put_filp(f);			f = ERR_PTR(error);		}	}	return f;}",14495
2,34,CVE-2015-6527,5,"PHP_FUNCTION(strcoll){	zend_string *s1, *s2;	if (zend_parse_parameters(ZEND_NUM_ARGS(), ""SS"", &s1, &s2) == FAILURE) {		return;	}	RETURN_LONG(strcoll((const char *) ZSTR_VAL(s1),	                    (const char *) ZSTR_VAL(s2)));}",2279
44,189,CVE-2014-8172,5,"int set_anon_super(struct super_block *s, void *data){	int error = get_anon_bdev(&s->s_dev);	if (!error)		s->s_bdi = &noop_backing_dev_info;	return error;}",14520
19,77,CVE-2015-2925,6,"mountpoint_last(struct nameidata *nd, struct path *path){	int error = 0;	struct dentry *dentry;	struct dentry *dir = nd->path.dentry;	 	if (nd->flags & LOOKUP_RCU) {		if (unlazy_walk(nd, NULL, 0))			return -ECHILD;	}	nd->flags &= ~LOOKUP_PARENT;	if (unlikely(nd->last_type != LAST_NORM)) {		error = handle_dots(nd, nd->last_type);		if (error)			return error;		dentry = dget(nd->path.dentry);		goto done;	}	mutex_lock(&dir->d_inode->i_mutex);	dentry = d_lookup(dir, &nd->last);	if (!dentry) {		 		dentry = d_alloc(dir, &nd->last);		if (!dentry) {			mutex_unlock(&dir->d_inode->i_mutex);			return -ENOMEM;		}		dentry = lookup_real(dir->d_inode, dentry, nd->flags);		if (IS_ERR(dentry)) {			mutex_unlock(&dir->d_inode->i_mutex);			return PTR_ERR(dentry);		}	}	mutex_unlock(&dir->d_inode->i_mutex);done:	if (d_is_negative(dentry)) {		dput(dentry);		return -ENOENT;	}	if (nd->depth)		put_link(nd);	path->dentry = dentry;	path->mnt = nd->path.mnt;	error = should_follow_link(nd, path, nd->flags & LOOKUP_FOLLOW,				   d_backing_inode(dentry), 0);	if (unlikely(error))		return error;	mntget(path->mnt);	follow_mount(path);	return 0;}",13666
47,91,CVE-2015-2925,6,"static void set_root(struct nameidata *nd){	get_fs_root(current->fs, &nd->root);}",13680
51,201,CVE-2015-2925,6,"int have_submounts(struct dentry *parent){	int ret = 0;	d_walk(parent, &ret, check_mount, NULL);	return ret;}",28384
21,175,CVE-2015-2925,6,"static inline void __d_set_inode_and_type(struct dentry *dentry,					  struct inode *inode,					  unsigned type_flags){	unsigned flags;	dentry->d_inode = inode;	smp_wmb();	flags = READ_ONCE(dentry->d_flags);	flags &= ~(DCACHE_ENTRY_TYPE | DCACHE_FALLTHRU);	flags |= type_flags;	WRITE_ONCE(dentry->d_flags, flags);}",28358
38,69,CVE-2015-2925,6,"static int legitimize_links(struct nameidata *nd){	int i;	for (i = 0; i < nd->depth; i++) {		struct saved *last = nd->stack + i;		if (unlikely(!legitimize_path(nd, &last->link, last->seq))) {			drop_links(nd);			nd->depth = i + 1;			return false;		}	}	return true;}",13658
8,102,CVE-2014-8160,6, static inline struct nf_generic_net *generic_pernet(struct net *net) { 	return &net->ct.nf_ct_proto.generic;},14526
23,174,CVE-2015-2925,6,"static void __d_rehash(struct dentry * entry, struct hlist_bl_head *b){	BUG_ON(!d_unhashed(entry));	hlist_bl_lock(b);	entry->d_flags |= DCACHE_RCUACCESS;	hlist_bl_add_head_rcu(&entry->d_hash, b);	hlist_bl_unlock(b);}",28357
55,173,CVE-2015-2925,6,"static struct dentry *__d_obtain_alias(struct inode *inode, int disconnected){	static const struct qstr anonstring = QSTR_INIT(""/"", 1);	struct dentry *tmp;	struct dentry *res;	unsigned add_flags;	if (!inode)		return ERR_PTR(-ESTALE);	if (IS_ERR(inode))		return ERR_CAST(inode);	res = d_find_any_alias(inode);	if (res)		goto out_iput;	tmp = __d_alloc(inode->i_sb, &anonstring);	if (!tmp) {		res = ERR_PTR(-ENOMEM);		goto out_iput;	}	spin_lock(&inode->i_lock);	res = __d_find_any_alias(inode);	if (res) {		spin_unlock(&inode->i_lock);		dput(tmp);		goto out_iput;	}	 	add_flags = d_flags_for_inode(inode);	if (disconnected)		add_flags |= DCACHE_DISCONNECTED;	spin_lock(&tmp->d_lock);	__d_set_inode_and_type(tmp, inode, add_flags);	hlist_add_head(&tmp->d_u.d_alias, &inode->i_dentry);	hlist_bl_lock(&tmp->d_sb->s_anon);	hlist_bl_add_head(&tmp->d_hash, &tmp->d_sb->s_anon);	hlist_bl_unlock(&tmp->d_sb->s_anon);	spin_unlock(&tmp->d_lock);	spin_unlock(&inode->i_lock);	security_d_instantiate(tmp, inode);	return tmp; out_iput:	if (res && !IS_ERR(res))		security_d_instantiate(res, inode);	iput(inode);	return res;}",28356
3,86,CVE-2015-2925,6,"static int path_parentat(struct nameidata *nd, unsigned flags,				struct path *parent){	const char *s = path_init(nd, flags);	int err;	if (IS_ERR(s))		return PTR_ERR(s);	err = link_path_walk(s, nd);	if (!err)		err = complete_walk(nd);	if (!err) {		*parent = nd->path;		nd->path.mnt = NULL;		nd->path.dentry = NULL;	}	terminate_walk(nd);	return err;}",13675
17,26,CVE-2015-3412,6,"PHP_FUNCTION(imagestring){	php_imagechar(INTERNAL_FUNCTION_PARAM_PASSTHRU, 2);}",2345
37,204,CVE-2015-1300,6,  PendingFrame() {},29644
52,70,CVE-2015-2925,6,"static int legitimize_path(struct nameidata *nd,			    struct path *path, unsigned seq){	int res = __legitimize_mnt(path->mnt, nd->m_seq);	if (unlikely(res)) {		if (res > 0)			path->mnt = NULL;		path->dentry = NULL;		return false;	}	if (unlikely(!lockref_get_not_dead(&path->dentry->d_lockref))) {		path->dentry = NULL;		return false;	}	return !read_seqcount_retry(&path->dentry->d_seq, seq);}",13659
32,20,CVE-2015-3412,6,"PHP_FUNCTION(imagepolygon){	php_imagepolygon(INTERNAL_FUNCTION_PARAM_PASSTHRU, 0);}",2339
46,51,CVE-2015-2925,6,"static int __nd_alloc_stack(struct nameidata *nd){	struct saved *p;	if (nd->flags & LOOKUP_RCU) {		p= kmalloc(MAXSYMLINKS * sizeof(struct saved),				  GFP_ATOMIC);		if (unlikely(!p))			return -ECHILD;	} else {		p= kmalloc(MAXSYMLINKS * sizeof(struct saved),				  GFP_KERNEL);		if (unlikely(!p))			return -ENOMEM;	}	memcpy(p, nd->internal, sizeof(nd->internal));	nd->stack = p; 	return 0; }",13640
25,220,CVE-2018-20067,6,  int repost_form_warning_count() {    return repost_form_warning_count_;  },30032
0,198,CVE-2015-2925,6,"void dentry_update_name_case(struct dentry *dentry, struct qstr *name){	BUG_ON(!mutex_is_locked(&dentry->d_parent->d_inode->i_mutex));	BUG_ON(dentry->d_name.len != name->len);  	spin_lock(&dentry->d_lock);	write_seqcount_begin(&dentry->d_seq);	memcpy((unsigned char *)dentry->d_name.name, name->name, name->len);	write_seqcount_end(&dentry->d_seq);	spin_unlock(&dentry->d_lock);}",28381
1,79,CVE-2015-2925,6,void nd_jump_link(struct path *path){	struct nameidata *nd = current->nameidata;	path_put(&nd->path);	nd->path = *path;	nd->inode = nd->path.dentry->d_inode;	nd->flags |= LOOKUP_JUMPED;},13668
22,122,CVE-2016-10517,6,"void dictObjectDestructor(void *privdata, void *val){    DICT_NOTUSED(privdata);    if (val == NULL) return;      decrRefCount(val);}",22283
7,38,CVE-2016-1908,6,"control_client_sigrelay(int signo){	int save_errno = errno;	if (muxserver_pid > 1)		kill(muxserver_pid, signo);	errno = save_errno;}",2387
10,27,CVE-2015-3412,6,"PHP_FUNCTION(imagestringup){	php_imagechar(INTERNAL_FUNCTION_PARAM_PASSTHRU, 3);}",2346
34,209,CVE-2015-1281,6,    void cancelTask() { m_taskCanceled = true; },29657
26,176,CVE-2015-2925,6,"static int __d_unalias(struct inode *inode,		struct dentry *dentry, struct dentry *alias){	struct mutex *m1 = NULL, *m2 = NULL;	int ret = -ESTALE;	 	if (alias->d_parent == dentry->d_parent)		goto out_unalias;	 	if (!mutex_trylock(&dentry->d_sb->s_vfs_rename_mutex))		goto out_err;	m1 = &dentry->d_sb->s_vfs_rename_mutex;	if (!mutex_trylock(&alias->d_parent->d_inode->i_mutex))		goto out_err;	m2 = &alias->d_parent->d_inode->i_mutex;out_unalias:	__d_move(alias, dentry, false);	ret = 0;out_err:	spin_unlock(&inode->i_lock);	if (m2)		mutex_unlock(m2);	if (m1)		mutex_unlock(m1);	return ret;}",28359
35,141,CVE-2016-10517,6,void resetCommandTableStats(void) {    int numcommands = sizeof(redisCommandTable)/sizeof(struct redisCommand);    int j;    for (j = 0; j < numcommands; j++) {        struct redisCommand *c = redisCommandTable+j;        c->microseconds = 0;        c->calls = 0;    }},22302
48,189,CVE-2015-2925,6,"void d_invalidate(struct dentry *dentry){	 	spin_lock(&dentry->d_lock);	if (d_unhashed(dentry)) {		spin_unlock(&dentry->d_lock);		return;	}	spin_unlock(&dentry->d_lock);	 	if (!dentry->d_inode) {		d_drop(dentry);		return;	}	for (;;) {		struct detach_data data;		data.mountpoint = NULL;		INIT_LIST_HEAD(&data.select.dispose);		data.select.start = dentry;		data.select.found = 0;		d_walk(dentry, &data, detach_and_collect, check_and_drop);		if (data.select.found)			shrink_dentry_list(&data.select.dispose);		if (data.mountpoint) {			detach_mounts(data.mountpoint);			dput(data.mountpoint);		}		if (!data.mountpoint && !data.select.found)			break;		cond_resched();	}}",28372
49,164,CVE-2015-7837,6,"static int bzImage64_probe(const char *buf, unsigned long len){	int ret = -ENOEXEC;	struct setup_header *header;	 	if (len < 2 * 512) {		pr_err(""File is too short to be a bzImage\n"");		return ret;	}	header = (struct setup_header *)(buf + offsetof(struct boot_params, hdr));	if (memcmp((char *)&header->header, ""HdrS"", 4) != 0) {		pr_err(""Not a bzImage\n"");		return ret;	}	if (header->boot_flag != 0xAA55) {		pr_err(""No x86 boot sector present\n"");		return ret;	}	if (header->version < 0x020C) {		pr_err(""Must be at least protocol version 2.12\n"");		return ret;	}	if (!(header->loadflags & LOADED_HIGH)) {		pr_err(""zImage not a bzImage\n"");		return ret;	}	if (!(header->xloadflags & XLF_KERNEL_64)) {		pr_err(""Not a bzImage64. XLF_KERNEL_64 is not set.\n"");		return ret;	}	if (!(header->xloadflags & XLF_CAN_BE_LOADED_ABOVE_4G)) {		pr_err(""XLF_CAN_BE_LOADED_ABOVE_4G is not set.\n"");		return ret;	}	 	if (efi_enabled(EFI_RUNTIME_SERVICES) && !efi_enabled(EFI_64BIT)) {		pr_debug(""EFI is 32 bit. Can't load kernel above 4G.\n"");		return ret;	}	 	pr_debug(""It's a relocatable bzImage64\n"");	ret = 0;	return ret;}",22893
56,130,CVE-2016-10517,6,unsigned int getLRUClock(void) {    return (mstime()/LRU_CLOCK_RESOLUTION) & LRU_CLOCK_MAX;},22291
29,148,CVE-2016-10517,6,void updateDictResizePolicy(void) {    if (server.rdb_child_pid == -1 && server.aof_child_pid == -1)        dictEnableResize();    else        dictDisableResize();},22309
54,158,CVE-2016-6271,6,"int messageTypeStringtoInt(int messageTypeString[8]) {	if (memcmp(messageTypeString, ""Hello   "", 8) == 0) {		return MSGTYPE_HELLO;	} else if (memcmp(messageTypeString, ""HelloACK"", 8) == 0) {		return MSGTYPE_HELLOACK;	} else if (memcmp(messageTypeString, ""Commit  "", 8) == 0) {		return MSGTYPE_COMMIT;	} else if (memcmp(messageTypeString, ""DHPart1 "", 8) == 0) {		return MSGTYPE_DHPART1;	} else if (memcmp(messageTypeString, ""DHPart2 "", 8) == 0) {		return MSGTYPE_DHPART2;	} else if (memcmp(messageTypeString, ""Confirm1"", 8) == 0) {		return MSGTYPE_CONFIRM1;	} else if (memcmp(messageTypeString, ""Confirm2"", 8) == 0) {		return MSGTYPE_CONFIRM2;	} else if (memcmp(messageTypeString, ""Conf2ACK"", 8) == 0) {		return MSGTYPE_CONF2ACK;	} else if (memcmp(messageTypeString, ""Error   "", 8) == 0) {		return MSGTYPE_ERROR;	} else if (memcmp(messageTypeString, ""ErrorACK"", 8) == 0) {		return MSGTYPE_ERRORACK;	} else if (memcmp(messageTypeString, ""GoClear "", 8) == 0) {		return MSGTYPE_GOCLEAR;	} else if (memcmp(messageTypeString, ""ClearACK"", 8) == 0) {		return MSGTYPE_CLEARACK;	} else if (memcmp(messageTypeString, ""SASrelay"", 8) == 0) {		return MSGTYPE_SASRELAY;	} else if (memcmp(messageTypeString, ""RelayACK"", 8) == 0) {		return MSGTYPE_RELAYACK;	} else if (memcmp(messageTypeString, ""Ping    "", 8) == 0) {		return MSGTYPE_PING;	} else if (memcmp(messageTypeString, ""PingACK "", 8) == 0) {		return MSGTYPE_PINGACK;	} else {		return MSGTYPE_INVALID;	}}",22813
42,63,CVE-2015-2925,6,"static int follow_managed(struct path *path, struct nameidata *nd){	struct vfsmount *mnt = path->mnt;  	unsigned managed;	int need_mntput = false;	int ret = 0;	 	while (managed = ACCESS_ONCE(path->dentry->d_flags),	       managed &= DCACHE_MANAGED_DENTRY,	       unlikely(managed != 0)) {		 		if (managed & DCACHE_MANAGE_TRANSIT) {			BUG_ON(!path->dentry->d_op);			BUG_ON(!path->dentry->d_op->d_manage);			ret = path->dentry->d_op->d_manage(path->dentry, false);			if (ret < 0)				break;		}		 		if (managed & DCACHE_MOUNTED) {			struct vfsmount *mounted = lookup_mnt(path);			if (mounted) {				dput(path->dentry);				if (need_mntput)					mntput(path->mnt);				path->mnt = mounted;				path->dentry = dget(mounted->mnt_root);				need_mntput = true;				continue;			}			 		}		 		if (managed & DCACHE_NEED_AUTOMOUNT) {			ret = follow_automount(path, nd, &need_mntput);			if (ret < 0)				break;			continue;		}		 		break;	}	if (need_mntput && path->mnt == mnt)		mntput(path->mnt);	if (ret == -EISDIR)		ret = 0;	if (need_mntput)		nd->flags |= LOOKUP_JUMPED;	if (unlikely(ret < 0))		path_put_conditional(path, nd);	return ret;}",13652
4,34,CVE-2015-3412,6,"PHP_FUNCTION(stream_filter_prepend){	apply_filter_to_stream(0, INTERNAL_FUNCTION_PARAM_PASSTHRU);}",2353
43,14,CVE-2015-3412,6,"PHP_FUNCTION(imagegif){	_php_image_output_ctx(INTERNAL_FUNCTION_PARAM_PASSTHRU, PHP_GDIMG_TYPE_GIF, ""GIF"", gdImageGifCtx);}",2333
24,94,CVE-2015-2925,6,static void terminate_walk(struct nameidata *nd){	drop_links(nd);	if (!(nd->flags & LOOKUP_RCU)) {		int i;		path_put(&nd->path);		for (i = 0; i < nd->depth; i++)			path_put(&nd->stack[i].link);		if (nd->root.mnt && !(nd->flags & LOOKUP_ROOT)) {			path_put(&nd->root);			nd->root.mnt = NULL;		}	} else {		nd->flags &= ~LOOKUP_RCU;		if (!(nd->flags & LOOKUP_ROOT))			nd->root.mnt = NULL;		rcu_read_unlock();	}	nd->depth = 0;},13683
11,195,CVE-2015-2925,6,"static inline int dentry_cmp(const struct dentry *dentry, const unsigned char *ct, unsigned tcount){	const unsigned char *cs;	 	cs = ACCESS_ONCE(dentry->d_name.name);	smp_read_barrier_depends();	return dentry_string_cmp(cs, ct, tcount);}",28378
20,16,CVE-2015-3412,6,"PHP_FUNCTION(imagejpeg){	_php_image_output_ctx(INTERNAL_FUNCTION_PARAM_PASSTHRU, PHP_GDIMG_TYPE_JPG, ""JPEG"", gdImageJpegCtx);}",2335
41,144,CVE-2016-10517,6,"int time_independent_strcmp(char *a, char *b) {    char bufa[CONFIG_AUTHPASS_MAX_LEN], bufb[CONFIG_AUTHPASS_MAX_LEN];         unsigned int alen = strlen(a);    unsigned int blen = strlen(b);    unsigned int j;    int diff = 0;         if (alen > sizeof(bufa) || blen > sizeof(bufb)) return 1;    memset(bufa,0,sizeof(bufa));             memset(bufb,0,sizeof(bufb));                  memcpy(bufa,a,alen);    memcpy(bufb,b,blen);         for (j = 0; j < sizeof(bufa); j++) {        diff |= (bufa[j] ^ bufb[j]);    }         diff |= alen ^ blen;    return diff;  }",22305
13,45,CVE-2016-1908,6,"set_addrinfo_port(struct addrinfo *addrs, int port){	struct addrinfo *addr;	for (addr = addrs; addr != NULL; addr = addr->ai_next) {		switch (addr->ai_family) {		case AF_INET:			((struct sockaddr_in *)addr->ai_addr)->			    sin_port = htons(port);			break;		case AF_INET6:			((struct sockaddr_in6 *)addr->ai_addr)->			    sin6_port = htons(port);			break;		}	}}",2394
15,42,CVE-2016-1908,6,"check_agent_present(void){	int r;	if (options.forward_agent) {		 		if ((r = ssh_get_authentication_socket(NULL)) != 0) {			options.forward_agent = 0;			if (r != SSH_ERR_AGENT_NOT_PRESENT)				debug(""ssh_get_authentication_socket: %s"",				    ssh_err(r));		}	}}",2391
12,161,CVE-2016-6271,6,int getCurrentTimeInMs() {	return myCurrentTime;},22816
18,196,CVE-2015-2925,6,static void dentry_lru_add(struct dentry *dentry){	if (unlikely(!(dentry->d_flags & DCACHE_LRU_LIST)))		d_lru_add(dentry);},28379
5,2,CVE-2015-3412,6,"PHP_METHOD(domdocument, loadHTMLFile){	dom_load_html(INTERNAL_FUNCTION_PARAM_PASSTHRU, DOM_LOAD_FILE);}",2321
39,39,CVE-2016-1908,6,"mux_client_forwards(int fd, int cancel_flag){	int i, ret = 0;	debug3(""%s: %s forwardings: %d local, %d remote"", __func__,	    cancel_flag ? ""cancel"" : ""request"",	    options.num_local_forwards, options.num_remote_forwards);	 	for (i = 0; i < options.num_local_forwards; i++) {		if (mux_client_forward(fd, cancel_flag,		    options.local_forwards[i].connect_port == 0 ?		    MUX_FWD_DYNAMIC : MUX_FWD_LOCAL,		    options.local_forwards + i) != 0)			ret = -1;	}	for (i = 0; i < options.num_remote_forwards; i++) {		if (mux_client_forward(fd, cancel_flag, MUX_FWD_REMOTE,		    options.remote_forwards + i) != 0)			ret = -1;	}	return ret;}",2388
40,46,CVE-2016-1908,6,"ssh_init_forwarding(void){	int success = 0;	int i;	 	for (i = 0; i < options.num_local_forwards; i++) {		debug(""Local connections to %.200s:%d forwarded to remote ""		    ""address %.200s:%d"",		    (options.local_forwards[i].listen_path != NULL) ?		    options.local_forwards[i].listen_path :		    (options.local_forwards[i].listen_host == NULL) ?		    (options.fwd_opts.gateway_ports ? ""*"" : ""LOCALHOST"") :		    options.local_forwards[i].listen_host,		    options.local_forwards[i].listen_port,		    (options.local_forwards[i].connect_path != NULL) ?		    options.local_forwards[i].connect_path :		    options.local_forwards[i].connect_host,		    options.local_forwards[i].connect_port);		success += channel_setup_local_fwd_listener(		    &options.local_forwards[i], &options.fwd_opts);	}	if (i > 0 && success != i && options.exit_on_forward_failure)		fatal(""Could not request local forwarding."");	if (i > 0 && success == 0)		error(""Could not request local forwarding."");	 	for (i = 0; i < options.num_remote_forwards; i++) {		debug(""Remote connections from %.200s:%d forwarded to ""		    ""local address %.200s:%d"",		    (options.remote_forwards[i].listen_path != NULL) ?		    options.remote_forwards[i].listen_path :		    (options.remote_forwards[i].listen_host == NULL) ?		    ""LOCALHOST"" : options.remote_forwards[i].listen_host,		    options.remote_forwards[i].listen_port,		    (options.remote_forwards[i].connect_path != NULL) ?		    options.remote_forwards[i].connect_path :		    options.remote_forwards[i].connect_host,		    options.remote_forwards[i].connect_port);		options.remote_forwards[i].handle =		    channel_request_remote_forwarding(		    &options.remote_forwards[i]);		if (options.remote_forwards[i].handle < 0) {			if (options.exit_on_forward_failure)				fatal(""Could not request remote forwarding."");			else				logit(""Warning: Could not request remote ""				    ""forwarding."");		} else {			client_register_global_confirm(ssh_confirm_remote_forward,			    &options.remote_forwards[i]);		}	}	 	if (options.tun_open != SSH_TUNMODE_NO) {		if (client_request_tun_fwd(options.tun_open,		    options.tun_local, options.tun_remote) == -1) {			if (options.exit_on_forward_failure)				fatal(""Could not request tunnel forwarding."");			else				error(""Could not request tunnel forwarding."");		}	}			}",2395
16,5,CVE-2015-3412,6,"PHP_FUNCTION(imagecreatefromjpeg){	_php_image_create_from(INTERNAL_FUNCTION_PARAM_PASSTHRU, PHP_GDIMG_TYPE_JPG, ""JPEG"", gdImageCreateFromJpeg, gdImageCreateFromJpegCtx);}",2324
33,117,CVE-2016-10517,6,"int checkForSentinelMode(int argc, char **argv) {    int j;    if (strstr(argv[0],""redis-sentinel"") != NULL) return 1;    for (j = 1; j < argc; j++)        if (!strcmp(argv[j],""--sentinel"")) return 1;    return 0;}",22278
14,103,CVE-2014-8160,6,"static int generic_pkt_to_tuple(const struct sk_buff *skb,				 unsigned int dataoff,				 struct nf_conntrack_tuple *tuple){	tuple->src.u.all = 0;	tuple->dst.u.all = 0;	return true;}",14527
28,36,CVE-2016-1908,6,"compare_forward(struct Forward *a, struct Forward *b){	if (!compare_host(a->listen_host, b->listen_host))		return 0;	if (!compare_host(a->listen_path, b->listen_path))		return 0;	if (a->listen_port != b->listen_port)		return 0;	if (!compare_host(a->connect_host, b->connect_host))		return 0;	if (!compare_host(a->connect_path, b->connect_path))		return 0;	if (a->connect_port != b->connect_port)		return 0;	return 1;}",2385
31,139,CVE-2016-10517,6,"int redisIsSupervised(int mode) {    if (mode == SUPERVISED_AUTODETECT) {        const char *upstart_job = getenv(""UPSTART_JOB"");        const char *notify_socket = getenv(""NOTIFY_SOCKET"");        if (upstart_job) {            redisSupervisedUpstart();        } else if (notify_socket) {            redisSupervisedSystemd();        }    } else if (mode == SUPERVISED_UPSTART) {        return redisSupervisedUpstart();    } else if (mode == SUPERVISED_SYSTEMD) {        return redisSupervisedSystemd();    }    return 0;}",22300
50,225,CVE-2015-2925,6,"static int follow_dotdot_rcu(struct nameidata *nd){	struct inode *inode = nd->inode;	if (!nd->root.mnt)		set_root_rcu(nd);	while (1) {		if (path_equal(&nd->path, &nd->root))			break;		if (nd->path.dentry != nd->path.mnt->mnt_root) {			struct dentry *old = nd->path.dentry;			struct dentry *parent = old->d_parent;			unsigned seq;			inode = parent->d_inode;			seq = read_seqcount_begin(&parent->d_seq);			if (unlikely(read_seqcount_retry(&old->d_seq, nd->seq))) 				return -ECHILD; 			nd->path.dentry = parent; 			nd->seq = seq; 			break; 		} else { 			struct mount *mnt = real_mount(nd->path.mnt);			struct mount *mparent = mnt->mnt_parent;			struct dentry *mountpoint = mnt->mnt_mountpoint;			struct inode *inode2 = mountpoint->d_inode;			unsigned seq = read_seqcount_begin(&mountpoint->d_seq);			if (unlikely(read_seqretry(&mount_lock, nd->m_seq)))				return -ECHILD;			if (&mparent->mnt == nd->path.mnt)				break;			 			nd->path.dentry = mountpoint;			nd->path.mnt = &mparent->mnt;			inode = inode2;			nd->seq = seq;		}	}	while (unlikely(d_mountpoint(nd->path.dentry))) {		struct mount *mounted;		mounted = __lookup_mnt(nd->path.mnt, nd->path.dentry);		if (unlikely(read_seqretry(&mount_lock, nd->m_seq)))			return -ECHILD;		if (!mounted)			break;		nd->path.mnt = &mounted->mnt;		nd->path.dentry = mounted->mnt.mnt_root;		inode = nd->path.dentry->d_inode;		nd->seq = read_seqcount_begin(&nd->path.dentry->d_seq);	}	nd->inode = inode;	return 0;}",31200
27,112,CVE-2016-10517,6,"char *getClientTypeName(int class) {    switch(class) {    case CLIENT_TYPE_NORMAL: return ""normal"";    case CLIENT_TYPE_SLAVE:  return ""slave"";    case CLIENT_TYPE_PUBSUB: return ""pubsub"";    case CLIENT_TYPE_MASTER: return ""master"";    default:                       return NULL;    }}",22273
36,207,CVE-2015-1281,6,DEFINE_TRACE(DocumentVisibilityObserver){    visitor->trace(m_document);},29655
53,62,CVE-2015-2925,6,"static int follow_automount(struct path *path, struct nameidata *nd,			    int *need_mntput){	struct vfsmount *mnt;	int err;	if (!path->dentry->d_op || !path->dentry->d_op->d_automount)		return -EREMOTE;	 	if (!(nd->flags & (LOOKUP_PARENT | LOOKUP_DIRECTORY |			   LOOKUP_OPEN | LOOKUP_CREATE | LOOKUP_AUTOMOUNT)) &&	    path->dentry->d_inode)		return -EISDIR;	nd->total_link_count++;	if (nd->total_link_count >= 40)		return -ELOOP;	mnt = path->dentry->d_op->d_automount(path);	if (IS_ERR(mnt)) {		 		if (PTR_ERR(mnt) == -EISDIR && (nd->flags & LOOKUP_PARENT))			return -EREMOTE;		return PTR_ERR(mnt);	}	if (!mnt)  		return 0;	if (!*need_mntput) {		 		mntget(path->mnt);		*need_mntput = true;	}	err = finish_automount(mnt, path);	switch (err) {	case -EBUSY:		 		return 0;	case 0:		path_put(path);		path->mnt = mnt;		path->dentry = dget(mnt->mnt_root);		return 0;	default:		return err;	}}",13651
9,142,CVE-2016-10517,6,"void serverLogFromHandler(int level, const char *msg) {    int fd;    int log_to_stdout = server.logfile[0] == '\0';    char buf[64];    if ((level&0xff) < server.verbosity || (log_to_stdout && server.daemonize))        return;    fd = log_to_stdout ? STDOUT_FILENO :                         open(server.logfile, O_APPEND|O_CREAT|O_WRONLY, 0644);    if (fd == -1) return;    ll2string(buf,sizeof(buf),getpid());    if (write(fd,buf,strlen(buf)) == -1) goto err;    if (write(fd,"":signal-handler ("",17) == -1) goto err;    ll2string(buf,sizeof(buf),time(NULL));    if (write(fd,buf,strlen(buf)) == -1) goto err;    if (write(fd,"") "",2) == -1) goto err;    if (write(fd,msg,strlen(msg)) == -1) goto err;    if (write(fd,""\n"",1) == -1) goto err;err:    if (!log_to_stdout) close(fd);}",22303
6,126,CVE-2016-10517,6,"int dictSdsKeyCaseCompare(void *privdata, const void *key1,        const void *key2){    DICT_NOTUSED(privdata);    return strcasecmp(key1, key2) == 0;}",22287
30,24,CVE-2015-3412,6,"PHP_FUNCTION(imagechar){	php_imagechar(INTERNAL_FUNCTION_PARAM_PASSTHRU, 0);}",2343
45,60,CVE-2015-2925,6,"filename_mountpoint(int dfd, struct filename *name, struct path *path,			unsigned int flags){	struct nameidata nd;	int error;	if (IS_ERR(name))		return PTR_ERR(name);	set_nameidata(&nd, dfd, name);	error = path_mountpoint(&nd, flags | LOOKUP_RCU, path);	if (unlikely(error == -ECHILD))		error = path_mountpoint(&nd, flags, path);	if (unlikely(error == -ESTALE))		error = path_mountpoint(&nd, flags | LOOKUP_REVAL, path);	if (likely(!error))		audit_inode(name, path->dentry, 0);	restore_nameidata();	putname(name);	return error;}",13649
2,181,CVE-2015-2925,6,"struct dentry *d_add_ci(struct dentry *dentry, struct inode *inode,			struct qstr *name){	struct dentry *found;	struct dentry *new;	 	found = d_hash_and_lookup(dentry->d_parent, name);	if (!found) {		new = d_alloc(dentry->d_parent, name);		if (!new) {			found = ERR_PTR(-ENOMEM);		} else {			found = d_splice_alias(inode, new);			if (found) {				dput(new);				return found;			}			return new;		}	}	iput(inode);	return found;}",28364
44,156,CVE-2016-6271,6,int computeKeyAgreementPrivateValueLength(int keyAgreementAlgo) {	int pvLength = 0;	switch (keyAgreementAlgo) {		case ZRTP_KEYAGREEMENT_DH3k	:			pvLength = 384;			break;		case ZRTP_KEYAGREEMENT_DH2k :			pvLength = 256;			break;		case ZRTP_KEYAGREEMENT_EC25	:			pvLength = 64;			break;		case ZRTP_KEYAGREEMENT_EC38	:			pvLength = 96;			break;		case ZRTP_KEYAGREEMENT_EC52 :			pvLength = 132;			break;		default :			pvLength = 0;			break;	}	return pvLength;},22811
11,770,CVE-2011-2918,23,"ptrace_modify_breakpoint(struct perf_event *bp, int len, int type,			 struct task_struct *tsk, int disabled){	int err;	int gen_len, gen_type;	struct perf_event_attr attr;	 	if (!bp)		return -EINVAL;	err = arch_bp_generic_fields(len, type, &gen_len, &gen_type);	if (err)		return err;	attr = bp->attr;	attr.bp_len = gen_len;	attr.bp_type = gen_type;	attr.disabled = disabled;	return modify_user_hw_breakpoint(bp, &attr);}",6162
149,1862,CVE-2014-3690,23,"static int handle_set_cr0(struct kvm_vcpu *vcpu, unsigned long val){	if (is_guest_mode(vcpu)) {		struct vmcs12 *vmcs12 = get_vmcs12(vcpu);		unsigned long orig_val = val;		 		val = (val & ~vmcs12->cr0_guest_host_mask) |			(vmcs12->guest_cr0 & vmcs12->cr0_guest_host_mask);		if (!nested_cr0_valid(vmcs12, val))			return 1;		if (kvm_set_cr0(vcpu, val))			return 1;		vmcs_writel(CR0_READ_SHADOW, orig_val);		return 0;	} else {		if (to_vmx(vcpu)->nested.vmxon &&		    ((val & VMXON_CR0_ALWAYSON) != VMXON_CR0_ALWAYSON))			return 1;		return kvm_set_cr0(vcpu, val);	}}",11050
278,939,CVE-2011-2918,23,static inline void update_cgrp_time_from_cpuctx(struct perf_cpu_context *cpuctx){},6331
161,1706,CVE-2014-7841,23,"struct sctp_chunk *sctp_chunkify(struct sk_buff *skb,			    const struct sctp_association *asoc,			    struct sock *sk){	struct sctp_chunk *retval;	retval = kmem_cache_zalloc(sctp_chunk_cachep, GFP_ATOMIC);	if (!retval)		goto nodata;	if (!sk)		pr_debug(""%s: chunkifying skb:%p w/o an sk\n"", __func__, skb);	INIT_LIST_HEAD(&retval->list);	retval->skb		= skb;	retval->asoc		= (struct sctp_association *)asoc;	retval->singleton	= 1;	retval->fast_retransmit = SCTP_CAN_FRTX;	 	INIT_LIST_HEAD(&retval->transmitted_list);	INIT_LIST_HEAD(&retval->frag_list);	SCTP_DBG_OBJCNT_INC(chunk);	atomic_set(&retval->refcnt, 1);nodata:	return retval;}",10514
612,1157,CVE-2013-4127,23,static void vhost_net_tx_packet(struct vhost_net *net){	++net->tx_packets;	if (net->tx_packets < 1024)		return;	net->tx_packets = 0;	net->tx_zcopy_err = 0;},7996
551,514,CVE-2011-2918,23,"static int mipspmu_get_irq(void){	int err;	if (mipspmu->irq >= 0) {		 		err = request_irq(mipspmu->irq, mipspmu->handle_irq,			IRQF_DISABLED | IRQF_NOBALANCING,			""mips_perf_pmu"", NULL);		if (err) {			pr_warning(""Unable to request IRQ%d for MIPS ""			   ""performance counters!\n"", mipspmu->irq);		}	} else if (cp0_perfcount_irq < 0) {		 		save_perf_irq = perf_irq;		perf_irq = mipspmu->handle_shared_irq;		err = 0;	} else {		pr_warning(""The platform hasn't properly defined its ""			""interrupt controller.\n"");		err = -ENOENT;	}	return err;}",5906
101,1486,CVE-2013-0217,23,"static inline void set_page_ext(struct page *pg, struct xen_netbk *netbk,				unsigned int idx){	unsigned int group = netbk - xen_netbk;	union page_ext ext = { .e = { .group = group + 1, .idx = idx } };	BUILD_BUG_ON(sizeof(ext) > sizeof(ext.mapping));	pg->mapping = ext.mapping;}",9783
303,541,CVE-2011-2918,23,"unsigned long ptrace_get_reg(struct task_struct *task, int regno){	if (task->thread.regs == NULL)		return -EIO;	if (regno == PT_MSR)		return get_user_msr(task);	if (regno < (sizeof(struct pt_regs) / sizeof(unsigned long)))		return ((unsigned long *)task->thread.regs)[regno];	return -EIO;}",5933
128,2261,CVE-2015-5307,23,static int vmx_has_high_real_mode_segbase(void){	return enable_unrestricted_guest || emulate_invalid_guest_state;},13383
387,1665,CVE-2014-8481,23,"static int emulate_popf(struct x86_emulate_ctxt *ctxt,			void *dest, int len){	int rc;	unsigned long val, change_mask;	int iopl = (ctxt->eflags & X86_EFLAGS_IOPL) >> IOPL_SHIFT;	int cpl = ctxt->ops->cpl(ctxt);	rc = emulate_pop(ctxt, &val, len);	if (rc != X86EMUL_CONTINUE)		return rc;	change_mask = EFLG_CF | EFLG_PF | EFLG_AF | EFLG_ZF | EFLG_SF | EFLG_OF		| EFLG_TF | EFLG_DF | EFLG_NT | EFLG_AC | EFLG_ID;	switch(ctxt->mode) {	case X86EMUL_MODE_PROT64:	case X86EMUL_MODE_PROT32:	case X86EMUL_MODE_PROT16:		if (cpl == 0)			change_mask |= EFLG_IOPL;		if (cpl <= iopl)			change_mask |= EFLG_IF;		break;	case X86EMUL_MODE_VM86:		if (iopl < 3)			return emulate_gp(ctxt, 0);		change_mask |= EFLG_IF;		break;	default:  		change_mask |= (EFLG_IOPL | EFLG_IF);		break;	}	*(unsigned long *)dest =		(ctxt->eflags & ~change_mask) | (val & change_mask);	return rc;}",10436
320,2215,CVE-2015-5307,23,static int handle_pcommit(struct kvm_vcpu *vcpu){	 	WARN_ON(1);	return 1;},13337
62,841,CVE-2011-2918,23,"perf_cgroup_set_timestamp(struct task_struct *task,			  struct perf_event_context *ctx){}",6233
450,1678,CVE-2014-8481,23,"static void save_state_to_tss16(struct x86_emulate_ctxt *ctxt,				struct tss_segment_16 *tss){	tss->ip = ctxt->_eip;	tss->flag = ctxt->eflags;	tss->ax = reg_read(ctxt, VCPU_REGS_RAX);	tss->cx = reg_read(ctxt, VCPU_REGS_RCX);	tss->dx = reg_read(ctxt, VCPU_REGS_RDX);	tss->bx = reg_read(ctxt, VCPU_REGS_RBX);	tss->sp = reg_read(ctxt, VCPU_REGS_RSP);	tss->bp = reg_read(ctxt, VCPU_REGS_RBP);	tss->si = reg_read(ctxt, VCPU_REGS_RSI);	tss->di = reg_read(ctxt, VCPU_REGS_RDI);	tss->es = get_segment_selector(ctxt, VCPU_SREG_ES);	tss->cs = get_segment_selector(ctxt, VCPU_SREG_CS);	tss->ss = get_segment_selector(ctxt, VCPU_SREG_SS);	tss->ds = get_segment_selector(ctxt, VCPU_SREG_DS);	tss->ldt = get_segment_selector(ctxt, VCPU_SREG_LDTR);}",10449
491,1713,CVE-2014-7841,23,"struct sctp_chunk *sctp_make_shutdown_ack(const struct sctp_association *asoc,				     const struct sctp_chunk *chunk){	struct sctp_chunk *retval;	retval = sctp_make_control(asoc, SCTP_CID_SHUTDOWN_ACK, 0, 0);	 	if (retval && chunk)		retval->transport = chunk->transport;	return retval;}",10521
23,1111,CVE-2013-4592,23,void kvm_release_page_clean(struct page *page){	WARN_ON(is_error_page(page));	kvm_release_pfn_clean(page_to_pfn(page));},7515
434,2578,CVE-2013-2909,23,    void addUncommittedWidth(float delta) { m_uncommittedWidth += delta; },29367
671,2462,CVE-2015-8785,23,"static int fuse_writepage_locked(struct page *page){	struct address_space *mapping = page->mapping;	struct inode *inode = mapping->host;	struct fuse_conn *fc = get_fuse_conn(inode);	struct fuse_inode *fi = get_fuse_inode(inode);	struct fuse_req *req;	struct page *tmp_page;	int error = -ENOMEM;	set_page_writeback(page);	req = fuse_request_alloc_nofs(1);	if (!req)		goto err;	 	__set_bit(FR_BACKGROUND, &req->flags);	tmp_page = alloc_page(GFP_NOFS | __GFP_HIGHMEM);	if (!tmp_page)		goto err_free;	error = -EIO;	req->ff = fuse_write_file_get(fc, fi);	if (!req->ff)		goto err_nofile;	fuse_write_fill(req, req->ff, page_offset(page), 0);	copy_highpage(tmp_page, page);	req->misc.write.in.write_flags |= FUSE_WRITE_CACHE;	req->misc.write.next = NULL;	req->in.argpages = 1;	req->num_pages = 1;	req->pages[0] = tmp_page;	req->page_descs[0].offset = 0;	req->page_descs[0].length = PAGE_SIZE;	req->end = fuse_writepage_end;	req->inode = inode;	inc_wb_stat(&inode_to_bdi(inode)->wb, WB_WRITEBACK);	inc_zone_page_state(tmp_page, NR_WRITEBACK_TEMP);	spin_lock(&fc->lock);	list_add(&req->writepages_entry, &fi->writepages);	list_add_tail(&req->list, &fi->queued_writes);	fuse_flush_writepages(inode);	spin_unlock(&fc->lock);	end_page_writeback(page);	return 0;err_nofile:	__free_page(tmp_page);err_free:	fuse_request_free(req);err:	end_page_writeback(page);	return error;}",18735
281,951,CVE-2011-2918,23,"static int perf_output_space(struct ring_buffer *rb, unsigned long tail,			      unsigned long offset, unsigned long head){	unsigned long mask;	if (!rb->writable)		return true;	mask = perf_data_size(rb) - 1;	offset = (offset - tail) & mask;	head   = (head   - tail) & mask;	if ((int)(head - offset) < 0)		return false;	return true;}",6343
89,371,CVE-2012-0207,23,"	__acquires(rcu){	rcu_read_lock();	return *pos ? igmp_mcf_get_idx(seq, *pos - 1) : SEQ_START_TOKEN;}",4111
470,2457,CVE-2015-8785,23,"int fuse_write_inode(struct inode *inode, struct writeback_control *wbc){	struct fuse_conn *fc = get_fuse_conn(inode);	struct fuse_inode *fi = get_fuse_inode(inode);	struct fuse_file *ff;	int err;	ff = __fuse_write_file_get(fc, fi);	err = fuse_flush_times(inode, ff);	if (ff)		fuse_file_put(ff, 0);	return err;}",18730
530,1400,CVE-2013-2015,23,"static struct dx_countlimit *get_dx_countlimit(struct inode *inode,					       struct ext4_dir_entry *dirent,					       int *offset){	struct ext4_dir_entry *dp;	struct dx_root_info *root;	int count_offset;	if (le16_to_cpu(dirent->rec_len) == EXT4_BLOCK_SIZE(inode->i_sb))		count_offset = 8;	else if (le16_to_cpu(dirent->rec_len) == 12) {		dp = (struct ext4_dir_entry *)(((void *)dirent) + 12);		if (le16_to_cpu(dp->rec_len) !=		    EXT4_BLOCK_SIZE(inode->i_sb) - 12)			return NULL;		root = (struct dx_root_info *)(((void *)dp + 12));		if (root->reserved_zero ||		    root->info_length != sizeof(struct dx_root_info))			return NULL;		count_offset = 32;	} else		return NULL;	if (offset)		*offset = count_offset;	return (struct dx_countlimit *)(((void *)dirent) + count_offset);}",9109
545,861,CVE-2011-2918,23,static int perf_event_index(struct perf_event *event){	if (event->hw.state & PERF_HES_STOPPED)		return 0;	if (event->state != PERF_EVENT_STATE_ACTIVE)		return 0;	return event->hw.idx + 1 - PERF_EVENT_INDEX_OFFSET;},6253
453,2511,CVE-2019-15538,23,"xfs_vn_ci_lookup(	struct inode	*dir,	struct dentry	*dentry,	unsigned int flags){	struct xfs_inode *ip;	struct xfs_name	xname;	struct xfs_name ci_name;	struct qstr	dname;	int		error;	if (dentry->d_name.len >= MAXNAMELEN)		return ERR_PTR(-ENAMETOOLONG);	xfs_dentry_to_name(&xname, dentry);	error = xfs_lookup(XFS_I(dir), &xname, &ip, &ci_name);	if (unlikely(error)) {		if (unlikely(error != -ENOENT))			return ERR_PTR(error);		 		return NULL;	}	 	if (!ci_name.name)		return d_splice_alias(VFS_I(ip), dentry);	 	dname.name = ci_name.name;	dname.len = ci_name.len;	dentry = d_add_ci(dentry, VFS_I(ip), &dname);	kmem_free(ci_name.name);	return dentry;}",26634
134,746,CVE-2011-2918,23,"static int p4_next_cntr(int thread, unsigned long *used_mask,			struct p4_event_bind *bind){	int i, j;	for (i = 0; i < P4_CNTR_LIMIT; i++) {		j = bind->cntr[thread][i];		if (j != -1 && !test_bit(j, used_mask))			return j;	}	return -1;}",6138
196,846,CVE-2011-2918,23,static inline void perf_detach_cgroup(struct perf_event *event){	perf_put_cgroup(event);	event->cgrp = NULL;},6238
579,1907,CVE-2014-3690,23,"static int tr_valid(struct kvm_vcpu *vcpu){	struct kvm_segment tr;	vmx_get_segment(vcpu, &tr, VCPU_SREG_TR);	if (tr.unusable)		return false;	if (tr.selector & SELECTOR_TI_MASK)	 		return false;	if (tr.type != 3 && tr.type != 11)  		return false;	if (!tr.present)		return false;	return true;}",11095
50,2434,CVE-2015-8785,23,"struct fuse_file *fuse_file_alloc(struct fuse_conn *fc){	struct fuse_file *ff;	ff = kmalloc(sizeof(struct fuse_file), GFP_KERNEL);	if (unlikely(!ff))		return NULL;	ff->fc = fc;	ff->reserved_req = fuse_request_alloc(0);	if (unlikely(!ff->reserved_req)) {		kfree(ff);		return NULL;	}	INIT_LIST_HEAD(&ff->write_entry);	atomic_set(&ff->count, 0);	RB_CLEAR_NODE(&ff->polled_node);	init_waitqueue_head(&ff->poll_wait);	spin_lock(&fc->lock);	ff->kh = ++fc->khctr;	spin_unlock(&fc->lock);	return ff;}",18707
513,2122,CVE-2012-6638,23,"void tcp_update_metrics(struct sock *sk){	struct tcp_sock *tp = tcp_sk(sk);	struct dst_entry *dst = __sk_dst_get(sk);	if (sysctl_tcp_nometrics_save)		return;	dst_confirm(dst);	if (dst && (dst->flags & DST_HOST)) {		const struct inet_connection_sock *icsk = inet_csk(sk);		int m;		unsigned long rtt;		if (icsk->icsk_backoff || !tp->srtt) {			 			if (!(dst_metric_locked(dst, RTAX_RTT)))				dst_metric_set(dst, RTAX_RTT, 0);			return;		}		rtt = dst_metric_rtt(dst, RTAX_RTT);		m = rtt - tp->srtt;		 		if (!(dst_metric_locked(dst, RTAX_RTT))) {			if (m <= 0)				set_dst_metric_rtt(dst, RTAX_RTT, tp->srtt);			else				set_dst_metric_rtt(dst, RTAX_RTT, rtt - (m >> 3));		}		if (!(dst_metric_locked(dst, RTAX_RTTVAR))) {			unsigned long var;			if (m < 0)				m = -m;			 			m >>= 1;			if (m < tp->mdev)				m = tp->mdev;			var = dst_metric_rtt(dst, RTAX_RTTVAR);			if (m >= var)				var = m;			else				var -= (var - m) >> 2;			set_dst_metric_rtt(dst, RTAX_RTTVAR, var);		}		if (tcp_in_initial_slowstart(tp)) {			 			if (dst_metric(dst, RTAX_SSTHRESH) &&			    !dst_metric_locked(dst, RTAX_SSTHRESH) &&			    (tp->snd_cwnd >> 1) > dst_metric(dst, RTAX_SSTHRESH))				dst_metric_set(dst, RTAX_SSTHRESH, tp->snd_cwnd >> 1);			if (!dst_metric_locked(dst, RTAX_CWND) &&			    tp->snd_cwnd > dst_metric(dst, RTAX_CWND))				dst_metric_set(dst, RTAX_CWND, tp->snd_cwnd);		} else if (tp->snd_cwnd > tp->snd_ssthresh &&			   icsk->icsk_ca_state == TCP_CA_Open) {			 			if (!dst_metric_locked(dst, RTAX_SSTHRESH))				dst_metric_set(dst, RTAX_SSTHRESH,					       max(tp->snd_cwnd >> 1, tp->snd_ssthresh));			if (!dst_metric_locked(dst, RTAX_CWND))				dst_metric_set(dst, RTAX_CWND,					       (dst_metric(dst, RTAX_CWND) +						tp->snd_cwnd) >> 1);		} else {			 			if (!dst_metric_locked(dst, RTAX_CWND))				dst_metric_set(dst, RTAX_CWND,					       (dst_metric(dst, RTAX_CWND) +						tp->snd_ssthresh) >> 1);			if (dst_metric(dst, RTAX_SSTHRESH) &&			    !dst_metric_locked(dst, RTAX_SSTHRESH) &&			    tp->snd_ssthresh > dst_metric(dst, RTAX_SSTHRESH))				dst_metric_set(dst, RTAX_SSTHRESH, tp->snd_ssthresh);		}		if (!dst_metric_locked(dst, RTAX_REORDERING)) {			if (dst_metric(dst, RTAX_REORDERING) < tp->reordering &&			    tp->reordering != sysctl_tcp_reordering)				dst_metric_set(dst, RTAX_REORDERING, tp->reordering);		}	}}",12756
460,876,CVE-2011-2918,23,"perf_install_in_context(struct perf_event_context *ctx,			struct perf_event *event,			int cpu){	struct task_struct *task = ctx->task;	lockdep_assert_held(&ctx->mutex);	event->ctx = ctx;	if (!task) {		 		cpu_function_call(cpu, __perf_install_in_context, event);		return;	}retry:	if (!task_function_call(task, __perf_install_in_context, event))		return;	raw_spin_lock_irq(&ctx->lock);	 	if (ctx->is_active) {		raw_spin_unlock_irq(&ctx->lock);		goto retry;	}	 	add_event_to_ctx(event, ctx);	raw_spin_unlock_irq(&ctx->lock);}",6268
126,285,CVE-2012-1601,23,int kvm_arch_vcpu_runnable(struct kvm_vcpu *vcpu){	return (vcpu->arch.mp_state == KVM_MP_STATE_RUNNABLE &&		!vcpu->arch.apf.halted)		|| !list_empty_careful(&vcpu->async_pf.done)		|| vcpu->arch.mp_state == KVM_MP_STATE_SIPI_RECEIVED		|| atomic_read(&vcpu->arch.nmi_queued) ||		(kvm_arch_interrupt_allowed(vcpu) &&		 kvm_cpu_has_interrupt(vcpu));},3763
650,2222,CVE-2015-5307,23,static void hardware_disable(void){	if (vmm_exclusive) {		vmclear_local_loaded_vmcss();		kvm_cpu_vmxoff();	}	cr4_clear_bits(X86_CR4_VMXE);},13344
207,2047,CVE-2012-6638,23,"static inline void TCP_ECN_rcv_synack(struct tcp_sock *tp, const struct tcphdr *th){	if ((tp->ecn_flags & TCP_ECN_OK) && (!th->ece || th->cwr))		tp->ecn_flags &= ~TCP_ECN_OK;}",12681
459,1564,CVE-2011-2491,23,rpc_restart_call(struct rpc_task *task){	if (RPC_ASSASSINATED(task))		return 0;	task->tk_action = call_start;	return 1;},10183
205,1525,CVE-2011-2491,23,"static int do_vfs_lock(struct file_lock *fl){	int res = 0;	switch (fl->fl_flags & (FL_POSIX|FL_FLOCK)) {		case FL_POSIX:			res = posix_lock_file_wait(fl->fl_file, fl);			break;		case FL_FLOCK:			res = flock_lock_file_wait(fl->fl_file, fl);			break;		default:			BUG();	}	return res;}",10144
96,2643,CVE-2012-2133,23,"int hugetlb_get_quota(struct address_space *mapping, long delta){	int ret = 0;	struct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(mapping->host->i_sb);	if (sbinfo->free_blocks > -1) {		spin_lock(&sbinfo->stat_lock);		if (sbinfo->free_blocks - delta >= 0)			sbinfo->free_blocks -= delta;		else			ret = -ENOMEM;		spin_unlock(&sbinfo->stat_lock);	}	return ret;}",30938
368,1958,CVE-2014-3690,23,static int vmx_vm_has_apicv(struct kvm *kvm){	return enable_apicv && irqchip_in_kernel(kvm);},11146
290,779,CVE-2011-2918,23,"__bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,		       unsigned long address, int si_code){	struct task_struct *tsk = current;	 	if (error_code & PF_USER) {		 		local_irq_enable();		 		if (is_prefetch(regs, error_code, address))			return;		if (is_errata100(regs, address))			return;		if (unlikely(show_unhandled_signals))			show_signal_msg(regs, error_code, address, tsk);		 		tsk->thread.cr2		= address;		tsk->thread.error_code	= error_code | (address >= TASK_SIZE);		tsk->thread.trap_no	= 14;		force_sig_info_fault(SIGSEGV, si_code, address, tsk, 0);		return;	}	if (is_f00f_bug(regs, address))		return;	no_context(regs, error_code, address);}",6171
641,1819,CVE-2014-3690,23,static inline int cpu_has_vmx_unrestricted_guest(void){	return vmcs_config.cpu_based_2nd_exec_ctrl &		SECONDARY_EXEC_UNRESTRICTED_GUEST;},11007
13,1367,CVE-2013-2017,23,void synchronize_net(void){	might_sleep();	synchronize_rcu();},9076
535,338,CVE-2012-1601,23,static int kvm_vm_ioctl_get_nr_mmu_pages(struct kvm *kvm){	return kvm->arch.n_max_mmu_pages;},3816
516,985,CVE-2011-2918,23,static inline void irq_time_write_end(void){},6377
311,1804,CVE-2014-3690,23,static inline int cpu_has_vmx_ept_4levels(void){	return vmx_capability.ept & VMX_EPT_PAGE_WALK_4_BIT;},10992
85,2224,CVE-2015-5307,23,"static void load_vmcs12_host_state(struct kvm_vcpu *vcpu,				   struct vmcs12 *vmcs12){	struct kvm_segment seg;	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER)		vcpu->arch.efer = vmcs12->host_ia32_efer;	else if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		vcpu->arch.efer |= (EFER_LMA | EFER_LME);	else		vcpu->arch.efer &= ~(EFER_LMA | EFER_LME);	vmx_set_efer(vcpu, vcpu->arch.efer);	kvm_register_write(vcpu, VCPU_REGS_RSP, vmcs12->host_rsp);	kvm_register_write(vcpu, VCPU_REGS_RIP, vmcs12->host_rip);	vmx_set_rflags(vcpu, X86_EFLAGS_FIXED);	 	vmx_set_cr0(vcpu, vmcs12->host_cr0);	 	update_exception_bitmap(vcpu);	vcpu->arch.cr0_guest_owned_bits = (vcpu->fpu_active ? X86_CR0_TS : 0);	vmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits);	 	vcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK);	kvm_set_cr4(vcpu, vmcs12->host_cr4);	nested_ept_uninit_mmu_context(vcpu);	kvm_set_cr3(vcpu, vmcs12->host_cr3);	kvm_mmu_reset_context(vcpu);	if (!enable_ept)		vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;	if (enable_vpid) {		 		vmx_flush_tlb(vcpu);	}	vmcs_write32(GUEST_SYSENTER_CS, vmcs12->host_ia32_sysenter_cs);	vmcs_writel(GUEST_SYSENTER_ESP, vmcs12->host_ia32_sysenter_esp);	vmcs_writel(GUEST_SYSENTER_EIP, vmcs12->host_ia32_sysenter_eip);	vmcs_writel(GUEST_IDTR_BASE, vmcs12->host_idtr_base);	vmcs_writel(GUEST_GDTR_BASE, vmcs12->host_gdtr_base);	 	if (vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS)		vmcs_write64(GUEST_BNDCFGS, 0);	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT) {		vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat);		vcpu->arch.pat = vmcs12->host_ia32_pat;	}	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)		vmcs_write64(GUEST_IA32_PERF_GLOBAL_CTRL,			vmcs12->host_ia32_perf_global_ctrl);	 	seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.selector = vmcs12->host_cs_selector,		.type = 11,		.present = 1,		.s = 1,		.g = 1	};	if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		seg.l = 1;	else		seg.db = 1;	vmx_set_segment(vcpu, &seg, VCPU_SREG_CS);	seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.type = 3,		.present = 1,		.s = 1,		.db = 1,		.g = 1	};	seg.selector = vmcs12->host_ds_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_DS);	seg.selector = vmcs12->host_es_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_ES);	seg.selector = vmcs12->host_ss_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_SS);	seg.selector = vmcs12->host_fs_selector;	seg.base = vmcs12->host_fs_base;	vmx_set_segment(vcpu, &seg, VCPU_SREG_FS);	seg.selector = vmcs12->host_gs_selector;	seg.base = vmcs12->host_gs_base;	vmx_set_segment(vcpu, &seg, VCPU_SREG_GS);	seg = (struct kvm_segment) {		.base = vmcs12->host_tr_base,		.limit = 0x67,		.selector = vmcs12->host_tr_selector,		.type = 11,		.present = 1	};	vmx_set_segment(vcpu, &seg, VCPU_SREG_TR);	kvm_set_dr(vcpu, 7, 0x400);	vmcs_write64(GUEST_IA32_DEBUGCTL, 0);	if (cpu_has_vmx_msr_bitmap())		vmx_set_msr_bitmap(vcpu);	if (nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,				vmcs12->vm_exit_msr_load_count))		nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL);}",13346
61,72,CVE-2012-4467,23,"int kernel_getpeername(struct socket *sock, struct sockaddr *addr,			 int *addrlen){	return sock->ops->getname(sock, addr, addrlen, 1);}",2740
284,103,CVE-2012-2390,23,"static void decrement_hugepage_resv_vma(struct hstate *h,			struct vm_area_struct *vma){	if (vma->vm_flags & VM_NORESERVE)		return;	if (vma->vm_flags & VM_MAYSHARE) {		 		h->resv_huge_pages--;	} else if (is_vma_resv_set(vma, HPAGE_RESV_OWNER)) {		 		h->resv_huge_pages--;	}}",3175
503,2634,CVE-2015-7540,23," int asn1_write_BOOLEAN(struct asn1_data *data, int v) {       asn1_push_tag(data, ASN1_BOOLEAN);       asn1_write_uint8(data, v ? 0xFF : 0);       asn1_pop_tag(data);       return !data->has_error; }",30869
313,2595,CVE-2013-2870,23,  void CompleteConnection(int result) {    connection_callback_.Run(result);  },29403
401,201,CVE-2012-1601,23,int kvm_arch_vcpu_runnable(struct kvm_vcpu *vcpu){	return (vcpu->arch.mp_state == KVM_MP_STATE_RUNNABLE) ||		(kvm_highest_pending_irq(vcpu) != -1);},3679
485,2111,CVE-2012-6638,23,static int tcp_skb_seglen(const struct sk_buff *skb){	return tcp_skb_pcount(skb) == 1 ? skb->len : tcp_skb_mss(skb);},12745
588,668,CVE-2011-2918,23,"static inline unsigned int fps_regval(struct fpustate *f,				      unsigned int insn_regnum){	return f->regs[insn_regnum];}",6060
645,261,CVE-2012-1601,23,"void kvm_arch_async_page_present(struct kvm_vcpu *vcpu,				 struct kvm_async_pf *work){	struct x86_exception fault;	trace_kvm_async_pf_ready(work->arch.token, work->gva);	if (is_error_page(work->page))		work->arch.token = ~0;  	else		kvm_del_async_pf_gfn(vcpu, work->arch.gfn);	if ((vcpu->arch.apf.msr_val & KVM_ASYNC_PF_ENABLED) &&	    !apf_put_user(vcpu, KVM_PV_REASON_PAGE_READY)) {		fault.vector = PF_VECTOR;		fault.error_code_valid = true;		fault.error_code = 0;		fault.nested_page_fault = false;		fault.address = work->arch.token;		kvm_inject_page_fault(vcpu, &fault);	}	vcpu->arch.apf.halted = false;}",3739
523,996,CVE-2011-2918,23,"static void put_prev_task(struct rq *rq, struct task_struct *prev){	if (prev->on_rq || rq->skip_clock_update < 0)		update_rq_clock(rq);	prev->sched_class->put_prev_task(rq, prev);}",6388
598,145,CVE-2012-2133,23,static void huge_pagevec_release(struct pagevec *pvec){	int i;	for (i = 0; i < pagevec_count(pvec); ++i)		put_page(pvec->pages[i]);	pagevec_reinit(pvec);},3489
475,1607,CVE-2011-2491,23,static inline void rpc_task_set_debuginfo(struct rpc_task *task){},10226
92,511,CVE-2011-2918,23,static void mipspmu_enable(struct pmu *pmu){	if (mipspmu)		mipspmu->start();},5903
287,1135,CVE-2013-4162,23,"void udp_v6_clear_sk(struct sock *sk, int size){	struct inet_sock *inet = inet_sk(sk);	 	sk_prot_clear_portaddr_nulls(sk, offsetof(struct inet_sock, pinet6));	size -= offsetof(struct inet_sock, pinet6) + sizeof(inet->pinet6);	memset(&inet->pinet6 + 1, 0, size);}",7960
589,1990,CVE-2014-1446,23,"static int yam_set_mac_address(struct net_device *dev, void *addr){	struct sockaddr *sa = (struct sockaddr *) addr;	 	memcpy(dev->dev_addr, sa->sa_data, dev->addr_len);	return 0;}",12028
479,810,CVE-2011-2918,23,"static void cpu_clock_event_stop(struct perf_event *event, int flags){	perf_swevent_cancel_hrtimer(event);	cpu_clock_event_update(event);}",6202
179,1022,CVE-2011-2918,23,"static int is_softlockup(unsigned long touch_ts){	unsigned long now = get_timestamp(smp_processor_id());	 	if (time_after(now, touch_ts + get_softlockup_thresh()))		return now - touch_ts;	return 0;}",6414
425,1764,CVE-2014-6410,23,"int udf_add_aext(struct inode *inode, struct extent_position *epos,		 struct kernel_lb_addr *eloc, int elen, int inc){	int adsize;	struct short_ad *sad = NULL;	struct long_ad *lad = NULL;	struct allocExtDesc *aed;	int *ptr;	struct udf_inode_info *iinfo = UDF_I(inode);	if (!epos->bh)		ptr = iinfo->i_ext.i_data + epos->offset -			udf_file_entry_alloc_offset(inode) +			iinfo->i_lenEAttr;	else		ptr = epos->bh->b_data + epos->offset;	if (iinfo->i_alloc_type == ICBTAG_FLAG_AD_SHORT)		adsize = sizeof(struct short_ad);	else if (iinfo->i_alloc_type == ICBTAG_FLAG_AD_LONG)		adsize = sizeof(struct long_ad);	else		return -EIO;	if (epos->offset + (2 * adsize) > inode->i_sb->s_blocksize) {		unsigned char *sptr, *dptr;		struct buffer_head *nbh;		int err, loffset;		struct kernel_lb_addr obloc = epos->block;		epos->block.logicalBlockNum = udf_new_block(inode->i_sb, NULL,						obloc.partitionReferenceNum,						obloc.logicalBlockNum, &err);		if (!epos->block.logicalBlockNum)			return -ENOSPC;		nbh = udf_tgetblk(inode->i_sb, udf_get_lb_pblock(inode->i_sb,								 &epos->block,								 0));		if (!nbh)			return -EIO;		lock_buffer(nbh);		memset(nbh->b_data, 0x00, inode->i_sb->s_blocksize);		set_buffer_uptodate(nbh);		unlock_buffer(nbh);		mark_buffer_dirty_inode(nbh, inode);		aed = (struct allocExtDesc *)(nbh->b_data);		if (!UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_STRICT))			aed->previousAllocExtLocation =					cpu_to_le32(obloc.logicalBlockNum);		if (epos->offset + adsize > inode->i_sb->s_blocksize) {			loffset = epos->offset;			aed->lengthAllocDescs = cpu_to_le32(adsize);			sptr = ptr - adsize;			dptr = nbh->b_data + sizeof(struct allocExtDesc);			memcpy(dptr, sptr, adsize);			epos->offset = sizeof(struct allocExtDesc) + adsize;		} else {			loffset = epos->offset + adsize;			aed->lengthAllocDescs = cpu_to_le32(0);			sptr = ptr;			epos->offset = sizeof(struct allocExtDesc);			if (epos->bh) {				aed = (struct allocExtDesc *)epos->bh->b_data;				le32_add_cpu(&aed->lengthAllocDescs, adsize);			} else {				iinfo->i_lenAlloc += adsize;				mark_inode_dirty(inode);			}		}		if (UDF_SB(inode->i_sb)->s_udfrev >= 0x0200)			udf_new_tag(nbh->b_data, TAG_IDENT_AED, 3, 1,				    epos->block.logicalBlockNum, sizeof(struct tag));		else			udf_new_tag(nbh->b_data, TAG_IDENT_AED, 2, 1,				    epos->block.logicalBlockNum, sizeof(struct tag));		switch (iinfo->i_alloc_type) {		case ICBTAG_FLAG_AD_SHORT:			sad = (struct short_ad *)sptr;			sad->extLength = cpu_to_le32(EXT_NEXT_EXTENT_ALLOCDECS |						     inode->i_sb->s_blocksize);			sad->extPosition =				cpu_to_le32(epos->block.logicalBlockNum);			break;		case ICBTAG_FLAG_AD_LONG:			lad = (struct long_ad *)sptr;			lad->extLength = cpu_to_le32(EXT_NEXT_EXTENT_ALLOCDECS |						     inode->i_sb->s_blocksize);			lad->extLocation = cpu_to_lelb(epos->block);			memset(lad->impUse, 0x00, sizeof(lad->impUse));			break;		}		if (epos->bh) {			if (!UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_STRICT) ||			    UDF_SB(inode->i_sb)->s_udfrev >= 0x0201)				udf_update_tag(epos->bh->b_data, loffset);			else				udf_update_tag(epos->bh->b_data,						sizeof(struct allocExtDesc));			mark_buffer_dirty_inode(epos->bh, inode);			brelse(epos->bh);		} else {			mark_inode_dirty(inode);		}		epos->bh = nbh;	}	udf_write_aext(inode, epos, eloc, elen, inc);	if (!epos->bh) {		iinfo->i_lenAlloc += adsize;		mark_inode_dirty(inode);	} else {		aed = (struct allocExtDesc *)epos->bh->b_data;		le32_add_cpu(&aed->lengthAllocDescs, adsize);		if (!UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_STRICT) ||				UDF_SB(inode->i_sb)->s_udfrev >= 0x0201)			udf_update_tag(epos->bh->b_data,					epos->offset + (inc ? 0 : adsize));		else			udf_update_tag(epos->bh->b_data,					sizeof(struct allocExtDesc));		mark_buffer_dirty_inode(epos->bh, inode);	}	return 0;}",10588
394,2381,CVE-2016-2847,23,"static char *pipefs_dname(struct dentry *dentry, char *buffer, int buflen){	return dynamic_dname(dentry, buffer, buflen, ""pipe:[%lu]"",				d_inode(dentry)->i_ino);}",17475
327,1762,CVE-2014-6418,23,"static void remove_ticket_handler(struct ceph_auth_client *ac,				  struct ceph_x_ticket_handler *th){	struct ceph_x_info *xi = ac->private;	dout(""remove_ticket_handler %p %d\n"", th, th->service);	rb_erase(&th->node, &xi->ticket_handlers);	ceph_crypto_key_destroy(&th->session_key);	if (th->ticket_blob)		ceph_buffer_put(th->ticket_blob);	kfree(th);}",10586
294,1504,CVE-2011-4087,23,"void br_netfilter_rtable_init(struct net_bridge *br){	struct rtable *rt = &br->fake_rtable;	atomic_set(&rt->dst.__refcnt, 1);	rt->dst.dev = br->dev;	rt->dst.path = &rt->dst;	dst_metric_set(&rt->dst, RTAX_MTU, 1500);	rt->dst.flags	= DST_NOXFRM;	rt->dst.ops = &fake_dst_ops;}",10070
454,612,CVE-2011-2918,23,static int fault_in_kernel_space(unsigned long address){	return address >= TASK_SIZE;},6004
82,656,CVE-2011-2918,23,"static inline int decode_access_size(struct pt_regs *regs, unsigned int insn){	unsigned int tmp;	tmp = ((insn >> 19) & 0xf);	if (tmp == 11 || tmp == 14)  		return 8;	tmp &= 3;	if (!tmp)		return 4;	else if (tmp == 3)		return 16;	 	else if (tmp == 2)		return 2;	else {		printk(""Impossible unaligned trap. insn=%08x\n"", insn);		die_if_kernel(""Byte sized unaligned access?!?!"", regs);		 		return 0;	}}",6048
55,1609,CVE-2011-2491,23,"void rpc_wake_up_queued_task(struct rpc_wait_queue *queue, struct rpc_task *task){	spin_lock_bh(&queue->lock);	rpc_wake_up_task_queue_locked(queue, task);	spin_unlock_bh(&queue->lock);}",10228
17,1036,CVE-2011-0716,23,"static void __br_multicast_send_query(struct net_bridge *br,				      struct net_bridge_port *port,				      struct br_ip *ip){	struct sk_buff *skb;	skb = br_multicast_alloc_query(br, ip);	if (!skb)		return;	if (port) {		__skb_push(skb, sizeof(struct ethhdr));		skb->dev = port->dev;		NF_HOOK(NFPROTO_BRIDGE, NF_BR_LOCAL_OUT, skb, NULL, skb->dev,			dev_queue_xmit);	} else		netif_rx(skb);}",6974
378,137,CVE-2012-2390,23,static inline struct hugepage_subpool *subpool_vma(struct vm_area_struct *vma){	return subpool_inode(vma->vm_file->f_dentry->d_inode);},3209
197,1737,CVE-2014-7145,23,"copy_fs_info_to_kstatfs(struct smb2_fs_full_size_info *pfs_inf,			struct kstatfs *kst){	kst->f_bsize = le32_to_cpu(pfs_inf->BytesPerSector) *			  le32_to_cpu(pfs_inf->SectorsPerAllocationUnit);	kst->f_blocks = le64_to_cpu(pfs_inf->TotalAllocationUnits);	kst->f_bfree  = le64_to_cpu(pfs_inf->ActualAvailableAllocationUnits);	kst->f_bavail = le64_to_cpu(pfs_inf->CallerAvailableAllocationUnits);	return;}",10561
182,982,CVE-2011-2918,23,static inline void irq_time_write_begin(void){	__this_cpu_inc(irq_time_seq.sequence);	smp_wmb();},6374
466,2125,CVE-2015-8104,23,"static int ac_interception(struct vcpu_svm *svm){	kvm_queue_exception_e(&svm->vcpu, AC_VECTOR, 0);	return 1;}",13015
159,114,CVE-2012-2390,23,static void hugetlb_register_all_nodes(void) { },3186
493,1796,CVE-2014-3690,23,"static int code_segment_valid(struct kvm_vcpu *vcpu){	struct kvm_segment cs;	unsigned int cs_rpl;	vmx_get_segment(vcpu, &cs, VCPU_SREG_CS);	cs_rpl = cs.selector & SELECTOR_RPL_MASK;	if (cs.unusable)		return false;	if (~cs.type & (AR_TYPE_CODE_MASK|AR_TYPE_ACCESSES_MASK))		return false;	if (!cs.s)		return false;	if (cs.type & AR_TYPE_WRITEABLE_MASK) {		if (cs.dpl > cs_rpl)			return false;	} else {		if (cs.dpl != cs_rpl)			return false;	}	if (!cs.present)		return false;	 	return true;}",10984
498,2239,CVE-2015-5307,23,"static inline int nested_vmx_merge_msr_bitmap(struct kvm_vcpu *vcpu,					       struct vmcs12 *vmcs12){	int msr;	struct page *page;	unsigned long *msr_bitmap;	if (!nested_cpu_has_virt_x2apic_mode(vmcs12))		return false;	page = nested_get_page(vcpu, vmcs12->msr_bitmap);	if (!page) {		WARN_ON(1);		return false;	}	msr_bitmap = (unsigned long *)kmap(page);	if (!msr_bitmap) {		nested_release_page_clean(page);		WARN_ON(1);		return false;	}	if (nested_cpu_has_virt_x2apic_mode(vmcs12)) {		if (nested_cpu_has_apic_reg_virt(vmcs12))			for (msr = 0x800; msr <= 0x8ff; msr++)				nested_vmx_disable_intercept_for_msr(					msr_bitmap,					vmx_msr_bitmap_nested,					msr, MSR_TYPE_R);		 		nested_vmx_disable_intercept_for_msr(msr_bitmap,				vmx_msr_bitmap_nested,				APIC_BASE_MSR + (APIC_TASKPRI >> 4),				MSR_TYPE_R | MSR_TYPE_W);		if (nested_cpu_has_vid(vmcs12)) {			 			nested_vmx_disable_intercept_for_msr(				msr_bitmap,				vmx_msr_bitmap_nested,				APIC_BASE_MSR + (APIC_EOI >> 4),				MSR_TYPE_W);			nested_vmx_disable_intercept_for_msr(				msr_bitmap,				vmx_msr_bitmap_nested,				APIC_BASE_MSR + (APIC_SELF_IPI >> 4),				MSR_TYPE_W);		}	} else {		 		for (msr = 0x800; msr <= 0x8ff; msr++)			__vmx_enable_intercept_for_msr(				vmx_msr_bitmap_nested,				msr,				MSR_TYPE_R);		__vmx_enable_intercept_for_msr(				vmx_msr_bitmap_nested,				APIC_BASE_MSR + (APIC_TASKPRI >> 4),				MSR_TYPE_W);		__vmx_enable_intercept_for_msr(				vmx_msr_bitmap_nested,				APIC_BASE_MSR + (APIC_EOI >> 4),				MSR_TYPE_W);		__vmx_enable_intercept_for_msr(				vmx_msr_bitmap_nested,				APIC_BASE_MSR + (APIC_SELF_IPI >> 4),				MSR_TYPE_W);	}	kunmap(page);	nested_release_page_clean(page);	return true;}",13361
42,1440,CVE-2013-1767,23,static struct dentry *shmem_get_parent(struct dentry *child){	return ERR_PTR(-ESTALE);},9639
527,166,CVE-2012-1601,23,"static int handle_pal_call(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run){	struct exit_ctl_data *p;	p = kvm_get_exit_data(vcpu);	if (p->exit_reason == EXIT_REASON_PAL_CALL)		return kvm_pal_emul(vcpu, kvm_run);	else {		kvm_run->exit_reason = KVM_EXIT_UNKNOWN;		kvm_run->hw.hardware_exit_reason = 2;		return 0;	}}",3644
216,1046,CVE-2011-0716,23,static void br_multicast_group_query_expired(unsigned long data){	struct net_bridge_mdb_entry *mp = (void *)data;	struct net_bridge *br = mp->br;	spin_lock(&br->multicast_lock);	if (!netif_running(br->dev) || hlist_unhashed(&mp->mglist) ||	    mp->queries_sent >= br->multicast_last_member_count)		goto out;	br_multicast_send_group_query(mp);out:	spin_unlock(&br->multicast_lock);},6984
277,2547,CVE-2012-2888,23,  SyncMessageStatusReceiver() {},29179
33,2265,CVE-2015-5307,23,"static int vmx_pre_block(struct kvm_vcpu *vcpu){	unsigned long flags;	unsigned int dest;	struct pi_desc old, new;	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);	if (!kvm_arch_has_assigned_device(vcpu->kvm) ||		!irq_remapping_cap(IRQ_POSTING_CAP))		return 0;	vcpu->pre_pcpu = vcpu->cpu;	spin_lock_irqsave(&per_cpu(blocked_vcpu_on_cpu_lock,			  vcpu->pre_pcpu), flags);	list_add_tail(&vcpu->blocked_vcpu_list,		      &per_cpu(blocked_vcpu_on_cpu,		      vcpu->pre_pcpu));	spin_unlock_irqrestore(&per_cpu(blocked_vcpu_on_cpu_lock,			       vcpu->pre_pcpu), flags);	do {		old.control = new.control = pi_desc->control;		 		if (pi_test_on(pi_desc) == 1) {			spin_lock_irqsave(&per_cpu(blocked_vcpu_on_cpu_lock,					  vcpu->pre_pcpu), flags);			list_del(&vcpu->blocked_vcpu_list);			spin_unlock_irqrestore(					&per_cpu(blocked_vcpu_on_cpu_lock,					vcpu->pre_pcpu), flags);			vcpu->pre_pcpu = -1;			return 1;		}		WARN((pi_desc->sn == 1),		     ""Warning: SN field of posted-interrupts ""		     ""is set before blocking\n"");		 		dest = cpu_physical_id(vcpu->pre_pcpu);		if (x2apic_enabled())			new.ndst = dest;		else			new.ndst = (dest << 8) & 0xFF00;		 		new.nv = POSTED_INTR_WAKEUP_VECTOR;	} while (cmpxchg(&pi_desc->control, old.control,			new.control) != old.control);	return 0;}",13387
113,2590,CVE-2013-2910,23,"  void ClickResetButton() {    ASSERT_TRUE(JSExecuted(""$('reset-button').click();""));  }",29379
484,570,CVE-2011-2918,23,"void *set_exception_table_vec(unsigned int vec, void *handler){	extern void *exception_handling_table[];	void *old_handler;	old_handler = exception_handling_table[vec];	exception_handling_table[vec] = handler;	return old_handler;}",5962
165,2428,CVE-2015-8877,23,static double filter_quadratic(const double x1){	const double x = x1 < 0.0 ? -x1 : x1;	if (x <= 0.5) return (- 2.0 * x * x + 1);	if (x <= 1.5) return (x * x - 2.5* x + 1.5);	return 0.0;},18459
487,643,CVE-2011-2918,23,"static inline int decode_access_size(unsigned int insn){	insn = (insn >> 19) & 3;	if(!insn)		return 4;	else if(insn == 3)		return 8;	else if(insn == 2)		return 2;	else {		printk(""Impossible unaligned trap. insn=%08x\n"", insn);		die_if_kernel(""Byte sized unaligned access?!?!"", current->thread.kregs);		return 4;  	}}",6035
441,504,CVE-2011-2918,23,"static inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr){	int ret = 0;	if (!user_mode(regs)) {		 		preempt_disable();		if (kprobe_running() && kprobe_fault_handler(regs, fsr))			ret = 1;		preempt_enable();	}	return ret;}",5896
595,1498,CVE-2013-0217,23,int xen_netbk_must_stop_queue(struct xenvif *vif){	if (!xen_netbk_rx_ring_full(vif))		return 0;	vif->rx.sring->req_event = vif->rx_req_cons_peek +		max_required_rx_slots(vif);	mb();  	return xen_netbk_rx_ring_full(vif);},9795
643,1325,CVE-2013-2017,23,"static inline struct sk_buff *handle_ing(struct sk_buff *skb,					 struct packet_type **pt_prev,					 int *ret, struct net_device *orig_dev){	if (skb->dev->rx_queue.qdisc == &noop_qdisc)		goto out;	if (*pt_prev) {		*ret = deliver_skb(skb, *pt_prev, orig_dev);		*pt_prev = NULL;	} else {		 		skb->tc_verd = SET_TC_OK2MUNGE(skb->tc_verd);	}	switch (ing_filter(skb)) {	case TC_ACT_SHOT:	case TC_ACT_STOLEN:		kfree_skb(skb);		return NULL;	}out:	skb->tc_verd = 0;	return skb;}",9034
307,1688,CVE-2014-8117,23,"file_reset(struct magic_set *ms){	if (ms->mlist[0] == NULL) {		file_error(ms, 0, ""no magic files loaded"");		return -1;	}	if (ms->o.buf) {		free(ms->o.buf);		ms->o.buf = NULL;	}	if (ms->o.pbuf) {		free(ms->o.pbuf);		ms->o.pbuf = NULL;	}	ms->event_flags &= ~EVENT_HAD_ERR;	ms->error = -1;	return 0;}",10466
627,1587,CVE-2011-2491,23,void rpc_destroy_wait_queue(struct rpc_wait_queue *queue){	del_timer_sync(&queue->timer_list.timer);},10206
402,1761,CVE-2014-6418,23,"static void ceph_x_validate_tickets(struct ceph_auth_client *ac, int *pneed){	int want = ac->want_keys;	struct ceph_x_info *xi = ac->private;	int service;	*pneed = ac->want_keys & ~(xi->have_keys);	for (service = 1; service <= want; service <<= 1) {		struct ceph_x_ticket_handler *th;		if (!(ac->want_keys & service))			continue;		if (*pneed & service)			continue;		th = get_ticket_handler(ac, service);		if (IS_ERR(th)) {			*pneed |= service;			continue;		}		if (get_seconds() >= th->renew_after)			*pneed |= service;		if (get_seconds() >= th->expires)			xi->have_keys &= ~service;	}}",10585
256,1240,CVE-2013-2141,23,"static int recalc_sigpending_tsk(struct task_struct *t){	if ((t->jobctl & JOBCTL_PENDING_MASK) ||	    PENDING(&t->pending, &t->blocked) ||	    PENDING(&t->signal->shared_pending, &t->blocked)) {		set_tsk_thread_flag(t, TIF_SIGPENDING);		return 1;	}	 	return 0;}",8846
94,745,CVE-2011-2918,23,"static void p4_hw_watchdog_set_attr(struct perf_event_attr *wd_attr){	 	WARN_ON_ONCE(wd_attr->type	!= PERF_TYPE_HARDWARE ||		     wd_attr->config	!= PERF_COUNT_HW_CPU_CYCLES);	wd_attr->type	= PERF_TYPE_RAW;	wd_attr->config	=		p4_config_pack_escr(P4_ESCR_EVENT(P4_EVENT_EXECUTION_EVENT)		|			P4_ESCR_EMASK_BIT(P4_EVENT_EXECUTION_EVENT, NBOGUS0)		|			P4_ESCR_EMASK_BIT(P4_EVENT_EXECUTION_EVENT, NBOGUS1)		|			P4_ESCR_EMASK_BIT(P4_EVENT_EXECUTION_EVENT, NBOGUS2)		|			P4_ESCR_EMASK_BIT(P4_EVENT_EXECUTION_EVENT, NBOGUS3)		|			P4_ESCR_EMASK_BIT(P4_EVENT_EXECUTION_EVENT, BOGUS0)		|			P4_ESCR_EMASK_BIT(P4_EVENT_EXECUTION_EVENT, BOGUS1)		|			P4_ESCR_EMASK_BIT(P4_EVENT_EXECUTION_EVENT, BOGUS2)		|			P4_ESCR_EMASK_BIT(P4_EVENT_EXECUTION_EVENT, BOGUS3))		|		p4_config_pack_cccr(P4_CCCR_THRESHOLD(15) | P4_CCCR_COMPLEMENT		|			P4_CCCR_COMPARE);}",6137
176,1316,CVE-2013-2017,23,void dev_set_rx_mode(struct net_device *dev){	netif_addr_lock_bh(dev);	__dev_set_rx_mode(dev);	netif_addr_unlock_bh(dev);},9025
532,1873,CVE-2014-3690,23,"static void loaded_vmcs_clear(struct loaded_vmcs *loaded_vmcs){	int cpu = loaded_vmcs->cpu;	if (cpu != -1)		smp_call_function_single(cpu,			 __loaded_vmcs_clear, loaded_vmcs, 1);}",11061
64,435,CVE-2011-2918,23,"static int alpha_check_constraints(struct perf_event **events,				   unsigned long *evtypes, int n_ev){	 	if (n_ev == 0)		return 0;	if (n_ev > alpha_pmu->num_pmcs)		return -1;	return alpha_pmu->check_constraints(events, evtypes, n_ev);}",5827
661,807,CVE-2011-2918,23,static int cpu_clock_event_init(struct perf_event *event){	if (event->attr.type != PERF_TYPE_SOFTWARE)		return -ENOENT;	if (event->attr.config != PERF_COUNT_SW_CPU_CLOCK)		return -ENOENT;	perf_swevent_init_hrtimer(event);	return 0;},6199
415,248,CVE-2012-1601,23,"int emulator_write_emulated(struct x86_emulate_ctxt *ctxt,			    unsigned long addr,			    const void *val,			    unsigned int bytes,			    struct x86_exception *exception){	return emulator_read_write(ctxt, addr, (void *)val, bytes,				   exception, &write_emultor);}",3726
531,456,CVE-2011-2918,23,"armv6pmu_get_event_idx(struct cpu_hw_events *cpuc,		       struct hw_perf_event *event){	 	if (ARMV6_PERFCTR_CPU_CYCLES == event->config_base) {		if (test_and_set_bit(ARMV6_CYCLE_COUNTER, cpuc->used_mask))			return -EAGAIN;		return ARMV6_CYCLE_COUNTER;	} else {		 		if (!test_and_set_bit(ARMV6_COUNTER1, cpuc->used_mask))			return ARMV6_COUNTER1;		if (!test_and_set_bit(ARMV6_COUNTER0, cpuc->used_mask))			return ARMV6_COUNTER0;		 		return -EAGAIN;	}}",5848
553,2044,CVE-2012-6638,23,static inline void TCP_ECN_queue_cwr(struct tcp_sock *tp){	if (tp->ecn_flags & TCP_ECN_OK)		tp->ecn_flags |= TCP_ECN_QUEUE_CWR;},12678
206,1053,CVE-2011-0716,23,"static void br_multicast_port_query_expired(unsigned long data){	struct net_bridge_port *port = (void *)data;	struct net_bridge *br = port->br;	spin_lock(&br->multicast_lock);	if (port->state == BR_STATE_DISABLED ||	    port->state == BR_STATE_BLOCKING)		goto out;	if (port->multicast_startup_queries_sent <	    br->multicast_startup_query_count)		port->multicast_startup_queries_sent++;	br_multicast_send_query(port->br, port,				port->multicast_startup_queries_sent);out:	spin_unlock(&br->multicast_lock);}",6991
375,844,CVE-2011-2918,23,"static void perf_ctx_lock(struct perf_cpu_context *cpuctx,			  struct perf_event_context *ctx){	raw_spin_lock(&cpuctx->ctx.lock);	if (ctx)		raw_spin_lock(&ctx->lock);}",6236
637,1491,CVE-2013-0217,23,void xen_netbk_add_xenvif(struct xenvif *vif){	int i;	int min_netfront_count;	int min_group = 0;	struct xen_netbk *netbk;	min_netfront_count = atomic_read(&xen_netbk[0].netfront_count);	for (i = 0; i < xen_netbk_group_nr; i++) {		int netfront_count = atomic_read(&xen_netbk[i].netfront_count);		if (netfront_count < min_netfront_count) {			min_group = i;			min_netfront_count = netfront_count;		}	}	netbk = &xen_netbk[min_group];	vif->netbk = netbk;	atomic_inc(&netbk->netfront_count);},9788
362,2688,CVE-2013-2017,23,"int dev_forward_skb(struct net_device *dev, struct sk_buff *skb) { 	skb_orphan(skb); 	if (!(dev->flags & IFF_UP))		return NET_RX_DROP;	if (skb->len > (dev->mtu + dev->hard_header_len)) 		return NET_RX_DROP; 	skb_set_dev(skb, dev); 	skb->tstamp.tv64 = 0; 	skb->pkt_type = PACKET_HOST;	skb->protocol = eth_type_trans(skb, dev);	return netif_rx(skb);}",31081
510,2201,CVE-2015-5307,23,"static int allocate_vpid(void){	int vpid;	if (!enable_vpid)		return 0;	spin_lock(&vmx_vpid_lock);	vpid = find_first_zero_bit(vmx_vpid_bitmap, VMX_NR_VPIDS);	if (vpid < VMX_NR_VPIDS)		__set_bit(vpid, vmx_vpid_bitmap);	else		vpid = 0;	spin_unlock(&vmx_vpid_lock);	return vpid;}",13323
546,542,CVE-2011-2918,23,"int ptrace_put_reg(struct task_struct *task, int regno, unsigned long data){	if (task->thread.regs == NULL)		return -EIO;	if (regno == PT_MSR)		return set_user_msr(task, data);	if (regno == PT_TRAP)		return set_user_trap(task, data);	if (regno <= PT_MAX_PUT_REG) {		((unsigned long *)task->thread.regs)[regno] = data;		return 0;	}	return -EIO;}",5934
398,2491,CVE-2019-15921,23,static int genl_lock_done(struct netlink_callback *cb){	 	const struct genl_ops *ops = cb->data;	int rc = 0;	if (ops->done) {		genl_lock();		rc = ops->done(cb);		genl_unlock();	}	return rc;},26564
44,374,CVE-2012-0207,23,"static struct sk_buff *add_grhead(struct sk_buff *skb, struct ip_mc_list *pmc,	int type, struct igmpv3_grec **ppgr){	struct net_device *dev = pmc->interface->dev;	struct igmpv3_report *pih;	struct igmpv3_grec *pgr;	if (!skb)		skb = igmpv3_newpack(dev, dev->mtu);	if (!skb)		return NULL;	pgr = (struct igmpv3_grec *)skb_put(skb, sizeof(struct igmpv3_grec));	pgr->grec_type = type;	pgr->grec_auxwords = 0;	pgr->grec_nsrcs = 0;	pgr->grec_mca = pmc->multiaddr;	pih = igmpv3_report_hdr(skb);	pih->ngrec = htons(ntohs(pih->ngrec)+1);	*ppgr = pgr;	return skb;}",4114
349,1576,CVE-2011-2491,23,"static int rpcproc_decode_null(void *rqstp, struct xdr_stream *xdr, void *obj){	return 0;}",10195
455,169,CVE-2012-1601,23,"static int handle_vcpu_debug(struct kvm_vcpu *vcpu,				struct kvm_run *kvm_run){	printk(""VMM: %s"", vcpu->arch.log_buf);	return 1;}",3647
653,624,CVE-2011-2918,23,"perf_callchain_user(struct perf_callchain_entry *entry, struct pt_regs *regs){	flushw_user();	if (test_thread_flag(TIF_32BIT))		perf_callchain_user_32(entry, regs);	else		perf_callchain_user_64(entry, regs);}",6016
587,1016,CVE-2011-2918,23,"static int ttwu_remote(struct task_struct *p, int wake_flags){	struct rq *rq;	int ret = 0;	rq = __task_rq_lock(p);	if (p->on_rq) {		ttwu_do_wakeup(rq, p, wake_flags);		ret = 1;	}	__task_rq_unlock(rq);	return ret;}",6408
97,2129,CVE-2015-8104,23,"static int interrupt_window_interception(struct vcpu_svm *svm){	kvm_make_request(KVM_REQ_EVENT, &svm->vcpu);	svm_clear_vintr(svm);	svm->vmcb->control.int_ctl &= ~V_IRQ_MASK;	mark_dirty(svm->vmcb, VMCB_INTR);	++svm->vcpu.stat.irq_window_exits;	return 1;}",13019
302,1154,CVE-2013-4127,23,"int vhost_net_set_ubuf_info(struct vhost_net *n){	int zcopy;	int i;	for (i = 0; i < VHOST_NET_VQ_MAX; ++i) {		zcopy = vhost_net_zcopy_mask & (0x1 << i);		if (!zcopy)			continue;		n->vqs[i].ubuf_info = kmalloc(sizeof(*n->vqs[i].ubuf_info) *					      UIO_MAXIOV, GFP_KERNEL);		if  (!n->vqs[i].ubuf_info)			goto err;	}	return 0;err:	vhost_net_clear_ubuf_info(n);	return -ENOMEM;}",7993
244,2001,CVE-2014-1444,23,"fst_close(struct net_device *dev){	struct fst_port_info *port;	struct fst_card_info *card;	unsigned char tx_dma_done;	unsigned char rx_dma_done;	port = dev_to_port(dev);	card = port->card;	tx_dma_done = inb(card->pci_conf + DMACSR1);	rx_dma_done = inb(card->pci_conf + DMACSR0);	dbg(DBG_OPEN,	    ""Port Close: tx_dma_in_progress = %d (%x) rx_dma_in_progress = %d (%x)\n"",	    card->dmatx_in_progress, tx_dma_done, card->dmarx_in_progress,	    rx_dma_done);	netif_stop_queue(dev);	fst_closeport(dev_to_port(dev));	if (port->mode != FST_RAW) {		hdlc_close(dev);	}	module_put(THIS_MODULE);	return 0;}",12039
626,1101,CVE-2013-4592,23,"void kvm_exit(void){	kvm_exit_debug();	misc_deregister(&kvm_dev);	kmem_cache_destroy(kvm_vcpu_cache);	kvm_async_pf_deinit();	unregister_syscore_ops(&kvm_syscore_ops);	unregister_reboot_notifier(&kvm_reboot_notifier);	unregister_cpu_notifier(&kvm_cpu_notifier);	on_each_cpu(hardware_disable_nolock, NULL, 1);	kvm_arch_hardware_unsetup();	kvm_arch_exit();	free_cpumask_var(cpus_hardware_enabled);}",7505
581,392,CVE-2012-0207,23,"static int igmpv3_sendpack(struct sk_buff *skb){	struct igmphdr *pig = igmp_hdr(skb);	const int igmplen = skb->tail - skb->transport_header;	pig->csum = ip_compute_csum(igmp_hdr(skb), igmplen);	return ip_local_out(skb);}",4132
442,2696,CVE-2011-2479,23,"int khugepaged_enter_vma_merge(struct vm_area_struct *vma){	unsigned long hstart, hend;	if (!vma->anon_vma)		  		return 0;	if (vma->vm_file || vma->vm_ops) 		  		return 0;	VM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma)); 	hstart = (vma->vm_start + ~HPAGE_PMD_MASK) & HPAGE_PMD_MASK; 	hend = vma->vm_end & HPAGE_PMD_MASK; 	if (hstart < hend)		return khugepaged_enter(vma);	return 0;}",31116
386,1784,CVE-2014-6410,23,"static int udf_writepage(struct page *page, struct writeback_control *wbc){	return block_write_full_page(page, udf_get_block, wbc);}",10608
211,1217,CVE-2013-2141,23,long do_no_restart_syscall(struct restart_block *param){	return -EINTR;},8823
557,381,CVE-2012-0207,23,"static struct ip_mc_list *igmp_mc_get_next(struct seq_file *seq, struct ip_mc_list *im){	struct igmp_mc_iter_state *state = igmp_mc_seq_private(seq);	im = rcu_dereference(im->next_rcu);	while (!im) {		state->dev = next_net_device_rcu(state->dev);		if (!state->dev) {			state->in_dev = NULL;			break;		}		state->in_dev = __in_dev_get_rcu(state->dev);		if (!state->in_dev)			continue;		im = rcu_dereference(state->in_dev->mc_list);	}	return im;}",4121
317,663,CVE-2011-2918,23,"static void bmask(struct pt_regs *regs, unsigned int insn){	unsigned long rs1, rs2, rd_val, gsr;	maybe_flush_windows(RS1(insn), RS2(insn), RD(insn), 0);	rs1 = fetch_reg(RS1(insn), regs);	rs2 = fetch_reg(RS2(insn), regs);	rd_val = rs1 + rs2;	store_reg(regs, rd_val, RD(insn));	gsr = current_thread_info()->gsr[0] & 0xffffffff;	gsr |= rd_val << 32UL;	current_thread_info()->gsr[0] = gsr;}",6055
238,78,CVE-2012-4467,23,"static struct inode *sock_alloc_inode(struct super_block *sb){	struct socket_alloc *ei;	struct socket_wq *wq;	ei = kmem_cache_alloc(sock_inode_cachep, GFP_KERNEL);	if (!ei)		return NULL;	wq = kmalloc(sizeof(*wq), GFP_KERNEL);	if (!wq) {		kmem_cache_free(sock_inode_cachep, ei);		return NULL;	}	init_waitqueue_head(&wq->wait);	wq->fasync_list = NULL;	RCU_INIT_POINTER(ei->socket.wq, wq);	ei->socket.state = SS_UNCONNECTED;	ei->socket.flags = 0;	ei->socket.ops = NULL;	ei->socket.sk = NULL;	ei->socket.file = NULL;	return &ei->vfs_inode;}",2746
591,295,CVE-2012-1601,23,"int kvm_fast_pio_out(struct kvm_vcpu *vcpu, int size, unsigned short port){	unsigned long val = kvm_register_read(vcpu, VCPU_REGS_RAX);	int ret = emulator_pio_out_emulated(&vcpu->arch.emulate_ctxt,					    size, port, &val, 1);	 	vcpu->arch.pio.count = 0;	return ret;}",3773
178,926,CVE-2011-2918,23,"static void swevent_hlist_put_cpu(struct perf_event *event, int cpu){	struct swevent_htable *swhash = &per_cpu(swevent_htable, cpu);	mutex_lock(&swhash->hlist_mutex);	if (!--swhash->hlist_refcount)		swevent_hlist_release(swhash);	mutex_unlock(&swhash->hlist_mutex);}",6318
282,524,CVE-2011-2918,23,static int regs_to_trapnr(struct pt_regs *regs){	return (regs->cp0_cause >> 2) & 0x1f;},5916
623,2148,CVE-2015-6526,23,"perf_callchain_kernel(struct perf_callchain_entry *entry, struct pt_regs *regs){	unsigned long sp, next_sp;	unsigned long next_ip;	unsigned long lr;	long level = 0;	unsigned long *fp;	lr = regs->link;	sp = regs->gpr[1];	perf_callchain_store(entry, perf_instruction_pointer(regs));	if (!validate_sp(sp, current, STACK_FRAME_OVERHEAD))		return;	for (;;) {		fp = (unsigned long *) sp;		next_sp = fp[0];		if (next_sp == sp + STACK_INT_FRAME_SIZE &&		    fp[STACK_FRAME_MARKER] == STACK_FRAME_REGS_MARKER) {			 			regs = (struct pt_regs *)(sp + STACK_FRAME_OVERHEAD);			next_ip = regs->nip;			lr = regs->link;			level = 0;			perf_callchain_store(entry, PERF_CONTEXT_KERNEL);		} else {			if (level == 0)				next_ip = lr;			else				next_ip = fp[STACK_FRAME_LR_SAVE];			 			if ((level == 1 && next_ip == lr) ||			    (level <= 1 && !kernel_text_address(next_ip)))				next_ip = 0;			++level;		}		perf_callchain_store(entry, next_ip);		if (!valid_next_sp(next_sp, sp))			return;		sp = next_sp;	}}",13120
109,1438,CVE-2013-1767,23,"static void *shmem_follow_short_symlink(struct dentry *dentry, struct nameidata *nd){	nd_set_link(nd, SHMEM_I(dentry->d_inode)->symlink);	return NULL;}",9637
620,1407,CVE-2013-1797,23,"static int emulator_fix_hypercall(struct x86_emulate_ctxt *ctxt){	struct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);	char instruction[3];	unsigned long rip = kvm_rip_read(vcpu);	 	kvm_mmu_zap_all(vcpu->kvm);	kvm_x86_ops->patch_hypercall(vcpu, instruction);	return emulator_write_emulated(ctxt, rip, instruction, 3, NULL);}",9506
118,2197,CVE-2015-5307,23,"static inline void __vmx_flush_tlb(struct kvm_vcpu *vcpu, int vpid){	vpid_sync_context(vpid);	if (enable_ept) {		if (!VALID_PAGE(vcpu->arch.mmu.root_hpa))			return;		ept_sync_context(construct_eptp(vcpu->arch.mmu.root_hpa));	}}",13319
184,1206,CVE-2013-2634,23,"int dcb_setapp(struct net_device *dev, struct dcb_app *new){	struct dcb_app_type *itr;	struct dcb_app_type event;	int err = 0;	event.ifindex = dev->ifindex;	memcpy(&event.app, new, sizeof(event.app));	if (dev->dcbnl_ops->getdcbx)		event.dcbx = dev->dcbnl_ops->getdcbx(dev);	spin_lock(&dcb_lock);	 	if ((itr = dcb_app_lookup(new, dev->ifindex, 0))) {		if (new->priority)			itr->app.priority = new->priority;		else {			list_del(&itr->list);			kfree(itr);		}		goto out;	}	 	if (new->priority)		err = dcb_app_add(new, dev->ifindex);out:	spin_unlock(&dcb_lock);	if (!err)		call_dcbevent_notifiers(DCB_APP_EVENT, &event);	return err;}",8544
389,476,CVE-2011-2918,23,"xscale2pmu_start(void){	unsigned long flags, val;	raw_spin_lock_irqsave(&pmu_lock, flags);	val = xscale2pmu_read_pmnc() & ~XSCALE_PMU_CNT64;	val |= XSCALE_PMU_ENABLE;	xscale2pmu_write_pmnc(val);	raw_spin_unlock_irqrestore(&pmu_lock, flags);}",5868
422,2341,CVE-2016-5350,23,printer_notify_hf_index(int field){	int result = -1;	switch(field) {	case PRINTER_NOTIFY_SERVER_NAME:		result = hf_servername;		break;	case PRINTER_NOTIFY_PRINTER_NAME:		result = hf_printername;		break;	case PRINTER_NOTIFY_SHARE_NAME:		result = hf_sharename;		break;	case PRINTER_NOTIFY_PORT_NAME:		result = hf_portname;		break;	case PRINTER_NOTIFY_DRIVER_NAME:		result = hf_drivername;		break;	case PRINTER_NOTIFY_COMMENT:		result = hf_printercomment;		break;	case PRINTER_NOTIFY_LOCATION:		result = hf_printerlocation;		break;	case PRINTER_NOTIFY_SEPFILE:		result = hf_sepfile;		break;	case PRINTER_NOTIFY_PRINT_PROCESSOR:		result = hf_printprocessor;		break;	case PRINTER_NOTIFY_PARAMETERS:		result = hf_parameters;		break;	case PRINTER_NOTIFY_DATATYPE:		result = hf_parameters;		break;	}	return result;},16481
585,1352,CVE-2013-2017,23,"void netdev_state_change(struct net_device *dev){	if (dev->flags & IFF_UP) {		call_netdevice_notifiers(NETDEV_CHANGE, dev);		rtmsg_ifinfo(RTM_NEWLINK, dev, 0);	}}",9061
175,243,CVE-2012-1601,23,"static int emulator_read_emulated(struct x86_emulate_ctxt *ctxt,				  unsigned long addr,				  void *val,				  unsigned int bytes,				  struct x86_exception *exception){	return emulator_read_write(ctxt, addr, val, bytes,				   exception, &read_emultor);}",3721
84,2277,CVE-2014-9621,23,"toomany(struct magic_set *ms, const char *name, int num){	if (file_printf(ms, "", too many %s (%u)"", name, num	    ) == -1)		return -1;	return 0;}",14450
107,438,CVE-2011-2918,23,"static void alpha_pmu_disable(struct pmu *pmu){	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	if (!cpuc->enabled)		return;	cpuc->enabled = 0;	cpuc->n_added = 0;	wrperfmon(PERFMON_CMD_DISABLE, cpuc->idx_mask);}",5830
344,2079,CVE-2012-6638,23,"static void tcp_grow_window(struct sock *sk, const struct sk_buff *skb){	struct tcp_sock *tp = tcp_sk(sk);	 	if (tp->rcv_ssthresh < tp->window_clamp &&	    (int)tp->rcv_ssthresh < tcp_space(sk) &&	    !tcp_memory_pressure) {		int incr;		 		if (tcp_win_from_space(skb->truesize) <= skb->len)			incr = 2 * tp->advmss;		else			incr = __tcp_grow_window(sk, skb);		if (incr) {			tp->rcv_ssthresh = min(tp->rcv_ssthresh + incr,					       tp->window_clamp);			inet_csk(sk)->icsk_ack.quick |= 1;		}	}}",12713
35,609,CVE-2011-2918,23,"static int fxchg(struct sh_fpu_soft_struct *fregs, int flag){	FPSCR ^= flag;	return 0;}",6001
449,510,CVE-2011-2918,23,static void mipspmu_disable(struct pmu *pmu){	if (mipspmu)		mipspmu->stop();},5902
0,1823,CVE-2014-3690,23,static inline int cpu_has_vmx_vpid(void){	return vmcs_config.cpu_based_2nd_exec_ctrl &		SECONDARY_EXEC_ENABLE_VPID;},11011
269,2576,CVE-2011-3053,23,"double LimitPercent(double percent) {  return min(max(percent, 0.0), 100.0);}",29345
495,685,CVE-2011-2918,23,"perf_event_nmi_handler(struct notifier_block *self,			 unsigned long cmd, void *__args){	struct die_args *args = __args;	unsigned int this_nmi;	int handled;	if (!atomic_read(&active_events))		return NOTIFY_DONE;	switch (cmd) {	case DIE_NMI:		break;	case DIE_NMIUNKNOWN:		this_nmi = percpu_read(irq_stat.__nmi_count);		if (this_nmi != __this_cpu_read(pmu_nmi.marked))			 			return NOTIFY_DONE;		 		return NOTIFY_STOP;	default:		return NOTIFY_DONE;	}	handled = x86_pmu.handle_irq(args->regs);	if (!handled)		return NOTIFY_DONE;	this_nmi = percpu_read(irq_stat.__nmi_count);	if ((handled > 1) ||		 	    ((__this_cpu_read(pmu_nmi.marked) == this_nmi) &&	     (__this_cpu_read(pmu_nmi.handled) > 1))) {		 		__this_cpu_write(pmu_nmi.marked, this_nmi + 1);		__this_cpu_write(pmu_nmi.handled, handled);	}	return NOTIFY_STOP;}",6077
420,12,CVE-2015-7540,23,"static int push_int_bigendian(struct asn1_data *data, unsigned int i, int negative){	int lowest = i & 0xFF;	i = i >> 8;	if (i != 0)		if (!push_int_bigendian(data, i, negative))			return false;	if (data->nesting->start+1 == data->ofs) {		 		if (negative) {			 			if (lowest == 0xFF)				return true;			if ((lowest & 0x80) == 0) {				 				if (!asn1_write_uint8(data, 0xff))					return false;			}		} else {			if (lowest & 0x80) {				 				if (!asn1_write_uint8(data, 0))					return false;			}		}	}	return asn1_write_uint8(data, lowest);}",212
54,17,CVE-2014-9718,23,"static void put_le16(int *p, unsigned int v){    *p = cpu_to_le16(v);}",1040
316,1794,CVE-2014-3690,23,"static void clear_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr){	unsigned i;	struct msr_autoload *m = &vmx->msr_autoload;	switch (msr) {	case MSR_EFER:		if (cpu_has_load_ia32_efer) {			clear_atomic_switch_msr_special(vmx,					VM_ENTRY_LOAD_IA32_EFER,					VM_EXIT_LOAD_IA32_EFER);			return;		}		break;	case MSR_CORE_PERF_GLOBAL_CTRL:		if (cpu_has_load_perf_global_ctrl) {			clear_atomic_switch_msr_special(vmx,					VM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL,					VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL);			return;		}		break;	}	for (i = 0; i < m->nr; ++i)		if (m->guest[i].index == msr)			break;	if (i == m->nr)		return;	--m->nr;	m->guest[i] = m->guest[m->nr];	m->host[i] = m->host[m->nr];	vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->nr);	vmcs_write32(VM_EXIT_MSR_LOAD_COUNT, m->nr);}",10982
154,1727,CVE-2014-7283,23,"xfs_da_compname(	struct xfs_da_args *args,	const unsigned char *name,	int		len){	return (args->namelen == len && memcmp(args->name, name, len) == 0) ?					XFS_CMP_EXACT : XFS_CMP_DIFFERENT;}",10551
660,204,CVE-2012-1601,23,"static void kvm_build_io_pmt(struct kvm *kvm){	unsigned long i, j;	 	for (i = 0; i < (sizeof(io_ranges) / sizeof(struct kvm_io_range));							i++) {		for (j = io_ranges[i].start;				j < io_ranges[i].start + io_ranges[i].size;				j += PAGE_SIZE)			kvm_set_pmt_entry(kvm, j >> PAGE_SHIFT,					io_ranges[i].type, 0);	}}",3682
250,1767,CVE-2014-6410,23,"int udf_current_aext(struct inode *inode, struct extent_position *epos,			struct kernel_lb_addr *eloc, int *elen, int inc){	int alen;	int etype;	int *ptr;	struct short_ad *sad;	struct long_ad *lad;	struct udf_inode_info *iinfo = UDF_I(inode);	if (!epos->bh) {		if (!epos->offset)			epos->offset = udf_file_entry_alloc_offset(inode);		ptr = iinfo->i_ext.i_data + epos->offset -			udf_file_entry_alloc_offset(inode) +			iinfo->i_lenEAttr;		alen = udf_file_entry_alloc_offset(inode) +							iinfo->i_lenAlloc;	} else {		if (!epos->offset)			epos->offset = sizeof(struct allocExtDesc);		ptr = epos->bh->b_data + epos->offset;		alen = sizeof(struct allocExtDesc) +			le32_to_cpu(((struct allocExtDesc *)epos->bh->b_data)->							lengthAllocDescs);	}	switch (iinfo->i_alloc_type) {	case ICBTAG_FLAG_AD_SHORT:		sad = udf_get_fileshortad(ptr, alen, &epos->offset, inc);		if (!sad)			return -1;		etype = le32_to_cpu(sad->extLength) >> 30;		eloc->logicalBlockNum = le32_to_cpu(sad->extPosition);		eloc->partitionReferenceNum =				iinfo->i_location.partitionReferenceNum;		*elen = le32_to_cpu(sad->extLength) & UDF_EXTENT_LENGTH_MASK;		break;	case ICBTAG_FLAG_AD_LONG:		lad = udf_get_filelongad(ptr, alen, &epos->offset, inc);		if (!lad)			return -1;		etype = le32_to_cpu(lad->extLength) >> 30;		*eloc = lelb_to_cpu(lad->extLocation);		*elen = le32_to_cpu(lad->extLength) & UDF_EXTENT_LENGTH_MASK;		break;	default:		udf_debug(""alloc_type = %d unsupported\n"", iinfo->i_alloc_type);		return -1;	}	return etype;}",10591
352,2622,CVE-2014-1700,23,  MockEventBlocker() {},29565
471,1845,CVE-2014-3690,23,static inline struct vmcs12 *get_vmcs12(struct kvm_vcpu *vcpu){	return to_vmx(vcpu)->nested.current_vmcs12;},11033
574,2295,CVE-2014-9620,23,magic_version(void){	return MAGIC_VERSION;},14468
359,391,CVE-2012-0207,23,"static void igmpv3_clear_zeros(struct ip_sf_list **ppsf){	struct ip_sf_list *psf_prev, *psf_next, *psf;	psf_prev = NULL;	for (psf=*ppsf; psf; psf = psf_next) {		psf_next = psf->sf_next;		if (psf->sf_crcount == 0) {			if (psf_prev)				psf_prev->sf_next = psf->sf_next;			else				*ppsf = psf->sf_next;			kfree(psf);		} else			psf_prev = psf;	}}",4131
648,687,CVE-2011-2918,23,unsigned long perf_instruction_pointer(struct pt_regs *regs){	unsigned long ip;	if (perf_guest_cbs && perf_guest_cbs->is_in_guest())		ip = perf_guest_cbs->get_guest_ip();	else		ip = instruction_pointer(regs);	return ip;},6079
651,676,CVE-2011-2918,23,"static unsigned int get_fault_insn(struct pt_regs *regs, unsigned int insn){	if (!insn) {		if (!regs->tpc || (regs->tpc & 0x3))			return 0;		if (regs->tstate & TSTATE_PRIV) {			insn = *(unsigned int *) regs->tpc;		} else {			insn = get_user_insn(regs->tpc);		}	}	return insn;}",6068
72,859,CVE-2011-2918,23,static void perf_event_free_filter(struct perf_event *event){},6251
124,1795,CVE-2014-3690,23,"static void clear_atomic_switch_msr_special(struct vcpu_vmx *vmx,		unsigned long entry, unsigned long exit){	vm_entry_controls_clearbit(vmx, entry);	vm_exit_controls_clearbit(vmx, exit);}",10983
655,24,CVE-2016-7421,23,pvscsi_register_types(void){    type_register_static(&pvscsi_info);},1323
388,1430,CVE-2013-1767,23,"static unsigned long shmem_default_max_inodes(void){	return min(totalram_pages - totalhigh_pages, totalram_pages / 2);}",9629
566,334,CVE-2012-1601,23,"static int kvm_vcpu_ioctl_x86_set_xcrs(struct kvm_vcpu *vcpu,				       struct kvm_xcrs *guest_xcrs){	int i, r = 0;	if (!cpu_has_xsave)		return -EINVAL;	if (guest_xcrs->nr_xcrs > KVM_MAX_XCRS || guest_xcrs->flags)		return -EINVAL;	for (i = 0; i < guest_xcrs->nr_xcrs; i++)		 		if (guest_xcrs->xcrs[0].xcr == XCR_XFEATURE_ENABLED_MASK) {			r = __kvm_set_xcr(vcpu, XCR_XFEATURE_ENABLED_MASK,				guest_xcrs->xcrs[0].value);			break;		}	if (r)		r = -EINVAL;	return r;}",3812
25,1966,CVE-2014-3538,23,"file_signextend(struct magic_set *ms, struct magic *m, int v){	if (!(m->flag & UNSIGNED)) {		switch(m->type) {		 		case FILE_BYTE:			v = (char) v;			break;		case FILE_SHORT:		case FILE_BESHORT:		case FILE_LESHORT:			v = (short) v;			break;		case FILE_DATE:		case FILE_BEDATE:		case FILE_LEDATE:		case FILE_MEDATE:		case FILE_LDATE:		case FILE_BELDATE:		case FILE_LELDATE:		case FILE_MELDATE:		case FILE_LONG:		case FILE_BELONG:		case FILE_LELONG:		case FILE_MELONG:		case FILE_FLOAT:		case FILE_BEFLOAT:		case FILE_LEFLOAT:			v = (int) v;			break;		case FILE_QUAD:		case FILE_BEQUAD:		case FILE_LEQUAD:		case FILE_QDATE:		case FILE_QLDATE:		case FILE_QWDATE:		case FILE_BEQDATE:		case FILE_BEQLDATE:		case FILE_BEQWDATE:		case FILE_LEQDATE:		case FILE_LEQLDATE:		case FILE_LEQWDATE:		case FILE_DOUBLE:		case FILE_BEDOUBLE:		case FILE_LEDOUBLE:			v = (int) v;			break;		case FILE_STRING:		case FILE_PSTRING:		case FILE_BESTRING16:		case FILE_LESTRING16:		case FILE_REGEX:		case FILE_SEARCH:		case FILE_DEFAULT:		case FILE_INDIRECT:		case FILE_NAME:		case FILE_USE:		case FILE_CLEAR:			break;		default:			if (ms->flags & MAGIC_CHECK)			    file_magwarn(ms, ""cannot happen: m->type=%d\n"",				    m->type);			return ~0U;		}	}	return v;}",11429
20,242,CVE-2012-1601,23,static void emulator_put_fpu(struct x86_emulate_ctxt *ctxt){	preempt_enable();},3720
350,1859,CVE-2014-3690,23,static int handle_nop(struct kvm_vcpu *vcpu){	skip_emulated_instruction(vcpu);	return 1;},11047
59,1455,CVE-2013-1767,23,static int shmem_reserve_inode(struct super_block *sb){	struct shmem_sb_info *sbinfo = SHMEM_SB(sb);	if (sbinfo->max_inodes) {		spin_lock(&sbinfo->stat_lock);		if (!sbinfo->free_inodes) {			spin_unlock(&sbinfo->stat_lock);			return -ENOSPC;		}		sbinfo->free_inodes--;		spin_unlock(&sbinfo->stat_lock);	}	return 0;},9654
447,2461,CVE-2015-8785,23,"static void fuse_writepage_free(struct fuse_conn *fc, struct fuse_req *req){	int i;	for (i = 0; i < req->num_pages; i++)		__free_page(req->pages[i]);	if (req->ff)		fuse_file_put(req->ff, false);}",18734
162,795,CVE-2011-2918,23,"static int __perf_cgroup_move(void *info){	struct task_struct *task = info;	perf_cgroup_switch(task, PERF_CGROUP_SWOUT | PERF_CGROUP_SWIN);	return 0;}",6187
56,2132,CVE-2015-8104,23,"static int nested_svm_vmexit(struct vcpu_svm *svm){	struct vmcb *nested_vmcb;	struct vmcb *hsave = svm->nested.hsave;	struct vmcb *vmcb = svm->vmcb;	struct page *page;	trace_kvm_nested_vmexit_inject(vmcb->control.exit_code,				       vmcb->control.exit_info_1,				       vmcb->control.exit_info_2,				       vmcb->control.exit_int_info,				       vmcb->control.exit_int_info_err,				       KVM_ISA_SVM);	nested_vmcb = nested_svm_map(svm, svm->nested.vmcb, &page);	if (!nested_vmcb)		return 1;	 	leave_guest_mode(&svm->vcpu);	svm->nested.vmcb = 0;	 	disable_gif(svm);	nested_vmcb->save.es     = vmcb->save.es;	nested_vmcb->save.cs     = vmcb->save.cs;	nested_vmcb->save.ss     = vmcb->save.ss;	nested_vmcb->save.ds     = vmcb->save.ds;	nested_vmcb->save.gdtr   = vmcb->save.gdtr;	nested_vmcb->save.idtr   = vmcb->save.idtr;	nested_vmcb->save.efer   = svm->vcpu.arch.efer;	nested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);	nested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);	nested_vmcb->save.cr2    = vmcb->save.cr2;	nested_vmcb->save.cr4    = svm->vcpu.arch.cr4;	nested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);	nested_vmcb->save.rip    = vmcb->save.rip;	nested_vmcb->save.rsp    = vmcb->save.rsp;	nested_vmcb->save.rax    = vmcb->save.rax;	nested_vmcb->save.dr7    = vmcb->save.dr7;	nested_vmcb->save.dr6    = vmcb->save.dr6;	nested_vmcb->save.cpl    = vmcb->save.cpl;	nested_vmcb->control.int_ctl           = vmcb->control.int_ctl;	nested_vmcb->control.int_vector        = vmcb->control.int_vector;	nested_vmcb->control.int_state         = vmcb->control.int_state;	nested_vmcb->control.exit_code         = vmcb->control.exit_code;	nested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;	nested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;	nested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;	nested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;	nested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;	if (svm->nrips_enabled)		nested_vmcb->control.next_rip  = vmcb->control.next_rip;	 	if (vmcb->control.event_inj & SVM_EVTINJ_VALID) {		struct vmcb_control_area *nc = &nested_vmcb->control;		nc->exit_int_info     = vmcb->control.event_inj;		nc->exit_int_info_err = vmcb->control.event_inj_err;	}	nested_vmcb->control.tlb_ctl           = 0;	nested_vmcb->control.event_inj         = 0;	nested_vmcb->control.event_inj_err     = 0;	 	if (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))		nested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;	 	copy_vmcb_control_area(vmcb, hsave);	kvm_clear_exception_queue(&svm->vcpu);	kvm_clear_interrupt_queue(&svm->vcpu);	svm->nested.nested_cr3 = 0;	 	svm->vmcb->save.es = hsave->save.es;	svm->vmcb->save.cs = hsave->save.cs;	svm->vmcb->save.ss = hsave->save.ss;	svm->vmcb->save.ds = hsave->save.ds;	svm->vmcb->save.gdtr = hsave->save.gdtr;	svm->vmcb->save.idtr = hsave->save.idtr;	kvm_set_rflags(&svm->vcpu, hsave->save.rflags);	svm_set_efer(&svm->vcpu, hsave->save.efer);	svm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);	svm_set_cr4(&svm->vcpu, hsave->save.cr4);	if (npt_enabled) {		svm->vmcb->save.cr3 = hsave->save.cr3;		svm->vcpu.arch.cr3 = hsave->save.cr3;	} else {		(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);	}	kvm_register_write(&svm->vcpu, VCPU_REGS_RAX, hsave->save.rax);	kvm_register_write(&svm->vcpu, VCPU_REGS_RSP, hsave->save.rsp);	kvm_register_write(&svm->vcpu, VCPU_REGS_RIP, hsave->save.rip);	svm->vmcb->save.dr7 = 0;	svm->vmcb->save.cpl = 0;	svm->vmcb->control.exit_int_info = 0;	mark_all_dirty(svm->vmcb);	nested_svm_unmap(page);	nested_svm_uninit_mmu_context(&svm->vcpu);	kvm_mmu_reset_context(&svm->vcpu);	kvm_mmu_load(&svm->vcpu);	return 0;}",13022
81,1825,CVE-2014-3690,23,"static inline void crash_disable_local_vmclear(int cpu){	cpumask_clear_cpu(cpu, &crash_vmclear_enabled_bitmap);}",11013
223,674,CVE-2011-2918,23,"void window_overflow_fault(void){	unsigned long sp;	sp = current_thread_info()->rwbuf_stkptrs[0];	if(((sp + 0x38) & PAGE_MASK) != (sp & PAGE_MASK))		force_user_fault(sp + 0x38, 1);	force_user_fault(sp, 1);	check_stack_aligned(sp);}",6066
562,500,CVE-2011-2918,23,"do_translation_fault(unsigned long addr, unsigned int fsr,		     struct pt_regs *regs){	return 0;}",5892
235,1900,CVE-2014-3690,23,"static int pi_test_and_set_pir(int vector, struct pi_desc *pi_desc){	return test_and_set_bit(vector, (unsigned long *)pi_desc->pir);}",11088
233,701,CVE-2011-2918,23,static void x86_pmu_disable(struct pmu *pmu){	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	if (!x86_pmu_initialized())		return;	if (!cpuc->enabled)		return;	cpuc->n_added = 0;	cpuc->enabled = 0;	barrier();	x86_pmu.disable_all();},6093
138,1731,CVE-2014-7145,23,"SMB2_logoff(const unsigned int xid, struct cifs_ses *ses){	struct smb2_logoff_req *req;  	int rc = 0;	struct TCP_Server_Info *server;	cifs_dbg(FYI, ""disconnect session %p\n"", ses);	if (ses && (ses->server))		server = ses->server;	else		return -EIO;	 	if (ses->need_reconnect)		goto smb2_session_already_dead;	rc = small_smb2_init(SMB2_LOGOFF, NULL, (void **) &req);	if (rc)		return rc;	  	req->hdr.SessionId = ses->Suid;	if (server->sign)		req->hdr.Flags |= SMB2_FLAGS_SIGNED;	rc = SendReceiveNoRsp(xid, ses, (char *) &req->hdr, 0);	 smb2_session_already_dead:	return rc;}",10555
572,1377,CVE-2013-2015,23,"static struct ext4_dir_entry_2* dx_pack_dirents(char *base, unsigned blocksize){	struct ext4_dir_entry_2 *next, *to, *prev, *de = (struct ext4_dir_entry_2 *) base;	unsigned rec_len = 0;	prev = to = de;	while ((char*)de < base + blocksize) {		next = ext4_next_entry(de, blocksize);		if (de->inode && de->name_len) {			rec_len = EXT4_DIR_REC_LEN(de->name_len);			if (de > to)				memmove(to, de, rec_len);			to->rec_len = ext4_rec_len_to_disk(rec_len, blocksize);			prev = to;			to = (struct ext4_dir_entry_2 *) (((char *) to) + rec_len);		}		de = next;	}	return prev;}",9086
492,478,CVE-2011-2918,23,"static int break_trap(struct pt_regs *regs, unsigned int instr){	ptrace_break(current, regs);	return 0;}",5870
187,932,CVE-2011-2918,23,"static void task_clock_event_stop(struct perf_event *event, int flags){	perf_swevent_cancel_hrtimer(event);	task_clock_event_update(event, event->ctx->time);}",6324
240,1347,CVE-2013-2017,23,"static void netdev_init_queues(struct net_device *dev){	netdev_init_one_queue(dev, &dev->rx_queue, NULL);	netdev_for_each_tx_queue(dev, netdev_init_one_queue, NULL);	spin_lock_init(&dev->tx_global_lock);}",9056
95,2250,CVE-2015-5307,23,static int vmx_cpu_uses_apicv(struct kvm_vcpu *vcpu){	return enable_apicv && lapic_in_kernel(vcpu);},13372
340,425,CVE-2012-0058,23,"static void wait_for_all_aios(struct kioctx *ctx){	struct task_struct *tsk = current;	DECLARE_WAITQUEUE(wait, tsk);	spin_lock_irq(&ctx->ctx_lock);	if (!ctx->reqs_active)		goto out;	add_wait_queue(&ctx->wait, &wait);	set_task_state(tsk, TASK_UNINTERRUPTIBLE);	while (ctx->reqs_active) {		spin_unlock_irq(&ctx->ctx_lock);		io_schedule();		set_task_state(tsk, TASK_UNINTERRUPTIBLE);		spin_lock_irq(&ctx->ctx_lock);	}	__set_task_state(tsk, TASK_RUNNING);	remove_wait_queue(&ctx->wait, &wait);out:	spin_unlock_irq(&ctx->ctx_lock);}",4165
164,2089,CVE-2012-6638,23,static void tcp_mtup_probe_failed(struct sock *sk){	struct inet_connection_sock *icsk = inet_csk(sk);	icsk->icsk_mtup.search_high = icsk->icsk_mtup.probe_size - 1;	icsk->icsk_mtup.probe_size = 0;},12723
190,4,CVE-2015-7540,23,"int asn1_write_uint8(struct asn1_data *data, int v){	return asn1_write(data, &v, 1);}",81
127,707,CVE-2011-2918,23,static int x86_pmu_event_init(struct perf_event *event){	struct pmu *tmp;	int err;	switch (event->attr.type) {	case PERF_TYPE_RAW:	case PERF_TYPE_HARDWARE:	case PERF_TYPE_HW_CACHE:		break;	default:		return -ENOENT;	}	err = __x86_pmu_event_init(event);	if (!err) {		 		tmp = event->pmu;		event->pmu = &pmu;		if (event->group_leader != event)			err = validate_group(event);		else			err = validate_event(event);		event->pmu = tmp;	}	if (err) {		if (event->destroy)			event->destroy(event);	}	return err;},6099
259,2101,CVE-2012-6638,23,"static void tcp_reset(struct sock *sk){	 	switch (sk->sk_state) {	case TCP_SYN_SENT:		sk->sk_err = ECONNREFUSED;		break;	case TCP_CLOSE_WAIT:		sk->sk_err = EPIPE;		break;	case TCP_CLOSE:		return;	default:		sk->sk_err = ECONNRESET;	}	 	smp_wmb();	if (!sock_flag(sk, SOCK_DEAD))		sk->sk_error_report(sk);	tcp_done(sk);}",12735
318,741,CVE-2011-2918,23,"static void release_pebs_buffer(int cpu){	struct debug_store *ds = per_cpu(cpu_hw_events, cpu).ds;	if (!ds || !x86_pmu.pebs)		return;	kfree((void *)(unsigned long)ds->pebs_buffer_base);	ds->pebs_buffer_base = 0;}",6133
371,2314,CVE-2016-7166,23,"_archive_filter_name(struct archive *_a, int n){	struct archive_read_filter *f = get_filter(_a, n);	return f == NULL ? NULL : f->name;}",15825
6,767,CVE-2011-2918,23,"static unsigned long *pt_regs_access(struct pt_regs *regs, unsigned long offset){	BUILD_BUG_ON(offsetof(struct pt_regs, r15) != 0);	return &regs->r15 + (offset / sizeof(regs->r15));}",6159
593,1834,CVE-2014-3690,23,"static void ept_load_pdptrs(struct kvm_vcpu *vcpu){	struct kvm_mmu *mmu = vcpu->arch.walk_mmu;	if (!test_bit(VCPU_EXREG_PDPTR,		      (unsigned long *)&vcpu->arch.regs_dirty))		return;	if (is_paging(vcpu) && is_pae(vcpu) && !is_long_mode(vcpu)) {		vmcs_write64(GUEST_PDPTR0, mmu->pdptrs[0]);		vmcs_write64(GUEST_PDPTR1, mmu->pdptrs[1]);		vmcs_write64(GUEST_PDPTR2, mmu->pdptrs[2]);		vmcs_write64(GUEST_PDPTR3, mmu->pdptrs[3]);	}}",11022
634,802,CVE-2011-2918,23,"static int __perf_remove_from_context(void *info){	struct perf_event *event = info;	struct perf_event_context *ctx = event->ctx;	struct perf_cpu_context *cpuctx = __get_cpu_context(ctx);	raw_spin_lock(&ctx->lock);	event_sched_out(event, cpuctx, ctx);	list_del_event(event, ctx);	if (!ctx->nr_events && cpuctx->task_ctx == ctx) {		ctx->is_active = 0;		cpuctx->task_ctx = NULL;	}	raw_spin_unlock(&ctx->lock);	return 0;}",6194
306,2545,CVE-2011-1292,23,  void set_autofill_enabled(int autofill_enabled) {    autofill_enabled_ = autofill_enabled;  },29152
67,1077,CVE-2013-5634,23,int kvm_arch_hardware_enable(void *garbage){	return 0;},7481
356,620,CVE-2011-2918,23,"static int check_excludes(struct perf_event **evts, int n_prev, int n_new){	int eu = 0, ek = 0, eh = 0;	struct perf_event *event;	int i, n, first;	n = n_prev + n_new;	if (n <= 1)		return 0;	first = 1;	for (i = 0; i < n; i++) {		event = evts[i];		if (first) {			eu = event->attr.exclude_user;			ek = event->attr.exclude_kernel;			eh = event->attr.exclude_hv;			first = 0;		} else if (event->attr.exclude_user != eu ||			   event->attr.exclude_kernel != ek ||			   event->attr.exclude_hv != eh) {			return -EAGAIN;		}	}	return 0;}",6012
326,1754,CVE-2014-6418,23,"static int ceph_x_handle_reply(struct ceph_auth_client *ac, int result,			       void *buf, void *end){	struct ceph_x_info *xi = ac->private;	struct ceph_x_reply_header *head = buf;	struct ceph_x_ticket_handler *th;	int len = end - buf;	int op;	int ret;	if (result)		return result;   	if (xi->starting) {		 		struct ceph_x_server_challenge *sc = buf;		if (len != sizeof(*sc))			return -EINVAL;		xi->server_challenge = le64_to_cpu(sc->server_challenge);		dout(""handle_reply got server challenge %llx\n"",		     xi->server_challenge);		xi->starting = false;		xi->have_keys &= ~CEPH_ENTITY_TYPE_AUTH;		return -EAGAIN;	}	op = le16_to_cpu(head->op);	result = le32_to_cpu(head->result);	dout(""handle_reply op %d result %d\n"", op, result);	switch (op) {	case CEPHX_GET_AUTH_SESSION_KEY:		 		ret = ceph_x_proc_ticket_reply(ac, &xi->secret,					       buf + sizeof(*head), end);		break;	case CEPHX_GET_PRINCIPAL_SESSION_KEY:		th = get_ticket_handler(ac, CEPH_ENTITY_TYPE_AUTH);		if (IS_ERR(th))			return PTR_ERR(th);		ret = ceph_x_proc_ticket_reply(ac, &th->session_key,					       buf + sizeof(*head), end);		break;	default:		return -EINVAL;	}	if (ret)		return ret;	if (ac->want_keys == xi->have_keys)		return 0;	return -EAGAIN;}",10578
185,2108,CVE-2012-6638,23,static int tcp_should_expand_sndbuf(const struct sock *sk){	const struct tcp_sock *tp = tcp_sk(sk);	 	if (sk->sk_userlocks & SOCK_SNDBUF_LOCK)		return 0;	 	if (tcp_memory_pressure)		return 0;	 	if (atomic_long_read(&tcp_memory_allocated) >= sysctl_tcp_mem[0])		return 0;	 	if (tp->packets_out >= tp->snd_cwnd)		return 0;	return 1;},12742
608,1420,CVE-2013-1797,23,"static int kvm_vcpu_ioctl_interrupt(struct kvm_vcpu *vcpu,				    struct kvm_interrupt *irq){	if (irq->irq < 0 || irq->irq >= KVM_NR_INTERRUPTS)		return -EINVAL;	if (irqchip_in_kernel(vcpu->kvm))		return -ENXIO;	kvm_queue_interrupt(vcpu, irq->irq, false);	kvm_make_request(KVM_REQ_EVENT, vcpu);	return 0;}",9519
312,1573,CVE-2011-2491,23,"void rpc_task_set_client(struct rpc_task *task, struct rpc_clnt *clnt){	if (clnt != NULL) {		rpc_task_release_client(task);		task->tk_client = clnt;		atomic_inc(&clnt->cl_count);		if (clnt->cl_softrtry)			task->tk_flags |= RPC_TASK_SOFT;		 		spin_lock(&clnt->cl_lock);		list_add_tail(&task->tk_task, &clnt->cl_tasks);		spin_unlock(&clnt->cl_lock);	}}",10192
213,1658,CVE-2014-8481,23,"static int em_sgdt(struct x86_emulate_ctxt *ctxt){	return emulate_store_desc_ptr(ctxt, ctxt->ops->get_gdt);}",10429
270,1641,CVE-2014-8481,23,"static int em_call(struct x86_emulate_ctxt *ctxt){	int rc;	long rel = ctxt->src.val;	ctxt->src.val = (unsigned long)ctxt->_eip;	rc = jmp_rel(ctxt, rel);	if (rc != X86EMUL_CONTINUE)		return rc;	return em_push(ctxt);}",10412
346,426,CVE-2011-4326,23,"static int __udp6_lib_mcast_deliver(struct net *net, struct sk_buff *skb,		struct in6_addr *saddr, struct in6_addr *daddr,		struct udp_table *udptable){	struct sock *sk, *stack[256 / sizeof(struct sock *)];	const struct udphdr *uh = udp_hdr(skb);	struct udp_hslot *hslot = udp_hashslot(udptable, net, ntohs(uh->dest));	int dif;	unsigned int i, count = 0;	spin_lock(&hslot->lock);	sk = sk_nulls_head(&hslot->head);	dif = inet6_iif(skb);	sk = udp_v6_mcast_next(net, sk, uh->dest, daddr, uh->source, saddr, dif);	while (sk) {		stack[count++] = sk;		sk = udp_v6_mcast_next(net, sk_nulls_next(sk), uh->dest, daddr,				       uh->source, saddr, dif);		if (unlikely(count == ARRAY_SIZE(stack))) {			if (!sk)				break;			flush_stack(stack, count, skb, ~0);			count = 0;		}	}	 	for (i = 0; i < count; i++)		sock_hold(stack[i]);	spin_unlock(&hslot->lock);	if (count) {		flush_stack(stack, count, skb, count - 1);		for (i = 0; i < count; i++)			sock_put(stack[i]);	} else {		kfree_skb(skb);	}	return 0;}",4640
1,466,CVE-2011-2918,23,"xscale1_pmnc_counter_has_overflowed(unsigned long pmnc,					enum xscale_counters counter){	int ret = 0;	switch (counter) {	case XSCALE_CYCLE_COUNTER:		ret = pmnc & XSCALE1_CCOUNT_OVERFLOW;		break;	case XSCALE_COUNTER0:		ret = pmnc & XSCALE1_COUNT0_OVERFLOW;		break;	case XSCALE_COUNTER1:		ret = pmnc & XSCALE1_COUNT1_OVERFLOW;		break;	default:		WARN_ONCE(1, ""invalid counter number (%d)\n"", counter);	}	return ret;}",5858
243,539,CVE-2011-2918,23,static unsigned long get_user_msr(struct task_struct *task){	return task->thread.regs->msr | task->thread.fpexc_mode;},5931
230,1097,CVE-2013-5634,23,"static int kvm_vm_ioctl_set_device_addr(struct kvm *kvm,					struct kvm_arm_device_addr *dev_addr){	unsigned long dev_id, type;	dev_id = (dev_addr->id & KVM_ARM_DEVICE_ID_MASK) >>		KVM_ARM_DEVICE_ID_SHIFT;	type = (dev_addr->id & KVM_ARM_DEVICE_TYPE_MASK) >>		KVM_ARM_DEVICE_TYPE_SHIFT;	switch (dev_id) {	case KVM_ARM_DEVICE_VGIC_V2:		if (!vgic_present)			return -ENXIO;		return kvm_vgic_set_addr(kvm, type, dev_addr->addr);	default:		return -ENODEV;	}}",7501
461,1521,CVE-2011-4087,23,"static inline struct nf_bridge_info *nf_bridge_unshare(struct sk_buff *skb){	struct nf_bridge_info *nf_bridge = skb->nf_bridge;	if (atomic_read(&nf_bridge->use) > 1) {		struct nf_bridge_info *tmp = nf_bridge_alloc(skb);		if (tmp) {			memcpy(tmp, nf_bridge, sizeof(struct nf_bridge_info));			atomic_set(&tmp->use, 1);		}		nf_bridge_put(nf_bridge);		nf_bridge = tmp;	}	return nf_bridge;}",10087
496,2546,CVE-2012-2888,23,  OutOfProcessProxy() {},29178
499,1481,CVE-2013-0217,23,"static void netbk_gop_frag_copy(struct xenvif *vif, struct sk_buff *skb,				struct netrx_pending_operations *npo,				struct page *page, unsigned long size,				unsigned long offset, int *head){	struct gnttab_copy *copy_gop;	struct netbk_rx_meta *meta;	 	unsigned int uninitialized_var(group), uninitialized_var(idx);	int foreign = get_page_ext(page, &group, &idx);	unsigned long bytes;	 	BUG_ON(size + offset > PAGE_SIZE<<compound_order(page));	meta = npo->meta + npo->meta_prod - 1;	 	page += offset >> PAGE_SHIFT;	offset &= ~PAGE_MASK;	while (size > 0) {		BUG_ON(offset >= PAGE_SIZE);		BUG_ON(npo->copy_off > MAX_BUFFER_OFFSET);		bytes = PAGE_SIZE - offset;		if (bytes > size)			bytes = size;		if (start_new_rx_buffer(npo->copy_off, bytes, *head)) {			 			BUG_ON(*head);			meta = get_next_rx_buffer(vif, npo);		}		if (npo->copy_off + bytes > MAX_BUFFER_OFFSET)			bytes = MAX_BUFFER_OFFSET - npo->copy_off;		copy_gop = npo->copy + npo->copy_prod++;		copy_gop->flags = GNTCOPY_dest_gref;		if (foreign) {			struct xen_netbk *netbk = &xen_netbk[group];			struct pending_tx_info *src_pend;			src_pend = &netbk->pending_tx_info[idx];			copy_gop->source.domid = src_pend->vif->domid;			copy_gop->source.u.ref = src_pend->req.gref;			copy_gop->flags |= GNTCOPY_source_gref;		} else {			void *vaddr = page_address(page);			copy_gop->source.domid = DOMID_SELF;			copy_gop->source.u.gmfn = virt_to_mfn(vaddr);		}		copy_gop->source.offset = offset;		copy_gop->dest.domid = vif->domid;		copy_gop->dest.offset = npo->copy_off;		copy_gop->dest.u.ref = npo->copy_gref;		copy_gop->len = bytes;		npo->copy_off += bytes;		meta->size += bytes;		offset += bytes;		size -= bytes;		 		if (offset == PAGE_SIZE && size) {			BUG_ON(!PageCompound(page));			page++;			offset = 0;		}		 		if (*head && skb_shinfo(skb)->gso_size && !vif->gso_prefix)			vif->rx.req_cons++;		*head = 0;  	}}",9778
121,2652,CVE-2011-2918,23,"static void alpha_perf_event_irq_handler(unsigned long la_ptr,					struct pt_regs *regs){	struct cpu_hw_events *cpuc;	struct perf_sample_data data;	struct perf_event *event;	struct hw_perf_event *hwc;	int idx, j;	__get_cpu_var(irq_pmi_count)++;	cpuc = &__get_cpu_var(cpu_hw_events);	 	wrperfmon(PERFMON_CMD_DISABLE, cpuc->idx_mask);	 	if (unlikely(la_ptr >= alpha_pmu->num_pmcs)) {		 		irq_err_count++;		pr_warning(""PMI: silly index %ld\n"", la_ptr);		wrperfmon(PERFMON_CMD_ENABLE, cpuc->idx_mask);		return;	}	idx = la_ptr;	perf_sample_data_init(&data, 0);	for (j = 0; j < cpuc->n_events; j++) {		if (cpuc->current_idx[j] == idx)			break;	}	if (unlikely(j == cpuc->n_events)) {		 		wrperfmon(PERFMON_CMD_ENABLE, cpuc->idx_mask);		return;	}	event = cpuc->event[j];	if (unlikely(!event)) {		 		irq_err_count++;		pr_warning(""PMI: No event at index %d!\n"", idx);		wrperfmon(PERFMON_CMD_ENABLE, cpuc->idx_mask);		return;	}	hwc = &event->hw;	alpha_perf_event_update(event, hwc, idx, alpha_pmu->pmc_max_period[idx]+1); 	data.period = event->hw.last_period;  	if (alpha_perf_event_set_period(event, hwc, idx)) {		if (perf_event_overflow(event, 1, &data, regs)) { 			 			alpha_pmu_stop(event, 0);		}	}	wrperfmon(PERFMON_CMD_ENABLE, cpuc->idx_mask);	return;}",30995
423,1357,CVE-2013-2017,23,int netif_rx_ni(struct sk_buff *skb){	int err;	preempt_disable();	err = netif_rx(skb);	if (local_softirq_pending())		do_softirq();	preempt_enable();	return err;},9066
146,823,CVE-2011-2918,23,"inherit_task_group(struct perf_event *event, struct task_struct *parent,		   struct perf_event_context *parent_ctx,		   struct task_struct *child, int ctxn,		   int *inherited_all){	int ret;	struct perf_event_context *child_ctx;	if (!event->attr.inherit) {		*inherited_all = 0;		return 0;	}	child_ctx = child->perf_event_ctxp[ctxn];	if (!child_ctx) {		 		child_ctx = alloc_perf_context(event->pmu, child);		if (!child_ctx)			return -ENOMEM;		child->perf_event_ctxp[ctxn] = child_ctx;	}	ret = inherit_group(event, parent, parent_ctx,			    child, child_ctx);	if (ret)		*inherited_all = 0;	return ret;}",6215
541,1928,CVE-2014-3690,23,"static void vmx_get_idt(struct kvm_vcpu *vcpu, struct desc_ptr *dt){	dt->size = vmcs_read32(GUEST_IDTR_LIMIT);	dt->address = vmcs_readl(GUEST_IDTR_BASE);}",11116
657,2324,CVE-2016-7166,23,"archive_read_header_position(struct archive *_a){	struct archive_read *a = (struct archive_read *)_a;	archive_check_magic(_a, ARCHIVE_READ_MAGIC,	    ARCHIVE_STATE_ANY, ""archive_read_header_position"");	return (a->header_position);}",15835
635,1243,CVE-2013-2141,23,"int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group){	int sig = q->info.si_signo;	struct sigpending *pending;	unsigned long flags;	int ret, result;	BUG_ON(!(q->flags & SIGQUEUE_PREALLOC));	ret = -1;	if (!likely(lock_task_sighand(t, &flags)))		goto ret;	ret = 1;  	result = TRACE_SIGNAL_IGNORED;	if (!prepare_signal(sig, t, false))		goto out;	ret = 0;	if (unlikely(!list_empty(&q->list))) {		 		BUG_ON(q->info.si_code != SI_TIMER);		q->info.si_overrun++;		result = TRACE_SIGNAL_ALREADY_PENDING;		goto out;	}	q->info.si_overrun = 0;	signalfd_notify(t, sig);	pending = group ? &t->signal->shared_pending : &t->pending;	list_add_tail(&q->list, &pending->list);	sigaddset(&pending->signal, sig);	complete_signal(sig, t, group);	result = TRACE_SIGNAL_DELIVERED;out:	trace_signal_generate(sig, &q->info, t, group, result);	unlock_task_sighand(t, &flags);ret:	return ret;}",8849
66,856,CVE-2011-2918,23,static inline void perf_event_exit_cpu(int cpu) { },6248
354,1544,CVE-2011-2491,23,"call_refreshresult(struct rpc_task *task){	int status = task->tk_status;	dprint_status(task);	task->tk_status = 0;	task->tk_action = call_refresh;	switch (status) {	case 0:		if (rpcauth_uptodatecred(task))			task->tk_action = call_allocate;		return;	case -ETIMEDOUT:		rpc_delay(task, 3*HZ);	case -EAGAIN:		status = -EACCES;		if (!task->tk_cred_retry)			break;		task->tk_cred_retry--;		dprintk(""RPC: %5u %s: retry refresh creds\n"",				task->tk_pid, __func__);		return;	}	dprintk(""RPC: %5u %s: refresh creds failed with error %d\n"",				task->tk_pid, __func__, status);	rpc_exit(task, status);}",10163
534,2597,CVE-2013-2861,23,  int can_close() { return can_close_app_list_; },29415
34,1848,CVE-2014-3690,23,"static int guest_state_valid(struct kvm_vcpu *vcpu){	if (enable_unrestricted_guest)		return true;	 	if (!is_protmode(vcpu) || (vmx_get_rflags(vcpu) & X86_EFLAGS_VM)) {		if (!rmode_segment_valid(vcpu, VCPU_SREG_CS))			return false;		if (!rmode_segment_valid(vcpu, VCPU_SREG_SS))			return false;		if (!rmode_segment_valid(vcpu, VCPU_SREG_DS))			return false;		if (!rmode_segment_valid(vcpu, VCPU_SREG_ES))			return false;		if (!rmode_segment_valid(vcpu, VCPU_SREG_FS))			return false;		if (!rmode_segment_valid(vcpu, VCPU_SREG_GS))			return false;	} else {	 		if (!cs_ss_rpl_check(vcpu))			return false;		if (!code_segment_valid(vcpu))			return false;		if (!stack_segment_valid(vcpu))			return false;		if (!data_segment_valid(vcpu, VCPU_SREG_DS))			return false;		if (!data_segment_valid(vcpu, VCPU_SREG_ES))			return false;		if (!data_segment_valid(vcpu, VCPU_SREG_FS))			return false;		if (!data_segment_valid(vcpu, VCPU_SREG_GS))			return false;		if (!tr_valid(vcpu))			return false;		if (!ldtr_valid(vcpu))			return false;	}	 	return true;}",11036
310,1889,CVE-2014-3690,23,static void nested_release_page_clean(struct page *page){	kvm_release_page_clean(page);},11077
49,206,CVE-2012-1601,23,int kvm_dev_ioctl_check_extension(long ext){	int r;	switch (ext) {	case KVM_CAP_IRQCHIP:	case KVM_CAP_MP_STATE:	case KVM_CAP_IRQ_INJECT_STATUS:		r = 1;		break;	case KVM_CAP_COALESCED_MMIO:		r = KVM_COALESCED_MMIO_PAGE_OFFSET;		break;	case KVM_CAP_IOMMU:		r = iommu_present(&pci_bus_type);		break;	default:		r = 0;	}	return r;},3684
53,2110,CVE-2012-6638,23,"static void tcp_skb_mark_lost_uncond_verify(struct tcp_sock *tp,					    struct sk_buff *skb){	tcp_verify_retransmit_hint(tp, skb);	if (!(TCP_SKB_CB(skb)->sacked & (TCPCB_LOST|TCPCB_SACKED_ACKED))) {		tp->lost_out += tcp_skb_pcount(skb);		TCP_SKB_CB(skb)->sacked |= TCPCB_LOST;	}}",12744
524,1526,CVE-2011-2491,23,static struct nlm_lockowner *nlm_get_lockowner(struct nlm_lockowner *lockowner){	atomic_inc(&lockowner->count);	return lockowner;},10145
263,628,CVE-2011-2918,23,"void perf_event_grab_pmc(void){	if (atomic_inc_not_zero(&active_events))		return;	mutex_lock(&pmc_grab_mutex);	if (atomic_read(&active_events) == 0) {		if (atomic_read(&nmi_active) > 0) {			on_each_cpu(perf_stop_nmi_watchdog, NULL, 1);			BUG_ON(atomic_read(&nmi_active) != 0);		}		atomic_inc(&active_events);	}	mutex_unlock(&pmc_grab_mutex);}",6020
568,2642,CVE-2012-2390,23," static void hugetlb_vm_op_close(struct vm_area_struct *vma) { 	struct hstate *h = hstate_vma(vma);	struct resv_map *reservations = vma_resv_map(vma);	struct hugepage_subpool *spool = subpool_vma(vma);	unsigned long reserve;	unsigned long start;	unsigned long end;	if (reservations) {		start = vma_hugecache_offset(h, vma, vma->vm_start);		end = vma_hugecache_offset(h, vma, vma->vm_end); 		reserve = (end - start) - 			region_count(&reservations->regions, start, end); 		kref_put(&reservations->refs, resv_map_release);  		if (reserve) { 			hugetlb_acct_memory(h, -reserve);			hugepage_subpool_put_pages(spool, reserve);		}	}}",30937
251,238,CVE-2012-1601,23,"static int emulator_intercept(struct x86_emulate_ctxt *ctxt,			      struct x86_instruction_info *info,			      enum x86_intercept_stage stage){	return kvm_x86_ops->check_intercept(emul_to_vcpu(ctxt), info, stage);}",3716
119,2276,CVE-2015-5307,23,"static inline void vpid_sync_vcpu_single(int vpid){	if (vpid == 0)		return;	if (cpu_has_vmx_invvpid_single())		__invvpid(VMX_VPID_EXTENT_SINGLE_CONTEXT, vpid, 0);}",13398
379,550,CVE-2011-2918,23,"int __handle_fault(unsigned long uaddr, unsigned long pgm_int_code, int write){	struct pt_regs regs;	int access, fault;	regs.psw.mask = psw_kernel_bits;	if (!irqs_disabled())		regs.psw.mask |= PSW_MASK_IO | PSW_MASK_EXT;	regs.psw.addr = (unsigned long) __builtin_return_address(0);	regs.psw.addr |= PSW_ADDR_AMODE;	uaddr &= PAGE_MASK;	access = write ? VM_WRITE : VM_READ;	fault = do_exception(&regs, access, uaddr | 2);	if (unlikely(fault)) {		if (fault & VM_FAULT_OOM)			return -EFAULT;		else if (fault & VM_FAULT_SIGBUS)			do_sigbus(&regs, pgm_int_code, uaddr);	}	return fault ? -EFAULT : 0;}",5942
576,544,CVE-2011-2918,23,"static int set_user_msr(struct task_struct *task, unsigned long msr){	task->thread.regs->msr &= ~MSR_DEBUGCHANGE;	task->thread.regs->msr |= msr & MSR_DEBUGCHANGE;	return 0;}",5936
602,1371,CVE-2013-2017,23,"void unregister_netdevice_queue(struct net_device *dev, struct list_head *head){	ASSERT_RTNL();	if (head) {		list_move_tail(&dev->unreg_list, head);	} else {		rollback_registered(dev);		 		net_set_todo(dev);	}}",9080
384,1519,CVE-2011-4087,23,"static inline void nf_bridge_push_encap_header(struct sk_buff *skb){	unsigned int len = nf_bridge_encap_header_len(skb);	skb_push(skb, len);	skb->network_header -= len;}",10085
271,1409,CVE-2013-1797,23,"void kvm_arch_async_page_present(struct kvm_vcpu *vcpu,				 struct kvm_async_pf *work){	struct x86_exception fault;	trace_kvm_async_pf_ready(work->arch.token, work->gva);	if (is_error_page(work->page))		work->arch.token = ~0;  	else		kvm_del_async_pf_gfn(vcpu, work->arch.gfn);	if ((vcpu->arch.apf.msr_val & KVM_ASYNC_PF_ENABLED) &&	    !apf_put_user(vcpu, KVM_PV_REASON_PAGE_READY)) {		fault.vector = PF_VECTOR;		fault.error_code_valid = true;		fault.error_code = 0;		fault.nested_page_fault = false;		fault.address = work->arch.token;		kvm_inject_page_fault(vcpu, &fault);	}	vcpu->arch.apf.halted = false;	vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;}",9508
397,1288,CVE-2013-2017,23,"int dev_alloc_name(struct net_device *dev, const char *name){	char buf[IFNAMSIZ];	struct net *net;	int ret;	BUG_ON(!dev_net(dev));	net = dev_net(dev);	ret = __dev_alloc_name(net, name, buf);	if (ret >= 0)		strlcpy(dev->name, buf, IFNAMSIZ);	return ret;}",8997
506,2600,CVE-2013-0919,23,  ActionBoxTest() {},29435
305,2160,CVE-2015-6252,23,int vhost_dev_has_owner(struct vhost_dev *dev){	return dev->mm;},13138
342,1376,CVE-2013-2015,23,"static inline unsigned dx_node_limit(struct inode *dir){	unsigned entry_space = dir->i_sb->s_blocksize - EXT4_DIR_REC_LEN(0);	if (EXT4_HAS_RO_COMPAT_FEATURE(dir->i_sb,				       EXT4_FEATURE_RO_COMPAT_METADATA_CSUM))		entry_space -= sizeof(struct dx_tail);	return entry_space / sizeof(struct dx_entry);}",9085
539,1060,CVE-2011-0716,23,"int br_multicast_set_router(struct net_bridge *br, unsigned long val){	int err = -ENOENT;	spin_lock_bh(&br->multicast_lock);	if (!netif_running(br->dev))		goto unlock;	switch (val) {	case 0:	case 2:		del_timer(&br->multicast_router_timer);		 	case 1:		br->multicast_router = val;		err = 0;		break;	default:		err = -EINVAL;		break;	}unlock:	spin_unlock_bh(&br->multicast_lock);	return err;}",6998
517,1168,CVE-2013-2635,23,void __rtnl_af_unregister(struct rtnl_af_ops *ops){	list_del(&ops->list);},8506
242,908,CVE-2011-2918,23,"static int perf_tp_filter_match(struct perf_event *event,				struct perf_sample_data *data){	void *record = data->raw->data;	if (likely(!event->filter) || filter_match_preds(event->filter, record))		return 1;	return 0;}",6300
291,1007,CVE-2011-2918,23,"int select_task_rq(struct task_struct *p, int sd_flags, int wake_flags){	int cpu = p->sched_class->select_task_rq(p, sd_flags, wake_flags);	 	if (unlikely(!cpumask_test_cpu(cpu, &p->cpus_allowed) ||		     !cpu_online(cpu)))		cpu = select_fallback_rq(task_cpu(p), p);	return cpu;}",6399
674,1950,CVE-2014-3690,23,"static void vmx_set_idt(struct kvm_vcpu *vcpu, struct desc_ptr *dt){	vmcs_write32(GUEST_IDTR_LIMIT, dt->size);	vmcs_writel(GUEST_IDTR_BASE, dt->address);}",11138
51,1475,CVE-2013-0217,23,"static struct netbk_rx_meta *get_next_rx_buffer(struct xenvif *vif,						struct netrx_pending_operations *npo){	struct netbk_rx_meta *meta;	struct xen_netif_rx_request *req;	req = RING_GET_REQUEST(&vif->rx, vif->rx.req_cons++);	meta = npo->meta + npo->meta_prod++;	meta->gso_size = 0;	meta->size = 0;	meta->id = req->id;	npo->copy_off = 0;	npo->copy_gref = req->gref;	return meta;}",9772
560,592,CVE-2011-2918,23,"static int flds(struct sh_fpu_soft_struct *fregs, int n){	FPUL = FRn;	return 0;}",5984
87,1803,CVE-2014-3690,23,static inline int cpu_has_vmx_ept_2m_page(void){	return vmx_capability.ept & VMX_EPT_2MB_PAGE_BIT;},10991
123,782,CVE-2011-2918,23,"bad_area(struct pt_regs *regs, unsigned long error_code, unsigned long address){	__bad_area(regs, error_code, address, SEGV_MAPERR);}",6174
297,1961,CVE-2014-3690,23,"static inline void vpid_sync_vcpu_single(struct vcpu_vmx *vmx){	if (vmx->vpid == 0)		return;	if (cpu_has_vmx_invvpid_single())		__invvpid(VMX_VPID_EXTENT_SINGLE_CONTEXT, vmx->vpid, 0);}",11149
192,150,CVE-2012-2133,23,"static void hugetlbfs_evict_inode(struct inode *inode){	truncate_hugepages(inode, 0);	end_writeback(inode);}",3494
30,1040,CVE-2011-0716,23,"static struct net_bridge_mdb_entry *br_mdb_ip6_get(	struct net_bridge_mdb_htable *mdb, const struct in6_addr *dst){	struct br_ip br_dst;	ipv6_addr_copy(&br_dst.u.ip6, dst);	br_dst.proto = htons(ETH_P_IPV6);	return br_mdb_ip_get(mdb, &br_dst);}",6978
160,619,CVE-2011-2918,23,"static inline void print_vma(struct vm_area_struct *vma){	printk(""vma start 0x%08lx\n"", vma->vm_start);	printk(""vma end   0x%08lx\n"", vma->vm_end);	print_prots(vma->vm_page_prot);	printk(""vm_flags 0x%08lx\n"", vma->vm_flags);}",6011
536,1193,CVE-2013-2635,23,void rtnl_link_unregister(struct rtnl_link_ops *ops){	rtnl_lock();	__rtnl_link_unregister(ops);	rtnl_unlock();},8531
370,2637,CVE-2015-7540,23," int asn1_write_LDAPString(struct asn1_data *data, const char *s) {       asn1_write(data, s, strlen(s));       return !data->has_error; }",30872
558,2382,CVE-2016-2550,23,"static void maybe_add_creds(struct sk_buff *skb, const struct socket *sock,			    const struct sock *other){	if (UNIXCB(skb).pid)		return;	if (unix_passcred_enabled(sock, other)) {		UNIXCB(skb).pid  = get_pid(task_tgid(current));		current_uid_gid(&UNIXCB(skb).uid, &UNIXCB(skb).gid);	}}",17485
556,2592,CVE-2013-2922,23,    FileBrowserPrivateGetDriveFilesFunction() {},29384
254,658,CVE-2011-2918,23,static inline enum direction decode_direction(unsigned int insn){	unsigned long tmp = (insn >> 21) & 1;	if (!tmp)		return load;	else {		switch ((insn>>19)&0xf) {		case 15:  			return both;		default:			return store;		}	}},6050
600,1552,CVE-2011-2491,23,rpc_call_start(struct rpc_task *task){	task->tk_action = call_start;},10171
325,2328,CVE-2016-7166,23,"archive_read_set_callback_data(struct archive *_a, void *client_data){	return archive_read_set_callback_data2(_a, client_data, 0);}",15839
547,2173,CVE-2015-6252,23,"void vhost_poll_stop(struct vhost_poll *poll){	if (poll->wqh) {		remove_wait_queue(poll->wqh, &poll->wait);		poll->wqh = NULL;	}}",13151
629,57,CVE-2014-0221,23,dtls1_guess_mtu(unsigned int curr_mtu)	{	unsigned int i;	if ( curr_mtu == 0 )		return g_probable_mtu[0] ;	for ( i = 0; i < sizeof(g_probable_mtu)/sizeof(g_probable_mtu[0]); i++)		if ( curr_mtu > g_probable_mtu[i])			return g_probable_mtu[i];	return curr_mtu;	},2251
477,521,CVE-2011-2918,23,"int cu2_notifier_call_chain(unsigned long val, void *v){	return raw_notifier_call_chain(&cu2_chain, val, v);}",5913
526,105,CVE-2012-2390,23,"static void enqueue_huge_page(struct hstate *h, struct page *page){	int nid = page_to_nid(page);	list_add(&page->lru, &h->hugepage_freelists[nid]);	h->free_huge_pages++;	h->free_huge_pages_node[nid]++;}",3177
652,1456,CVE-2013-1767,23,"static int shmem_rmdir(struct inode *dir, struct dentry *dentry){	if (!simple_empty(dentry))		return -ENOTEMPTY;	drop_nlink(dentry->d_inode);	drop_nlink(dir);	return shmem_unlink(dir, dentry);}",9655
21,2019,CVE-2014-1444,23,"fst_openport(struct fst_port_info *port){	int signals;	int txq_length;	 	if (port->card->state == FST_RUNNING) {		if (port->run) {			dbg(DBG_OPEN, ""open: found port already running\n"");			fst_issue_cmd(port, STOPPORT);			port->run = 0;		}		fst_rx_config(port);		fst_tx_config(port);		fst_op_raise(port, OPSTS_RTS | OPSTS_DTR);		fst_issue_cmd(port, STARTPORT);		port->run = 1;		signals = FST_RDL(port->card, v24DebouncedSts[port->index]);		if (signals & (((port->hwif == X21) || (port->hwif == X21D))			       ? IPSTS_INDICATE : IPSTS_DCD))			netif_carrier_on(port_to_dev(port));		else			netif_carrier_off(port_to_dev(port));		txq_length = port->txqe - port->txqs;		port->txqe = 0;		port->txqs = 0;	}}",12057
171,1331,CVE-2013-2017,23,"static void napi_gro_flush(struct napi_struct *napi){	struct sk_buff *skb, *next;	for (skb = napi->gro_list; skb; skb = next) {		next = skb->next;		skb->next = NULL;		napi_gro_complete(skb);	}	napi->gro_count = 0;	napi->gro_list = NULL;}",9040
476,2692,CVE-2013-1767,23,"static int shmem_remount_fs(struct super_block *sb, int *flags, char *data){	struct shmem_sb_info *sbinfo = SHMEM_SB(sb);	struct shmem_sb_info config = *sbinfo; 	unsigned long inodes; 	int error = -EINVAL;  	if (shmem_parse_options(data, &config, true)) 		return error; 	spin_lock(&sbinfo->stat_lock);	inodes = sbinfo->max_inodes - sbinfo->free_inodes;	if (percpu_counter_compare(&sbinfo->used_blocks, config.max_blocks) > 0)		goto out;	if (config.max_inodes < inodes)		goto out;	 	if (config.max_blocks && !sbinfo->max_blocks)		goto out;	if (config.max_inodes && !sbinfo->max_inodes)		goto out;	error = 0;	sbinfo->max_blocks  = config.max_blocks; 	sbinfo->max_inodes  = config.max_inodes; 	sbinfo->free_inodes = config.max_inodes - inodes; 	mpol_put(sbinfo->mpol);	sbinfo->mpol        = config.mpol;	  out: 	spin_unlock(&sbinfo->stat_lock); 	return error;}",31091
26,977,CVE-2011-2918,23,"static int get_group(int cpu, struct sd_data *sdd, struct sched_group **sg){	struct sched_domain *sd = *per_cpu_ptr(sdd->sd, cpu);	struct sched_domain *child = sd->child;	if (child)		cpu = cpumask_first(sched_domain_span(child));	if (sg)		*sg = *per_cpu_ptr(sdd->sg, cpu);	return cpu;}",6369
150,808,CVE-2011-2918,23,static void cpu_clock_event_read(struct perf_event *event){	cpu_clock_event_update(event);},6200
406,2686,CVE-2013-4127,23,"static long vhost_net_set_backend(struct vhost_net *n, unsigned index, int fd){	struct socket *sock, *oldsock;	struct vhost_virtqueue *vq;	struct vhost_net_virtqueue *nvq;	struct vhost_net_ubuf_ref *ubufs, *oldubufs = NULL;	int r;	mutex_lock(&n->dev.mutex);	r = vhost_dev_check_owner(&n->dev);	if (r)		goto err;	if (index >= VHOST_NET_VQ_MAX) {		r = -ENOBUFS;		goto err;	}	vq = &n->vqs[index].vq;	nvq = &n->vqs[index];	mutex_lock(&vq->mutex);	 	if (!vhost_vq_access_ok(vq)) {		r = -EFAULT;		goto err_vq;	}	sock = get_socket(fd);	if (IS_ERR(sock)) {		r = PTR_ERR(sock);		goto err_vq;	}	 	oldsock = rcu_dereference_protected(vq->private_data,					    lockdep_is_held(&vq->mutex));	if (sock != oldsock) {		ubufs = vhost_net_ubuf_alloc(vq,					     sock && vhost_sock_zcopy(sock));		if (IS_ERR(ubufs)) {			r = PTR_ERR(ubufs);			goto err_ubufs;		}		vhost_net_disable_vq(n, vq);		rcu_assign_pointer(vq->private_data, sock);		r = vhost_init_used(vq);		if (r)			goto err_used;		r = vhost_net_enable_vq(n, vq);		if (r)			goto err_used;		oldubufs = nvq->ubufs;		nvq->ubufs = ubufs;		n->tx_packets = 0;		n->tx_zcopy_err = 0;		n->tx_flush = false;	} 	mutex_unlock(&vq->mutex);  	if (oldubufs) {		vhost_net_ubuf_put_and_wait(oldubufs); 		mutex_lock(&vq->mutex); 		vhost_zerocopy_signal_used(n, vq); 		mutex_unlock(&vq->mutex);	}	if (oldsock) {		vhost_net_flush_vq(n, index);		fput(oldsock->file);	}	mutex_unlock(&n->dev.mutex);	return 0;err_used: 	rcu_assign_pointer(vq->private_data, oldsock); 	vhost_net_enable_vq(n, vq); 	if (ubufs)		vhost_net_ubuf_put_and_wait(ubufs); err_ubufs: 	fput(sock->file); err_vq:	mutex_unlock(&vq->mutex);err:	mutex_unlock(&n->dev.mutex);	return r;}",31061
181,804,CVE-2011-2918,23,"static int context_equiv(struct perf_event_context *ctx1,			 struct perf_event_context *ctx2){	return ctx1->parent_ctx && ctx1->parent_ctx == ctx2->parent_ctx		&& ctx1->parent_gen == ctx2->parent_gen		&& !ctx1->pin_count && !ctx2->pin_count;}",6196
103,495,CVE-2011-2918,23,"do_bad(unsigned long addr, unsigned int fsr, struct pt_regs *regs){	return 1;}",5887
239,1691,CVE-2014-8116,23,"do_note_freebsd_version(struct magic_set *ms, int swap, void *v){	int desc;	(void)memcpy(&desc, v, sizeof(desc));	desc = elf_getu32(swap, desc);	if (file_printf(ms, "", for FreeBSD"") == -1)		return;	 	if (desc == 460002) {		if (file_printf(ms, "" 4.6.2"") == -1)			return;	} else if (desc < 460100) {		if (file_printf(ms, "" %d.%d"", desc / 100000,		    desc / 10000 % 10) == -1)			return;		if (desc / 1000 % 10 > 0)			if (file_printf(ms, "".%d"", desc / 1000 % 10) == -1)				return;		if ((desc % 1000 > 0) || (desc % 100000 == 0))			if (file_printf(ms, "" (%d)"", desc) == -1)				return;	} else if (desc < 500000) {		if (file_printf(ms, "" %d.%d"", desc / 100000,		    desc / 10000 % 10 + desc / 1000 % 10) == -1)			return;		if (desc / 100 % 10 > 0) {			if (file_printf(ms, "" (%d)"", desc) == -1)				return;		} else if (desc / 10 % 10 > 0) {			if (file_printf(ms, "".%d"", desc / 10 % 10) == -1)				return;		}	} else {		if (file_printf(ms, "" %d.%d"", desc / 100000,		    desc / 1000 % 100) == -1)			return;		if ((desc / 100 % 10 > 0) ||		    (desc % 100000 / 100 == 0)) {			if (file_printf(ms, "" (%d)"", desc) == -1)				return;		} else if (desc / 10 % 10 > 0) {			if (file_printf(ms, "".%d"", desc / 10 % 10) == -1)				return;		}	}}",10469
111,1666,CVE-2014-8481,23,"static int emulate_store_desc_ptr(struct x86_emulate_ctxt *ctxt,				  void (*get)(struct x86_emulate_ctxt *ctxt,					      struct desc_ptr *ptr)){	struct desc_ptr desc_ptr;	if (ctxt->mode == X86EMUL_MODE_PROT64)		ctxt->op_bytes = 8;	get(ctxt, &desc_ptr);	if (ctxt->op_bytes == 2) {		ctxt->op_bytes = 4;		desc_ptr.address &= 0x00ffffff;	}	 	ctxt->dst.type = OP_NONE;	return segmented_write(ctxt, ctxt->dst.addr.mem,			       &desc_ptr, 2 + ctxt->op_bytes);}",10437
76,1967,CVE-2014-3538,23,"magic_entry_free(struct magic_entry *me, int nme){	int i;	if (me == NULL)		return;	for (i = 0; i < nme; i++)		free(me[i].mp);	free(me);}",11430
172,2057,CVE-2012-6638,23,static int tcp_any_retrans_done(const struct sock *sk){	const struct tcp_sock *tp = tcp_sk(sk);	struct sk_buff *skb;	if (tp->retrans_out)		return 1;	skb = tcp_write_queue_head(sk);	if (unlikely(skb && TCP_SKB_CB(skb)->sacked & TCPCB_EVER_RETRANS))		return 1;	return 0;},12691
279,1839,CVE-2014-3690,23,"static void fix_pmode_seg(struct kvm_vcpu *vcpu, int seg,		struct kvm_segment *save){	if (!emulate_invalid_guest_state) {		 		if (seg == VCPU_SREG_CS || seg == VCPU_SREG_SS)			save->selector &= ~SELECTOR_RPL_MASK;		save->dpl = save->selector & SELECTOR_RPL_MASK;		save->s = 1;	}	vmx_set_segment(vcpu, save, seg);}",11027
337,117,CVE-2012-2390,23,"static int hugetlb_sysfs_add_hstate(struct hstate *h, struct kobject *parent,				    struct kobject **hstate_kobjs,				    struct attribute_group *hstate_attr_group){	int retval;	int hi = h - hstates;	hstate_kobjs[hi] = kobject_create_and_add(h->name, parent);	if (!hstate_kobjs[hi])		return -ENOMEM;	retval = sysfs_create_group(hstate_kobjs[hi], hstate_attr_group);	if (retval)		kobject_put(hstate_kobjs[hi]);	return retval;}",3189
267,1606,CVE-2011-2491,23,"static inline void rpc_set_waitqueue_priority(struct rpc_wait_queue *queue, int priority){	queue->priority = priority;	queue->count = 1 << (priority * 2);}",10225
330,2297,CVE-2014-9428,23,"static struct sk_buff *batadv_frag_create(struct sk_buff *skb,					  struct batadv_frag_packet *frag_head,					  unsigned int mtu){	struct sk_buff *skb_fragment;	unsigned header_size = sizeof(*frag_head);	unsigned fragment_size = mtu - header_size;	skb_fragment = netdev_alloc_skb(NULL, mtu + ETH_HLEN);	if (!skb_fragment)		goto err;	skb->priority = TC_PRIO_CONTROL;	 	skb_reserve(skb_fragment, header_size + ETH_HLEN);	skb_split(skb, skb_fragment, skb->len - fragment_size);	 	skb_push(skb_fragment, header_size);	memcpy(skb_fragment->data, frag_head, header_size);err:	return skb_fragment;}",14480
610,217,CVE-2012-1601,23,"static int kvm_vcpu_pre_transition(struct kvm_vcpu *vcpu){	unsigned long psr;	int r;	int cpu = smp_processor_id();	if (vcpu->arch.last_run_cpu != cpu ||			per_cpu(last_vcpu, cpu) != vcpu) {		per_cpu(last_vcpu, cpu) = vcpu;		vcpu->arch.last_run_cpu = cpu;		kvm_flush_tlb_all();	}	vcpu->arch.host_rr6 = ia64_get_rr(RR6);	vti_set_rr6(vcpu->arch.vmm_rr);	local_irq_save(psr);	r = kvm_insert_vmm_mapping(vcpu);	local_irq_restore(psr);	return r;}",3695
65,2687,CVE-2013-4127,23,"static void vhost_net_ubuf_put_and_wait(struct vhost_net_ubuf_ref *ubufs) { 	kref_put(&ubufs->kref, vhost_net_zerocopy_done_signal); 	wait_event(ubufs->wait, !atomic_read(&ubufs->kref.refcount)); 	kfree(ubufs); }",31062
472,1033,CVE-2011-1479,23,SYSCALL_DEFINE0(inotify_init){	return sys_inotify_init1(0);},6848
504,1092,CVE-2013-5634,23,static void kvm_arm_set_running_vcpu(struct kvm_vcpu *vcpu){	BUG_ON(preemptible());	__get_cpu_var(kvm_arm_running_vcpu) = vcpu;},7496
412,2138,CVE-2015-8104,23,"static void svm_set_segment(struct kvm_vcpu *vcpu,			    struct kvm_segment *var, int seg){	struct vcpu_svm *svm = to_svm(vcpu);	struct vmcb_seg *s = svm_seg(vcpu, seg);	s->base = var->base;	s->limit = var->limit;	s->selector = var->selector;	if (var->unusable)		s->attrib = 0;	else {		s->attrib = (var->type & SVM_SELECTOR_TYPE_MASK);		s->attrib |= (var->s & 1) << SVM_SELECTOR_S_SHIFT;		s->attrib |= (var->dpl & 3) << SVM_SELECTOR_DPL_SHIFT;		s->attrib |= (var->present & 1) << SVM_SELECTOR_P_SHIFT;		s->attrib |= (var->avl & 1) << SVM_SELECTOR_AVL_SHIFT;		s->attrib |= (var->l & 1) << SVM_SELECTOR_L_SHIFT;		s->attrib |= (var->db & 1) << SVM_SELECTOR_DB_SHIFT;		s->attrib |= (var->g & 1) << SVM_SELECTOR_G_SHIFT;	}	 	if (seg == VCPU_SREG_SS)		svm->vmcb->save.cpl = (s->attrib >> SVM_SELECTOR_DPL_SHIFT) & 3; 	mark_dirty(svm->vmcb, VMCB_SEG); }",13028
435,2408,CVE-2015-8877,23,"static double KernelBessel_P1(const double x){	double p, q;	register long i;	static const double	Pone[] =	{		0.352246649133679798341724373e+5,		0.62758845247161281269005675e+5,		0.313539631109159574238669888e+5,		0.49854832060594338434500455e+4,		0.2111529182853962382105718e+3,		0.12571716929145341558495e+1	},	Qone[] =	{		0.352246649133679798068390431e+5,		0.626943469593560511888833731e+5,		0.312404063819041039923015703e+5,		0.4930396490181088979386097e+4,		0.2030775189134759322293574e+3,		0.1e+1	};	p = Pone[5];	q = Qone[5];	for (i=4; i >= 0; i--)	{		p = p*(8.0/x)*(8.0/x)+Pone[i];		q = q*(8.0/x)*(8.0/x)+Qone[i];	}	return (double)(p/q);}",18439
520,528,CVE-2011-2918,23,unsigned long perf_instruction_pointer(struct pt_regs *regs){	unsigned long ip;	if (TRAP(regs) != 0xf00)		return regs->nip;	 	ip = mfspr(SPRN_SIAR) + perf_ip_adjust(regs);	return ip;},5920
616,1704,CVE-2014-7841,23,int sctp_chunk_iif(const struct sctp_chunk *chunk){	struct sctp_af *af;	int iif = 0;	af = sctp_get_af_specific(ipver2af(ip_hdr(chunk->skb)->version));	if (af)		iif = af->skb_iif(chunk->skb);	return iif;},10512
508,1668,CVE-2014-8481,23,void emulator_invalidate_register_cache(struct x86_emulate_ctxt *ctxt){	invalidate_registers(ctxt);},10439
29,1308,CVE-2013-2017,23,"static int dev_new_index(struct net *net){	static int ifindex;	for (;;) {		if (++ifindex <= 0)			ifindex = 1;		if (!__dev_get_by_index(net, ifindex))			return ifindex;	}}",9017
565,39,CVE-2016-4008,23,"asn1_get_length_ber (const unsigned char *ber, int ber_len, int *len){  int ret;  long err;  ret = asn1_get_length_der (ber, ber_len, len);  if (ret == -1)    {				       err = _asn1_get_indefinite_length_string (ber + 1, ber_len, &ret);      if (err != ASN1_SUCCESS)	return -3;    }  return ret;}",1963
273,1813,CVE-2014-3690,23,static inline int cpu_has_vmx_invvpid_global(void){	return vmx_capability.vpid & VMX_VPID_EXTENT_GLOBAL_CONTEXT_BIT;},11001
112,1633,CVE-2014-9420,23,"static char *get_symlink_chunk(char *rpnt, struct rock_ridge *rr, char *plimit){	int slen;	int rootflag;	struct SL_component *oldslp;	struct SL_component *slp;	slen = rr->len - 5;	slp = &rr->u.SL.link;	while (slen > 1) {		rootflag = 0;		switch (slp->flags & ~1) {		case 0:			if (slp->len > plimit - rpnt)				return NULL;			memcpy(rpnt, slp->text, slp->len);			rpnt += slp->len;			break;		case 2:			if (rpnt >= plimit)				return NULL;			*rpnt++ = '.';			break;		case 4:			if (2 > plimit - rpnt)				return NULL;			*rpnt++ = '.';			*rpnt++ = '.';			break;		case 8:			if (rpnt >= plimit)				return NULL;			rootflag = 1;			*rpnt++ = '/';			break;		default:			printk(""Symlink component flag not implemented (%d)\n"",			       slp->flags);		}		slen -= slp->len + 2;		oldslp = slp;		slp = (struct SL_component *)((char *)slp + slp->len + 2);		if (slen < 2) {			 			if ((!rootflag) && (rr->u.SL.flags & 1) &&			    !(oldslp->flags & 1)) {				if (rpnt >= plimit)					return NULL;				*rpnt++ = '/';			}			break;		}		 		if (!rootflag && !(oldslp->flags & 1)) {			if (rpnt >= plimit)				return NULL;			*rpnt++ = '/';		}	}	return rpnt;}",10361
603,191,CVE-2012-1601,23,"int kvm_arch_vcpu_ioctl_get_sregs(struct kvm_vcpu *vcpu,		struct kvm_sregs *sregs){	return -EINVAL;}",3669
18,525,CVE-2011-2918,23,"static const struct exception_table_entry *search_dbe_tables(unsigned long addr){	const struct exception_table_entry *e;	e = search_extable(__start___dbe_table, __stop___dbe_table - 1, addr);	if (!e)		e = search_module_dbetables(addr);	return e;}",5917
421,1763,CVE-2014-6410,23,static void __udf_clear_extent_cache(struct inode *inode){	struct udf_inode_info *iinfo = UDF_I(inode);	if (iinfo->cached_extent.lstart != -1) {		brelse(iinfo->cached_extent.epos.bh);		iinfo->cached_extent.lstart = -1;	}},10587
315,900,CVE-2011-2918,23,static int perf_swevent_init(struct perf_event *event){	int event_id = event->attr.config;	if (event->attr.type != PERF_TYPE_SOFTWARE)		return -ENOENT;	switch (event_id) {	case PERF_COUNT_SW_CPU_CLOCK:	case PERF_COUNT_SW_TASK_CLOCK:		return -ENOENT;	default:		break;	}	if (event_id >= PERF_COUNT_SW_MAX)		return -ENOENT;	if (!event->parent) {		int err;		err = swevent_hlist_get(event);		if (err)			return err;		jump_label_inc(&perf_swevent_enabled[event_id]);		event->destroy = sw_perf_event_destroy;	}	return 0;},6292
399,1238,CVE-2013-2141,23,void recalc_sigpending(void){	if (!recalc_sigpending_tsk(current) && !freezing(current))		clear_thread_flag(TIF_SIGPENDING);},8844
597,1338,CVE-2013-2017,23,"unsigned long netdev_boot_base(const char *prefix, int unit){	const struct netdev_boot_setup *s = dev_boot_setup;	char name[IFNAMSIZ];	int i;	sprintf(name, ""%s%d"", prefix, unit);	 	if (__dev_get_by_name(&init_net, name))		return 1;	for (i = 0; i < NETDEV_BOOT_SETUP_MAX; i++)		if (!strcmp(name, s[i].name))			return s[i].map.base_addr;	return 0;}",9047
268,2099,CVE-2012-6638,23,"static void tcp_rearm_rto(struct sock *sk){	const struct tcp_sock *tp = tcp_sk(sk);	if (!tp->packets_out) {		inet_csk_clear_xmit_timer(sk, ICSK_TIME_RETRANS);	} else {		inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,					  inet_csk(sk)->icsk_rto, TCP_RTO_MAX);	}}",12733
37,1759,CVE-2014-6418,23,"static int ceph_x_should_authenticate(struct ceph_auth_client *ac){	struct ceph_x_info *xi = ac->private;	int need;	ceph_x_validate_tickets(ac, &need);	dout(""ceph_x_should_authenticate want=%d need=%d have=%d\n"",	     ac->want_keys, need, xi->have_keys);	return need != 0;}",10583
519,1139,CVE-2013-4127,23,"static struct socket *get_raw_socket(int fd){	struct {		struct sockaddr_ll sa;		char  buf[MAX_ADDR_LEN];	} uaddr;	int uaddr_len = sizeof uaddr, r;	struct socket *sock = sockfd_lookup(fd, &r);	if (!sock)		return ERR_PTR(-ENOTSOCK);	 	if (sock->sk->sk_type != SOCK_RAW) {		r = -ESOCKTNOSUPPORT;		goto err;	}	r = sock->ops->getname(sock, (struct sockaddr *)&uaddr.sa,			       &uaddr_len, 0);	if (r)		goto err;	if (uaddr.sa.sll_family != AF_PACKET) {		r = -EPFNOSUPPORT;		goto err;	}	return sock;err:	fput(sock->file);	return ERR_PTR(r);}",7978
374,2087,CVE-2012-6638,23,static inline int tcp_may_undo(const struct tcp_sock *tp){	return tp->undo_marker && (!tp->undo_retrans || tcp_packet_delayed(tp));},12721
355,2623,CVE-2014-1700,23,  void ResetObserver() {    suppressed_ = false;    notified_ = false;  },29566
618,943,CVE-2011-2918,23,static void perf_mmap_free_page(unsigned long addr){	struct page *page = virt_to_page((void *)addr);	page->mapping = NULL;	__free_page(page);},6335
285,239,CVE-2012-1601,23,"static int emulator_pio_in_emulated(struct x86_emulate_ctxt *ctxt,				    int size, unsigned short port, void *val,				    unsigned int count){	struct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);	int ret;	if (vcpu->arch.pio.count)		goto data_avail;	ret = emulator_pio_in_out(vcpu, size, port, val, count, true);	if (ret) {data_avail:		memcpy(val, vcpu->arch.pio_data, size * count);		vcpu->arch.pio.count = 0;		return 1;	}	return 0;}",3717
596,2476,CVE-2016-10153,23,static void teardown_sgtable(struct sg_table *sgt){	if (sgt->orig_nents > 1)		sg_free_table(sgt);},22491
258,872,CVE-2011-2918,23,"static int perf_fasync(int fd, struct file *filp, int on){	struct inode *inode = filp->f_path.dentry->d_inode;	struct perf_event *event = filp->private_data;	int retval;	mutex_lock(&inode->i_mutex);	retval = fasync_helper(fd, filp, on, &event->fasync);	mutex_unlock(&inode->i_mutex);	if (retval < 0)		return retval;	return 0;}",6264
580,2036,CVE-2013-7339,23,"void rds_ib_exit(void){	rds_info_deregister_func(RDS_INFO_IB_CONNECTIONS, rds_ib_ic_info);	rds_ib_unregister_client();	rds_ib_destroy_nodev_conns();	rds_ib_sysctl_exit();	rds_ib_recv_exit();	rds_trans_unregister(&rds_ib_transport);}",12321
621,1991,CVE-2014-1446,23,"static void yam_set_uart(struct net_device *dev){	struct yam_port *yp = netdev_priv(dev);	int divisor = 115200 / yp->baudrate;	outb(0, IER(dev->base_addr));	outb(LCR_DLAB | LCR_BIT8, LCR(dev->base_addr));	outb(divisor, DLL(dev->base_addr));	outb(0, DLM(dev->base_addr));	outb(LCR_BIT8, LCR(dev->base_addr));	outb(PTT_OFF, MCR(dev->base_addr));	outb(0x00, FCR(dev->base_addr));	 	inb(RBR(dev->base_addr));	inb(MSR(dev->base_addr));	 	outb(ENABLE_RTXINT, IER(dev->base_addr));}",12029
229,394,CVE-2012-0207,23,"static void ip_mc_clear_src(struct ip_mc_list *pmc){	struct ip_sf_list *psf, *nextpsf;	for (psf=pmc->tomb; psf; psf=nextpsf) {		nextpsf = psf->sf_next;		kfree(psf);	}	pmc->tomb = NULL;	for (psf=pmc->sources; psf; psf=nextpsf) {		nextpsf = psf->sf_next;		kfree(psf);	}	pmc->sources = NULL;	pmc->sfmode = MCAST_EXCLUDE;	pmc->sfcount[MCAST_INCLUDE] = 0;	pmc->sfcount[MCAST_EXCLUDE] = 1;}",4134
203,95,CVE-2012-2390,23,int PageHuge(struct page *page){	compound_page_dtor *dtor;	if (!PageCompound(page))		return 0;	page = compound_head(page);	dtor = get_compound_page_dtor(page);	return dtor == free_huge_page;},3167
405,1995,CVE-2014-1444,23,"check_started_ok(struct fst_card_info *card){	int i;	 	if (FST_RDW(card, smcVersion) != SMC_VERSION) {		pr_err(""Bad shared memory version %d expected %d\n"",		       FST_RDW(card, smcVersion), SMC_VERSION);		card->state = FST_BADVERSION;		return;	}	if (FST_RDL(card, endOfSmcSignature) != END_SIG) {		pr_err(""Missing shared memory signature\n"");		card->state = FST_BADVERSION;		return;	}	 	if ((i = FST_RDB(card, taskStatus)) == 0x01) {		card->state = FST_RUNNING;	} else if (i == 0xFF) {		pr_err(""Firmware initialisation failed. Card halted\n"");		card->state = FST_HALTED;		return;	} else if (i != 0x00) {		pr_err(""Unknown firmware status 0x%x\n"", i);		card->state = FST_HALTED;		return;	}	 	if (FST_RDL(card, numberOfPorts) != card->nports) {		pr_warn(""Port count mismatch on card %d.  Firmware thinks %d we say %d\n"",			card->card_no,			FST_RDL(card, numberOfPorts), card->nports);	}}",12033
469,2405,CVE-2015-8953,23,"static int ovl_set_timestamps(struct dentry *upperdentry, struct kstat *stat){	struct iattr attr = {		.ia_valid =		     ATTR_ATIME | ATTR_MTIME | ATTR_ATIME_SET | ATTR_MTIME_SET,		.ia_atime = stat->atime,		.ia_mtime = stat->mtime,	};	return notify_change(upperdentry, &attr, NULL);}",18434
501,1682,CVE-2014-8481,23,"static void string_addr_inc(struct x86_emulate_ctxt *ctxt, int reg,		struct operand *op){	int df = (ctxt->eflags & EFLG_DF) ? -op->count : op->count;	register_address_increment(ctxt, reg_rmw(ctxt, reg), df * op->bytes);	op->addr.mem.ea = register_address(ctxt, reg_read(ctxt, reg));}",10453
143,1600,CVE-2011-2491,23,"void rpc_put_task_async(struct rpc_task *task){	rpc_do_put_task(task, task->tk_workqueue);}",10219
351,1140,CVE-2013-4127,23,"static int get_rx_bufs(struct vhost_virtqueue *vq,		       struct vring_used_elem *heads,		       int datalen,		       unsigned *iovcount,		       struct vhost_log *log,		       unsigned *log_num,		       unsigned int quota){	unsigned int out, in;	int seg = 0;	int headcount = 0;	unsigned d;	int r, nlogs = 0;	while (datalen > 0 && headcount < quota) {		if (unlikely(seg >= UIO_MAXIOV)) {			r = -ENOBUFS;			goto err;		}		d = vhost_get_vq_desc(vq->dev, vq, vq->iov + seg,				      ARRAY_SIZE(vq->iov) - seg, &out,				      &in, log, log_num);		if (d == vq->num) {			r = 0;			goto err;		}		if (unlikely(out || in <= 0)) {			vq_err(vq, ""unexpected descriptor format for RX: ""				""out %d, in %d\n"", out, in);			r = -EINVAL;			goto err;		}		if (unlikely(log)) {			nlogs += *log_num;			log += *log_num;		}		heads[headcount].id = d;		heads[headcount].len = iov_length(vq->iov + seg, in);		datalen -= heads[headcount].len;		++headcount;		seg += in;	}	heads[headcount - 1].len += datalen;	*iovcount = seg;	if (unlikely(log))		*log_num = nlogs;	return headcount;err:	vhost_discard_vq_desc(vq, headcount);	return r;}",7979
200,1215,CVE-2013-2141,23,"static int check_kill_permission(int sig, struct siginfo *info,				 struct task_struct *t){	struct pid *sid;	int error;	if (!valid_signal(sig))		return -EINVAL;	if (!si_fromuser(info))		return 0;	error = audit_signal_info(sig, t);  	if (error)		return error;	if (!same_thread_group(current, t) &&	    !kill_ok_by_cred(t)) {		switch (sig) {		case SIGCONT:			sid = task_session(t);			 			if (!sid || sid == task_session(current))				break;		default:			return -EPERM;		}	}	return security_task_kill(t, info, sig, 0);}",8821
512,296,CVE-2012-1601,23,unsigned long kvm_get_cr8(struct kvm_vcpu *vcpu){	if (irqchip_in_kernel(vcpu->kvm))		return kvm_lapic_get_cr8(vcpu);	else		return vcpu->arch.cr8;},3774
218,1246,CVE-2013-2141,23,"static int sigkill_pending(struct task_struct *tsk){	return	sigismember(&tsk->pending.signal, SIGKILL) ||		sigismember(&tsk->signal->shared_pending.signal, SIGKILL);}",8852
104,553,CVE-2011-2918,23,"static inline int notify_page_fault(struct pt_regs *regs){	int ret = 0;	 	if (kprobes_built_in() && !user_mode(regs)) {		preempt_disable();		if (kprobe_running() && kprobe_fault_handler(regs, 14))			ret = 1;		preempt_enable();	}	return ret;}",5945
226,1232,CVE-2013-2141,23,"int kill_pid(struct pid *pid, int sig, int priv){	return kill_pid_info(sig, __si_special(priv), pid);}",8838
582,2058,CVE-2012-6638,23,"static void tcp_check_reno_reordering(struct sock *sk, const int addend){	struct tcp_sock *tp = tcp_sk(sk);	if (tcp_limit_reno_sacked(tp))		tcp_update_reordering(sk, tp->packets_out + addend, 0);}",12692
382,241,CVE-2012-1601,23,"static int emulator_pio_out_emulated(struct x86_emulate_ctxt *ctxt,				     int size, unsigned short port,				     const void *val, unsigned int count){	struct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);	memcpy(vcpu->arch.pio_data, val, size * count);	return emulator_pio_in_out(vcpu, size, port, (void *)val, count, false);}",3719
93,1503,CVE-2013-0217,23,"void xen_netbk_unmap_frontend_rings(struct xenvif *vif){	if (vif->tx.sring)		xenbus_unmap_ring_vfree(xenvif_to_xenbus_device(vif),					vif->tx.sring);	if (vif->rx.sring)		xenbus_unmap_ring_vfree(xenvif_to_xenbus_device(vif),					vif->rx.sring);}",9800
607,1850,CVE-2014-3690,23,"static int handle_apic_eoi_induced(struct kvm_vcpu *vcpu){	unsigned long exit_qualification = vmcs_readl(EXIT_QUALIFICATION);	int vector = exit_qualification & 0xff;	 	kvm_apic_set_eoi_accelerated(vcpu, vector);	return 1;}",11038
3,2121,CVE-2012-6638,23,"static void tcp_undo_spur_to_response(struct sock *sk, int flag){	if (flag & FLAG_ECE)		tcp_ratehalving_spur_to_response(sk);	else		tcp_undo_cwr(sk, true);}",12755
4,411,CVE-2012-0058,23,static inline void aio_run_all_iocbs(struct kioctx *ctx){	spin_lock_irq(&ctx->ctx_lock);	while (__aio_run_iocbs(ctx))		;	spin_unlock_irq(&ctx->ctx_lock);},4151
416,2413,CVE-2015-8877,23,static double filter_bicubic(const double t){	const double abs_t = (double)fabs(t);	const double abs_t_sq = abs_t * abs_t;	if (abs_t<1) return 1-2*abs_t_sq+abs_t_sq*abs_t;	if (abs_t<2) return 4 - 8*abs_t +5*abs_t_sq - abs_t_sq*abs_t;	return 0;},18444
319,1227,CVE-2013-2141,23,static inline int is_si_special(const struct siginfo *info){	return info <= SEND_SIG_FORCED;},8833
75,2522,CVE-2019-11463,23,trad_enc_decrypt_byte(struct trad_enc_ctx *ctx){	unsigned temp = ctx->keys[2] | 2;	return (int)((temp * (temp ^ 1)) >> 8) & 0xff;},27131
48,849,CVE-2011-2918,23,static void perf_event__read_size(struct perf_event *event){	int entry = sizeof(u64);  	int size = 0;	int nr = 1;	if (event->attr.read_format & PERF_FORMAT_TOTAL_TIME_ENABLED)		size += sizeof(u64);	if (event->attr.read_format & PERF_FORMAT_TOTAL_TIME_RUNNING)		size += sizeof(u64);	if (event->attr.read_format & PERF_FORMAT_ID)		entry += sizeof(u64);	if (event->attr.read_format & PERF_FORMAT_GROUP) {		nr += event->group_leader->nr_siblings;		size += sizeof(u64);	}	size += entry * nr;	event->read_size = size;},6241
117,1903,CVE-2014-3690,23,"static int rmode_exception(struct kvm_vcpu *vcpu, int vec){	switch (vec) {	case BP_VECTOR:		 		to_vmx(vcpu)->vcpu.arch.event_exit_inst_len =			vmcs_read32(VM_EXIT_INSTRUCTION_LEN);		if (vcpu->guest_debug & KVM_GUESTDBG_USE_SW_BP)			return false;		 	case DB_VECTOR:		if (vcpu->guest_debug &			(KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))			return false;		 	case DE_VECTOR:	case OF_VECTOR:	case BR_VECTOR:	case UD_VECTOR:	case DF_VECTOR:	case SS_VECTOR:	case GP_VECTOR:	case MF_VECTOR:		return true;	break;	}	return false;}",11091
391,1005,CVE-2011-2918,23,"static inline void schedule_debug(struct task_struct *prev){	 	if (unlikely(in_atomic_preempt_off() && !prev->exit_state))		__schedule_bug(prev);	profile_hit(SCHED_PROFILING, __builtin_return_address(0));	schedstat_inc(this_rq(), sched_count);}",6397
408,1442,CVE-2013-1767,23,static inline struct mempolicy *shmem_get_sbmpol(struct shmem_sb_info *sbinfo){	return NULL;},9641
43,2054,CVE-2012-6638,23,"static void tcp_ack_saw_tstamp(struct sock *sk, int flag){	 	struct tcp_sock *tp = tcp_sk(sk);	tcp_valid_rtt_meas(sk, tcp_time_stamp - tp->rx_opt.rcv_tsecr);}",12688
577,2308,CVE-2016-7166,23,__archive_read_free_filters(struct archive_read *a){	while (a->filter != NULL) {		struct archive_read_filter *t = a->filter->upstream;		free(a->filter);		a->filter = t;	}},15819
444,1261,CVE-2013-2017,23,static void veth_setup(struct net_device *dev){	ether_setup(dev);	dev->netdev_ops = &veth_netdev_ops;	dev->ethtool_ops = &veth_ethtool_ops;	dev->features |= NETIF_F_LLTX;	dev->destructor = veth_dev_free;},8970
40,2347,CVE-2016-3156,23,static void devinet_sysctl_unregister(struct in_device *idev){},17316
41,444,CVE-2011-2918,23,"static inline unsigned long alpha_read_pmc(int idx){	unsigned long val;	val = wrperfmon(PERFMON_CMD_READ, 0);	val >>= alpha_pmu->pmc_count_shift[idx];	val &= alpha_pmu->pmc_count_mask[idx];	return val;}",5836
323,2009,CVE-2014-1444,23,"fst_init_dma(struct fst_card_info *card){	 	if (card->family == FST_FAMILY_TXU) {	        pci_set_master(card->device);		outl(0x00020441, card->pci_conf + DMAMODE0);		outl(0x00020441, card->pci_conf + DMAMODE1);		outl(0x0, card->pci_conf + DMATHR);	}}",12047
116,1403,CVE-2013-2015,23,"static inline int search_dirblock(struct buffer_head *bh,				  struct inode *dir,				  const struct qstr *d_name,				  unsigned int offset,				  struct ext4_dir_entry_2 **res_dir){	return search_dir(bh, bh->b_data, dir->i_sb->s_blocksize, dir,			  d_name, offset, res_dir);}",9112
253,633,CVE-2011-2918,23,"static int sparc_pmu_commit_txn(struct pmu *pmu){	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	int n;	if (!sparc_pmu)		return -EINVAL;	cpuc = &__get_cpu_var(cpu_hw_events);	n = cpuc->n_events;	if (check_excludes(cpuc->event, 0, n))		return -EINVAL;	if (sparc_check_constraints(cpuc->event, cpuc->events, n))		return -EAGAIN;	cpuc->group_flag &= ~PERF_EVENT_TXN;	perf_pmu_enable(pmu);	return 0;}",6025
552,1674,CVE-2014-8481,23,"static int pio_in_emulated(struct x86_emulate_ctxt *ctxt,			   unsigned int size, unsigned short port,			   void *dest){	struct read_cache *rc = &ctxt->io_read;	if (rc->pos == rc->end) {  		unsigned int in_page, n;		unsigned int count = ctxt->rep_prefix ?			address_mask(ctxt, reg_read(ctxt, VCPU_REGS_RCX)) : 1;		in_page = (ctxt->eflags & EFLG_DF) ?			offset_in_page(reg_read(ctxt, VCPU_REGS_RDI)) :			PAGE_SIZE - offset_in_page(reg_read(ctxt, VCPU_REGS_RDI));		n = min3(in_page, (unsigned int)sizeof(rc->data) / size, count);		if (n == 0)			n = 1;		rc->pos = rc->end = 0;		if (!ctxt->ops->pio_in_emulated(ctxt, size, port, rc->data, n))			return 0;		rc->end = n * size;	}	if (ctxt->rep_prefix && (ctxt->d & String) &&	    !(ctxt->eflags & EFLG_DF)) {		ctxt->dst.data = rc->data + rc->pos;		ctxt->dst.type = OP_MEM_STR;		ctxt->dst.count = (rc->end - rc->pos) / size;		rc->pos = rc->end;	} else {		memcpy(dest, rc->data + rc->pos, size);		rc->pos += size;	}	return 1;}",10445
231,355,CVE-2012-1601,23,static int valid_pat_type(unsigned t){	return t < 8 && (1 << t) & 0xf3;  },3833
8,1663,CVE-2014-8481,23,"int emulate_int_real(struct x86_emulate_ctxt *ctxt, int irq){	int rc;	invalidate_registers(ctxt);	rc = __emulate_int_real(ctxt, irq);	if (rc == X86EMUL_CONTINUE)		writeback_registers(ctxt);	return rc;}",10434
482,2665,CVE-2011-2918,23,"void ptrace_triggered(struct perf_event *bp, int nmi, 		      struct perf_sample_data *data, struct pt_regs *regs) { 	struct perf_event_attr attr;	 	attr = bp->attr;	attr.disabled = true;	modify_user_hw_breakpoint(bp, &attr);}",31008
486,1391,CVE-2013-2015,23,"struct ext4_dir_entry_2 *ext4_init_dot_dotdot(struct inode *inode,			  struct ext4_dir_entry_2 *de,			  int blocksize, int csum_size,			  unsigned int parent_ino, int dotdot_real_len){	de->inode = cpu_to_le32(inode->i_ino);	de->name_len = 1;	de->rec_len = ext4_rec_len_to_disk(EXT4_DIR_REC_LEN(de->name_len),					   blocksize);	strcpy(de->name, ""."");	ext4_set_de_type(inode->i_sb, de, S_IFDIR);	de = ext4_next_entry(de, blocksize);	de->inode = cpu_to_le32(parent_ino);	de->name_len = 2;	if (!dotdot_real_len)		de->rec_len = ext4_rec_len_to_disk(blocksize -					(csum_size + EXT4_DIR_REC_LEN(1)),					blocksize);	else		de->rec_len = ext4_rec_len_to_disk(				EXT4_DIR_REC_LEN(de->name_len), blocksize);	strcpy(de->name, "".."");	ext4_set_de_type(inode->i_sb, de, S_IFDIR);	return ext4_next_entry(de, blocksize);}",9100
108,667,CVE-2011-2918,23,"static inline unsigned int *fps_regaddr(struct fpustate *f,					unsigned int insn_regnum){	return &f->regs[insn_regnum];}",6059
564,1362,CVE-2013-2017,23,void skb_gro_reset_offset(struct sk_buff *skb){	NAPI_GRO_CB(skb)->data_offset = 0;	NAPI_GRO_CB(skb)->frag0 = NULL;	NAPI_GRO_CB(skb)->frag0_len = 0;	if (skb->mac_header == skb->tail &&	    !PageHighMem(skb_shinfo(skb)->frags[0].page)) {		NAPI_GRO_CB(skb)->frag0 =			page_address(skb_shinfo(skb)->frags[0].page) +			skb_shinfo(skb)->frags[0].page_offset;		NAPI_GRO_CB(skb)->frag0_len = skb_shinfo(skb)->frags[0].size;	}},9071
647,2064,CVE-2012-6638,23,static void tcp_clear_retrans_partial(struct tcp_sock *tp){	tp->retrans_out = 0;	tp->lost_out = 0;	tp->undo_marker = 0;	tp->undo_retrans = 0;},12698
670,1469,CVE-2013-0281,23,"pick_ipc_type(enum qb_ipc_type requested){    const char *env = getenv(""PCMK_ipc_type"");    if(env && strcmp(""shared-mem"", env) == 0) {        return QB_IPC_SHM;    } else if(env && strcmp(""socket"", env) == 0) {        return QB_IPC_SOCKET;    } else if(env && strcmp(""posix"", env) == 0) {        return QB_IPC_POSIX_MQ;    } else if(env && strcmp(""sysv"", env) == 0) {        return QB_IPC_SYSV_MQ;    } else if(requested == QB_IPC_NATIVE) {                 return QB_IPC_SOCKET;    }    return requested;}",9765
664,575,CVE-2011-2918,23,"void do_reserved_inst(unsigned long error_code, struct pt_regs *regs){	 	unsigned long opcode = 0x6ff4fff0;  	unsigned long pc, aligned_pc;	int get_user_error;	int trapnr = 12;	int signr = SIGILL;	char *exception_name = ""reserved_instruction"";	pc = regs->pc;	if ((pc & 3) == 1) {		 		aligned_pc = pc & ~3;		if (!access_ok(VERIFY_READ, aligned_pc, sizeof(unsigned long))) {			get_user_error = -EFAULT;		} else {			get_user_error = __get_user(opcode, (unsigned long *)aligned_pc);		}		if (get_user_error >= 0) {			unsigned long index, shift;			unsigned long major, minor, combined;			unsigned long reserved_field;			reserved_field = opcode & 0xf;  			major = (opcode >> 26) & 0x3f;			minor = (opcode >> 16) & 0xf;			combined = (major << 4) | minor;			index = major;			shift = minor << 1;			if (reserved_field == 0) {				int opcode_state = (shmedia_opcode_table[index] >> shift) & 0x3;				switch (opcode_state) {					case OPCODE_INVALID:						 						break;					case OPCODE_USER_VALID:						 						return;					case OPCODE_PRIV_VALID:						if (!user_mode(regs)) {							 							return;  						}						 						break;					case OPCODE_CTRL_REG:						 						if (!user_mode(regs)) return;						 						if (combined == 0x9f) {  							unsigned long regno = (opcode >> 20) & 0x3f;							if (regno >= 62) {								return;							}							 						} else if (combined == 0x1bf) {  							unsigned long regno = (opcode >> 4) & 0x3f;							if (regno >= 62) {								return;							}							 						} else {							 						}						break;					default:						 						break;				}			}			 		} else {			 			trapnr = 87;			exception_name = ""address error (exec)"";			signr = SIGSEGV;		}	}	do_unhandled_exception(trapnr, signr, exception_name, ""do_reserved_inst"", error_code, regs, current);}",5967
252,1468,CVE-2013-0281,23,"gio_poll_dispatch_del(int fd){    struct gio_to_qb_poll *adaptor;    crm_trace(""Looking for fd=%d"", fd);    if (qb_array_index(gio_map, fd, (void**)&adaptor) == 0) {        crm_trace(""Marking adaptor %p unused (ref=%d)"", adaptor, gio_adapter_refcount(adaptor));        adaptor->is_used = QB_FALSE;    }    return 0;}",9764
170,1833,CVE-2014-3690,23,"static void enter_pmode(struct kvm_vcpu *vcpu){	unsigned long flags;	struct vcpu_vmx *vmx = to_vmx(vcpu);	 	vmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_ES], VCPU_SREG_ES);	vmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_DS], VCPU_SREG_DS);	vmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_FS], VCPU_SREG_FS);	vmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_GS], VCPU_SREG_GS);	vmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_SS], VCPU_SREG_SS);	vmx_get_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_CS], VCPU_SREG_CS);	vmx->rmode.vm86_active = 0;	vmx_segment_cache_clear(vmx);	vmx_set_segment(vcpu, &vmx->rmode.segs[VCPU_SREG_TR], VCPU_SREG_TR);	flags = vmcs_readl(GUEST_RFLAGS);	flags &= RMODE_GUEST_OWNED_EFLAGS_BITS;	flags |= vmx->rmode.save_rflags & ~RMODE_GUEST_OWNED_EFLAGS_BITS;	vmcs_writel(GUEST_RFLAGS, flags);	vmcs_writel(GUEST_CR4, (vmcs_readl(GUEST_CR4) & ~X86_CR4_VME) |			(vmcs_readl(CR4_READ_SHADOW) & X86_CR4_VME));	update_exception_bitmap(vcpu);	fix_pmode_seg(vcpu, VCPU_SREG_CS, &vmx->rmode.segs[VCPU_SREG_CS]);	fix_pmode_seg(vcpu, VCPU_SREG_SS, &vmx->rmode.segs[VCPU_SREG_SS]);	fix_pmode_seg(vcpu, VCPU_SREG_ES, &vmx->rmode.segs[VCPU_SREG_ES]);	fix_pmode_seg(vcpu, VCPU_SREG_DS, &vmx->rmode.segs[VCPU_SREG_DS]);	fix_pmode_seg(vcpu, VCPU_SREG_FS, &vmx->rmode.segs[VCPU_SREG_FS]);	fix_pmode_seg(vcpu, VCPU_SREG_GS, &vmx->rmode.segs[VCPU_SREG_GS]);}",11021
7,1610,CVE-2011-2491,23,"static void rpc_wake_up_task_queue_locked(struct rpc_wait_queue *queue, struct rpc_task *task){	if (RPC_IS_QUEUED(task) && task->tk_waitqueue == queue)		__rpc_do_wake_up_task(queue, task);}",10229
673,70,CVE-2012-4467,23,"int kernel_bind(struct socket *sock, struct sockaddr *addr, int addrlen){	return sock->ops->bind(sock, addr, addrlen);}",2738
424,1493,CVE-2013-0217,23,"void xen_netbk_check_rx_xenvif(struct xenvif *vif){	int more_to_do;	RING_FINAL_CHECK_FOR_REQUESTS(&vif->tx, more_to_do);	if (more_to_do)		xen_netbk_schedule_xenvif(vif);}",9790
329,2549,CVE-2012-2888,23,  void PrintEnd() {    if (ppp_printing_ != NULL)      ppp_printing_->End(plugin_->pp_instance());  },29181
601,2586,CVE-2013-2909,23,    void setFirstLine(int firstLine) { m_isFirstLine = firstLine; },29375
515,1043,CVE-2011-0716,23,void br_multicast_del_port(struct net_bridge_port *port){	del_timer_sync(&port->multicast_router_timer);},6981
464,148,CVE-2012-2133,23,static inline int hugetlbfs_dec_free_inodes(struct hugetlbfs_sb_info *sbinfo){	if (sbinfo->free_inodes >= 0) {		spin_lock(&sbinfo->stat_lock);		if (unlikely(!sbinfo->free_inodes)) {			spin_unlock(&sbinfo->stat_lock);			return 0;		}		sbinfo->free_inodes--;		spin_unlock(&sbinfo->stat_lock);	}	return 1;},3492
266,617,CVE-2011-2918,23,"void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page){	unsigned long flags;	if (vma->vm_mm) {		page &= PAGE_MASK;		local_irq_save(flags);		local_flush_tlb_one(get_asid(), page);		local_irq_restore(flags);	}}",6009
31,20,CVE-2010-4352,23,"simple_method_return (void){  DBusMessage *message;  message =  dbus_message_new (DBUS_MESSAGE_TYPE_METHOD_RETURN);  if (message == NULL)    _dbus_assert_not_reached (""oom"");  set_reply_serial (message);    return message;}",1231
135,1856,CVE-2014-3690,23,"static int handle_invlpg(struct kvm_vcpu *vcpu){	unsigned long exit_qualification = vmcs_readl(EXIT_QUALIFICATION);	kvm_mmu_invlpg(vcpu, exit_qualification);	skip_emulated_instruction(vcpu);	return 1;}",11044
570,2617,CVE-2014-1742,23,  MyData() {},29551
332,516,CVE-2011-2918,23,"static void mipspmu_start(struct perf_event *event, int flags){	struct hw_perf_event *hwc = &event->hw;	if (!mipspmu)		return;	if (flags & PERF_EF_RELOAD)		WARN_ON_ONCE(!(hwc->state & PERF_HES_UPTODATE));	hwc->state = 0;	 	mipspmu_event_set_period(event, hwc, hwc->idx);	 	mipspmu->enable_event(hwc, hwc->idx);}",5908
15,2052,CVE-2012-6638,23,"static inline int tcp_ack_is_dubious(const struct sock *sk, const int flag){	return !(flag & FLAG_NOT_DUP) || (flag & FLAG_CA_ALERT) ||		inet_csk(sk)->icsk_ca_state != TCP_CA_Open;}",12686
321,77,CVE-2012-4467,23,"static struct socket *sock_alloc(void){	struct inode *inode;	struct socket *sock;	inode = new_inode_pseudo(sock_mnt->mnt_sb);	if (!inode)		return NULL;	sock = SOCKET_I(inode);	kmemcheck_annotate_bitfield(sock, type);	inode->i_ino = get_next_ino();	inode->i_mode = S_IFSOCK | S_IRWXUGO;	inode->i_uid = current_fsuid();	inode->i_gid = current_fsgid();	this_cpu_add(sockets_in_use, 1);	return sock;}",2745
636,505,CVE-2011-2918,23,"static inline int notify_page_fault(struct pt_regs *regs, unsigned int fsr){	return 0;}",5897
393,1650,CVE-2014-8481,23,"static int em_loop(struct x86_emulate_ctxt *ctxt){	int rc = X86EMUL_CONTINUE;	register_address_increment(ctxt, reg_rmw(ctxt, VCPU_REGS_RCX), -1);	if ((address_mask(ctxt, reg_read(ctxt, VCPU_REGS_RCX)) != 0) &&	    (ctxt->b == 0xe2 || test_cc(ctxt->b ^ 0x5, ctxt->eflags)))		rc = jmp_rel(ctxt, ctxt->src.val);	return rc;}",10421
38,2669,CVE-2011-2918,23,"static void ptrace_triggered(struct perf_event *bp, int nmi, 			     struct perf_sample_data *data, 			     struct pt_regs *regs) {	int i;	struct thread_struct *thread = &(current->thread);	 	for (i = 0; i < HBP_NUM; i++) {		if (thread->ptrace_bps[i] == bp)			break;	}	thread->debugreg6 |= (DR_TRAP0 << i);}",31012
275,629,CVE-2011-2918,23,"void perf_event_release_pmc(void){	if (atomic_dec_and_mutex_lock(&active_events, &pmc_grab_mutex)) {		if (atomic_read(&nmi_active) == 0)			on_each_cpu(start_nmi_watchdog, NULL, 1);		mutex_unlock(&pmc_grab_mutex);	}}",6021
232,2299,CVE-2014-9428,23,"void batadv_frag_purge_orig(struct batadv_orig_node *orig_node,			    int (*check_cb)(struct batadv_frag_table_entry *)){	struct batadv_frag_table_entry *chain;	int i;	for (i = 0; i < BATADV_FRAG_BUFFER_COUNT; i++) {		chain = &orig_node->fragments[i];		spin_lock_bh(&orig_node->fragments[i].lock);		if (!check_cb || check_cb(chain)) {			batadv_frag_clear_chain(&orig_node->fragments[i].head);			orig_node->fragments[i].size = 0;		}		spin_unlock_bh(&orig_node->fragments[i].lock);	}}",14482
390,1300,CVE-2013-2017,23,"static int dev_gso_segment(struct sk_buff *skb){	struct net_device *dev = skb->dev;	struct sk_buff *segs;	int features = dev->features & ~(illegal_highdma(dev, skb) ?					 NETIF_F_SG : 0);	segs = skb_gso_segment(skb, features);	 	if (!segs)		return 0;	if (IS_ERR(segs))		return PTR_ERR(segs);	skb->next = segs;	DEV_GSO_CB(skb)->destructor = skb->destructor;	skb->destructor = dev_gso_skb_destructor;	return 0;}",9009
418,257,CVE-2012-1601,23,"static void inject_pending_event(struct kvm_vcpu *vcpu){	 	if (vcpu->arch.exception.pending) {		trace_kvm_inj_exception(vcpu->arch.exception.nr,					vcpu->arch.exception.has_error_code,					vcpu->arch.exception.error_code);		kvm_x86_ops->queue_exception(vcpu, vcpu->arch.exception.nr,					  vcpu->arch.exception.has_error_code,					  vcpu->arch.exception.error_code,					  vcpu->arch.exception.reinject);		return;	}	if (vcpu->arch.nmi_injected) {		kvm_x86_ops->set_nmi(vcpu);		return;	}	if (vcpu->arch.interrupt.pending) {		kvm_x86_ops->set_irq(vcpu);		return;	}	 	if (vcpu->arch.nmi_pending) {		if (kvm_x86_ops->nmi_allowed(vcpu)) {			--vcpu->arch.nmi_pending;			vcpu->arch.nmi_injected = true;			kvm_x86_ops->set_nmi(vcpu);		}	} else if (kvm_cpu_has_interrupt(vcpu)) {		if (kvm_x86_ops->interrupt_allowed(vcpu)) {			kvm_queue_interrupt(vcpu, kvm_cpu_get_interrupt(vcpu),					    false);			kvm_x86_ops->set_irq(vcpu);		}	}}",3735
246,2301,CVE-2014-9428,23,"int batadv_frag_skb_buffer(struct sk_buff **skb,			    struct batadv_orig_node *orig_node_src){	struct sk_buff *skb_out = NULL;	struct hlist_head head = HLIST_HEAD_INIT;	int ret = false;	 	if (!batadv_frag_insert_packet(orig_node_src, *skb, &head))		goto out_err;	 	if (hlist_empty(&head))		goto out;	skb_out = batadv_frag_merge_packets(&head, *skb);	if (!skb_out)		goto out_err;out:	*skb = skb_out;	ret = true;out_err:	return ret;}",14484
543,249,CVE-2012-1601,23,static int exception_class(int vector){	switch (vector) {	case PF_VECTOR:		return EXCPT_PF;	case DE_VECTOR:	case TS_VECTOR:	case NP_VECTOR:	case SS_VECTOR:	case GP_VECTOR:		return EXCPT_CONTRIBUTORY;	default:		break;	}	return EXCPT_BENIGN;},3727
665,2204,CVE-2015-5307,23,static inline int cpu_has_vmx_posted_intr(void){	return IS_ENABLED(CONFIG_X86_LOCAL_APIC) &&		vmcs_config.pin_based_exec_ctrl & PIN_BASED_POSTED_INTR;},13326
417,322,CVE-2012-1601,23,"static void kvm_shared_msr_cpu_online(void){	unsigned i;	for (i = 0; i < shared_msrs_global.nr; ++i)		shared_msr_update(i, shared_msrs_global.msrs[i]);}",3800
129,1189,CVE-2013-2635,23,int rtnl_is_locked(void){	return mutex_is_locked(&rtnl_mutex);},8527
611,1817,CVE-2014-3690,23,static inline int cpu_has_vmx_posted_intr(void){	return vmcs_config.pin_based_exec_ctrl & PIN_BASED_POSTED_INTR;},11005
280,893,CVE-2011-2918,23,static inline void perf_put_cgroup(struct perf_event *event){	css_put(&event->cgrp->css);},6285
594,1908,CVE-2014-3690,23,"static void update_cr8_intercept(struct kvm_vcpu *vcpu, int tpr, int irr){	struct vmcs12 *vmcs12 = get_vmcs12(vcpu);	if (is_guest_mode(vcpu) &&		nested_cpu_has(vmcs12, CPU_BASED_TPR_SHADOW))		return;	if (irr == -1 || tpr < irr) {		vmcs_write32(TPR_THRESHOLD, 0);		return;	}	vmcs_write32(TPR_THRESHOLD, irr);}",11096
215,2172,CVE-2015-6252,23,"int vhost_poll_start(struct vhost_poll *poll, struct file *file){	unsigned long mask;	int ret = 0;	if (poll->wqh)		return 0;	mask = file->f_op->poll(file, &poll->table);	if (mask)		vhost_poll_wakeup(&poll->wait, 0, 0, (void *)mask);	if (mask & POLLERR) {		if (poll->wqh)			remove_wait_queue(poll->wqh, &poll->wait);		ret = -EINVAL;	}	return ret;}",13150
114,1065,CVE-2013-5634,23,static void check_kvm_target_cpu(void *ret){	*(int *)ret = kvm_target_cpu();},7469
497,2211,CVE-2015-5307,23,static void free_nested(struct vcpu_vmx *vmx){	if (!vmx->nested.vmxon)		return;	vmx->nested.vmxon = false;	free_vpid(vmx->nested.vpid02);	nested_release_vmcs12(vmx);	if (enable_shadow_vmcs)		free_vmcs(vmx->nested.current_shadow_vmcs);	 	if (vmx->nested.apic_access_page) {		nested_release_page(vmx->nested.apic_access_page);		vmx->nested.apic_access_page = NULL;	}	if (vmx->nested.virtual_apic_page) {		nested_release_page(vmx->nested.virtual_apic_page);		vmx->nested.virtual_apic_page = NULL;	}	if (vmx->nested.pi_desc_page) {		kunmap(vmx->nested.pi_desc_page);		nested_release_page(vmx->nested.pi_desc_page);		vmx->nested.pi_desc_page = NULL;		vmx->nested.pi_desc = NULL;	}	nested_free_all_saved_vmcss(vmx);},13333
613,2147,CVE-2015-6526,23,"static int is_sigreturn_64_address(unsigned long nip, unsigned long fp){	if (nip == fp + offsetof(struct signal_frame_64, tramp))		return 1;	if (vdso64_rt_sigtramp && current->mm->context.vdso_base &&	    nip == current->mm->context.vdso_base + vdso64_rt_sigtramp)		return 1;	return 0;}",13119
264,911,CVE-2011-2918,23,"static void perf_unpin_context(struct perf_event_context *ctx){	unsigned long flags;	raw_spin_lock_irqsave(&ctx->lock, flags);	--ctx->pin_count;	raw_spin_unlock_irqrestore(&ctx->lock, flags);}",6303
214,1510,CVE-2011-4087,23,"static int br_nf_pre_routing_finish(struct sk_buff *skb){	struct net_device *dev = skb->dev;	struct iphdr *iph = ip_hdr(skb);	struct nf_bridge_info *nf_bridge = skb->nf_bridge;	struct rtable *rt;	int err;	if (nf_bridge->mask & BRNF_PKT_TYPE) {		skb->pkt_type = PACKET_OTHERHOST;		nf_bridge->mask ^= BRNF_PKT_TYPE;	}	nf_bridge->mask ^= BRNF_NF_BRIDGE_PREROUTING;	if (dnat_took_place(skb)) {		if ((err = ip_route_input(skb, iph->daddr, iph->saddr, iph->tos, dev))) {			struct in_device *in_dev = __in_dev_get_rcu(dev);			 			if (err != -EHOSTUNREACH || !in_dev || IN_DEV_FORWARD(in_dev))				goto free_skb;			rt = ip_route_output(dev_net(dev), iph->daddr, 0,					     RT_TOS(iph->tos), 0);			if (!IS_ERR(rt)) {				 				if (rt->dst.dev == dev) {					skb_dst_set(skb, &rt->dst);					goto bridged_dnat;				}				ip_rt_put(rt);			}free_skb:			kfree_skb(skb);			return 0;		} else {			if (skb_dst(skb)->dev == dev) {bridged_dnat:				skb->dev = nf_bridge->physindev;				nf_bridge_update_protocol(skb);				nf_bridge_push_encap_header(skb);				NF_HOOK_THRESH(NFPROTO_BRIDGE,					       NF_BR_PRE_ROUTING,					       skb, skb->dev, NULL,					       br_nf_pre_routing_finish_bridge,					       1);				return 0;			}			memcpy(eth_hdr(skb)->h_dest, dev->dev_addr, ETH_ALEN);			skb->pkt_type = PACKET_HOST;		}	} else {		rt = bridge_parent_rtable(nf_bridge->physindev);		if (!rt) {			kfree_skb(skb);			return 0;		}		skb_dst_set_noref(skb, &rt->dst);	}	skb->dev = nf_bridge->physindev;	nf_bridge_update_protocol(skb);	nf_bridge_push_encap_header(skb);	NF_HOOK_THRESH(NFPROTO_BRIDGE, NF_BR_PRE_ROUTING, skb, skb->dev, NULL,		       br_handle_frame_finish, 1);	return 0;}",10076
433,652,CVE-2011-2918,23,static inline int sign_extend_imm13(int imm){	return imm << 19 >> 19;},6044
518,2474,CVE-2016-10153,23,static void ceph_key_destroy(struct key *key){	struct ceph_crypto_key *ckey = key->payload.data[0];	ceph_crypto_key_destroy(ckey);	kfree(ckey);},22489
529,945,CVE-2011-2918,23,"perf_mmap_to_page(struct ring_buffer *rb, unsigned long pgoff){	if (pgoff > (1UL << page_order(rb)))		return NULL;	return vmalloc_to_page((void *)rb->user_page + pgoff * PAGE_SIZE);}",6337
225,2704,CVE-2015-8104,23,"static void update_db_bp_intercept(struct kvm_vcpu *vcpu) { 	struct vcpu_svm *svm = to_svm(vcpu); 	clr_exception_intercept(svm, DB_VECTOR); 	clr_exception_intercept(svm, BP_VECTOR); 	if (svm->nmi_singlestep)		set_exception_intercept(svm, DB_VECTOR); 	if (vcpu->guest_debug & KVM_GUESTDBG_ENABLE) {		if (vcpu->guest_debug &		    (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))			set_exception_intercept(svm, DB_VECTOR); 		if (vcpu->guest_debug & KVM_GUESTDBG_USE_SW_BP) 			set_exception_intercept(svm, BP_VECTOR); 	} else		vcpu->guest_debug = 0;}",31186
158,688,CVE-2011-2918,23,unsigned long perf_misc_flags(struct pt_regs *regs){	int misc = 0;	if (perf_guest_cbs && perf_guest_cbs->is_in_guest()) {		if (perf_guest_cbs->is_user_mode())			misc |= PERF_RECORD_MISC_GUEST_USER;		else			misc |= PERF_RECORD_MISC_GUEST_KERNEL;	} else {		if (user_mode(regs))			misc |= PERF_RECORD_MISC_USER;		else			misc |= PERF_RECORD_MISC_KERNEL;	}	if (regs->flags & PERF_EFLAGS_EXACT)		misc |= PERF_RECORD_MISC_EXACT_IP;	return misc;},6080
199,2416,CVE-2015-8877,23,"static double filter_bspline(const double x){	if (x>2.0f) {		return 0.0f;	} else {		double a, b, c, d;		 		const double xm1 = x - 1.0f;		const double xp1 = x + 1.0f;		const double xp2 = x + 2.0f;		if ((xp2) <= 0.0f) a = 0.0f; else a = xp2*xp2*xp2;		if ((xp1) <= 0.0f) b = 0.0f; else b = xp1*xp1*xp1;		if (x <= 0) c = 0.0f; else c = x*x*x;		if ((xm1) <= 0.0f) d = 0.0f; else d = xm1*xm1*xm1;		return (0.16666666666666666667f * (a - (4.0f * b) + (6.0f * c) - (4.0f * d)));	}}",18447
106,2442,CVE-2015-8785,23,static inline unsigned long fuse_get_user_addr(const struct iov_iter *ii){	return (unsigned long)ii->iov->iov_base + ii->iov_offset;},18715
658,885,CVE-2011-2918,23,void perf_pmu_disable(struct pmu *pmu){	int *count = this_cpu_ptr(pmu->pmu_disable_count);	if (!(*count)++)		pmu->pmu_disable(pmu);},6277
439,345,CVE-2012-1601,23,"static int kvmclock_cpu_notifier(struct notifier_block *nfb,					unsigned long action, void *hcpu){	unsigned int cpu = (unsigned long)hcpu;	switch (action) {		case CPU_ONLINE:		case CPU_DOWN_FAILED:			smp_call_function_single(cpu, tsc_khz_changed, NULL, 1);			break;		case CPU_DOWN_PREPARE:			smp_call_function_single(cpu, tsc_bad, NULL, 1);			break;	}	return NOTIFY_OK;}",3823
440,1517,CVE-2011-4087,23,"static inline void nf_bridge_pull_encap_header(struct sk_buff *skb){	unsigned int len = nf_bridge_encap_header_len(skb);	skb_pull(skb, len);	skb->network_header += len;}",10083
561,1298,CVE-2013-2017,23,"static int dev_get_valid_name(struct net *net, const char *name, char *buf,			      int fmt){	if (!dev_valid_name(name))		return -EINVAL;	if (fmt && strchr(name, '%'))		return __dev_alloc_name(net, name, buf);	else if (__dev_get_by_name(net, name))		return -EEXIST;	else if (buf != name)		strlcpy(buf, name, IFNAMSIZ);	return 0;}",9007
480,732,CVE-2011-2918,23,static void intel_pmu_disable_bts(void){	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	unsigned long debugctlmsr;	if (!cpuc->ds)		return;	debugctlmsr = get_debugctlmsr();	debugctlmsr &=		~(DEBUGCTLMSR_TR | DEBUGCTLMSR_BTS | DEBUGCTLMSR_BTINT |		  DEBUGCTLMSR_BTS_OFF_OS | DEBUGCTLMSR_BTS_OFF_USR);	update_debugctlmsr(debugctlmsr);},6124
120,1760,CVE-2014-6418,23,"static int ceph_x_update_authorizer(	struct ceph_auth_client *ac, int peer_type,	struct ceph_auth_handshake *auth){	struct ceph_x_authorizer *au;	struct ceph_x_ticket_handler *th;	th = get_ticket_handler(ac, peer_type);	if (IS_ERR(th))		return PTR_ERR(th);	au = (struct ceph_x_authorizer *)auth->authorizer;	if (au->secret_id < th->secret_id) {		dout(""ceph_x_update_authorizer service %u secret %llu < %llu\n"",		     au->service, au->secret_id, th->secret_id);		return ceph_x_build_authorizer(ac, th, au);	}	return 0;}",10584
137,2490,CVE-2019-15921,23,static void genl_lock_all(void){	down_write(&cb_lock);	genl_lock();},26563
90,1550,CVE-2011-2491,23,"rpc_call_async(struct rpc_clnt *clnt, const struct rpc_message *msg, int flags,	       const struct rpc_call_ops *tk_ops, void *data){	struct rpc_task	*task;	struct rpc_task_setup task_setup_data = {		.rpc_client = clnt,		.rpc_message = msg,		.callback_ops = tk_ops,		.callback_data = data,		.flags = flags|RPC_TASK_ASYNC,	};	task = rpc_run_task(&task_setup_data);	if (IS_ERR(task))		return PTR_ERR(task);	rpc_put_task(task);	return 0;}",10169
540,2409,CVE-2015-8877,23,"static double KernelBessel_Q1(const double x){	double p, q;	register long i;	static const double	Pone[] =	{		0.3511751914303552822533318e+3,		0.7210391804904475039280863e+3,		0.4259873011654442389886993e+3,		0.831898957673850827325226e+2,		0.45681716295512267064405e+1,		0.3532840052740123642735e-1	},	Qone[] =	{		0.74917374171809127714519505e+4,		0.154141773392650970499848051e+5,		0.91522317015169922705904727e+4,		0.18111867005523513506724158e+4,		0.1038187585462133728776636e+3,		0.1e+1	};	p = Pone[5];	q = Qone[5];	for (i=4; i >= 0; i--)	{		p = p*(8.0/x)*(8.0/x)+Pone[i];		q = q*(8.0/x)*(8.0/x)+Qone[i];	}	return (double)(p/q);}",18440
286,269,CVE-2012-1601,23,int kvm_arch_hardware_setup(void){	return kvm_x86_ops->hardware_setup();},3747
331,998,CVE-2011-2918,23,"static void rq_attach_root(struct rq *rq, struct root_domain *rd){	struct root_domain *old_rd = NULL;	unsigned long flags;	raw_spin_lock_irqsave(&rq->lock, flags);	if (rq->rd) {		old_rd = rq->rd;		if (cpumask_test_cpu(rq->cpu, old_rd->online))			set_rq_offline(rq);		cpumask_clear_cpu(rq->cpu, old_rd->span);		 		if (!atomic_dec_and_test(&old_rd->refcount))			old_rd = NULL;	}	atomic_inc(&rd->refcount);	rq->rd = rd;	cpumask_set_cpu(rq->cpu, rd->span);	if (cpumask_test_cpu(rq->cpu, cpu_active_mask))		set_rq_online(rq);	raw_spin_unlock_irqrestore(&rq->lock, flags);	if (old_rd)		call_rcu_sched(&old_rd->rcu, free_rootdomain);}",6390
632,847,CVE-2011-2918,23,static inline void perf_detach_cgroup(struct perf_event *event){},6239
395,798,CVE-2011-2918,23,"__perf_event_exit_task(struct perf_event *child_event,			 struct perf_event_context *child_ctx,			 struct task_struct *child){	if (child_event->parent) {		raw_spin_lock_irq(&child_ctx->lock);		perf_group_detach(child_event);		raw_spin_unlock_irq(&child_ctx->lock);	}	perf_remove_from_context(child_event);	 	if (child_event->parent) {		sync_child_event(child_event, child);		free_event(child_event);	}}",6190
248,2256,CVE-2015-5307,23,"static void vmx_dump_sel(char *name, int sel){	pr_err(""%s sel=0x%04x, attr=0x%05x, limit=0x%08x, base=0x%016lx\n"",	       name, vmcs_read32(sel),	       vmcs_read32(sel + GUEST_ES_AR_BYTES - GUEST_ES_SELECTOR),	       vmcs_read32(sel + GUEST_ES_LIMIT - GUEST_ES_SELECTOR),	       vmcs_readl(sel + GUEST_ES_BASE - GUEST_ES_SELECTOR));}",13378
521,300,CVE-2012-1601,23,unsigned long kvm_get_rflags(struct kvm_vcpu *vcpu){	unsigned long rflags;	rflags = kvm_x86_ops->get_rflags(vcpu);	if (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)		rflags &= ~X86_EFLAGS_TF;	return rflags;},3778
431,2258,CVE-2015-5307,23,"static void vmx_flush_tlb(struct kvm_vcpu *vcpu){	__vmx_flush_tlb(vcpu, to_vmx(vcpu)->vpid);}",13380
322,2216,CVE-2015-5307,23,"static int handle_pml_full(struct kvm_vcpu *vcpu){	unsigned long exit_qualification;	trace_kvm_pml_full(vcpu->vcpu_id);	exit_qualification = vmcs_readl(EXIT_QUALIFICATION);	 	if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&			cpu_has_virtual_nmis() &&			(exit_qualification & INTR_INFO_UNBLOCK_NMI))		vmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO,				GUEST_INTR_STATE_NMI);	 	return 1;}",13338
257,34,CVE-2016-4008,23,"_asn1_get_time_der (unsigned type, const unsigned char *der, int der_len, int *ret_len,		    char *str, int str_size, unsigned flags){  int len_len, str_len;  unsigned i;  unsigned sign_count = 0;  unsigned dot_count = 0;  const unsigned char *p;  if (der_len <= 0 || str == NULL)    return ASN1_DER_ERROR;  str_len = asn1_get_length_der (der, der_len, &len_len);  if (str_len <= 0 || str_size < str_len)    return ASN1_DER_ERROR;     if (str_len < 8)    {      warn();      return ASN1_DER_ERROR;    }  if (flags & ASN1_DECODE_FLAG_STRICT_DER)    {      p = &der[len_len];      for (i=0;i<(unsigned)(str_len-1);i++)         {           if (isdigit(p[i]) == 0)             {               if (type == ASN1_ETYPE_GENERALIZED_TIME)                 {                                       if (p[i] == '.' && dot_count == 0)                     {                       dot_count++;                       continue;                     }                                   if (!(flags & ASN1_DECODE_FLAG_STRICT_DER) &&                       (p[i] == '+' || p[i] == '-') && sign_count == 0)                     {                       sign_count++;                       continue;                     }                 }               warn();               return ASN1_DER_ERROR;             }         }      if (sign_count == 0 && p[str_len-1] != 'Z')        {          warn();          return ASN1_DER_ERROR;        }    }  memcpy (str, der + len_len, str_len);  str[str_len] = 0;  *ret_len = str_len + len_len;  return ASN1_SUCCESS;}",1958
167,2332,CVE-2016-7166,23,"choose_format(struct archive_read *a){	int slots;	int i;	int bid, best_bid;	int best_bid_slot;	slots = sizeof(a->formats) / sizeof(a->formats[0]);	best_bid = -1;	best_bid_slot = -1;	 	a->format = &(a->formats[0]);	for (i = 0; i < slots; i++, a->format++) {		if (a->format->bid) {			bid = (a->format->bid)(a, best_bid);			if (bid == ARCHIVE_FATAL)				return (ARCHIVE_FATAL);			if (a->filter->position != 0)				__archive_read_seek(a, 0, SEEK_SET);			if ((bid > best_bid) || (best_bid_slot < 0)) {				best_bid = bid;				best_bid_slot = i;			}		}	}	 	if (best_bid_slot < 0) {		archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,		    ""No formats registered"");		return (ARCHIVE_FATAL);	}	 	if (best_bid < 1) {		archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,		    ""Unrecognized archive format"");		return (ARCHIVE_FATAL);	}	return (best_bid_slot);}",15843
12,1697,CVE-2014-7841,23,"void *sctp_addto_chunk(struct sctp_chunk *chunk, int len, const void *data){	void *target;	void *padding;	int chunklen = ntohs(chunk->chunk_hdr->length);	int padlen = WORD_ROUND(chunklen) - chunklen;	padding = skb_put(chunk->skb, padlen);	target = skb_put(chunk->skb, len);	memset(padding, 0, padlen);	memcpy(target, data, len);	 	chunk->chunk_hdr->length = htons(chunklen + padlen + len);	chunk->chunk_end = skb_tail_pointer(chunk->skb);	return target;}",10505
227,2584,CVE-2013-2909,23,    void setCheckForFloatsFromLastLine(int check) { m_checkForFloatsFromLastLine = check; },29373
293,1406,CVE-2013-1797,23,"static int complete_emulated_mmio(struct kvm_vcpu *vcpu){	struct kvm_run *run = vcpu->run;	struct kvm_mmio_fragment *frag;	unsigned len;	BUG_ON(!vcpu->mmio_needed);	 	frag = &vcpu->mmio_fragments[vcpu->mmio_cur_fragment];	len = min(8u, frag->len);	if (!vcpu->mmio_is_write)		memcpy(frag->data, run->mmio.data, len);	if (frag->len <= 8) {		 		frag++;		vcpu->mmio_cur_fragment++;	} else {		 		frag->data += len;		frag->gpa += len;		frag->len -= len;	}	if (vcpu->mmio_cur_fragment == vcpu->mmio_nr_fragments) {		vcpu->mmio_needed = 0;		if (vcpu->mmio_is_write)			return 1;		vcpu->mmio_read_completed = 1;		return complete_emulated_io(vcpu);	}	run->exit_reason = KVM_EXIT_MMIO;	run->mmio.phys_addr = frag->gpa;	if (vcpu->mmio_is_write)		memcpy(run->mmio.data, frag->data, min(8u, frag->len));	run->mmio.len = min(8u, frag->len);	run->mmio.is_write = vcpu->mmio_is_write;	vcpu->arch.complete_userspace_io = complete_emulated_mmio;	return 0;}",9505
437,365,CVE-2012-1583,23,static int xfrm6_tunnel_init_state(struct xfrm_state *x){	if (x->props.mode != XFRM_MODE_TUNNEL)		return -EINVAL;	if (x->encap)		return -EINVAL;	x->props.header_len = sizeof(struct ipv6hdr);	return 0;},3843
649,122,CVE-2012-2390,23,"static int hugetlb_vm_op_fault(struct vm_area_struct *vma, struct vm_fault *vmf){	BUG();	return 0;}",3194
228,326,CVE-2012-1601,23,"static int kvm_vcpu_ioctl_interrupt(struct kvm_vcpu *vcpu,				    struct kvm_interrupt *irq){	if (irq->irq < 0 || irq->irq >= 256)		return -EINVAL;	if (irqchip_in_kernel(vcpu->kvm))		return -ENXIO;	kvm_queue_interrupt(vcpu, irq->irq, false);	kvm_make_request(KVM_REQ_EVENT, vcpu);	return 0;}",3804
336,366,CVE-2012-1583,23,"static int xfrm6_tunnel_input(struct xfrm_state *x, struct sk_buff *skb){	return 0;}",3844
419,1191,CVE-2013-2635,23,"struct net *rtnl_link_get_net(struct net *src_net, struct nlattr *tb[]){	struct net *net;	 	if (tb[IFLA_NET_NS_PID])		net = get_net_ns_by_pid(nla_get_u32(tb[IFLA_NET_NS_PID]));	else if (tb[IFLA_NET_NS_FD])		net = get_net_ns_by_fd(nla_get_u32(tb[IFLA_NET_NS_FD]));	else		net = get_net(src_net);	return net;}",8529
180,65,CVE-2012-4467,23,"static struct sock_iocb *alloc_sock_iocb(struct kiocb *iocb,					 struct sock_iocb *siocb){	if (!is_sync_kiocb(iocb)) {		siocb = kmalloc(sizeof(*siocb), GFP_KERNEL);		if (!siocb)			return NULL;		iocb->ki_dtor = sock_aio_dtor;	}	siocb->kiocb = iocb;	iocb->private = siocb;	return siocb;}",2733
509,2053,CVE-2012-6638,23,"static void tcp_ack_probe(struct sock *sk){	const struct tcp_sock *tp = tcp_sk(sk);	struct inet_connection_sock *icsk = inet_csk(sk);	 	if (!after(TCP_SKB_CB(tcp_send_head(sk))->end_seq, tcp_wnd_end(tp))) {		icsk->icsk_backoff = 0;		inet_csk_clear_xmit_timer(sk, ICSK_TIME_PROBE0);		 	} else {		inet_csk_reset_xmit_timer(sk, ICSK_TIME_PROBE0,					  min(icsk->icsk_rto << icsk->icsk_backoff, TCP_RTO_MAX),					  TCP_RTO_MAX);	}}",12687
676,2284,CVE-2014-9620,23,"usage(void){	(void)fprintf(stderr, USAGE, progname, progname, progname);	exit(1);}",14457
481,1974,CVE-2014-3538,23,"set_last_default(struct magic_set *ms, struct magic_entry *me, int nme){	int i;	for (i = 0; i < nme; i++) {		if (me[i].mp->cont_level == 0 &&		    me[i].mp->type == FILE_DEFAULT) {			while (++i < nme)				if (me[i].mp->cont_level == 0)					break;			if (i != nme) {				 				ms->line = me[i].mp->lineno;				file_magwarn(ms,				    ""level 0 \""default\"" did not sort last"");			}			return;					    		}	}}",11437
32,1202,CVE-2013-2635,23,"static int rtnl_vf_ports_fill(struct sk_buff *skb, struct net_device *dev){	struct nlattr *vf_ports;	struct nlattr *vf_port;	int vf;	int err;	vf_ports = nla_nest_start(skb, IFLA_VF_PORTS);	if (!vf_ports)		return -EMSGSIZE;	for (vf = 0; vf < dev_num_vf(dev->dev.parent); vf++) {		vf_port = nla_nest_start(skb, IFLA_VF_PORT);		if (!vf_port)			goto nla_put_failure;		if (nla_put_u32(skb, IFLA_PORT_VF, vf))			goto nla_put_failure;		err = dev->netdev_ops->ndo_get_vf_port(dev, vf, skb);		if (err == -EMSGSIZE)			goto nla_put_failure;		if (err) {			nla_nest_cancel(skb, vf_port);			continue;		}		nla_nest_end(skb, vf_port);	}	nla_nest_end(skb, vf_ports);	return 0;nla_put_failure:	nla_nest_cancel(skb, vf_ports);	return -EMSGSIZE;}",8540
102,306,CVE-2012-1601,23,"int kvm_is_linear_rip(struct kvm_vcpu *vcpu, unsigned long linear_rip){	unsigned long current_rip = kvm_rip_read(vcpu) +		get_segment_base(vcpu, VCPU_SREG_CS);	return current_rip == linear_rip;}",3784
224,2003,CVE-2014-1444,23,"fst_cpurelease(struct fst_card_info *card){	if (card->family == FST_FAMILY_TXU) {		 		(void) readb(card->mem);		 		outw(0x040e, card->pci_conf + CNTRL_9054 + 2);		outw(0x040f, card->pci_conf + CNTRL_9054 + 2);	} else {		(void) readb(card->ctlmem);	}}",12041
152,1479,CVE-2013-0217,23,"static int netbk_check_gop(struct xenvif *vif, int nr_meta_slots,			   struct netrx_pending_operations *npo){	struct gnttab_copy     *copy_op;	int status = XEN_NETIF_RSP_OKAY;	int i;	for (i = 0; i < nr_meta_slots; i++) {		copy_op = npo->copy + npo->copy_cons++;		if (copy_op->status != GNTST_okay) {			netdev_dbg(vif->dev,				   ""Bad status %d from copy to DOM%d.\n"",				   copy_op->status, vif->domid);			status = XEN_NETIF_RSP_ERROR;		}	}	return status;}",9776
210,1309,CVE-2013-2017,23,"int dev_open(struct net_device *dev){	int ret;	 	if (dev->flags & IFF_UP)		return 0;	 	ret = __dev_open(dev);	if (ret < 0)		return ret;	 	rtmsg_ifinfo(RTM_NEWLINK, dev, IFF_UP|IFF_RUNNING);	call_netdevice_notifiers(NETDEV_UP, dev);	return ret;}",9018
14,1132,CVE-2013-4162,23,"int udp_seq_open(struct inode *inode, struct file *file){	struct udp_seq_afinfo *afinfo = PDE_DATA(inode);	struct udp_iter_state *s;	int err;	err = seq_open_net(inode, file, &afinfo->seq_ops,			   sizeof(struct udp_iter_state));	if (err < 0)		return err;	s = ((struct seq_file *)file->private_data)->private;	s->family		= afinfo->family;	s->udp_table		= afinfo->udp_table;	return err;}",7957
599,2573,CVE-2011-3099,23,    void destroyWindowAndWaitUntilClosed()    {        g_assert(m_inspectorWindow);        gtk_widget_destroy(m_inspectorWindow);        m_inspectorWindow = 0;        g_main_loop_run(m_mainLoop);    },29341
198,455,CVE-2011-2918,23,"armv6pmu_enable_event(struct hw_perf_event *hwc,		      int idx){	unsigned long val, mask, evt, flags;	if (ARMV6_CYCLE_COUNTER == idx) {		mask	= 0;		evt	= ARMV6_PMCR_CCOUNT_IEN;	} else if (ARMV6_COUNTER0 == idx) {		mask	= ARMV6_PMCR_EVT_COUNT0_MASK;		evt	= (hwc->config_base << ARMV6_PMCR_EVT_COUNT0_SHIFT) |			  ARMV6_PMCR_COUNT0_IEN;	} else if (ARMV6_COUNTER1 == idx) {		mask	= ARMV6_PMCR_EVT_COUNT1_MASK;		evt	= (hwc->config_base << ARMV6_PMCR_EVT_COUNT1_SHIFT) |			  ARMV6_PMCR_COUNT1_IEN;	} else {		WARN_ONCE(1, ""invalid counter number (%d)\n"", idx);		return;	}	 	raw_spin_lock_irqsave(&pmu_lock, flags);	val = armv6_pmcr_read();	val &= ~mask;	val |= evt;	armv6_pmcr_write(val);	raw_spin_unlock_irqrestore(&pmu_lock, flags);}",5847
465,2028,CVE-2013-7348,23,"SYSCALL_DEFINE1(io_destroy, aio_context_t, ctx){	struct kioctx *ioctx = lookup_ioctx(ctx);	if (likely(NULL != ioctx)) {		kill_ioctx(current->mm, ioctx);		percpu_ref_put(&ioctx->users);		return 0;	}	pr_debug(""EINVAL: io_destroy: invalid context id\n"");	return -EINVAL;}",12313
537,2494,CVE-2019-15921,23,"static void genl_rcv(struct sk_buff *skb){	down_read(&cb_lock);	netlink_rcv_skb(skb, &genl_rcv_msg);	up_read(&cb_lock);}",26567
360,2094,CVE-2012-6638,23,"static int tcp_prune_queue(struct sock *sk){	struct tcp_sock *tp = tcp_sk(sk);	SOCK_DEBUG(sk, ""prune_queue: c=%x\n"", tp->copied_seq);	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PRUNECALLED);	if (atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf)		tcp_clamp_window(sk);	else if (tcp_memory_pressure)		tp->rcv_ssthresh = min(tp->rcv_ssthresh, 4U * tp->advmss);	tcp_collapse_ofo_queue(sk);	if (!skb_queue_empty(&sk->sk_receive_queue))		tcp_collapse(sk, &sk->sk_receive_queue,			     skb_peek(&sk->sk_receive_queue),			     NULL,			     tp->copied_seq, tp->rcv_nxt);	sk_mem_reclaim(sk);	if (atomic_read(&sk->sk_rmem_alloc) <= sk->sk_rcvbuf)		return 0;	 	tcp_prune_ofo_queue(sk);	if (atomic_read(&sk->sk_rmem_alloc) <= sk->sk_rcvbuf)		return 0;	 	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_RCVPRUNED);	 	tp->pred_flags = 0;	return -1;}",12728
522,341,CVE-2012-1601,23,"static int kvm_vm_ioctl_reinject(struct kvm *kvm,				 struct kvm_reinject_control *control){	if (!kvm->arch.vpit)		return -ENXIO;	mutex_lock(&kvm->arch.vpit->pit_state.lock);	kvm->arch.vpit->pit_state.pit_timer.reinject = control->pit_reinject;	mutex_unlock(&kvm->arch.vpit->pit_state.lock);	return 0;}",3819
343,490,CVE-2011-2918,23,"int regs_within_kernel_stack(struct pt_regs *regs, unsigned long addr){	return ((addr & ~(THREAD_SIZE - 1))  ==		(kernel_stack_pointer(regs) & ~(THREAD_SIZE - 1)));}",5882
365,519,CVE-2011-2918,23,"static void save_raw_perf_callchain(struct perf_callchain_entry *entry,	unsigned long reg29){	unsigned long *sp = (unsigned long *)reg29;	unsigned long addr;	while (!kstack_end(sp)) {		addr = *sp++;		if (__kernel_text_address(addr)) {			perf_callchain_store(entry, addr);			if (entry->nr >= PERF_MAX_STACK_DEPTH)				break;		}	}}",5911
436,2344,CVE-2016-3156,23,static void __devinet_sysctl_unregister(struct ipv4_devconf *cnf){	struct devinet_sysctl_table *t = cnf->sysctl;	if (!t)		return;	cnf->sysctl = NULL;	unregister_net_sysctl_table(t->sysctl_header);	kfree(t);},17313
168,721,CVE-2011-2918,23,static void intel_pmu_disable_event(struct perf_event *event){	struct hw_perf_event *hwc = &event->hw;	if (unlikely(hwc->idx == X86_PMC_IDX_FIXED_BTS)) {		intel_pmu_disable_bts();		intel_pmu_drain_bts_buffer();		return;	}	if (unlikely(hwc->config_base == MSR_ARCH_PERFMON_FIXED_CTR_CTRL)) {		intel_pmu_disable_fixed(hwc);		return;	}	x86_pmu_disable_event(event);	if (unlikely(event->attr.precise_ip))		intel_pmu_pebs_disable(event);},6113
667,563,CVE-2011-2918,23,"void user_enable_single_step(struct task_struct *child){	unsigned long pc = get_stack_long(child, offsetof(struct pt_regs, pc));	set_tsk_thread_flag(child, TIF_SINGLESTEP);	if (ptrace_get_breakpoints(child) < 0)		return;	set_single_step(child, pc);	ptrace_put_breakpoints(child);}",5955
345,925,CVE-2011-2918,23,"static int swevent_hlist_get_cpu(struct perf_event *event, int cpu){	struct swevent_htable *swhash = &per_cpu(swevent_htable, cpu);	int err = 0;	mutex_lock(&swhash->hlist_mutex);	if (!swevent_hlist_deref(swhash) && cpu_online(cpu)) {		struct swevent_hlist *hlist;		hlist = kzalloc(sizeof(*hlist), GFP_KERNEL);		if (!hlist) {			err = -ENOMEM;			goto exit;		}		rcu_assign_pointer(swhash->swevent_hlist, hlist);	}	swhash->hlist_refcount++;exit:	mutex_unlock(&swhash->hlist_mutex);	return err;}",6317
668,222,CVE-2012-1601,23,static int vcpu_reset(struct kvm_vcpu *vcpu){	int r;	long psr;	local_irq_save(psr);	r = kvm_insert_vmm_mapping(vcpu);	local_irq_restore(psr);	if (r)		goto fail;	vcpu->arch.launched = 0;	kvm_arch_vcpu_uninit(vcpu);	r = kvm_arch_vcpu_init(vcpu);	if (r)		goto fail;	kvm_purge_vmm_mapping(vcpu);	r = 0;fail:	return r;},3700
550,304,CVE-2012-1601,23,"int kvm_inject_realmode_interrupt(struct kvm_vcpu *vcpu, int irq, int inc_eip){	struct x86_emulate_ctxt *ctxt = &vcpu->arch.emulate_ctxt;	int ret;	init_emulate_ctxt(vcpu);	ctxt->op_bytes = 2;	ctxt->ad_bytes = 2;	ctxt->_eip = ctxt->eip + inc_eip;	ret = emulate_int_real(ctxt, irq);	if (ret != X86EMUL_CONTINUE)		return EMULATE_FAIL;	ctxt->eip = ctxt->_eip;	memcpy(vcpu->arch.regs, ctxt->regs, sizeof ctxt->regs);	kvm_rip_write(vcpu, ctxt->eip);	kvm_set_rflags(vcpu, ctxt->eflags);	if (irq == NMI_VECTOR)		vcpu->arch.nmi_pending = 0;	else		vcpu->arch.interrupt.pending = false;	return EMULATE_DONE;}",3782
237,1542,CVE-2011-2491,23,"call_connect_status(struct rpc_task *task){	struct rpc_clnt *clnt = task->tk_client;	int status = task->tk_status;	dprint_status(task);	task->tk_status = 0;	if (status >= 0 || status == -EAGAIN) {		clnt->cl_stats->netreconn++;		task->tk_action = call_transmit;		return;	}	switch (status) {		 	case -ETIMEDOUT:		task->tk_action = call_timeout;		break;	default:		rpc_exit(task, -EIO);	}}",10161
662,488,CVE-2011-2918,23,const char *regs_query_register_name(unsigned int offset){	const struct pt_regs_offset *roff;	for (roff = regoffset_table; roff->name != NULL; roff++)		if (roff->offset == offset)			return roff->name;	return NULL;},5880
586,1733,CVE-2014-7145,23,"SMB2_tdis(const unsigned int xid, struct cifs_tcon *tcon){	struct smb2_tree_disconnect_req *req;  	int rc = 0;	struct TCP_Server_Info *server;	struct cifs_ses *ses = tcon->ses;	cifs_dbg(FYI, ""Tree Disconnect\n"");	if (ses && (ses->server))		server = ses->server;	else		return -EIO;	if ((tcon->need_reconnect) || (tcon->ses->need_reconnect))		return 0;	rc = small_smb2_init(SMB2_TREE_DISCONNECT, tcon, (void **) &req);	if (rc)		return rc;	rc = SendReceiveNoRsp(xid, ses, (char *)&req->hdr, 0);	if (rc)		cifs_stats_fail_inc(tcon, SMB2_TREE_DISCONNECT_HE);	return rc;}",10557
348,2456,CVE-2015-8785,23,"static struct fuse_file *fuse_write_file_get(struct fuse_conn *fc,					     struct fuse_inode *fi){	struct fuse_file *ff = __fuse_write_file_get(fc, fi);	WARN_ON(!ff);	return ff;}",18729
675,1922,CVE-2014-3690,23,"static struct kvm_vcpu *vmx_create_vcpu(struct kvm *kvm, unsigned int id){	int err;	struct vcpu_vmx *vmx = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL);	int cpu;	if (!vmx)		return ERR_PTR(-ENOMEM);	allocate_vpid(vmx);	err = kvm_vcpu_init(&vmx->vcpu, kvm, id);	if (err)		goto free_vcpu;	vmx->guest_msrs = kmalloc(PAGE_SIZE, GFP_KERNEL);	BUILD_BUG_ON(ARRAY_SIZE(vmx_msr_index) * sizeof(vmx->guest_msrs[0])		     > PAGE_SIZE);	err = -ENOMEM;	if (!vmx->guest_msrs) {		goto uninit_vcpu;	}	vmx->loaded_vmcs = &vmx->vmcs01;	vmx->loaded_vmcs->vmcs = alloc_vmcs();	if (!vmx->loaded_vmcs->vmcs)		goto free_msrs;	if (!vmm_exclusive)		kvm_cpu_vmxon(__pa(per_cpu(vmxarea, raw_smp_processor_id())));	loaded_vmcs_init(vmx->loaded_vmcs);	if (!vmm_exclusive)		kvm_cpu_vmxoff();	cpu = get_cpu();	vmx_vcpu_load(&vmx->vcpu, cpu);	vmx->vcpu.cpu = cpu;	err = vmx_vcpu_setup(vmx);	vmx_vcpu_put(&vmx->vcpu);	put_cpu();	if (err)		goto free_vmcs;	if (vm_need_virtualize_apic_accesses(kvm)) {		err = alloc_apic_access_page(kvm);		if (err)			goto free_vmcs;	}	if (enable_ept) {		if (!kvm->arch.ept_identity_map_addr)			kvm->arch.ept_identity_map_addr =				VMX_EPT_IDENTITY_PAGETABLE_ADDR;		err = init_rmode_identity_map(kvm);		if (err)			goto free_vmcs;	}	vmx->nested.current_vmptr = -1ull;	vmx->nested.current_vmcs12 = NULL;	return &vmx->vcpu;free_vmcs:	free_loaded_vmcs(vmx->loaded_vmcs);free_msrs:	kfree(vmx->guest_msrs);uninit_vcpu:	kvm_vcpu_uninit(&vmx->vcpu);free_vcpu:	free_vpid(vmx);	kmem_cache_free(kvm_vcpu_cache, vmx);	return ERR_PTR(err);}",11110
366,1204,CVE-2013-2634,23,"int dcb_ieee_delapp(struct net_device *dev, struct dcb_app *del){	struct dcb_app_type *itr;	struct dcb_app_type event;	int err = -ENOENT;	event.ifindex = dev->ifindex;	memcpy(&event.app, del, sizeof(event.app));	if (dev->dcbnl_ops->getdcbx)		event.dcbx = dev->dcbnl_ops->getdcbx(dev);	spin_lock(&dcb_lock);	 	if ((itr = dcb_app_lookup(del, dev->ifindex, del->priority))) {		list_del(&itr->list);		kfree(itr);		err = 0;	}	spin_unlock(&dcb_lock);	if (!err)		call_dcbevent_notifiers(DCB_APP_EVENT, &event);	return err;}",8542
413,219,CVE-2012-1601,23,"static int kvm_vm_ioctl_get_irqchip(struct kvm *kvm,					struct kvm_irqchip *chip){	int r;	r = 0;	switch (chip->chip_id) {	case KVM_IRQCHIP_IOAPIC:		r = kvm_get_ioapic(kvm, &chip->chip.ioapic);		break;	default:		r = -EINVAL;		break;	}	return r;}",3697
262,1870,CVE-2014-3690,23,"static void init_vmcs_shadow_fields(void){	int i, j;	 	for (i = j = 0; i < max_shadow_read_write_fields; i++) {		switch (shadow_read_write_fields[i]) {		case GUEST_BNDCFGS:			if (!vmx_mpx_supported())				continue;			break;		default:			break;		}		if (j < i)			shadow_read_write_fields[j] =				shadow_read_write_fields[i];		j++;	}	max_shadow_read_write_fields = j;	 	for (i = 0; i < max_shadow_read_write_fields; i++) {		clear_bit(shadow_read_write_fields[i],			  vmx_vmwrite_bitmap);		clear_bit(shadow_read_write_fields[i],			  vmx_vmread_bitmap);	}	for (i = 0; i < max_shadow_read_only_fields; i++)		clear_bit(shadow_read_only_fields[i],			  vmx_vmread_bitmap);}",11058
644,554,CVE-2011-2918,23,static inline int user_space_fault(unsigned long trans_exc_code){	 	trans_exc_code &= 3;	if (trans_exc_code == 2)		 		return current->thread.mm_segment.ar4;	if (user_mode == HOME_SPACE_MODE)		 		return trans_exc_code == 3;	 	return trans_exc_code != 3;},5946
468,1921,CVE-2014-3690,23,"static void vmx_complete_interrupts(struct vcpu_vmx *vmx){	__vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,				  VM_EXIT_INSTRUCTION_LEN,				  IDT_VECTORING_ERROR_CODE);}",11109
78,45,CVE-2016-2179,23,"int ssl_set_version_bound(int method_version, int version, int *bound){    if (version == 0) {        *bound = version;        return 1;    }         switch (method_version) {    default:                 return 0;    case TLS_ANY_VERSION:        if (version < SSL3_VERSION || version > TLS_MAX_VERSION)            return 0;        break;    case DTLS_ANY_VERSION:        if (DTLS_VERSION_GT(version, DTLS_MAX_VERSION) ||            DTLS_VERSION_LT(version, DTLS1_BAD_VER))            return 0;        break;    }    *bound = version;    return 1;}",2076
663,2448,CVE-2015-8785,23,"static inline void fuse_page_descs_length_init(struct fuse_req *req,		unsigned index, unsigned nr_pages){	int i;	for (i = index; i < index + nr_pages; i++)		req->page_descs[i].length = PAGE_SIZE -			req->page_descs[i].offset;}",18721
195,877,CVE-2011-2918,23,"perf_lock_task_context(struct task_struct *task, int ctxn, unsigned long *flags){	struct perf_event_context *ctx;	rcu_read_lock();retry:	ctx = rcu_dereference(task->perf_event_ctxp[ctxn]);	if (ctx) {		 		raw_spin_lock_irqsave(&ctx->lock, *flags);		if (ctx != rcu_dereference(task->perf_event_ctxp[ctxn])) {			raw_spin_unlock_irqrestore(&ctx->lock, *flags);			goto retry;		}		if (!atomic_inc_not_zero(&ctx->refcount)) {			raw_spin_unlock_irqrestore(&ctx->lock, *flags);			ctx = NULL;		}	}	rcu_read_unlock();	return ctx;}",6269
410,915,CVE-2011-2918,23,"static void put_callchain_buffers(void){	if (atomic_dec_and_mutex_lock(&nr_callchain_events, &callchain_mutex)) {		release_callchain_buffers();		mutex_unlock(&callchain_mutex);	}}",6307
625,1069,CVE-2013-5634,23,"void kvm_arch_commit_memory_region(struct kvm *kvm,				   struct kvm_userspace_memory_region *mem,				   const struct kvm_memory_slot *old,				   enum kvm_mr_change change){}",7473
583,2181,CVE-2015-5366,23,"static int __udp_queue_rcv_skb(struct sock *sk, struct sk_buff *skb){	int rc;	if (inet_sk(sk)->inet_daddr) {		sock_rps_save_rxhash(sk, skb);		sk_mark_napi_id(sk, skb);		sk_incoming_cpu_update(sk);	}	rc = sock_queue_rcv_skb(sk, skb);	if (rc < 0) {		int is_udplite = IS_UDPLITE(sk);		 		if (rc == -ENOMEM)			UDP_INC_STATS_BH(sock_net(sk), UDP_MIB_RCVBUFERRORS,					 is_udplite);		UDP_INC_STATS_BH(sock_net(sk), UDP_MIB_INERRORS, is_udplite);		kfree_skb(skb);		trace_udp_fail_queue_rcv_skb(rc, sk);		return -1;	}	return 0;}",13303
186,537,CVE-2011-2918,23,"void do_syscall_trace_leave(struct pt_regs *regs){	int step;	if (unlikely(current->audit_context))		audit_syscall_exit((regs->ccr&0x10000000)?AUDITSC_FAILURE:AUDITSC_SUCCESS,				   regs->result);	if (unlikely(test_thread_flag(TIF_SYSCALL_TRACEPOINT)))		trace_sys_exit(regs, regs->result);	step = test_thread_flag(TIF_SINGLESTEP);	if (step || test_thread_flag(TIF_SYSCALL_TRACE))		tracehook_report_syscall_exit(regs, step);}",5929
555,1265,CVE-2013-2017,23,"static void __dev_addr_discard(struct dev_addr_list **list){	struct dev_addr_list *tmp;	while (*list != NULL) {		tmp = *list;		*list = tmp->next;		if (tmp->da_users > tmp->da_gusers)			printk(""__dev_addr_discard: address leakage! ""			       ""da_users=%d\n"", tmp->da_users);		kfree(tmp);	}}",8974
272,1863,CVE-2014-3690,23,static int handle_triple_fault(struct kvm_vcpu *vcpu){	vcpu->run->exit_reason = KVM_EXIT_SHUTDOWN;	return 0;},11051
372,543,CVE-2011-2918,23,"static int set_dac_range(struct task_struct *child,			 struct ppc_hw_breakpoint *bp_info){	int mode = bp_info->addr_mode & PPC_BREAKPOINT_MODE_MASK;	 	if (bp_info->condition_mode)		return -EINVAL;	 	if (bp_info->addr >= TASK_SIZE)		return -EIO;	if (mode == PPC_BREAKPOINT_MODE_MASK) {		 		if (~((unsigned long)bp_info->addr2) >= TASK_SIZE)			return -EIO;	} else {		 		if (bp_info->addr2 >= TASK_SIZE)			return -EIO;	}	if (child->thread.dbcr0 &	    (DBCR0_DAC1R | DBCR0_DAC1W | DBCR0_DAC2R | DBCR0_DAC2W))		return -ENOSPC;	if (bp_info->trigger_type & PPC_BREAKPOINT_TRIGGER_READ)		child->thread.dbcr0 |= (DBCR0_DAC1R | DBCR0_IDM);	if (bp_info->trigger_type & PPC_BREAKPOINT_TRIGGER_WRITE)		child->thread.dbcr0 |= (DBCR0_DAC1W | DBCR0_IDM);	child->thread.dac1 = bp_info->addr;	child->thread.dac2 = bp_info->addr2;	if (mode == PPC_BREAKPOINT_MODE_RANGE_INCLUSIVE)		child->thread.dbcr2  |= DBCR2_DAC12M;	else if (mode == PPC_BREAKPOINT_MODE_RANGE_EXCLUSIVE)		child->thread.dbcr2  |= DBCR2_DAC12MX;	else	 		child->thread.dbcr2  |= DBCR2_DAC12MM;	child->thread.regs->msr |= MSR_DE;	return 5;}",5935
202,1318,CVE-2013-2017,23,"int dev_unicast_add(struct net_device *dev, void *addr){	int err;	ASSERT_RTNL();	netif_addr_lock_bh(dev);	err = __hw_addr_add(&dev->uc, addr, dev->addr_len,			    NETDEV_HW_ADDR_T_UNICAST);	if (!err)		__dev_set_rx_mode(dev);	netif_addr_unlock_bh(dev);	return err;}",9027
411,1673,CVE-2014-8481,23,"static inline int jmp_rel(struct x86_emulate_ctxt *ctxt, int rel){	return assign_eip_near(ctxt, ctxt->_eip + rel);}",10444
430,736,CVE-2011-2918,23,static void intel_pmu_pebs_enable(struct perf_event *event){	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	struct hw_perf_event *hwc = &event->hw;	hwc->config &= ~ARCH_PERFMON_EVENTSEL_INT;	cpuc->pebs_enabled |= 1ULL << hwc->idx;	WARN_ON_ONCE(cpuc->enabled);	if (x86_pmu.intel_cap.pebs_trap && event->attr.precise_ip > 1)		intel_pmu_lbr_enable(event);},6128
631,1830,CVE-2014-3690,23,"static int cs_ss_rpl_check(struct kvm_vcpu *vcpu){	struct kvm_segment cs, ss;	vmx_get_segment(vcpu, &cs, VCPU_SREG_CS);	vmx_get_segment(vcpu, &ss, VCPU_SREG_SS);	return ((cs.selector & SELECTOR_RPL_MASK) ==		 (ss.selector & SELECTOR_RPL_MASK));}",11018
559,2205,CVE-2015-5307,23,static inline int cpu_has_vmx_tsc_scaling(void){	return vmcs_config.cpu_based_2nd_exec_ctrl &		SECONDARY_EXEC_TSC_SCALING;},13327
533,1513,CVE-2011-4087,23,static inline struct net_device *bridge_parent(const struct net_device *dev){	struct net_bridge_port *port;	port = br_port_get_rcu(dev);	return port ? port->br->dev : NULL;},10079
639,1662,CVE-2014-8481,23,"static int emulate_int(struct x86_emulate_ctxt *ctxt, int irq){	switch(ctxt->mode) {	case X86EMUL_MODE_REAL:		return __emulate_int_real(ctxt, irq);	case X86EMUL_MODE_VM86:	case X86EMUL_MODE_PROT16:	case X86EMUL_MODE_PROT32:	case X86EMUL_MODE_PROT64:	default:		 		return X86EMUL_UNHANDLEABLE;	}}",10433
490,700,CVE-2011-2918,23,"static void x86_pmu_del(struct perf_event *event, int flags){	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	int i;	 	if (cpuc->group_flag & PERF_EVENT_TXN)		return;	x86_pmu_stop(event, PERF_EF_UPDATE);	for (i = 0; i < cpuc->n_events; i++) {		if (event == cpuc->event_list[i]) {			if (x86_pmu.put_event_constraints)				x86_pmu.put_event_constraints(cpuc, event);			while (++i < cpuc->n_events)				cpuc->event_list[i-1] = cpuc->event_list[i];			--cpuc->n_events;			break;		}	}	perf_event_update_userpage(event);}",6092
98,2579,CVE-2013-2909,23,    void commit()    {        m_committedWidth += m_uncommittedWidth;        m_uncommittedWidth = 0;    },29368
494,644,CVE-2011-2918,23,static inline enum direction decode_direction(unsigned int insn){	unsigned long tmp = (insn >> 21) & 1;	if(!tmp)		return load;	else {		if(((insn>>19)&0x3f) == 15)			return both;		else			return store;	}},6036
656,1163,CVE-2013-4125,23,"static void fib6_gc_timer_cb(unsigned long arg){	fib6_run_gc(0, (struct net *)arg);}",8002
628,678,CVE-2011-2918,23,"static void backtrace_address(void *data, unsigned long addr, int reliable){	struct perf_callchain_entry *entry = data;	perf_callchain_store(entry, addr);}",6070
189,362,CVE-2012-1601,23,"static int kvm_mmu_notifier_clear_flush_young(struct mmu_notifier *mn,					      struct mm_struct *mm,					      unsigned long address){	struct kvm *kvm = mmu_notifier_to_kvm(mn);	int young, idx;	idx = srcu_read_lock(&kvm->srcu);	spin_lock(&kvm->mmu_lock);	young = kvm_age_hva(kvm, address);	if (young)		kvm_flush_remote_tlbs(kvm);	spin_unlock(&kvm->mmu_lock);	srcu_read_unlock(&kvm->srcu, idx);	return young;}",3840
385,2411,CVE-2015-8877,23,"static double filter_bell(const double x1){	const double x = x1 < 0.0 ? -x1 : x1;	if (x < 0.5) return (0.75 - x*x);	if (x < 1.5) return (0.5 * pow(x - 1.5, 2.0));	return 0.0;}",18442
357,2596,CVE-2013-2870,23,  void SetBeforeConnectResult(int result) {    before_connect_result_ = result;  },29404
409,1236,CVE-2013-2141,23,"void ptrace_notify(int exit_code){	BUG_ON((exit_code & (0x7f | ~0xffff)) != SIGTRAP);	if (unlikely(current->task_works))		task_work_run();	spin_lock_irq(&current->sighand->siglock);	ptrace_do_notify(SIGTRAP, exit_code, CLD_TRAPPED);	spin_unlock_irq(&current->sighand->siglock);}",8842
140,742,CVE-2011-2918,23,static void reserve_ds_buffers(void){},6134
462,2700,CVE-2012-6638,23,"int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb,			  const struct tcphdr *th, unsigned int len){	struct tcp_sock *tp = tcp_sk(sk);	struct inet_connection_sock *icsk = inet_csk(sk);	int queued = 0;	int res;	tp->rx_opt.saw_tstamp = 0;	switch (sk->sk_state) {	case TCP_CLOSE:		goto discard;	case TCP_LISTEN:		if (th->ack)			return 1;		if (th->rst) 			goto discard;  		if (th->syn) { 			if (icsk->icsk_af_ops->conn_request(sk, skb) < 0) 				return 1; 			 			kfree_skb(skb);			return 0;		}		goto discard;	case TCP_SYN_SENT:		queued = tcp_rcv_synsent_state_process(sk, skb, th, len);		if (queued >= 0)			return queued;		 		tcp_urg(sk, skb, th);		__kfree_skb(skb);		tcp_data_snd_check(sk);		return 0;	}	res = tcp_validate_incoming(sk, skb, th, 0);	if (res <= 0)		return -res;	 	if (th->ack) {		int acceptable = tcp_ack(sk, skb, FLAG_SLOWPATH) > 0;		switch (sk->sk_state) {		case TCP_SYN_RECV:			if (acceptable) {				tp->copied_seq = tp->rcv_nxt;				smp_mb();				tcp_set_state(sk, TCP_ESTABLISHED);				sk->sk_state_change(sk);				 				if (sk->sk_socket)					sk_wake_async(sk,						      SOCK_WAKE_IO, POLL_OUT);				tp->snd_una = TCP_SKB_CB(skb)->ack_seq;				tp->snd_wnd = ntohs(th->window) <<					      tp->rx_opt.snd_wscale;				tcp_init_wl(tp, TCP_SKB_CB(skb)->seq);				if (tp->rx_opt.tstamp_ok)					tp->advmss -= TCPOLEN_TSTAMP_ALIGNED;				 				icsk->icsk_af_ops->rebuild_header(sk);				tcp_init_metrics(sk);				tcp_init_congestion_control(sk);				 				tp->lsndtime = tcp_time_stamp;				tcp_mtup_init(sk);				tcp_initialize_rcv_mss(sk);				tcp_init_buffer_space(sk);				tcp_fast_path_on(tp);			} else {				return 1;			}			break;		case TCP_FIN_WAIT1:			if (tp->snd_una == tp->write_seq) {				tcp_set_state(sk, TCP_FIN_WAIT2);				sk->sk_shutdown |= SEND_SHUTDOWN;				dst_confirm(__sk_dst_get(sk));				if (!sock_flag(sk, SOCK_DEAD))					 					sk->sk_state_change(sk);				else {					int tmo;					if (tp->linger2 < 0 ||					    (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&					     after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt))) {						tcp_done(sk);						NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONDATA);						return 1;					}					tmo = tcp_fin_time(sk);					if (tmo > TCP_TIMEWAIT_LEN) {						inet_csk_reset_keepalive_timer(sk, tmo - TCP_TIMEWAIT_LEN);					} else if (th->fin || sock_owned_by_user(sk)) {						 						inet_csk_reset_keepalive_timer(sk, tmo);					} else {						tcp_time_wait(sk, TCP_FIN_WAIT2, tmo);						goto discard;					}				}			}			break;		case TCP_CLOSING:			if (tp->snd_una == tp->write_seq) {				tcp_time_wait(sk, TCP_TIME_WAIT, 0);				goto discard;			}			break;		case TCP_LAST_ACK:			if (tp->snd_una == tp->write_seq) {				tcp_update_metrics(sk);				tcp_done(sk);				goto discard;			}			break;		}	} else		goto discard;	 	tcp_urg(sk, skb, th);	 	switch (sk->sk_state) {	case TCP_CLOSE_WAIT:	case TCP_CLOSING:	case TCP_LAST_ACK:		if (!before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt))			break;	case TCP_FIN_WAIT1:	case TCP_FIN_WAIT2:		 		if (sk->sk_shutdown & RCV_SHUTDOWN) {			if (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&			    after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt)) {				NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONDATA);				tcp_reset(sk);				return 1;			}		}		 	case TCP_ESTABLISHED:		tcp_data_queue(sk, skb);		queued = 1;		break;	}	 	if (sk->sk_state != TCP_CLOSE) {		tcp_data_snd_check(sk);		tcp_ack_snd_check(sk);	}	if (!queued) {discard:		__kfree_skb(skb);	}	return 0;}",31176
309,1942,CVE-2014-3690,23,"vmx_patch_hypercall(struct kvm_vcpu *vcpu, unsigned char *hypercall){	 	hypercall[0] = 0x0f;	hypercall[1] = 0x01;	hypercall[2] = 0xc1;}",11130
483,957,CVE-2011-2918,23,"static void __free_domain_allocs(struct s_data *d, enum s_alloc what,				 const struct cpumask *cpu_map){	switch (what) {	case sa_rootdomain:		if (!atomic_read(&d->rd->refcount))			free_rootdomain(&d->rd->rcu);  	case sa_sd:		free_percpu(d->sd);  	case sa_sd_storage:		__sdt_free(cpu_map);  	case sa_none:		break;	}}",6349
380,275,CVE-2012-1601,23,void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu){	vcpu->arch.apf.msr_val = 0;	vcpu_load(vcpu);	kvm_mmu_unload(vcpu);	vcpu_put(vcpu);	fx_free(vcpu);	kvm_x86_ops->vcpu_free(vcpu);},3753
605,1076,CVE-2013-5634,23,void kvm_arch_hardware_disable(void *garbage){},7480
212,2608,CVE-2014-7907,23,"  int GetOrientationAngle() {    int angle;    ExecuteScriptAndGetValue(shell()->web_contents()->GetMainFrame(),                             ""screen.orientation.angle"")->GetAsInteger(&angle);    return angle;  }",29495
71,2235,CVE-2015-5307,23,"static int nested_vmx_check_apicv_controls(struct kvm_vcpu *vcpu,					   struct vmcs12 *vmcs12){	if (!nested_cpu_has_virt_x2apic_mode(vmcs12) &&	    !nested_cpu_has_apic_reg_virt(vmcs12) &&	    !nested_cpu_has_vid(vmcs12) &&	    !nested_cpu_has_posted_intr(vmcs12))		return 0;	 	if (nested_cpu_has_virt_x2apic_mode(vmcs12) &&	    nested_cpu_has2(vmcs12, SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES))		return -EINVAL;	 	if (nested_cpu_has_vid(vmcs12) &&	   !nested_exit_on_intr(vcpu))		return -EINVAL;	 	if (nested_cpu_has_posted_intr(vmcs12) &&	   (!nested_cpu_has_vid(vmcs12) ||	    !nested_exit_intr_ack_set(vcpu) ||	    vmcs12->posted_intr_nv & 0xff00))		return -EINVAL;	 	if (!nested_cpu_has(vmcs12, CPU_BASED_TPR_SHADOW))		return -EINVAL;	return 0;}",13357
358,850,CVE-2011-2918,23,static int perf_event_comm_match(struct perf_event *event){	if (event->state < PERF_EVENT_STATE_INACTIVE)		return 0;	if (!event_filter_match(event))		return 0;	if (event->attr.comm)		return 1;	return 0;},6242
630,2203,CVE-2015-5307,23,static inline int cpu_has_vmx_pml(void){	return vmcs_config.cpu_based_2nd_exec_ctrl & SECONDARY_EXEC_ENABLE_PML;},13325
110,2076,CVE-2012-6638,23,static void tcp_enter_quickack_mode(struct sock *sk){	struct inet_connection_sock *icsk = inet_csk(sk);	tcp_incr_quickack(sk);	icsk->icsk_ack.pingpong = 0;	icsk->icsk_ack.ato = TCP_ATO_MIN;},12710
288,76,CVE-2012-4467,23,static void sock_aio_dtor(struct kiocb *iocb){	kfree(iocb->private);},2744
298,1709,CVE-2014-7841,23,"void sctp_init_addrs(struct sctp_chunk *chunk, union sctp_addr *src,		     union sctp_addr *dest){	memcpy(&chunk->source, src, sizeof(union sctp_addr));	memcpy(&chunk->dest, dest, sizeof(union sctp_addr));}",10517
220,25,CVE-2016-7421,23,"static int pvscsi_vmstate_test_pci_device(void *opaque, int version_id){    return !pvscsi_vmstate_need_pcie_device(opaque);}",1324
438,156,CVE-2012-2133,23,"static int hugetlbfs_setattr(struct dentry *dentry, struct iattr *attr){	struct inode *inode = dentry->d_inode;	struct hstate *h = hstate_inode(inode);	int error;	unsigned int ia_valid = attr->ia_valid;	BUG_ON(!inode);	error = inode_change_ok(inode, attr);	if (error)		return error;	if (ia_valid & ATTR_SIZE) {		error = -EINVAL;		if (attr->ia_size & ~huge_page_mask(h))			return -EINVAL;		error = hugetlb_vmtruncate(inode, attr->ia_size);		if (error)			return error;	}	setattr_copy(inode, attr);	mark_inode_dirty(inode);	return 0;}",3500
642,673,CVE-2011-2918,23,unsigned long probe_memory(void){	unsigned long total = 0;	int i;	for (i = 0; sp_banks[i].num_bytes; i++)		total += sp_banks[i].num_bytes;	return total;},6065
672,1993,CVE-2014-1446,23,"static void yam_start_tx(struct net_device *dev, struct yam_port *yp){	if ((yp->tx_state == TX_TAIL) || (yp->txd == 0))		yp->tx_count = 1;	else		yp->tx_count = (yp->bitrate * yp->txd) / 8000;	yp->tx_state = TX_HEAD;	ptt_on(dev);}",12031
58,1549,CVE-2011-2491,23,"call_transmit_status(struct rpc_task *task){	task->tk_action = call_status;	 	if (task->tk_status == 0) {		xprt_end_transmit(task);		rpc_task_force_reencode(task);		return;	}	switch (task->tk_status) {	case -EAGAIN:		break;	default:		dprint_status(task);		xprt_end_transmit(task);		rpc_task_force_reencode(task);		break;		 	case -ECONNREFUSED:	case -EHOSTDOWN:	case -EHOSTUNREACH:	case -ENETUNREACH:		if (RPC_IS_SOFTCONN(task)) {			xprt_end_transmit(task);			rpc_exit(task, task->tk_status);			break;		}	case -ECONNRESET:	case -ENOTCONN:	case -EPIPE:		rpc_task_force_reencode(task);	}}",10168
617,1683,CVE-2014-8481,23,"static int writeback(struct x86_emulate_ctxt *ctxt, struct operand *op){	switch (op->type) {	case OP_REG:		write_register_operand(op);		break;	case OP_MEM:		if (ctxt->lock_prefix)			return segmented_cmpxchg(ctxt,						 op->addr.mem,						 &op->orig_val,						 &op->val,						 op->bytes);		else			return segmented_write(ctxt,					       op->addr.mem,					       &op->val,					       op->bytes);		break;	case OP_MEM_STR:		return segmented_write(ctxt,				       op->addr.mem,				       op->data,				       op->bytes * op->count);		break;	case OP_XMM:		write_sse_reg(ctxt, &op->vec_val, op->addr.xmm);		break;	case OP_MM:		write_mmx_reg(ctxt, &op->mm_val, op->addr.mm);		break;	case OP_NONE:		 		break;	default:		break;	}	return X86EMUL_CONTINUE;}",10454
622,1535,CVE-2011-2491,23,static void nlmclnt_rpc_release(void *data){	nlmclnt_release_call(data);},10154
367,2188,CVE-2015-5366,23,"void udp_v4_early_demux(struct sk_buff *skb){	struct net *net = dev_net(skb->dev);	const struct iphdr *iph;	const struct udphdr *uh;	struct sock *sk;	struct dst_entry *dst;	int dif = skb->dev->ifindex;	 	if (!pskb_may_pull(skb, skb_transport_offset(skb) + sizeof(struct udphdr)))		return;	iph = ip_hdr(skb);	uh = udp_hdr(skb);	if (skb->pkt_type == PACKET_BROADCAST ||	    skb->pkt_type == PACKET_MULTICAST)		sk = __udp4_lib_mcast_demux_lookup(net, uh->dest, iph->daddr,						   uh->source, iph->saddr, dif);	else if (skb->pkt_type == PACKET_HOST)		sk = __udp4_lib_demux_lookup(net, uh->dest, iph->daddr,					     uh->source, iph->saddr, dif);	else		return;	if (!sk)		return;	skb->sk = sk;	skb->destructor = sock_efree;	dst = sk->sk_rx_dst;	if (dst)		dst = dst_check(dst, 0);	if (dst)		skb_dst_set_noref(skb, dst);}",13310
147,1425,CVE-2013-1797,23,"int x86_emulate_instruction(struct kvm_vcpu *vcpu,			    unsigned long cr2,			    int emulation_type,			    void *insn,			    int insn_len){	int r;	struct x86_emulate_ctxt *ctxt = &vcpu->arch.emulate_ctxt;	int writeback = true;	int write_fault_to_spt = vcpu->arch.write_fault_to_shadow_pgtable;	 	vcpu->arch.write_fault_to_shadow_pgtable = false;	kvm_clear_exception_queue(vcpu);	if (!(emulation_type & EMULTYPE_NO_DECODE)) {		init_emulate_ctxt(vcpu);		ctxt->interruptibility = 0;		ctxt->have_exception = false;		ctxt->perm_ok = false;		ctxt->only_vendor_specific_insn			= emulation_type & EMULTYPE_TRAP_UD;		r = x86_decode_insn(ctxt, insn, insn_len);		trace_kvm_emulate_insn_start(vcpu);		++vcpu->stat.insn_emulation;		if (r != EMULATION_OK)  {			if (emulation_type & EMULTYPE_TRAP_UD)				return EMULATE_FAIL;			if (reexecute_instruction(vcpu, cr2,						  write_fault_to_spt))				return EMULATE_DONE;			if (emulation_type & EMULTYPE_SKIP)				return EMULATE_FAIL;			return handle_emulation_failure(vcpu);		}	}	if (emulation_type & EMULTYPE_SKIP) {		kvm_rip_write(vcpu, ctxt->_eip);		return EMULATE_DONE;	}	if (retry_instruction(ctxt, cr2, emulation_type))		return EMULATE_DONE;	 	if (vcpu->arch.emulate_regs_need_sync_from_vcpu) {		vcpu->arch.emulate_regs_need_sync_from_vcpu = false;		emulator_invalidate_register_cache(ctxt);	}restart:	r = x86_emulate_insn(ctxt);	if (r == EMULATION_INTERCEPTED)		return EMULATE_DONE;	if (r == EMULATION_FAILED) {		if (reexecute_instruction(vcpu, cr2, write_fault_to_spt))			return EMULATE_DONE;		return handle_emulation_failure(vcpu);	}	if (ctxt->have_exception) {		inject_emulated_exception(vcpu);		r = EMULATE_DONE;	} else if (vcpu->arch.pio.count) {		if (!vcpu->arch.pio.in)			vcpu->arch.pio.count = 0;		else {			writeback = false;			vcpu->arch.complete_userspace_io = complete_emulated_pio;		}		r = EMULATE_DO_MMIO;	} else if (vcpu->mmio_needed) {		if (!vcpu->mmio_is_write)			writeback = false;		r = EMULATE_DO_MMIO;		vcpu->arch.complete_userspace_io = complete_emulated_mmio;	} else if (r == EMULATION_RESTART)		goto restart;	else		r = EMULATE_DONE;	if (writeback) {		toggle_interruptibility(vcpu, ctxt->interruptibility);		kvm_set_rflags(vcpu, ctxt->eflags);		kvm_make_request(KVM_REQ_EVENT, vcpu);		vcpu->arch.emulate_regs_need_sync_to_vcpu = false;		kvm_rip_write(vcpu, ctxt->eip);	} else		vcpu->arch.emulate_regs_need_sync_to_vcpu = true;	return r;}",9524
131,738,CVE-2011-2918,23,"static void release_bts_buffer(int cpu){	struct debug_store *ds = per_cpu(cpu_hw_events, cpu).ds;	if (!ds || !x86_pmu.bts)		return;	kfree((void *)(unsigned long)ds->bts_buffer_base);	ds->bts_buffer_base = 0;}",6130
451,2684,CVE-2013-4163,23,"static void ip6_append_data_mtu(int *mtu, 				int *maxfraglen, 				unsigned int fragheaderlen, 				struct sk_buff *skb,				struct rt6_info *rt) { 	if (!(rt->dst.flags & DST_XFRM_TUNNEL)) { 		if (skb == NULL) {			 			*mtu = *mtu - rt->dst.header_len;		} else {			 			*mtu = dst_mtu(rt->dst.path); 		} 		*maxfraglen = ((*mtu - fragheaderlen) & ~7) 			      + fragheaderlen - sizeof(struct frag_hdr);	}}",31059
308,1273,CVE-2013-2017,23,static void __hw_addr_init(struct netdev_hw_addr_list *list){	INIT_LIST_HEAD(&list->list);	list->count = 0;},8982
188,880,CVE-2011-2918,23,"static int perf_mmap_fault(struct vm_area_struct *vma, struct vm_fault *vmf){	struct perf_event *event = vma->vm_file->private_data;	struct ring_buffer *rb;	int ret = VM_FAULT_SIGBUS;	if (vmf->flags & FAULT_FLAG_MKWRITE) {		if (vmf->pgoff == 0)			ret = 0;		return ret;	}	rcu_read_lock();	rb = rcu_dereference(event->rb);	if (!rb)		goto unlock;	if (vmf->pgoff && (vmf->flags & FAULT_FLAG_WRITE))		goto unlock;	vmf->page = perf_mmap_to_page(rb, vmf->pgoff);	if (!vmf->page)		goto unlock;	get_page(vmf->page);	vmf->page->mapping = vma->vm_file->f_mapping;	vmf->page->index   = vmf->pgoff;	ret = 0;unlock:	rcu_read_unlock();	return ret;}",6272
507,2249,CVE-2015-5307,23,"static int vmx_check_nested_events(struct kvm_vcpu *vcpu, int external_intr){	struct vcpu_vmx *vmx = to_vmx(vcpu);	if (nested_cpu_has_preemption_timer(get_vmcs12(vcpu)) &&	    vmx->nested.preemption_timer_expired) {		if (vmx->nested.nested_run_pending)			return -EBUSY;		nested_vmx_vmexit(vcpu, EXIT_REASON_PREEMPTION_TIMER, 0, 0);		return 0;	}	if (vcpu->arch.nmi_pending && nested_exit_on_nmi(vcpu)) {		if (vmx->nested.nested_run_pending ||		    vcpu->arch.interrupt.pending)			return -EBUSY;		nested_vmx_vmexit(vcpu, EXIT_REASON_EXCEPTION_NMI,				  NMI_VECTOR | INTR_TYPE_NMI_INTR |				  INTR_INFO_VALID_MASK, 0);		 		vcpu->arch.nmi_pending = 0;		vmx_set_nmi_mask(vcpu, true);		return 0;	}	if ((kvm_cpu_has_interrupt(vcpu) || external_intr) &&	    nested_exit_on_intr(vcpu)) {		if (vmx->nested.nested_run_pending)			return -EBUSY;		nested_vmx_vmexit(vcpu, EXIT_REASON_EXTERNAL_INTERRUPT, 0, 0);		return 0;	}	return vmx_complete_nested_posted_interrupt(vcpu);}",13371
478,1134,CVE-2013-4162,23,"static void flush_stack(struct sock **stack, unsigned int count,			struct sk_buff *skb, unsigned int final){	struct sk_buff *skb1 = NULL;	struct sock *sk;	unsigned int i;	for (i = 0; i < count; i++) {		sk = stack[i];		if (likely(skb1 == NULL))			skb1 = (i == final) ? skb : skb_clone(skb, GFP_ATOMIC);		if (!skb1) {			atomic_inc(&sk->sk_drops);			UDP6_INC_STATS_BH(sock_net(sk), UDP_MIB_RCVBUFERRORS,					  IS_UDPLITE(sk));			UDP6_INC_STATS_BH(sock_net(sk), UDP_MIB_INERRORS,					  IS_UDPLITE(sk));		}		if (skb1 && udpv6_queue_rcv_skb(sk, skb1) <= 0)			skb1 = NULL;	}	if (unlikely(skb1))		kfree_skb(skb1);}",7959
584,875,CVE-2011-2918,23,static inline void perf_get_cgroup(struct perf_event *event){	css_get(&event->cgrp->css);},6267
132,5,CVE-2015-7540,23,"static int push_int_bigendian(struct asn1_data *data, unsigned int i, int negative){	int lowest = i & 0xFF;	i = i >> 8;	if (i != 0)		if (!push_int_bigendian(data, i, negative))			return false;	if (data->nesting->start+1 == data->ofs) {		 		if (negative) {			 			if (lowest == 0xFF)				return true;			if ((lowest & 0x80) == 0) {				 				if (!asn1_write_uint8(data, 0xff))					return false;			}		} else {			if (lowest & 0x80) {				 				if (!asn1_write_uint8(data, 0))					return false;			}		}	}	return asn1_write_uint8(data, lowest);}",82
173,1114,CVE-2013-4592,23,"int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id){	struct page *page;	int r;	mutex_init(&vcpu->mutex);	vcpu->cpu = -1;	vcpu->kvm = kvm;	vcpu->vcpu_id = id;	vcpu->pid = NULL;	init_waitqueue_head(&vcpu->wq);	kvm_async_pf_vcpu_init(vcpu);	page = alloc_page(GFP_KERNEL | __GFP_ZERO);	if (!page) {		r = -ENOMEM;		goto fail;	}	vcpu->run = page_address(page);	kvm_vcpu_set_in_spin_loop(vcpu, false);	kvm_vcpu_set_dy_eligible(vcpu, false);	r = kvm_arch_vcpu_init(vcpu);	if (r < 0)		goto fail_free_run;	return 0;fail_free_run:	free_page((unsigned long)vcpu->run);fail:	return r;}",7518
364,1405,CVE-2013-1797,23,"static int __vcpu_run(struct kvm_vcpu *vcpu){	int r;	struct kvm *kvm = vcpu->kvm;	if (unlikely(vcpu->arch.mp_state == KVM_MP_STATE_SIPI_RECEIVED)) {		pr_debug(""vcpu %d received sipi with vector # %x\n"",			 vcpu->vcpu_id, vcpu->arch.sipi_vector);		kvm_lapic_reset(vcpu);		r = kvm_vcpu_reset(vcpu);		if (r)			return r;		vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;	}	vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);	r = vapic_enter(vcpu);	if (r) {		srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);		return r;	}	r = 1;	while (r > 0) {		if (vcpu->arch.mp_state == KVM_MP_STATE_RUNNABLE &&		    !vcpu->arch.apf.halted)			r = vcpu_enter_guest(vcpu);		else {			srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);			kvm_vcpu_block(vcpu);			vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);			if (kvm_check_request(KVM_REQ_UNHALT, vcpu))			{				switch(vcpu->arch.mp_state) {				case KVM_MP_STATE_HALTED:					vcpu->arch.mp_state =						KVM_MP_STATE_RUNNABLE;				case KVM_MP_STATE_RUNNABLE:					vcpu->arch.apf.halted = false;					break;				case KVM_MP_STATE_SIPI_RECEIVED:				default:					r = -EINTR;					break;				}			}		}		if (r <= 0)			break;		clear_bit(KVM_REQ_PENDING_TIMER, &vcpu->requests);		if (kvm_cpu_has_pending_timer(vcpu))			kvm_inject_pending_timer_irqs(vcpu);		if (dm_request_for_irq_injection(vcpu)) {			r = -EINTR;			vcpu->run->exit_reason = KVM_EXIT_INTR;			++vcpu->stat.request_irq_exits;		}		kvm_check_async_pf_completion(vcpu);		if (signal_pending(current)) {			r = -EINTR;			vcpu->run->exit_reason = KVM_EXIT_INTR;			++vcpu->stat.signal_exits;		}		if (need_resched()) {			srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);			kvm_resched(vcpu);			vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);		}	}	srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);	vapic_exit(vcpu);	return r;}",9504
473,1916,CVE-2014-3690,23,static inline int vmcs_field_type(unsigned long field){	if (0x1 & field)	 		return VMCS_FIELD_TYPE_U32;	return (field >> 13) & 0x3 ;},11104
177,704,CVE-2011-2918,23,"static void x86_pmu_enable_all(int added){	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	int idx;	for (idx = 0; idx < x86_pmu.num_counters; idx++) {		struct hw_perf_event *hwc = &cpuc->events[idx]->hw;		if (!test_bit(idx, cpuc->active_mask))			continue;		__x86_pmu_enable_event(hwc, ARCH_PERFMON_EVENTSEL_ENABLE);	}}",6096
578,1397,CVE-2013-2015,23,"static int ext4_rmdir(struct inode *dir, struct dentry *dentry){	int retval;	struct inode *inode;	struct buffer_head *bh;	struct ext4_dir_entry_2 *de;	handle_t *handle;	 	dquot_initialize(dir);	dquot_initialize(dentry->d_inode);	handle = ext4_journal_start(dir, EXT4_DELETE_TRANS_BLOCKS(dir->i_sb));	if (IS_ERR(handle))		return PTR_ERR(handle);	retval = -ENOENT;	bh = ext4_find_entry(dir, &dentry->d_name, &de, NULL);	if (!bh)		goto end_rmdir;	if (IS_DIRSYNC(dir))		ext4_handle_sync(handle);	inode = dentry->d_inode;	retval = -EIO;	if (le32_to_cpu(de->inode) != inode->i_ino)		goto end_rmdir;	retval = -ENOTEMPTY;	if (!empty_dir(inode))		goto end_rmdir;	retval = ext4_delete_entry(handle, dir, de, bh);	if (retval)		goto end_rmdir;	if (!EXT4_DIR_LINK_EMPTY(inode))		ext4_warning(inode->i_sb,			     ""empty directory has too many links (%d)"",			     inode->i_nlink);	inode->i_version++;	clear_nlink(inode);	 	inode->i_size = 0;	ext4_orphan_add(handle, inode);	inode->i_ctime = dir->i_ctime = dir->i_mtime = ext4_current_time(inode);	ext4_mark_inode_dirty(handle, inode);	ext4_dec_count(handle, dir);	ext4_update_dx_flag(dir);	ext4_mark_inode_dirty(handle, dir);end_rmdir:	ext4_journal_stop(handle);	brelse(bh);	return retval;}",9106
163,1976,CVE-2014-3538,23,swap4(int sv){	int rv;	int *s = (int *)(void *)&sv; 	int *d = (int *)(void *)&rv; 	d[0] = s[3];	d[1] = s[2];	d[2] = s[1];	d[3] = s[0];	return rv;},11439
209,1435,CVE-2013-1767,23,"static void shmem_evict_inode(struct inode *inode){	struct shmem_inode_info *info = SHMEM_I(inode);	if (inode->i_mapping->a_ops == &shmem_aops) {		shmem_unacct_size(info->flags, inode->i_size);		inode->i_size = 0;		shmem_truncate_range(inode, 0, (loff_t)-1);		if (!list_empty(&info->swaplist)) {			mutex_lock(&shmem_swaplist_mutex);			list_del_init(&info->swaplist);			mutex_unlock(&shmem_swaplist_mutex);		}	} else		kfree(info->symlink);	simple_xattrs_free(&info->xattrs);	WARN_ON(inode->i_blocks);	shmem_free_inode(inode->i_sb);	clear_inode(inode);}",9634
609,1924,CVE-2014-3690,23,"static void vmx_fpu_deactivate(struct kvm_vcpu *vcpu){	 	vmx_decache_cr0_guest_bits(vcpu);	vmcs_set_bits(GUEST_CR0, X86_CR0_TS | X86_CR0_MP);	update_exception_bitmap(vcpu);	vcpu->arch.cr0_guest_owned_bits = 0;	vmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits);	if (is_guest_mode(vcpu)) {		 		struct vmcs12 *vmcs12 = get_vmcs12(vcpu);		vmcs12->guest_cr0 = (vmcs12->guest_cr0 & ~X86_CR0_TS) |			(vcpu->arch.cr0 & X86_CR0_TS);		vmcs_writel(CR0_READ_SHADOW, nested_read_cr0(vmcs12));	} else		vmcs_writel(CR0_READ_SHADOW, vcpu->arch.cr0);}",11112
457,637,CVE-2011-2918,23,"static void sparc_pmu_start(struct perf_event *event, int flags){	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	int idx = active_event_index(cpuc, event);	if (flags & PERF_EF_RELOAD) {		WARN_ON_ONCE(!(event->hw.state & PERF_HES_UPTODATE));		sparc_perf_event_set_period(event, &event->hw, idx);	}	event->hw.state = 0;	sparc_pmu_enable_event(cpuc, &event->hw, idx);}",6029
183,1024,CVE-2011-2918,23,void touch_softlockup_watchdog_sync(void){	__raw_get_cpu_var(softlockup_touch_sync) = true;	__raw_get_cpu_var(watchdog_touch_ts) = 0;},6416
407,2585,CVE-2013-2909,23,    void setEndLineMatched(int endLineMatched) { m_endLineMatched = endLineMatched; },29374
68,1183,CVE-2013-2635,23,"static int rtnl_dellink(struct sk_buff *skb, struct nlmsghdr *nlh, void *arg){	struct net *net = sock_net(skb->sk);	const struct rtnl_link_ops *ops;	struct net_device *dev;	struct ifinfomsg *ifm;	char ifname[IFNAMSIZ];	struct nlattr *tb[IFLA_MAX+1];	int err;	LIST_HEAD(list_kill);	err = nlmsg_parse(nlh, sizeof(*ifm), tb, IFLA_MAX, ifla_policy);	if (err < 0)		return err;	if (tb[IFLA_IFNAME])		nla_strlcpy(ifname, tb[IFLA_IFNAME], IFNAMSIZ);	ifm = nlmsg_data(nlh);	if (ifm->ifi_index > 0)		dev = __dev_get_by_index(net, ifm->ifi_index);	else if (tb[IFLA_IFNAME])		dev = __dev_get_by_name(net, ifname);	else		return -EINVAL;	if (!dev)		return -ENODEV;	ops = dev->rtnl_link_ops;	if (!ops)		return -EOPNOTSUPP;	ops->dellink(dev, &list_kill);	unregister_netdevice_many(&list_kill);	list_del(&list_kill);	return 0;}",8521
573,136,CVE-2012-2390,23,static inline struct hugepage_subpool *subpool_inode(struct inode *inode){	return HUGETLBFS_SB(inode->i_sb)->spool;},3208
324,968,CVE-2011-2918,23,static const struct cpumask *cpu_cpu_mask(int cpu){	return cpumask_of_node(cpu_to_node(cpu));},6360
201,167,CVE-2012-1601,23,"static int handle_sal_call(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run){	struct exit_ctl_data *p;	p = kvm_get_exit_data(vcpu);	if (p->exit_reason == EXIT_REASON_SAL_CALL) {		kvm_sal_emul(vcpu);		return 1;	} else {		kvm_run->exit_reason = KVM_EXIT_UNKNOWN;		kvm_run->hw.hardware_exit_reason = 3;		return 0;	}}",3645
5,1599,CVE-2011-2491,23,"void rpc_prepare_task(struct rpc_task *task){	task->tk_ops->rpc_call_prepare(task, task->tk_calldata);}",10218
153,404,CVE-2012-0058,23,"static void __put_ioctx(struct kioctx *ctx){	BUG_ON(ctx->reqs_active);	cancel_delayed_work(&ctx->wq);	cancel_work_sync(&ctx->wq.work);	aio_free_ring(ctx);	mmdrop(ctx->mm);	ctx->mm = NULL;	pr_debug(""__put_ioctx: freeing %p\n"", ctx);	call_rcu(&ctx->rcu_head, ctx_rcu_free);}",4144
193,1776,CVE-2014-6410,23,"static int udf_readpage(struct file *file, struct page *page){	return mpage_readpage(page, udf_get_block);}",10600
296,1039,CVE-2011-0716,23,"static int br_ip6_multicast_mld2_report(struct net_bridge *br,					struct net_bridge_port *port,					struct sk_buff *skb){	struct icmp6hdr *icmp6h;	struct mld2_grec *grec;	int i;	int len;	int num;	int err = 0;	if (!pskb_may_pull(skb, sizeof(*icmp6h)))		return -EINVAL;	icmp6h = icmp6_hdr(skb);	num = ntohs(icmp6h->icmp6_dataun.un_data16[1]);	len = sizeof(*icmp6h);	for (i = 0; i < num; i++) {		__be16 *nsrcs, _nsrcs;		nsrcs = skb_header_pointer(skb,					   len + offsetof(struct mld2_grec,							  grec_mca),					   sizeof(_nsrcs), &_nsrcs);		if (!nsrcs)			return -EINVAL;		if (!pskb_may_pull(skb,				   len + sizeof(*grec) +				   sizeof(struct in6_addr) * (*nsrcs)))			return -EINVAL;		grec = (struct mld2_grec *)(skb->data + len);		len += sizeof(*grec) + sizeof(struct in6_addr) * (*nsrcs);		 		switch (grec->grec_type) {		case MLD2_MODE_IS_INCLUDE:		case MLD2_MODE_IS_EXCLUDE:		case MLD2_CHANGE_TO_INCLUDE:		case MLD2_CHANGE_TO_EXCLUDE:		case MLD2_ALLOW_NEW_SOURCES:		case MLD2_BLOCK_OLD_SOURCES:			break;		default:			continue;		}		err = br_ip6_multicast_add_group(br, port, &grec->grec_mca);		if (!err)			break;	}	return err;}",6977
74,2644,CVE-2012-2133,23,"void hugetlb_put_quota(struct address_space *mapping, long delta){	struct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(mapping->host->i_sb);	if (sbinfo->free_blocks > -1) {		spin_lock(&sbinfo->stat_lock);		sbinfo->free_blocks += delta;		spin_unlock(&sbinfo->stat_lock);	}}",30939
22,1370,CVE-2013-2017,23,"int unregister_netdevice_notifier(struct notifier_block *nb){	int err;	rtnl_lock();	err = raw_notifier_chain_unregister(&netdev_chain, nb);	rtnl_unlock();	return err;}",9079
19,1651,CVE-2014-8481,23,"static int em_mov(struct x86_emulate_ctxt *ctxt){	memcpy(ctxt->dst.valptr, ctxt->src.valptr, sizeof(ctxt->src.valptr));	return X86EMUL_CONTINUE;}",10422
144,112,CVE-2012-2390,23,"static void hugepage_subpool_put_pages(struct hugepage_subpool *spool,				       long delta){	if (!spool)		return;	spin_lock(&spool->lock);	spool->used_hpages -= delta;	 	unlock_or_release_subpool(spool);}",3184
426,1638,CVE-2014-8481,23,"static void adjust_modrm_seg(struct x86_emulate_ctxt *ctxt, int base_reg){	if (base_reg == VCPU_REGS_RSP || base_reg == VCPU_REGS_RBP)		ctxt->modrm_seg = VCPU_SREG_SS;}",10409
115,515,CVE-2011-2918,23,mipspmu_map_general_event(int idx){	const struct mips_perf_event *pev;	pev = ((*mipspmu->general_event_map)[idx].event_id ==		UNSUPPORTED_PERF_EVENT_ID ? ERR_PTR(-EOPNOTSUPP) :		&(*mipspmu->general_event_map)[idx]);	return pev;},5907
606,2293,CVE-2014-9620,23,"magic_list(struct magic_set *ms, const char *magicfile){	if (ms == NULL)		return -1;	return file_apprentice(ms, magicfile, FILE_LIST);}",14466
300,665,CVE-2011-2918,23,"static inline unsigned long *fpd_regaddr(struct fpustate *f,					 unsigned int insn_regnum){	insn_regnum = (((insn_regnum & 1) << 5) |		       (insn_regnum & 0x1e));	return (unsigned long *) &f->regs[insn_regnum];}",6057
341,1579,CVE-2011-2491,23,"static void __rpc_add_wait_queue(struct rpc_wait_queue *queue, struct rpc_task *task){	BUG_ON (RPC_IS_QUEUED(task));	if (RPC_IS_PRIORITY(queue))		__rpc_add_wait_queue_priority(queue, task);	else if (RPC_IS_SWAPPER(task))		list_add(&task->u.tk_wait.list, &queue->tasks[0]);	else		list_add_tail(&task->u.tk_wait.list, &queue->tasks[0]);	task->tk_waitqueue = queue;	queue->qlen++;	rpc_set_queued(task);	dprintk(""RPC: %5u added to queue %p \""%s\""\n"",			task->tk_pid, queue, rpc_qname(queue));}",10198
265,1295,CVE-2013-2017,23,"struct net_device *dev_get_by_name(struct net *net, const char *name){	struct net_device *dev;	rcu_read_lock();	dev = dev_get_by_name_rcu(net, name);	if (dev)		dev_hold(dev);	rcu_read_unlock();	return dev;}",9004
234,2143,CVE-2015-6526,23,"static inline int current_is_64bit(void){	 	return !test_ti_thread_flag(task_thread_info(current), TIF_32BIT);}",13115
502,1431,CVE-2013-1767,23,"static void shmem_delete_from_page_cache(struct page *page, void *radswap){	struct address_space *mapping = page->mapping;	int error;	spin_lock_irq(&mapping->tree_lock);	error = shmem_radix_tree_replace(mapping, page->index, page, radswap);	page->mapping = NULL;	mapping->nrpages--;	__dec_zone_page_state(page, NR_FILE_PAGES);	__dec_zone_page_state(page, NR_SHMEM);	spin_unlock_irq(&mapping->tree_lock);	page_cache_release(page);	BUG_ON(error);}",9630
299,1031,CVE-2011-2918,23,"static void watchdog_prepare_cpu(int cpu){	struct hrtimer *hrtimer = &per_cpu(watchdog_hrtimer, cpu);	WARN_ON(per_cpu(softlockup_watchdog, cpu));	hrtimer_init(hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);	hrtimer->function = watchdog_timer_fn;}",6423
105,975,CVE-2011-2918,23,"static void enqueue_task(struct rq *rq, struct task_struct *p, int flags){	update_rq_clock(rq);	sched_info_queued(p);	p->sched_class->enqueue_task(rq, p, flags);}",6367
166,1899,CVE-2014-3690,23,"static int pi_test_and_set_on(struct pi_desc *pi_desc){	return test_and_set_bit(POSTED_INTR_ON,			(unsigned long *)&pi_desc->control);}",11087
376,2369,CVE-2016-3156,23,"int fib_unmerge(struct net *net){	struct fib_table *old, *new;	 	old = fib_get_table(net, RT_TABLE_LOCAL);	if (!old)		return 0;	new = fib_trie_unmerge(old);	if (!new)		return -ENOMEM;	 	if (new != old) {		fib_replace_table(net, old, new);		fib_free_table(old);	}	return 0;}",17338
456,698,CVE-2011-2918,23,"static int x86_pmu_commit_txn(struct pmu *pmu){	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	int assign[X86_PMC_IDX_MAX];	int n, ret;	n = cpuc->n_events;	if (!x86_pmu_initialized())		return -EAGAIN;	ret = x86_pmu.schedule_events(cpuc, n, assign);	if (ret)		return ret;	 	memcpy(cpuc->assign, assign, n*sizeof(int));	cpuc->group_flag &= ~PERF_EVENT_TXN;	perf_pmu_enable(pmu);	return 0;}",6090
489,308,CVE-2012-1601,23,"void kvm_lmsw(struct kvm_vcpu *vcpu, unsigned long msw){	(void)kvm_set_cr0(vcpu, kvm_read_cr0_bits(vcpu, ~0x0eul) | (msw & 0x0f));}",3786
194,600,CVE-2011-2918,23,"fmov_reg_reg(struct sh_fpu_soft_struct *fregs, struct pt_regs *regs, int m,	     int n){	if (FPSCR_SZ) {		FMOV_EXT(m);		FMOV_EXT(n);		DRn = DRm;	} else {		FRn = FRm;	}	return 0;}",5992
569,377,CVE-2012-0207,23,"static void igmp_gq_timer_expire(unsigned long data){	struct in_device *in_dev = (struct in_device *)data;	in_dev->mr_gq_running = 0;	igmpv3_send_report(in_dev, NULL);	__in_dev_put(in_dev);}",4117
363,682,CVE-2011-2918,23,"static inline int match_prev_assignment(struct hw_perf_event *hwc,					struct cpu_hw_events *cpuc,					int i){	return hwc->idx == cpuc->assign[i] &&		hwc->last_cpu == smp_processor_id() &&		hwc->last_tag == cpuc->tags[i];}",6074
169,1461,CVE-2013-1767,23,"static int shmem_statfs(struct dentry *dentry, struct kstatfs *buf){	struct shmem_sb_info *sbinfo = SHMEM_SB(dentry->d_sb);	buf->f_type = TMPFS_MAGIC;	buf->f_bsize = PAGE_CACHE_SIZE;	buf->f_namelen = NAME_MAX;	if (sbinfo->max_blocks) {		buf->f_blocks = sbinfo->max_blocks;		buf->f_bavail =		buf->f_bfree  = sbinfo->max_blocks -				percpu_counter_sum(&sbinfo->used_blocks);	}	if (sbinfo->max_inodes) {		buf->f_files = sbinfo->max_inodes;		buf->f_ffree = sbinfo->free_inodes;	}	 	return 0;}",9660
79,1017,CVE-2011-2918,23,"static inline void update_load_set(struct load_weight *lw, unsigned long w){	lw->weight = w;	lw->inv_weight = 0;}",6409
446,1738,CVE-2014-7145,23,"create_durable_buf(void){	struct create_durable *buf;	buf = kzalloc(sizeof(struct create_durable), GFP_KERNEL);	if (!buf)		return NULL;	buf->ccontext.DataOffset = cpu_to_le16(offsetof					(struct create_durable, Data));	buf->ccontext.DataLength = cpu_to_le32(16);	buf->ccontext.NameOffset = cpu_to_le16(offsetof				(struct create_durable, Name));	buf->ccontext.NameLength = cpu_to_le16(4);	 	buf->Name[0] = 'D';	buf->Name[1] = 'H';	buf->Name[2] = 'n';	buf->Name[3] = 'Q';	return buf;}",10562
403,1694,CVE-2014-8116,23,"getu32(int swap, int value){	union {		int ui;		char c[4];	} retval, tmpval;	if (swap) {		tmpval.ui = value;		retval.c[0] = tmpval.c[3];		retval.c[1] = tmpval.c[2];		retval.c[2] = tmpval.c[1];		retval.c[3] = tmpval.c[0];				return retval.ui;	} else		return value;}",10472
36,155,CVE-2012-2133,23,static int hugetlbfs_set_page_dirty(struct page *page){	struct page *head = compound_head(page);	SetPageDirty(head);	return 0;},3499
361,764,CVE-2011-2918,23,"static unsigned long get_flags(struct task_struct *task){	unsigned long retval = task_pt_regs(task)->flags;	 	if (test_tsk_thread_flag(task, TIF_FORCED_TF))		retval &= ~X86_EFLAGS_TF;	return retval;}",6156
208,1482,CVE-2013-0217,23,"static int netbk_gop_skb(struct sk_buff *skb,			 struct netrx_pending_operations *npo){	struct xenvif *vif = netdev_priv(skb->dev);	int nr_frags = skb_shinfo(skb)->nr_frags;	int i;	struct xen_netif_rx_request *req;	struct netbk_rx_meta *meta;	unsigned char *data;	int head = 1;	int old_meta_prod;	old_meta_prod = npo->meta_prod;	 	if (skb_shinfo(skb)->gso_size && vif->gso_prefix) {		req = RING_GET_REQUEST(&vif->rx, vif->rx.req_cons++);		meta = npo->meta + npo->meta_prod++;		meta->gso_size = skb_shinfo(skb)->gso_size;		meta->size = 0;		meta->id = req->id;	}	req = RING_GET_REQUEST(&vif->rx, vif->rx.req_cons++);	meta = npo->meta + npo->meta_prod++;	if (!vif->gso_prefix)		meta->gso_size = skb_shinfo(skb)->gso_size;	else		meta->gso_size = 0;	meta->size = 0;	meta->id = req->id;	npo->copy_off = 0;	npo->copy_gref = req->gref;	data = skb->data;	while (data < skb_tail_pointer(skb)) {		unsigned int offset = offset_in_page(data);		unsigned int len = PAGE_SIZE - offset;		if (data + len > skb_tail_pointer(skb))			len = skb_tail_pointer(skb) - data;		netbk_gop_frag_copy(vif, skb, npo,				    virt_to_page(data), len, offset, &head);		data += len;	}	for (i = 0; i < nr_frags; i++) {		netbk_gop_frag_copy(vif, skb, npo,				    skb_frag_page(&skb_shinfo(skb)->frags[i]),				    skb_frag_size(&skb_shinfo(skb)->frags[i]),				    skb_shinfo(skb)->frags[i].page_offset,				    &head);	}	return npo->meta_prod - old_meta_prod;}",9779
47,953,CVE-2011-2918,23,"struct ring_buffer *rb_alloc(int nr_pages, long watermark, int cpu, int flags){	struct ring_buffer *rb;	unsigned long size;	void *all_buf;	size = sizeof(struct ring_buffer);	size += sizeof(void *);	rb = kzalloc(size, GFP_KERNEL);	if (!rb)		goto fail;	INIT_WORK(&rb->work, rb_free_work);	all_buf = vmalloc_user((nr_pages + 1) * PAGE_SIZE);	if (!all_buf)		goto fail_all_buf;	rb->user_page = all_buf;	rb->data_pages[0] = all_buf + PAGE_SIZE;	rb->page_order = ilog2(nr_pages);	rb->nr_pages = 1;	ring_buffer_init(rb, watermark, flags);	return rb;fail_all_buf:	kfree(rb);fail:	return NULL;}",6345
249,2300,CVE-2014-9428,23,static int batadv_frag_size_limit(void){	int limit = BATADV_FRAG_MAX_FRAG_SIZE;	limit -= sizeof(struct batadv_frag_packet);	limit *= BATADV_FRAG_MAX_FRAGMENTS;	return limit;},14483
443,1744,CVE-2014-7145,23,"smb2_echo_callback(struct mid_q_entry *mid){	struct TCP_Server_Info *server = mid->callback_data;	struct smb2_echo_rsp *smb2 = (struct smb2_echo_rsp *)mid->resp_buf;	unsigned int credits_received = 1;	if (mid->mid_state == MID_RESPONSE_RECEIVED)		credits_received = le16_to_cpu(smb2->hdr.CreditRequest);	DeleteMidQEntry(mid);	add_credits(server, credits_received, CIFS_ECHO_OP);}",10568
542,47,CVE-2016-2179,23,"unsigned int dtls_raw_hello_verify_request(unsigned char *buf,                                           unsigned char *cookie,                                           unsigned char cookie_len){    unsigned int msg_len;    unsigned char *p;    p = buf;         *(p++) = DTLS1_VERSION >> 8;    *(p++) = DTLS1_VERSION & 0xFF;    *(p++) = (unsigned char)cookie_len;    memcpy(p, cookie, cookie_len);    p += cookie_len;    msg_len = p - buf;    return msg_len;}",2078
125,2419,CVE-2015-8877,23,static double filter_cubic_convolution(const double x1){	const double x = x1 < 0.0 ? -x1 : x1;	const double x2 = x1 * x1;	const double x2_x = x2 * x;	if (x <= 1.0) return ((4.0 / 3.0)* x2_x - (7.0 / 3.0) * x2 + 1.0);	if (x <= 2.0) return (- (7.0 / 12.0) * x2_x + 3 * x2 - (59.0 / 12.0) * x + 2.5);	if (x <= 3.0) return ( (1.0/12.0) * x2_x - (2.0 / 3.0) * x2 + 1.75 * x - 1.5);	return 0;},18450
369,329,CVE-2012-1601,23,"static void kvm_vcpu_ioctl_x86_get_debugregs(struct kvm_vcpu *vcpu,					     struct kvm_debugregs *dbgregs){	memcpy(dbgregs->db, vcpu->arch.db, sizeof(vcpu->arch.db));	dbgregs->dr6 = vcpu->arch.dr6;	dbgregs->dr7 = vcpu->arch.dr7;	dbgregs->flags = 0;	memset(&dbgregs->reserved, 0, sizeof(dbgregs->reserved));}",3807
304,1693,CVE-2014-8116,23,"getu16(int swap, int value){	union {		int ui;		char c[2];	} retval, tmpval;	if (swap) {		tmpval.ui = value;		retval.c[0] = tmpval.c[1];		retval.c[1] = tmpval.c[0];				return retval.ui;	} else		return value;}",10471
633,1110,CVE-2013-4592,23,"static void kvm_mmu_notifier_release(struct mmu_notifier *mn,				     struct mm_struct *mm){	struct kvm *kvm = mmu_notifier_to_kvm(mn);	int idx;	idx = srcu_read_lock(&kvm->srcu);	kvm_arch_flush_shadow_all(kvm);	srcu_read_unlock(&kvm->srcu, idx);}",7514
28,684,CVE-2011-2918,23,"perf_callchain_user32(struct pt_regs *regs, struct perf_callchain_entry *entry){    return 0;}",6076
80,2379,CVE-2016-2847,23,"pipe_fasync(int fd, struct file *filp, int on){	struct pipe_inode_info *pipe = filp->private_data;	int retval = 0;	__pipe_lock(pipe);	if (filp->f_mode & FMODE_READ)		retval = fasync_helper(fd, filp, on, &pipe->fasync_readers);	if ((filp->f_mode & FMODE_WRITE) && retval >= 0) {		retval = fasync_helper(fd, filp, on, &pipe->fasync_writers);		if (retval < 0 && (filp->f_mode & FMODE_READ))			 			fasync_helper(-1, filp, 0, &pipe->fasync_readers);	}	__pipe_unlock(pipe); 	return retval; }",17473
241,2680,CVE-2011-1479,23,"static void inotify_free_group_priv(struct fsnotify_group *group){	  	idr_for_each(&group->inotify_data.idr, idr_callback, group); 	idr_remove_all(&group->inotify_data.idr); 	idr_destroy(&group->inotify_data.idr); 	free_uid(group->inotify_data.user); }",31029
567,2010,CVE-2014-1444,23,"fst_intr(int dummy, void *dev_id){	struct fst_card_info *card = dev_id;	struct fst_port_info *port;	int rdidx;		 	int wridx;	int event;		 	unsigned int dma_intcsr = 0;	unsigned int do_card_interrupt;	unsigned int int_retry_count;	 	dbg(DBG_INTR, ""intr: %d %p\n"", card->irq, card);	if (card->state != FST_RUNNING) {		pr_err(""Interrupt received for card %d in a non running state (%d)\n"",		       card->card_no, card->state);		 		fst_clear_intr(card);		return IRQ_HANDLED;	}	 	fst_clear_intr(card);	 	do_card_interrupt = 0;	if (FST_RDB(card, interruptHandshake) == 1) {		do_card_interrupt += FST_CARD_INT;		 		FST_WRB(card, interruptHandshake, 0xEE);	}	if (card->family == FST_FAMILY_TXU) {		 		dma_intcsr = inl(card->pci_conf + INTCSR_9054);		if (dma_intcsr & 0x00200000) {			 			dbg(DBG_RX, ""DMA Rx xfer complete\n"");			outb(0x8, card->pci_conf + DMACSR0);			fst_rx_dma_complete(card, card->dma_port_rx,					    card->dma_len_rx, card->dma_skb_rx,					    card->dma_rxpos);			card->dmarx_in_progress = 0;			do_card_interrupt += FST_RX_DMA_INT;		}		if (dma_intcsr & 0x00400000) {			 			dbg(DBG_TX, ""DMA Tx xfer complete\n"");			outb(0x8, card->pci_conf + DMACSR1);			fst_tx_dma_complete(card, card->dma_port_tx,					    card->dma_len_tx, card->dma_txpos);			card->dmatx_in_progress = 0;			do_card_interrupt += FST_TX_DMA_INT;		}	}	 	int_retry_count = FST_RDL(card, interruptRetryCount);	if (int_retry_count) {		dbg(DBG_ASS, ""Card %d int_retry_count is  %d\n"",		    card->card_no, int_retry_count);		FST_WRL(card, interruptRetryCount, 0);	}	if (!do_card_interrupt) {		return IRQ_HANDLED;	}	 	fst_q_work_item(&fst_work_intq, card->card_no);	tasklet_schedule(&fst_int_task);	 	rdidx = FST_RDB(card, interruptEvent.rdindex) & 0x1f;	wridx = FST_RDB(card, interruptEvent.wrindex) & 0x1f;	while (rdidx != wridx) {		event = FST_RDB(card, interruptEvent.evntbuff[rdidx]);		port = &card->ports[event & 0x03];		dbg(DBG_INTR, ""Processing Interrupt event: %x\n"", event);		switch (event) {		case TE1_ALMA:			dbg(DBG_INTR, ""TE1 Alarm intr\n"");			if (port->run)				fst_intr_te1_alarm(card, port);			break;		case CTLA_CHG:		case CTLB_CHG:		case CTLC_CHG:		case CTLD_CHG:			if (port->run)				fst_intr_ctlchg(card, port);			break;		case ABTA_SENT:		case ABTB_SENT:		case ABTC_SENT:		case ABTD_SENT:			dbg(DBG_TX, ""Abort complete port %d\n"", port->index);			break;		case TXA_UNDF:		case TXB_UNDF:		case TXC_UNDF:		case TXD_UNDF:			 			dbg(DBG_TX, ""Tx underflow port %d\n"", port->index);			port_to_dev(port)->stats.tx_errors++;			port_to_dev(port)->stats.tx_fifo_errors++;			dbg(DBG_ASS, ""Tx underflow on card %d port %d\n"",			    card->card_no, port->index);			break;		case INIT_CPLT:			dbg(DBG_INIT, ""Card init OK intr\n"");			break;		case INIT_FAIL:			dbg(DBG_INIT, ""Card init FAILED intr\n"");			card->state = FST_IFAILED;			break;		default:			pr_err(""intr: unknown card event %d. ignored\n"", event);			break;		}		 		if (++rdidx >= MAX_CIRBUFF)			rdidx = 0;	}	FST_WRB(card, interruptEvent.rdindex, rdidx);        return IRQ_HANDLED;}",12048
381,2280,CVE-2014-9620,23,"parse_apple(struct magic_set *ms, struct magic_entry *me, const char *line){	struct magic *m = &me->mp[0];	return parse_extra(ms, me, line, offsetof(struct magic, apple),	    sizeof(m->apple), ""APPLE"", ""!+-./"", 0);}",14453
571,2496,CVE-2019-15921,23,void genl_unlock(void){	mutex_unlock(&genl_mutex);},26569
157,245,CVE-2012-1601,23,"int emulator_set_dr(struct x86_emulate_ctxt *ctxt, int dr, unsigned long value){	return __kvm_set_dr(emul_to_vcpu(ctxt), dr, value);}",3723
274,1067,CVE-2013-5634,23,static void exit_vm_noop(void *info){},7471
500,183,CVE-2012-1601,23,"int kvm_arch_init_vm(struct kvm *kvm){	BUG_ON(!kvm);	kvm->arch.is_sn2 = ia64_platform_is(""sn2"");	kvm->arch.metaphysical_rr0 = GUEST_PHYSICAL_RR0;	kvm->arch.metaphysical_rr4 = GUEST_PHYSICAL_RR4;	kvm->arch.vmm_init_rr = VMM_INIT_RR;	 	kvm_build_io_pmt(kvm);	INIT_LIST_HEAD(&kvm->arch.assigned_dev_head);	 	set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);	return 0;}",3661
463,2146,CVE-2015-6526,23,"static int is_sigreturn_32_address(unsigned int nip, unsigned int fp){	if (nip == fp + offsetof(struct signal_frame_32, mctx.mc_pad))		return 1;	if (vdso32_sigtramp && current->mm->context.vdso_base &&	    nip == current->mm->context.vdso_base + vdso32_sigtramp)		return 1;	return 0;}",13118
338,2471,CVE-2015-1339,23,"static int cuse_release(struct inode *inode, struct file *file){	struct fuse_file *ff = file->private_data;	struct fuse_conn *fc = ff->fc;	fuse_sync_release(ff, file->f_flags);	fuse_conn_put(fc);	return 0;}",19214
39,1081,CVE-2013-5634,23,void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu){	kvm_arch_vcpu_free(vcpu);},7485
604,2641,CVE-2012-3510,23," void xacct_add_tsk(struct taskstats *stats, struct task_struct *p) { 	  	stats->coremem = jiffies_to_usecs(p->acct_rss_mem1) * PAGE_SIZE / MB; 	stats->virtmem = jiffies_to_usecs(p->acct_vm_mem1) * PAGE_SIZE / MB;	if (p->mm) { 		 		stats->hiwater_rss   = p->mm->hiwater_rss * PAGE_SIZE / KB;		stats->hiwater_vm    = p->mm->hiwater_vm * PAGE_SIZE / KB; 	} 	stats->read_char	= p->rchar; 	stats->write_char	= p->wchar;	stats->read_syscalls	= p->syscr;	stats->write_syscalls	= p->syscw;}",30934
666,1084,CVE-2013-5634,23,"int kvm_arch_vcpu_ioctl_get_mpstate(struct kvm_vcpu *vcpu,				    struct kvm_mp_state *mp_state){	return -EINVAL;}",7488
590,2269,CVE-2015-5307,23,"static void vmx_slot_disable_log_dirty(struct kvm *kvm,				       struct kvm_memory_slot *slot){	kvm_mmu_slot_set_dirty(kvm, slot);}",13391
377,283,CVE-2012-1601,23,void kvm_arch_vcpu_put(struct kvm_vcpu *vcpu){	kvm_x86_ops->vcpu_put(vcpu);	kvm_put_guest_fpu(vcpu);	vcpu->arch.last_guest_tsc = kvm_x86_ops->read_l1_tsc(vcpu);},3761
73,211,CVE-2012-1601,23,"int kvm_highest_pending_irq(struct kvm_vcpu *vcpu){    struct vpd *vpd = to_host(vcpu->kvm, vcpu->arch.vpd);    if (vpd->irr[0] & (1UL << NMI_VECTOR))		return NMI_VECTOR;    if (vpd->irr[0] & (1UL << ExtINT_VECTOR))		return ExtINT_VECTOR;    return find_highest_bits((int *)&vpd->irr[0]);}",3689
448,1798,CVE-2014-3690,23,static inline int cpu_has_virtual_nmis(void){	return vmcs_config.pin_based_exec_ctrl & PIN_BASED_VIRTUAL_NMIS;},10986
353,1785,CVE-2014-6410,23,"static int udf_writepages(struct address_space *mapping,			struct writeback_control *wbc){	return mpage_writepages(mapping, wbc, udf_get_block);}",10609
130,1978,CVE-2014-1446,23,"static void fpga_reset(int iobase){	outb(0, IER(iobase));	outb(LCR_DLAB | LCR_BIT5, LCR(iobase));	outb(1, DLL(iobase));	outb(0, DLM(iobase));	outb(LCR_BIT5, LCR(iobase));	inb(LSR(iobase));	inb(MSR(iobase));	 	outb(MCR_OUT1 | MCR_OUT2, MCR(iobase));	delay(100);	 	outb(MCR_DTR | MCR_RTS | MCR_OUT1 | MCR_OUT2, MCR(iobase));	delay(100);}",12016
136,1042,CVE-2011-0716,23,"void br_multicast_add_port(struct net_bridge_port *port){	port->multicast_router = 1;	setup_timer(&port->multicast_router_timer, br_multicast_router_expired,		    (unsigned long)port);	setup_timer(&port->multicast_query_timer,		    br_multicast_port_query_expired, (unsigned long)port);}",6980
247,2495,CVE-2019-15921,23,"static int genl_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh,			struct netlink_ext_ack *extack){	const struct genl_family *family;	int err;	family = genl_family_find_byid(nlh->nlmsg_type);	if (family == NULL)		return -ENOENT;	if (!family->parallel_ops)		genl_lock();	err = genl_family_rcv_msg(family, skb, nlh, extack);	if (!family->parallel_ops)		genl_unlock();	return err;}",26568
548,1702,CVE-2014-7841,23,void sctp_chunk_free(struct sctp_chunk *chunk){	 	if (chunk->msg)		sctp_datamsg_put(chunk->msg);	sctp_chunk_put(chunk);},10510
27,1852,CVE-2014-3690,23,static int handle_cpuid(struct kvm_vcpu *vcpu){	kvm_emulate_cpuid(vcpu);	return 1;},11040
544,443,CVE-2011-2918,23,"static void alpha_pmu_stop(struct perf_event *event, int flags){	struct hw_perf_event *hwc = &event->hw;	struct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);	if (!(hwc->state & PERF_HES_STOPPED)) {		cpuc->idx_mask &= ~(1UL<<hwc->idx);		hwc->state |= PERF_HES_STOPPED;	}	if ((flags & PERF_EF_UPDATE) && !(hwc->state & PERF_HES_UPTODATE)) {		alpha_perf_event_update(event, hwc, hwc->idx, 0);		hwc->state |= PERF_HES_UPTODATE;	}	if (cpuc->enabled)		wrperfmon(PERFMON_CMD_DISABLE, (1UL<<hwc->idx));}",5835
260,51,CVE-2016-0798,23,"static void close_accept_socket(void){    BIO_printf(bio_err, ""shutdown accept socket\n"");    if (accept_socket >= 0) {        SHUTDOWN2(accept_socket);    }}",2223
373,135,CVE-2012-2390,23,"static void set_vma_resv_map(struct vm_area_struct *vma, struct resv_map *map){	VM_BUG_ON(!is_vm_hugetlb_page(vma));	VM_BUG_ON(vma->vm_flags & VM_MAYSHARE);	set_vma_private_data(vma, (get_vma_private_data(vma) &				HPAGE_RESV_MASK) | (unsigned long)map);}",3207
458,884,CVE-2011-2918,23,static int perf_pmu_commit_txn(struct pmu *pmu){	perf_pmu_enable(pmu);	return 0;},6276
427,180,CVE-2012-1601,23,"void kvm_arch_free_vm(struct kvm *kvm){	unsigned long vm_base = kvm->arch.vm_base;	if (vm_base) {		memset((void *)vm_base, 0, KVM_VM_DATA_SIZE);		free_pages(vm_base, get_order(KVM_VM_DATA_SIZE));	}}",3658
392,1816,CVE-2014-3690,23,static inline int cpu_has_vmx_ple(void){	return vmcs_config.cpu_based_2nd_exec_ctrl &		SECONDARY_EXEC_PAUSE_LOOP_EXITING;},11004
10,1071,CVE-2013-5634,23,void kvm_arch_destroy_vm(struct kvm *kvm){	int i;	kvm_free_stage2_pgd(kvm);	for (i = 0; i < KVM_MAX_VCPUS; ++i) {		if (kvm->vcpus[i]) {			kvm_arch_vcpu_free(kvm->vcpus[i]);			kvm->vcpus[i] = NULL;		}	}},7475
646,1956,CVE-2014-3690,23,static void vmx_vcpu_put(struct kvm_vcpu *vcpu){	__vmx_load_host_state(to_vmx(vcpu));	if (!vmm_exclusive) {		__loaded_vmcs_clear(to_vmx(vcpu)->loaded_vmcs);		vcpu->cpu = -1;		kvm_cpu_vmxoff();	}},11144
328,1563,CVE-2011-2491,23,"rpc_release_client(struct rpc_clnt *clnt){	dprintk(""RPC:       rpc_release_client(%p)\n"", clnt);	if (list_empty(&clnt->cl_tasks))		wake_up(&destroy_wait);	if (atomic_dec_and_test(&clnt->cl_count))		rpc_free_auth(clnt);}",10182
514,22,CVE-2016-7421,23,pvscsi_log2(int input){    int log = 0;    assert(input > 0);    while (input >> ++log) {    }    return log;},1321
221,1604,CVE-2011-2491,23,"static inline void rpc_reset_waitqueue_priority(struct rpc_wait_queue *queue){	rpc_set_waitqueue_priority(queue, queue->maxpriority);	rpc_set_waitqueue_owner(queue, 0);}",10223
549,2417,CVE-2015-8877,23,static double filter_catmullrom(const double x){	if (x < -2.0)		return(0.0f);	if (x < -1.0)		return(0.5f*(4.0f+x*(8.0f+x*(5.0f+x))));	if (x < 0.0)		return(0.5f*(2.0f+x*x*(-5.0f-3.0f*x)));	if (x < 1.0)		return(0.5f*(2.0f+x*x*(-5.0f+3.0f*x)));	if (x < 2.0)		return(0.5f*(4.0f+x*(-8.0f+x*(5.0f-x))));	return(0.0f);},18448
295,2113,CVE-2012-6638,23,static inline void tcp_store_ts_recent(struct tcp_sock *tp){	tp->rx_opt.ts_recent = tp->rx_opt.rcv_tsval;	tp->rx_opt.ts_recent_stamp = get_seconds();},12747
289,1565,CVE-2011-2491,23,rpc_restart_call_prepare(struct rpc_task *task){	if (RPC_ASSASSINATED(task))		return 0;	task->tk_action = rpc_prepare_task;	return 1;},10184
404,711,CVE-2011-2918,23,static inline void x86_pmu_read(struct perf_event *event){	x86_perf_event_update(event);},6103
335,48,CVE-2016-10163,23,"static int vrend_decode_create_ve(struct vrend_decode_ctx *ctx, int handle, int length){   struct pipe_vertex_element *ve = NULL;   int num_elements;   int i;   int ret;   if (length < 1)      return EINVAL;   if ((length - 1) % 4)      return EINVAL;   num_elements = (length - 1) / 4;   if (num_elements) {      ve = calloc(num_elements, sizeof(struct pipe_vertex_element));      if (!ve)         return ENOMEM;      for (i = 0; i < num_elements; i++) {         ve[i].src_offset = get_buf_entry(ctx, VIRGL_OBJ_VERTEX_ELEMENTS_V0_SRC_OFFSET(i));         ve[i].instance_divisor = get_buf_entry(ctx, VIRGL_OBJ_VERTEX_ELEMENTS_V0_INSTANCE_DIVISOR(i));         ve[i].vertex_buffer_index = get_buf_entry(ctx, VIRGL_OBJ_VERTEX_ELEMENTS_V0_VERTEX_BUFFER_INDEX(i));         ve[i].src_format = get_buf_entry(ctx, VIRGL_OBJ_VERTEX_ELEMENTS_V0_SRC_FORMAT(i));      }   }   ret = vrend_create_vertex_elements_state(ctx->grctx, handle, num_elements, ve);   FREE(ve);   return ret;}",2217
474,2649,CVE-2012-2133,23,"static void free_huge_page(struct page *page){	  	struct hstate *h = page_hstate(page); 	int nid = page_to_nid(page);	struct address_space *mapping; 	mapping = (struct address_space *) page_private(page); 	set_page_private(page, 0); 	page->mapping = NULL; 	BUG_ON(page_count(page));	BUG_ON(page_mapcount(page));	INIT_LIST_HEAD(&page->lru);	spin_lock(&hugetlb_lock);	if (h->surplus_huge_pages_node[nid] && huge_page_order(h) < MAX_ORDER) {		update_and_free_page(h, page);		h->surplus_huge_pages--;		h->surplus_huge_pages_node[nid]--;	} else { 		enqueue_huge_page(h, page); 	} 	spin_unlock(&hugetlb_lock);	if (mapping)		hugetlb_put_quota(mapping, 1); }",30944
428,1187,CVE-2013-2635,23,"static int rtnl_fdb_add(struct sk_buff *skb, struct nlmsghdr *nlh, void *arg){	struct net *net = sock_net(skb->sk);	struct ndmsg *ndm;	struct nlattr *tb[NDA_MAX+1];	struct net_device *dev;	u8 *addr;	int err;	err = nlmsg_parse(nlh, sizeof(*ndm), tb, NDA_MAX, NULL);	if (err < 0)		return err;	ndm = nlmsg_data(nlh);	if (ndm->ndm_ifindex == 0) {		pr_info(""PF_BRIDGE: RTM_NEWNEIGH with invalid ifindex\n"");		return -EINVAL;	}	dev = __dev_get_by_index(net, ndm->ndm_ifindex);	if (dev == NULL) {		pr_info(""PF_BRIDGE: RTM_NEWNEIGH with unknown ifindex\n"");		return -ENODEV;	}	if (!tb[NDA_LLADDR] || nla_len(tb[NDA_LLADDR]) != ETH_ALEN) {		pr_info(""PF_BRIDGE: RTM_NEWNEIGH with invalid address\n"");		return -EINVAL;	}	addr = nla_data(tb[NDA_LLADDR]);	if (!is_valid_ether_addr(addr)) {		pr_info(""PF_BRIDGE: RTM_NEWNEIGH with invalid ether address\n"");		return -EINVAL;	}	err = -EOPNOTSUPP;	 	if ((!ndm->ndm_flags || ndm->ndm_flags & NTF_MASTER) &&	    (dev->priv_flags & IFF_BRIDGE_PORT)) {		struct net_device *br_dev = netdev_master_upper_dev_get(dev);		const struct net_device_ops *ops = br_dev->netdev_ops;		err = ops->ndo_fdb_add(ndm, tb, dev, addr, nlh->nlmsg_flags);		if (err)			goto out;		else			ndm->ndm_flags &= ~NTF_MASTER;	}	 	if ((ndm->ndm_flags & NTF_SELF) && dev->netdev_ops->ndo_fdb_add) {		err = dev->netdev_ops->ndo_fdb_add(ndm, tb,						   dev, addr,						   nlh->nlmsg_flags);		if (!err) {			rtnl_fdb_notify(dev, addr, RTM_NEWNEIGH);			ndm->ndm_flags &= ~NTF_SELF;		}	}out:	return err;}",8525
314,797,CVE-2011-2918,23,"static int __perf_event_enable(void *info){	struct perf_event *event = info;	struct perf_event_context *ctx = event->ctx;	struct perf_event *leader = event->group_leader;	struct perf_cpu_context *cpuctx = __get_cpu_context(ctx);	int err;	if (WARN_ON_ONCE(!ctx->is_active))		return -EINVAL;	raw_spin_lock(&ctx->lock);	update_context_time(ctx);	if (event->state >= PERF_EVENT_STATE_INACTIVE)		goto unlock;	 	perf_cgroup_set_timestamp(current, ctx);	__perf_event_mark_enabled(event, ctx);	if (!event_filter_match(event)) {		if (is_cgroup_event(event))			perf_cgroup_defer_enabled(event);		goto unlock;	}	 	if (leader != event && leader->state != PERF_EVENT_STATE_ACTIVE)		goto unlock;	if (!group_can_go_on(event, cpuctx, 1)) {		err = -EEXIST;	} else {		if (event == leader)			err = group_sched_in(event, cpuctx, ctx);		else			err = event_sched_in(event, cpuctx, ctx);	}	if (err) {		 		if (leader != event)			group_sched_out(leader, cpuctx, ctx);		if (leader->attr.pinned) {			update_group_times(leader);			leader->state = PERF_EVENT_STATE_ERROR;		}	}unlock:	raw_spin_unlock(&ctx->lock);	return 0;}",6189
145,309,CVE-2012-1601,23,void kvm_load_guest_fpu(struct kvm_vcpu *vcpu){	if (vcpu->guest_fpu_loaded)		return;	 	kvm_put_guest_xcr0(vcpu);	vcpu->guest_fpu_loaded = 1;	unlazy_fpu(current);	fpu_restore_checking(&vcpu->arch.guest_fpu);	trace_kvm_fpu(1);},3787
525,299,CVE-2012-1601,23,static unsigned long kvm_get_guest_ip(void){	unsigned long ip = 0;	if (__this_cpu_read(current_vcpu))		ip = kvm_rip_read(__this_cpu_read(current_vcpu));	return ip;},3777
334,1099,CVE-2013-5634,23,"static int vcpu_interrupt_line(struct kvm_vcpu *vcpu, int number, int level){	int bit_index;	int set;	unsigned long *ptr;	if (number == KVM_ARM_IRQ_CPU_IRQ)		bit_index = __ffs(HCR_VI);	else  		bit_index = __ffs(HCR_VF);	ptr = (unsigned long *)&vcpu->arch.irq_lines;	if (level)		set = test_and_set_bit(bit_index, ptr);	else		set = test_and_clear_bit(bit_index, ptr);	 	if (set == level)		return 0;	 	kvm_vcpu_kick(vcpu);	return 0;}",7503
452,1102,CVE-2013-4592,23,"void kvm_flush_remote_tlbs(struct kvm *kvm){	long dirty_count = kvm->tlbs_dirty;	smp_mb();	if (make_all_cpus_request(kvm, KVM_REQ_TLB_FLUSH))		++kvm->stat.remote_tlb_flush;	cmpxchg(&kvm->tlbs_dirty, dirty_count, 0);}",7506
528,1562,CVE-2011-2491,23,"static void rpc_register_client(struct rpc_clnt *clnt){	spin_lock(&rpc_client_lock);	list_add(&clnt->cl_clients, &all_clients);	spin_unlock(&rpc_client_lock);}",10181
538,715,CVE-2011-2918,23,"intel_bts_constraints(struct perf_event *event){	struct hw_perf_event *hwc = &event->hw;	unsigned int hw_event, bts_event;	if (event->attr.freq)		return NULL;	hw_event = hwc->config & INTEL_ARCH_EVENT_MASK;	bts_event = x86_pmu.event_map(PERF_COUNT_HW_BRANCH_INSTRUCTIONS);	if (unlikely(hw_event == bts_event && hwc->sample_period == 1))		return &bts_constraint;	return NULL;}",6107
347,1894,CVE-2014-3690,23,"static int nested_vmx_exit_handled_cr(struct kvm_vcpu *vcpu,	struct vmcs12 *vmcs12){	unsigned long exit_qualification = vmcs_readl(EXIT_QUALIFICATION);	int cr = exit_qualification & 15;	int reg = (exit_qualification >> 8) & 15;	unsigned long val = kvm_register_readl(vcpu, reg);	switch ((exit_qualification >> 4) & 3) {	case 0:  		switch (cr) {		case 0:			if (vmcs12->cr0_guest_host_mask &			    (val ^ vmcs12->cr0_read_shadow))				return 1;			break;		case 3:			if ((vmcs12->cr3_target_count >= 1 &&					vmcs12->cr3_target_value0 == val) ||				(vmcs12->cr3_target_count >= 2 &&					vmcs12->cr3_target_value1 == val) ||				(vmcs12->cr3_target_count >= 3 &&					vmcs12->cr3_target_value2 == val) ||				(vmcs12->cr3_target_count >= 4 &&					vmcs12->cr3_target_value3 == val))				return 0;			if (nested_cpu_has(vmcs12, CPU_BASED_CR3_LOAD_EXITING))				return 1;			break;		case 4:			if (vmcs12->cr4_guest_host_mask &			    (vmcs12->cr4_read_shadow ^ val))				return 1;			break;		case 8:			if (nested_cpu_has(vmcs12, CPU_BASED_CR8_LOAD_EXITING))				return 1;			break;		}		break;	case 2:  		if ((vmcs12->cr0_guest_host_mask & X86_CR0_TS) &&		    (vmcs12->cr0_read_shadow & X86_CR0_TS))			return 1;		break;	case 1:  		switch (cr) {		case 3:			if (vmcs12->cpu_based_vm_exec_control &			    CPU_BASED_CR3_STORE_EXITING)				return 1;			break;		case 8:			if (vmcs12->cpu_based_vm_exec_control &			    CPU_BASED_CR8_STORE_EXITING)				return 1;			break;		}		break;	case 3:  		 		if (vmcs12->cr0_guest_host_mask & 0xe &		    (val ^ vmcs12->cr0_read_shadow))			return 1;		if ((vmcs12->cr0_guest_host_mask & 0x1) &&		    !(vmcs12->cr0_read_shadow & 0x1) &&		    (val & 0x1))			return 1;		break;	}	return 0;}",11082
191,2542,CVE-2011-1292,23,  AutoFillMetricsTest() {},29149
52,2238,CVE-2015-5307,23,"static int nested_vmx_load_msr_check(struct kvm_vcpu *vcpu,				     struct vmx_msr_entry *e){	if (e->index == MSR_FS_BASE ||	    e->index == MSR_GS_BASE ||	    e->index == MSR_IA32_SMM_MONITOR_CTL ||  	    nested_vmx_msr_check_common(vcpu, e))		return -EINVAL;	return 0;}",13360
659,2189,CVE-2015-5366,23,"static int __udpv6_queue_rcv_skb(struct sock *sk, struct sk_buff *skb){	int rc;	if (!ipv6_addr_any(&sk->sk_v6_daddr)) {		sock_rps_save_rxhash(sk, skb);		sk_mark_napi_id(sk, skb);		sk_incoming_cpu_update(sk);	}	rc = sock_queue_rcv_skb(sk, skb);	if (rc < 0) {		int is_udplite = IS_UDPLITE(sk);		 		if (rc == -ENOMEM)			UDP6_INC_STATS_BH(sock_net(sk),					UDP_MIB_RCVBUFERRORS, is_udplite);		UDP6_INC_STATS_BH(sock_net(sk), UDP_MIB_INERRORS, is_udplite);		kfree_skb(skb);		return -1;	}	return 0;}",13311
245,2100,CVE-2012-6638,23,"static void tcp_remove_reno_sacks(struct sock *sk, int acked){	struct tcp_sock *tp = tcp_sk(sk);	if (acked > 0) {		 		if (acked - 1 >= tp->sacked_out)			tp->sacked_out = 0;		else			tp->sacked_out -= acked - 1;	}	tcp_check_reno_reordering(sk, acked);	tcp_verify_left_out(tp);}",12734
396,891,CVE-2011-2918,23,static void perf_pmu_start_txn(struct pmu *pmu){	perf_pmu_disable(pmu);},6283
217,69,CVE-2012-4467,23,"int kernel_accept(struct socket *sock, struct socket **newsock, int flags){	struct sock *sk = sock->sk;	int err;	err = sock_create_lite(sk->sk_family, sk->sk_type, sk->sk_protocol,			       newsock);	if (err < 0)		goto done;	err = sock->ops->accept(sock, *newsock, flags);	if (err < 0) {		sock_release(*newsock);		*newsock = NULL;		goto done;	}	(*newsock)->ops = sock->ops;	__module_get((*newsock)->ops->owner);done:	return err;}",2737
133,2212,CVE-2015-5307,23,"static void free_vpid(int vpid){	if (!enable_vpid || vpid == 0)		return;	spin_lock(&vmx_vpid_lock);	__clear_bit(vpid, vmx_vpid_bitmap);	spin_unlock(&vmx_vpid_lock);}",13334
83,2435,CVE-2015-8785,23,"static long fuse_file_compat_ioctl(struct file *file, unsigned int cmd,				   unsigned long arg){	return fuse_ioctl_common(file, cmd, arg, FUSE_IOCTL_COMPAT);}",18708
99,2631,CVE-2014-1700,23,  SyncNavigationStateVisitor() {},29574
255,2447,CVE-2015-8785,23,"int fuse_open_common(struct inode *inode, struct file *file, int isdir){	struct fuse_conn *fc = get_fuse_conn(inode);	int err;	int lock_inode = (file->f_flags & O_TRUNC) &&			  fc->atomic_o_trunc &&			  fc->writeback_cache;	err = generic_file_open(inode, file);	if (err)		return err;	if (lock_inode)		mutex_lock(&inode->i_mutex);	err = fuse_do_open(fc, get_node_id(inode), file, isdir);	if (!err)		fuse_finish_open(inode, file);	if (lock_inode)		mutex_unlock(&inode->i_mutex);	return err;}",18720
383,32,CVE-2016-6301,23,"gettime1900d(void){	struct timeval tv;	gettimeofday(&tv, NULL);  	G.cur_time = tv.tv_sec + (1.0e-6 * tv.tv_usec) + OFFSET_1900_1970;	return G.cur_time;}",1657
619,1748,CVE-2014-7145,23,"validate_and_copy_buf(unsigned int offset, unsigned int buffer_length,		      struct smb2_hdr *hdr, unsigned int minbufsize,		      char *data){	char *begin_of_buf = 4   + offset + (char *)hdr;	int rc;	if (!data)		return -EINVAL;	rc = validate_buf(offset, buffer_length, hdr, minbufsize);	if (rc)		return rc;	memcpy(data, begin_of_buf, buffer_length);	return 0;}",10572
151,1471,CVE-2013-0281,23,mon_shutdown(int nsig){    clean_up(EX_OK);},9767
63,1277,CVE-2013-2017,23,"static void __netdev_init_queue_locks_one(struct net_device *dev,					  struct netdev_queue *dev_queue,					  void *_unused){	spin_lock_init(&dev_queue->_xmit_lock);	netdev_set_xmit_lockdep_class(&dev_queue->_xmit_lock, dev->type);	dev_queue->xmit_lock_owner = -1;}",8986
88,1241,CVE-2013-2141,23,"send_sig(int sig, struct task_struct *p, int priv){	return send_sig_info(sig, __si_special(priv), p);}",8847
511,2241,CVE-2015-5307,23,"static int nested_vmx_store_msr_check(struct kvm_vcpu *vcpu,				      struct vmx_msr_entry *e){	if (e->index == MSR_IA32_SMBASE ||  	    nested_vmx_msr_check_common(vcpu, e))		return -EINVAL;	return 0;}",13363
100,2682,CVE-2011-1479,23," static int inotify_release(struct inode *ignored, struct file *file) { 	struct fsnotify_group *group = file->private_data;	struct user_struct *user = group->inotify_data.user;  	pr_debug(""%s: group=%p\n"", __func__, group); 	fsnotify_clear_marks_by_group(group); 	  	fsnotify_put_group(group); 	atomic_dec(&user->inotify_devs); 	return 0; }",31031
640,142,CVE-2012-2390,23,unsigned long vma_kernel_pagesize(struct vm_area_struct *vma){	struct hstate *hstate;	if (!is_vm_hugetlb_page(vma))		return PAGE_SIZE;	hstate = hstate_vma(vma);	return 1UL << (hstate->order + PAGE_SHIFT);},3214
45,860,CVE-2011-2918,23,"void perf_event_header__init_id(struct perf_event_header *header,				struct perf_sample_data *data,				struct perf_event *event){	if (event->attr.sample_id_all)		__perf_event_header__init_id(header, data, event);}",6252
77,342,CVE-2012-1601,23,"static int kvm_vm_ioctl_set_irqchip(struct kvm *kvm, struct kvm_irqchip *chip){	int r;	r = 0;	switch (chip->chip_id) {	case KVM_IRQCHIP_PIC_MASTER:		spin_lock(&pic_irqchip(kvm)->lock);		memcpy(&pic_irqchip(kvm)->pics[0],			&chip->chip.pic,			sizeof(struct kvm_pic_state));		spin_unlock(&pic_irqchip(kvm)->lock);		break;	case KVM_IRQCHIP_PIC_SLAVE:		spin_lock(&pic_irqchip(kvm)->lock);		memcpy(&pic_irqchip(kvm)->pics[1],			&chip->chip.pic,			sizeof(struct kvm_pic_state));		spin_unlock(&pic_irqchip(kvm)->lock);		break;	case KVM_IRQCHIP_IOAPIC:		r = kvm_set_ioapic(kvm, &chip->chip.ioapic);		break;	default:		r = -EINVAL;		break;	}	kvm_pic_update_irq(pic_irqchip(kvm));	return r;}",3820
669,1115,CVE-2013-4592,23,void kvm_vcpu_kick(struct kvm_vcpu *vcpu){	int me;	int cpu = vcpu->cpu;	wait_queue_head_t *wqp;	wqp = kvm_arch_vcpu_wq(vcpu);	if (waitqueue_active(wqp)) {		wake_up_interruptible(wqp);		++vcpu->stat.halt_wakeup;	}	me = get_cpu();	if (cpu != me && (unsigned)cpu < nr_cpu_ids && cpu_online(cpu))		if (kvm_arch_vcpu_should_kick(vcpu))			smp_send_reschedule(cpu);	put_cpu();},7519
9,756,CVE-2011-2918,23,int kgdb_arch_init(void){ 	return register_die_notifier(&kgdb_notifier); },6148
339,1965,CVE-2014-3538,23,"check_format(struct magic_set *ms, struct magic *m){	char *ptr;	for (ptr = m->desc; *ptr; ptr++)		if (*ptr == '%')			break;	if (*ptr == '\0') {		 		return 1;	}	assert(file_nformats == file_nnames);	if (m->type >= file_nformats) {		file_magwarn(ms, ""Internal error inconsistency between ""		    ""m->type and format strings"");				return -1;	}	if (file_formats[m->type] == FILE_FMT_NONE) {		file_magwarn(ms, ""No format string for `%s' with description ""		    ""`%s'"", m->desc, file_names[m->type]);		return -1;	}	ptr++;	if (check_format_type(ptr, m->type) == -1) {		 		file_magwarn(ms, ""Printf format `%c' is not valid for type ""		    ""`%s' in description `%s'"", *ptr ? *ptr : '?',		    file_names[m->type], m->desc);		return -1;	}		for (; *ptr; ptr++) {		if (*ptr == '%') {			file_magwarn(ms,			    ""Too many format strings (should have at most one) ""			    ""for `%s' with description `%s'"",			    file_names[m->type], m->desc);			return -1;		}	}	return 0;}",11428
57,814,CVE-2011-2918,23,"ctx_group_list(struct perf_event *event, struct perf_event_context *ctx){	if (event->attr.pinned)		return &ctx->pinned_groups;	else		return &ctx->flexible_groups;}",6206
592,1428,CVE-2013-1767,23,"static struct inode *shmem_alloc_inode(struct super_block *sb){	struct shmem_inode_info *info;	info = kmem_cache_alloc(shmem_inode_cachep, GFP_KERNEL);	if (!info)		return NULL;	return &info->vfs_inode;}",9627
155,2226,CVE-2015-5307,23,static inline int nested_cpu_has_posted_intr(struct vmcs12 *vmcs12){	return vmcs12->pin_based_vm_exec_control & PIN_BASED_POSTED_INTR;},13348
654,2196,CVE-2015-5307,23,"static int ud_interception(struct vcpu_svm *svm){	int er;	er = emulate_instruction(&svm->vcpu, EMULTYPE_TRAP_UD);	if (er != EMULATE_DONE)		kvm_queue_exception(&svm->vcpu, UD_VECTOR); 	return 1; }",13318
283,693,CVE-2011-2918,23,"static int validate_group(struct perf_event *event){	struct perf_event *leader = event->group_leader;	struct cpu_hw_events *fake_cpuc;	int ret, n;	ret = -ENOMEM;	fake_cpuc = kmalloc(sizeof(*fake_cpuc), GFP_KERNEL | __GFP_ZERO);	if (!fake_cpuc)		goto out;	 	ret = -ENOSPC;	n = collect_events(fake_cpuc, leader, true);	if (n < 0)		goto out_free;	fake_cpuc->n_events = n;	n = collect_events(fake_cpuc, event, false);	if (n < 0)		goto out_free;	fake_cpuc->n_events = n;	ret = x86_pmu.schedule_events(fake_cpuc, n, NULL);out_free:	kfree(fake_cpuc);out:	return ret;}",6085
86,351,CVE-2012-1601,23,"static int retry_instruction(struct x86_emulate_ctxt *ctxt,			      unsigned long cr2,  int emulation_type){	struct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);	unsigned long last_retry_eip, last_retry_addr, gpa = cr2;	last_retry_eip = vcpu->arch.last_retry_eip;	last_retry_addr = vcpu->arch.last_retry_addr;	 	vcpu->arch.last_retry_eip = vcpu->arch.last_retry_addr = 0;	if (!(emulation_type & EMULTYPE_RETRY))		return false;	if (x86_page_table_writing_insn(ctxt))		return false;	if (ctxt->eip == last_retry_eip && last_retry_addr == cr2)		return false;	vcpu->arch.last_retry_eip = ctxt->eip;	vcpu->arch.last_retry_addr = cr2;	if (!vcpu->arch.mmu.direct_map)		gpa = kvm_mmu_gva_to_gpa_write(vcpu, cr2, NULL);	kvm_mmu_unprotect_page(vcpu->kvm, gpa >> PAGE_SHIFT);	return true;}",3829
219,1072,CVE-2013-5634,23,void kvm_arch_exit(void){	kvm_perf_teardown();},7476
505,324,CVE-2012-1601,23,static void kvm_unload_vcpu_mmu(struct kvm_vcpu *vcpu){	vcpu_load(vcpu);	kvm_mmu_unload(vcpu);	vcpu_put(vcpu);},3802
2,2528,CVE-2011-3897,23,  PrintWebViewHelperTestBase() {},29101
467,2237,CVE-2015-5307,23,"static int nested_vmx_exit_handled_cr(struct kvm_vcpu *vcpu,	struct vmcs12 *vmcs12){	unsigned long exit_qualification = vmcs_readl(EXIT_QUALIFICATION);	int cr = exit_qualification & 15;	int reg = (exit_qualification >> 8) & 15;	unsigned long val = kvm_register_readl(vcpu, reg);	switch ((exit_qualification >> 4) & 3) {	case 0:  		switch (cr) {		case 0:			if (vmcs12->cr0_guest_host_mask &			    (val ^ vmcs12->cr0_read_shadow))				return true;			break;		case 3:			if ((vmcs12->cr3_target_count >= 1 &&					vmcs12->cr3_target_value0 == val) ||				(vmcs12->cr3_target_count >= 2 &&					vmcs12->cr3_target_value1 == val) ||				(vmcs12->cr3_target_count >= 3 &&					vmcs12->cr3_target_value2 == val) ||				(vmcs12->cr3_target_count >= 4 &&					vmcs12->cr3_target_value3 == val))				return false;			if (nested_cpu_has(vmcs12, CPU_BASED_CR3_LOAD_EXITING))				return true;			break;		case 4:			if (vmcs12->cr4_guest_host_mask &			    (vmcs12->cr4_read_shadow ^ val))				return true;			break;		case 8:			if (nested_cpu_has(vmcs12, CPU_BASED_CR8_LOAD_EXITING))				return true;			break;		}		break;	case 2:  		if ((vmcs12->cr0_guest_host_mask & X86_CR0_TS) &&		    (vmcs12->cr0_read_shadow & X86_CR0_TS))			return true;		break;	case 1:  		switch (cr) {		case 3:			if (vmcs12->cpu_based_vm_exec_control &			    CPU_BASED_CR3_STORE_EXITING)				return true;			break;		case 8:			if (vmcs12->cpu_based_vm_exec_control &			    CPU_BASED_CR8_STORE_EXITING)				return true;			break;		}		break;	case 3:  		 		if (vmcs12->cr0_guest_host_mask & 0xe &		    (val ^ vmcs12->cr0_read_shadow))			return true;		if ((vmcs12->cr0_guest_host_mask & 0x1) &&		    !(vmcs12->cr0_read_shadow & 0x1) &&		    (val & 0x1))			return true;		break;	}	return false;}",13359
638,2012,CVE-2014-1444,23,"fst_intr_rx(struct fst_card_info *card, struct fst_port_info *port){	unsigned char dmabits;	int pi;	int rxp;	int rx_status;	unsigned short len;	struct sk_buff *skb;	struct net_device *dev = port_to_dev(port);	 	pi = port->index;	rxp = port->rxpos;	dmabits = FST_RDB(card, rxDescrRing[pi][rxp].bits);	if (dmabits & DMA_OWN) {		dbg(DBG_RX | DBG_INTR, ""intr_rx: No buffer port %d pos %d\n"",		    pi, rxp);		return;	}	if (card->dmarx_in_progress) {		return;	}	 	len = FST_RDW(card, rxDescrRing[pi][rxp].mcnt);	 	len -= 2;	if (len == 0) {		 		pr_err(""Frame received with 0 length. Card %d Port %d\n"",		       card->card_no, port->index);		 		FST_WRB(card, rxDescrRing[pi][rxp].bits, DMA_OWN);		rxp = (rxp+1) % NUM_RX_BUFFER;		port->rxpos = rxp;		return;	}	 	dbg(DBG_RX, ""intr_rx: %d,%d: flags %x len %d\n"", pi, rxp, dmabits, len);	if (dmabits != (RX_STP | RX_ENP) || len > LEN_RX_BUFFER - 2) {		fst_log_rx_error(card, port, dmabits, rxp, len);		fst_recover_rx_error(card, port, dmabits, rxp, len);		return;	}	 	if ((skb = dev_alloc_skb(len)) == NULL) {		dbg(DBG_RX, ""intr_rx: can't allocate buffer\n"");		dev->stats.rx_dropped++;		 		FST_WRB(card, rxDescrRing[pi][rxp].bits, DMA_OWN);		rxp = (rxp+1) % NUM_RX_BUFFER;		port->rxpos = rxp;		return;	}	 	if ((len < FST_MIN_DMA_LEN) || (card->family == FST_FAMILY_TXP)) {		memcpy_fromio(skb_put(skb, len),			      card->mem + BUF_OFFSET(rxBuffer[pi][rxp][0]),			      len);		 		FST_WRB(card, rxDescrRing[pi][rxp].bits, DMA_OWN);		 		dev->stats.rx_packets++;		dev->stats.rx_bytes += len;		 		dbg(DBG_RX, ""Pushing frame up the stack\n"");		if (port->mode == FST_RAW)			skb->protocol = farsync_type_trans(skb, dev);		else			skb->protocol = hdlc_type_trans(skb, dev);		rx_status = netif_rx(skb);		fst_process_rx_status(rx_status, port_to_dev(port)->name);		if (rx_status == NET_RX_DROP)			dev->stats.rx_dropped++;	} else {		card->dma_skb_rx = skb;		card->dma_port_rx = port;		card->dma_len_rx = len;		card->dma_rxpos = rxp;		fst_rx_dma(card, card->rx_dma_handle_card,			   BUF_OFFSET(rxBuffer[pi][rxp][0]), len);	}	if (rxp != port->rxpos) {		dbg(DBG_ASS, ""About to increment rxpos by more than 1\n"");		dbg(DBG_ASS, ""rxp = %d rxpos = %d\n"", rxp, port->rxpos);	}	rxp = (rxp+1) % NUM_RX_BUFFER;	port->rxpos = rxp;}",12050
614,789,CVE-2011-2918,23,"kmmio_fault(struct pt_regs *regs, unsigned long addr){	if (unlikely(is_kmmio_active()))		if (kmmio_handler(regs, addr) == 1)			return -1;	return 0;}",6181
142,487,CVE-2011-2918,23,"unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs, unsigned int n){	unsigned long *addr = (unsigned long *)kernel_stack_pointer(regs);	addr += n;	if (regs_within_kernel_stack(regs, (unsigned long)addr))		return *addr;	else		return 0;}",5879
301,1619,CVE-2011-2479,23,"static inline struct page *alloc_hugepage(int defrag){	return alloc_pages(alloc_hugepage_gfpmask(defrag, 0),			   HPAGE_PMD_ORDER);}",10257
615,2678,CVE-2011-2918,23,"static void perf_output_wakeup(struct perf_output_handle *handle) { 	atomic_set(&handle->rb->poll, POLL_IN); 	if (handle->nmi) {		handle->event->pending_wakeup = 1;		irq_work_queue(&handle->event->pending);	} else		perf_event_wakeup(handle->event); }",31021
554,2128,CVE-2015-8104,23,static int halt_interception(struct vcpu_svm *svm){	svm->next_rip = kvm_rip_read(&svm->vcpu) + 1;	return kvm_emulate_halt(&svm->vcpu);},13018
261,2306,CVE-2016-7166,23,__archive_read_close_filters(struct archive_read *a){	struct archive_read_filter *f = a->filter;	int r = ARCHIVE_OK;	 	while (f != NULL) {		struct archive_read_filter *t = f->upstream;		if (!f->closed && f->close != NULL) {			int r1 = (f->close)(f);			f->closed = 1;			if (r1 < r)				r = r1;		}		free(f->buffer);		f->buffer = NULL;		f = t;	}	return r;},15817
333,236,CVE-2012-1601,23,"static void emulator_get_idt(struct x86_emulate_ctxt *ctxt, struct desc_ptr *dt){	kvm_x86_ops->get_idt(emul_to_vcpu(ctxt), dt);}",3714
16,2049,CVE-2012-6638,23,"static void __tcp_ack_snd_check(struct sock *sk, int ofo_possible){	struct tcp_sock *tp = tcp_sk(sk);	     	if (((tp->rcv_nxt - tp->rcv_wup) > inet_csk(sk)->icsk_ack.rcv_mss &&	      	     __tcp_select_window(sk) >= tp->rcv_wnd) ||	     	    tcp_in_quickack_mode(sk) ||	     	    (ofo_possible && skb_peek(&tp->out_of_order_queue))) {		 		tcp_send_ack(sk);	} else {		 		tcp_send_delayed_ack(sk);	}}",12683
122,1209,CVE-2013-2141,23,SYSCALL_DEFINE0(pause){	while (!signal_pending(current)) {		current->state = TASK_INTERRUPTIBLE;		schedule();	}	return -ERESTARTNOHAND;},8815
174,956,CVE-2011-2918,23,"ring_buffer_init(struct ring_buffer *rb, long watermark, int flags){	long max_size = perf_data_size(rb);	if (watermark)		rb->watermark = min(max_size, watermark);	if (!rb->watermark)		rb->watermark = max_size / 2;	if (flags & RING_BUFFER_WRITABLE)		rb->writable = 1;	atomic_set(&rb->refcount, 1);}",6348
432,1038,CVE-2011-0716,23,"static void br_ip6_multicast_leave_group(struct net_bridge *br,					 struct net_bridge_port *port,					 const struct in6_addr *group){	struct br_ip br_group;	if (ipv6_is_local_multicast(group))		return;	ipv6_addr_copy(&br_group.u.ip6, group);	br_group.proto = htons(ETH_P_IPV6);	br_multicast_leave_group(br, port, &br_group);}",6976
624,1026,CVE-2011-2918,23,"static void watchdog_disable(int cpu){	struct task_struct *p = per_cpu(softlockup_watchdog, cpu);	struct hrtimer *hrtimer = &per_cpu(watchdog_hrtimer, cpu);	 	hrtimer_cancel(hrtimer);	 	watchdog_nmi_disable(cpu);	 	if (p) {		per_cpu(softlockup_watchdog, cpu) = NULL;		kthread_stop(p);	}}",6418
292,986,CVE-2011-2918,23,"static void irqtime_account_idle_ticks(int ticks){	int i;	struct rq *rq = this_rq();	for (i = 0; i < ticks; i++)		irqtime_account_process_tick(current, 0, rq);}",6378
148,56,CVE-2014-0221,23,"dtls1_get_message_header(unsigned char *data, struct hm_header_st *msg_hdr)	{	memset(msg_hdr, 0x00, sizeof(struct hm_header_st));	msg_hdr->type = *(data++);	n2l3(data, msg_hdr->msg_len);	n2s(data, msg_hdr->seq);	n2l3(data, msg_hdr->frag_off);	n2l3(data, msg_hdr->frag_len);	}",2250
24,2365,CVE-2016-3156,23,"static int ip_mc_config(struct sock *sk, int join, const struct in_ifaddr *ifa){	struct ip_mreqn mreq = {		.imr_multiaddr.s_addr = ifa->ifa_address,		.imr_ifindex = ifa->ifa_dev->dev->ifindex,	};	int ret;	ASSERT_RTNL();	lock_sock(sk);	if (join)		ret = ip_mc_join_group(sk, &mreq);	else		ret = ip_mc_leave_group(sk, &mreq);	release_sock(sk);	return ret;}",17334
139,1898,CVE-2014-3690,23,"static int pi_test_and_clear_on(struct pi_desc *pi_desc){	return test_and_clear_bit(POSTED_INTR_ON,			(unsigned long *)&pi_desc->control);}",11086
276,9,CVE-2015-7540,23,"int asn1_write_Integer(struct asn1_data *data, int i){	if (!asn1_push_tag(data, ASN1_INTEGER)) return false;	if (!asn1_write_implicit_Integer(data, i)) return false;	return asn1_pop_tag(data);}",209
141,2069,CVE-2012-6638,23,"static void tcp_cwnd_down(struct sock *sk, int flag){	struct tcp_sock *tp = tcp_sk(sk);	int decr = tp->snd_cwnd_cnt + 1;	if ((flag & (FLAG_ANY_PROGRESS | FLAG_DSACKING_ACK)) ||	    (tcp_is_reno(tp) && !(flag & FLAG_NOT_DUP))) {		tp->snd_cwnd_cnt = decr & 1;		decr >>= 1;		if (decr && tp->snd_cwnd > tcp_cwnd_min(sk))			tp->snd_cwnd -= decr;		tp->snd_cwnd = min(tp->snd_cwnd, tcp_packets_in_flight(tp) + 1);		tp->snd_cwnd_stamp = tcp_time_stamp;	}}",12703
204,852,CVE-2011-2918,23,"static void perf_event_context_sched_out(struct task_struct *task, int ctxn,					 struct task_struct *next){	struct perf_event_context *ctx = task->perf_event_ctxp[ctxn];	struct perf_event_context *next_ctx;	struct perf_event_context *parent;	struct perf_cpu_context *cpuctx;	int do_switch = 1;	if (likely(!ctx))		return;	cpuctx = __get_cpu_context(ctx);	if (!cpuctx->task_ctx)		return;	rcu_read_lock();	parent = rcu_dereference(ctx->parent_ctx);	next_ctx = next->perf_event_ctxp[ctxn];	if (parent && next_ctx &&	    rcu_dereference(next_ctx->parent_ctx) == parent) {		 		raw_spin_lock(&ctx->lock);		raw_spin_lock_nested(&next_ctx->lock, SINGLE_DEPTH_NESTING);		if (context_equiv(ctx, next_ctx)) {			 			task->perf_event_ctxp[ctxn] = next_ctx;			next->perf_event_ctxp[ctxn] = ctx;			ctx->task = next;			next_ctx->task = task;			do_switch = 0;			perf_event_sync_stat(ctx, next_ctx);		}		raw_spin_unlock(&next_ctx->lock);		raw_spin_unlock(&ctx->lock);	}	rcu_read_unlock();	if (do_switch) {		raw_spin_lock(&ctx->lock);		ctx_sched_out(ctx, cpuctx, EVENT_ALL);		cpuctx->task_ctx = NULL;		raw_spin_unlock(&ctx->lock);	}}",6244
69,1953,CVE-2014-3690,23,"static int vmx_set_tss_addr(struct kvm *kvm, unsigned int addr){	int ret;	struct kvm_userspace_memory_region tss_mem = {		.slot = TSS_PRIVATE_MEMSLOT,		.guest_phys_addr = addr,		.memory_size = PAGE_SIZE * 3,		.flags = 0,	};	ret = kvm_set_memory_region(kvm, &tss_mem);	if (ret)		return ret;	kvm->arch.tss_addr = addr;	return init_rmode_tss(kvm);}",11141
488,1987,CVE-2014-1446,23,"static inline void yam_rx_byte(struct net_device *dev, struct yam_port *yp, unsigned char rxb){	if (yp->rx_len < YAM_MAX_FRAME) {		unsigned char c = yp->rx_crcl;		yp->rx_crcl = (chktabl[c] ^ yp->rx_crch);		yp->rx_crch = (chktabh[c] ^ rxb);		yp->rx_buf[yp->rx_len++] = rxb;	}}",12025
46,246,CVE-2012-1601,23,"static void emulator_set_gdt(struct x86_emulate_ctxt *ctxt, struct desc_ptr *dt){	kvm_x86_ops->set_gdt(emul_to_vcpu(ctxt), dt);}",3724
400,1192,CVE-2013-2635,23,int rtnl_link_register(struct rtnl_link_ops *ops){	int err;	rtnl_lock();	err = __rtnl_link_register(ops);	rtnl_unlock();	return err;},8530
575,27,CVE-2016-6304,23,int tls1_ec_curve_id2nid(int curve_id){         if ((curve_id < 1) || ((unsigned int)curve_id >                           sizeof(nid_list) / sizeof(nid_list[0])))        return 0;    return nid_list[curve_id - 1];},1649
156,1495,CVE-2013-0217,23,void xen_netbk_deschedule_xenvif(struct xenvif *vif){	struct xen_netbk *netbk = vif->netbk;	spin_lock_irq(&netbk->net_schedule_list_lock);	remove_from_net_schedule_list(vif);	spin_unlock_irq(&netbk->net_schedule_list_lock);},9792
60,576,CVE-2011-2918,23,"static void do_unhandled_exception(int trapnr, int signr, char *str, char *fn_name,		unsigned long error_code, struct pt_regs *regs, struct task_struct *tsk){	show_excp_regs(fn_name, trapnr, signr, regs);	tsk->thread.error_code = error_code;	tsk->thread.trap_no = trapnr;	if (user_mode(regs))		force_sig(signr, tsk);	die_if_no_fixup(str, regs, error_code);}",5968
563,463,CVE-2011-2918,23,"static int armv7pmu_get_event_idx(struct cpu_hw_events *cpuc,				  struct hw_perf_event *event){	int idx;	 	if (event->config_base == ARMV7_PERFCTR_CPU_CYCLES) {		if (test_and_set_bit(ARMV7_CYCLE_COUNTER, cpuc->used_mask))			return -EAGAIN;		return ARMV7_CYCLE_COUNTER;	} else {		 		for (idx = ARMV7_COUNTER0; idx <= armpmu->num_events; ++idx) {			if (!test_and_set_bit(idx, cpuc->used_mask))				return idx;		}		 		return -EAGAIN;	}}",5855
222,2566,CVE-2011-3108,23,  RangeTransactionServer() {    not_modified_ = false;    modified_ = false;    bad_200_ = false;  },29318
91,1715,CVE-2014-7841,23,"static int sctp_process_inv_paramlength(const struct sctp_association *asoc,					struct sctp_paramhdr *param,					const struct sctp_chunk *chunk,					struct sctp_chunk **errp){	 	if (*errp)		sctp_chunk_free(*errp);	 	*errp = sctp_make_violation_paramlen(asoc, chunk, param);	return 0;}",10523
445,1605,CVE-2011-2491,23,"static void rpc_set_active(struct rpc_task *task){	rpc_task_set_debuginfo(task);	set_bit(RPC_TASK_ACTIVE, &task->tk_runstate);}",10224
414,907,CVE-2011-2918,23,"static int perf_tp_event_match(struct perf_event *event,				struct perf_sample_data *data,				struct pt_regs *regs){	if (event->hw.state & PERF_HES_STOPPED)		return 0;	 	if (event->attr.exclude_kernel)		return 0;	if (!perf_tp_filter_match(event, data))		return 0;	return 1;}",6299
70,538,CVE-2011-2918,23,"static int evr_active(struct task_struct *target,		      const struct user_regset *regset){	flush_spe_to_thread(target);	return target->thread.used_spe ? regset->n : 0;}",5930
429,2150,CVE-2015-6526,23,"static inline void perf_callchain_user_64(struct perf_callchain_entry *entry,					  struct pt_regs *regs){}",13122
236,2264,CVE-2015-5307,23,"static void vmx_post_block(struct kvm_vcpu *vcpu){	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);	struct pi_desc old, new;	unsigned int dest;	unsigned long flags;	if (!kvm_arch_has_assigned_device(vcpu->kvm) ||		!irq_remapping_cap(IRQ_POSTING_CAP))		return;	do {		old.control = new.control = pi_desc->control;		dest = cpu_physical_id(vcpu->cpu);		if (x2apic_enabled())			new.ndst = dest;		else			new.ndst = (dest << 8) & 0xFF00;		 		new.sn = 0;		 		new.nv = POSTED_INTR_VECTOR;	} while (cmpxchg(&pi_desc->control, old.control,			new.control) != old.control);	if(vcpu->pre_pcpu != -1) {		spin_lock_irqsave(			&per_cpu(blocked_vcpu_on_cpu_lock,			vcpu->pre_pcpu), flags);		list_del(&vcpu->blocked_vcpu_list);		spin_unlock_irqrestore(			&per_cpu(blocked_vcpu_on_cpu_lock,			vcpu->pre_pcpu), flags);		vcpu->pre_pcpu = -1;	}}",13386
498,570,CVE-2011-3637,24,"static int numa_maps_open(struct inode *inode, struct file *file){	return do_maps_open(inode, file, &proc_pid_numa_maps_op);}",5517
632,2751,CVE-2011-2724,24," static int check_mtab(const char *progname, const char *devname,                      const char *dir) {       if (check_newline(progname, devname) == -1 ||           check_newline(progname, dir) == -1)                return EX_USAGE;        return 0; }",30886
50,1475,CVE-2013-7271,24,"base_sock_create(struct net *net, struct socket *sock, int protocol){	struct sock *sk;	if (sock->type != SOCK_RAW)		return -ESOCKTNOSUPPORT;	sk = sk_alloc(net, PF_ISDN, GFP_KERNEL, &mISDN_proto);	if (!sk)		return -ENOMEM;	sock_init_data(sock, sk);	sock->ops = &base_sock_ops;	sock->state = SS_UNCONNECTED;	sock_reset_flag(sk, SOCK_ZAPPED);	sk->sk_protocol = protocol;	sk->sk_state    = MISDN_OPEN;	mISDN_sock_link(&base_sockets, sk);	return 0;}",12363
659,1819,CVE-2015-7509,24,"static void ext4_update_dx_flag(struct inode *inode){	if (!EXT4_HAS_COMPAT_FEATURE(inode->i_sb,				     EXT4_FEATURE_COMPAT_DIR_INDEX))		ext4_clear_inode_flag(inode, EXT4_INODE_INDEX);}",13100
282,1067,CVE-2014-3645,24,"static int kvm_sync_page(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,			 struct list_head *invalid_list){	return __kvm_sync_page(vcpu, sp, invalid_list, true);}",11201
11,1599,CVE-2013-7271,24,static void netlink_deliver_tap(struct sk_buff *skb){	rcu_read_lock();	if (unlikely(!list_empty(&netlink_tap_all)))		__netlink_deliver_tap(skb);	rcu_read_unlock();},12487
310,1619,CVE-2013-7271,24,"static void netlink_ring_setup_skb(struct sk_buff *skb, struct sock *sk,				   struct netlink_ring *ring,				   struct nl_mmap_hdr *hdr){	unsigned int size;	void *data;	size = ring->frame_size - NL_MMAP_HDRLEN;	data = (void *)hdr + NL_MMAP_HDRLEN;	skb->head	= data;	skb->data	= data;	skb_reset_tail_pointer(skb);	skb->end	= skb->tail + size;	skb->len	= 0;	skb->destructor	= netlink_skb_destructor;	NETLINK_CB(skb).flags |= NETLINK_SKB_MMAPED;	NETLINK_CB(skb).sk = sk;}",12507
159,245,CVE-2012-6085,24,import_release_stats_handle (void *p){    xfree (p);},1018
623,2293,CVE-2018-18955,24,static void userns_put(struct ns_common *ns){	put_user_ns(to_user_ns(ns));},23422
485,1845,CVE-2016-9191,24,"static struct ctl_table *lookup_entry(struct ctl_table_header **phead,				      struct ctl_dir *dir,				      const char *name, int namelen){	struct ctl_table_header *head;	struct ctl_table *entry;	spin_lock(&sysctl_lock);	entry = find_entry(&head, dir, name, namelen);	if (entry && use_table(head))		*phead = head;	else		entry = NULL;	spin_unlock(&sysctl_lock);	return entry;}",15206
346,366,CVE-2016-4072,24,"PHP_METHOD(PharFileInfo, hasMetadata){	PHAR_ENTRY_OBJECT();	if (zend_parse_parameters_none() == FAILURE) {		return;	}	RETURN_BOOL(Z_TYPE(entry_obj->entry->metadata) != IS_UNDEF);}",1936
530,985,CVE-2014-5336,24,"*mk_vhost_fdt_chain_lookup(unsigned int hash, struct vhost_fdt_hash_table *ht){    int i;    struct vhost_fdt_hash_chain *hc = NULL;    for (i = 0; i < VHOST_FDT_HASHTABLE_CHAINS; i++) {        hc = &ht->chain[i];        if (hc->hash == hash) {            return hc;        }    }    return NULL;}",10642
490,2765,CVE-2013-6368,24,"static void vapic_exit(struct kvm_vcpu *vcpu){	struct kvm_lapic *apic = vcpu->arch.apic;	int idx;	if (!apic || !apic->vapic_addr)		return;	idx = srcu_read_lock(&vcpu->kvm->srcu);	kvm_release_page_dirty(apic->vapic_page);	mark_page_dirty(vcpu->kvm, apic->vapic_addr >> PAGE_SHIFT);	srcu_read_unlock(&vcpu->kvm->srcu, idx);}",31043
213,1309,CVE-2014-2038,24,"int nfs_flush_incompatible(struct file *file, struct page *page){	struct nfs_open_context *ctx = nfs_file_open_context(file);	struct nfs_lock_context *l_ctx;	struct nfs_page	*req;	int do_flush, status;	 	do {		req = nfs_page_find_request(page);		if (req == NULL)			return 0;		l_ctx = req->wb_lock_context;		do_flush = req->wb_page != page || req->wb_context != ctx;		if (l_ctx && ctx->dentry->d_inode->i_flock != NULL) {			do_flush |= l_ctx->lockowner.l_owner != current->files				|| l_ctx->lockowner.l_pid != current->tgid;		}		nfs_release_request(req);		if (!do_flush)			return 0;		status = nfs_wb_page(page_file_mapping(page)->host, page);	} while (status == 0);	return status;}",11856
251,2100,CVE-2017-15951,24,"static int request_key_auth_instantiate(struct key *key,					struct key_preparsed_payload *prep){	key->payload.data[0] = (struct request_key_auth *)prep->data;	return 0;}",19923
23,2430,CVE-2017-18509,24,"static struct mfc6_cache *ip6mr_cache_alloc_unres(void){	struct mfc6_cache *c = kmem_cache_zalloc(mrt_cachep, GFP_ATOMIC);	if (!c)		return NULL;	skb_queue_head_init(&c->mfc_un.unres.unresolved);	c->mfc_un.unres.expires = jiffies + 10 * HZ;	return c;}",28044
468,612,CVE-2011-1080,24,"static int compat_calc_match(struct ebt_entry_match *m, int *off){	*off += ebt_compat_match_offset(m->u.match, m->match_size);	*off += ebt_compat_entry_padsize();	return 0;}",6915
609,1428,CVE-2014-0203,24,"static int check_mem_permission(struct task_struct *task){	 	if (task == current)		return 0;	 	if (task_is_stopped_or_traced(task)) {		int match;		rcu_read_lock();		match = (tracehook_tracer_task(task) == current);		rcu_read_unlock();		if (match && ptrace_may_access(task, PTRACE_MODE_ATTACH))			return 0;	}	 	return -EPERM;}",12138
420,1442,CVE-2014-0203,24,"static int proc_cwd_link(struct inode *inode, struct path *path){	struct task_struct *task = get_proc_task(inode);	int result = -ENOENT;	if (task) {		result = get_fs_path(task, path, 0);		put_task_struct(task);	}	return result;}",12152
223,1246,CVE-2014-2739,24,"static void cma_translate_ib(struct sockaddr_ib *sib, struct rdma_dev_addr *dev_addr){	dev_addr->dev_type = ARPHRD_INFINIBAND;	rdma_addr_set_sgid(dev_addr, (union ib_gid *) &sib->sib_addr);	ib_addr_set_pkey(dev_addr, ntohs(sib->sib_pkey));}",11721
501,643,CVE-2013-6368,24,"static void init_decode_cache(struct x86_emulate_ctxt *ctxt){	memset(&ctxt->opcode_len, 0,	       (void *)&ctxt->_regs - (void *)&ctxt->opcode_len);	ctxt->fetch.start = 0;	ctxt->fetch.end = 0;	ctxt->io_read.pos = 0;	ctxt->io_read.end = 0;	ctxt->mem_read.pos = 0;	ctxt->mem_read.end = 0;}",7410
354,2079,CVE-2017-15951,24,"static void keyring_destroy(struct key *keyring){	if (keyring->description) {		write_lock(&keyring_name_lock);		if (keyring->name_link.next != NULL &&		    !list_empty(&keyring->name_link))			list_del(&keyring->name_link);		write_unlock(&keyring_name_lock);	}	if (keyring->restrict_link) {		struct key_restriction *keyres = keyring->restrict_link;		key_put(keyres->key);		kfree(keyres);	}	assoc_array_destroy(&keyring->keys, &keyring_assoc_array_ops);}",19902
101,2755,CVE-2015-5589,24," PHP_METHOD(Phar, count) {        PHAR_ARCHIVE_OBJECT();        if (zend_parse_parameters_none() == FAILURE) {                return;        }	RETURN_LONG(zend_hash_num_elements(&phar_obj->arc.archive->manifest));}",30915
611,1908,CVE-2016-5358,24,ampdu_reassemble_cleanup(void){    reassembly_table_destroy(&ampdu_reassembly_table);},16473
537,996,CVE-2014-4503,24,"void dev_error(struct cgpu_info *dev, enum dev_reason reason){	dev->device_last_not_well = time(NULL);	dev->device_not_well_reason = reason;	switch (reason) {		case REASON_THREAD_FAIL_INIT:			dev->thread_fail_init_count++;			break;		case REASON_THREAD_ZERO_HASH:			dev->thread_zero_hash_count++;			break;		case REASON_THREAD_FAIL_QUEUE:			dev->thread_fail_queue_count++;			break;		case REASON_DEV_SICK_IDLE_60:			dev->dev_sick_idle_60_count++;			break;		case REASON_DEV_DEAD_IDLE_600:			dev->dev_dead_idle_600_count++;			break;		case REASON_DEV_NOSTART:			dev->dev_nostart_count++;			break;		case REASON_DEV_OVER_HEAT:			dev->dev_over_heat_count++;			break;		case REASON_DEV_THERMAL_CUTOFF:			dev->dev_thermal_cutoff_count++;			break;		case REASON_DEV_COMMS_ERROR:			dev->dev_comms_error_count++;			break;		case REASON_DEV_THROTTLE:			dev->dev_throttle_count++;			break;	}}",10864
494,732,CVE-2013-4254,24,"__hw_perf_event_init(struct perf_event *event){	struct arm_pmu *armpmu = to_arm_pmu(event->pmu);	struct hw_perf_event *hwc = &event->hw;	int mapping;	mapping = armpmu->map_event(event);	if (mapping < 0) {		pr_debug(""event %x:%llx not supported\n"", event->attr.type,			 event->attr.config);		return mapping;	}	 	hwc->idx		= -1;	hwc->config_base	= 0;	hwc->config		= 0;	hwc->event_base		= 0;	 	if ((!armpmu->set_event_filter ||	     armpmu->set_event_filter(hwc, &event->attr)) &&	     event_requires_mode_exclusion(&event->attr)) {		pr_debug(""ARM performance counters do not support ""			 ""mode exclusion\n"");		return -EOPNOTSUPP;	}	 	hwc->config_base	    |= (unsigned long)mapping;	if (!hwc->sample_period) {		 		hwc->sample_period  = armpmu->max_period >> 1;		hwc->last_period    = hwc->sample_period;		local64_set(&hwc->period_left, hwc->sample_period);	}	if (event->group_leader != event) {		if (validate_group(event) != 0)			return -EINVAL;	}	return 0;}",7883
526,296,CVE-2014-7840,24,int ram_bytes_remaining(void){    return ram_save_remaining() * TARGET_PAGE_SIZE;},1296
613,2476,CVE-2010-1152,24,"static enum test_return test_binary_replace(void) {    return test_binary_replace_impl(""test_binary_replace"",                                    PROTOCOL_BINARY_CMD_REPLACE);}",28233
572,381,CVE-2016-4071,24,"PHP_MINFO_FUNCTION(snmp){	php_info_print_table_start();	php_info_print_table_row(2, ""NET-SNMP Support"", ""enabled"");	php_info_print_table_row(2, ""NET-SNMP Version"", netsnmp_get_version());	php_info_print_table_row(2, ""PHP SNMP Version"", PHP_SNMP_VERSION);	php_info_print_table_end();}",1951
92,1715,CVE-2013-7271,24,static void vsock_init_tables(void){	int i;	for (i = 0; i < ARRAY_SIZE(vsock_bind_table); i++)		INIT_LIST_HEAD(&vsock_bind_table[i]);	for (i = 0; i < ARRAY_SIZE(vsock_connected_table); i++)		INIT_LIST_HEAD(&vsock_connected_table[i]);},12603
499,2111,CVE-2017-15868,24,"static void __bnep_copy_ci(struct bnep_conninfo *ci, struct bnep_session *s){	memset(ci, 0, sizeof(*ci));	memcpy(ci->dst, s->eh.h_source, ETH_ALEN);	strcpy(ci->device, s->dev->name);	ci->flags = s->flags;	ci->state = s->state;	ci->role  = s->role;}",19955
61,841,CVE-2013-1828,24,static void sctp_enter_memory_pressure(struct sock *sk){	sctp_memory_pressure = 1;},9397
284,9,CVE-2018-1000037,24,	fz_catch(ctx)	{		fz_rethrow(ctx);	},206
612,1498,CVE-2013-7271,24,"static int pppoe_seq_show(struct seq_file *seq, void *v){	struct pppox_sock *po;	char *dev_name;	if (v == SEQ_START_TOKEN) {		seq_puts(seq, ""Id       Address              Device\n"");		goto out;	}	po = v;	dev_name = po->pppoe_pa.dev;	seq_printf(seq, ""%08X %pM %8s\n"",		po->pppoe_pa.sid, po->pppoe_pa.remote, dev_name);out:	return 0;}",12386
96,2310,CVE-2018-17456,24,"static int fsck_commit_buffer(struct commit *commit, const char *buffer,	unsigned long size, struct fsck_options *options){	unsigned char tree_sha1[20], sha1[20];	struct commit_graft *graft;	unsigned parent_count, parent_line_count = 0, author_count;	int err;	const char *buffer_begin = buffer;	if (verify_headers(buffer, size, &commit->object, options))		return -1;	if (!skip_prefix(buffer, ""tree "", &buffer))		return report(options, &commit->object, FSCK_MSG_MISSING_TREE, ""invalid format - expected 'tree' line"");	if (get_sha1_hex(buffer, tree_sha1) || buffer[40] != '\n') {		err = report(options, &commit->object, FSCK_MSG_BAD_TREE_SHA1, ""invalid 'tree' line format - bad sha1"");		if (err)			return err;	}	buffer += 41;	while (skip_prefix(buffer, ""parent "", &buffer)) {		if (get_sha1_hex(buffer, sha1) || buffer[40] != '\n') {			err = report(options, &commit->object, FSCK_MSG_BAD_PARENT_SHA1, ""invalid 'parent' line format - bad sha1"");			if (err)				return err;		}		buffer += 41;		parent_line_count++;	}	graft = lookup_commit_graft(&commit->object.oid);	parent_count = commit_list_count(commit->parents);	if (graft) {		if (graft->nr_parent == -1 && !parent_count)			;  		else if (graft->nr_parent != parent_count) {			err = report(options, &commit->object, FSCK_MSG_MISSING_GRAFT, ""graft objects missing"");			if (err)				return err;		}	} else {		if (parent_count != parent_line_count) {			err = report(options, &commit->object, FSCK_MSG_MISSING_PARENT, ""parent objects missing"");			if (err)				return err;		}	}	author_count = 0;	while (skip_prefix(buffer, ""author "", &buffer)) {		author_count++;		err = fsck_ident(&buffer, &commit->object, options);		if (err)			return err;	}	if (author_count < 1)		err = report(options, &commit->object, FSCK_MSG_MISSING_AUTHOR, ""invalid format - expected 'author' line"");	else if (author_count > 1)		err = report(options, &commit->object, FSCK_MSG_MULTIPLE_AUTHORS, ""invalid format - multiple 'author' lines"");	if (err)		return err;	if (!skip_prefix(buffer, ""committer "", &buffer))		return report(options, &commit->object, FSCK_MSG_MISSING_COMMITTER, ""invalid format - expected 'committer' line"");	err = fsck_ident(&buffer, &commit->object, options);	if (err)		return err;	if (!commit->tree) {		err = report(options, &commit->object, FSCK_MSG_BAD_TREE, ""could not load commit's tree %s"", sha1_to_hex(tree_sha1));		if (err)			return err;	}	if (memchr(buffer_begin, '\0', size)) {		err = report(options, &commit->object, FSCK_MSG_NUL_IN_COMMIT,			     ""NUL byte in the commit object body"");		if (err)			return err;	}	return 0;}",23602
85,2338,CVE-2018-14361,24,"static int fetch_description(char *line, void *data){  struct NntpServer *nserv = data;  struct NntpData *nntp_data = NULL;  char *desc = NULL;  if (!line)    return 0;  desc = strpbrk(line, "" \t"");  if (desc)  {    *desc++ = '\0';    desc += strspn(desc, "" \t"");  }  else    desc = strchr(line, '\0');  nntp_data = mutt_hash_find(nserv->groups_hash, line);  if (nntp_data && (mutt_str_strcmp(desc, nntp_data->desc) != 0))  {    mutt_str_replace(&nntp_data->desc, desc);    mutt_debug(2, ""group: %s, desc: %s\n"", line, desc);  }  return 0;}",24483
126,1795,CVE-2015-8215,24,"static void inet6_prefix_notify(int event, struct inet6_dev *idev,			 struct prefix_info *pinfo){	struct sk_buff *skb;	struct net *net = dev_net(idev->dev);	int err = -ENOBUFS;	skb = nlmsg_new(inet6_prefix_nlmsg_size(), GFP_ATOMIC);	if (skb == NULL)		goto errout;	err = inet6_fill_prefix(skb, idev, pinfo, 0, 0, event, 0);	if (err < 0) {		 		WARN_ON(err == -EMSGSIZE);		kfree_skb(skb);		goto errout;	}	rtnl_notify(skb, net, 0, RTNLGRP_IPV6_PREFIX, NULL, GFP_ATOMIC);	return;errout:	if (err < 0)		rtnl_set_sk_err(net, RTNLGRP_IPV6_PREFIX, err);}",13005
230,2777,CVE-2014-0203,24,"static void *proc_pid_follow_link(struct dentry *dentry, struct nameidata *nd){	struct inode *inode = dentry->d_inode;	int error = -EACCES;	 	path_put(&nd->path);	 	if (!proc_fd_access_allowed(inode)) 		goto out;  	error = PROC_I(inode)->op.proc_get_link(inode, &nd->path);	nd->last_type = LAST_BIND; out: 	return ERR_PTR(error); }",31170
330,2215,CVE-2017-5669,24,static int shm_fault(struct vm_fault *vmf){	struct file *file = vmf->vma->vm_file;	struct shm_file_data *sfd = shm_file_data(file);	return sfd->vm_ops->fault(vmf);},21977
517,2706,CVE-2016-3760,24, static int get_adapter_properties(void) {       if (interface_ready() == FALSE) return BT_STATUS_NOT_READY; return btif_get_adapter_properties();},30517
394,32,CVE-2017-16227,24,"aspath_merge (struct aspath *as1, struct aspath *as2){  struct assegment *last, *new;  if (! as1 || ! as2)    return NULL;  last = new = assegment_dup_all (as1->segments);       while (last && last->next)    last = last->next;    last->next = as2->segments;  as2->segments = new;  aspath_str_update (as2);  return as2;}",354
522,1668,CVE-2013-7271,24,"static void *prb_dispatch_next_block(struct tpacket_kbdq_core *pkc,		struct packet_sock *po){	struct tpacket_block_desc *pbd;	smp_rmb();	 	pbd = GET_CURR_PBLOCK_DESC_FROM_CORE(pkc);	 	if (TP_STATUS_USER & BLOCK_STATUS(pbd)) {		prb_freeze_queue(pkc, po);		return NULL;	}	 	prb_open_block(pkc, pbd);	return (void *)pkc->nxt_offset;}",12556
313,1693,CVE-2013-7271,24,"static unsigned int rcvbuf_limit(struct sock *sk, struct sk_buff *buf){	struct tipc_msg *msg = buf_msg(buf);	unsigned int limit;	if (msg_connected(msg))		limit = sysctl_tipc_rmem[2];	else		limit = sk->sk_rcvbuf >> TIPC_CRITICAL_IMPORTANCE <<			msg_importance(msg);	return limit;}",12581
119,1903,CVE-2016-6197,24,"static struct dentry *ovl_whiteout(struct dentry *workdir,				   struct dentry *dentry){	int err;	struct dentry *whiteout;	struct inode *wdir = workdir->d_inode;	whiteout = ovl_lookup_temp(workdir, dentry);	if (IS_ERR(whiteout))		return whiteout;	err = ovl_do_whiteout(wdir, whiteout);	if (err) {		dput(whiteout);		whiteout = ERR_PTR(err);	}	return whiteout;}",16258
113,1666,CVE-2013-7271,24,"static int prb_curr_blk_in_use(struct tpacket_kbdq_core *pkc,				      struct tpacket_block_desc *pbd){	return TP_STATUS_USER & BLOCK_STATUS(pbd);}",12554
567,1674,CVE-2013-7271,24,"static void *prb_lookup_block(struct packet_sock *po,				     struct packet_ring_buffer *rb,				     unsigned int idx,				     int status){	struct tpacket_kbdq_core *pkc  = GET_PBDQC_FROM_RB(rb);	struct tpacket_block_desc *pbd = GET_PBLOCK_DESC(pkc, idx);	if (status != BLOCK_STATUS(pbd))		return NULL;	return pbd;}",12562
471,637,CVE-2013-6368,24,"static inline int complete_emulated_io(struct kvm_vcpu *vcpu){	int r;	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);	r = emulate_instruction(vcpu, EMULTYPE_NO_DECODE);	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);	if (r != EMULATE_DONE)		return 0;	return 1;}",7404
391,275,CVE-2012-5534,24,"string_strcasestr (const char *string, const char *search){    int length_search;    length_search = utf8_strlen (search);    if (!string || !search || (length_search == 0))        return NULL;    while (string[0])    {        if (string_strncasecmp (string, search, length_search) == 0)            return (char *)string;        string = utf8_next_char (string);    }    return NULL;}",1206
606,1990,CVE-2017-1000252,24,ioeventfd_destructor(struct kvm_io_device *this){	struct _ioeventfd *p = to_ioeventfd(this);	ioeventfd_release(p);},19451
242,1542,CVE-2013-7271,24,"static void __sco_sock_close(struct sock *sk){	BT_DBG(""sk %p state %d socket %p"", sk, sk->sk_state, sk->sk_socket);	switch (sk->sk_state) {	case BT_LISTEN:		sco_sock_cleanup_listen(sk);		break;	case BT_CONNECTED:	case BT_CONFIG:		if (sco_pi(sk)->conn->hcon) {			sk->sk_state = BT_DISCONN;			sco_sock_set_timer(sk, SCO_DISCONN_TIMEOUT);			hci_conn_drop(sco_pi(sk)->conn->hcon);			sco_pi(sk)->conn->hcon = NULL;		} else			sco_chan_del(sk, ECONNRESET);		break;	case BT_CONNECT2:	case BT_CONNECT:	case BT_DISCONN:		sco_chan_del(sk, ECONNRESET);		break;	default:		sock_set_flag(sk, SOCK_ZAPPED);		break;	}}",12430
422,915,CVE-2013-0216,24,static struct net_device_stats *xenvif_get_stats(struct net_device *dev){	struct xenvif *vif = netdev_priv(dev);	return &vif->dev->stats;},9806
89,1241,CVE-2014-2739,24,"static void cma_set_loopback(struct sockaddr *addr){	switch (addr->sa_family) {	case AF_INET:		((struct sockaddr_in *) addr)->sin_addr.s_addr = htonl(INADDR_LOOPBACK);		break;	case AF_INET6:		ipv6_addr_set(&((struct sockaddr_in6 *) addr)->sin6_addr,			      0, 0, 0, htonl(1));		break;	default:		ib_addr_set(&((struct sockaddr_ib *) addr)->sib_addr,			    0, 0, 0, htonl(1));		break;	}}",11716
496,2738,CVE-2016-3760,24,"void setup_test_env(void){ int i = 0; while (console_cmd_list[i].name != NULL) {        console_cmd_maxlen = MAX(console_cmd_maxlen, (int)strlen(console_cmd_list[i].name));        i++; }}",30549
668,2222,CVE-2017-5226,24,"get_newroot_path (const char *path){  while (*path == '/')    path++;  return strconcat (""/newroot/"", path);}",22137
327,663,CVE-2013-6368,24,"int kvm_arch_vcpu_ioctl_set_guest_debug(struct kvm_vcpu *vcpu,					struct kvm_guest_debug *dbg){	unsigned long rflags;	int i, r;	if (dbg->control & (KVM_GUESTDBG_INJECT_DB | KVM_GUESTDBG_INJECT_BP)) {		r = -EBUSY;		if (vcpu->arch.exception.pending)			goto out;		if (dbg->control & KVM_GUESTDBG_INJECT_DB)			kvm_queue_exception(vcpu, DB_VECTOR);		else			kvm_queue_exception(vcpu, BP_VECTOR);	}	 	rflags = kvm_get_rflags(vcpu);	vcpu->guest_debug = dbg->control;	if (!(vcpu->guest_debug & KVM_GUESTDBG_ENABLE))		vcpu->guest_debug = 0;	if (vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP) {		for (i = 0; i < KVM_NR_DB_REGS; ++i)			vcpu->arch.eff_db[i] = dbg->arch.debugreg[i];		vcpu->arch.guest_debug_dr7 = dbg->arch.debugreg[7];	} else {		for (i = 0; i < KVM_NR_DB_REGS; i++)			vcpu->arch.eff_db[i] = vcpu->arch.db[i];	}	kvm_update_dr7(vcpu);	if (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)		vcpu->arch.singlestep_rip = kvm_rip_read(vcpu) +			get_segment_base(vcpu, VCPU_SREG_CS);	 	kvm_set_rflags(vcpu, rflags);	kvm_x86_ops->update_db_bp_intercept(vcpu);	r = 0;out:	return r;}",7430
480,2125,CVE-2017-14604,24,nautilus_mime_actions_get_required_file_attributes (void){    return NAUTILUS_FILE_ATTRIBUTE_INFO |           NAUTILUS_FILE_ATTRIBUTE_LINK_INFO;},20142
447,2648,CVE-2018-17476,24,  BrowserTestWithExtensionsDisabled() {},30063
665,2064,CVE-2017-17862,24,"static int states_equal(struct bpf_verifier_env *env,			 struct bpf_verifier_state *old,			 struct bpf_verifier_state *cur){	struct idpair *idmap;	int ret = false;	int i;	idmap = kcalloc(ID_MAP_SIZE, sizeof(struct idpair), GFP_KERNEL);	 	if (!idmap)		return false;	for (i = 0; i < MAX_BPF_REG; i++) {		if (!regsafe(&old->regs[i], &cur->regs[i], idmap))			goto out_free;	}	if (!stacksafe(old, cur, idmap))		goto out_free;	ret = true;out_free:	kfree(idmap);	return ret;}",19562
620,191,CVE-2011-1428,24,"irc_server_msgq_flush (){    struct t_irc_message *next;    char *ptr_data, *new_msg, *ptr_msg, *pos;    char *nick, *host, *command, *channel, *arguments;    char *msg_decoded, *msg_decoded_without_color;    char str_modifier[64], modifier_data[256];        while (irc_recv_msgq)    {        if (irc_recv_msgq->data)        {            ptr_data = irc_recv_msgq->data;            while (ptr_data[0] == ' ')            {                ptr_data++;            }                        if (ptr_data[0])            {                irc_raw_print (irc_recv_msgq->server, IRC_RAW_FLAG_RECV,                               ptr_data);                                irc_message_parse (ptr_data, NULL, NULL, &command, NULL, NULL);                snprintf (str_modifier, sizeof (str_modifier),                          ""irc_in_%s"",                          (command) ? command : ""unknown"");                new_msg = weechat_hook_modifier_exec (str_modifier,                                                      irc_recv_msgq->server->name,                                                      ptr_data);                if (command)                    free (command);                                                 if (new_msg && (strcmp (ptr_data, new_msg) == 0))                {                    free (new_msg);                    new_msg = NULL;                }                                                 if (!new_msg || new_msg[0])                {                                         ptr_msg = (new_msg) ? new_msg : ptr_data;                                        while (ptr_msg && ptr_msg[0])                    {                        pos = strchr (ptr_msg, '\n');                        if (pos)                            pos[0] = '\0';                                                if (new_msg)                        {                            irc_raw_print (irc_recv_msgq->server,                                           IRC_RAW_FLAG_RECV | IRC_RAW_FLAG_MODIFIED,                                           ptr_msg);                        }                                                irc_message_parse (ptr_msg, &nick, &host, &command,                                           &channel, &arguments);                                                                         if (channel && irc_channel_is_channel (channel))                        {                            snprintf (modifier_data, sizeof (modifier_data),                                      ""%s.%s.%s"",                                      weechat_plugin->name,                                      irc_recv_msgq->server->name,                                      channel);                        }                        else                        {                            if (nick && (!host || (strcmp (nick, host) != 0)))                            {                                snprintf (modifier_data, sizeof (modifier_data),                                          ""%s.%s.%s"",                                          weechat_plugin->name,                                          irc_recv_msgq->server->name,                                          nick);                            }                            else                            {                                snprintf (modifier_data, sizeof (modifier_data),                                          ""%s.%s"",                                          weechat_plugin->name,                                          irc_recv_msgq->server->name);                            }                        }                        msg_decoded = weechat_hook_modifier_exec (""charset_decode"",                                                                  modifier_data,                                                                  ptr_msg);                                                                         msg_decoded_without_color =                            weechat_string_remove_color ((msg_decoded) ? msg_decoded : ptr_msg,                                                         ""?"");                                                                         if (irc_redirect_message (irc_recv_msgq->server,                                                  (msg_decoded_without_color) ?                                                  msg_decoded_without_color : ((msg_decoded) ? msg_decoded : ptr_msg),                                                  command, arguments))                        {                                                     }                        else                        {                                                         irc_protocol_recv_command (irc_recv_msgq->server,                                                       (msg_decoded_without_color) ?                                                       msg_decoded_without_color : ((msg_decoded) ? msg_decoded : ptr_msg),                                                       command,                                                       channel);                        }                                                if (nick)                            free (nick);                        if (host)                            free (host);                        if (command)                            free (command);                        if (channel)                            free (channel);                        if (arguments)                            free (arguments);                        if (msg_decoded)                            free (msg_decoded);                        if (msg_decoded_without_color)                            free (msg_decoded_without_color);                                                if (pos)                        {                            pos[0] = '\n';                            ptr_msg = pos + 1;                        }                        else                            ptr_msg = NULL;                    }                }                else                {                    irc_raw_print (irc_recv_msgq->server,                                   IRC_RAW_FLAG_RECV | IRC_RAW_FLAG_MODIFIED,                                   _(""(message dropped)""));                }                if (new_msg)                    free (new_msg);            }            free (irc_recv_msgq->data);        }                next = irc_recv_msgq->next_message;        free (irc_recv_msgq);        irc_recv_msgq = next;        if (!irc_recv_msgq)            irc_msgq_last_msg = NULL;    }}",685
531,1168,CVE-2014-2739,24,"static int cm_init_qp_rtr_attr(struct cm_id_private *cm_id_priv,			       struct ib_qp_attr *qp_attr,			       int *qp_attr_mask){	unsigned long flags;	int ret;	spin_lock_irqsave(&cm_id_priv->lock, flags);	switch (cm_id_priv->id.state) {	case IB_CM_REQ_RCVD:	case IB_CM_MRA_REQ_SENT:	case IB_CM_REP_RCVD:	case IB_CM_MRA_REP_SENT:	case IB_CM_REP_SENT:	case IB_CM_MRA_REP_RCVD:	case IB_CM_ESTABLISHED:		*qp_attr_mask = IB_QP_STATE | IB_QP_AV | IB_QP_PATH_MTU |				IB_QP_DEST_QPN | IB_QP_RQ_PSN;		qp_attr->ah_attr = cm_id_priv->av.ah_attr;		if (!cm_id_priv->av.valid) {			spin_unlock_irqrestore(&cm_id_priv->lock, flags);			return -EINVAL;		}		if (cm_id_priv->av.ah_attr.vlan_id != 0xffff) {			qp_attr->vlan_id = cm_id_priv->av.ah_attr.vlan_id;			*qp_attr_mask |= IB_QP_VID;		}		if (!is_zero_ether_addr(cm_id_priv->av.smac)) {			memcpy(qp_attr->smac, cm_id_priv->av.smac,			       sizeof(qp_attr->smac));			*qp_attr_mask |= IB_QP_SMAC;		}		if (cm_id_priv->alt_av.valid) {			if (cm_id_priv->alt_av.ah_attr.vlan_id != 0xffff) {				qp_attr->alt_vlan_id =					cm_id_priv->alt_av.ah_attr.vlan_id;				*qp_attr_mask |= IB_QP_ALT_VID;			}			if (!is_zero_ether_addr(cm_id_priv->alt_av.smac)) {				memcpy(qp_attr->alt_smac,				       cm_id_priv->alt_av.smac,				       sizeof(qp_attr->alt_smac));				*qp_attr_mask |= IB_QP_ALT_SMAC;			}		}		qp_attr->path_mtu = cm_id_priv->path_mtu;		qp_attr->dest_qp_num = be32_to_cpu(cm_id_priv->remote_qpn);		qp_attr->rq_psn = be32_to_cpu(cm_id_priv->rq_psn);		if (cm_id_priv->qp_type == IB_QPT_RC ||		    cm_id_priv->qp_type == IB_QPT_XRC_TGT) {			*qp_attr_mask |= IB_QP_MAX_DEST_RD_ATOMIC |					 IB_QP_MIN_RNR_TIMER;			qp_attr->max_dest_rd_atomic =					cm_id_priv->responder_resources;			qp_attr->min_rnr_timer = 0;		}		if (cm_id_priv->alt_av.ah_attr.dlid) {			*qp_attr_mask |= IB_QP_ALT_PATH;			qp_attr->alt_port_num = cm_id_priv->alt_av.port->port_num;			qp_attr->alt_pkey_index = cm_id_priv->alt_av.pkey_index;			qp_attr->alt_timeout = cm_id_priv->alt_av.timeout;			qp_attr->alt_ah_attr = cm_id_priv->alt_av.ah_attr;		}		ret = 0;		break;	default:		ret = -EINVAL;		break;	}	spin_unlock_irqrestore(&cm_id_priv->lock, flags);	return ret;}",11643
171,1461,CVE-2014-0203,24,"static int tid_fd_revalidate(struct dentry *dentry, struct nameidata *nd){	struct inode *inode = dentry->d_inode;	struct task_struct *task = get_proc_task(inode);	int fd = proc_fd(inode);	struct files_struct *files;	const struct cred *cred;	if (task) {		files = get_files_struct(task);		if (files) {			rcu_read_lock();			if (fcheck_files(files, fd)) {				rcu_read_unlock();				put_files_struct(files);				if (task_dumpable(task)) {					rcu_read_lock();					cred = __task_cred(task);					inode->i_uid = cred->euid;					inode->i_gid = cred->egid;					rcu_read_unlock();				} else {					inode->i_uid = 0;					inode->i_gid = 0;				}				inode->i_mode &= ~(S_ISUID | S_ISGID);				security_task_to_inode(task, inode);				put_task_struct(task);				return 1;			}			rcu_read_unlock();			put_files_struct(files);		}		put_task_struct(task);	}	d_drop(dentry);	return 0;}",12171
243,78,CVE-2015-5296,24,int smb1cli_conn_server_writeunlock(struct smbXcli_conn *conn){	return conn->smb1.server.writeunlock;},486
547,1873,CVE-2016-9191,24,static void sysctl_head_finish(struct ctl_table_header *head){	if (!head)		return;	spin_lock(&sysctl_lock);	unuse_table(head);	spin_unlock(&sysctl_lock);},15234
521,2249,CVE-2015-5195,24,"get_match(	char *s,	struct masks *m	){	while (m->name) {		if (strcmp(s, m->name) == 0)			return m->mask;		else			m++;	}	return 0;}",22915
326,2407,CVE-2019-1010251,24,void DecodeGlobalConfig(void){    DecodeTeredoConfig();},26385
631,789,CVE-2013-2140,24,"static int dispatch_other_io(struct xen_blkif *blkif,			     struct blkif_request *req,			     struct pending_req *pending_req){	free_req(blkif, pending_req);	make_response(blkif, req->u.other.id, req->operation,		      BLKIF_RSP_EOPNOTSUPP);	return -EIO;}",8866
603,1733,CVE-2013-7271,24,"static unsigned int x25_new_lci(struct x25_neigh *nb){	unsigned int lci = 1;	struct sock *sk;	read_lock_bh(&x25_list_lock);	while ((sk = __x25_find_socket(lci, nb)) != NULL) {		sock_put(sk);		if (++lci == 4096) {			lci = 0;			break;		}	}	read_unlock_bh(&x25_list_lock);	return lci;}",12621
13,1071,CVE-2014-3645,24,"static void kvm_unlink_unsync_page(struct kvm *kvm, struct kvm_mmu_page *sp){	WARN_ON(!sp->unsync);	trace_kvm_mmu_sync_page(sp);	sp->unsync = 0;	--kvm->stat.mmu_unsync;}",11205
673,24,CVE-2017-16227,24,"aspath_finish (void){  hash_clean (ashash, (void (*)(void *))aspath_free);  hash_free (ashash);  ashash = NULL;    if (snmp_stream)    stream_free (snmp_stream);}",346
58,1455,CVE-2014-0203,24,"static int proc_setattr(struct dentry *dentry, struct iattr *attr){	int error;	struct inode *inode = dentry->d_inode;	if (attr->ia_valid & ATTR_MODE)		return -EPERM;	error = inode_change_ok(inode, attr);	if (!error)		error = inode_setattr(inode, attr);	return error;}",12165
62,1277,CVE-2014-2523,24,"static inline struct dccp_net *dccp_pernet(struct net *net){	return net_generic(net, dccp_net_id);}",11823
288,1839,CVE-2016-9191,24,"static struct ctl_dir *get_subdir(struct ctl_dir *dir,				  const char *name, int namelen){	struct ctl_table_set *set = dir->header.set;	struct ctl_dir *subdir, *new = NULL;	int err;	spin_lock(&sysctl_lock);	subdir = find_subdir(dir, name, namelen);	if (!IS_ERR(subdir))		goto found;	if (PTR_ERR(subdir) != -ENOENT)		goto failed;	spin_unlock(&sysctl_lock);	new = new_dir(set, name, namelen);	spin_lock(&sysctl_lock);	subdir = ERR_PTR(-ENOMEM);	if (!new)		goto failed;	 	subdir = find_subdir(dir, name, namelen);	if (!IS_ERR(subdir))		goto found;	if (PTR_ERR(subdir) != -ENOENT)		goto failed;	 	err = insert_header(dir, &new->header);	subdir = ERR_PTR(err);	if (err)		goto failed;	subdir = new;found:	subdir->header.nreg++;failed:	if (IS_ERR(subdir)) {		pr_err(""sysctl could not get directory: "");		sysctl_print_dir(dir);		pr_cont(""/%*.*s %ld\n"",			namelen, namelen, name, PTR_ERR(subdir));	}	drop_sysctl_table(&dir->header);	if (new)		drop_sysctl_table(&new->header);	spin_unlock(&sysctl_lock);	return subdir;}",15200
689,2462,CVE-2010-1152,24,"static enum test_return test_binary_decrq(void) {    return test_binary_decr_impl(""test_binary_decrq"",                                 PROTOCOL_BINARY_CMD_DECREMENTQ);}",28219
655,1491,CVE-2013-7271,24,static void pppoe_flush_dev(struct net_device *dev){	struct pppoe_net *pn;	int i;	pn = pppoe_pernet(dev_net(dev));	write_lock_bh(&pn->hash_lock);	for (i = 0; i < PPPOE_HASH_SIZE; i++) {		struct pppox_sock *po = pn->hash_table[i];		struct sock *sk;		while (po) {			while (po && po->pppoe_dev != dev) {				po = po->next;			}			if (!po)				break;			sk = sk_pppox(po);			 			sock_hold(sk);			write_unlock_bh(&pn->hash_lock);			lock_sock(sk);			if (po->pppoe_dev == dev &&			    sk->sk_state & (PPPOX_CONNECTED | PPPOX_BOUND | PPPOX_ZOMBIE)) {				pppox_unbind_sock(sk);				sk->sk_state = PPPOX_ZOMBIE;				sk->sk_state_change(sk);				po->pppoe_dev = NULL;				dev_put(dev);			}			release_sock(sk);			sock_put(sk);			 			BUG_ON(pppoe_pernet(dev_net(dev)) == NULL);			write_lock_bh(&pn->hash_lock);			po = pn->hash_table[i];		}	}	write_unlock_bh(&pn->hash_lock);},12379
307,1709,CVE-2013-7271,24,static unsigned int unix_skb_len(const struct sk_buff *skb){	return skb->len - UNIXCB(skb).consumed;},12597
311,1154,CVE-2014-2739,24,"static void cm_format_paths_from_req(struct cm_req_msg *req_msg,					    struct ib_sa_path_rec *primary_path,					    struct ib_sa_path_rec *alt_path){	memset(primary_path, 0, sizeof *primary_path);	primary_path->dgid = req_msg->primary_local_gid;	primary_path->sgid = req_msg->primary_remote_gid;	primary_path->dlid = req_msg->primary_local_lid;	primary_path->slid = req_msg->primary_remote_lid;	primary_path->flow_label = cm_req_get_primary_flow_label(req_msg);	primary_path->hop_limit = req_msg->primary_hop_limit;	primary_path->traffic_class = req_msg->primary_traffic_class;	primary_path->reversible = 1;	primary_path->pkey = req_msg->pkey;	primary_path->sl = cm_req_get_primary_sl(req_msg);	primary_path->mtu_selector = IB_SA_EQ;	primary_path->mtu = cm_req_get_path_mtu(req_msg);	primary_path->rate_selector = IB_SA_EQ;	primary_path->rate = cm_req_get_primary_packet_rate(req_msg);	primary_path->packet_life_time_selector = IB_SA_EQ;	primary_path->packet_life_time =		cm_req_get_primary_local_ack_timeout(req_msg);	primary_path->packet_life_time -= (primary_path->packet_life_time > 0);	if (req_msg->alt_local_lid) {		memset(alt_path, 0, sizeof *alt_path);		alt_path->dgid = req_msg->alt_local_gid;		alt_path->sgid = req_msg->alt_remote_gid;		alt_path->dlid = req_msg->alt_local_lid;		alt_path->slid = req_msg->alt_remote_lid;		alt_path->flow_label = cm_req_get_alt_flow_label(req_msg);		alt_path->hop_limit = req_msg->alt_hop_limit;		alt_path->traffic_class = req_msg->alt_traffic_class;		alt_path->reversible = 1;		alt_path->pkey = req_msg->pkey;		alt_path->sl = cm_req_get_alt_sl(req_msg);		alt_path->mtu_selector = IB_SA_EQ;		alt_path->mtu = cm_req_get_path_mtu(req_msg);		alt_path->rate_selector = IB_SA_EQ;		alt_path->rate = cm_req_get_alt_packet_rate(req_msg);		alt_path->packet_life_time_selector = IB_SA_EQ;		alt_path->packet_life_time =			cm_req_get_alt_local_ack_timeout(req_msg);		alt_path->packet_life_time -= (alt_path->packet_life_time > 0);	}}",11629
561,542,CVE-2011-4914,24,"static void rose_insert_socket(struct sock *sk){	spin_lock_bh(&rose_list_lock);	sk_add_node(sk, &rose_list);	spin_unlock_bh(&rose_list_lock);}",4389
277,2646,CVE-2018-17471,24,  void WillWaitForFullscreenExit() { waiting_for_ = kFullscreenExit; },30061
433,12,CVE-2017-16227,24,"aspath_cmp (const void *arg1, const void *arg2){  const struct assegment *seg1 = ((const struct aspath *)arg1)->segments;  const struct assegment *seg2 = ((const struct aspath *)arg2)->segments;    while (seg1 || seg2)    {      int i;      if ((!seg1 && seg2) || (seg1 && !seg2))	return 0;      if (seg1->type != seg2->type)        return 0;            if (seg1->length != seg2->length)        return 0;      for (i = 0; i < seg1->length; i++)        if (seg1->as[i] != seg2->as[i])          return 0;      seg1 = seg1->next;      seg2 = seg2->next;    }  return 1;}",334
486,1033,CVE-2014-3645,24,static void init_shadow_page_table(struct kvm_mmu_page *sp){	int i;	for (i = 0; i < PT64_ENT_PER_PAGE; ++i)		sp->spt[i] = 0ull;},11167
362,2694,CVE-2018-6121,24,  void Wait() {    if (!AreAllFramesInTab())      message_loop_runner_->Run();  },30335
128,285,CVE-2014-7840,24,static void check_guest_throttling(void){    static int t0;    int        t1;    if (!mig_throttle_on) {        return;    }    if (!t0)  {        t0 = qemu_clock_get_ns(QEMU_CLOCK_REALTIME);        return;    }    t1 = qemu_clock_get_ns(QEMU_CLOCK_REALTIME);         if (40 < (t1-t0)/1000000) {        mig_throttle_guest_down();        t0 = t1;    }},1285
190,932,CVE-2011-3619,24,"static int apparmor_inode_getattr(struct vfsmount *mnt, struct dentry *dentry){	if (!mediated_filesystem(dentry->d_inode))		return 0;	return common_perm_mnt_dentry(OP_GETATTR, mnt, dentry,				      AA_MAY_META_READ);}",10103
607,2269,CVE-2014-8324,24,"static int net_set_rate(struct wif *wi, int rate){	int c = htonl(rate);	return net_cmd(wi_priv(wi), NET_SET_RATE, &c, sizeof(c));}",23120
423,1673,CVE-2013-7271,24,"static void prb_init_ft_ops(struct tpacket_kbdq_core *p1,			union tpacket_req_u *req_u){	p1->feature_req_word = req_u->req3.tp_feature_req_word;}",12561
556,1928,CVE-2016-2548,24,"static int snd_timer_start1(struct snd_timer *timer, struct snd_timer_instance *timeri,			    unsigned long sticks){	list_move_tail(&timeri->active_list, &timer->active_list_head);	if (timer->running) {		if (timer->hw.flags & SNDRV_TIMER_HW_SLAVE)			goto __start_now;		timer->flags |= SNDRV_TIMER_FLG_RESCHED;		timeri->flags |= SNDRV_TIMER_IFLG_START;		return 1;	 	} else {		timer->sticks = sticks;		timer->hw.start(timer);	      __start_now:		timer->running++;		timeri->flags |= SNDRV_TIMER_IFLG_RUNNING;		return 0;	}}",17511
64,435,CVE-2017-12187,24,PseudoramiXResetScreens(void){    TRACE;    pseudoramiXNumScreens = 0;},2567
233,326,CVE-2017-5932,24,getifs (){  return ifs_value;},1630
601,875,CVE-2013-1819,24,xfs_buf_lru_del(	struct xfs_buf	*bp){	struct xfs_buftarg *btp = bp->b_target;	if (list_empty(&bp->b_lru))		return;	spin_lock(&btp->bt_lru_lock);	if (!list_empty(&bp->b_lru)) {		list_del_init(&bp->b_lru);		btp->bt_lru_nr--;	}	spin_unlock(&btp->bt_lru_lock);},9482
55,2762,CVE-2011-2518,24,"static int tomoyo_mount_acl(struct tomoyo_request_info *r, char *dev_name,			    struct path *dir, char *type, unsigned long flags){	struct path path;	struct file_system_type *fstype = NULL;	const char *requested_type = NULL;	const char *requested_dir_name = NULL;	const char *requested_dev_name = NULL;	struct tomoyo_path_info rtype;	struct tomoyo_path_info rdev;	struct tomoyo_path_info rdir;	int need_dev = 0;	int error = -ENOMEM;	 	requested_type = tomoyo_encode(type);	if (!requested_type)		goto out;	rtype.name = requested_type;	tomoyo_fill_path_info(&rtype);	 	requested_dir_name = tomoyo_realpath_from_path(dir);	if (!requested_dir_name) {		error = -ENOMEM;		goto out;	}	rdir.name = requested_dir_name;	tomoyo_fill_path_info(&rdir);	 	if (!strcmp(type, TOMOYO_MOUNT_REMOUNT_KEYWORD)) {		 	} else if (!strcmp(type, TOMOYO_MOUNT_MAKE_UNBINDABLE_KEYWORD) ||		   !strcmp(type, TOMOYO_MOUNT_MAKE_PRIVATE_KEYWORD) ||		   !strcmp(type, TOMOYO_MOUNT_MAKE_SLAVE_KEYWORD) ||		   !strcmp(type, TOMOYO_MOUNT_MAKE_SHARED_KEYWORD)) {		 	} else if (!strcmp(type, TOMOYO_MOUNT_BIND_KEYWORD) ||		   !strcmp(type, TOMOYO_MOUNT_MOVE_KEYWORD)) {		need_dev = -1;  	} else {		fstype = get_fs_type(type);		if (!fstype) {			error = -ENODEV;			goto out;		}		if (fstype->fs_flags & FS_REQUIRES_DEV)			 			need_dev = 1; 	} 	if (need_dev) { 		 		if (kern_path(dev_name, LOOKUP_FOLLOW, &path)) { 			error = -ENOENT; 			goto out; 		}		requested_dev_name = tomoyo_realpath_from_path(&path);		path_put(&path);		if (!requested_dev_name) {			error = -ENOENT;			goto out;		}	} else {		 		if (!dev_name)			dev_name = ""<NULL>"";		requested_dev_name = tomoyo_encode(dev_name);		if (!requested_dev_name) {			error = -ENOMEM;			goto out;		}	}	rdev.name = requested_dev_name;	tomoyo_fill_path_info(&rdev);	r->param_type = TOMOYO_TYPE_MOUNT_ACL;	r->param.mount.need_dev = need_dev;	r->param.mount.dev = &rdev;	r->param.mount.dir = &rdir;	r->param.mount.type = &rtype;	r->param.mount.flags = flags;	do {		tomoyo_check_acl(r, tomoyo_check_mount_acl);		error = tomoyo_audit_mount_log(r);	} while (error == TOMOYO_RETRY_REQUEST); out:	kfree(requested_dev_name);	kfree(requested_dir_name);	if (fstype)		put_filesystem(fstype);	kfree(requested_type);	return error;}",31025
412,201,CVE-2011-1428,24,"irc_server_search_option (const char *option_name){    int i;        if (!option_name)        return -1;        for (i = 0; i < IRC_SERVER_NUM_OPTIONS; i++)    {        if (weechat_strcasecmp (irc_server_option_string[i],                                option_name) == 0)            return i;    }             return -1;}",695
17,525,CVE-2012-2136,24,"static inline void sock_valint_flag(struct sock *sk, int bit, int valint){	if (valint)		sock_set_flag(sk, bit);	else		sock_reset_flag(sk, bit);}",3484
325,1794,CVE-2015-8215,24,"void inet6_netconf_notify_devconf(struct net *net, int type, int ifindex,				  struct ipv6_devconf *devconf){	struct sk_buff *skb;	int err = -ENOBUFS;	skb = nlmsg_new(inet6_netconf_msgsize_devconf(type), GFP_ATOMIC);	if (skb == NULL)		goto errout;	err = inet6_netconf_fill_devconf(skb, ifindex, devconf, 0, 0,					 RTM_NEWNETCONF, 0, type);	if (err < 0) {		 		WARN_ON(err == -EMSGSIZE);		kfree_skb(skb);		goto errout;	}	rtnl_notify(skb, net, 0, RTNLGRP_IPV6_NETCONF, NULL, GFP_ATOMIC);	return;errout:	rtnl_set_sk_err(net, RTNLGRP_IPV6_NETCONF, err);}",13004
384,135,CVE-2011-1428,24,"hook_print_exec (struct t_gui_buffer *buffer, struct t_gui_line *line){    struct t_hook *ptr_hook, *next_hook;    char *prefix_no_color, *message_no_color;    int tags_match, tag_found, i, j;        if (!line->data->message || !line->data->message[0])        return;        prefix_no_color = (line->data->prefix) ?        gui_color_decode (line->data->prefix, NULL) : NULL;        message_no_color = gui_color_decode (line->data->message, NULL);    if (!message_no_color)    {        if (prefix_no_color)            free (prefix_no_color);        return;    }        hook_exec_start ();        ptr_hook = weechat_hooks[HOOK_TYPE_PRINT];    while (ptr_hook)    {        next_hook = ptr_hook->next_hook;                if (!ptr_hook->deleted            && !ptr_hook->running            && (!HOOK_PRINT(ptr_hook, buffer)                || (buffer == HOOK_PRINT(ptr_hook, buffer)))            && (!HOOK_PRINT(ptr_hook, message)                || !HOOK_PRINT(ptr_hook, message)[0]                || string_strcasestr (prefix_no_color, HOOK_PRINT(ptr_hook, message))                || string_strcasestr (message_no_color, HOOK_PRINT(ptr_hook, message))))        {                         if (HOOK_PRINT(ptr_hook, tags_array))            {                                 if (line->data->tags_array)                {                    tags_match = 1;                    for (i = 0; i < HOOK_PRINT(ptr_hook, tags_count); i++)                    {                                                 tag_found = 0;                        for (j = 0; j < line->data->tags_count; j++)                        {                            if (string_strcasecmp (HOOK_PRINT(ptr_hook, tags_array)[i],                                                   line->data->tags_array[j]) == 0)                            {                                tag_found = 1;                                break;                            }                        }                                                 if (!tag_found)                        {                            tags_match = 0;                            break;                        }                    }                }                else                    tags_match = 0;            }            else                tags_match = 1;                                     if (tags_match)            {                ptr_hook->running = 1;                (void) (HOOK_PRINT(ptr_hook, callback))                    (ptr_hook->callback_data, buffer, line->data->date,                     line->data->tags_count,                     (const char **)line->data->tags_array,                     (int)line->data->displayed, (int)line->data->highlight,                     (HOOK_PRINT(ptr_hook, strip_colors)) ? prefix_no_color : line->data->prefix,                     (HOOK_PRINT(ptr_hook, strip_colors)) ? message_no_color : line->data->message);                ptr_hook->running = 0;            }        }                ptr_hook = next_hook;    }        if (prefix_no_color)        free (prefix_no_color);    if (message_no_color)        free (message_no_color);        hook_exec_end ();}",629
149,1425,CVE-2014-0203,24,"int vfs_symlink(struct inode *dir, struct dentry *dentry, const char *oldname){	int error = may_create(dir, dentry);	if (error)		return error;	if (!dir->i_op->symlink)		return -EPERM;	error = security_inode_symlink(dir, dentry, oldname);	if (error)		return error;	vfs_dq_init(dir);	error = dir->i_op->symlink(dir, dentry, oldname);	if (!error)		fsnotify_create(dir, dentry);	return error;}",12135
679,807,CVE-2013-1848,24,"void __ext3_std_error (struct super_block * sb, const char * function,		       int errno){	char nbuf[16];	const char *errstr;	 	if (errno == -EROFS && journal_current_handle() == NULL &&	    (sb->s_flags & MS_RDONLY))		return;	errstr = ext3_decode_error(sb, errno, nbuf);	ext3_msg(sb, KERN_CRIT, ""error in %s: %s"", function, errstr);	ext3_handle_error(sb);}",9363
397,1784,CVE-2015-8215,24,"static int if6_seq_open(struct inode *inode, struct file *file){	return seq_open_net(inode, file, &if6_seq_ops,			    sizeof(struct if6_iter_state));}",12994
630,2147,CVE-2017-11665,24,"void ff_amf_write_object_start(int **dst){    bytestream_put_byte(dst, AMF_DATA_TYPE_OBJECT);}",20462
207,852,CVE-2013-1828,24,"static inline int sctp_verify_addr(struct sock *sk, union sctp_addr *addr,				   int len){	struct sctp_af *af;	 	af = sctp_sockaddr_af(sctp_sk(sk), addr, len);	if (!af)		return -EINVAL;	 	if (!af->addr_valid(addr, sctp_sk(sk), NULL))		return -EINVAL;	if (!sctp_sk(sk)->pf->send_verify(sctp_sk(sk), (addr)))		return -EINVAL;	return 0;}",9408
519,324,CVE-2017-5932,24,fifos_pending (){  return nfifo;},1628
154,1479,CVE-2013-7271,24,"mISDN_sock_create(struct net *net, struct socket *sock, int proto, int kern){	int err = -EPROTONOSUPPORT;	switch (proto) {	case ISDN_P_BASE:		err = base_sock_create(net, sock, proto);		break;	case ISDN_P_TE_S0:	case ISDN_P_NT_S0:	case ISDN_P_TE_E1:	case ISDN_P_NT_E1:	case ISDN_P_LAPD_TE:	case ISDN_P_LAPD_NT:	case ISDN_P_B_RAW:	case ISDN_P_B_HDLC:	case ISDN_P_B_X75SLP:	case ISDN_P_B_L2DTMF:	case ISDN_P_B_L2DSP:	case ISDN_P_B_L2DSPHDLC:		err = data_sock_create(net, sock, proto);		break;	default:		return err;	}	return err;}",12367
390,550,CVE-2011-4914,24,static int rose_loopback_running(void){	return timer_pending(&loopback_timer);},4397
459,1738,CVE-2013-7271,24,"static int x25_wait_for_connection_establishment(struct sock *sk){	DECLARE_WAITQUEUE(wait, current);	int rc;	add_wait_queue_exclusive(sk_sleep(sk), &wait);	for (;;) {		__set_current_state(TASK_INTERRUPTIBLE);		rc = -ERESTARTSYS;		if (signal_pending(current))			break;		rc = sock_error(sk);		if (rc) {			sk->sk_socket->state = SS_UNCONNECTED;			break;		}		rc = 0;		if (sk->sk_state != TCP_ESTABLISHED) {			release_sock(sk);			schedule();			lock_sock(sk);		} else			break;	}	__set_current_state(TASK_RUNNING);	remove_wait_queue(sk_sleep(sk), &wait);	return rc;}",12626
240,1900,CVE-2016-6197,24,"static int ovl_set_opaque(struct dentry *upperdentry){	return ovl_do_setxattr(upperdentry, OVL_XATTR_OPAQUE, ""y"", 1, 0);}",16255
303,1504,CVE-2013-7271,24,"static int atalk_create(struct net *net, struct socket *sock, int protocol,			int kern){	struct sock *sk;	int rc = -ESOCKTNOSUPPORT;	if (!net_eq(net, &init_net))		return -EAFNOSUPPORT;	 	if (sock->type != SOCK_RAW && sock->type != SOCK_DGRAM)		goto out;	rc = -ENOMEM;	sk = sk_alloc(net, PF_APPLETALK, GFP_KERNEL, &ddp_proto);	if (!sk)		goto out;	rc = 0;	sock->ops = &atalk_dgram_ops;	sock_init_data(sock, sk);	 	sock_set_flag(sk, SOCK_ZAPPED);out:	return rc;}",12392
82,1825,CVE-2016-9919,24,"static struct dst_entry *icmpv6_route_lookup(struct net *net,					     struct sk_buff *skb,					     struct sock *sk,					     struct flowi6 *fl6){	struct dst_entry *dst, *dst2;	struct flowi6 fl2;	int err;	err = ip6_dst_lookup(net, sk, &dst, fl6);	if (err)		return ERR_PTR(err);	 	if (ipv6_anycast_destination(dst, &fl6->daddr)) {		net_dbg_ratelimited(""icmp6_send: acast source\n"");		dst_release(dst);		return ERR_PTR(-EINVAL);	}	 	dst2 = dst;	dst = xfrm_lookup(net, dst, flowi6_to_flowi(fl6), sk, 0);	if (!IS_ERR(dst)) {		if (dst != dst2)			return dst;	} else {		if (PTR_ERR(dst) == -EPERM)			dst = NULL;		else			return dst;	}	err = xfrm_decode_session_reverse(skb, flowi6_to_flowi(&fl2), AF_INET6);	if (err)		goto relookup_failed;	err = ip6_dst_lookup(net, sk, &dst2, &fl2);	if (err)		goto relookup_failed;	dst2 = xfrm_lookup(net, dst2, flowi6_to_flowi(&fl2), sk, XFRM_LOOKUP_ICMP);	if (!IS_ERR(dst2)) {		dst_release(dst);		dst = dst2;	} else {		err = PTR_ERR(dst2);		if (err == -EPERM) {			dst_release(dst);			return dst2;		} else			goto relookup_failed;	}relookup_failed:	if (dst)		return dst;	return ERR_PTR(err);}",14965
42,2054,CVE-2017-17862,24,"static int push_insn(int t, int w, int e, struct bpf_verifier_env *env){	if (e == FALLTHROUGH && insn_state[t] >= (DISCOVERED | FALLTHROUGH))		return 0;	if (e == BRANCH && insn_state[t] >= (DISCOVERED | BRANCH))		return 0;	if (w < 0 || w >= env->prog->len) {		verbose(env, ""jump out of range from insn %d to %d\n"", t, w);		return -EINVAL;	}	if (e == BRANCH)		 		env->explored_states[w] = STATE_LIST_MARK;	if (insn_state[w] == 0) {		 		insn_state[t] = DISCOVERED | e;		insn_state[w] = DISCOVERED;		if (cur_stack >= env->prog->len)			return -E2BIG;		insn_stack[cur_stack++] = w;		return 1;	} else if ((insn_state[w] & 0xF0) == DISCOVERED) {		verbose(env, ""back-edge from insn %d to %d\n"", t, w);		return -EINVAL;	} else if (insn_state[w] == EXPLORED) {		 		insn_state[t] = DISCOVERED | e;	} else {		verbose(env, ""insn state internal bug\n"");		return -EFAULT;	}	return 0;}",19552
271,2350,CVE-2018-11232,24,"static int etm_event_add(struct perf_event *event, int mode){	int ret = 0;	struct hw_perf_event *hwc = &event->hw;	if (mode & PERF_EF_START) {		etm_event_start(event, 0);		if (hwc->state & PERF_HES_STOPPED)			ret = -EINVAL;	} else {		hwc->state = PERF_HES_STOPPED;	}	return ret;}",25205
484,2457,CVE-2010-1152,24,"static enum test_return stop_memcached_server(void) {    close(sock);    assert(kill(server_pid, SIGTERM) == 0);    return TEST_PASS;}",28214
177,956,CVE-2014-5472,24,"static struct inode *isofs_alloc_inode(struct super_block *sb){	struct iso_inode_info *ei;	ei = kmem_cache_alloc(isofs_inode_cachep, GFP_KERNEL);	if (!ei)		return NULL;	return &ei->vfs_inode;}",10613
33,1848,CVE-2016-9191,24,"static struct ctl_dir *new_dir(struct ctl_table_set *set,			       const char *name, int namelen){	struct ctl_table *table;	struct ctl_dir *new;	struct ctl_node *node;	char *new_name;	new = kzalloc(sizeof(*new) + sizeof(struct ctl_node) +		      sizeof(struct ctl_table)*2 +  namelen + 1,		      GFP_KERNEL);	if (!new)		return NULL;	node = (struct ctl_node *)(new + 1);	table = (struct ctl_table *)(node + 1);	new_name = (char *)(table + 2);	memcpy(new_name, name, namelen);	new_name[namelen] = '\0';	table[0].procname = new_name;	table[0].mode = S_IFDIR|S_IRUGO|S_IXUGO;	init_header(&new->header, set->dir.header.root, set, node, table);	return new;}",15209
161,114,CVE-2015-5296,24,"void cli_cm_display(struct cli_state *cli){	int i;	for (i=0; cli; cli = cli->next,i++ ) {		d_printf(""%d:\tserver=%s, share=%s\n"",			i, smbXcli_conn_remote_name(cli->conn), cli->share);	}}",522
388,283,CVE-2014-7840,24,static void XBZRLE_cache_unlock(void){    if (migrate_use_xbzrle())        qemu_mutex_unlock(&XBZRLE.lock);},1283
644,1101,CVE-2014-3645,24,static void paging_free(struct kvm_vcpu *vcpu){	nonpaging_free(vcpu);},11235
132,1978,CVE-2008-7316,24,"void end_page_writeback(struct page *page){	if (!TestClearPageReclaim(page) || rotate_reclaimable_page(page)) {		if (!test_clear_page_writeback(page))			BUG();	}	smp_mb__after_clear_bit();	wake_up_page(page, PG_writeback);}",19430
196,1776,CVE-2015-8215,24,static void addrconf_sysctl_unregister(struct inet6_dev *idev){	__addrconf_sysctl_unregister(&idev->cnf);	neigh_sysctl_unregister(idev->nd_parms);},12986
318,1942,CVE-2016-1541,24,"read_decryption_header(struct archive_read *a){	struct zip *zip = (struct zip *)(a->format->data);	const char *p;	unsigned int remaining_size;	unsigned int ts;	 	p = __archive_read_ahead(a, 2, NULL);	if (p == NULL)		goto truncated;	ts = zip->iv_size;	zip->iv_size = archive_le16dec(p);	__archive_read_consume(a, 2);	if (ts < zip->iv_size) {		free(zip->iv);		zip->iv = NULL;	}	p = __archive_read_ahead(a, zip->iv_size, NULL);	if (p == NULL)		goto truncated;	if (zip->iv == NULL) {		zip->iv = malloc(zip->iv_size);		if (zip->iv == NULL)			goto nomem;	}	memcpy(zip->iv, p, zip->iv_size);	__archive_read_consume(a, zip->iv_size);	 	p = __archive_read_ahead(a, 14, NULL);	if (p == NULL)		goto truncated;	remaining_size = archive_le32dec(p);	if (remaining_size < 16 || remaining_size > (1 << 18))		goto corrupted;	 	if (archive_le16dec(p+4) != 3) {		archive_set_error(&a->archive,		    ARCHIVE_ERRNO_FILE_FORMAT,		    ""Unsupported encryption format version: %u"",		    archive_le16dec(p+4));		return (ARCHIVE_FAILED);	}	 	zip->alg_id = archive_le16dec(p+6);	switch (zip->alg_id) {	case 0x6601: 	case 0x6602: 	case 0x6603: 	case 0x6609: 	case 0x660E: 	case 0x660F: 	case 0x6610: 	case 0x6702: 	case 0x6720: 	case 0x6721: 	case 0x6801: 		 		break;	default:		archive_set_error(&a->archive,		    ARCHIVE_ERRNO_FILE_FORMAT,		    ""Unknown encryption algorithm: %u"", zip->alg_id);		return (ARCHIVE_FAILED);	}	 	zip->bit_len = archive_le16dec(p+8);	 	zip->flags = archive_le16dec(p+10);	switch (zip->flags & 0xf000) {	case 0x0001:  	case 0x0002:  	case 0x0003:  		break;	default:		archive_set_error(&a->archive,		    ARCHIVE_ERRNO_FILE_FORMAT,		    ""Unknown encryption flag: %u"", zip->flags);		return (ARCHIVE_FAILED);	}	if ((zip->flags & 0xf000) == 0 ||	    (zip->flags & 0xf000) == 0x4000) {		archive_set_error(&a->archive,		    ARCHIVE_ERRNO_FILE_FORMAT,		    ""Unknown encryption flag: %u"", zip->flags);		return (ARCHIVE_FAILED);	}	 	ts = zip->erd_size;	zip->erd_size = archive_le16dec(p+12);	__archive_read_consume(a, 14);	if ((zip->erd_size & 0xf) != 0 ||	    (zip->erd_size + 16) > remaining_size ||	    (zip->erd_size + 16) < zip->erd_size)		goto corrupted;	if (ts < zip->erd_size) {		free(zip->erd);		zip->erd = NULL;	}	p = __archive_read_ahead(a, zip->erd_size, NULL);	if (p == NULL)		goto truncated;	if (zip->erd == NULL) {		zip->erd = malloc(zip->erd_size);		if (zip->erd == NULL)			goto nomem;	}	memcpy(zip->erd, p, zip->erd_size);	__archive_read_consume(a, zip->erd_size);	 	p = __archive_read_ahead(a, 4, NULL);	if (p == NULL)		goto truncated;	 	if (archive_le32dec(p) != 0)		goto corrupted;	__archive_read_consume(a, 4);	 	p = __archive_read_ahead(a, 2, NULL);	if (p == NULL)		goto truncated;	ts = zip->v_size;	zip->v_size = archive_le16dec(p);	__archive_read_consume(a, 2);	if ((zip->v_size & 0x0f) != 0 ||	    (zip->erd_size + zip->v_size + 16) > remaining_size ||	    (zip->erd_size + zip->v_size + 16) < (zip->erd_size + zip->v_size))		goto corrupted;	if (ts < zip->v_size) {		free(zip->v_data);		zip->v_data = NULL;	}	p = __archive_read_ahead(a, zip->v_size, NULL);	if (p == NULL)		goto truncated;	if (zip->v_data == NULL) {		zip->v_data = malloc(zip->v_size);		if (zip->v_data == NULL)			goto nomem;	}	memcpy(zip->v_data, p, zip->v_size);	__archive_read_consume(a, zip->v_size);	p = __archive_read_ahead(a, 4, NULL);	if (p == NULL)		goto truncated;	zip->v_crc32 = archive_le32dec(p);	__archive_read_consume(a, 4);	 	archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,	    ""Encrypted file is unsupported"");	return (ARCHIVE_FAILED);truncated:	archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,	    ""Truncated ZIP file data"");	return (ARCHIVE_FATAL);corrupted:	archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,	    ""Corrupted ZIP file data"");	return (ARCHIVE_FATAL);nomem:	archive_set_error(&a->archive, ENOMEM,	    ""No memory for ZIP decryption"");	return (ARCHIVE_FATAL);}",18172
356,426,CVE-2014-9645,24,"static void load_modules_dep(void){	struct module_entry *m;	char *colon, *tokens[2];	parser_t *p;	 	p = config_open2(CONFIG_DEFAULT_DEPMOD_FILE, xfopen_for_read);	while (G.num_unresolved_deps	 && config_read(p, tokens, 2, 1, ""# \t"", PARSE_NORMAL)	) {		colon = last_char_is(tokens[0], ':');		if (colon == NULL)			continue;		*colon = 0;		m = get_modentry(tokens[0]);		if (m == NULL)			continue;		 		if ((m->flags & MODULE_FLAG_LOADED)		 && !(option_mask32 & (OPT_REMOVE | OPT_SHOW_DEPS))		) {			DBG(""skip deps of %s, it's already loaded"", tokens[0]);			continue;		}		m->flags |= MODULE_FLAG_FOUND_IN_MODDEP;		if ((m->flags & MODULE_FLAG_NEED_DEPS) && (m->deps == NULL)) {			G.num_unresolved_deps--;			llist_add_to(&m->deps, xstrdup(tokens[0]));			if (tokens[1])				string_to_llist(tokens[1], &m->deps, "" \t"");		} else			DBG(""skipping dep line"");	}	config_close(p);}",2506
184,804,CVE-2013-1943,24,static void kvm_io_bus_destroy(struct kvm_io_bus *bus){	int i;	for (i = 0; i < bus->dev_count; i++) {		struct kvm_io_device *pos = bus->devs[i];		kvm_iodevice_destructor(pos);	}	kfree(bus);},9217
312,541,CVE-2011-4914,24,"static int rose_info_show(struct seq_file *seq, void *v){	char buf[11], rsbuf[11];	if (v == SEQ_START_TOKEN)		seq_puts(seq,			 ""dest_addr  dest_call src_addr   src_call  dev   lci neigh st vs vr va   t  t1  t2  t3  hb    idle Snd-Q Rcv-Q inode\n"");	else {		struct sock *s = sk_entry(v);		struct rose_sock *rose = rose_sk(s);		const char *devname, *callsign;		const struct net_device *dev = rose->device;		if (!dev)			devname = ""???"";		else			devname = dev->name;		seq_printf(seq, ""%-10s %-9s "",			   rose2asc(rsbuf, &rose->dest_addr),			   ax2asc(buf, &rose->dest_call));		if (ax25cmp(&rose->source_call, &null_ax25_address) == 0)			callsign = ""??????-?"";		else			callsign = ax2asc(buf, &rose->source_call);		seq_printf(seq,			   ""%-10s %-9s %-5s %3.3X %05d  %d  %d  %d  %d %3lu %3lu %3lu %3lu %3lu %3lu/%03lu %5d %5d %ld\n"",			rose2asc(rsbuf, &rose->source_addr),			callsign,			devname,			rose->lci & 0x0FFF,			(rose->neighbour) ? rose->neighbour->number : 0,			rose->state,			rose->vs,			rose->vr,			rose->va,			ax25_display_timer(&rose->timer) / HZ,			rose->t1 / HZ,			rose->t2 / HZ,			rose->t3 / HZ,			rose->hb / HZ,			ax25_display_timer(&rose->idletimer) / (60 * HZ),			rose->idle / (60 * HZ),			sk_wmem_alloc_get(s),			sk_rmem_alloc_get(s),			s->sk_socket ? SOCK_INODE(s->sk_socket)->i_ino : 0L);	}	return 0;}",4388
527,2122,CVE-2017-14604,24," is_all_button_text (const char *button_text){    g_assert (button_text != NULL);    return !strcmp (button_text, SKIP_ALL) ||           !strcmp (button_text, REPLACE_ALL) ||           !strcmp (button_text, DELETE_ALL) ||           !strcmp (button_text, MERGE_ALL);}",20139
645,1587,CVE-2013-7271,24,"static void **alloc_pg_vec(struct netlink_sock *nlk,			   struct nl_mmap_req *req, unsigned int order){	unsigned int block_nr = req->nm_block_nr;	unsigned int i;	void **pg_vec;	pg_vec = kcalloc(block_nr, sizeof(void *), GFP_KERNEL);	if (pg_vec == NULL)		return NULL;	for (i = 0; i < block_nr; i++) {		pg_vec[i] = alloc_one_pg_vec_page(order);		if (pg_vec[i] == NULL)			goto err1;	}	return pg_vec;err1:	free_pg_vec(pg_vec, order, block_nr);	return NULL;}",12475
393,241,CVE-2015-0293,24,long ssl2_default_timeout(void){    return (300);},990
435,2341,CVE-2018-14361,24,"static int nntp_connect_error(struct NntpServer *nserv){  nserv->status = NNTP_NONE;  mutt_error(_(""Server closed connection!""));  return -1;}",24486
425,219,CVE-2013-2168,24,"_dbus_get_real_time (long *tv_sec,                     long *tv_usec){  struct timeval t;  gettimeofday (&t, NULL);  if (tv_sec)    *tv_sec = t.tv_sec;  if (tv_usec)    *tv_usec = t.tv_usec;}",734
461,2461,CVE-2010-1152,24,"static enum test_return test_binary_decr(void) {    return test_binary_decr_impl(""test_binary_decr"",                                 PROTOCOL_BINARY_CMD_DECREMENT);}",28218
416,1995,CVE-2017-1000252,24,"static void irqfd_update(struct kvm *kvm, struct kvm_kernel_irqfd *irqfd){	struct kvm_kernel_irq_routing_entry *e;	struct kvm_kernel_irq_routing_entry entries[KVM_NR_IRQCHIPS];	int n_entries;	n_entries = kvm_irq_map_gsi(kvm, entries, irqfd->gsi);	write_seqcount_begin(&irqfd->irq_entry_sc);	e = entries;	if (n_entries == 1)		irqfd->irq_entry = *e;	else		irqfd->irq_entry.type = 0;	write_seqcount_end(&irqfd->irq_entry_sc);}",19456
495,1974,CVE-2008-7316,24,"static inline int __filemap_fdatawrite(struct address_space *mapping,	int sync_mode){	return __filemap_fdatawrite_range(mapping, 0, LLONG_MAX, sync_mode);}",19426
134,5,CVE-2018-1000040,24,static inline float fung(float x){	if (x >= 6.0f / 29.0f)		return x * x * x;	return (108.0f / 841.0f) * (x - (4.0f / 29.0f));},202
94,1503,CVE-2013-7271,24,"static int atalk_compat_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg){	 	if (cmd == SIOCATALKDIFADDR)		return atalk_ioctl(sock, cmd, (unsigned long)compat_ptr(arg));	return -ENOIOCTLCMD;}",12391
44,860,CVE-2013-1819,24,"_xfs_buf_ioapply(	struct xfs_buf	*bp){	struct blk_plug	plug;	int		rw;	int		offset;	int		size;	int		i;	if (bp->b_flags & XBF_WRITE) {		if (bp->b_flags & XBF_SYNCIO)			rw = WRITE_SYNC;		else			rw = WRITE;		if (bp->b_flags & XBF_FUA)			rw |= REQ_FUA;		if (bp->b_flags & XBF_FLUSH)			rw |= REQ_FLUSH;		 		if (bp->b_ops) {			bp->b_ops->verify_write(bp);			if (bp->b_error) {				xfs_force_shutdown(bp->b_target->bt_mount,						   SHUTDOWN_CORRUPT_INCORE);				return;			}		}	} else if (bp->b_flags & XBF_READ_AHEAD) {		rw = READA;	} else {		rw = READ;	}	 	rw |= REQ_META;	 	offset = bp->b_offset;	size = BBTOB(bp->b_io_length);	blk_start_plug(&plug);	for (i = 0; i < bp->b_map_count; i++) {		xfs_buf_ioapply_map(bp, i, &offset, &size, rw);		if (bp->b_error)			break;		if (size <= 0)			break;	 	}	blk_finish_plug(&plug);}",9467
375,1405,CVE-2014-0203,24,"int may_open(struct path *path, int acc_mode, int flag){	struct dentry *dentry = path->dentry;	struct inode *inode = dentry->d_inode;	int error;	if (!inode)		return -ENOENT;	switch (inode->i_mode & S_IFMT) {	case S_IFLNK:		return -ELOOP;	case S_IFDIR:		if (acc_mode & MAY_WRITE)			return -EISDIR;		break;	case S_IFBLK:	case S_IFCHR:		if (path->mnt->mnt_flags & MNT_NODEV)			return -EACCES;		 	case S_IFIFO:	case S_IFSOCK:		flag &= ~O_TRUNC;		break;	}	error = inode_permission(inode, acc_mode);	if (error)		return error;	 	if (IS_APPEND(inode)) {		if  ((flag & FMODE_WRITE) && !(flag & O_APPEND))			return -EPERM;		if (flag & O_TRUNC)			return -EPERM;	}	 	if (flag & O_NOATIME && !is_owner_or_cap(inode))		return -EPERM;	 	return break_lease(inode, flag);}",12115
21,1370,CVE-2014-1874,24,"static void security_load_policycaps(void){	selinux_policycap_netpeer = ebitmap_get_bit(&policydb.policycaps,						  POLICYDB_CAPABILITY_NETPEER);	selinux_policycap_openperm = ebitmap_get_bit(&policydb.policycaps,						  POLICYDB_CAPABILITY_OPENPERM);	selinux_policycap_alwaysnetwork = ebitmap_get_bit(&policydb.policycaps,						  POLICYDB_CAPABILITY_ALWAYSNETWORK);}",11920
179,1316,CVE-2014-2038,24,"static void nfs_init_cinfo_from_inode(struct nfs_commit_info *cinfo,				      struct inode *inode){	cinfo->lock = &inode->i_lock;	cinfo->mds = &NFS_I(inode)->commit_info;	cinfo->ds = pnfs_get_ds_info(inode);	cinfo->dreq = NULL;	cinfo->completion_ops = &nfs_commit_completion_ops;}",11863
564,2417,CVE-2019-12439,24,propagate_exit_status (int status){  if (WIFEXITED (status))    return WEXITSTATUS (status);     if (WIFSIGNALED (status))    return 128 + WTERMSIG (status);     return 255;},26874
309,665,CVE-2013-6368,24,"int kvm_arch_vcpu_postcreate(struct kvm_vcpu *vcpu){	int r;	struct msr_data msr;	r = vcpu_load(vcpu);	if (r)		return r;	msr.data = 0x0;	msr.index = MSR_IA32_TSC;	msr.host_initiated = true;	kvm_write_tsc(vcpu, &msr);	vcpu_put(vcpu);	return r;}",7432
244,2277,CVE-2014-8323,24,"void usage(){	printf(""\n""		""  %s - (C) 2007,2008 Andrea Bittau\n""		""  http://www.aircrack-ng.org\n""		""\n""		""  Usage: buddy-ng <options>\n""		""\n""		""  Options:\n""		""\n""		""       -h        : This help screen\n""		""       -p        : Don't drop privileges\n""		""\n"",		getVersion(""Buddy-ng"", _MAJ, _MIN, _SUB_MIN, _REVISION, _BETA, _RC));	exit(1);}",23128
340,2297,CVE-2018-18021,24,"int kvm_arch_vcpu_ioctl_set_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs){	return -EINVAL;}",23581
444,2258,CVE-2014-8324,24,static int handshake(int s){	if (s) {}  	 	return 0;},23109
465,2757,CVE-2012-0879,24,void exit_io_context(void){	struct io_context *ioc;	task_lock(current);	ioc = current->io_context;	current->io_context = NULL;	task_unlock(current);	if (atomic_dec_and_test(&ioc->nr_tasks)) {		if (ioc->aic && ioc->aic->exit) 			ioc->aic->exit(ioc->aic); 		cfq_exit(ioc); 		put_io_context(ioc); 	} },30951
187,1206,CVE-2014-2739,24,"static int cma_connect_iw(struct rdma_id_private *id_priv,			  struct rdma_conn_param *conn_param){	struct iw_cm_id *cm_id;	int ret;	struct iw_cm_conn_param iw_param;	cm_id = iw_create_cm_id(id_priv->id.device, cma_iw_handler, id_priv);	if (IS_ERR(cm_id))		return PTR_ERR(cm_id);	id_priv->cm_id.iw = cm_id;	memcpy(&cm_id->local_addr, cma_src_addr(id_priv),	       rdma_addr_size(cma_src_addr(id_priv)));	memcpy(&cm_id->remote_addr, cma_dst_addr(id_priv),	       rdma_addr_size(cma_dst_addr(id_priv)));	ret = cma_modify_qp_rtr(id_priv, conn_param);	if (ret)		goto out;	if (conn_param) {		iw_param.ord = conn_param->initiator_depth;		iw_param.ird = conn_param->responder_resources;		iw_param.private_data = conn_param->private_data;		iw_param.private_data_len = conn_param->private_data_len;		iw_param.qpn = id_priv->id.qp ? id_priv->qp_num : conn_param->qp_num;	} else {		memset(&iw_param, 0, sizeof iw_param);		iw_param.qpn = id_priv->qp_num;	}	ret = iw_cm_connect(cm_id, &iw_param);out:	if (ret) {		iw_destroy_cm_id(cm_id);		id_priv->cm_id.iw = NULL;	}	return ret;}",11681
97,2768,CVE-2013-0216,24,"void xenvif_disconnect(struct xenvif *vif) { 	struct net_device *dev = vif->dev;	if (netif_carrier_ok(dev)) {		rtnl_lock();		netif_carrier_off(dev);  		if (netif_running(dev))			xenvif_down(vif);		rtnl_unlock();		xenvif_put(vif);	}  	atomic_dec(&vif->refcnt); 	wait_event(vif->waiting_to_free, atomic_read(&vif->refcnt) == 0);	del_timer_sync(&vif->credit_timeout);	if (vif->irq)		unbind_from_irqhandler(vif->irq, vif);	unregister_netdev(vif->dev);	xen_netbk_unmap_frontend_rings(vif);	free_netdev(vif->dev);}",31099
371,2094,CVE-2017-15951,24,"int install_thread_keyring_to_cred(struct cred *new){	struct key *keyring;	if (new->thread_keyring)		return 0;	keyring = keyring_alloc(""_tid"", new->uid, new->gid, new,				KEY_POS_ALL | KEY_USR_VIEW,				KEY_ALLOC_QUOTA_OVERRUN,				NULL, NULL);	if (IS_ERR(keyring))		return PTR_ERR(keyring);	new->thread_keyring = keyring;	return 0;}",19917
663,261,CVE-2012-5534,24,hook_init (){    int type;    for (type = 0; type < HOOK_NUM_TYPES; type++)    {        weechat_hooks[type] = NULL;        last_weechat_hook[type] = NULL;    }    hook_last_system_time = time (NULL);},1192
305,1039,CVE-2014-3645,24,"int kvm_age_hva(struct kvm *kvm, unsigned long hva){	return kvm_handle_hva(kvm, hva, hva, kvm_age_rmapp);}",11173
415,711,CVE-2013-4587,24,"static int kvm_device_release(struct inode *inode, struct file *filp){	struct kvm_device *dev = filp->private_data;	struct kvm *kvm = dev->kvm;	kvm_put_kvm(kvm);	return 0;}",7650
691,70,CVE-2015-5296,24,int smb1cli_conn_max_xmit(struct smbXcli_conn *conn){	return conn->smb1.max_xmit;},478
584,377,CVE-2016-4071,24,"PHP_FUNCTION(snmp2_real_walk){	php_snmp(INTERNAL_FUNCTION_PARAM_PASSTHRU, SNMP_CMD_WALK, SNMP_VERSION_2c);}",1947
178,243,CVE-2012-6085,24,import_new_stats_handle (void){    return xmalloc_clear ( sizeof (struct stats_s) );},1016
355,925,CVE-2011-3619,24,static void apparmor_cred_free(struct cred *cred){	aa_free_task_context(cred->security);	cred->security = NULL;},10096
431,257,CVE-2012-5534,24,"hook_hsignal_send (const char *signal, struct t_hashtable *hashtable){    struct t_hook *ptr_hook, *next_hook;    hook_exec_start ();    ptr_hook = weechat_hooks[HOOK_TYPE_HSIGNAL];    while (ptr_hook)    {        next_hook = ptr_hook->next_hook;        if (!ptr_hook->deleted            && !ptr_hook->running            && (string_match (signal, HOOK_HSIGNAL(ptr_hook, signal), 0)))        {            ptr_hook->running = 1;            (void) (HOOK_HSIGNAL(ptr_hook, callback))                (ptr_hook->callback_data, signal, hashtable);            ptr_hook->running = 0;        }        ptr_hook = next_hook;    }    hook_exec_end ();}",1188
641,2148,CVE-2017-11665,24,"void ff_amf_write_string(int **dst, const char *str){    bytestream_put_byte(dst, AMF_DATA_TYPE_STRING);    bytestream_put_be16(dst, strlen(str));    bytestream_put_buffer(dst, str, strlen(str));}",20463
109,438,CVE-2017-12187,24,"RenderSetBit(unsigned char *line, int x, int bit){    unsigned char mask;    if (screenInfo.bitmapBitOrder == LSBFirst)        mask = (1 << (x & 7));    else        mask = (0x80 >> (x & 7));         line += (x >> 3);    if (bit)        *line |= mask;    else        *line &= ~mask;}",2570
118,1403,CVE-2014-0203,24,"static inline int may_create(struct inode *dir, struct dentry *child){	if (child->d_inode)		return -EEXIST;	if (IS_DEADDIR(dir))		return -ENOENT;	return inode_permission(dir, MAY_WRITE | MAY_EXEC);}",12113
399,1430,CVE-2014-0203,24,"void dup_mm_exe_file(struct mm_struct *oldmm, struct mm_struct *newmm){	 	newmm->exe_file = get_mm_exe_file(oldmm);}",12140
476,2773,CVE-2014-5336,24,"static inline int mk_vhost_fdt_close(struct session_request *sr){    int id;    unsigned int hash;    struct vhost_fdt_hash_table *ht = NULL;    struct vhost_fdt_hash_chain *hc;    if (config->fdt == MK_FALSE) {        return close(sr->fd_file);    }    id   = sr->vhost_fdt_id;    hash = sr->vhost_fdt_hash;    ht = mk_vhost_fdt_table_lookup(id, sr->host_conf);    if (mk_unlikely(!ht)) {        return close(sr->fd_file);    }         hc = mk_vhost_fdt_chain_lookup(hash, ht);    if (hc) {                 hc->readers--;        if (hc->readers == 0) {            hc->fd   = -1;            hc->hash = 0;            ht->av_slots++;            return close(sr->fd_file);        }        else {             return 0;         }     }     return close(sr->fd_file); }",31131
290,951,CVE-2011-3619,24,"static int param_set_aauint(const char *val, const struct kernel_param *kp){	if (!capable(CAP_MAC_ADMIN))		return -EPERM;	return param_set_uint(val, kp);}",10122
408,1288,CVE-2014-2038,24,nfs_clear_request_commit(struct nfs_page *req){},11835
389,137,CVE-2011-1428,24,"hook_process_child (struct t_hook *hook_process){    char *exec_args[4] = { ""sh"", ""-c"", NULL, NULL };             close (STDIN_FILENO);             close (HOOK_PROCESS(hook_process, child_read[HOOK_PROCESS_STDOUT]));    close (HOOK_PROCESS(hook_process, child_read[HOOK_PROCESS_STDERR]));    if (dup2 (HOOK_PROCESS(hook_process, child_write[HOOK_PROCESS_STDOUT]),              STDOUT_FILENO) < 0)    {        _exit (EXIT_FAILURE);    }    if (dup2 (HOOK_PROCESS(hook_process, child_write[HOOK_PROCESS_STDERR]),              STDERR_FILENO) < 0)    {        _exit (EXIT_FAILURE);    }             exec_args[2] = HOOK_PROCESS(hook_process, command);    execvp (exec_args[0], exec_args);             fprintf (stderr, ""Error with command '%s'\n"",             HOOK_PROCESS(hook_process, command));    _exit (EXIT_FAILURE);}",631
235,1097,CVE-2014-3645,24,"static int paging32E_init_context(struct kvm_vcpu *vcpu,				  struct kvm_mmu *context){	return paging64_init_context_common(vcpu, context, PT32E_ROOT_LEVEL);}",11231
84,2501,CVE-2017-12843,24,"static void clear_id() {    if (imapd_id.params) {        freeattvalues(imapd_id.params);    }    memset(&imapd_id, 0, sizeof(struct id_data));}",28502
107,975,CVE-2014-5472,24,"static int rootdir_empty(struct super_block *sb, unsigned long block){	int offset = 0, files = 0, de_len;	struct iso_directory_record *de;	struct buffer_head *bh;	bh = sb_bread(sb, block);	if (!bh)		return true;	while (files < 3) {		de = (struct iso_directory_record *) (bh->b_data + offset);		de_len = *(unsigned char *) de;		if (de_len == 0)			break;		files++;		offset += de_len;	}	brelse(bh);	return files < 3;}",10632
165,1976,CVE-2008-7316,24,"int __remove_suid(struct dentry *dentry, int kill){	struct iattr newattrs;	newattrs.ia_valid = ATTR_FORCE | kill;	return notify_change(dentry, &newattrs);}",19428
35,155,CVE-2011-1428,24,"network_connect_child (struct t_hook *hook_connect){    struct t_proxy *ptr_proxy;    struct addrinfo hints, *res, *res_local, *ptr_res;    char status_str[2], *ptr_address, *status_ok_with_address;    char ipv4_address[INET_ADDRSTRLEN + 1], ipv6_address[INET6_ADDRSTRLEN + 1];    char status_ok_without_address[1 + 5 + 1];    int rc, length;        res = NULL;    res_local = NULL;        status_str[1] = '\0';        ptr_proxy = NULL;    if (HOOK_CONNECT(hook_connect, proxy)        && HOOK_CONNECT(hook_connect, proxy)[0])    {        ptr_proxy = proxy_search (HOOK_CONNECT(hook_connect, proxy));        if (!ptr_proxy)        {                         status_str[0] = '0' + WEECHAT_HOOK_CONNECT_PROXY_ERROR;            write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);            return;        }    }        if (ptr_proxy)    {                 memset (&hints, 0, sizeof (hints));        hints.ai_family = (CONFIG_BOOLEAN(ptr_proxy->options[PROXY_OPTION_IPV6])) ?            AF_INET6 : AF_INET;        hints.ai_socktype = SOCK_STREAM;        if (getaddrinfo (CONFIG_STRING(ptr_proxy->options[PROXY_OPTION_ADDRESS]), NULL, &hints, &res) !=0)        {                         status_str[0] = '0' + WEECHAT_HOOK_CONNECT_ADDRESS_NOT_FOUND;            write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);            return;        }        if (!res)        {                         status_str[0] = '0' + WEECHAT_HOOK_CONNECT_ADDRESS_NOT_FOUND;            write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);            return;        }        if ((CONFIG_BOOLEAN(ptr_proxy->options[PROXY_OPTION_IPV6]) && (res->ai_family != AF_INET6))            || ((!CONFIG_BOOLEAN(ptr_proxy->options[PROXY_OPTION_IPV6]) && (res->ai_family != AF_INET))))        {                         status_str[0] = '0' + WEECHAT_HOOK_CONNECT_IP_ADDRESS_NOT_FOUND;            write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);            freeaddrinfo (res);            return;        }                if (CONFIG_BOOLEAN(ptr_proxy->options[PROXY_OPTION_IPV6]))            ((struct sockaddr_in6 *)(res->ai_addr))->sin6_port = htons (CONFIG_INTEGER(ptr_proxy->options[PROXY_OPTION_PORT]));        else            ((struct sockaddr_in *)(res->ai_addr))->sin_port = htons (CONFIG_INTEGER(ptr_proxy->options[PROXY_OPTION_PORT]));                         if (connect (HOOK_CONNECT(hook_connect, sock),                     res->ai_addr, res->ai_addrlen) != 0)        {                         status_str[0] = '0' + WEECHAT_HOOK_CONNECT_CONNECTION_REFUSED;            write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);            freeaddrinfo (res);            return;        }                if (!network_pass_proxy (HOOK_CONNECT(hook_connect, proxy),                                 HOOK_CONNECT(hook_connect, sock),                                 HOOK_CONNECT(hook_connect, address),                                 HOOK_CONNECT(hook_connect, port)))        {                         status_str[0] = '0' + WEECHAT_HOOK_CONNECT_PROXY_ERROR;            write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);            freeaddrinfo (res);            return;        }        status_str[0] = '0' + WEECHAT_HOOK_CONNECT_OK;    }    else    {                 if (HOOK_CONNECT(hook_connect, local_hostname)            && HOOK_CONNECT(hook_connect, local_hostname[0]))        {            memset (&hints, 0, sizeof(hints));            hints.ai_family = (HOOK_CONNECT(hook_connect, ipv6)) ? AF_INET6 : AF_INET;            hints.ai_socktype = SOCK_STREAM;            rc = getaddrinfo (HOOK_CONNECT(hook_connect, local_hostname),                              NULL, &hints, &res_local);            if ((rc != 0) || !res_local                || (HOOK_CONNECT(hook_connect, ipv6)                    && (res_local->ai_family != AF_INET6))                || ((!HOOK_CONNECT(hook_connect, ipv6)                     && (res_local->ai_family != AF_INET))))            {                                 status_str[0] = '0' + WEECHAT_HOOK_CONNECT_LOCAL_HOSTNAME_ERROR;                write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);                if (res_local)                    freeaddrinfo (res_local);                return;            }            if (bind (HOOK_CONNECT(hook_connect, sock),                      res_local->ai_addr, res_local->ai_addrlen) < 0)            {                                 status_str[0] = '0' + WEECHAT_HOOK_CONNECT_LOCAL_HOSTNAME_ERROR;                write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);                if (res_local)                    freeaddrinfo (res_local);                return;            }        }                         memset (&hints, 0, sizeof(hints));        hints.ai_family = (HOOK_CONNECT(hook_connect, ipv6)) ? AF_INET6 : AF_INET;        hints.ai_socktype = SOCK_STREAM;        rc = getaddrinfo (HOOK_CONNECT(hook_connect, address),                          NULL, &hints, &res);        if ((rc != 0) || !res)        {                         status_str[0] = '0' + WEECHAT_HOOK_CONNECT_ADDRESS_NOT_FOUND;            write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);            if (res)                freeaddrinfo (res);            if (res_local)                freeaddrinfo (res_local);            return;        }                status_str[0] = '0' + WEECHAT_HOOK_CONNECT_IP_ADDRESS_NOT_FOUND;                         for (ptr_res = res; ptr_res; ptr_res = ptr_res->ai_next)        {                         if ((HOOK_CONNECT(hook_connect, ipv6) && (ptr_res->ai_family != AF_INET6))                || ((!HOOK_CONNECT(hook_connect, ipv6) && (ptr_res->ai_family != AF_INET))))                continue;                                     if (HOOK_CONNECT(hook_connect, ipv6))                ((struct sockaddr_in6 *)(ptr_res->ai_addr))->sin6_port =                    htons (HOOK_CONNECT(hook_connect, port));            else                ((struct sockaddr_in *)(ptr_res->ai_addr))->sin_port =                    htons (HOOK_CONNECT(hook_connect, port));                        if (connect (HOOK_CONNECT(hook_connect, sock),                         ptr_res->ai_addr, ptr_res->ai_addrlen) == 0)            {                status_str[0] = '0' + WEECHAT_HOOK_CONNECT_OK;                break;            }            else                status_str[0] = '0' + WEECHAT_HOOK_CONNECT_CONNECTION_REFUSED;        }    }        if (status_str[0] == '0' + WEECHAT_HOOK_CONNECT_OK)    {        status_ok_with_address = NULL;        ptr_address = NULL;        if (HOOK_CONNECT(hook_connect, ipv6))        {            if (inet_ntop (AF_INET6,                           &((struct sockaddr_in6 *)(res->ai_addr))->sin6_addr,                           ipv6_address,                           INET6_ADDRSTRLEN))            {                ptr_address = ipv6_address;            }        }        else        {            if (inet_ntop (AF_INET,                           &((struct sockaddr_in *)(res->ai_addr))->sin_addr,                           ipv4_address,                           INET_ADDRSTRLEN))            {                ptr_address = ipv4_address;            }        }        if (ptr_address)        {            length = strlen (status_str) + 5 + strlen (ptr_address) + 1;            status_ok_with_address = malloc (length);            if (status_ok_with_address)            {                snprintf (status_ok_with_address, length, ""%s%05d%s"",                          status_str, (int)strlen (ptr_address), ptr_address);            }        }                if (status_ok_with_address)        {            write (HOOK_CONNECT(hook_connect, child_write),                   status_ok_with_address, strlen (status_ok_with_address));            free (status_ok_with_address);        }        else        {            snprintf (status_ok_without_address, sizeof (status_ok_without_address),                      ""%s%05d"", status_str, 0);            write (HOOK_CONNECT(hook_connect, child_write),                   status_ok_without_address, strlen (status_ok_without_address));        }    }    else    {        write (HOOK_CONNECT(hook_connect, child_write), status_str, 1);    }        if (res)        freeaddrinfo (res);    if (res_local)        freeaddrinfo (res_local);}",649
123,2725,CVE-2016-3760,24,"void bdt_dut_mode_configure(char *p){ int mode = -1;    bdt_log(""BT DUT MODE CONFIGURE""); if (!bt_enabled) {        bdt_log(""Bluetooth must be enabled for test_mode to work.""); return; }    mode = get_signed_int(&p, mode); if ((mode != 0) && (mode != 1)) {        bdt_log(""Please specify mode: 1 to enter, 0 to exit""); return; }    status = sBtInterface->dut_mode_configure(mode);    check_return_status(status);}",30536
0,2251,CVE-2015-5195,24,"normal_dtoa(	double d	){	char *	buf;	char *	pch_e;	char *	pch_nz;	LIB_GETBUF(buf);	snprintf(buf, LIB_BUFLENGTH, ""%g"", d);	 	pch_e = strchr(buf, 'e');	if (NULL == pch_e) {		pch_e = strchr(buf, 'E');		if (NULL == pch_e)			return buf;		*pch_e = 'e';	}	pch_e++;	if ('-' == *pch_e)		pch_e++;	pch_nz = pch_e;	while ('0' == *pch_nz)		pch_nz++;	if (pch_nz == pch_e)		return buf;	strncpy(pch_e, pch_nz, LIB_BUFLENGTH - (pch_e - buf));	return buf;}",22917
359,1576,CVE-2013-7271,24,"static int pfkey_send_acquire(struct xfrm_state *x, struct xfrm_tmpl *t, struct xfrm_policy *xp){	struct sk_buff *skb;	struct sadb_msg *hdr;	struct sadb_address *addr;	struct sadb_x_policy *pol;	int sockaddr_size;	int size;	struct sadb_x_sec_ctx *sec_ctx;	struct xfrm_sec_ctx *xfrm_ctx;	int ctx_size = 0;	sockaddr_size = pfkey_sockaddr_size(x->props.family);	if (!sockaddr_size)		return -EINVAL;	size = sizeof(struct sadb_msg) +		(sizeof(struct sadb_address) * 2) +		(sockaddr_size * 2) +		sizeof(struct sadb_x_policy);	if (x->id.proto == IPPROTO_AH)		size += count_ah_combs(t);	else if (x->id.proto == IPPROTO_ESP)		size += count_esp_combs(t);	if ((xfrm_ctx = x->security)) {		ctx_size = PFKEY_ALIGN8(xfrm_ctx->ctx_len);		size +=  sizeof(struct sadb_x_sec_ctx) + ctx_size;	}	skb =  alloc_skb(size + 16, GFP_ATOMIC);	if (skb == NULL)		return -ENOMEM;	hdr = (struct sadb_msg *) skb_put(skb, sizeof(struct sadb_msg));	hdr->sadb_msg_version = PF_KEY_V2;	hdr->sadb_msg_type = SADB_ACQUIRE;	hdr->sadb_msg_satype = pfkey_proto2satype(x->id.proto);	hdr->sadb_msg_len = size / sizeof(int);	hdr->sadb_msg_errno = 0;	hdr->sadb_msg_reserved = 0;	hdr->sadb_msg_seq = x->km.seq = get_acqseq();	hdr->sadb_msg_pid = 0;	 	addr = (struct sadb_address*) skb_put(skb,					      sizeof(struct sadb_address)+sockaddr_size);	addr->sadb_address_len =		(sizeof(struct sadb_address)+sockaddr_size)/			sizeof(int);	addr->sadb_address_exttype = SADB_EXT_ADDRESS_SRC;	addr->sadb_address_proto = 0;	addr->sadb_address_reserved = 0;	addr->sadb_address_prefixlen =		pfkey_sockaddr_fill(&x->props.saddr, 0,				    (struct sockaddr *) (addr + 1),				    x->props.family);	if (!addr->sadb_address_prefixlen)		BUG();	 	addr = (struct sadb_address*) skb_put(skb,					      sizeof(struct sadb_address)+sockaddr_size);	addr->sadb_address_len =		(sizeof(struct sadb_address)+sockaddr_size)/			sizeof(int);	addr->sadb_address_exttype = SADB_EXT_ADDRESS_DST;	addr->sadb_address_proto = 0;	addr->sadb_address_reserved = 0;	addr->sadb_address_prefixlen =		pfkey_sockaddr_fill(&x->id.daddr, 0,				    (struct sockaddr *) (addr + 1),				    x->props.family);	if (!addr->sadb_address_prefixlen)		BUG();	pol = (struct sadb_x_policy *)  skb_put(skb, sizeof(struct sadb_x_policy));	pol->sadb_x_policy_len = sizeof(struct sadb_x_policy)/sizeof(int);	pol->sadb_x_policy_exttype = SADB_X_EXT_POLICY;	pol->sadb_x_policy_type = IPSEC_POLICY_IPSEC;	pol->sadb_x_policy_dir = XFRM_POLICY_OUT + 1;	pol->sadb_x_policy_reserved = 0;	pol->sadb_x_policy_id = xp->index;	pol->sadb_x_policy_priority = xp->priority;	 	if (x->id.proto == IPPROTO_AH)		dump_ah_combs(skb, t);	else if (x->id.proto == IPPROTO_ESP)		dump_esp_combs(skb, t);	 	if (xfrm_ctx) {		sec_ctx = (struct sadb_x_sec_ctx *) skb_put(skb,				sizeof(struct sadb_x_sec_ctx) + ctx_size);		sec_ctx->sadb_x_sec_len =		  (sizeof(struct sadb_x_sec_ctx) + ctx_size) / sizeof(int);		sec_ctx->sadb_x_sec_exttype = SADB_X_EXT_SEC_CTX;		sec_ctx->sadb_x_ctx_doi = xfrm_ctx->ctx_doi;		sec_ctx->sadb_x_ctx_alg = xfrm_ctx->ctx_alg;		sec_ctx->sadb_x_ctx_len = xfrm_ctx->ctx_len;		memcpy(sec_ctx + 1, xfrm_ctx->ctx_str,		       xfrm_ctx->ctx_len);	}	return pfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_REGISTERED, NULL, xs_net(x));}",12464
175,2057,CVE-2017-17862,24,"static int reg_is_init_pkt_pointer(const struct bpf_reg_state *reg,				    enum bpf_reg_type which){	 	return reg->type == which &&	       reg->id == 0 &&	       reg->off == 0 &&	       tnum_equals_const(reg->var_off, 0);}",19555
259,633,CVE-2011-1080,24,"static int size_entry_mwt(struct ebt_entry *entry, const unsigned char *base,			  unsigned int *total,			  struct ebt_entries_buf_state *state){	unsigned int i, j, startoff, new_offset = 0;	 	unsigned int offsets[4];	unsigned int *offsets_update = NULL;	int ret;	char *buf_start;	if (*total < sizeof(struct ebt_entries))		return -EINVAL;	if (!entry->bitmask) {		*total -= sizeof(struct ebt_entries);		return ebt_buf_add(state, entry, sizeof(struct ebt_entries));	}	if (*total < sizeof(*entry) || entry->next_offset < sizeof(*entry))		return -EINVAL;	startoff = state->buf_user_offset;	 	ret = ebt_buf_add(state, entry,			offsetof(struct ebt_entry, watchers_offset));	if (ret < 0)		return ret;	offsets[0] = sizeof(struct ebt_entry);  	memcpy(&offsets[1], &entry->watchers_offset,			sizeof(offsets) - sizeof(offsets[0]));	if (state->buf_kern_start) {		buf_start = state->buf_kern_start + state->buf_kern_offset;		offsets_update = (unsigned int *) buf_start;	}	ret = ebt_buf_add(state, &offsets[1],			sizeof(offsets) - sizeof(offsets[0]));	if (ret < 0)		return ret;	buf_start = (char *) entry;	 	for (i = 0, j = 1 ; j < 4 ; j++, i++) {		struct compat_ebt_entry_mwt *match32;		unsigned int size;		char *buf = buf_start;		buf = buf_start + offsets[i];		if (offsets[i] > offsets[j])			return -EINVAL;		match32 = (struct compat_ebt_entry_mwt *) buf;		size = offsets[j] - offsets[i];		ret = ebt_size_mwt(match32, size, i, state, base);		if (ret < 0)			return ret;		new_offset += ret;		if (offsets_update && new_offset) {			pr_debug(""change offset %d to %d\n"",				offsets_update[i], offsets[j] + new_offset);			offsets_update[i] = offsets[j] + new_offset;		}	}	startoff = state->buf_user_offset - startoff;	BUG_ON(*total < startoff);	*total -= startoff;	return 0;}",6936
54,1609,CVE-2013-7271,24,static void netlink_mm_open(struct vm_area_struct *vma){	struct file *file = vma->vm_file;	struct socket *sock = file->private_data;	struct sock *sk = sock->sk;	if (sk)		atomic_inc(&nlk_sk(sk)->mapped);},12497
342,516,CVE-2012-2136,24,"int sock_no_shutdown(struct socket *sock, int how){	return -EOPNOTSUPP;}",3475
182,1022,CVE-2014-3645,24,"static void __kvm_unsync_page(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp){	trace_kvm_mmu_unsync_page(sp);	++vcpu->kvm->stat.mmu_unsync;	sp->unsync = 1;	kvm_mmu_mark_parents_unsync(sp);}",11156
678,204,CVE-2011-1428,24,"irc_server_set_index_current_address (struct t_irc_server *server, int index){    if (server->current_address)    {        free (server->current_address);        server->current_address = NULL;    }    server->current_port = 0;        if (index < server->addresses_count)    {        server->index_current_address = index;        if (server->current_address)            free (server->current_address);        server->current_address = strdup (server->addresses_array[index]);        server->current_port = server->ports_array[index];    }}",698
206,95,CVE-2015-5296,24,"void smb2cli_conn_set_cc_chunk_len(struct smbXcli_conn *conn,				    int chunk_len){	conn->smb2.cc_chunk_len = chunk_len;}",503
211,1482,CVE-2013-7271,24,misdn_sock_cleanup(void){	sock_unregister(PF_ISDN);},12370
287,2358,CVE-2018-11232,24,"int etm_perf_symlink(struct coresight_device *csdev, int link){	char entry[sizeof(""cpu9999999"")];	int ret = 0, cpu = source_ops(csdev)->cpu_id(csdev);	struct device *pmu_dev = etm_pmu.dev;	struct device *cs_dev = &csdev->dev;	sprintf(entry, ""cpu%d"", cpu);	if (!etm_perf_up)		return -EPROBE_DEFER;	if (link) {		ret = sysfs_create_link(&pmu_dev->kobj, &cs_dev->kobj, entry);		if (ret)			return ret;		per_cpu(csdev_src, cpu) = csdev;	} else {		sysfs_remove_link(&pmu_dev->kobj, entry);		per_cpu(csdev_src, cpu) = NULL;	}	return 0;}",25213
344,1099,CVE-2014-3645,24,"static int paging64_init_context(struct kvm_vcpu *vcpu,				 struct kvm_mmu *context){	return paging64_init_context_common(vcpu, context, PT64_ROOT_LEVEL);}",11233
573,2382,CVE-2017-18200,24,"int rewrite_data_page(struct f2fs_io_info *fio){	int err;	fio->new_blkaddr = fio->old_blkaddr;	stat_inc_inplace_blocks(fio->sbi);	err = f2fs_submit_page_bio(fio);	f2fs_update_iostat(fio->sbi, fio->io_type, F2FS_BLKSIZE);	return err;}",26042
306,1961,CVE-2015-3288,24,"void sync_mm_rss(struct mm_struct *mm){	int i;	for (i = 0; i < NR_MM_COUNTERS; i++) {		if (current->rss_stat.count[i]) {			add_mm_counter(mm, i, current->rss_stat.count[i]);			current->rss_stat.count[i] = 0;		}	}	current->rss_stat.events = 0;}",19122
281,1813,CVE-2015-7509,24,"static void ext4_dirent_csum_set(struct inode *inode,				 struct ext4_dir_entry *dirent){	struct ext4_dir_entry_tail *t;	if (!EXT4_HAS_RO_COMPAT_FEATURE(inode->i_sb,					EXT4_FEATURE_RO_COMPAT_METADATA_CSUM))		return;	t = get_dirent_tail(inode, dirent);	if (!t) {		EXT4_ERROR_INODE(inode, ""metadata_csum set but no space in dir ""				 ""leaf for checksum.  Please run e2fsck -D."");		return;	}	t->det_checksum = ext4_dirent_csum(inode, dirent,					   (void *)t - (void *)dirent);}",13094
669,676,CVE-2013-6368,24,"int kvm_set_cr4(struct kvm_vcpu *vcpu, unsigned long cr4){	unsigned long old_cr4 = kvm_read_cr4(vcpu);	unsigned long pdptr_bits = X86_CR4_PGE | X86_CR4_PSE |				   X86_CR4_PAE | X86_CR4_SMEP;	if (cr4 & CR4_RESERVED_BITS)		return 1;	if (!guest_cpuid_has_xsave(vcpu) && (cr4 & X86_CR4_OSXSAVE))		return 1;	if (!guest_cpuid_has_smep(vcpu) && (cr4 & X86_CR4_SMEP))		return 1;	if (!guest_cpuid_has_fsgsbase(vcpu) && (cr4 & X86_CR4_FSGSBASE))		return 1;	if (is_long_mode(vcpu)) {		if (!(cr4 & X86_CR4_PAE))			return 1;	} else if (is_paging(vcpu) && (cr4 & X86_CR4_PAE)		   && ((cr4 ^ old_cr4) & pdptr_bits)		   && !load_pdptrs(vcpu, vcpu->arch.walk_mmu,				   kvm_read_cr3(vcpu)))		return 1;	if ((cr4 & X86_CR4_PCIDE) && !(old_cr4 & X86_CR4_PCIDE)) {		if (!guest_cpuid_has_pcid(vcpu))			return 1;		 		if ((kvm_read_cr3(vcpu) & X86_CR3_PCID_MASK) || !is_long_mode(vcpu))			return 1;	}	if (kvm_x86_ops->set_cr4(vcpu, cr4))		return 1;	if (((cr4 ^ old_cr4) & pdptr_bits) ||	    (!(cr4 & X86_CR4_PCIDE) && (old_cr4 & X86_CR4_PCIDE)))		kvm_mmu_reset_context(vcpu);	if ((cr4 ^ old_cr4) & X86_CR4_OSXSAVE)		kvm_update_cpuid(vcpu);	return 0;}",7443
72,859,CVE-2013-1828,24,static inline int sctp_wspace(struct sctp_association *asoc){	int amt;	if (asoc->ep->sndbuf_policy)		amt = asoc->sndbuf_used;	else		amt = sk_wmem_alloc_get(asoc->base.sk);	if (amt >= asoc->base.sk->sk_sndbuf) {		if (asoc->base.sk->sk_userlocks & SOCK_SNDBUF_LOCK)			amt = 0;		else {			amt = sk_stream_wspace(asoc->base.sk);			if (amt < 0)				amt = 0;		}	} else {		amt = asoc->base.sk->sk_sndbuf - amt;	}	return amt;},9415
124,1209,CVE-2014-2739,24,"static int cma_disable_callback(struct rdma_id_private *id_priv,				enum rdma_cm_state state){	mutex_lock(&id_priv->handler_mutex);	if (id_priv->state != state) {		mutex_unlock(&id_priv->handler_mutex);		return -EINVAL;	}	return 0;}",11684
197,600,CVE-2011-3363,24,"srcip_matches(struct sockaddr *srcaddr, struct sockaddr *rhs){	switch (srcaddr->sa_family) {	case AF_UNSPEC:		return (rhs->sa_family == AF_UNSPEC);	case AF_INET: {		struct sockaddr_in *saddr4 = (struct sockaddr_in *)srcaddr;		struct sockaddr_in *vaddr4 = (struct sockaddr_in *)rhs;		return (saddr4->sin_addr.s_addr == vaddr4->sin_addr.s_addr);	}	case AF_INET6: {		struct sockaddr_in6 *saddr6 = (struct sockaddr_in6 *)srcaddr;		struct sockaddr_in6 *vaddr6 = (struct sockaddr_in6 *)&rhs;		return ipv6_addr_equal(&saddr6->sin6_addr, &vaddr6->sin6_addr);	}	default:		WARN_ON(1);		return false;  	}}",5547
256,1767,CVE-2015-8215,24,"void addrconf_leave_solict(struct inet6_dev *idev, const struct in6_addr *addr){	struct in6_addr maddr;	if (idev->dev->flags&(IFF_LOOPBACK|IFF_NOARP))		return;	addrconf_addr_solict_mult(addr, &maddr);	__ipv6_dev_mc_dec(idev, &maddr);}",12977
417,2759,CVE-2011-4913,24,"static int rose_parse_ccitt(unsigned char *p, struct rose_facilities_struct *facilities, int len){	unsigned char l, n = 0;	char callsign[11];	do {		switch (*p & 0xC0) {		case 0x00:			p   += 2;			n   += 2;			len -= 2;			break;		case 0x40:			p   += 3;			n   += 3;			len -= 3;			break;		case 0x80:			p   += 4;			n   += 4;			len -= 4;			break;  		case 0xC0: 			l = p[1]; 			if (*p == FAC_CCITT_DEST_NSAP) { 				memcpy(&facilities->source_addr, p + 7, ROSE_ADDR_LEN); 				memcpy(callsign, p + 12,   l - 10);				callsign[l - 10] = '\0';				asc2ax(&facilities->source_call, callsign);			}			if (*p == FAC_CCITT_SRC_NSAP) {				memcpy(&facilities->dest_addr, p + 7, ROSE_ADDR_LEN);				memcpy(callsign, p + 12, l - 10);				callsign[l - 10] = '\0';				asc2ax(&facilities->dest_call, callsign);			}			p   += l + 2;			n   += l + 2;			len -= l + 2;			break;		}	} while (*p != 0x00 && len > 0);	return n;}",30954
320,1804,CVE-2015-8215,24,static inline int rt_scope(int ifa_scope){	if (ifa_scope & IFA_HOST)		return RT_SCOPE_HOST;	else if (ifa_scope & IFA_LINK)		return RT_SCOPE_LINK;	else if (ifa_scope & IFA_SITE)		return RT_SCOPE_SITE;	else		return RT_SCOPE_UNIVERSE;},13014
25,977,CVE-2014-5472,24,"static char *get_symlink_chunk(char *rpnt, struct rock_ridge *rr, char *plimit){	int slen;	int rootflag;	struct SL_component *oldslp;	struct SL_component *slp;	slen = rr->len - 5;	slp = &rr->u.SL.link;	while (slen > 1) {		rootflag = 0;		switch (slp->flags & ~1) {		case 0:			if (slp->len > plimit - rpnt)				return NULL;			memcpy(rpnt, slp->text, slp->len);			rpnt += slp->len;			break;		case 2:			if (rpnt >= plimit)				return NULL;			*rpnt++ = '.';			break;		case 4:			if (2 > plimit - rpnt)				return NULL;			*rpnt++ = '.';			*rpnt++ = '.';			break;		case 8:			if (rpnt >= plimit)				return NULL;			rootflag = 1;			*rpnt++ = '/';			break;		default:			printk(""Symlink component flag not implemented (%d)\n"",			       slp->flags);		}		slen -= slp->len + 2;		oldslp = slp;		slp = (struct SL_component *)((char *)slp + slp->len + 2);		if (slen < 2) {			 			if ((!rootflag) && (rr->u.SL.flags & 1) &&			    !(oldslp->flags & 1)) {				if (rpnt >= plimit)					return NULL;				*rpnt++ = '/';			}			break;		}		 		if (!rootflag && !(oldslp->flags & 1)) {			if (rpnt >= plimit)				return NULL;			*rpnt++ = '/';		}	} 	return rpnt; }",10634
657,1662,CVE-2013-7271,24,"static int packet_release(struct socket *sock){	struct sock *sk = sock->sk;	struct packet_sock *po;	struct net *net;	union tpacket_req_u req_u;	if (!sk)		return 0;	net = sock_net(sk);	po = pkt_sk(sk);	mutex_lock(&net->packet.sklist_lock);	sk_del_node_init_rcu(sk);	mutex_unlock(&net->packet.sklist_lock);	preempt_disable();	sock_prot_inuse_add(net, sk->sk_prot, -1);	preempt_enable();	spin_lock(&po->bind_lock);	unregister_prot_hook(sk, false);	if (po->prot_hook.dev) {		dev_put(po->prot_hook.dev);		po->prot_hook.dev = NULL;	}	spin_unlock(&po->bind_lock);	packet_flush_mclist(sk);	if (po->rx_ring.pg_vec) {		memset(&req_u, 0, sizeof(req_u));		packet_set_ring(sk, &req_u, 1, 0);	}	if (po->tx_ring.pg_vec) {		memset(&req_u, 0, sizeof(req_u));		packet_set_ring(sk, &req_u, 1, 1);	}	fanout_release(sk);	synchronize_net();	 	sock_orphan(sk);	sock->sk = NULL;	 	skb_queue_purge(&sk->sk_receive_queue);	sk_refcnt_debug_release(sk);	sock_put(sk);	return 0;}",12550
20,2019,CVE-2017-17862,24,static void __mark_reg_unknown(struct bpf_reg_state *reg){	reg->type = SCALAR_VALUE;	reg->id = 0;	reg->off = 0;	reg->var_off = tnum_unknown;	__mark_reg_unbounded(reg);},19517
590,2295,CVE-2018-18021,24,"int kvm_arch_vcpu_ioctl_get_regs(struct kvm_vcpu *vcpu, struct kvm_regs *regs){	return -EINVAL;}",23579
59,576,CVE-2011-3363,24,"cifs_get_tcp_session(struct smb_vol *volume_info){	struct TCP_Server_Info *tcp_ses = NULL;	struct sockaddr_storage addr;	struct sockaddr_in *sin_server = (struct sockaddr_in *) &addr;	struct sockaddr_in6 *sin_server6 = (struct sockaddr_in6 *) &addr;	int rc;	memset(&addr, 0, sizeof(struct sockaddr_storage));	cFYI(1, ""UNC: %s ip: %s"", volume_info->UNC, volume_info->UNCip);	if (volume_info->UNCip && volume_info->UNC) {		rc = cifs_fill_sockaddr((struct sockaddr *)&addr,					volume_info->UNCip,					strlen(volume_info->UNCip),					volume_info->port);		if (!rc) {			 			rc = -EINVAL;			goto out_err;		}	} else if (volume_info->UNCip) {		 		cERROR(1, ""Connecting to DFS root not implemented yet"");		rc = -EINVAL;		goto out_err;	} else   {		cERROR(1, ""CIFS mount error: No UNC path (e.g. -o ""			""unc=//192.168.1.100/public) specified"");		rc = -EINVAL;		goto out_err;	}	 	tcp_ses = cifs_find_tcp_session((struct sockaddr *)&addr, volume_info);	if (tcp_ses)		return tcp_ses;	tcp_ses = kzalloc(sizeof(struct TCP_Server_Info), GFP_KERNEL);	if (!tcp_ses) {		rc = -ENOMEM;		goto out_err;	}	rc = cifs_crypto_shash_allocate(tcp_ses);	if (rc) {		cERROR(1, ""could not setup hash structures rc %d"", rc);		goto out_err;	}	cifs_set_net_ns(tcp_ses, get_net(current->nsproxy->net_ns));	tcp_ses->hostname = extract_hostname(volume_info->UNC);	if (IS_ERR(tcp_ses->hostname)) {		rc = PTR_ERR(tcp_ses->hostname);		goto out_err_crypto_release;	}	tcp_ses->noblocksnd = volume_info->noblocksnd;	tcp_ses->noautotune = volume_info->noautotune;	tcp_ses->tcp_nodelay = volume_info->sockopt_tcp_nodelay;	atomic_set(&tcp_ses->inFlight, 0);	init_waitqueue_head(&tcp_ses->response_q);	init_waitqueue_head(&tcp_ses->request_q);	INIT_LIST_HEAD(&tcp_ses->pending_mid_q);	mutex_init(&tcp_ses->srv_mutex);	memcpy(tcp_ses->workstation_RFC1001_name,		volume_info->source_rfc1001_name, RFC1001_NAME_LEN_WITH_NULL);	memcpy(tcp_ses->server_RFC1001_name,		volume_info->target_rfc1001_name, RFC1001_NAME_LEN_WITH_NULL);	tcp_ses->session_estab = false;	tcp_ses->sequence_number = 0;	tcp_ses->lstrp = jiffies;	INIT_LIST_HEAD(&tcp_ses->tcp_ses_list);	INIT_LIST_HEAD(&tcp_ses->smb_ses_list);	INIT_DELAYED_WORK(&tcp_ses->echo, cifs_echo_request);	 	tcp_ses->tcpStatus = CifsNew;	memcpy(&tcp_ses->srcaddr, &volume_info->srcaddr,	       sizeof(tcp_ses->srcaddr));	++tcp_ses->srv_count;	if (addr.ss_family == AF_INET6) {		cFYI(1, ""attempting ipv6 connect"");		 		 		memcpy(&tcp_ses->dstaddr, sin_server6,		       sizeof(struct sockaddr_in6));	} else		memcpy(&tcp_ses->dstaddr, sin_server,		       sizeof(struct sockaddr_in));	rc = ip_connect(tcp_ses);	if (rc < 0) {		cERROR(1, ""Error connecting to socket. Aborting operation"");		goto out_err_crypto_release;	}	 	__module_get(THIS_MODULE);	tcp_ses->tsk = kthread_run((void *)(void *)cifs_demultiplex_thread,				  tcp_ses, ""cifsd"");	if (IS_ERR(tcp_ses->tsk)) {		rc = PTR_ERR(tcp_ses->tsk);		cERROR(1, ""error %d create cifsd thread"", rc);		module_put(THIS_MODULE);		goto out_err_crypto_release;	}	 	spin_lock(&cifs_tcp_ses_lock);	list_add(&tcp_ses->tcp_ses_list, &cifs_tcp_ses_list);	spin_unlock(&cifs_tcp_ses_lock);	cifs_fscache_get_client_cookie(tcp_ses);	 	queue_delayed_work(system_nrt_wq, &tcp_ses->echo, SMB_ECHO_INTERVAL);	return tcp_ses;out_err_crypto_release:	cifs_crypto_shash_release(tcp_ses);	put_net(cifs_net_ns(tcp_ses));out_err:	if (tcp_ses) {		if (!IS_ERR(tcp_ses->hostname))			kfree(tcp_ses->hostname);		if (tcp_ses->ssocket)			sock_release(tcp_ses->ssocket);		kfree(tcp_ses);	}	return ERR_PTR(rc);}",5523
487,1916,CVE-2016-4809,24,"archive_read_support_format_cpio(struct archive *_a){	struct archive_read *a = (struct archive_read *)_a;	struct cpio *cpio;	int r;	archive_check_magic(_a, ARCHIVE_READ_MAGIC,	    ARCHIVE_STATE_NEW, ""archive_read_support_format_cpio"");	cpio = (struct cpio *)calloc(1, sizeof(*cpio));	if (cpio == NULL) {		archive_set_error(&a->archive, ENOMEM, ""Can't allocate cpio data"");		return (ARCHIVE_FATAL);	}	cpio->magic = CPIO_MAGIC;	r = __archive_read_register_format(a,	    cpio,	    ""cpio"",	    archive_read_format_cpio_bid,	    archive_read_format_cpio_options,	    archive_read_format_cpio_read_header,	    archive_read_format_cpio_read_data,	    archive_read_format_cpio_skip,	    NULL,	    archive_read_format_cpio_cleanup,	    NULL,	    NULL);	if (r != ARCHIVE_OK)		free(cpio);	return (ARCHIVE_OK);}",16642
481,2237,CVE-2016-7536,24,"static inline const unsigned char *ReadResourceShort(const unsigned char *p,  unsigned short *quantum){  *quantum=(unsigned short) (*p++ << 8);  *quantum|=(unsigned short) (*p++ << 0);  return(p);}",22799
162,619,CVE-2011-1080,24,"ebt_check_entry_size_and_hooks(const struct ebt_entry *e,   const struct ebt_table_info *newinfo,   unsigned int *n, unsigned int *cnt,   unsigned int *totalcnt, unsigned int *udc_cnt){	int i;	for (i = 0; i < NF_BR_NUMHOOKS; i++) {		if ((void *)e == (void *)newinfo->hook_entry[i])			break;	}	 	if (i != NF_BR_NUMHOOKS || !e->bitmask) {		 		if (*n != *cnt) {			BUGPRINT(""nentries does not equal the nr of entries ""				 ""in the chain\n"");			return -EINVAL;		}		if (((struct ebt_entries *)e)->policy != EBT_DROP &&		   ((struct ebt_entries *)e)->policy != EBT_ACCEPT) {			 			if (i != NF_BR_NUMHOOKS ||			   ((struct ebt_entries *)e)->policy != EBT_RETURN) {				BUGPRINT(""bad policy\n"");				return -EINVAL;			}		}		if (i == NF_BR_NUMHOOKS)  			(*udc_cnt)++;		if (((struct ebt_entries *)e)->counter_offset != *totalcnt) {			BUGPRINT(""counter_offset != totalcnt"");			return -EINVAL;		}		*n = ((struct ebt_entries *)e)->nentries;		*cnt = 0;		return 0;	}	 	if (sizeof(struct ebt_entry) > e->watchers_offset ||	   e->watchers_offset > e->target_offset ||	   e->target_offset >= e->next_offset) {		BUGPRINT(""entry offsets not in right order\n"");		return -EINVAL;	}	 	if (e->next_offset - e->target_offset < sizeof(struct ebt_entry_target)) {		BUGPRINT(""target size too small\n"");		return -EINVAL;	}	(*cnt)++;	(*totalcnt)++;	return 0;}",6922
56,814,CVE-2013-1848,24,static int ext3_blkdev_remove(struct ext3_sb_info *sbi){	struct block_device *bdev;	int ret = -ENODEV;	bdev = sbi->journal_bdev;	if (bdev) {		ret = ext3_blkdev_put(bdev);		sbi->journal_bdev = NULL;	}	return ret;},9370
81,2444,CVE-2017-18509,24,"static void ip6mr_update_thresholds(struct mr6_table *mrt, struct mfc6_cache *cache,				    unsigned char *ttls){	int vifi;	cache->mfc_un.res.minvif = MAXMIFS;	cache->mfc_un.res.maxvif = 0;	memset(cache->mfc_un.res.ttls, 255, MAXMIFS);	for (vifi = 0; vifi < mrt->maxvif; vifi++) {		if (MIF_EXISTS(mrt, vifi) &&		    ttls[vifi] && ttls[vifi] < 255) {			cache->mfc_un.res.ttls[vifi] = ttls[vifi];			if (cache->mfc_un.res.minvif > vifi)				cache->mfc_un.res.minvif = vifi;			if (cache->mfc_un.res.maxvif <= vifi)				cache->mfc_un.res.maxvif = vifi + 1;		}	}	cache->mfc_un.res.lastuse = jiffies;}",28058
523,2053,CVE-2017-17862,24,"static void propagate_liveness(const struct bpf_verifier_state *state,			       struct bpf_verifier_state *parent){	while (do_propagate_liveness(state, parent)) {		 		state = parent;		parent = state->parent;	}}",19551
454,504,CVE-2012-2136,24,"void sock_enable_timestamp(struct sock *sk, int flag){	if (!sock_flag(sk, flag)) {		unsigned long previous_flags = sk->sk_flags;		sock_set_flag(sk, flag);		 		if (!(previous_flags & SK_FLAGS_TIMESTAMP))			net_enable_timestamp();	}}",3463
576,1298,CVE-2014-2038,24,"static int nfs_commit_unstable_pages(struct inode *inode, struct writeback_control *wbc){	struct nfs_inode *nfsi = NFS_I(inode);	int flags = FLUSH_SYNC;	int ret = 0;	 	if (!nfsi->commit_info.ncommit)		return ret;	if (wbc->sync_mode == WB_SYNC_NONE) {		 		if (nfsi->commit_info.ncommit <= (nfsi->npages >> 1))			goto out_mark_dirty;		 		flags = 0;	}	ret = nfs_commit_inode(inode, flags);	if (ret >= 0) {		if (wbc->sync_mode == WB_SYNC_NONE) {			if (ret < wbc->nr_to_write)				wbc->nr_to_write -= ret;			else				wbc->nr_to_write = 0;		}		return 0;	}out_mark_dirty:	__mark_inode_dirty(inode, I_DIRTY_DATASYNC);	return ret;}",11845
263,34,CVE-2017-16227,24,"aspath_prepend (struct aspath *as1, struct aspath *as2){  struct assegment *seg1;  struct assegment *seg2;  if (! as1 || ! as2)    return NULL;    seg1 = as1->segments;  seg2 = as2->segments;       if (seg2 == NULL)    {      as2->segments = assegment_dup_all (as1->segments);      aspath_str_update (as2);      return as2;    }       if (seg1 == NULL)    return as2;       while (seg1 && seg1->next)    seg1 = seg1->next;     if (seg1->type == AS_SEQUENCE && seg2->type == AS_CONFED_SEQUENCE)    as2 = aspath_delete_confed_seq (as2);       seg2 = as2->segments;       if (seg2 == NULL)    {      as2->segments = assegment_dup_all (as1->segments);      aspath_str_update (as2);      return as2;    }       if (seg1->type != seg2->type)    return aspath_merge (as1, as2);  if (seg1->type == AS_SEQUENCE)    {                          seg1 = as2->segments = assegment_dup_all (as1->segments);                   while (seg1 && seg1->next)        seg1 = seg1->next;                   seg1 = assegment_append_asns (seg1, seg2->as, seg2->length);                   seg1->next = seg2->next;                   assegment_free (seg2);                   aspath_str_update (as2);      return as2;    }  else    {             return aspath_merge (as1, as2);    }        }",356
176,1114,CVE-2014-3645,24,"static void ept_save_pdptrs(struct kvm_vcpu *vcpu){	if (is_paging(vcpu) && is_pae(vcpu) && !is_long_mode(vcpu)) {		vcpu->arch.mmu.pdptrs[0] = vmcs_read64(GUEST_PDPTR0);		vcpu->arch.mmu.pdptrs[1] = vmcs_read64(GUEST_PDPTR1);		vcpu->arch.mmu.pdptrs[2] = vmcs_read64(GUEST_PDPTR2);		vcpu->arch.mmu.pdptrs[3] = vmcs_read64(GUEST_PDPTR3);	}	__set_bit(VCPU_EXREG_PDPTR,		  (unsigned long *)&vcpu->arch.regs_avail);	__set_bit(VCPU_EXREG_PDPTR,		  (unsigned long *)&vcpu->arch.regs_dirty);}",11248
138,1042,CVE-2014-3645,24,void kvm_disable_tdp(void){	tdp_enabled = false;},11176
588,1377,CVE-2014-0203,24,static int __follow_mount(struct path *path){	int res = 0;	while (d_mountpoint(path->dentry)) {		struct vfsmount *mounted = lookup_mnt(path);		if (!mounted)			break;		dput(path->dentry);		if (res)			mntput(path->mnt);		path->mnt = mounted;		path->dentry = dget(mounted->mnt_root);		res = 1;	}	return res;},12087
635,943,CVE-2011-3619,24,"static int common_mmap(int op, struct file *file, unsigned long prot,		       unsigned long flags){	struct dentry *dentry;	int mask = 0;	if (!file || !file->f_security)		return 0;	if (prot & PROT_READ)		mask |= MAY_READ;	 	if ((prot & PROT_WRITE) && !(flags & MAP_PRIVATE))		mask |= MAY_WRITE;	if (prot & PROT_EXEC)		mask |= AA_EXEC_MMAP;	dentry = file->f_path.dentry;	return common_file_perm(op, file, mask);}",10114
637,1407,CVE-2014-0203,24,"static int open_will_truncate(int flag, struct inode *inode){	 	if (special_file(inode->i_mode))		return 0;	return (flag & O_TRUNC);}",12117
291,524,CVE-2012-2136,24,void sock_update_netprioidx(struct sock *sk){	if (in_interrupt())		return;	sk->sk_cgrp_prioidx = task_netprioidx(current);},3483
508,644,CVE-2013-6368,24,"static void init_emulate_ctxt(struct kvm_vcpu *vcpu){	struct x86_emulate_ctxt *ctxt = &vcpu->arch.emulate_ctxt;	int cs_db, cs_l;	kvm_x86_ops->get_cs_db_l_bits(vcpu, &cs_db, &cs_l);	ctxt->eflags = kvm_get_rflags(vcpu);	ctxt->eip = kvm_rip_read(vcpu);	ctxt->mode = (!is_protmode(vcpu))		? X86EMUL_MODE_REAL :		     (ctxt->eflags & X86_EFLAGS_VM)	? X86EMUL_MODE_VM86 :		     cs_l				? X86EMUL_MODE_PROT64 :		     cs_db				? X86EMUL_MODE_PROT32 :							  X86EMUL_MODE_PROT16;	ctxt->guest_mode = is_guest_mode(vcpu);	init_decode_cache(ctxt);	vcpu->arch.emulate_regs_need_sync_from_vcpu = false;}",7411
95,745,CVE-2013-4254,24,"perf_callchain_kernel(struct perf_callchain_entry *entry, struct pt_regs *regs){	struct stackframe fr;	if (perf_guest_cbs && perf_guest_cbs->is_in_guest()) {		 		return;	}	fr.fp = regs->ARM_fp;	fr.sp = regs->ARM_sp;	fr.lr = regs->ARM_lr;	fr.pc = regs->ARM_pc;	walk_stackframe(&fr, callchain_trace, entry);}",7896
434,1763,CVE-2015-8215,24,"static void addrconf_gre_config(struct net_device *dev){	struct inet6_dev *idev;	ASSERT_RTNL();	idev = ipv6_find_idev(dev);	if (idev == NULL) {		pr_debug(""%s: add_dev failed\n"", __func__);		return;	}	addrconf_addr_gen(idev, true);}",12973
164,795,CVE-2013-2140,24,"static void xen_blk_drain_io(struct xen_blkif *blkif){	atomic_set(&blkif->drain, 1);	do {		 		if (atomic_read(&blkif->refcnt) <= 2)			break;		wait_for_completion_interruptible_timeout(				&blkif->drain_complete, HZ);		if (!atomic_read(&blkif->drain))			break;	} while (!kthread_should_stop());	atomic_set(&blkif->drain, 0);}",8872
220,2248,CVE-2015-5195,24,get_correct_host_mode(	int token	){	switch (token) {	case T_Server:	case T_Pool:	case T_Manycastclient:		return MODE_CLIENT;	case T_Peer:		return MODE_ACTIVE;	case T_Broadcast:		return MODE_BROADCAST;	default:		return 0;	}},22914
127,2485,CVE-2012-0879,24,"void release_task(struct task_struct * p){	struct task_struct *leader;	int zap_leader;repeat:	tracehook_prepare_release_task(p);	 	atomic_dec(&__task_cred(p)->user->processes);	proc_flush_task(p);	write_lock_irq(&tasklist_lock);	tracehook_finish_release_task(p);	__exit_signal(p);	 	zap_leader = 0;	leader = p->group_leader;	if (leader != p && thread_group_empty(leader) && leader->exit_state == EXIT_ZOMBIE) {		BUG_ON(task_detached(leader));		do_notify_parent(leader, leader->exit_signal);		 		zap_leader = task_detached(leader);		 		if (zap_leader)			leader->exit_state = EXIT_DEAD;	}	write_unlock_irq(&tasklist_lock);	release_thread(p);	call_rcu(&p->rcu, delayed_put_task_struct);	p = leader;	if (unlikely(zap_leader))		goto repeat;}",28242
279,1409,CVE-2014-0203,24,"static int path_init(int dfd, const char *name, unsigned int flags, struct nameidata *nd){	int retval = 0;	int fput_needed;	struct file *file;	nd->last_type = LAST_ROOT;  	nd->flags = flags;	nd->depth = 0;	nd->root.mnt = NULL;	if (*name=='/') {		set_root(nd);		nd->path = nd->root;		path_get(&nd->root);	} else if (dfd == AT_FDCWD) {		struct fs_struct *fs = current->fs;		read_lock(&fs->lock);		nd->path = fs->pwd;		path_get(&fs->pwd);		read_unlock(&fs->lock);	} else {		struct dentry *dentry;		file = fget_light(dfd, &fput_needed);		retval = -EBADF;		if (!file)			goto out_fail;		dentry = file->f_path.dentry;		retval = -ENOTDIR;		if (!S_ISDIR(dentry->d_inode->i_mode))			goto fput_fail;		retval = file_permission(file, MAY_EXEC);		if (retval)			goto fput_fail;		nd->path = file->f_path;		path_get(&file->f_path);		fput_light(file, fput_needed);	}	return 0;fput_fail:	fput_light(file, fput_needed);out_fail:	return retval;}",12119
406,798,CVE-2013-2140,24,"static void xen_blkbk_unmap(struct xen_blkif *blkif,                            struct grant_page *pages[],                            int num){	struct gnttab_unmap_grant_ref unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST];	struct page *unmap_pages[BLKIF_MAX_SEGMENTS_PER_REQUEST];	unsigned int i, invcount = 0;	int ret;	for (i = 0; i < num; i++) {		if (pages[i]->persistent_gnt != NULL) {			put_persistent_gnt(blkif, pages[i]->persistent_gnt);			continue;		}		if (pages[i]->handle == BLKBACK_INVALID_HANDLE)			continue;		unmap_pages[invcount] = pages[i]->page;		gnttab_set_unmap_op(&unmap[invcount], vaddr(pages[i]->page),				    GNTMAP_host_map, pages[i]->handle);		pages[i]->handle = BLKBACK_INVALID_HANDLE;		if (++invcount == BLKIF_MAX_SEGMENTS_PER_REQUEST) {			ret = gnttab_unmap_refs(unmap, NULL, unmap_pages,			                        invcount);			BUG_ON(ret);			put_free_pages(blkif, unmap_pages, invcount);			invcount = 0;		}	}	if (invcount) {		ret = gnttab_unmap_refs(unmap, NULL, unmap_pages, invcount);		BUG_ON(ret);		put_free_pages(blkif, unmap_pages, invcount);	}}",8875
550,338,CVE-2016-4579,24,release_ocsp_extensions (struct ocsp_extension_s *ex){  while (ex)    {      struct ocsp_extension_s *tmp = ex->next;      xfree (ex);      ex = tmp;    }},1875
250,2001,CVE-2017-1000252,24,"int kvm_irqfd_init(void){	irqfd_cleanup_wq = alloc_workqueue(""kvm-irqfd-cleanup"", 0, 0);	if (!irqfd_cleanup_wq)		return -ENOMEM;	return 0;}",19462
6,1851,CVE-2016-9191,24,"static int proc_sys_compare(const struct dentry *dentry,		unsigned int len, const char *str, const struct qstr *name){	struct ctl_table_header *head;	struct inode *inode;	 	 	inode = d_inode_rcu(dentry);	if (!inode)		return 1;	if (name->len != len)		return 1;	if (memcmp(name->name, str, len))		return 1;	head = rcu_dereference(PROC_I(inode)->sysctl);	return !head || !sysctl_is_seen(head);}",15212
482,1921,CVE-2016-4425,24,static int decode_unicode_escape(const char *str){    int i;    int value = 0;    assert(str[0] == 'u');    for(i = 1; i <= 4; i++) {        char c = str[i];        value <<= 4;        if(l_isdigit(c))            value += c - '0';        else if(l_islower(c))            value += c - 'a' + 10;        else if(l_isupper(c))            value += c - 'A' + 10;        else            return -1;    }    return value;},16978
205,1318,CVE-2014-2038,24,"void nfs_init_commit(struct nfs_commit_data *data,		     struct list_head *head,		     struct pnfs_layout_segment *lseg,		     struct nfs_commit_info *cinfo){	struct nfs_page *first = nfs_list_entry(head->next);	struct inode *inode = first->wb_context->dentry->d_inode;	 	list_splice_init(head, &data->pages);	data->inode	  = inode;	data->cred	  = first->wb_context->cred;	data->lseg	  = lseg;  	data->mds_ops     = &nfs_commit_ops;	data->completion_ops = cinfo->completion_ops;	data->dreq	  = cinfo->dreq;	data->args.fh     = NFS_FH(data->inode);	 	data->args.offset = 0;	data->args.count  = 0;	data->context     = get_nfs_open_context(first->wb_context);	data->res.fattr   = &data->fattr;	data->res.verf    = &data->verf;	nfs_fattr_init(&data->fattr);}",11865
652,802,CVE-2013-1943,24,"int kvm_get_dirty_log(struct kvm *kvm,			struct kvm_dirty_log *log, int *is_dirty){	struct kvm_memory_slot *memslot;	int r, i;	unsigned long n;	unsigned long any = 0;	r = -EINVAL;	if (log->slot >= KVM_MEMORY_SLOTS)		goto out;	memslot = &kvm->memslots->memslots[log->slot];	r = -ENOENT;	if (!memslot->dirty_bitmap)		goto out;	n = kvm_dirty_bitmap_bytes(memslot);	for (i = 0; !any && i < n/sizeof(long); ++i)		any = memslot->dirty_bitmap[i];	r = -EFAULT;	if (copy_to_user(log->dirty_bitmap, memslot->dirty_bitmap, n))		goto out;	if (any)		*is_dirty = 1;	r = 0;out:	return r;}",9215
160,688,CVE-2013-6368,24,"static int kvm_vcpu_ioctl_x86_set_vcpu_events(struct kvm_vcpu *vcpu,					      struct kvm_vcpu_events *events){	if (events->flags & ~(KVM_VCPUEVENT_VALID_NMI_PENDING			      | KVM_VCPUEVENT_VALID_SIPI_VECTOR			      | KVM_VCPUEVENT_VALID_SHADOW))		return -EINVAL;	process_nmi(vcpu);	vcpu->arch.exception.pending = events->exception.injected;	vcpu->arch.exception.nr = events->exception.nr;	vcpu->arch.exception.has_error_code = events->exception.has_error_code;	vcpu->arch.exception.error_code = events->exception.error_code;	vcpu->arch.interrupt.pending = events->interrupt.injected;	vcpu->arch.interrupt.nr = events->interrupt.nr;	vcpu->arch.interrupt.soft = events->interrupt.soft;	if (events->flags & KVM_VCPUEVENT_VALID_SHADOW)		kvm_x86_ops->set_interrupt_shadow(vcpu,						  events->interrupt.shadow);	vcpu->arch.nmi_injected = events->nmi.injected;	if (events->flags & KVM_VCPUEVENT_VALID_NMI_PENDING)		vcpu->arch.nmi_pending = events->nmi.pending;	kvm_x86_ops->set_nmi_mask(vcpu, events->nmi.masked);	if (events->flags & KVM_VCPUEVENT_VALID_SIPI_VECTOR &&	    kvm_vcpu_has_lapic(vcpu))		vcpu->arch.apic->sipi_vector = events->sipi_vector;	kvm_make_request(KVM_REQ_EVENT, vcpu);	return 0;}",7455
67,1077,CVE-2014-3645,24,static void mmu_audit_disable(void) { },11211
670,1456,CVE-2014-0203,24,"static int proc_single_open(struct inode *inode, struct file *filp){	int ret;	ret = single_open(filp, proc_single_show, NULL);	if (!ret) {		struct seq_file *m = filp->private_data;		m->private = inode;	}	return ret;}",12166
594,1397,CVE-2014-0203,24,"static int handle_truncate(struct path *path){	struct inode *inode = path->dentry->d_inode;	int error = get_write_access(inode);	if (error)		return error;	 	error = locks_verify_locked(inode);	if (!error)		error = security_path_truncate(path, 0,				       ATTR_MTIME|ATTR_CTIME|ATTR_OPEN);	if (!error) {		error = do_truncate(path->dentry, 0,				    ATTR_MTIME|ATTR_CTIME|ATTR_OPEN,				    NULL);	}	put_write_access(inode);	return error;}",12107
185,982,CVE-2014-5336,24,"void mk_request_ka_next(struct client_session *cs){    cs->first_method = -1;    cs->body_pos_end = -1;    cs->body_length = 0;    cs->counter_connections++;         cs->init_time = log_current_utime;    cs->status = MK_REQUEST_STATUS_INCOMPLETE;    mk_list_add(&cs->request_incomplete, cs_incomplete);}",10639
374,682,CVE-2013-6368,24,int kvm_vcpu_compatible(struct kvm_vcpu *vcpu){	return irqchip_in_kernel(vcpu->kvm) == (vcpu->arch.apic != NULL);},7449
337,1762,CVE-2015-8215,24,"static int addrconf_fixup_forwarding(struct ctl_table *table, int *p, int newf){	struct net *net;	int old;	if (!rtnl_trylock())		return restart_syscall();	net = (struct net *)table->extra2;	old = *p;	*p = newf;	if (p == &net->ipv6.devconf_dflt->forwarding) {		if ((!newf) ^ (!old))			inet6_netconf_notify_devconf(net, NETCONFA_FORWARDING,						     NETCONFA_IFINDEX_DEFAULT,						     net->ipv6.devconf_dflt);		rtnl_unlock();		return 0;	}	if (p == &net->ipv6.devconf_all->forwarding) {		net->ipv6.devconf_dflt->forwarding = newf;		addrconf_forward_change(net, newf);		if ((!newf) ^ (!old))			inet6_netconf_notify_devconf(net, NETCONFA_FORWARDING,						     NETCONFA_IFINDEX_ALL,						     net->ipv6.devconf_all);	} else if ((!newf) ^ (!old))		dev_forward_change((struct inet6_dev *)table->extra1);	rtnl_unlock();	if (newf)		rt6_purge_dflt_routers(net);	return 1;}",12972
254,2256,CVE-2014-8324,24,"static int do_net_open(char *iface){	int s, port;	char ip[16];	struct sockaddr_in s_in;	port = get_ip_port(iface, ip, sizeof(ip)-1);	if (port == -1)		return -1;	s_in.sin_family = PF_INET;	s_in.sin_port = htons(port);	if (!inet_aton(ip, &s_in.sin_addr))		return -1;	if ((s = socket(s_in.sin_family, SOCK_STREAM, IPPROTO_TCP)) == -1)		return -1;	printf(""Connecting to %s port %d...\n"", ip, port);	if (connect(s, (struct sockaddr*) &s_in, sizeof(s_in)) == -1) {		close(s);		printf(""Failed to connect\n"");		return -1;	}	if (handshake(s) == -1) {		close(s);		printf(""Failed to connect - handshake failed\n"");		return -1;	}	printf(""Connection successful\n"");	return s;}",23107
209,1053,CVE-2014-3645,24,"static void kvm_mmu_free_page(struct kvm_mmu_page *sp){	ASSERT(is_empty_shadow_page(sp->spt));	hlist_del(&sp->hash_link);	list_del(&sp->link);	free_page((unsigned long)sp->spt);	if (!sp->role.direct)		free_page((unsigned long)sp->gfns);	kmem_cache_free(mmu_page_header_cache, sp);}",11187
350,425,CVE-2014-9645,24,static const char *humanly_readable_name(struct module_entry *m){	 	return m->probed_name ? m->probed_name : m->modname;},2505
602,1352,CVE-2014-2038,24,"void nfs_write_prepare(struct rpc_task *task, void *calldata){	struct nfs_write_data *data = calldata;	int err;	err = NFS_PROTO(data->header->inode)->write_rpc_prepare(task, data);	if (err)		rpc_exit(task, err);}",11899
1,193,CVE-2011-1428,24,"irc_server_outqueue_free (struct t_irc_server *server,                          int priority,                          struct t_irc_outqueue *outqueue){    struct t_irc_outqueue *new_outqueue;             if (server->last_outqueue[priority] == outqueue)        server->last_outqueue[priority] = outqueue->prev_outqueue;    if (outqueue->prev_outqueue)    {        (outqueue->prev_outqueue)->next_outqueue = outqueue->next_outqueue;        new_outqueue = server->outqueue[priority];    }    else        new_outqueue = outqueue->next_outqueue;        if (outqueue->next_outqueue)        (outqueue->next_outqueue)->prev_outqueue = outqueue->prev_outqueue;             if (outqueue->command)        free (outqueue->command);    if (outqueue->message_before_mod)        free (outqueue->message_before_mod);    if (outqueue->message_after_mod)        free (outqueue->message_after_mod);    if (outqueue->tags)        free (outqueue->tags);    free (outqueue);    server->outqueue[priority] = new_outqueue;}",687
398,1665,CVE-2013-7271,24,"static void prb_clear_rxhash(struct tpacket_kbdq_core *pkc,			struct tpacket3_hdr *ppd){	ppd->hv1.tp_rxhash = 0;}",12553
317,1273,CVE-2014-2673,24,"static inline int valid_irq_stack(unsigned long sp, struct task_struct *p,				  unsigned long nbytes){	unsigned long stack_page;	unsigned long cpu = task_cpu(p);	 	if (cpu < NR_CPUS && cpu_possible(cpu)) {		stack_page = (unsigned long) hardirq_ctx[cpu];		if (sp >= stack_page + sizeof(struct thread_struct)		    && sp <= stack_page + THREAD_SIZE - nbytes)			return 1;		stack_page = (unsigned long) softirq_ctx[cpu];		if (sp >= stack_page + sizeof(struct thread_struct)		    && sp <= stack_page + THREAD_SIZE - nbytes)			return 1;	}	return 0;}",11765
441,1187,CVE-2014-2739,24,"int ib_cm_notify(struct ib_cm_id *cm_id, enum ib_event_type event){	int ret;	switch (event) {	case IB_EVENT_COMM_EST:		ret = cm_establish(cm_id);		break;	case IB_EVENT_PATH_MIG:		ret = cm_migrate(cm_id);		break;	default:		ret = -EINVAL;	}	return ret;}",11662
666,687,CVE-2013-6368,24,"static void kvm_vcpu_ioctl_x86_get_vcpu_events(struct kvm_vcpu *vcpu,					       struct kvm_vcpu_events *events){	process_nmi(vcpu);	events->exception.injected =		vcpu->arch.exception.pending &&		!kvm_exception_is_soft(vcpu->arch.exception.nr);	events->exception.nr = vcpu->arch.exception.nr;	events->exception.has_error_code = vcpu->arch.exception.has_error_code;	events->exception.pad = 0;	events->exception.error_code = vcpu->arch.exception.error_code;	events->interrupt.injected =		vcpu->arch.interrupt.pending && !vcpu->arch.interrupt.soft;	events->interrupt.nr = vcpu->arch.interrupt.nr;	events->interrupt.soft = 0;	events->interrupt.shadow =		kvm_x86_ops->get_interrupt_shadow(vcpu,			KVM_X86_SHADOW_INT_MOV_SS | KVM_X86_SHADOW_INT_STI);	events->nmi.injected = vcpu->arch.nmi_injected;	events->nmi.pending = vcpu->arch.nmi_pending != 0;	events->nmi.masked = kvm_x86_ops->get_nmi_mask(vcpu);	events->nmi.pad = 0;	events->sipi_vector = 0;  	events->flags = (KVM_VCPUEVENT_VALID_NMI_PENDING			 | KVM_VCPUEVENT_VALID_SHADOW);	memset(&events->reserved, 0, sizeof(events->reserved));}",7454
401,1300,CVE-2014-2038,24,"struct nfs_commit_data *nfs_commitdata_alloc(void){	struct nfs_commit_data *p = mempool_alloc(nfs_commit_mempool, GFP_NOIO);	if (p) {		memset(p, 0, sizeof(*p));		INIT_LIST_HEAD(&p->pages);	}	return p;}",11847
131,1189,CVE-2014-2739,24,"static void addr_handler(int status, struct sockaddr *src_addr,			 struct rdma_dev_addr *dev_addr, void *context){	struct rdma_id_private *id_priv = context;	struct rdma_cm_event event;	memset(&event, 0, sizeof event);	mutex_lock(&id_priv->handler_mutex);	if (!cma_comp_exch(id_priv, RDMA_CM_ADDR_QUERY,			   RDMA_CM_ADDR_RESOLVED))		goto out;	memcpy(cma_src_addr(id_priv), src_addr, rdma_addr_size(src_addr));	if (!status && !id_priv->cma_dev)		status = cma_acquire_dev(id_priv, NULL);	if (status) {		if (!cma_comp_exch(id_priv, RDMA_CM_ADDR_RESOLVED,				   RDMA_CM_ADDR_BOUND))			goto out;		event.event = RDMA_CM_EVENT_ADDR_ERROR;		event.status = status;	} else		event.event = RDMA_CM_EVENT_ADDR_RESOLVED;	if (id_priv->id.event_handler(&id_priv->id, &event)) {		cma_exch(id_priv, RDMA_CM_DESTROYING);		mutex_unlock(&id_priv->handler_mutex);		cma_deref_id(id_priv);		rdma_destroy_id(&id_priv->id);		return;	}out:	mutex_unlock(&id_priv->handler_mutex);	cma_deref_id(id_priv);}",11664
238,701,CVE-2013-4587,24,"static int __kvm_io_bus_read(struct kvm_io_bus *bus, struct kvm_io_range *range,			     void *val){	int idx;	idx = kvm_io_bus_get_first_dev(bus, range->addr, range->len);	if (idx < 0)		return -EOPNOTSUPP;	while (idx < bus->dev_count &&		kvm_io_bus_cmp(range, &bus->range[idx]) == 0) {		if (!kvm_iodevice_read(bus->range[idx].dev, range->addr,				       range->len, val))			return idx;		idx++;	}	return -EOPNOTSUPP;}",7640
188,2108,CVE-2017-15951,24,void user_destroy(struct key *key){	struct user_key_payload *upayload = key->payload.data[0];	kzfree(upayload);},19931
121,2337,CVE-2018-16276,24,"static int yurex_release(struct inode *inode, struct file *file){	struct usb_yurex *dev;	dev = file->private_data;	if (dev == NULL)		return -ENODEV;	 	kref_put(&dev->kref, yurex_delete);	return 0;}",24394
455,2769,CVE-2013-0216,24,"static int netbk_set_skb_gso(struct xenvif *vif,			     struct sk_buff *skb, 			     struct xen_netif_extra_info *gso) { 	if (!gso->u.gso.size) {		netdev_dbg(vif->dev, ""GSO size must not be zero.\n""); 		return -EINVAL; 	}  	  	if (gso->u.gso.type != XEN_NETIF_GSO_TYPE_TCPV4) {		netdev_dbg(vif->dev, ""Bad GSO type %d.\n"", gso->u.gso.type); 		return -EINVAL; 	} 	skb_shinfo(skb)->gso_size = gso->u.gso.size;	skb_shinfo(skb)->gso_type = SKB_GSO_TCPV4;	 	skb_shinfo(skb)->gso_type |= SKB_GSO_DODGY;	skb_shinfo(skb)->gso_segs = 0;	return 0;}",31100
146,112,CVE-2015-5296,24,"static int smbXcli_session_destructor(struct smbXcli_session *session){	if (session->conn == NULL) {		return 0;	}	DLIST_REMOVE(session->conn->sessions, session);	return 0;}",520
557,47,CVE-2017-16227,24,assegment_dup_all (struct assegment *seg){  struct assegment *new = NULL;  struct assegment *head = NULL;    while (seg)    {      if (head)        {          new->next = assegment_dup (seg);          new = new->next;        }      else        head = new = assegment_dup (seg);            seg = seg->next;    }  return head;},369
675,2324,CVE-2018-17456,24,"static int fsck_walk_tree(struct tree *tree, void *data, struct fsck_options *options){	struct tree_desc desc;	struct name_entry entry;	int res = 0;	const char *name;	if (parse_tree(tree))		return -1;	name = get_object_name(options, &tree->object);	if (init_tree_desc_gently(&desc, tree->buffer, tree->size))		return -1;	while (tree_entry_gently(&desc, &entry)) {		struct object *obj;		int result;		if (S_ISGITLINK(entry.mode))			continue;		if (S_ISDIR(entry.mode)) {			obj = (struct object *)lookup_tree(entry.oid);			if (name && obj)				put_object_name(options, obj, ""%s%s/"", name,					entry.path);			result = options->walk(obj, OBJ_TREE, data, options);		}		else if (S_ISREG(entry.mode) || S_ISLNK(entry.mode)) {			obj = (struct object *)lookup_blob(entry.oid);			if (name && obj)				put_object_name(options, obj, ""%s%s"", name,					entry.path);			result = options->walk(obj, OBJ_BLOB, data, options);		}		else {			result = error(""in tree %s: entry %s has bad mode %.6o"",					describe_object(options, &tree->object), entry.path, entry.mode);		}		if (result < 0)			return result;		if (!res)			res = result;	}	return res;}",23616
621,2713,CVE-2016-3760,24,void btif_config_flush(void) {  assert(config != NULL);  assert(alarm_timer != NULL);  alarm_cancel(alarm_timer);  btif_config_write();},30524
569,2128,CVE-2017-14230,24,static void mboxlist_closesubs(struct db *sub){    cyrusdb_close(sub);},20148
66,856,CVE-2013-1828,24,"static int sctp_wait_for_packet(struct sock * sk, int *err, long *timeo_p){	int error;	DEFINE_WAIT(wait);	prepare_to_wait_exclusive(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);	 	error = sock_error(sk);	if (error)		goto out;	if (!skb_queue_empty(&sk->sk_receive_queue))		goto ready;	 	if (sk->sk_shutdown & RCV_SHUTDOWN)		goto out;	 	error = -ENOTCONN;	 	if (list_empty(&sctp_sk(sk)->ep->asocs) && !sctp_sstate(sk, LISTENING))		goto out;	 	if (signal_pending(current))		goto interrupted;	 	sctp_release_sock(sk);	*timeo_p = schedule_timeout(*timeo_p);	sctp_lock_sock(sk);ready:	finish_wait(sk_sleep(sk), &wait);	return 0;interrupted:	error = sock_intr_errno(*timeo_p);out:	finish_wait(sk_sleep(sk), &wait);	*err = error;	return error;}",9412
579,1362,CVE-2014-2038,24,static int wb_priority(struct writeback_control *wbc){	if (wbc->for_reclaim)		return FLUSH_HIGHPRI | FLUSH_STABLE;	if (wbc->for_kupdate || wbc->for_background)		return FLUSH_LOWPRI | FLUSH_COND_STABLE;	return FLUSH_COND_STABLE;},11909
216,1658,CVE-2013-7271,24,"static void *packet_lookup_frame(struct packet_sock *po,		struct packet_ring_buffer *rb,		unsigned int position,		int status){	unsigned int pg_vec_pos, frame_offset;	union tpacket_uhdr h;	pg_vec_pos = position / rb->frames_per_block;	frame_offset = position % rb->frames_per_block;	h.raw = rb->pg_vec[pg_vec_pos].buffer +		(frame_offset * rb->frame_size);	if (status != __packet_get_status(po, h.raw))		return NULL;	return h.raw;}",12546
664,1956,CVE-2015-3288,24,"int handle_mm_fault(struct mm_struct *mm, struct vm_area_struct *vma,		    unsigned long address, unsigned int flags){	int ret;	__set_current_state(TASK_RUNNING);	count_vm_event(PGFAULT);	mem_cgroup_count_vm_event(mm, PGFAULT);	 	check_sync_rss_stat(current);	 	if (flags & FAULT_FLAG_USER)		mem_cgroup_oom_enable();	ret = __handle_mm_fault(mm, vma, address, flags);	if (flags & FAULT_FLAG_USER) {		mem_cgroup_oom_disable();                                 if (task_in_memcg_oom(current) && !(ret & VM_FAULT_OOM))                        mem_cgroup_oom_synchronize(false);	}	return ret;}",19117
34,609,CVE-2011-2518,24,"int tomoyo_write_mount(char *data, struct tomoyo_domain_info *domain,		       const int is_delete){	struct tomoyo_mount_acl e = { .head.type = TOMOYO_TYPE_MOUNT_ACL };	int error = is_delete ? -ENOENT : -ENOMEM;	char *w[4];	if (!tomoyo_tokenize(data, w, sizeof(w)) || !w[3][0])		return -EINVAL;	if (!tomoyo_parse_name_union(w[0], &e.dev_name) ||	    !tomoyo_parse_name_union(w[1], &e.dir_name) ||	    !tomoyo_parse_name_union(w[2], &e.fs_type) ||	    !tomoyo_parse_number_union(w[3], &e.flags))		goto out;	error = tomoyo_update_domain(&e.head, sizeof(e), is_delete, domain,				     tomoyo_same_mount_acl, NULL); out:	tomoyo_put_name_union(&e.dev_name);	tomoyo_put_name_union(&e.dir_name);	tomoyo_put_name_union(&e.fs_type);	tomoyo_put_number_union(&e.flags);	return error;}",6546
616,2573,CVE-2011-1296,24,  void EnsureFindBoxOpen() {    EnsureFindBoxOpenForBrowser(browser());  },29153
49,2500,CVE-2017-12843,24,"static char *canonical_list_pattern(const char *reference, const char *pattern){    int patlen = strlen(pattern);    int reflen = strlen(reference);    char *buf = xmalloc(patlen + reflen + 1);    buf[0] = '\0';    if (*reference) {        if (reference[reflen-1] == imapd_namespace.hier_sep &&                pattern[0] == imapd_namespace.hier_sep)            --reflen;        memcpy(buf, reference, reflen);        buf[reflen] = '\0';    }    strcat(buf, pattern);    return buf;}",28501
53,17,CVE-2017-16227,24,aspath_count_confeds (struct aspath *aspath){  int count = 0;  struct assegment *seg = aspath->segments;    while (seg)    {      if (seg->type == AS_CONFED_SEQUENCE)        count += seg->length;      else if (seg->type == AS_CONFED_SET)        count++;            seg = seg->next;    }  return count;},339
553,715,CVE-2013-4587,24,"static int kvm_init_debug(void){	int r = -EEXIST;	struct kvm_stats_debugfs_item *p;	kvm_debugfs_dir = debugfs_create_dir(""kvm"", NULL);	if (kvm_debugfs_dir == NULL)		goto out;	for (p = debugfs_entries; p->name; ++p) {		p->dentry = debugfs_create_file(p->name, 0444, kvm_debugfs_dir,						(void *)(long)p->offset,						stat_fops[p->kind]);		if (p->dentry == NULL)			goto out_dir;	}	return 0;out_dir:	debugfs_remove_recursive(kvm_debugfs_dir);out:	return r;}",7654
546,456,CVE-2010-1152,24,"static void set_current_time(void) {    struct timeval timer;    gettimeofday(&timer, NULL);    current_time = (rel_time_t) (timer.tv_sec - process_started);}",2647
591,27,CVE-2017-16227,24,"aspath_hash_alloc (void *arg){  const struct aspath *aspath = arg;  struct aspath *new;     assert (aspath->str);  if (! aspath->str)    return NULL;     new = XMALLOC (MTYPE_AS_PATH, sizeof (struct aspath));     new->refcnt = 0;  new->segments = aspath->segments;  new->str = aspath->str;  new->str_len = aspath->str_len;  return new;}",349
294,239,CVE-2011-0465,24,"FindFirst(char *string, char dest, int *lines){    if (lines)	*lines = 0;    for (;;) {	if (*string == '\0')	    return NULL;	if (*string == '\\') {	    if (*++string == '\0')		return NULL;	} else if (*string == dest)	    return string;	if (*string == '\n'  &&  lines)	    (*lines)++;	string++;    }}",848
515,1682,CVE-2013-7271,24,"static void register_prot_hook(struct sock *sk){	struct packet_sock *po = pkt_sk(sk);	if (!po->running) {		if (po->fanout)			__fanout_link(sk, po);		else			dev_add_pack(&po->prot_hook);		sock_hold(sk);		po->running = 1;	}}",12570
270,911,CVE-2013-0216,24,static int xenvif_close(struct net_device *dev){	struct xenvif *vif = netdev_priv(dev);	if (netif_carrier_ok(dev))		xenvif_down(vif);	netif_stop_queue(dev);	return 0;},9802
315,2614,CVE-2018-18358,24,"  HttpProxyScriptBrowserTest() {    http_server_.ServeFilesFromSourceDirectory(""chrome/test/data"");  }",30020
692,1950,CVE-2015-3288,24,"	__releases(ptl){	struct page *old_page;	old_page = vm_normal_page(vma, address, orig_pte);	if (!old_page) {		 		if ((vma->vm_flags & (VM_WRITE|VM_SHARED)) ==				     (VM_WRITE|VM_SHARED))			return wp_pfn_shared(mm, vma, address, page_table, ptl,					     orig_pte, pmd);		pte_unmap_unlock(page_table, ptl);		return wp_page_copy(mm, vma, address, page_table, pmd,				    orig_pte, old_page);	}	 	if (PageAnon(old_page) && !PageKsm(old_page)) {		if (!trylock_page(old_page)) {			page_cache_get(old_page);			pte_unmap_unlock(page_table, ptl);			lock_page(old_page);			page_table = pte_offset_map_lock(mm, pmd, address,							 &ptl);			if (!pte_same(*page_table, orig_pte)) {				unlock_page(old_page);				pte_unmap_unlock(page_table, ptl);				page_cache_release(old_page);				return 0;			}			page_cache_release(old_page);		}		if (reuse_swap_page(old_page)) {			 			page_move_anon_rmap(old_page, vma, address);			unlock_page(old_page);			return wp_page_reuse(mm, vma, address, page_table, ptl,					     orig_pte, old_page, 0, 0);		}		unlock_page(old_page);	} else if (unlikely((vma->vm_flags & (VM_WRITE|VM_SHARED)) ==					(VM_WRITE|VM_SHARED))) {		return wp_page_shared(mm, vma, address, page_table, pmd,				      ptl, orig_pte, old_page);	}	 	page_cache_get(old_page);	pte_unmap_unlock(page_table, ptl);	return wp_page_copy(mm, vma, address, page_table, pmd,			    orig_pte, old_page);}",19111
51,2296,CVE-2018-18021,24,"int kvm_arch_vcpu_ioctl_set_guest_debug(struct kvm_vcpu *vcpu,					struct kvm_guest_debug *dbg){	int ret = 0;	trace_kvm_set_guest_debug(vcpu, dbg->control);	if (dbg->control & ~KVM_GUESTDBG_VALID_MASK) {		ret = -EINVAL;		goto out;	}	if (dbg->control & KVM_GUESTDBG_ENABLE) {		vcpu->guest_debug = dbg->control;		 		if (vcpu->guest_debug & KVM_GUESTDBG_USE_HW) {			vcpu->arch.external_debug_state = dbg->arch;		}	} else {		 		vcpu->guest_debug = 0;	}out:	return ret;}",23580
370,391,CVE-2014-2855,24,"static void generate_hash(const char *in, const char *challenge, char *out){	char buf[MAX_DIGEST_LEN];	int len;	sum_init(0);	sum_update(in, strlen(in));	sum_update(challenge, strlen(challenge));	len = sum_end(buf);	base64_encode(buf, len, out, 0);}",2080
87,351,CVE-2016-4072,24,"PHP_METHOD(Phar, getAlias){	PHAR_ARCHIVE_OBJECT();	if (zend_parse_parameters_none() == FAILURE) {		return;	}	if (phar_obj->archive->alias && phar_obj->archive->alias != phar_obj->archive->fname) {		RETURN_STRINGL(phar_obj->archive->alias, phar_obj->archive->alias_len);	}}",1921
278,1641,CVE-2013-7271,24,"static int __packet_get_status(struct packet_sock *po, void *frame){	union tpacket_uhdr h;	smp_rmb();	h.raw = frame;	switch (po->tp_version) {	case TPACKET_V1:		flush_dcache_page(pgv_to_page(&h.h1->tp_status));		return h.h1->tp_status;	case TPACKET_V2:		flush_dcache_page(pgv_to_page(&h.h2->tp_status));		return h.h2->tp_status;	case TPACKET_V3:	default:		WARN(1, ""TPACKET version not supported.\n"");		BUG();		return 0;	}}",12529
192,362,CVE-2016-4072,24,"PHP_METHOD(Phar, delMetadata){	char *error;	PHAR_ARCHIVE_OBJECT();	if (PHAR_G(readonly) && !phar_obj->archive->is_data) {		zend_throw_exception_ex(spl_ce_BadMethodCallException, 0, ""Write operations disabled by the php.ini setting phar.readonly"");		return;	}	if (Z_TYPE(phar_obj->archive->metadata) != IS_UNDEF) {		zval_ptr_dtor(&phar_obj->archive->metadata);		ZVAL_UNDEF(&phar_obj->archive->metadata);		phar_obj->archive->is_modified = 1;		phar_flush(phar_obj->archive, 0, 0, 0, &error);		if (error) {			zend_throw_exception_ex(phar_ce_PharException, 0, ""%s"", error);			efree(error);			RETURN_FALSE;		} else {			RETURN_TRUE;		}	} else {		RETURN_TRUE;	}}",1932
30,20,CVE-2017-16227,24,"aspath_dup (struct aspath *aspath){  unsigned short buflen = aspath->str_len + 1;  struct aspath *new;  new = XCALLOC (MTYPE_AS_PATH, sizeof (struct aspath));  if (aspath->segments)    new->segments = assegment_dup_all (aspath->segments);  if (!aspath->str)    return new;  new->str = XMALLOC (MTYPE_AS_STR, buflen);  new->str_len = aspath->str_len;     if (aspath->str_len > 0)    memcpy (new->str, aspath->str, buflen);  else    new->str[0] = '\0';  return new;}",342
551,1193,CVE-2014-2739,24,"static int cma_alloc_any_port(struct idr *ps, struct rdma_id_private *id_priv){	static unsigned int last_used_port;	int low, high, remaining;	unsigned int rover;	inet_get_local_port_range(&init_net, &low, &high);	remaining = (high - low) + 1;	rover = prandom_u32() % remaining + low;retry:	if (last_used_port != rover &&	    !idr_find(ps, (unsigned short) rover)) {		int ret = cma_alloc_port(ps, id_priv, rover);		 		if (!ret)			last_used_port = rover;		if (ret != -EADDRNOTAVAIL)			return ret;	}	if (--remaining) {		rover++;		if ((rover < low) || (rover > high))			rover = low;		goto retry;	}	return -EADDRNOTAVAIL;}",11668
439,1638,CVE-2013-7271,24,"static void rawsock_write_queue_purge(struct sock *sk){	pr_debug(""sk=%p\n"", sk);	spin_lock_bh(&sk->sk_write_queue.lock);	__skb_queue_purge(&sk->sk_write_queue);	nfc_rawsock(sk)->tx_work_scheduled = false;	spin_unlock_bh(&sk->sk_write_queue.lock);}",12526
351,1579,CVE-2013-7271,24,"static void pppol2tp_session_close(struct l2tp_session *session){	struct pppol2tp_session *ps = l2tp_session_priv(session);	struct sock *sk = ps->sock;	struct socket *sock = sk->sk_socket;	BUG_ON(session->magic != L2TP_SESSION_MAGIC);	if (sock) {		inet_shutdown(sock, 2);		 		l2tp_session_inc_refcount(session);	}	return;}",12467
617,1552,CVE-2013-7271,24,"static int ipx_compat_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg){	 	switch (cmd) {	case SIOCAIPXITFCRT:	case SIOCAIPXPRISLT:	case SIOCIPXCFGDATA:	case SIOCIPXNCPCONN:		return ipx_ioctl(sock, cmd, arg);	default:		return -ENOIOCTLCMD;	}}",12440
574,2205,CVE-2017-6345,24,"static struct llc_sap_state_trans *llc_find_sap_trans(struct llc_sap *sap,						      struct sk_buff *skb){	int i = 0;	struct llc_sap_state_trans *rc = NULL;	struct llc_sap_state_trans **next_trans;	struct llc_sap_state *curr_state = &llc_sap_state_table[sap->state - 1];	 	for (next_trans = curr_state->transitions; next_trans[i]->ev; i++)		if (!next_trans[i]->ev(sap, skb)) {			rc = next_trans[i];  			break;		}	return rc;}",21838
540,299,CVE-2014-7840,24,"void ram_mig_init(void){    qemu_mutex_init(&XBZRLE.lock);    register_savevm_live(NULL, ""ram"", 0, 4, &savevm_ram_handlers, NULL);}",1299
477,2146,CVE-2017-11665,24,"void ff_amf_write_object_end(int **dst){         bytestream_put_be24(dst, AMF_DATA_TYPE_OBJECT_END);}",20461
26,1852,CVE-2016-9191,24,static int proc_sys_delete(const struct dentry *dentry){	return !!PROC_I(d_inode(dentry))->sysctl->unregistering;},15213
150,56,CVE-2011-2724,24,"static int get_pw_from_env(struct parsed_mount_info *parsed_info){	int rc = 0;	if (getenv(""PASSWD""))		rc = set_password(parsed_info, getenv(""PASSWD""));	else if (getenv(""PASSWD_FD""))		rc = get_password_from_file(atoi(getenv(""PASSWD_FD"")), NULL,					    parsed_info);	else if (getenv(""PASSWD_FILE""))		rc = get_password_from_file(0, getenv(""PASSWD_FILE""),					    parsed_info);	return rc;}",433
483,2405,CVE-2019-1010293,24,"void vm_info_final(struct user_ta_ctx *utc){	if (!utc->vm_info)		return;	 	tlbi_asid(utc->vm_info->asid);	asid_free(utc->vm_info->asid);	while (!TAILQ_EMPTY(&utc->vm_info->regions))		umap_remove_region(utc->vm_info,				   TAILQ_FIRST(&utc->vm_info->regions));	free(utc->vm_info);	utc->vm_info = NULL;}",26382
181,926,CVE-2011-3619,24,"static void apparmor_cred_transfer(struct cred *new, const struct cred *old){	const struct aa_task_cxt *old_cxt = old->security;	struct aa_task_cxt *new_cxt = new->security;	aa_dup_task_context(new_cxt, old_cxt);}",10097
103,2165,CVE-2017-9242,24,int ip6_push_pending_frames(struct sock *sk){	struct sk_buff *skb;	skb = ip6_finish_skb(sk);	if (!skb)		return 0;	return ip6_send_skb(skb);},20746
239,2143,CVE-2017-11665,24,"void ff_amf_write_field_name(int **dst, const char *str){    bytestream_put_be16(dst, strlen(str));    bytestream_put_buffer(dst, str, strlen(str));}",20458
269,628,CVE-2011-1080,24,"ebt_get_udc_positions(struct ebt_entry *e, struct ebt_table_info *newinfo,   unsigned int *n, struct ebt_cl_stack *udc){	int i;	 	if (e->bitmask)		return 0;	for (i = 0; i < NF_BR_NUMHOOKS; i++) {		if (newinfo->hook_entry[i] == (struct ebt_entries *)e)			break;	}	 	if (i != NF_BR_NUMHOOKS)		return 0;	udc[*n].cs.chaininfo = (struct ebt_entries *)e;	 	udc[*n].cs.n = 0;	udc[*n].hookmask = 0;	(*n)++;	return 0;}",6931
111,1438,CVE-2014-0203,24,"static int pid_getattr(struct vfsmount *mnt, struct dentry *dentry, struct kstat *stat){	struct inode *inode = dentry->d_inode;	struct task_struct *task;	const struct cred *cred;	generic_fillattr(inode, stat);	rcu_read_lock();	stat->uid = 0;	stat->gid = 0;	task = pid_task(proc_pid(inode), PIDTYPE_PID);	if (task) {		if ((inode->i_mode == (S_IFDIR|S_IRUGO|S_IXUGO)) ||		    task_dumpable(task)) {			cred = __task_cred(task);			stat->uid = cred->euid;			stat->gid = cred->egid;		}	}	rcu_read_unlock();	return 0;}",12148
76,1967,CVE-2015-3288,24,"static void unmap_page_range(struct mmu_gather *tlb,			     struct vm_area_struct *vma,			     unsigned long addr, unsigned long end,			     struct zap_details *details){	pgd_t *pgd;	unsigned long next;	if (details && !details->check_mapping)		details = NULL;	BUG_ON(addr >= end);	tlb_start_vma(tlb, vma);	pgd = pgd_offset(vma->vm_mm, addr);	do {		next = pgd_addr_end(addr, end);		if (pgd_none_or_clear_bad(pgd))			continue;		next = zap_pud_range(tlb, vma, pgd, addr, next, details);	} while (pgd++, addr = next, addr != end);	tlb_end_vma(tlb, vma);}",19128
172,1833,CVE-2016-9191,24,static int count_subheaders(struct ctl_table *table){	int has_files = 0;	int nr_subheaders = 0;	struct ctl_table *entry;	 	if (!table || !table->procname)		return 1;	for (entry = table; entry->procname; entry++) {		if (entry->child)			nr_subheaders += count_subheaders(entry->child);		else			has_files = 1;	}	return nr_subheaders + has_files;},15194
302,1406,CVE-2014-0203,24,static inline int open_to_namei_flags(int flag){	if ((flag+1) & O_ACCMODE)		flag++;	return flag;},12116
510,2615,CVE-2018-18358,24,  void OnFirstResult() {    EXPECT_FALSE(first_result_received_);    first_result_received_ = true;  },30021
267,2511,CVE-2017-12843,24,"void cmd_xconvmeta(const char *tag){    int r;    int c = ' ';    struct conversations_state *state = NULL;    struct dlist *cidlist = NULL;    struct dlist *itemlist = NULL;    if (backend_current) {                 prot_printf(backend_current->out, ""%s XCONVMETA "", tag);        if (!pipe_command(backend_current, 65536)) {            pipe_including_tag(backend_current, tag, 0);        }        return;    }    if (!config_getswitch(IMAPOPT_CONVERSATIONS)) {        prot_printf(imapd_out, ""%s BAD Unrecognized command\r\n"", tag);        eatline(imapd_in, c);        goto done;    }    c = dlist_parse_asatomlist(&cidlist, 0, imapd_in);    if (c != ' ') {        prot_printf(imapd_out, ""%s BAD Failed to parse CID list\r\n"", tag);        eatline(imapd_in, c);        goto done;    }    c = dlist_parse_asatomlist(&itemlist, 0, imapd_in);    if (c == '\r') c = prot_getc(imapd_in);    if (c != '\n') {        prot_printf(imapd_out, ""%s BAD Failed to parse item list\r\n"", tag);        eatline(imapd_in, c);        goto done;    }    r = conversations_open_user(imapd_userid, &state);    if (r) {        prot_printf(imapd_out, ""%s BAD failed to open db: %s\r\n"",                    tag, error_message(r));        goto done;    }    do_xconvmeta(tag, state, cidlist, itemlist); done:    dlist_free(&itemlist);    dlist_free(&cidlist);    conversations_commit(&state);}",28512
405,2381,CVE-2017-18200,24,"static int restore_curseg_summaries(struct f2fs_sb_info *sbi){	struct f2fs_journal *sit_j = CURSEG_I(sbi, CURSEG_COLD_DATA)->journal;	struct f2fs_journal *nat_j = CURSEG_I(sbi, CURSEG_HOT_DATA)->journal;	int type = CURSEG_HOT_DATA;	int err;	if (is_set_ckpt_flags(sbi, CP_COMPACT_SUM_FLAG)) {		int npages = npages_for_summary_flush(sbi, true);		if (npages >= 2)			ra_meta_pages(sbi, start_sum_block(sbi), npages,							META_CP, true);		 		if (read_compacted_summaries(sbi))			return -EINVAL;		type = CURSEG_HOT_NODE;	}	if (__exist_node_summaries(sbi))		ra_meta_pages(sbi, sum_blk_addr(sbi, NR_CURSEG_TYPE, type),					NR_CURSEG_TYPE - type, META_CP, true);	for (; type <= CURSEG_COLD_NODE; type++) {		err = read_normal_summaries(sbi, type);		if (err)			return err;	}	 	if (nats_in_cursum(nat_j) > NAT_JOURNAL_ENTRIES ||			sits_in_cursum(sit_j) > SIT_JOURNAL_ENTRIES)		return -EINVAL;	return 0;}",26041
387,2369,CVE-2017-18200,24,"static void __wait_one_discard_bio(struct f2fs_sb_info *sbi,							struct discard_cmd *dc){	struct discard_cmd_control *dcc = SM_I(sbi)->dcc_info;	wait_for_completion_io(&dc->wait);	mutex_lock(&dcc->cmd_lock);	f2fs_bug_on(sbi, dc->state != D_DONE);	dc->ref--;	if (!dc->ref)		__remove_discard_cmd(sbi, dc);	mutex_unlock(&dcc->cmd_lock);}",26029
349,1965,CVE-2015-3288,24,"void tlb_remove_table(struct mmu_gather *tlb, void *table){	struct mmu_table_batch **batch = &tlb->batch;	 	if (atomic_read(&tlb->mm->mm_users) < 2) {		__tlb_remove_table(table);		return;	}	if (*batch == NULL) {		*batch = (struct mmu_table_batch *)__get_free_page(GFP_NOWAIT | __GFP_NOWARN);		if (*batch == NULL) {			tlb_remove_table_one(table);			return;		}		(*batch)->nr = 0;	}	(*batch)->tables[(*batch)->nr++] = table;	if ((*batch)->nr == MAX_TABLE_BATCH)		tlb_table_flush(tlb);}",19126
628,1817,CVE-2015-7509,24,"static int ext4_rename(struct inode *old_dir, struct dentry *old_dentry,		       struct inode *new_dir, struct dentry *new_dentry){	handle_t *handle;	struct inode *old_inode, *new_inode;	struct buffer_head *old_bh, *new_bh, *dir_bh;	struct ext4_dir_entry_2 *old_de, *new_de;	int retval, force_da_alloc = 0;	dquot_initialize(old_dir);	dquot_initialize(new_dir);	old_bh = new_bh = dir_bh = NULL;	 	if (new_dentry->d_inode)		dquot_initialize(new_dentry->d_inode);	handle = ext4_journal_start(old_dir, 2 *					EXT4_DATA_TRANS_BLOCKS(old_dir->i_sb) +					EXT4_INDEX_EXTRA_TRANS_BLOCKS + 2);	if (IS_ERR(handle))		return PTR_ERR(handle);	if (IS_DIRSYNC(old_dir) || IS_DIRSYNC(new_dir))		ext4_handle_sync(handle);	old_bh = ext4_find_entry(old_dir, &old_dentry->d_name, &old_de);	 	old_inode = old_dentry->d_inode;	retval = -ENOENT;	if (!old_bh || le32_to_cpu(old_de->inode) != old_inode->i_ino)		goto end_rename;	new_inode = new_dentry->d_inode;	new_bh = ext4_find_entry(new_dir, &new_dentry->d_name, &new_de);	if (new_bh) {		if (!new_inode) {			brelse(new_bh);			new_bh = NULL;		}	}	if (S_ISDIR(old_inode->i_mode)) {		if (new_inode) {			retval = -ENOTEMPTY;			if (!empty_dir(new_inode))				goto end_rename;		}		retval = -EIO;		dir_bh = ext4_bread(handle, old_inode, 0, 0, &retval);		if (!dir_bh)			goto end_rename;		if (!buffer_verified(dir_bh) &&		    !ext4_dirent_csum_verify(old_inode,				(struct ext4_dir_entry *)dir_bh->b_data))			goto end_rename;		set_buffer_verified(dir_bh);		if (le32_to_cpu(PARENT_INO(dir_bh->b_data,				old_dir->i_sb->s_blocksize)) != old_dir->i_ino)			goto end_rename;		retval = -EMLINK;		if (!new_inode && new_dir != old_dir &&		    EXT4_DIR_LINK_MAX(new_dir))			goto end_rename;		BUFFER_TRACE(dir_bh, ""get_write_access"");		retval = ext4_journal_get_write_access(handle, dir_bh);		if (retval)			goto end_rename;	}	if (!new_bh) {		retval = ext4_add_entry(handle, new_dentry, old_inode);		if (retval)			goto end_rename;	} else {		BUFFER_TRACE(new_bh, ""get write access"");		retval = ext4_journal_get_write_access(handle, new_bh);		if (retval)			goto end_rename;		new_de->inode = cpu_to_le32(old_inode->i_ino);		if (EXT4_HAS_INCOMPAT_FEATURE(new_dir->i_sb,					      EXT4_FEATURE_INCOMPAT_FILETYPE))			new_de->file_type = old_de->file_type;		new_dir->i_version++;		new_dir->i_ctime = new_dir->i_mtime =					ext4_current_time(new_dir);		ext4_mark_inode_dirty(handle, new_dir);		BUFFER_TRACE(new_bh, ""call ext4_handle_dirty_metadata"");		retval = ext4_handle_dirty_dirent_node(handle, new_dir, new_bh);		if (unlikely(retval)) {			ext4_std_error(new_dir->i_sb, retval);			goto end_rename;		}		brelse(new_bh);		new_bh = NULL;	}	 	old_inode->i_ctime = ext4_current_time(old_inode);	ext4_mark_inode_dirty(handle, old_inode);	 	if (le32_to_cpu(old_de->inode) != old_inode->i_ino ||	    old_de->name_len != old_dentry->d_name.len ||	    strncmp(old_de->name, old_dentry->d_name.name, old_de->name_len) ||	    (retval = ext4_delete_entry(handle, old_dir,					old_de, old_bh)) == -ENOENT) {		 		struct buffer_head *old_bh2;		struct ext4_dir_entry_2 *old_de2;		old_bh2 = ext4_find_entry(old_dir, &old_dentry->d_name, &old_de2);		if (old_bh2) {			retval = ext4_delete_entry(handle, old_dir,						   old_de2, old_bh2);			brelse(old_bh2);		}	}	if (retval) {		ext4_warning(old_dir->i_sb,				""Deleting old file (%lu), %d, error=%d"",				old_dir->i_ino, old_dir->i_nlink, retval);	}	if (new_inode) {		ext4_dec_count(handle, new_inode);		new_inode->i_ctime = ext4_current_time(new_inode);	}	old_dir->i_ctime = old_dir->i_mtime = ext4_current_time(old_dir);	ext4_update_dx_flag(old_dir);	if (dir_bh) {		PARENT_INO(dir_bh->b_data, new_dir->i_sb->s_blocksize) =						cpu_to_le32(new_dir->i_ino);		BUFFER_TRACE(dir_bh, ""call ext4_handle_dirty_metadata"");		if (is_dx(old_inode)) {			retval = ext4_handle_dirty_dx_node(handle,							   old_inode,							   dir_bh);		} else {			retval = ext4_handle_dirty_dirent_node(handle,							       old_inode,							       dir_bh);		}		if (retval) {			ext4_std_error(old_dir->i_sb, retval);			goto end_rename;		}		ext4_dec_count(handle, old_dir);		if (new_inode) {			 			clear_nlink(new_inode);		} else {			ext4_inc_count(handle, new_dir);			ext4_update_dx_flag(new_dir);			ext4_mark_inode_dirty(handle, new_dir);		}	}	ext4_mark_inode_dirty(handle, old_dir);	if (new_inode) {		ext4_mark_inode_dirty(handle, new_inode);		if (!new_inode->i_nlink)			ext4_orphan_add(handle, new_inode);		if (!test_opt(new_dir->i_sb, NO_AUTO_DA_ALLOC))			force_da_alloc = 1;	}	retval = 0;end_rename:	brelse(dir_bh);	brelse(old_bh);	brelse(new_bh);	ext4_journal_stop(handle);	if (retval == 0 && force_da_alloc)		ext4_alloc_da_blocks(old_inode);	return retval;}",13098
65,2388,CVE-2017-18200,24,"static int f2fs_clear_qf_name(struct super_block *sb, int qtype){	struct f2fs_sb_info *sbi = F2FS_SB(sb);	if (sb_any_quota_loaded(sb) && sbi->s_qf_names[qtype]) {		f2fs_msg(sb, KERN_ERR, ""Cannot change journaled quota options""			"" when quota turned on"");		return -EINVAL;	}	kfree(sbi->s_qf_names[qtype]);	sbi->s_qf_names[qtype] = NULL;	return 0;}",26048
509,685,CVE-2013-6368,24,"static int kvm_vcpu_ioctl_interrupt(struct kvm_vcpu *vcpu,				    struct kvm_interrupt *irq){	if (irq->irq >= KVM_NR_INTERRUPTS)		return -EINVAL;	if (irqchip_in_kernel(vcpu->kvm))		return -ENXIO;	kvm_queue_interrupt(vcpu, irq->irq, false);	kvm_make_request(KVM_REQ_EVENT, vcpu);	return 0;}",7452
173,1331,CVE-2014-2038,24,"void nfs_pageio_init_write(struct nfs_pageio_descriptor *pgio,			       struct inode *inode, int ioflags,			       const struct nfs_pgio_completion_ops *compl_ops){	nfs_pageio_init(pgio, inode, &nfs_pageio_write_ops, compl_ops,				NFS_SERVER(inode)->wsize, ioflags);}",11878
626,1924,CVE-2016-2548,24,"int snd_timer_continue(struct snd_timer_instance *timeri){	struct snd_timer *timer;	int result = -EINVAL;	unsigned long flags;	if (timeri == NULL)		return result;	if (timeri->flags & SNDRV_TIMER_IFLG_SLAVE)		return snd_timer_start_slave(timeri);	timer = timeri->timer;	if (! timer)		return -EINVAL;	spin_lock_irqsave(&timer->lock, flags);	if (!timeri->cticks)		timeri->cticks = 1;	timeri->pticks = 0;	result = snd_timer_start1(timer, timeri, timer->sticks);	spin_unlock_irqrestore(&timer->lock, flags);	snd_timer_notify1(timeri, SNDRV_TIMER_EVENT_CONTINUE);	return result;}",17507
491,521,CVE-2012-2136,24,"static char *sock_prot_memory_pressure(struct proto *proto){	return proto->memory_pressure != NULL ?	proto_memory_pressure(proto) ? ""yes"" : ""no"" : ""NI"";}",3480
534,528,CVE-2012-2136,24,"void sock_wfree(struct sk_buff *skb){	struct sock *sk = skb->sk;	unsigned int len = skb->truesize;	if (!sock_flag(sk, SOCK_USE_WRITE_QUEUE)) {		 		atomic_sub(len - 1, &sk->sk_wmem_alloc);		sk->sk_write_space(sk);		len = 1;	}	 	if (atomic_sub_and_test(len, &sk->sk_wmem_alloc))		__sk_free(sk);}",3487
634,1683,CVE-2013-7271,24,"static unsigned int run_filter(const struct sk_buff *skb,				      const struct sock *sk,				      unsigned int res){	struct sk_filter *filter;	rcu_read_lock();	filter = rcu_dereference(sk->sk_filter);	if (filter != NULL)		res = SK_RUN_FILTER(filter, skb);	rcu_read_unlock();	return res;}",12571
595,1907,CVE-2016-5358,24,"proto_reg_handoff_pktap(void){	dissector_add_uint(""wtap_encap"", WTAP_ENCAP_PKTAP, pktap_handle);}",16472
29,1040,CVE-2014-3645,24,"static int kvm_age_rmapp(struct kvm *kvm, unsigned long *rmapp,			 struct kvm_memory_slot *slot, unsigned long data){	u64 *sptep;	struct rmap_iterator uninitialized_var(iter);	int young = 0;	 	if (!shadow_accessed_mask) {		young = kvm_unmap_rmapp(kvm, rmapp, slot, data);		goto out;	}	for (sptep = rmap_get_first(*rmapp, &iter); sptep;	     sptep = rmap_get_next(&iter)) {		BUG_ON(!is_shadow_present_pte(*sptep));		if (*sptep & shadow_accessed_mask) {			young = 1;			clear_bit((ffs(shadow_accessed_mask) - 1),				 (unsigned long *)sptep);		}	}out:	 	trace_kvm_age_page(data, slot, young);	return young;}",11174
581,334,CVE-2016-6302,24,"static void get_sigorhash(int *psig, int *phash, const char *str){    if (strcmp(str, ""RSA"") == 0) {        *psig = EVP_PKEY_RSA;    } else if (strcmp(str, ""DSA"") == 0) {        *psig = EVP_PKEY_DSA;    } else if (strcmp(str, ""ECDSA"") == 0) {        *psig = EVP_PKEY_EC;    } else {        *phash = OBJ_sn2nid(str);        if (*phash == NID_undef)            *phash = OBJ_ln2nid(str);    }}",1652
273,2343,CVE-2018-14361,24,"static int nntp_mbox_close(struct Context *ctx){  struct NntpData *nntp_data = ctx->data, *nntp_tmp = NULL;  if (!nntp_data)    return 0;  nntp_data->unread = ctx->unread;  nntp_acache_free(nntp_data);  if (!nntp_data->nserv || !nntp_data->nserv->groups_hash || !nntp_data->group)    return 0;  nntp_tmp = mutt_hash_find(nntp_data->nserv->groups_hash, nntp_data->group);  if (nntp_tmp == NULL || nntp_tmp != nntp_data)    nntp_data_free(nntp_data);  return 0;}",24488
112,2076,CVE-2017-15951,24,"long keyctl_set_reqkey_keyring(int reqkey_defl){	struct cred *new;	int ret, old_setting;	old_setting = current_cred_xxx(jit_keyring);	if (reqkey_defl == KEY_REQKEY_DEFL_NO_CHANGE)		return old_setting;	new = prepare_creds();	if (!new)		return -ENOMEM;	switch (reqkey_defl) {	case KEY_REQKEY_DEFL_THREAD_KEYRING:		ret = install_thread_keyring_to_cred(new);		if (ret < 0)			goto error;		goto set;	case KEY_REQKEY_DEFL_PROCESS_KEYRING:		ret = install_process_keyring_to_cred(new);		if (ret < 0)			goto error;		goto set;	case KEY_REQKEY_DEFL_DEFAULT:	case KEY_REQKEY_DEFL_SESSION_KEYRING:	case KEY_REQKEY_DEFL_USER_KEYRING:	case KEY_REQKEY_DEFL_USER_SESSION_KEYRING:	case KEY_REQKEY_DEFL_REQUESTOR_KEYRING:		goto set;	case KEY_REQKEY_DEFL_NO_CHANGE:	case KEY_REQKEY_DEFL_GROUP_KEYRING:	default:		ret = -EINVAL;		goto error;	}set:	new->jit_keyring = reqkey_defl;	commit_creds(new);	return old_setting;error:	abort_creds(new);	return ret;}",19899
539,1526,CVE-2013-7271,24,"static int ltalk_rcv(struct sk_buff *skb, struct net_device *dev,		     struct packet_type *pt, struct net_device *orig_dev){	if (!net_eq(dev_net(dev), &init_net))		goto freeit;	 	if (skb_mac_header(skb)[2] == 1) {		struct ddpehdr *ddp;		 		struct atalk_addr *ap = atalk_find_dev_addr(dev);		if (!ap || skb->len < sizeof(__be16) || skb->len > 1023)			goto freeit;		 		if (!(skb = skb_share_check(skb, GFP_ATOMIC)))			return 0;		 		ddp = (struct ddpehdr *) skb_push(skb, sizeof(*ddp) - 4);		 		 		ddp->deh_dnode = skb_mac_header(skb)[0];      		ddp->deh_snode = skb_mac_header(skb)[1];      		ddp->deh_dnet  = ap->s_net;	 		ddp->deh_snet  = ap->s_net;		ddp->deh_sum   = 0;		 		 		 		ddp->deh_len_hops = htons(skb->len + (DDP_MAXHOPS << 10));	}	skb_reset_transport_header(skb);	return atalk_rcv(skb, dev, pt, orig_dev);freeit:	kfree_skb(skb);	return 0;}",12414
18,1651,CVE-2013-7271,24,"static void init_prb_bdqc(struct packet_sock *po,			struct packet_ring_buffer *rb,			struct pgv *pg_vec,			union tpacket_req_u *req_u, int tx_ring){	struct tpacket_kbdq_core *p1 = &rb->prb_bdqc;	struct tpacket_block_desc *pbd;	memset(p1, 0x0, sizeof(*p1));	p1->knxt_seq_num = 1;	p1->pkbdq = pg_vec;	pbd = (struct tpacket_block_desc *)pg_vec[0].buffer;	p1->pkblk_start	= pg_vec[0].buffer;	p1->kblk_size = req_u->req3.tp_block_size;	p1->knum_blocks	= req_u->req3.tp_block_nr;	p1->hdrlen = po->tp_hdrlen;	p1->version = po->tp_version;	p1->last_kactive_blk_num = 0;	po->stats.stats3.tp_freeze_q_cnt = 0;	if (req_u->req3.tp_retire_blk_tov)		p1->retire_blk_tov = req_u->req3.tp_retire_blk_tov;	else		p1->retire_blk_tov = prb_calc_retire_blk_tmo(po,						req_u->req3.tp_block_size);	p1->tov_in_jiffies = msecs_to_jiffies(p1->retire_blk_tov);	p1->blk_sizeof_priv = req_u->req3.tp_sizeof_priv;	prb_init_ft_ops(p1, req_u);	prb_setup_retire_blk_timer(po, tx_ring);	prb_open_block(p1, pbd);}",12539
453,1517,CVE-2013-7271,24,"static int atif_proxy_probe_device(struct atalk_iface *atif,				   struct atalk_addr* proxy_addr){	int netrange = ntohs(atif->nets.nr_lastnet) -			ntohs(atif->nets.nr_firstnet) + 1;	 	int probe_net = ntohs(atif->address.s_net);	int probe_node = ATADDR_ANYNODE;	     	int netct, nodect;	 	if (probe_net == ATADDR_ANYNET) {		probe_net = ntohs(atif->nets.nr_firstnet);		if (netrange)			probe_net += jiffies % netrange;	}	if (probe_node == ATADDR_ANYNODE)		probe_node = jiffies & 0xFF;	 	for (netct = 0; netct <= netrange; netct++) {		 		proxy_addr->s_net = htons(probe_net);		for (nodect = 0; nodect < 256; nodect++) {			proxy_addr->s_node = (nodect + probe_node) & 0xFF;			if (proxy_addr->s_node > 0 &&			    proxy_addr->s_node < 254) {				 				int ret = aarp_proxy_probe_network(atif,								    proxy_addr);				if (ret != -EADDRINUSE)					return ret;			}		}		probe_net++;		if (probe_net > ntohs(atif->nets.nr_lastnet))			probe_net = ntohs(atif->nets.nr_firstnet);	}	return -EADDRINUSE;	 }",12405
545,1400,CVE-2014-0203,24,static inline int lookup_flags(unsigned int f){	unsigned long retval = LOOKUP_FOLLOW;	if (f & O_NOFOLLOW)		retval &= ~LOOKUP_FOLLOW;		if (f & O_DIRECTORY)		retval |= LOOKUP_DIRECTORY;	return retval;},12110
600,2181,CVE-2017-7645,24,"int nfsd_pool_stats_open(struct inode *inode, struct file *file){	int ret;	struct nfsd_net *nn = net_generic(inode->i_sb->s_fs_info, nfsd_net_id);	mutex_lock(&nfsd_mutex);	if (nn->nfsd_serv == NULL) {		mutex_unlock(&nfsd_mutex);		return -ENODEV;	}	 	svc_get(nn->nfsd_serv);	ret = svc_pool_stats_open(nn->nfsd_serv, file);	mutex_unlock(&nfsd_mutex);	return ret;}",21509
541,105,CVE-2015-5296,24,int smbXcli_conn_max_requests(struct smbXcli_conn *conn){	if (conn->protocol >= PROTOCOL_SMB2_02) {		 		return 1;	}	return conn->smb1.server.max_mux;},513
436,1357,CVE-2014-2038,24,"int nfs_writepage(struct page *page, struct writeback_control *wbc){	int ret;	ret = nfs_writepage_locked(page, wbc);	unlock_page(page);	return ret;}",11904
268,1870,CVE-2016-9191,24,static void start_unregistering(struct ctl_table_header *p){	 	if (unlikely(p->used)) {		struct completion wait;		init_completion(&wait);		p->unregistering = &wait;		spin_unlock(&sysctl_lock);		wait_for_completion(&wait);		spin_lock(&sysctl_lock);	} else {		 		p->unregistering = ERR_PTR(-EINVAL);	}	 	erase_header(p);},15231
37,2742,CVE-2016-3760,24,"static int is_shell_running(void) { char property_str[100];  property_get(""init.svc.zygote"", property_str, NULL); if (!strcmp(""running"", property_str)) { return true; } return false;}",30553
533,1139,CVE-2014-2739,24,"static struct cm_id_private * cm_acquire_mraed_id(struct cm_mra_msg *mra_msg){	switch (cm_mra_get_msg_mraed(mra_msg)) {	case CM_MSG_RESPONSE_REQ:		return cm_acquire_id(mra_msg->remote_comm_id, 0);	case CM_MSG_RESPONSE_REP:	case CM_MSG_RESPONSE_OTHER:		return cm_acquire_id(mra_msg->remote_comm_id,				     mra_msg->local_comm_id);	default:		return NULL;	}}",11614
402,1005,CVE-2014-4503,24,"int restart_stratum(struct pool *pool){	applog(LOG_DEBUG, ""Restarting stratum on pool %s"", get_pool_name(pool));	if (pool->stratum_active)		suspend_stratum(pool);	if (!initiate_stratum(pool))		return false;	if (pool->extranonce_subscribe && !subscribe_extranonce(pool))		return false;	if (!auth_stratum(pool))		return false;	return true;}",10873
382,2314,CVE-2018-17456,24,"static int fsck_msg_type(enum fsck_msg_id msg_id,	struct fsck_options *options){	int msg_type;	assert(msg_id >= 0 && msg_id < FSCK_MSG_MAX);	if (options->msg_type)		msg_type = options->msg_type[msg_id];	else {		msg_type = msg_id_info[msg_id].msg_type;		if (options->strict && msg_type == FSCK_WARN)			msg_type = FSCK_ERROR;	}	return msg_type;}",23606
636,1748,CVE-2015-8215,24,"static void  __ipv6_try_regen_rndid(struct inet6_dev *idev, struct in6_addr *tmpaddr){	if (tmpaddr && memcmp(idev->rndid, &tmpaddr->s6_addr[8], 8) == 0)		__ipv6_regen_rndid(idev);}",12958
285,2616,CVE-2018-18358,24,"  void AddSSLSocketData() {    ssl_.next_proto = kProtoHTTP2;    ssl_.ssl_info.cert =        ImportCertFromFile(GetTestCertsDirectory(), ""spdy_pooling.pem"");    ASSERT_TRUE(ssl_.ssl_info.cert);    session_deps_.socket_factory->AddSSLSocketDataProvider(&ssl_);  }",30022
297,76,CVE-2015-5296,24,int smb1cli_conn_server_time_zone(struct smbXcli_conn *conn){	return conn->smb1.server.time_zone;},484
661,1325,CVE-2014-2038,24,"nfs_mark_request_commit(struct nfs_page *req, struct pnfs_layout_segment *lseg,			struct nfs_commit_info *cinfo){}",11872
258,1468,CVE-2014-0077,24,"vhost_net_ubuf_alloc(struct vhost_virtqueue *vq, int zcopy){	struct vhost_net_ubuf_ref *ubufs;	 	if (!zcopy)		return NULL;	ubufs = kmalloc(sizeof(*ubufs), GFP_KERNEL);	if (!ubufs)		return ERR_PTR(-ENOMEM);	atomic_set(&ubufs->refcount, 1);	init_waitqueue_head(&ubufs->wait);	ubufs->vq = vq;	return ubufs;}",12281
597,392,CVE-2009-2624,24,"int inflate() {  int e;                   int r;                   unsigned h;                 wp = 0;  bk = 0;  bb = 0;     h = 0;  do {    hufts = 0;    if ((r = inflate_block(&e)) != 0)      return r;    if (hufts > h)      h = hufts;  } while (!e);     while (bk >= 8) {    bk -= 8;    inptr--;  }     flush_output(wp);     Trace ((stderr, ""<%u> "", h));  return 0;}",2220
639,2667,CVE-2018-6089,24,"  void WriteServiceWorkerFetchTestFiles() {    WriteFile(FILE_PATH_LITERAL(""sw.js""),              ""this.onactivate = function(event) {""              ""  event.waitUntil(self.clients.claim());""              ""};""              ""this.onfetch = function(event) {""              ""  event.respondWith(""              ""      self.clients.matchAll().then(function(clients) {""              ""          clients.forEach(function(client) {""              ""              client.postMessage(""              ""                'url:' + event.request.url + ', ' +""              ""                'mode:' + event.request.mode + ', ' +""              ""                'credentials:' + event.request.credentials""              ""              );""              ""            });""              ""          return fetch(event.request);""              ""        }));""              ""};"");    WriteFile(FILE_PATH_LITERAL(""test.html""),              ""<script>""              ""navigator.serviceWorker.register('./sw.js', {scope: './'})""              ""  .then(function(reg) {""              ""      reg.addEventListener('updatefound', function() {""              ""          var worker = reg.installing;""              ""          worker.addEventListener('statechange', function() {""              ""              if (worker.state == 'activated')""              ""                document.title = 'READY';""              ""            });""              ""        });""              ""    });""              ""var reportOnFetch = true;""              ""var issuedRequests = [];""              ""function reportRequests() {""              ""  var str = '';""              ""  issuedRequests.forEach(function(data) {""              ""      str += data + '\\n';""              ""    });""              ""  window.domAutomationController.send(str);""              ""}""              ""navigator.serviceWorker.addEventListener(""              ""    'message',""              ""    function(event) {""              ""      issuedRequests.push(event.data);""              ""      if (reportOnFetch) {""              ""        reportRequests();""              ""      }""              ""    }, false);""              ""</script>"");  }",30099
229,2003,CVE-2017-1000252,24,"void kvm_register_irq_ack_notifier(struct kvm *kvm,				   struct kvm_irq_ack_notifier *kian){	mutex_lock(&kvm->irq_lock);	hlist_add_head_rcu(&kian->link, &kvm->irq_ack_notifier_list);	mutex_unlock(&kvm->irq_lock);	kvm_arch_post_irq_ack_notifier_list_update(kvm);}",19464
203,1215,CVE-2014-2739,24,"static int cma_ib_mc_handler(int status, struct ib_sa_multicast *multicast){	struct rdma_id_private *id_priv;	struct cma_multicast *mc = multicast->context;	struct rdma_cm_event event;	int ret;	id_priv = mc->id_priv;	if (cma_disable_callback(id_priv, RDMA_CM_ADDR_BOUND) &&	    cma_disable_callback(id_priv, RDMA_CM_ADDR_RESOLVED))		return 0;	if (!status)		status = cma_set_qkey(id_priv, be32_to_cpu(multicast->rec.qkey));	mutex_lock(&id_priv->qp_mutex);	if (!status && id_priv->id.qp)		status = ib_attach_mcast(id_priv->id.qp, &multicast->rec.mgid,					 be16_to_cpu(multicast->rec.mlid));	mutex_unlock(&id_priv->qp_mutex);	memset(&event, 0, sizeof event);	event.status = status;	event.param.ud.private_data = mc->context;	if (!status) {		event.event = RDMA_CM_EVENT_MULTICAST_JOIN;		ib_init_ah_from_mcmember(id_priv->id.device,					 id_priv->id.port_num, &multicast->rec,					 &event.param.ud.ah_attr);		event.param.ud.qp_num = 0xFFFFFF;		event.param.ud.qkey = be32_to_cpu(multicast->rec.qkey);	} else		event.event = RDMA_CM_EVENT_MULTICAST_ERROR;	ret = id_priv->id.event_handler(&id_priv->id, &event);	if (ret) {		cma_exch(id_priv, RDMA_CM_DESTROYING);		mutex_unlock(&id_priv->handler_mutex);		rdma_destroy_id(&id_priv->id);		return 0;	}	mutex_unlock(&id_priv->handler_mutex);	return 0;}",11690
437,1493,CVE-2013-7271,24,"static inline struct pppoe_net *pppoe_pernet(struct net *net){	BUG_ON(!net);	return net_generic(net, pppoe_net_id);}",12381
507,1796,CVE-2015-8215,24,"static int inet6_rtm_getaddr(struct sk_buff *in_skb, struct nlmsghdr *nlh){	struct net *net = sock_net(in_skb->sk);	struct ifaddrmsg *ifm;	struct nlattr *tb[IFA_MAX+1];	struct in6_addr *addr = NULL, *peer;	struct net_device *dev = NULL;	struct inet6_ifaddr *ifa;	struct sk_buff *skb;	int err;	err = nlmsg_parse(nlh, sizeof(*ifm), tb, IFA_MAX, ifa_ipv6_policy);	if (err < 0)		goto errout;	addr = extract_addr(tb[IFA_ADDRESS], tb[IFA_LOCAL], &peer);	if (addr == NULL) {		err = -EINVAL;		goto errout;	}	ifm = nlmsg_data(nlh);	if (ifm->ifa_index)		dev = __dev_get_by_index(net, ifm->ifa_index);	ifa = ipv6_get_ifaddr(net, addr, dev, 1);	if (!ifa) {		err = -EADDRNOTAVAIL;		goto errout;	}	skb = nlmsg_new(inet6_ifaddr_msgsize(), GFP_KERNEL);	if (!skb) {		err = -ENOBUFS;		goto errout_ifa;	}	err = inet6_fill_ifaddr(skb, ifa, NETLINK_CB(in_skb).portid,				nlh->nlmsg_seq, RTM_NEWADDR, 0);	if (err < 0) {		 		WARN_ON(err == -EMSGSIZE);		kfree_skb(skb);		goto errout_ifa;	}	err = rtnl_unicast(skb, net, NETLINK_CB(in_skb).portid);errout_ifa:	in6_ifa_put(ifa);errout:	return err;}",13006
642,1026,CVE-2014-3645,24,static void destroy_kvm_mmu(struct kvm_vcpu *vcpu){	ASSERT(vcpu);	if (VALID_PAGE(vcpu->arch.mmu.root_hpa))		 		vcpu->arch.mmu.free(vcpu);},11160
143,2069,CVE-2017-15951,24,static int dns_resolver_match_preparse(struct key_match_data *match_data){	match_data->lookup_type = KEYRING_SEARCH_LOOKUP_ITERATE;	match_data->cmp = dns_resolver_cmp;	return 0;},19892
378,2188,CVE-2017-7645,24,"static int nfsd_startup_net(int nrservs, struct net *net){	struct nfsd_net *nn = net_generic(net, nfsd_net_id);	int ret;	if (nn->nfsd_net_up)		return 0;	ret = nfsd_startup_generic(nrservs);	if (ret)		return ret;	ret = nfsd_init_socks(net);	if (ret)		goto out_socks;	if (nfsd_needs_lockd() && !nn->lockd_up) {		ret = lockd_up(net);		if (ret)			goto out_socks;		nn->lockd_up = 1;	}	ret = nfs4_state_start_net(net);	if (ret)		goto out_lockd;	nn->nfsd_net_up = true;	return 0;out_lockd:	if (nn->lockd_up) {		lockd_down(net);		nn->lockd_up = 0;	}out_socks:	nfsd_shutdown_generic();	return ret;}",21516
200,1737,CVE-2013-7271,24,"int x25_rx_call_request(struct sk_buff *skb, struct x25_neigh *nb,			unsigned int lci){	struct sock *sk;	struct sock *make;	struct x25_sock *makex25;	struct x25_address source_addr, dest_addr;	struct x25_facilities facilities;	struct x25_dte_facilities dte_facilities;	int len, addr_len, rc;	 	skb_pull(skb, X25_STD_MIN_LEN);	 	addr_len = x25_parse_address_block(skb, &source_addr, &dest_addr);	if (addr_len <= 0)		goto out_clear_request;	skb_pull(skb, addr_len);	 	if (!pskb_may_pull(skb, 1))		goto out_clear_request;	len = skb->data[0] + 1;	if (!pskb_may_pull(skb, len))		goto out_clear_request;	skb_pull(skb,len);	 	if (skb->len > X25_MAX_CUD_LEN)		goto out_clear_request;	 	if (!pskb_may_pull(skb, skb->len))		goto out_clear_request;	 	sk = x25_find_listener(&source_addr,skb);	skb_push(skb,len);	if (sk != NULL && sk_acceptq_is_full(sk)) {		goto out_sock_put;	}	 	if (sk == NULL) {		skb_push(skb, addr_len + X25_STD_MIN_LEN);		if (sysctl_x25_forward &&				x25_forward_call(&dest_addr, nb, skb, lci) > 0)		{			 			kfree_skb(skb);			rc = 1;			goto out;		} else {			 			goto out_clear_request;		}	}	 	len = x25_negotiate_facilities(skb, sk, &facilities, &dte_facilities);	if (len == -1)		goto out_sock_put;	 	x25_limit_facilities(&facilities, nb);	 	make = x25_make_new(sk);	if (!make)		goto out_sock_put;	 	skb_pull(skb, len);	skb->sk     = make;	make->sk_state = TCP_ESTABLISHED;	makex25 = x25_sk(make);	makex25->lci           = lci;	makex25->dest_addr     = dest_addr;	makex25->source_addr   = source_addr;	makex25->neighbour     = nb;	makex25->facilities    = facilities;	makex25->dte_facilities= dte_facilities;	makex25->vc_facil_mask = x25_sk(sk)->vc_facil_mask;	 	makex25->vc_facil_mask &= ~X25_MASK_REVERSE;	 	makex25->vc_facil_mask &= ~X25_MASK_CALLING_AE;	makex25->cudmatchlength = x25_sk(sk)->cudmatchlength;	 	if (test_bit(X25_ACCPT_APPRV_FLAG, &makex25->flags)) {		x25_write_internal(make, X25_CALL_ACCEPTED);		makex25->state = X25_STATE_3;	}	 	skb_copy_from_linear_data(skb, makex25->calluserdata.cuddata, skb->len);	makex25->calluserdata.cudlength = skb->len;	sk->sk_ack_backlog++;	x25_insert_socket(make);	skb_queue_head(&sk->sk_receive_queue, skb);	x25_start_heartbeat(make);	if (!sock_flag(sk, SOCK_DEAD))		sk->sk_data_ready(sk, skb->len);	rc = 1;	sock_put(sk);out:	return rc;out_sock_put:	sock_put(sk);out_clear_request:	rc = 0;	x25_transmit_clear_request(nb, lci, 0x01);	goto out;}",12625
683,2204,CVE-2017-6345,24,"static void llc_do_mcast(struct llc_sap *sap, struct sk_buff *skb,			 struct sock **stack, int count){	struct sk_buff *skb1;	int i;	for (i = 0; i < count; i++) {		skb1 = skb_clone(skb, GFP_ATOMIC);		if (!skb1) {			sock_put(stack[i]);			continue;		}		llc_sap_rcv(sap, skb1, stack[i]);		sock_put(stack[i]);	}}",21837
218,2172,CVE-2017-7645,24,"nfsd_adjust_nfsd_versions4(void){	unsigned i;	for (i = 0; i <= NFSD_SUPPORTED_MINOR_VERSION; i++) {		if (nfsd_supported_minorversions[i])			return;	}	nfsd_vers(4, NFSD_CLEAR);}",21500
104,306,CVE-2014-7840,24,double xbzrle_mig_cache_miss_rate(void){    return acct_info.xbzrle_cache_miss_rate;},1306
226,1604,CVE-2013-7271,24,struct sock *netlink_getsockbyfilp(struct file *filp){	struct inode *inode = file_inode(filp);	struct sock *sock;	if (!S_ISSOCK(inode->i_mode))		return ERR_PTR(-ENOTSOCK);	sock = SOCKET_I(inode)->sk;	if (sock->sk_family != AF_NETLINK)		return ERR_PTR(-EINVAL);	sock_hold(sock);	return sock;},12492
599,2673,CVE-2017-15420,24,  BrowserSideNavigationBrowserDisableWebSecurityTest() {},30139
316,1688,CVE-2013-7271,24,"void __sock_recv_timestamp(struct msghdr *msg, struct sock *sk,	struct sk_buff *skb){	int need_software_tstamp = sock_flag(sk, SOCK_RCVTSTAMP);	struct timespec ts[3];	int empty = 1;	struct skb_shared_hwtstamps *shhwtstamps =		skb_hwtstamps(skb);	 	if (need_software_tstamp && skb->tstamp.tv64 == 0)		__net_timestamp(skb);	if (need_software_tstamp) {		if (!sock_flag(sk, SOCK_RCVTSTAMPNS)) {			struct timeval tv;			skb_get_timestamp(skb, &tv);			put_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMP,				 sizeof(tv), &tv);		} else {			skb_get_timestampns(skb, &ts[0]);			put_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMPNS,				 sizeof(ts[0]), &ts[0]);		}	}	memset(ts, 0, sizeof(ts));	if (sock_flag(sk, SOCK_TIMESTAMPING_SOFTWARE) &&	    ktime_to_timespec_cond(skb->tstamp, ts + 0))		empty = 0;	if (shhwtstamps) {		if (sock_flag(sk, SOCK_TIMESTAMPING_SYS_HARDWARE) &&		    ktime_to_timespec_cond(shhwtstamps->syststamp, ts + 1))			empty = 0;		if (sock_flag(sk, SOCK_TIMESTAMPING_RAW_HARDWARE) &&		    ktime_to_timespec_cond(shhwtstamps->hwtstamp, ts + 2))			empty = 0;	}	if (!empty)		put_cmsg(msg, SOL_SOCKET,			 SCM_TIMESTAMPING, sizeof(ts), &ts);}",12576
493,810,CVE-2013-1848,24,static void destroy_inodecache(void){	 	rcu_barrier();	kmem_cache_destroy(ext3_inode_cachep);},9366
93,511,CVE-2012-2136,24,"int sock_no_connect(struct socket *sock, struct sockaddr *saddr,		    int len, int flags){	return -EOPNOTSUPP;}",3470
460,2477,CVE-2010-1152,24,"static enum test_return test_binary_replaceq(void) {    return test_binary_replace_impl(""test_binary_replaceq"",                                    PROTOCOL_BINARY_CMD_REPLACEQ);}",28234
3,1113,CVE-2014-3645,24,"static void ept_load_pdptrs(struct kvm_vcpu *vcpu){	if (!test_bit(VCPU_EXREG_PDPTR,		      (unsigned long *)&vcpu->arch.regs_dirty))		return;	if (is_paging(vcpu) && is_pae(vcpu) && !is_long_mode(vcpu)) {		vmcs_write64(GUEST_PDPTR0, vcpu->arch.mmu.pdptrs[0]);		vmcs_write64(GUEST_PDPTR1, vcpu->arch.mmu.pdptrs[1]);		vmcs_write64(GUEST_PDPTR2, vcpu->arch.mmu.pdptrs[2]);		vmcs_write64(GUEST_PDPTR3, vcpu->arch.mmu.pdptrs[3]);	}}",11247
4,2703,CVE-2016-3760,24,static void dump(int fd){    btif_debug_dump(fd);},30514
593,2308,CVE-2018-17456,24,"static int fsck_blob(struct blob *blob, const char *buf,		     unsigned long size, struct fsck_options *options){	struct fsck_gitmodules_data data;	if (!oidset_contains(&gitmodules_found, &blob->object.oid))		return 0;	oidset_insert(&gitmodules_done, &blob->object.oid);	if (!buf) {		 		return report(options, &blob->object,			      FSCK_MSG_GITMODULES_PARSE,			      "".gitmodules too large to parse"");	}	data.obj = &blob->object;	data.options = options;	data.ret = 0;	if (git_config_from_mem(fsck_gitmodules_fn, CONFIG_ORIGIN_BLOB,				"".gitmodules"", buf, size, &data))		data.ret |= report(options, &blob->object,				   FSCK_MSG_GITMODULES_PARSE,				   ""could not parse gitmodules blob"");	return data.ret;}",23600
319,1889,CVE-2016-6197,24,"static int ovl_create_over_whiteout(struct dentry *dentry, struct inode *inode,				    struct kstat *stat, const char *link,				    struct dentry *hardlink){	struct dentry *workdir = ovl_workdir(dentry);	struct inode *wdir = workdir->d_inode;	struct dentry *upperdir = ovl_dentry_upper(dentry->d_parent);	struct inode *udir = upperdir->d_inode;	struct dentry *upper;	struct dentry *newdentry;	int err;	if (WARN_ON(!workdir))		return -EROFS;	err = ovl_lock_rename_workdir(workdir, upperdir);	if (err)		goto out;	newdentry = ovl_lookup_temp(workdir, dentry);	err = PTR_ERR(newdentry);	if (IS_ERR(newdentry))		goto out_unlock;	upper = lookup_one_len(dentry->d_name.name, upperdir,			       dentry->d_name.len);	err = PTR_ERR(upper);	if (IS_ERR(upper))		goto out_dput;	err = ovl_create_real(wdir, newdentry, stat, link, hardlink, true);	if (err)		goto out_dput2;	if (S_ISDIR(stat->mode)) {		err = ovl_set_opaque(newdentry);		if (err)			goto out_cleanup;		err = ovl_do_rename(wdir, newdentry, udir, upper,				    RENAME_EXCHANGE);		if (err)			goto out_cleanup;		ovl_cleanup(wdir, upper);	} else {		err = ovl_do_rename(wdir, newdentry, udir, upper, 0);		if (err)			goto out_cleanup;	}	ovl_dentry_version_inc(dentry->d_parent);	ovl_dentry_update(dentry, newdentry);	ovl_copyattr(newdentry->d_inode, inode);	d_instantiate(dentry, inode);	newdentry = NULL;out_dput2:	dput(upper);out_dput:	dput(newdentry);out_unlock:	unlock_rename(workdir, upperdir);out:	return err;out_cleanup:	ovl_cleanup(wdir, newdentry);	goto out_dput2;}",16244
75,2623,CVE-2018-20068,24,"  int did_replace_entry() {    EXPECT_EQ(1U, did_replace_entries_.size());    return did_replace_entries_[0];  }",30038
48,206,CVE-2011-1428,24,"irc_server_set_nicks (struct t_irc_server *server, const char *nicks){         server->nicks_count = 0;    if (server->nicks_array)    {        weechat_string_free_split (server->nicks_array);        server->nicks_array = NULL;    }             server->nicks_array = weechat_string_split ((nicks) ? nicks : IRC_SERVER_DEFAULT_NICKS,                                                "","", 0, 0,                                                &server->nicks_count);}",700
117,515,CVE-2012-2136,24,"int sock_no_mmap(struct file *file, struct socket *sock, struct vm_area_struct *vma){	 	return -ENODEV;}",3474
421,1236,CVE-2014-2739,24,"static void cma_save_ib_info(struct rdma_cm_id *id, struct rdma_cm_id *listen_id,			     struct ib_sa_path_rec *path){	struct sockaddr_ib *listen_ib, *ib;	listen_ib = (struct sockaddr_ib *) &listen_id->route.addr.src_addr;	ib = (struct sockaddr_ib *) &id->route.addr.src_addr;	ib->sib_family = listen_ib->sib_family;	ib->sib_pkey = path->pkey;	ib->sib_flowinfo = path->flow_label;	memcpy(&ib->sib_addr, &path->sgid, 16);	ib->sib_sid = listen_ib->sib_sid;	ib->sib_sid_mask = cpu_to_be64(0xffffffffffffffffULL);	ib->sib_scope_id = listen_ib->sib_scope_id;	ib = (struct sockaddr_ib *) &id->route.addr.dst_addr;	ib->sib_family = listen_ib->sib_family;	ib->sib_pkey = path->pkey;	ib->sib_flowinfo = path->flow_label;	memcpy(&ib->sib_addr, &path->dgid, 16);}",11711
440,180,CVE-2011-1428,24,"irc_server_get_prefix_char_index (struct t_irc_server *server,                                  char prefix_char){    const char *prefix_chars;    char *pos;        if (server)    {        prefix_chars = irc_server_get_prefix_chars (server);        pos = strchr (prefix_chars, prefix_char);        if (pos)            return pos - prefix_chars;    }        return -1;}",674
43,374,CVE-2016-4071,24,"PHP_FUNCTION(snmp2_get){	php_snmp(INTERNAL_FUNCTION_PARAM_PASSTHRU, SNMP_CMD_GET, SNMP_VERSION_2c);}",1944
352,1376,CVE-2014-1874,24,int selinux_audit_rule_known(struct audit_krule *rule){	int i;	for (i = 0; i < rule->field_count; i++) {		struct audit_field *f = &rule->fields[i];		switch (f->type) {		case AUDIT_SUBJ_USER:		case AUDIT_SUBJ_ROLE:		case AUDIT_SUBJ_TYPE:		case AUDIT_SUBJ_SEN:		case AUDIT_SUBJ_CLR:		case AUDIT_OBJ_USER:		case AUDIT_OBJ_ROLE:		case AUDIT_OBJ_TYPE:		case AUDIT_OBJ_LEV_LOW:		case AUDIT_OBJ_LEV_HIGH:			return 1;		}	}	return 0;},11926
380,329,CVE-2017-5932,24,num_fifos (){  return nfifo;},1633
513,1481,CVE-2013-7271,24,"static void mISDN_sock_unlink(struct mISDN_sock_list *l, struct sock *sk){	write_lock_bh(&l->lock);	sk_del_node_init(sk);	write_unlock_bh(&l->lock);}",12369
40,444,CVE-2017-7539,24,int nbd_client(int fd){    return -ENOTSUP;},2585
41,1440,CVE-2014-0203,24,"static struct dentry *proc_base_instantiate(struct inode *dir,	struct dentry *dentry, struct task_struct *task, const void *ptr){	const struct pid_entry *p = ptr;	struct inode *inode;	struct proc_inode *ei;	struct dentry *error = ERR_PTR(-EINVAL);	 	error = ERR_PTR(-ENOMEM);	inode = new_inode(dir->i_sb);	if (!inode)		goto out;	 	ei = PROC_I(inode);	inode->i_mtime = inode->i_atime = inode->i_ctime = CURRENT_TIME;	 	ei->pid = get_task_pid(task, PIDTYPE_PID);	if (!ei->pid)		goto out_iput;	inode->i_mode = p->mode;	if (S_ISDIR(inode->i_mode))		inode->i_nlink = 2;	if (S_ISLNK(inode->i_mode))		inode->i_size = 64;	if (p->iop)		inode->i_op = p->iop;	if (p->fop)		inode->i_fop = p->fop;	ei->op = p->op;	dentry->d_op = &proc_base_dentry_operations;	d_add(dentry, inode);	error = NULL;out:	return error;out_iput:	iput(inode);	goto out;}",12150
323,797,CVE-2013-2140,24,"static int xen_blkbk_parse_indirect(struct blkif_request *req,				    struct pending_req *pending_req,				    struct seg_buf seg[],				    struct phys_req *preq){	struct grant_page **pages = pending_req->indirect_pages;	struct xen_blkif *blkif = pending_req->blkif;	int indirect_grefs, rc, n, nseg, i;	struct blkif_request_segment_aligned *segments = NULL;	nseg = pending_req->nr_pages;	indirect_grefs = INDIRECT_PAGES(nseg);	BUG_ON(indirect_grefs > BLKIF_MAX_INDIRECT_PAGES_PER_REQUEST);	for (i = 0; i < indirect_grefs; i++)		pages[i]->gref = req->u.indirect.indirect_grefs[i];	rc = xen_blkbk_map(blkif, pages, indirect_grefs, true);	if (rc)		goto unmap;	for (n = 0, i = 0; n < nseg; n++) {		if ((n % SEGS_PER_INDIRECT_FRAME) == 0) {			 			if (segments)				kunmap_atomic(segments);			segments = kmap_atomic(pages[n/SEGS_PER_INDIRECT_FRAME]->page);		}		i = n % SEGS_PER_INDIRECT_FRAME;		pending_req->segments[n]->gref = segments[i].gref;		seg[n].nsec = segments[i].last_sect -			segments[i].first_sect + 1;		seg[n].offset = (segments[i].first_sect << 9);		if ((segments[i].last_sect >= (PAGE_SIZE >> 9)) ||		    (segments[i].last_sect < segments[i].first_sect)) {			rc = -EINVAL;			goto unmap;		}		preq->nr_sects += seg[n].nsec;	}unmap:	if (segments)		kunmap_atomic(segments);	xen_blkbk_unmap(blkif, pages, indirect_grefs);	return rc;}",8874
116,1065,CVE-2014-3645,24,void kvm_mmu_unload(struct kvm_vcpu *vcpu){	mmu_free_roots(vcpu);},11199
253,2564,CVE-2011-2840,24,"  void ClearStates() {    STLDeleteContainerPointers(states_.begin(), states_.end());    states_.clear();  }",29110
568,2044,CVE-2017-17862,24,"static void free_verifier_state(struct bpf_verifier_state *state,				int free_self){	kfree(state->stack);	if (free_self)		kfree(state);}",19542
231,1232,CVE-2014-2739,24,"static int cma_resolve_ib_route(struct rdma_id_private *id_priv, int timeout_ms){	struct rdma_route *route = &id_priv->id.route;	struct cma_work *work;	int ret;	work = kzalloc(sizeof *work, GFP_KERNEL);	if (!work)		return -ENOMEM;	work->id = id_priv;	INIT_WORK(&work->work, cma_work_handler);	work->old_state = RDMA_CM_ROUTE_QUERY;	work->new_state = RDMA_CM_ROUTE_RESOLVED;	work->event.event = RDMA_CM_EVENT_ROUTE_RESOLVED;	route->path_rec = kmalloc(sizeof *route->path_rec, GFP_KERNEL);	if (!route->path_rec) {		ret = -ENOMEM;		goto err1;	}	ret = cma_query_ib_route(id_priv, timeout_ms, work);	if (ret)		goto err2;	return 0;err2:	kfree(route->path_rec);	route->path_rec = NULL;err1:	kfree(work);	return ret;}",11707
8,216,CVE-2013-2168,24,_dbus_exit (int code){  _exit (code);},731
386,844,CVE-2013-1828,24,"int sctp_inet_listen(struct socket *sock, int backlog){	struct sock *sk = sock->sk;	struct sctp_endpoint *ep = sctp_sk(sk)->ep;	int err = -EINVAL;	if (unlikely(backlog < 0))		return err;	sctp_lock_sock(sk);	 	if (sctp_style(sk, UDP_HIGH_BANDWIDTH))		goto out;	if (sock->state != SS_UNCONNECTED)		goto out;	 	if (!backlog) {		if (sctp_sstate(sk, CLOSED))			goto out;		err = 0;		sctp_unhash_endpoint(ep);		sk->sk_state = SCTP_SS_CLOSED;		if (sk->sk_reuse)			sctp_sk(sk)->bind_hash->fastreuse = 1;		goto out;	}	 	if (sctp_sstate(sk, LISTENING))		sk->sk_max_ack_backlog = backlog;	else {		err = sctp_listen_start(sk, backlog);		if (err)			goto out;	}	err = 0;out:	sctp_release_sock(sk);	return err;}",9400
298,1565,CVE-2013-7271,24,void ipxitf_down(struct ipx_interface *intrfc){	spin_lock_bh(&ipx_interfaces_lock);	__ipxitf_down(intrfc);	spin_unlock_bh(&ipx_interfaces_lock);},12453
108,2195,CVE-2017-6345,24,"static inline int llc_estab_match(const struct llc_sap *sap,				   const struct llc_addr *daddr,				   const struct llc_addr *laddr,				   const struct sock *sk){	struct llc_sock *llc = llc_sk(sk);	return llc->laddr.lsap == laddr->lsap &&		llc->daddr.lsap == daddr->lsap &&		ether_addr_equal(llc->laddr.mac, laddr->mac) &&		ether_addr_equal(llc->daddr.mac, daddr->mac);}",21828
580,39,CVE-2017-16227,24,"aspath_reconcile_as4 ( struct aspath *aspath, struct aspath *as4path){  struct assegment *seg, *newseg, *prevseg = NULL;  struct aspath *newpath = NULL, *mergedpath;  int hops, cpasns = 0;    if (!aspath)    return NULL;    seg = aspath->segments;       hops = (aspath_count_hops (aspath) + aspath_count_confeds (aspath))         - aspath_count_hops (as4path);    if (hops < 0)    {      if (BGP_DEBUG (as4, AS4))        zlog_warn (""[AS4] Fewer hops in AS_PATH than NEW_AS_PATH"");              hops = aspath_count_hops (aspath);    }    if (!hops)   return aspath_dup (as4path);    if ( BGP_DEBUG(as4, AS4))    zlog_debug(""[AS4] got AS_PATH %s and AS4_PATH %s synthesizing now"",               aspath->str, as4path->str);  while (seg && hops > 0)    {      switch (seg->type)        {          case AS_SET:          case AS_CONFED_SET:            hops--;            cpasns = seg->length;            break;          case AS_CONFED_SEQUENCE:	     	    if (hops < seg->length)	      {	        if (BGP_DEBUG (as4, AS4))	          zlog_debug (""[AS4] AS4PATHmangle: AS_CONFED_SEQUENCE falls""	                      "" across 2/4 ASN boundary somewhere, broken.."");	        hops = seg->length;	      }	  case AS_SEQUENCE:	    cpasns = MIN(seg->length, hops);	    hops -= seg->length;	}            assert (cpasns <= seg->length);            newseg = assegment_new (seg->type, 0);      newseg = assegment_append_asns (newseg, seg->as, cpasns);      if (!newpath)        {          newpath = aspath_new ();          newpath->segments = newseg;        }      else        prevseg->next = newseg;      prevseg = newseg;      seg = seg->next;    }         mergedpath = aspath_merge (newpath, aspath_dup(as4path));  aspath_free (newpath);  mergedpath->segments = assegment_normalise (mergedpath->segments);  aspath_str_update (mergedpath);    if ( BGP_DEBUG(as4, AS4))    zlog_debug (""[AS4] result of synthesizing is %s"",                mergedpath->str);    return mergedpath;}",361
558,249,CVE-2012-5534,24,"hook_config_exec (const char *option, const char *value){    struct t_hook *ptr_hook, *next_hook;    hook_exec_start ();    ptr_hook = weechat_hooks[HOOK_TYPE_CONFIG];    while (ptr_hook)    {        next_hook = ptr_hook->next_hook;        if (!ptr_hook->deleted            && !ptr_hook->running            && (!HOOK_CONFIG(ptr_hook, option)                || (string_match (option, HOOK_CONFIG(ptr_hook, option), 0))))        {            ptr_hook->running = 1;            (void) (HOOK_CONFIG(ptr_hook, callback))                (ptr_hook->callback_data, option, value);            ptr_hook->running = 0;        }        ptr_hook = next_hook;    }    hook_exec_end ();}",1180
688,1469,CVE-2014-0077,24,"static int vhost_net_ubuf_put(struct vhost_net_ubuf_ref *ubufs){	int r = atomic_sub_return(1, &ubufs->refcount);	if (unlikely(!r))		wake_up(&ubufs->wait);	return r;}",12282
682,575,CVE-2011-3363,24,"cifs_get_tcon(struct cifsSesInfo *ses, struct smb_vol *volume_info){	int rc, xid;	struct cifsTconInfo *tcon;	tcon = cifs_find_tcon(ses, volume_info->UNC);	if (tcon) {		cFYI(1, ""Found match on UNC path"");		 		cifs_put_smb_ses(ses);		if (tcon->seal != volume_info->seal)			cERROR(1, ""transport encryption setting ""				   ""conflicts with existing tid"");		return tcon;	}	tcon = tconInfoAlloc();	if (tcon == NULL) {		rc = -ENOMEM;		goto out_fail;	}	tcon->ses = ses;	if (volume_info->password) {		tcon->password = kstrdup(volume_info->password, GFP_KERNEL);		if (!tcon->password) {			rc = -ENOMEM;			goto out_fail;		}	}	if (strchr(volume_info->UNC + 3, '\\') == NULL	    && strchr(volume_info->UNC + 3, '/') == NULL) {		cERROR(1, ""Missing share name"");		rc = -ENODEV;		goto out_fail;	}	 	xid = GetXid();	rc = CIFSTCon(xid, ses, volume_info->UNC, tcon, volume_info->local_nls);	FreeXid(xid);	cFYI(1, ""CIFS Tcon rc = %d"", rc);	if (rc)		goto out_fail;	if (volume_info->nodfs) {		tcon->Flags &= ~SMB_SHARE_IS_IN_DFS;		cFYI(1, ""DFS disabled (%d)"", tcon->Flags);	}	tcon->seal = volume_info->seal;	 	tcon->retry = volume_info->retry;	tcon->nocase = volume_info->nocase;	tcon->local_lease = volume_info->local_lease;	spin_lock(&cifs_tcp_ses_lock);	list_add(&tcon->tcon_list, &ses->tcon_list);	spin_unlock(&cifs_tcp_ses_lock);	cifs_fscache_get_super_cookie(tcon);	return tcon;out_fail:	tconInfoFree(tcon);	return ERR_PTR(rc);}",5522
252,2364,CVE-2017-18221,24,"void mlock_vma_page(struct page *page){	 	BUG_ON(!PageLocked(page));	VM_BUG_ON_PAGE(PageTail(page), page);	VM_BUG_ON_PAGE(PageCompound(page) && PageDoubleMap(page), page);	if (!TestSetPageMlocked(page)) {		mod_zone_page_state(page_zone(page), NR_MLOCK,				    hpage_nr_pages(page));		count_vm_event(UNEVICTABLE_PGMLOCKED);		if (!isolate_lru_page(page))			putback_lru_page(page);	}}",25829
170,721,CVE-2013-4587,24,"static void kvm_sched_in(struct preempt_notifier *pn, int cpu){	struct kvm_vcpu *vcpu = preempt_notifier_to_vcpu(pn);	if (vcpu->preempted)		vcpu->preempted = false;	kvm_arch_vcpu_load(vcpu, cpu);}",7660
7,1815,CVE-2015-7509,24,"static void ext4_dx_csum_set(struct inode *inode, struct ext4_dir_entry *dirent){	struct dx_countlimit *c;	struct dx_tail *t;	int count_offset, limit, count;	if (!EXT4_HAS_RO_COMPAT_FEATURE(inode->i_sb,					EXT4_FEATURE_RO_COMPAT_METADATA_CSUM))		return;	c = get_dx_countlimit(inode, dirent, &count_offset);	if (!c) {		EXT4_ERROR_INODE(inode, ""dir seems corrupt?  Run e2fsck -D."");		return;	}	limit = le16_to_cpu(c->limit);	count = le16_to_cpu(c->count);	if (count_offset + (limit * sizeof(struct dx_entry)) >	    EXT4_BLOCK_SIZE(inode->i_sb) - sizeof(struct dx_tail)) {		EXT4_ERROR_INODE(inode, ""metadata_csum set but no space for ""				 ""tree checksum.  Run e2fsck -D."");		return;	}	t = (struct dx_tail *)(((struct dx_entry *)c) + limit);	t->dt_checksum = ext4_dx_csum(inode, dirent, count_offset, count, t);}",13096
562,2173,CVE-2017-7645,24,"void nfsd_destroy(struct net *net){	struct nfsd_net *nn = net_generic(net, nfsd_net_id);	int destroy = (nn->nfsd_serv->sv_nrthreads == 1);	if (destroy)		svc_shutdown_net(nn->nfsd_serv, net);	svc_destroy(nn->nfsd_serv);	if (destroy)		nn->nfsd_serv = NULL;}",21501
555,2409,CVE-2019-15161,24,"is_url(const char *source){	char *colonp;	 	colonp = strchr(source, ':');	if (colonp == NULL)	{		 		return (0);	}	 	if (strncmp(colonp + 1, ""//"", 2) != 0)	{		 		return (0);	}	 	return (1);}",26643
329,1227,CVE-2014-2739,24,static void cma_release_dev(struct rdma_id_private *id_priv){	mutex_lock(&lock);	list_del(&id_priv->list);	cma_deref_dev(id_priv->cma_dev);	id_priv->cma_dev = NULL;	mutex_unlock(&lock);},11702
660,673,CVE-2013-6368,24,void kvm_load_guest_fpu(struct kvm_vcpu *vcpu){	if (vcpu->guest_fpu_loaded)		return;	 	kvm_put_guest_xcr0(vcpu);	vcpu->guest_fpu_loaded = 1;	__kernel_fpu_begin();	fpu_restore_checking(&vcpu->arch.guest_fpu);	trace_kvm_fpu(1);},7440
529,1043,CVE-2014-3645,24,void kvm_enable_tdp(void){	tdp_enabled = true;},11177
605,668,CVE-2013-6368,24,int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu){	int r;	vcpu->arch.mtrr_state.have_fixed = 1;	r = vcpu_load(vcpu);	if (r)		return r;	kvm_vcpu_reset(vcpu);	kvm_mmu_setup(vcpu);	vcpu_put(vcpu);	return r;},7435
266,51,CVE-2011-2724,24,"check_fstab(const char *progname, const char *mountpoint, const char *devname,	    char **options){	FILE *fstab;	struct mntent *mnt;	 	fstab = setmntent(_PATH_MNTTAB, ""r"");	if (!fstab) {		fprintf(stderr, ""Couldn't open %s for reading!\n"", _PATH_MNTTAB);		return EX_FILEIO;	}	while ((mnt = getmntent(fstab))) {		if (!strcmp(mountpoint, mnt->mnt_dir))			break;	}	endmntent(fstab);	if (mnt == NULL || strcmp(mnt->mnt_fsname, devname)) {		fprintf(stderr, ""%s: permission denied: no match for ""			""%s found in %s\n"", progname, mountpoint, _PATH_MNTTAB);		return EX_USAGE;	}	 	free(*options);	*options = strdup(mnt->mnt_opts);	return 0;}",428
31,1202,CVE-2014-2739,24,"static int cma_check_req_qp_type(struct rdma_cm_id *id, struct ib_cm_event *ib_event){	return (((ib_event->event == IB_CM_REQ_RECEIVED) &&		 (ib_event->param.req_rcvd.qp_type == id->qp_type)) ||		((ib_event->event == IB_CM_SIDR_REQ_RECEIVED) &&		 (id->qp_type == IB_QPT_UD)) ||		(!id->qp_type));}",11677
135,2270,CVE-2014-8324,24,"static int net_write(struct wif *wi, unsigned char *h80211, int len,		     struct tx_info *ti){	struct priv_net *pn = wi_priv(wi);	int sz = sizeof(*ti);	unsigned char buf[2048];	unsigned char *ptr = buf;	 	if (ti)		memcpy(ptr, ti, sz);	else		memset(ptr, 0, sizeof(*ti));	ptr += sz;	memcpy(ptr, h80211, len);	sz += len;	return net_cmd(pn, NET_WRITE, buf, sz);}",23121
586,2689,CVE-2019-5774,24,"void RecordOpensOutstanding(int size) {  UMA_HISTOGRAM_CUSTOM_COUNTS(""Download.OpensOutstanding"", size, 1  ,                              (1 << 10)  , 64  );}",30228
368,850,CVE-2013-1828,24,"static struct sctp_af *sctp_sockaddr_af(struct sctp_sock *opt,					union sctp_addr *addr, int len){	struct sctp_af *af;	 	if (len < sizeof (struct sockaddr))		return NULL;	 	if (addr->sa.sa_family == AF_INET6 &&	    ipv6_addr_v4mapped(&addr->v6.sin6_addr)) {		if (!opt->pf->af_supported(AF_INET, opt))			return NULL;	} else {		 		if (!opt->pf->af_supported(addr->sa.sa_family, opt))			return NULL;	}	 	af = sctp_get_af_specific(addr->sa.sa_family);	if (len < af->sockaddr_len)		return NULL;	return af;}",9406
332,2216,CVE-2017-5669,24,"static unsigned long shm_get_unmapped_area(struct file *file,	unsigned long addr, unsigned long len, unsigned long pgoff,	unsigned long flags){	struct shm_file_data *sfd = shm_file_data(file);	return sfd->file->f_op->get_unmapped_area(sfd->file, addr, len,						pgoff, flags);}",21978
15,1697,CVE-2013-7271,24,"int tipc_sock_accept_local(struct socket *sock, struct socket **newsock,			   int flags){	struct sock *sk = sock->sk;	int ret;	ret = sock_create_lite(sk->sk_family, sk->sk_type,			       sk->sk_protocol, newsock);	if (ret < 0)		return ret;	ret = accept(sock, *newsock, flags);	if (ret < 0) {		sock_release(*newsock);		return ret;	}	(*newsock)->ops = sock->ops;	return ret;}",12585
321,1573,CVE-2013-7271,24,"static void iucv_process_message(struct sock *sk, struct sk_buff *skb,				 struct iucv_path *path,				 struct iucv_message *msg){	int rc;	unsigned int len;	len = iucv_msg_length(msg);	 	 	IUCV_SKB_CB(skb)->class = msg->class;	 	if ((msg->flags & IUCV_IPRMDATA) && len > 7) {		if (memcmp(msg->rmmsg, iprm_shutdown, 8) == 0) {			skb->data = NULL;			skb->len = 0;		}	} else {		rc = pr_iucv->message_receive(path, msg,					      msg->flags & IUCV_IPRMDATA,					      skb->data, len, NULL);		if (rc) {			kfree_skb(skb);			return;		}		 		if (sk->sk_type == SOCK_STREAM &&		    skb->truesize >= sk->sk_rcvbuf / 4) {			rc = iucv_fragment_skb(sk, skb, len);			kfree_skb(skb);			skb = NULL;			if (rc) {				pr_iucv->path_sever(path, NULL);				return;			}			skb = skb_dequeue(&iucv_sk(sk)->backlog_skb_q);		} else {			skb_reset_transport_header(skb);			skb_reset_network_header(skb);			skb->len = len;		}	}	IUCV_SKB_CB(skb)->offset = 0;	if (sock_queue_rcv_skb(sk, skb))		skb_queue_head(&iucv_sk(sk)->backlog_skb_q, skb);}",12461
654,505,CVE-2012-2136,24,unsigned long sock_i_ino(struct sock *sk){	unsigned long ino;	read_lock_bh(&sk->sk_callback_lock);	ino = sk->sk_socket ? SOCK_INODE(sk->sk_socket)->i_ino : 0;	read_unlock_bh(&sk->sk_callback_lock);	return ino;},3464
604,1016,CVE-2014-4503,24,"struct thread_q *tq_new(void){	struct thread_q *tq;	tq = (struct thread_q *)calloc(1, sizeof(*tq));	if (!tq)		return NULL;	INIT_LIST_HEAD(&tq->q);	pthread_mutex_init(&tq->mutex, NULL);	pthread_cond_init(&tq->cond, NULL);	return tq;}",10884
38,1081,CVE-2014-3645,24,"static void mmu_free_memory_caches(struct kvm_vcpu *vcpu){	mmu_free_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,				pte_list_desc_cache);	mmu_free_memory_cache_page(&vcpu->arch.mmu_page_cache);	mmu_free_memory_cache(&vcpu->arch.mmu_page_header_cache,				mmu_page_header_cache);}",11215
275,1606,CVE-2013-7271,24,static void netlink_increment_head(struct netlink_ring *ring){	ring->head = ring->head != ring->frame_max ? ring->head + 1 : 0;},12494
232,2654,CVE-2018-6041,24,  void StartEmbeddedServer() {    SetupCrossSiteRedirector(embedded_test_server());    ASSERT_TRUE(embedded_test_server()->Start());  },30077
419,2655,CVE-2018-6041,24,  void StartServer() {    ASSERT_TRUE(embedded_test_server()->Start());    foo_host_port_ = embedded_test_server()->host_port_pair();    foo_host_port_.set_host(foo_com_);  },30078
475,1521,CVE-2013-7271,24,static struct atalk_route *atrtr_find(struct atalk_addr *target){	 	struct atalk_route *net_route = NULL;	struct atalk_route *r;	read_lock_bh(&atalk_routes_lock);	for (r = atalk_routes; r; r = r->next) {		if (!(r->flags & RTF_UP))			continue;		if (r->target.s_net == target->s_net) {			if (r->flags & RTF_HOST) {				 				if (r->target.s_node == target->s_node)					goto out;			} else				 				net_route = r;		}	}	 	if (net_route)		r = net_route;	else if (atrtr_default.dev)		r = &atrtr_default;	else  		r = NULL;out:	read_unlock_bh(&atalk_routes_lock);	return r;},12409
246,1347,CVE-2014-2038,24,"int nfs_wb_page_cancel(struct inode *inode, struct page *page){	struct nfs_page *req;	int ret = 0;	for (;;) {		wait_on_page_writeback(page);		req = nfs_page_find_request(page);		if (req == NULL)			break;		if (nfs_lock_request(req)) {			nfs_clear_request_commit(req);			nfs_inode_remove_request(req);			 			cancel_dirty_page(page, PAGE_CACHE_SIZE);			nfs_unlock_and_release_request(req);			break;		}		ret = nfs_wait_on_request(req);		nfs_release_request(req);		if (ret < 0)			break;	}	return ret;}",11894
559,443,CVE-2017-7539,24,"int nbd_client(int fd){    int ret;    int serrno;    TRACE(""Doing NBD loop"");    ret = ioctl(fd, NBD_DO_IT);    if (ret < 0 && errno == EPIPE) {                 ret = 0;    }    serrno = errno;    TRACE(""NBD loop returned %d: %s"", ret, strerror(serrno));    TRACE(""Clearing NBD queue"");    ioctl(fd, NBD_CLEAR_QUE);    TRACE(""Clearing NBD socket"");    ioctl(fd, NBD_CLEAR_SOCK);    errno = serrno;    return ret;}",2584
671,624,CVE-2011-1080,24,"static int ebt_compat_match_offset(const struct xt_match *match,				   unsigned int userlen){	 	if (unlikely(match->matchsize == -1))		return XT_ALIGN(userlen) - COMPAT_XT_ALIGN(userlen);	return xt_compat_match_offset(match);}",6927
449,2344,CVE-2018-14361,24,"static int nntp_msg_close(struct Context *ctx, struct Message *msg){  return mutt_file_fclose(&msg->fp);}",24489
129,707,CVE-2013-4587,24,"static int hardware_enable_all(void){	int r = 0;	raw_spin_lock(&kvm_count_lock);	kvm_usage_count++;	if (kvm_usage_count == 1) {		atomic_set(&hardware_enable_failed, 0);		on_each_cpu(hardware_enable_nolock, NULL, 1);		if (atomic_read(&hardware_enable_failed)) {			hardware_disable_all_nolock();			r = -EBUSY;		}	}	raw_spin_unlock(&kvm_count_lock);	return r;}",7646
629,1157,CVE-2014-2739,24,"static void cm_format_rep_event(struct cm_work *work, enum ib_qp_type qp_type){	struct cm_rep_msg *rep_msg;	struct ib_cm_rep_event_param *param;	rep_msg = (struct cm_rep_msg *)work->mad_recv_wc->recv_buf.mad;	param = &work->cm_event.param.rep_rcvd;	param->remote_ca_guid = rep_msg->local_ca_guid;	param->remote_qkey = be32_to_cpu(rep_msg->local_qkey);	param->remote_qpn = be32_to_cpu(cm_rep_get_qpn(rep_msg, qp_type));	param->starting_psn = be32_to_cpu(cm_rep_get_starting_psn(rep_msg));	param->responder_resources = rep_msg->initiator_depth;	param->initiator_depth = rep_msg->resp_resources;	param->target_ack_delay = cm_rep_get_target_ack_delay(rep_msg);	param->failover_accepted = cm_rep_get_failover(rep_msg);	param->flow_control = cm_rep_get_flow_ctrl(rep_msg);	param->rnr_retry_count = cm_rep_get_rnr_retry_count(rep_msg);	param->srq = cm_rep_get_srq(rep_msg);	work->cm_event.private_data = &rep_msg->private_data;}",11632
280,1863,CVE-2016-9191,24,"struct ctl_table_header *register_sysctl(const char *path, struct ctl_table *table){	return __register_sysctl_table(&sysctl_table_root.default_set,					path, table);}",15224
565,304,CVE-2014-7840,24,"int xbzrle_cache_resize(int new_size){    PageCache *new_cache;    int ret;    if (new_size < TARGET_PAGE_SIZE) {        return -1;    }    XBZRLE_cache_lock();    if (XBZRLE.cache != NULL) {        if (pow2floor(new_size) == migrate_xbzrle_cache_size()) {            goto out_new_size;        }        new_cache = cache_init(new_size / TARGET_PAGE_SIZE,                                        TARGET_PAGE_SIZE);        if (!new_cache) {            error_report(""Error creating cache"");            ret = -1;            goto out;        }        cache_fini(XBZRLE.cache);        XBZRLE.cache = new_cache;    }out_new_size:    ret = pow2floor(new_size);out:    XBZRLE_cache_unlock();    return ret;}",1304
215,2679,CVE-2017-15420,24,  int will_process_called() { return will_process_called_; },30145
114,1633,CVE-2013-7271,24,"static void rawsock_data_exchange_complete(void *context, struct sk_buff *skb,					   int err){	struct sock *sk = (struct sock *) context;	BUG_ON(in_irq());	pr_debug(""sk=%p err=%d\n"", sk, err);	if (err)		goto error;	err = rawsock_add_header(skb);	if (err)		goto error_skb;	err = sock_queue_rcv_skb(sk, skb);	if (err)		goto error_skb;	spin_lock_bh(&sk->sk_write_queue.lock);	if (!skb_queue_empty(&sk->sk_write_queue))		schedule_work(&nfc_rawsock(sk)->tx_work);	else		nfc_rawsock(sk)->tx_work_scheduled = false;	spin_unlock_bh(&sk->sk_write_queue.lock);	sock_put(sk);	return;error_skb:	kfree_skb(skb);error:	rawsock_report_error(sk, err);	sock_put(sk);}",12521
442,2150,CVE-2017-11665,24," static const char* rtmp_packet_type(int type) {     switch (type) {    case RTMP_PT_CHUNK_SIZE:     return ""chunk size"";    case RTMP_PT_BYTES_READ:     return ""bytes read"";    case RTMP_PT_PING:           return ""ping"";    case RTMP_PT_SERVER_BW:      return ""server bandwidth"";    case RTMP_PT_CLIENT_BW:      return ""client bandwidth"";    case RTMP_PT_AUDIO:          return ""audio packet"";    case RTMP_PT_VIDEO:          return ""video packet"";    case RTMP_PT_FLEX_STREAM:    return ""Flex shared stream"";    case RTMP_PT_FLEX_OBJECT:    return ""Flex shared object"";    case RTMP_PT_FLEX_MESSAGE:   return ""Flex shared message"";    case RTMP_PT_NOTIFY:         return ""notification"";    case RTMP_PT_SHARED_OBJ:     return ""shared object"";    case RTMP_PT_INVOKE:         return ""invoke"";    case RTMP_PT_METADATA:       return ""metadata"";    default:                     return ""unknown"";    }}",20465
618,2586,CVE-2015-6784,24,"    void registerURL(const char* file, const char* mimeType)    {        registerURL(file, file, mimeType);    }",29624
379,1958,CVE-2015-3288,24,"void print_vma_addr(char *prefix, unsigned long ip){	struct mm_struct *mm = current->mm;	struct vm_area_struct *vma;	 	if (preempt_count())		return;	down_read(&mm->mmap_sem);	vma = find_vma(mm, ip);	if (vma && vma->vm_file) {		struct file *f = vma->vm_file;		char *buf = (char *)__get_free_page(GFP_KERNEL);		if (buf) {			char *p;			p = file_path(f, buf, PAGE_SIZE);			if (IS_ERR(p))				p = ""?"";			printk(""%s%s[%lx+%lx]"", prefix, kbasename(p),					vma->vm_start,					vma->vm_end - vma->vm_start);			free_page((unsigned long)buf);		}	}	up_read(&mm->mmap_sem);}",19119
264,872,CVE-2013-1819,24,xfs_buf_is_vmapped(	struct xfs_buf	*bp){	 	return bp->b_addr && bp->b_page_count > 1;},9479
214,1217,CVE-2014-2739,24,"static int cma_init_conn_qp(struct rdma_id_private *id_priv, struct ib_qp *qp){	struct ib_qp_attr qp_attr;	int qp_attr_mask, ret;	qp_attr.qp_state = IB_QPS_INIT;	ret = rdma_init_qp_attr(&id_priv->id, &qp_attr, &qp_attr_mask);	if (ret)		return ret;	return ib_modify_qp(qp, &qp_attr, qp_attr_mask);}",11692
466,1102,CVE-2014-3645,24," static void paging_new_cr3(struct kvm_vcpu *vcpu) {	pgprintk(""%s: cr3 %lx\n"", __func__, kvm_read_cr3(vcpu));	mmu_free_roots(vcpu);}",11236
532,2474,CVE-2010-1152,24,static enum test_return test_binary_quit(void) {    return test_binary_quit_impl(PROTOCOL_BINARY_CMD_QUIT);},28231
570,1265,CVE-2014-2673,24,"static inline int set_dabr(struct arch_hw_breakpoint *brk){	unsigned long dabr, dabrx;	dabr = brk->address | (brk->type & HW_BRK_TYPE_DABR);	dabrx = ((brk->type >> 3) & 0x7);	if (ppc_md.set_dabr)		return ppc_md.set_dabr(dabr, dabrx);	return __set_dabr(dabr, dabrx);}",11757
225,25,CVE-2017-16227,24,"aspath_free (struct aspath *aspath){  if (!aspath)    return;  if (aspath->segments)    assegment_free_all (aspath->segments);  if (aspath->str)    XFREE (MTYPE_AS_STR, aspath->str);  XFREE (MTYPE_AS_PATH, aspath);}",347
158,1495,CVE-2013-7271,24,"static int pppoe_rcv_core(struct sock *sk, struct sk_buff *skb){	struct pppox_sock *po = pppox_sk(sk);	struct pppox_sock *relay_po;	 	if (sk->sk_state & PPPOX_BOUND) {		ppp_input(&po->chan, skb);	} else if (sk->sk_state & PPPOX_RELAY) {		relay_po = get_item_by_addr(sock_net(sk),					    &po->pppoe_relay);		if (relay_po == NULL)			goto abort_kfree;		if ((sk_pppox(relay_po)->sk_state & PPPOX_CONNECTED) == 0)			goto abort_put;		if (!__pppoe_xmit(sk_pppox(relay_po), skb))			goto abort_put;	} else {		if (sock_queue_rcv_skb(sk, skb))			goto abort_kfree;	}	return NET_RX_SUCCESS;abort_put:	sock_put(sk_pppox(relay_po));abort_kfree:	kfree_skb(skb);	return NET_RX_DROP;}",12383
199,846,CVE-2013-1828,24,"static int sctp_send_asconf(struct sctp_association *asoc,			    struct sctp_chunk *chunk){	struct net 	*net = sock_net(asoc->base.sk);	int		retval = 0;	 	if (asoc->addip_last_asconf) {		list_add_tail(&chunk->list, &asoc->addip_chunk_list);		goto out;	}	 	sctp_chunk_hold(chunk);	retval = sctp_primitive_ASCONF(net, asoc, chunk);	if (retval)		sctp_chunk_free(chunk);	else		asoc->addip_last_asconf = chunk;out:	return retval;}",9402
106,553,CVE-2011-4914,24,"	__acquires(rose_neigh_list_lock){	struct rose_neigh *rose_neigh;	int i = 1;	spin_lock_bh(&rose_neigh_list_lock);	if (*pos == 0)		return SEQ_START_TOKEN;	for (rose_neigh = rose_neigh_list; rose_neigh && i < *pos;	     rose_neigh = rose_neigh->next, ++i);	return (i == *pos) ? rose_neigh : NULL;}",4400
676,885,CVE-2013-1798,24,"static int ioapic_deliver(struct kvm_ioapic *ioapic, int irq){	union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];	struct kvm_lapic_irq irqe;	ioapic_debug(""dest=%x dest_mode=%x delivery_mode=%x ""		     ""vector=%x trig_mode=%x\n"",		     entry->fields.dest_id, entry->fields.dest_mode,		     entry->fields.delivery_mode, entry->fields.vector,		     entry->fields.trig_mode);	irqe.dest_id = entry->fields.dest_id;	irqe.vector = entry->fields.vector;	irqe.dest_mode = entry->fields.dest_mode;	irqe.trig_mode = entry->fields.trig_mode;	irqe.delivery_mode = entry->fields.delivery_mode << 8;	irqe.level = 1;	irqe.shorthand = 0;	return kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe);}",9492
472,884,CVE-2013-1798,24,"static void __kvm_ioapic_update_eoi(struct kvm_ioapic *ioapic, int vector,				     int trigger_mode){	int i;	for (i = 0; i < IOAPIC_NUM_PINS; i++) {		union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];		if (ent->fields.vector != vector)			continue;		 		spin_unlock(&ioapic->lock);		kvm_notify_acked_irq(ioapic->kvm, KVM_IRQCHIP_IOAPIC, i);		spin_lock(&ioapic->lock);		if (trigger_mode != IOAPIC_LEVEL_TRIG)			continue;		ASSERT(ent->fields.trig_mode == IOAPIC_LEVEL_TRIG);		ent->fields.remote_irr = 0;		if (!ent->fields.mask && (ioapic->irr & (1 << i)))			ioapic_service(ioapic, i);	}}",9491
473,1564,CVE-2013-7271,24,"static int ipxitf_demux_socket(struct ipx_interface *intrfc,			       struct sk_buff *skb, int copy){	struct ipxhdr *ipx = ipx_hdr(skb);	struct sock *sock1 = NULL, *sock2 = NULL;	struct sk_buff *skb1 = NULL, *skb2 = NULL;	int rc;	if (intrfc == ipx_primary_net && ntohs(ipx->ipx_dest.sock) == 0x451)		sock1 = ncp_connection_hack(intrfc, ipx);	if (!sock1)		 		sock1 = ipxitf_find_socket(intrfc, ipx->ipx_dest.sock);	 	if (ipx_primary_net && intrfc != ipx_primary_net) {		const int dsock = ntohs(ipx->ipx_dest.sock);		if (dsock == 0x452 || dsock == 0x453 || dsock == 0x456)			 			sock2 = ipxitf_find_socket(ipx_primary_net,							ipx->ipx_dest.sock);	}	 	rc = 0;	if (!sock1 && !sock2) {		if (!copy)			kfree_skb(skb);		goto out;	}	 	if (copy)		skb1 = skb_clone(skb, GFP_ATOMIC);	else		skb1 = skb;	rc = -ENOMEM;	if (!skb1)		goto out_put;	 	if (sock1 && sock2)		skb2 = skb_clone(skb1, GFP_ATOMIC);	else		skb2 = skb1;	if (sock1)		ipxitf_def_skb_handler(sock1, skb1);	if (!skb2)		goto out_put;	if (sock2)		ipxitf_def_skb_handler(sock2, skb2);	rc = 0;out_put:	if (sock1)		sock_put(sock1);	if (sock2)		sock_put(sock2);out:	return rc;}",12452
577,500,CVE-2012-2136,24,"static void sock_def_error_report(struct sock *sk){	struct socket_wq *wq;	rcu_read_lock();	wq = rcu_dereference(sk->sk_wq);	if (wq_has_sleeper(wq))		wake_up_interruptible_poll(&wq->wait, POLLERR);	sk_wake_async(sk, SOCK_WAKE_IO, POLL_ERR);	rcu_read_unlock();}",3459
418,2698,CVE-2016-3760,24,static void cleanup(void) {   stack_manager_get_interface()->clean_up_stack_async(); },30509
212,1435,CVE-2014-0203,24,"static int mem_open(struct inode* inode, struct file* file){	file->private_data = (void*)((long)current->self_exec_id);	return 0;}",12145
120,2254,CVE-2015-5194,24,token_name(	int token	){	return yytname[YYTRANSLATE(token)];},22920
647,57,CVE-2011-2724,24,"static void null_terminate_endl(char *source){	char *newline = strchr(source, '\n');	if (newline)		*newline = '\0';}",434
137,1856,CVE-2016-9191,24,"static int proc_sys_open(struct inode *inode, struct file *filp){	struct ctl_table_header *head = grab_header(inode);	struct ctl_table *table = PROC_I(inode)->sysctl_entry;	 	if (IS_ERR(head))		return PTR_ERR(head);	if (table->poll)		filp->private_data = proc_sys_poll_event(table->poll);	sysctl_head_finish(head);	return 0;}",15217
90,371,CVE-2016-4071,24,"PHP_FUNCTION(snmpwalk){	php_snmp(INTERNAL_FUNCTION_PARAM_PASSTHRU, (SNMP_CMD_WALK | SNMP_NUMERIC_KEYS), SNMP_VERSION_1);}",1941
518,1092,CVE-2014-3645,24,"static int mmu_unsync_walk(struct kvm_mmu_page *sp,			   struct kvm_mmu_pages *pvec){	if (!sp->unsync_children)		return 0;	mmu_pages_add(pvec, sp, 0);	return __mmu_unsync_walk(sp, pvec);}",11226
424,2138,CVE-2017-13715,24,"static int skb_flow_dissector_uses_key(struct flow_dissector *flow_dissector,					enum flow_dissector_key_id key_id){	return flow_dissector->used_keys & (1 << key_id);}",20238
286,939,CVE-2011-3619,24,"static int apparmor_path_unlink(struct path *dir, struct dentry *dentry){	return common_perm_rm(OP_UNLINK, dir, dentry, AA_MAY_DELETE);}",10110
331,77,CVE-2015-5296,24,int smb1cli_conn_server_writebraw(struct smbXcli_conn *conn){	return conn->smb1.server.writebraw;},485
650,847,CVE-2013-1828,24,"static inline void sctp_set_owner_w(struct sctp_chunk *chunk){	struct sctp_association *asoc = chunk->asoc;	struct sock *sk = asoc->base.sk;	 	sctp_association_hold(asoc);	skb_set_owner_w(chunk->skb, sk);	chunk->skb->destructor = sctp_wfree;	 	*((struct sctp_chunk **)(chunk->skb->cb)) = chunk;	asoc->sndbuf_used += SCTP_DATA_SNDSIZE(chunk) +				sizeof(struct sk_buff) +				sizeof(struct sctp_chunk);	atomic_add(sizeof(struct sctp_chunk), &sk->sk_wmem_alloc);	sk->sk_wmem_queued += chunk->skb->truesize;	sk_mem_charge(sk, chunk->skb->truesize);}",9403
395,1519,CVE-2013-7271,24,static int atrtr_delete(struct atalk_addr * addr){	struct atalk_route **r = &atalk_routes;	int retval = 0;	struct atalk_route *tmp;	write_lock_bh(&atalk_routes_lock);	while ((tmp = *r) != NULL) {		if (tmp->target.s_net == addr->s_net &&		    (!(tmp->flags&RTF_GATEWAY) ||		     tmp->target.s_node == addr->s_node)) {			*r = tmp->next;			dev_put(tmp->dev);			kfree(tmp);			goto out;		}		r = &tmp->next;	}	retval = -ENOENT;out:	write_unlock_bh(&atalk_routes_lock);	return retval;},12407
248,908,CVE-2013-0290,24,"struct sk_buff *skb_recv_datagram(struct sock *sk, unsigned int flags,				  int noblock, int *err){	int peeked, off = 0;	return __skb_recv_datagram(sk, flags | (noblock ? MSG_DONTWAIT : 0),				   &peeked, &off, err);}",9760
535,300,CVE-2014-7840,24,static void ram_migration_cancel(void *opaque){    migration_end();},1300
464,1678,CVE-2013-7271,24,"static void prb_retire_rx_blk_timer_expired(unsigned long data){	struct packet_sock *po = (struct packet_sock *)data;	struct tpacket_kbdq_core *pkc = &po->rx_ring.prb_bdqc;	unsigned int frozen;	struct tpacket_block_desc *pbd;	spin_lock(&po->sk.sk_receive_queue.lock);	frozen = prb_queue_frozen(pkc);	pbd = GET_CURR_PBLOCK_DESC_FROM_CORE(pkc);	if (unlikely(pkc->delete_blk_timer))		goto out;	 	if (BLOCK_NUM_PKTS(pbd)) {		while (atomic_read(&pkc->blk_fill_in_prog)) {			 			cpu_relax();		}	}	if (pkc->last_kactive_blk_num == pkc->kactive_blk_num) {		if (!frozen) {			prb_retire_current_block(pkc, po, TP_STATUS_BLK_TMO);			if (!prb_dispatch_next_block(pkc, po))				goto refresh_timer;			else				goto out;		} else {			 			if (prb_curr_blk_in_use(pkc, pbd)) {				 				goto refresh_timer;			} else {			        				prb_open_block(pkc, pbd);				goto out;			}		}	}refresh_timer:	_prb_refresh_rx_retire_blk_timer(pkc);out:	spin_unlock(&po->sk.sk_receive_queue.lock);}",12566
322,2665,CVE-2018-6089,24,  ChromeServiceWorkerManifestFetchTest() {},30097
257,238,CVE-2013-2168,24,_dbus_windows_get_datadir (void){	return _dbus_replace_install_prefix(DBUS_DATADIR);},753
167,2637,CVE-2018-17467,24,  void SetUpOverscrollEnvironment() { SetUpOverscrollEnvironmentImpl(0); },30052
12,756,CVE-2013-4129,24,"void br_multicast_init(struct net_bridge *br){	br->hash_elasticity = 4;	br->hash_max = 512;	br->multicast_router = 1;	br->multicast_querier = 0;	br->multicast_query_use_ifaddr = 0;	br->multicast_last_member_count = 2;	br->multicast_startup_query_count = 2;	br->multicast_last_member_interval = HZ;	br->multicast_query_response_interval = 10 * HZ;	br->multicast_startup_query_interval = 125 * HZ / 4;	br->multicast_query_interval = 125 * HZ;	br->multicast_querier_interval = 255 * HZ;	br->multicast_membership_interval = 260 * HZ;	spin_lock_init(&br->multicast_lock);	setup_timer(&br->multicast_router_timer,		    br_multicast_local_router_expired, 0);	setup_timer(&br->multicast_querier_timer,		    br_multicast_querier_expired, (unsigned long)br);	setup_timer(&br->multicast_query_timer, br_multicast_query_expired,		    (unsigned long)br);}",7972
227,2636,CVE-2018-17467,24,  void RunOnCompositingDidCommit() {    GetDelegatedFrameHost()->OnCompositingDidCommitForTesting(        window()->GetHost()->compositor());  },30051
293,103,CVE-2015-5296,24,int smbXcli_conn_is_connected(struct smbXcli_conn *conn){	if (conn == NULL) {		return false;	}	if (conn->sock_fd == -1) {		return false;	}	return true;},511
470,698,CVE-2013-6368,24," static void update_cr8_intercept(struct kvm_vcpu *vcpu) { 	int max_irr, tpr;	if (!kvm_x86_ops->update_cr8_intercept)		return;	if (!vcpu->arch.apic)		return;	if (!vcpu->arch.apic->vapic_addr)		max_irr = kvm_lapic_find_highest_irr(vcpu);	else		max_irr = -1;	if (max_irr != -1)		max_irr >>= 4;	tpr = kvm_lapic_get_cr8(vcpu);	kvm_x86_ops->update_cr8_intercept(vcpu, tpr, max_irr);}",7465
667,122,CVE-2011-1428,24,"hook_completion_exec (struct t_weechat_plugin *plugin,                      const char *completion_item,                      struct t_gui_buffer *buffer,                      struct t_gui_completion *completion){    struct t_hook *ptr_hook, *next_hook;             (void) plugin;        hook_exec_start ();        ptr_hook = weechat_hooks[HOOK_TYPE_COMPLETION];    while (ptr_hook)    {        next_hook = ptr_hook->next_hook;                if (!ptr_hook->deleted            && !ptr_hook->running            && (string_strcasecmp (HOOK_COMPLETION(ptr_hook, completion_item),                                   completion_item) == 0))        {            ptr_hook->running = 1;            (void) (HOOK_COMPLETION(ptr_hook, callback))                (ptr_hook->callback_data, completion_item, buffer, completion);            ptr_hook->running = 0;        }                ptr_hook = next_hook;    }        hook_exec_end ();}",616
228,674,CVE-2013-6368,24,"void kvm_put_guest_fpu(struct kvm_vcpu *vcpu){	kvm_put_guest_xcr0(vcpu);	if (!vcpu->guest_fpu_loaded)		return;	vcpu->guest_fpu_loaded = 0;	fpu_save_init(&vcpu->arch.guest_fpu);	__kernel_fpu_end();	++vcpu->stat.fpu_reload;	kvm_make_request(KVM_REQ_DEACTIVATE_FPU, vcpu);	trace_kvm_fpu(0);}",7441
336,1754,CVE-2015-8215,24,"static void addrconf_dad_completed(struct inet6_ifaddr *ifp){	struct net_device *dev = ifp->idev->dev;	struct in6_addr lladdr;	int send_rs, send_mld;	addrconf_del_dad_work(ifp);	 	ipv6_ifa_notify(RTM_NEWADDR, ifp);	 	read_lock_bh(&ifp->idev->lock);	send_mld = ifp->scope == IFA_LINK && ipv6_lonely_lladdr(ifp);	send_rs = send_mld &&		  ipv6_accept_ra(ifp->idev) &&		  ifp->idev->cnf.rtr_solicits > 0 &&		  (dev->flags&IFF_LOOPBACK) == 0;	read_unlock_bh(&ifp->idev->lock);	 	if (send_mld)		ipv6_mc_dad_complete(ifp->idev);	if (send_rs) {		 		if (ipv6_get_lladdr(dev, &lladdr, IFA_F_TENTATIVE))			return;		ndisc_send_rs(dev, &lladdr, &in6addr_linklocal_allrouters);		write_lock_bh(&ifp->idev->lock);		spin_lock(&ifp->lock);		ifp->idev->rs_probes = 1;		ifp->idev->if_flags |= IF_RS_SENT;		addrconf_mod_rs_timer(ifp->idev,				      ifp->idev->cnf.rtr_solicit_interval);		spin_unlock(&ifp->lock);		write_unlock_bh(&ifp->idev->lock);	}}",12964
451,156,CVE-2011-1428,24,"network_connect_gnutls_handshake_fd_cb (void *arg_hook_connect, int fd){    struct t_hook *hook_connect;    int rc, direction, flags;             (void) fd;        hook_connect = (struct t_hook *)arg_hook_connect;        rc = gnutls_handshake (*HOOK_CONNECT(hook_connect, gnutls_sess));        if ((rc == GNUTLS_E_AGAIN) || (rc == GNUTLS_E_INTERRUPTED))    {        direction = gnutls_record_get_direction (*HOOK_CONNECT(hook_connect, gnutls_sess));        flags = HOOK_FD(HOOK_CONNECT(hook_connect, handshake_hook_fd), flags);        if ((((flags & HOOK_FD_FLAG_READ) == HOOK_FD_FLAG_READ)             && (direction != 0))            || (((flags & HOOK_FD_FLAG_WRITE) == HOOK_FD_FLAG_WRITE)                && (direction != 1)))        {            HOOK_FD(HOOK_CONNECT(hook_connect, handshake_hook_fd), flags) =                (direction) ? HOOK_FD_FLAG_WRITE: HOOK_FD_FLAG_READ;        }    }    else if (rc != GNUTLS_E_SUCCESS)    {        (void) (HOOK_CONNECT(hook_connect, callback))            (hook_connect->callback_data,             WEECHAT_HOOK_CONNECT_GNUTLS_HANDSHAKE_ERROR,             rc,             gnutls_strerror (rc),             HOOK_CONNECT(hook_connect, handshake_ip_address));        unhook (hook_connect);    }    else    {        fcntl (HOOK_CONNECT(hook_connect, sock), F_SETFL,               HOOK_CONNECT(hook_connect, handshake_fd_flags));        unhook (HOOK_CONNECT(hook_connect, handshake_hook_fd));        (void) (HOOK_CONNECT(hook_connect, callback))                (hook_connect->callback_data, WEECHAT_HOOK_CONNECT_OK, 0, NULL,                 HOOK_CONNECT(hook_connect, handshake_ip_address));        unhook (hook_connect);    }        return WEECHAT_RC_OK;}",650
180,704,CVE-2013-4587,24,static void hardware_disable(void){	raw_spin_lock(&kvm_count_lock);	if (kvm_usage_count)		hardware_disable_nolock(NULL);	raw_spin_unlock(&kvm_count_lock);},7643
524,2201,CVE-2017-6345,24,"static void llc_sk_init(struct sock *sk){	struct llc_sock *llc = llc_sk(sk);	llc->state    = LLC_CONN_STATE_ADM;	llc->inc_cntr = llc->dec_cntr = 2;	llc->dec_step = llc->connect_step = 1;	setup_timer(&llc->ack_timer.timer, llc_conn_ack_tmr_cb,			(unsigned long)sk);	llc->ack_timer.expire	      = sysctl_llc2_ack_timeout;	setup_timer(&llc->pf_cycle_timer.timer, llc_conn_pf_cycle_tmr_cb,			(unsigned long)sk);	llc->pf_cycle_timer.expire	   = sysctl_llc2_p_timeout;	setup_timer(&llc->rej_sent_timer.timer, llc_conn_rej_tmr_cb,			(unsigned long)sk);	llc->rej_sent_timer.expire	   = sysctl_llc2_rej_timeout;	setup_timer(&llc->busy_state_timer.timer, llc_conn_busy_tmr_cb,			(unsigned long)sk);	llc->busy_state_timer.expire	     = sysctl_llc2_busy_timeout;	llc->n2 = 2;    	llc->k  = 2;    	llc->rw = 128;  	skb_queue_head_init(&llc->pdu_unack_q);	sk->sk_backlog_rcv = llc_backlog_rcv;}",21834
694,2284,CVE-2018-18955,24,"static int insert_extent(struct uid_gid_map *map, struct uid_gid_extent *extent){	struct uid_gid_extent *dest;	if (map->nr_extents == UID_GID_MAP_MAX_BASE_EXTENTS) {		struct uid_gid_extent *forward;		 		forward = kmalloc_array(UID_GID_MAP_MAX_EXTENTS,					sizeof(struct uid_gid_extent),					GFP_KERNEL);		if (!forward)			return -ENOMEM;		 		memcpy(forward, map->extent,		       map->nr_extents * sizeof(map->extent[0]));		map->forward = forward;		map->reverse = NULL;	}	if (map->nr_extents < UID_GID_MAP_MAX_BASE_EXTENTS)		dest = &map->extent[map->nr_extents];	else		dest = &map->forward[map->nr_extents];	*dest = *extent;	map->nr_extents++;	return 0;}",23413
71,2708,CVE-2016-3760,24,"int le_test_mode(int opcode, int* buf, int len){    LOG_INFO(""le_test_mode"");   if (interface_ready() == FALSE) return BT_STATUS_NOT_READY; return btif_le_test_mode(opcode, buf, len);}",30519
32,2325,CVE-2018-17456,24,"static char *get_object_name(struct fsck_options *options, struct object *obj){	if (!options->object_names)		return NULL;	return lookup_decoration(options->object_names, obj);}",23617
102,1486,CVE-2013-7271,24,"static inline struct pppox_sock *get_item_by_addr(struct net *net,						struct sockaddr_pppox *sp){	struct net_device *dev;	struct pppoe_net *pn;	struct pppox_sock *pppox_sock = NULL;	int ifindex;	rcu_read_lock();	dev = dev_get_by_name_rcu(net, sp->sa_addr.pppoe.dev);	if (dev) {		ifindex = dev->ifindex;		pn = pppoe_pernet(net);		pppox_sock = get_item(pn, sp->sa_addr.pppoe.sid,				sp->sa_addr.pppoe.remote, ifindex);	}	rcu_read_unlock();	return pppox_sock;}",12374
224,1072,CVE-2014-3645,24,"int kvm_unmap_hva(struct kvm *kvm, unsigned long hva){	return kvm_handle_hva(kvm, hva, 0, kvm_unmap_rmapp);}",11206
152,808,CVE-2013-1848,24,"static int clear_qf_name(struct super_block *sb, int qtype) {	struct ext3_sb_info *sbi = EXT3_SB(sb);	if (sb_any_quota_loaded(sb) &&		sbi->s_qf_names[qtype]) {		ext3_msg(sb, KERN_ERR, ""Cannot change journaled quota options""			"" when quota turned on"");		return 0;	}	if (sbi->s_qf_names[qtype]) {		kfree(sbi->s_qf_names[qtype]);		sbi->s_qf_names[qtype] = NULL;	}	return 1;}",9364
210,2047,CVE-2017-17862,24,static int is_spillable_regtype(enum bpf_reg_type type){	switch (type) {	case PTR_TO_MAP_VALUE:	case PTR_TO_MAP_VALUE_OR_NULL:	case PTR_TO_STACK:	case PTR_TO_CTX:	case PTR_TO_PACKET:	case PTR_TO_PACKET_META:	case PTR_TO_PACKET_END:	case CONST_PTR_TO_MAP:		return true;	default:		return false;	}},19545
14,770,CVE-2013-2146,24,"static void intel_fixup_er(struct perf_event *event, int idx){	event->hw.extra_reg.idx = idx;	if (idx == EXTRA_REG_RSP_0) {		event->hw.config &= ~INTEL_ARCH_EVENT_MASK;		event->hw.config |= 0x01b7;		event->hw.extra_reg.reg = MSR_OFFCORE_RSP_0;	} else if (idx == EXTRA_REG_RSP_1) {		event->hw.config &= ~INTEL_ARCH_EVENT_MASK;		event->hw.config |= 0x01bb;		event->hw.extra_reg.reg = MSR_OFFCORE_RSP_1;	}}",8795
512,2239,CVE-2015-5195,24,"concat_gen_fifos(	void *first,	void *second	){	gen_fifo *pf1;	gen_fifo *pf2;	pf1 = first;	pf2 = second;	if (NULL == pf1)		return pf2;	else if (NULL == pf2)		return pf1;	CONCAT_FIFO(*pf1, *pf2, link);	free(pf2);	return pf1;}",22905
198,877,CVE-2013-1819,24,xfs_buf_terminate(void){	destroy_workqueue(xfslogd_workqueue);	kmem_zone_destroy(xfs_buf_zone);},9484
479,2028,CVE-2017-17862,24,static int check_map_prealloc(struct bpf_map *map){	return (map->map_type != BPF_MAP_TYPE_HASH &&		map->map_type != BPF_MAP_TYPE_PERCPU_HASH &&		map->map_type != BPF_MAP_TYPE_HASH_OF_MAPS) ||		!(map->map_flags & BPF_F_NO_PREALLOC);},19526
552,2494,CVE-2012-0879,24,"static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm){	struct vm_area_struct *mpnt, *tmp, **pprev;	struct rb_node **rb_link, *rb_parent;	int retval;	unsigned long charge;	struct mempolicy *pol;	down_write(&oldmm->mmap_sem);	flush_cache_dup_mm(oldmm);	 	down_write_nested(&mm->mmap_sem, SINGLE_DEPTH_NESTING);	mm->locked_vm = 0;	mm->mmap = NULL;	mm->mmap_cache = NULL;	mm->free_area_cache = oldmm->mmap_base;	mm->cached_hole_size = ~0UL;	mm->map_count = 0;	cpumask_clear(mm_cpumask(mm));	mm->mm_rb = RB_ROOT;	rb_link = &mm->mm_rb.rb_node;	rb_parent = NULL;	pprev = &mm->mmap;	retval = ksm_fork(mm, oldmm);	if (retval)		goto out;	for (mpnt = oldmm->mmap; mpnt; mpnt = mpnt->vm_next) {		struct file *file;		if (mpnt->vm_flags & VM_DONTCOPY) {			long pages = vma_pages(mpnt);			mm->total_vm -= pages;			vm_stat_account(mm, mpnt->vm_flags, mpnt->vm_file,								-pages);			continue;		}		charge = 0;		if (mpnt->vm_flags & VM_ACCOUNT) {			unsigned int len = (mpnt->vm_end - mpnt->vm_start) >> PAGE_SHIFT;			if (security_vm_enough_memory(len))				goto fail_nomem;			charge = len;		}		tmp = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);		if (!tmp)			goto fail_nomem;		*tmp = *mpnt;		pol = mpol_dup(vma_policy(mpnt));		retval = PTR_ERR(pol);		if (IS_ERR(pol))			goto fail_nomem_policy;		vma_set_policy(tmp, pol);		tmp->vm_flags &= ~VM_LOCKED;		tmp->vm_mm = mm;		tmp->vm_next = NULL;		anon_vma_link(tmp);		file = tmp->vm_file;		if (file) {			struct inode *inode = file->f_path.dentry->d_inode;			struct address_space *mapping = file->f_mapping;			get_file(file);			if (tmp->vm_flags & VM_DENYWRITE)				atomic_dec(&inode->i_writecount);			spin_lock(&mapping->i_mmap_lock);			if (tmp->vm_flags & VM_SHARED)				mapping->i_mmap_writable++;			tmp->vm_truncate_count = mpnt->vm_truncate_count;			flush_dcache_mmap_lock(mapping);			 			vma_prio_tree_add(tmp, mpnt);			flush_dcache_mmap_unlock(mapping);			spin_unlock(&mapping->i_mmap_lock);		}		 		if (is_vm_hugetlb_page(tmp))			reset_vma_resv_huge_pages(tmp);		 		*pprev = tmp;		pprev = &tmp->vm_next;		__vma_link_rb(mm, tmp, rb_link, rb_parent);		rb_link = &tmp->vm_rb.rb_right;		rb_parent = &tmp->vm_rb;		mm->map_count++;		retval = copy_page_range(mm, oldmm, mpnt);		if (tmp->vm_ops && tmp->vm_ops->open)			tmp->vm_ops->open(tmp);		if (retval)			goto out;	}	 	arch_dup_mmap(oldmm, mm);	retval = 0;out:	up_write(&mm->mmap_sem);	flush_tlb_mm(oldmm);	up_write(&oldmm->mmap_sem);	return retval;fail_nomem_policy:	kmem_cache_free(vm_area_cachep, tmp);fail_nomem:	retval = -ENOMEM;	vm_unacct_memory(charge);	goto out;}",28251
360,1859,CVE-2016-9191,24,"static int proc_sys_revalidate(struct dentry *dentry, unsigned int flags){	if (flags & LOOKUP_RCU)		return -ECHILD;	return !PROC_I(d_inode(dentry))->sysctl->unregistering;}",15220
536,341,CVE-2016-4538,24,PHP_MSHUTDOWN_FUNCTION(bcmath){	UNREGISTER_INI_ENTRIES();	return SUCCESS;},1890
578,463,CVE-2012-2669,24,"static void kvp_acquire_lock(int pool){	struct flock fl = {F_WRLCK, SEEK_SET, 0, 0, 0};	fl.l_pid = getpid();	if (fcntl(kvp_file_info[pool].fd, F_SETLKW, &fl) == -1) {		syslog(LOG_ERR, ""Failed to acquire the lock pool: %d"", pool);		exit(-1);	}}",3163
343,236,CVE-2013-2168,24,"_dbus_win_error_string (int error_number){  char *msg;  FormatMessageA (FORMAT_MESSAGE_ALLOCATE_BUFFER |                  FORMAT_MESSAGE_IGNORE_INSERTS |                  FORMAT_MESSAGE_FROM_SYSTEM,                  NULL, error_number, 0,                  (LPSTR) &msg, 0, NULL);  if (msg[strlen (msg) - 1] == '\n')    msg[strlen (msg) - 1] = '\0';  if (msg[strlen (msg) - 1] == '\r')    msg[strlen (msg) - 1] = '\0';  return msg;}",751
365,2695,CVE-2018-6121,24,  void Run() { message_loop_runner_->Run(); },30336
469,169,CVE-2011-1428,24,"irc_server_disconnect_all (){    struct t_irc_server *ptr_server;        for (ptr_server = irc_servers; ptr_server;         ptr_server = ptr_server->next_server)    {        irc_server_disconnect (ptr_server, 0, 0);    }}",663
168,1899,CVE-2016-6197,24,"static int ovl_rmdir(struct inode *dir, struct dentry *dentry){	return ovl_do_remove(dentry, true);}",16254
685,563,CVE-2011-4913,24,void rose_clear_queues(struct sock *sk){	skb_queue_purge(&sk->sk_write_queue);	skb_queue_purge(&rose_sk(sk)->ack_queue);},4410
345,48,CVE-2017-16227,24,"assegment_free (struct assegment *seg){  if (!seg)    return;    if (seg->as)    assegment_data_free (seg->as);  memset (seg, 0xfe, sizeof(struct assegment));  XFREE (MTYPE_AS_SEG, seg);    return;}",370
686,222,CVE-2013-2168,24,_dbus_pid_for_log (void){  return getpid ();},737
566,514,CVE-2012-2136,24,"int sock_no_listen(struct socket *sock, int backlog){	return -EOPNOTSUPP;}",3473
237,2362,CVE-2017-18221,24,"static unsigned long __munlock_pagevec_fill(struct pagevec *pvec,		struct vm_area_struct *vma, int zoneid,	unsigned long start,		unsigned long end){	pte_t *pte;	spinlock_t *ptl;	 	pte = get_locked_pte(vma->vm_mm, start,	&ptl);	 	end = pgd_addr_end(start, end);	end = p4d_addr_end(start, end);	end = pud_addr_end(start, end);	end = pmd_addr_end(start, end);	 	start += PAGE_SIZE;	while (start < end) {		struct page *page = NULL;		pte++;		if (pte_present(*pte))			page = vm_normal_page(vma, start, *pte);		 		if (!page || page_zone_id(page) != zoneid)			break;		 		if (PageTransCompound(page))			break;		get_page(page);		 		start += PAGE_SIZE;		if (pagevec_add(pvec, page) == 0)			break;	}	pte_unmap_unlock(pte, ptl);	return start;}",25827
680,488,CVE-2012-2136,24,"static void sk_prot_free(struct proto *prot, struct sock *sk){	struct kmem_cache *slab;	struct module *owner;	owner = prot->owner;	slab = prot->slab;	security_sk_free(sk);	if (slab != NULL)		kmem_cache_free(slab, sk);	else		kfree(sk);	module_put(owner);}",3447
506,478,CVE-2012-2136,24,"static int proto_seq_open(struct inode *inode, struct file *file){	return seq_open_net(inode, file, &proto_seq_ops,			    sizeof(struct seq_net_private));}",3437
348,2539,CVE-2017-12843,24,"static int parse_windowargs(const char *tag,                            struct windowargs **wa,                            int updates){    struct windowargs windowargs;    struct buf arg = BUF_INITIALIZER;    struct buf ext_folder = BUF_INITIALIZER;    int c;    memset(&windowargs, 0, sizeof(windowargs));    c = prot_getc(imapd_in);    if (c == EOF)        goto out;    if (c != '(') {                 prot_ungetc(c, imapd_in);        goto out;    }    for (;;)    {        c = prot_getc(imapd_in);        if (c == EOF)            goto out;        if (c == ')')            break;           prot_ungetc(c, imapd_in);        c = getword(imapd_in, &arg);        if (!arg.len)            goto syntax_error;        if (!strcasecmp(arg.s, ""CONVERSATIONS""))            windowargs.conversations = 1;        else if (!strcasecmp(arg.s, ""POSITION"")) {            if (updates)                goto syntax_error;            if (c != ' ')                goto syntax_error;            c = prot_getc(imapd_in);            if (c != '(')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.position);            if (c != ' ')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.limit);            if (c != ')')                goto syntax_error;            c = prot_getc(imapd_in);            if (windowargs.position == 0)                goto syntax_error;        }        else if (!strcasecmp(arg.s, ""ANCHOR"")) {            if (updates)                goto syntax_error;            if (c != ' ')                goto syntax_error;            c = prot_getc(imapd_in);            if (c != '(')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.anchor);            if (c != ' ')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.offset);            if (c != ' ')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.limit);            if (c != ')')                goto syntax_error;            c = prot_getc(imapd_in);            if (windowargs.anchor == 0)                goto syntax_error;        }        else if (!strcasecmp(arg.s, ""MULTIANCHOR"")) {            if (updates)                goto syntax_error;            if (c != ' ')                goto syntax_error;            c = prot_getc(imapd_in);            if (c != '(')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.anchor);            if (c != ' ')                goto syntax_error;            c = getastring(imapd_in, imapd_out, &ext_folder);            if (c != ' ')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.offset);            if (c != ' ')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.limit);            if (c != ')')                goto syntax_error;            c = prot_getc(imapd_in);            if (windowargs.anchor == 0)                goto syntax_error;        }        else if (!strcasecmp(arg.s, ""CHANGEDSINCE"")) {            if (!updates)                goto syntax_error;            windowargs.changedsince = 1;            if (c != ' ')                goto syntax_error;            c = prot_getc(imapd_in);            if (c != '(')                goto syntax_error;            c = getmodseq(imapd_in, &windowargs.modseq);            if (c != ' ')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.uidnext);            if (c != ')')                goto syntax_error;            c = prot_getc(imapd_in);        } else if (!strcasecmp(arg.s, ""UPTO"")) {            if (!updates)                goto syntax_error;            if (c != ' ')                goto syntax_error;            c = prot_getc(imapd_in);            if (c != '(')                goto syntax_error;            c = getuint32(imapd_in, &windowargs.upto);            if (c != ')')                goto syntax_error;            c = prot_getc(imapd_in);            if (windowargs.upto == 0)                goto syntax_error;        }        else            goto syntax_error;        if (c == ')')            break;        if (c != ' ')            goto syntax_error;    }    c = prot_getc(imapd_in);    if (c != ' ')        goto syntax_error;out:         if (windowargs.anchor && windowargs.position)        goto syntax_error;         if (!!updates != windowargs.changedsince)        goto syntax_error;    if (ext_folder.len) {        windowargs.anchorfolder = mboxname_from_external(buf_cstring(&ext_folder),                                                         &imapd_namespace,                                                         imapd_userid);    }    *wa = xmemdup(&windowargs, sizeof(windowargs));    buf_free(&ext_folder);    buf_free(&arg);    return c;syntax_error:    free(windowargs.anchorfolder);    buf_free(&ext_folder);    prot_printf(imapd_out, ""%s BAD Syntax error in window arguments\r\n"", tag);    return EOF;}",28540
450,365,CVE-2016-4072,24,"PHP_METHOD(PharFileInfo, getPharFlags){	PHAR_ENTRY_OBJECT();	if (zend_parse_parameters_none() == FAILURE) {		return;	}	RETURN_LONG(entry_obj->entry->flags & ~(PHAR_ENT_PERM_MASK|PHAR_ENT_COMPRESSION_MASK));}",1935
693,1922,CVE-2016-2549,24,static int snd_hrtimer_close(struct snd_timer *t){	struct snd_hrtimer *stime = t->private_data;	if (stime) {		hrtimer_cancel(&stime->hrt);		kfree(stime);		t->private_data = NULL;	}	return 0;},17505
366,620,CVE-2011-1080,24,"ebt_cleanup_entry(struct ebt_entry *e, struct net *net, unsigned int *cnt){	struct xt_tgdtor_param par;	struct ebt_entry_target *t;	if (e->bitmask == 0)		return 0;	 	if (cnt && (*cnt)-- == 0)		return 1;	EBT_WATCHER_ITERATE(e, ebt_cleanup_watcher, net, NULL);	EBT_MATCH_ITERATE(e, ebt_cleanup_match, net, NULL);	t = (struct ebt_entry_target *)(((char *)e) + e->target_offset);	par.net      = net;	par.target   = t->u.target;	par.targinfo = t->data;	par.family   = NFPROTO_BRIDGE;	if (par.target->destroy != NULL)		par.target->destroy(&par);	module_put(par.target->me);	return 0;}",6923
413,1761,CVE-2015-8215,24,"static int addrconf_disable_ipv6(struct ctl_table *table, int *p, int newf){	struct net *net;	int old;	if (!rtnl_trylock())		return restart_syscall();	net = (struct net *)table->extra2;	old = *p;	*p = newf;	if (p == &net->ipv6.devconf_dflt->disable_ipv6) {		rtnl_unlock();		return 0;	}	if (p == &net->ipv6.devconf_all->disable_ipv6) {		net->ipv6.devconf_dflt->disable_ipv6 = newf;		addrconf_disable_change(net, newf);	} else if ((!newf) ^ (!old))		dev_disable_change((struct inet6_dev *)table->extra1);	rtnl_unlock();	return 0;}",12971
262,1240,CVE-2014-2739,24,static struct idr *cma_select_inet_ps(struct rdma_id_private *id_priv){	switch (id_priv->id.ps) {	case RDMA_PS_TCP:		return &tcp_ps;	case RDMA_PS_UDP:		return &udp_ps;	case RDMA_PS_IPOIB:		return &ipoib_ps;	case RDMA_PS_IB:		return &ib_ps;	default:		return NULL;	}},11715
662,554,CVE-2011-4914,24,	__releases(rose_node_list_lock){	spin_unlock_bh(&rose_node_list_lock);},4401
504,700,CVE-2013-6368,24,"int x86_emulate_instruction(struct kvm_vcpu *vcpu,			    unsigned long cr2,			    int emulation_type,			    void *insn,			    int insn_len){	int r;	struct x86_emulate_ctxt *ctxt = &vcpu->arch.emulate_ctxt;	int writeback = true;	int write_fault_to_spt = vcpu->arch.write_fault_to_shadow_pgtable;	 	vcpu->arch.write_fault_to_shadow_pgtable = false;	kvm_clear_exception_queue(vcpu);	if (!(emulation_type & EMULTYPE_NO_DECODE)) {		init_emulate_ctxt(vcpu);		 		if (kvm_vcpu_check_breakpoint(vcpu, &r))			return r;		ctxt->interruptibility = 0;		ctxt->have_exception = false;		ctxt->perm_ok = false;		ctxt->ud = emulation_type & EMULTYPE_TRAP_UD;		r = x86_decode_insn(ctxt, insn, insn_len);		trace_kvm_emulate_insn_start(vcpu);		++vcpu->stat.insn_emulation;		if (r != EMULATION_OK)  {			if (emulation_type & EMULTYPE_TRAP_UD)				return EMULATE_FAIL;			if (reexecute_instruction(vcpu, cr2, write_fault_to_spt,						emulation_type))				return EMULATE_DONE;			if (emulation_type & EMULTYPE_SKIP)				return EMULATE_FAIL;			return handle_emulation_failure(vcpu);		}	}	if (emulation_type & EMULTYPE_SKIP) {		kvm_rip_write(vcpu, ctxt->_eip);		return EMULATE_DONE;	}	if (retry_instruction(ctxt, cr2, emulation_type))		return EMULATE_DONE;	 	if (vcpu->arch.emulate_regs_need_sync_from_vcpu) {		vcpu->arch.emulate_regs_need_sync_from_vcpu = false;		emulator_invalidate_register_cache(ctxt);	}restart:	r = x86_emulate_insn(ctxt);	if (r == EMULATION_INTERCEPTED)		return EMULATE_DONE;	if (r == EMULATION_FAILED) {		if (reexecute_instruction(vcpu, cr2, write_fault_to_spt,					emulation_type))			return EMULATE_DONE;		return handle_emulation_failure(vcpu);	}	if (ctxt->have_exception) {		inject_emulated_exception(vcpu);		r = EMULATE_DONE;	} else if (vcpu->arch.pio.count) {		if (!vcpu->arch.pio.in) {			 			vcpu->arch.pio.count = 0;		} else {			writeback = false;			vcpu->arch.complete_userspace_io = complete_emulated_pio;		}		r = EMULATE_USER_EXIT;	} else if (vcpu->mmio_needed) {		if (!vcpu->mmio_is_write)			writeback = false;		r = EMULATE_USER_EXIT;		vcpu->arch.complete_userspace_io = complete_emulated_mmio;	} else if (r == EMULATION_RESTART)		goto restart;	else		r = EMULATE_DONE;	if (writeback) {		toggle_interruptibility(vcpu, ctxt->interruptibility);		kvm_make_request(KVM_REQ_EVENT, vcpu);		vcpu->arch.emulate_regs_need_sync_to_vcpu = false;		kvm_rip_write(vcpu, ctxt->eip);		if (r == EMULATE_DONE)			kvm_vcpu_check_singlestep(vcpu, &r);		kvm_set_rflags(vcpu, ctxt->eflags);	} else		vcpu->arch.emulate_regs_need_sync_to_vcpu = true;	return r;}",7467
78,45,CVE-2017-16227,24,"assegment_data_new (int num){  return (XMALLOC (MTYPE_AS_SEG_DATA, ASSEGMENT_DATA_SIZE (num, 1)));}",367
438,1764,CVE-2015-8215,24,"static void addrconf_join_anycast(struct inet6_ifaddr *ifp){	struct in6_addr addr;	if (ifp->prefix_len >= 127)  		return;	ipv6_addr_prefix(&addr, &ifp->addr, ifp->prefix_len);	if (ipv6_addr_any(&addr))		return;	__ipv6_dev_ac_inc(ifp->idev, &addr);}",12974
195,150,CVE-2011-1428,24,"hook_timer_time_to_next (struct timeval *tv_timeout){    struct t_hook *ptr_hook;    int found;    struct timeval tv_now;    long diff_usec;        hook_timer_check_system_clock ();        found = 0;    tv_timeout->tv_sec = 0;    tv_timeout->tv_usec = 0;        for (ptr_hook = weechat_hooks[HOOK_TYPE_TIMER]; ptr_hook;         ptr_hook = ptr_hook->next_hook)    {        if (!ptr_hook->deleted            && (!found                || (util_timeval_cmp (&HOOK_TIMER(ptr_hook, next_exec), tv_timeout) < 0)))        {            found = 1;            tv_timeout->tv_sec = HOOK_TIMER(ptr_hook, next_exec).tv_sec;            tv_timeout->tv_usec = HOOK_TIMER(ptr_hook, next_exec).tv_usec;        }    }             if (!found)    {        tv_timeout->tv_sec = 2;        tv_timeout->tv_usec = 0;        return;    }        gettimeofday (&tv_now, NULL);             if (util_timeval_cmp (tv_timeout, &tv_now) < 0)    {        tv_timeout->tv_sec = 0;        tv_timeout->tv_usec = 0;        return;    }        tv_timeout->tv_sec = tv_timeout->tv_sec - tv_now.tv_sec;    diff_usec = tv_timeout->tv_usec - tv_now.tv_usec;    if (diff_usec >= 0)        tv_timeout->tv_usec = diff_usec;    else    {        tv_timeout->tv_sec--;        tv_timeout->tv_usec = 1000000 + diff_usec;    }             if (tv_timeout->tv_sec > 2)    {        tv_timeout->tv_sec = 2;        tv_timeout->tv_usec = 0;    }}",644
410,1238,CVE-2014-2739,24,"static void cma_save_ip6_info(struct rdma_cm_id *id, struct rdma_cm_id *listen_id,			      struct cma_hdr *hdr){	struct sockaddr_in6 *listen6, *ip6;	listen6 = (struct sockaddr_in6 *) &listen_id->route.addr.src_addr;	ip6 = (struct sockaddr_in6 *) &id->route.addr.src_addr;	ip6->sin6_family = listen6->sin6_family;	ip6->sin6_addr = hdr->dst_addr.ip6;	ip6->sin6_port = listen6->sin6_port;	ip6 = (struct sockaddr_in6 *) &id->route.addr.dst_addr;	ip6->sin6_family = listen6->sin6_family;	ip6->sin6_addr = hdr->src_addr.ip6;	ip6->sin6_port = hdr->port;}",11713
643,1069,CVE-2014-3645,24,"int kvm_test_age_hva(struct kvm *kvm, unsigned long hva){	return kvm_handle_hva(kvm, hva, 0, kvm_test_age_rmapp);}",11203
560,861,CVE-2013-1819,24,mem_to_page(	void			*addr){	if ((!is_vmalloc_addr(addr))) {		return virt_to_page(addr);	} else {		return vmalloc_to_page(addr);	}},9468
186,1024,CVE-2014-3645,24,static int alloc_mmu_pages(struct kvm_vcpu *vcpu){	struct page *page;	int i;	ASSERT(vcpu);	 	page = alloc_page(GFP_KERNEL | __GFP_DMA32);	if (!page)		return -ENOMEM;	vcpu->arch.mmu.pae_root = page_address(page);	for (i = 0; i < 4; ++i)		vcpu->arch.mmu.pae_root[i] = INVALID_PAGE;	return 0;},11158
571,2662,CVE-2018-6085,24,int MaxStorageSizeForTable(int table_len) {  return table_len * (k64kEntriesStore / kBaseTableLen);},30094
272,1295,CVE-2014-2038,24,static void nfs_commit_release(void *calldata){	struct nfs_commit_data *data = calldata;	data->completion_ops->completion(data);	nfs_commitdata_release(calldata);},11842
372,764,CVE-2013-2146,24,"__intel_shared_reg_put_constraints(struct cpu_hw_events *cpuc,				   struct hw_perf_event_extra *reg){	struct er_account *era;	 	if (!reg->alloc || cpuc->is_fake)		return;	era = &cpuc->shared_regs->regs[reg->idx];	 	atomic_dec(&era->ref);	 	reg->alloc = 0;}",8789
202,2482,CVE-2012-0879,24,"void __set_special_pids(struct pid *pid){	struct task_struct *curr = current->group_leader;	if (task_session(curr) != pid)		change_pid(curr, PIDTYPE_SID, pid);	if (task_pgrp(curr) != pid)		change_pid(curr, PIDTYPE_PGID, pid);}",28239
411,1192,CVE-2014-2739,24,"static int cma_addr_cmp(struct sockaddr *src, struct sockaddr *dst){	if (src->sa_family != dst->sa_family)		return -1;	switch (src->sa_family) {	case AF_INET:		return ((struct sockaddr_in *) src)->sin_addr.s_addr !=		       ((struct sockaddr_in *) dst)->sin_addr.s_addr;	case AF_INET6:		return ipv6_addr_cmp(&((struct sockaddr_in6 *) src)->sin6_addr,				     &((struct sockaddr_in6 *) dst)->sin6_addr);	default:		return ib_addr_cmp(&((struct sockaddr_ib *) src)->sib_addr,				   &((struct sockaddr_ib *) dst)->sib_addr);	}}",11667
430,322,CVE-2017-5932,24,clear_fifo_list (){},1626
649,1830,CVE-2016-9191,24,"struct ctl_table_header *__register_sysctl_table(	struct ctl_table_set *set,	const char *path, struct ctl_table *table){	struct ctl_table_root *root = set->dir.header.root;	struct ctl_table_header *header;	const char *name, *nextname;	struct ctl_dir *dir;	struct ctl_table *entry;	struct ctl_node *node;	int nr_entries = 0;	for (entry = table; entry->procname; entry++)		nr_entries++;	header = kzalloc(sizeof(struct ctl_table_header) +			 sizeof(struct ctl_node)*nr_entries, GFP_KERNEL);	if (!header)		return NULL;	node = (struct ctl_node *)(header + 1);	init_header(header, root, set, node, table);	if (sysctl_check_table(path, table))		goto fail;	spin_lock(&sysctl_lock);	dir = &set->dir;	 	dir->header.nreg++;	spin_unlock(&sysctl_lock);	 	for (name = path; name; name = nextname) {		int namelen;		nextname = strchr(name, '/');		if (nextname) {			namelen = nextname - name;			nextname++;		} else {			namelen = strlen(name);		}		if (namelen == 0)			continue;		dir = get_subdir(dir, name, namelen);		if (IS_ERR(dir))			goto fail;	}	spin_lock(&sysctl_lock);	if (insert_header(dir, header))		goto fail_put_dir_locked;	drop_sysctl_table(&dir->header);	spin_unlock(&sysctl_lock);	return header;fail_put_dir_locked:	drop_sysctl_table(&dir->header);	spin_unlock(&sysctl_lock);fail:	kfree(header);	dump_stack();	return NULL;}",15191
684,1084,CVE-2014-3645,24,static int mmu_memory_cache_free_objects(struct kvm_mmu_memory_cache *cache){	return cache->nobjs;},11218
598,2058,CVE-2017-17862,24,static int reg_is_pkt_pointer(const struct bpf_reg_state *reg){	return type_is_pkt_pointer(reg->type);},19556
364,1544,CVE-2013-7271,24,"static struct sco_conn *sco_conn_add(struct hci_conn *hcon){	struct hci_dev *hdev = hcon->hdev;	struct sco_conn *conn = hcon->sco_data;	if (conn)		return conn;	conn = kzalloc(sizeof(struct sco_conn), GFP_KERNEL);	if (!conn)		return NULL;	spin_lock_init(&conn->lock);	hcon->sco_data = conn;	conn->hcon = hcon;	if (hdev->sco_mtu > 0)		conn->mtu = hdev->sco_mtu;	else		conn->mtu = 60;	BT_DBG(""hcon %p conn %p"", hcon, conn);	return conn;}",12432
503,308,CVE-2014-7840,24,int xbzrle_mig_pages_overflow(void){    return acct_info.xbzrle_overflows;},1308
690,1993,CVE-2017-1000252,24,irqfd_is_active(struct kvm_kernel_irqfd *irqfd){	return list_empty(&irqfd->list) ? false : true;},19454
98,2185,CVE-2017-7645,24,static void nfsd_shutdown_generic(void){	if (--nfsd_users)		return;	nfs4_state_shutdown();	nfsd_racache_shutdown();},21513
520,2671,CVE-2018-6111,24,  void AddObserverOnIDBThread() {    DCHECK(context_->TaskRunner()->RunsTasksInCurrentSequence());    context_->AddObserver(this);  },30119
497,957,CVE-2014-5472,24,"isofs_dentry_cmp(const struct dentry *parent, const struct dentry *dentry,		unsigned int len, const char *str, const struct qstr *name){	return isofs_dentry_cmp_common(len, str, name, 0, 0);}",10614
674,1163,CVE-2014-2739,24,static void cm_free_msg(struct ib_mad_send_buf *msg){	ib_destroy_ah(msg->ah);	if (msg->context[0])		cm_deref_id(msg->context[0]);	ib_free_send_mad(msg);},11638
516,1431,CVE-2014-0203,24,"static int get_fs_path(struct task_struct *task, struct path *path, int root){	struct fs_struct *fs;	int result = -ENOENT;	task_lock(task);	fs = task->fs;	if (fs) {		read_lock(&fs->lock);		*path = root ? fs->root : fs->pwd;		path_get(path);		read_unlock(&fs->lock);		result = 0;	}	task_unlock(task);	return result;}",12141
492,1134,CVE-2014-3645,24,"static void vmx_hwapic_irr_update(struct kvm_vcpu *vcpu, int max_irr){	if (max_irr == -1)		return;	vmx_set_rvi(max_irr);}",11268
646,678,CVE-2013-6368,24,"int kvm_set_msr(struct kvm_vcpu *vcpu, struct msr_data *msr){	return kvm_x86_ops->set_msr(vcpu, msr);}",7445
189,537,CVE-2011-4914,24,static void rose_destroy_timer(unsigned long data){	rose_destroy_socket((struct sock *)data);},4384
385,2087,CVE-2017-15951,24,"static struct rb_node *key_user_next(struct user_namespace *user_ns, struct rb_node *n){	return __key_user_next(user_ns, rb_next(n));}",19910
357,1894,CVE-2016-6197,24,"static int ovl_link(struct dentry *old, struct inode *newdir,		    struct dentry *new){	int err;	struct dentry *upper;	err = ovl_want_write(old);	if (err)		goto out;	err = ovl_copy_up(old);	if (err)		goto out_drop_write;	upper = ovl_dentry_upper(old);	err = ovl_create_or_link(new, upper->d_inode->i_mode, 0, NULL, upper);out_drop_write:	ovl_drop_write(old);out:	return err;}",16249
409,2560,CVE-2019-1010251,24,"void AppLayerProtoDetectUnittestCtxBackup(void){    SCEnter();    alpd_ctx_ut = alpd_ctx;    memset(&alpd_ctx, 0, sizeof(alpd_ctx));    SCReturn;}",28861
140,1731,CVE-2013-7271,24,"static int x25_listen(struct socket *sock, int backlog){	struct sock *sk = sock->sk;	int rc = -EOPNOTSUPP;	lock_sock(sk);	if (sk->sk_state != TCP_LISTEN) {		memset(&x25_sk(sk)->dest_addr, 0, X25_ADDR_LEN);		sk->sk_max_ack_backlog = backlog;		sk->sk_state           = TCP_LISTEN;		rc = 0;	}	release_sock(sk);	return rc;}",12619
462,1798,CVE-2015-8215,24,"int ipv6_chk_addr(struct net *net, const struct in6_addr *addr,		  const struct net_device *dev, int strict){	return ipv6_chk_addr_and_flags(net, addr, dev, strict, IFA_F_TENTATIVE);}",13008
648,2203,CVE-2017-6345,24,"static inline int llc_dgram_match(const struct llc_sap *sap,				   const struct llc_addr *laddr,				   const struct sock *sk){     struct llc_sock *llc = llc_sk(sk);     return sk->sk_type == SOCK_DGRAM &&	  llc->laddr.lsap == laddr->lsap &&	  ether_addr_equal(llc->laddr.mac, laddr->mac);}",21836
358,2524,CVE-2017-12843,24,"static int getlistretopts(char *tag, struct listargs *args){    static struct buf buf;    int c;    c = getword(imapd_in, &buf);    if (!*buf.s) {        prot_printf(imapd_out,                    ""%s BAD Invalid syntax in List command\r\n"", tag);        return EOF;    }    lcase(buf.s);    if (strcasecmp(buf.s, ""return"")) {        prot_printf(imapd_out,                    ""%s BAD Unexpected extra argument to List: \""%s\""\r\n"",                    tag, buf.s);        return EOF;    }    if (c != ' ' || (c = prot_getc(imapd_in)) != '(') {        prot_printf(imapd_out,                    ""%s BAD Missing return argument list\r\n"", tag);        return EOF;    }    if ( (c = prot_getc(imapd_in)) == ')')        return prot_getc(imapd_in);    else        prot_ungetc(c, imapd_in);    for (;;) {        c = getword(imapd_in, &buf);        if (!*buf.s) {            prot_printf(imapd_out,                        ""%s BAD Invalid syntax in List command\r\n"", tag);            return EOF;        }        lcase(buf.s);        if (!strcmp(buf.s, ""subscribed""))            args->ret |= LIST_RET_SUBSCRIBED;        else if (!strcmp(buf.s, ""children""))            args->ret |= LIST_RET_CHILDREN;        else if (!strcmp(buf.s, ""myrights""))            args->ret |= LIST_RET_MYRIGHTS;        else if (!strcmp(buf.s, ""special-use""))            args->ret |= LIST_RET_SPECIALUSE;        else if (!strcmp(buf.s, ""status"")) {            const char *errstr = ""Bad status string"";            args->ret |= LIST_RET_STATUS;            c = parse_statusitems(&args->statusitems, &errstr);            if (c == EOF) {                prot_printf(imapd_out, ""%s BAD %s"", tag, errstr);                return EOF;            }        }        else if (!strcmp(buf.s, ""metadata"")) {            args->ret |= LIST_RET_METADATA;                         c = parse_metadata_string_or_list(tag, &args->metaitems, NULL);            if (c == EOF) return EOF;        }        else {            prot_printf(imapd_out,                        ""%s BAD Invalid List return option \""%s\""\r\n"",                        tag, buf.s);            return EOF;        }        if (c != ' ') break;    }    if (c != ')') {        prot_printf(imapd_out,                    ""%s BAD Missing close parenthesis for List return options\r\n"", tag);        return EOF;    }    return prot_getc(imapd_in);}",28525
681,2448,CVE-2017-18509,24,"static int ipmr_mfc_open(struct inode *inode, struct file *file){	return seq_open_net(inode, file, &ipmr_mfc_seq_ops,			    sizeof(struct ipmr_mfc_iter));}",28062
110,667,CVE-2013-6368,24,int kvm_arch_vcpu_runnable(struct kvm_vcpu *vcpu){	return (vcpu->arch.mp_state == KVM_MP_STATE_RUNNABLE &&		!vcpu->arch.apf.halted)		|| !list_empty_careful(&vcpu->async_pf.done)		|| kvm_apic_has_events(vcpu)		|| vcpu->arch.pv.pv_unhalted		|| atomic_read(&vcpu->arch.nmi_queued) ||		(kvm_arch_interrupt_allowed(vcpu) &&		 kvm_cpu_has_interrupt(vcpu));},7434
656,2012,CVE-2017-1000201,24,"static int open_handlers(void){	struct dirent **dirent_list;	int num_handlers;	int num_good = 0;	int i;	num_handlers = scandir(handler_path, &dirent_list, is_handler, alphasort);	if (num_handlers == -1)		return -1;	for (i = 0; i < num_handlers; i++) {		char *path;		void *handle;		int (*handler_init)(void);		int ret;		ret = asprintf(&path, ""%s/%s"", handler_path, dirent_list[i]->d_name);		if (ret == -1) {			tcmu_err(""ENOMEM\n"");			continue;		}		handle = dlopen(path, RTLD_NOW|RTLD_LOCAL);		if (!handle) {			tcmu_err(""Could not open handler at %s: %s\n"", path, dlerror());			free(path);			continue;		}		handler_init = dlsym(handle, ""handler_init"");		if (!handler_init) {			tcmu_err(""dlsym failure on %s\n"", path);			free(path);			continue;		}		ret = handler_init();		free(path);		if (ret == 0)			num_good++;	}	for (i = 0; i < num_handlers; i++)		free(dirent_list[i]);	free(dirent_list);	return num_good;}",19502
640,1535,CVE-2013-7271,24,"void hci_sock_cleanup(void){	bt_procfs_cleanup(&init_net, ""hci"");	bt_sock_unregister(BTPROTO_HCI);	proto_unregister(&hci_sk_proto);}",12423
367,2666,CVE-2018-6089,24,  void InitializeServer() {    embedded_test_server()->ServeFilesFromDirectory(        service_worker_dir_.GetPath());    ASSERT_TRUE(embedded_test_server()->Start());  },30098
147,309,CVE-2014-7840,24,int xbzrle_mig_pages_transferred(void){    return acct_info.xbzrle_pages;},1309
308,1031,CVE-2014-3645,24,"static int init_kvm_softmmu(struct kvm_vcpu *vcpu){	int r = kvm_init_shadow_mmu(vcpu, vcpu->arch.walk_mmu);	vcpu->arch.walk_mmu->set_cr3           = kvm_x86_ops->set_cr3;	vcpu->arch.walk_mmu->get_cr3           = get_cr3;	vcpu->arch.walk_mmu->get_pdptr         = kvm_pdptr_read;	vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;	return r;}",11165
478,148,CVE-2011-1428,24,"hook_signal_send (const char *signal, const char *type_data, void *signal_data){    struct t_hook *ptr_hook, *next_hook;        hook_exec_start ();        ptr_hook = weechat_hooks[HOOK_TYPE_SIGNAL];    while (ptr_hook)    {        next_hook = ptr_hook->next_hook;                if (!ptr_hook->deleted            && !ptr_hook->running            && (string_match (signal, HOOK_SIGNAL(ptr_hook, signal), 0)))        {            ptr_hook->running = 1;            (void) (HOOK_SIGNAL(ptr_hook, callback))                (ptr_hook->callback_data, signal, type_data, signal_data);            ptr_hook->running = 0;        }                ptr_hook = next_hook;    }        hook_exec_end ();}",642
163,1706,CVE-2013-7271,24,"static void unix_release_sock(struct sock *sk, int embrion){	struct unix_sock *u = unix_sk(sk);	struct path path;	struct sock *skpair;	struct sk_buff *skb;	int state;	unix_remove_socket(sk);	 	unix_state_lock(sk);	sock_orphan(sk);	sk->sk_shutdown = SHUTDOWN_MASK;	path	     = u->path;	u->path.dentry = NULL;	u->path.mnt = NULL;	state = sk->sk_state;	sk->sk_state = TCP_CLOSE;	unix_state_unlock(sk);	wake_up_interruptible_all(&u->peer_wait);	skpair = unix_peer(sk);	if (skpair != NULL) {		if (sk->sk_type == SOCK_STREAM || sk->sk_type == SOCK_SEQPACKET) {			unix_state_lock(skpair);			 			skpair->sk_shutdown = SHUTDOWN_MASK;			if (!skb_queue_empty(&sk->sk_receive_queue) || embrion)				skpair->sk_err = ECONNRESET;			unix_state_unlock(skpair);			skpair->sk_state_change(skpair);			sk_wake_async(skpair, SOCK_WAKE_WAITD, POLL_HUP);		}		sock_put(skpair);  		unix_peer(sk) = NULL;	}	 	while ((skb = skb_dequeue(&sk->sk_receive_queue)) != NULL) {		if (state == TCP_LISTEN)			unix_release_sock(skb->sk, 1);		 		kfree_skb(skb);	}	if (path.dentry)		path_put(&path);	sock_put(sk);	 	 	if (unix_tot_inflight)		unix_gc();		 }",12594
627,217,CVE-2013-2168,24,_dbus_flush_caches (void){  _dbus_user_database_flush_system ();},732
457,1261,CVE-2014-2673,24,unsigned long randomize_et_dyn(unsigned long base){	unsigned long ret = PAGE_ALIGN(base + brk_rnd());	if (ret < base)		return base;	return ret;},11753
183,65,CVE-2011-2724,24,"toggle_dac_capability(int writable, int enable){	unsigned int capability = writable ? CAP_DAC_OVERRIDE : CAP_DAC_READ_SEARCH;	if (capng_update(enable ? CAPNG_ADD : CAPNG_DROP, CAPNG_EFFECTIVE, capability)) {		fprintf(stderr, ""Unable to update capability set.\n"");		return EX_SYSERR;	}	if (capng_apply(CAPNG_SELECT_CAPS)) {		fprintf(stderr, ""Unable to apply new capability set.\n"");		return EX_SYSERR;	}	return 0;}",442
407,891,CVE-2013-1798,24,"int kvm_ioapic_init(struct kvm *kvm){	struct kvm_ioapic *ioapic;	int ret;	ioapic = kzalloc(sizeof(struct kvm_ioapic), GFP_KERNEL);	if (!ioapic)		return -ENOMEM;	spin_lock_init(&ioapic->lock);	kvm->arch.vioapic = ioapic;	kvm_ioapic_reset(ioapic);	kvm_iodevice_init(&ioapic->dev, &ioapic_mmio_ops);	ioapic->kvm = kvm;	mutex_lock(&kvm->slots_lock);	ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, ioapic->base_address,				      IOAPIC_MEM_LENGTH, &ioapic->dev);	mutex_unlock(&kvm->slots_lock);	if (ret < 0) {		kvm->arch.vioapic = NULL;		kfree(ioapic);	}	return ret;}",9498
68,1183,CVE-2014-2739,24,"static int cm_rtu_handler(struct cm_work *work){	struct cm_id_private *cm_id_priv;	struct cm_rtu_msg *rtu_msg;	int ret;	rtu_msg = (struct cm_rtu_msg *)work->mad_recv_wc->recv_buf.mad;	cm_id_priv = cm_acquire_id(rtu_msg->remote_comm_id,				   rtu_msg->local_comm_id);	if (!cm_id_priv)		return -EINVAL;	work->cm_event.private_data = &rtu_msg->private_data;	spin_lock_irq(&cm_id_priv->lock);	if (cm_id_priv->id.state != IB_CM_REP_SENT &&	    cm_id_priv->id.state != IB_CM_MRA_REP_RCVD) {		spin_unlock_irq(&cm_id_priv->lock);		atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].				counter[CM_RTU_COUNTER]);		goto out;	}	cm_id_priv->id.state = IB_CM_ESTABLISHED;	ib_cancel_mad(cm_id_priv->av.port->mad_agent, cm_id_priv->msg);	ret = atomic_inc_and_test(&cm_id_priv->work_count);	if (!ret)		list_add_tail(&work->list, &cm_id_priv->work_list);	spin_unlock_irq(&cm_id_priv->lock);	if (ret)		cm_process_work(cm_id_priv, work);	else		cm_deref_id(cm_id_priv);	return 0;out:	cm_deref_id(cm_id_priv);	return -EINVAL;}",11658
589,136,CVE-2011-1428,24,"hook_process_add_to_buffer (struct t_hook *hook_process, int index_buffer,                            const char *buffer, int size){    if (HOOK_PROCESS(hook_process, buffer_size[index_buffer]) + size > HOOK_PROCESS_BUFFER_SIZE)        hook_process_send_buffers (hook_process, WEECHAT_HOOK_PROCESS_RUNNING);        memcpy (HOOK_PROCESS(hook_process, buffer[index_buffer]) +            HOOK_PROCESS(hook_process, buffer_size[index_buffer]),            buffer, size);    HOOK_PROCESS(hook_process, buffer_size[index_buffer]) += size;}",630
324,900,CVE-2013-1763,24,int sock_diag_register(const struct sock_diag_handler *hndl){	int err = 0;	if (hndl->family >= AF_MAX)		return -EINVAL;	mutex_lock(&sock_diag_table_mutex);	if (sock_diag_handlers[hndl->family])		err = -EBUSY;	else		sock_diag_handlers[hndl->family] = hndl;	mutex_unlock(&sock_diag_table_mutex);	return err;},9668
201,455,CVE-2010-1152,24,"static int server_socket_unix(const char *path, int access_mask) {    int sfd;    struct linger ling = {0, 0};    struct sockaddr_un addr;    struct stat tstat;    int flags =1;    int old_umask;    if (!path) {        return 1;    }    if ((sfd = new_socket_unix()) == -1) {        return 1;    }         if (lstat(path, &tstat) == 0) {        if (S_ISSOCK(tstat.st_mode))            unlink(path);    }    setsockopt(sfd, SOL_SOCKET, SO_REUSEADDR, (void *)&flags, sizeof(flags));    setsockopt(sfd, SOL_SOCKET, SO_KEEPALIVE, (void *)&flags, sizeof(flags));    setsockopt(sfd, SOL_SOCKET, SO_LINGER, (void *)&ling, sizeof(ling));         memset(&addr, 0, sizeof(addr));    addr.sun_family = AF_UNIX;    strncpy(addr.sun_path, path, sizeof(addr.sun_path) - 1);    assert(strcmp(addr.sun_path, path) == 0);    old_umask = umask( ~(access_mask&0777));    if (bind(sfd, (struct sockaddr *)&addr, sizeof(addr)) == -1) {        perror(""bind()"");        close(sfd);        umask(old_umask);        return 1;    }    umask(old_umask);    if (listen(sfd, settings.backlog) == -1) {        perror(""listen()"");        close(sfd);        return 1;    }    if (!(listen_conn = conn_new(sfd, conn_listening,                                 EV_READ | EV_PERSIST, 1,                                 local_transport, main_base))) {        fprintf(stderr, ""failed to create listening connection\n"");        exit(EXIT_FAILURE);    }    return 0;}",2646
5,173,CVE-2011-1428,24,irc_server_get_channel_count (struct t_irc_server *server){    int count;    struct t_irc_channel *ptr_channel;        count = 0;    for (ptr_channel = server->channels; ptr_channel;         ptr_channel = ptr_channel->next_channel)    {        if (ptr_channel->type == IRC_CHANNEL_TYPE_CHANNEL)        count++;    }    return count;},667
153,1471,CVE-2014-0077,24,static void vhost_net_ubuf_put_wait_and_free(struct vhost_net_ubuf_ref *ubufs){	vhost_net_ubuf_put_and_wait(ubufs);	kfree(ubufs);},12284
193,4,CVE-2018-1000037,24,	fz_catch(ctx)	{		fz_rethrow(ctx);	},76
296,1135,CVE-2014-3645,24,static int vmx_interrupt_allowed(struct kvm_vcpu *vcpu){	if (is_guest_mode(vcpu)) {		struct vmcs12 *vmcs12 = get_vmcs12(vcpu);		if (to_vmx(vcpu)->nested.nested_run_pending)			return 0;		if (nested_exit_on_intr(vcpu)) {			nested_vmx_vmexit(vcpu);			vmcs12->vm_exit_reason =				EXIT_REASON_EXTERNAL_INTERRUPT;			vmcs12->vm_exit_intr_info = 0;			 		}	}	return (vmcs_readl(GUEST_RFLAGS) & X86_EFLAGS_IF) &&		!(vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &			(GUEST_INTR_STATE_STI | GUEST_INTR_STATE_MOV_SS));},11269
74,2716,CVE-2016-3760,24,"int btif_config_has_section(const char *section) {  assert(config != NULL);  assert(section != NULL);  pthread_mutex_lock(&lock); int ret = config_has_section(config, section);  pthread_mutex_unlock(&lock); return ret;}",30527
22,1111,CVE-2014-3645,24,"static void clear_atomic_switch_msr(struct vcpu_vmx *vmx, unsigned msr){	unsigned i;	struct msr_autoload *m = &vmx->msr_autoload;	switch (msr) {	case MSR_EFER:		if (cpu_has_load_ia32_efer) {			clear_atomic_switch_msr_special(VM_ENTRY_LOAD_IA32_EFER,					VM_EXIT_LOAD_IA32_EFER);			return;		}		break;	case MSR_CORE_PERF_GLOBAL_CTRL:		if (cpu_has_load_perf_global_ctrl) {			clear_atomic_switch_msr_special(					VM_ENTRY_LOAD_IA32_PERF_GLOBAL_CTRL,					VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL);			return;		}		break;	}	for (i = 0; i < m->nr; ++i)		if (m->guest[i].index == msr)			break;	if (i == m->nr)		return;	--m->nr;	m->guest[i] = m->guest[m->nr];	m->host[i] = m->host[m->nr];	vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->nr);	vmcs_write32(VM_EXIT_MSR_LOAD_COUNT, m->nr);}",11245
19,242,CVE-2015-0293,24,int ssl2_num_ciphers(void){    return (SSL2_NUM_CIPHERS);},991
144,487,CVE-2012-2136,24,"void sk_prot_clear_portaddr_nulls(struct sock *sk, int size){	unsigned long nulls1, nulls2;	nulls1 = offsetof(struct sock, __sk_common.skc_node.next);	nulls2 = offsetof(struct sock, __sk_common.skc_portaddr_node.next);	if (nulls1 > nulls2)		swap(nulls1, nulls2);	if (nulls1 != 0)		memset((char *)sk, 0, nulls1);	memset((char *)sk + nulls1 + sizeof(void *), 0,	       nulls2 - nulls1 - sizeof(void *));	memset((char *)sk + nulls2 + sizeof(void *), 0,	       size - nulls2 - sizeof(void *));}",3446
426,2472,CVE-2010-1152,24,"static enum test_return test_binary_prepend(void) {    return test_binary_concat_impl(""test_binary_prepend"",                                   PROTOCOL_BINARY_CMD_PREPEND);}",28229
115,2660,CVE-2018-6043,24,   int has_prompted() { return has_prompted_; },30083
653,1243,CVE-2014-2739,24,"static void cma_set_req_event_data(struct rdma_cm_event *event,				   struct ib_cm_req_event_param *req_data,				   void *private_data, int offset){	event->param.conn.private_data = private_data + offset;	event->param.conn.private_data_len = IB_CM_REQ_PRIVATE_DATA_SIZE - offset;	event->param.conn.responder_resources = req_data->responder_resources;	event->param.conn.initiator_depth = req_data->initiator_depth;	event->param.conn.flow_control = req_data->flow_control;	event->param.conn.retry_count = req_data->retry_count;	event->param.conn.rnr_retry_count = req_data->rnr_retry_count;	event->param.conn.srq = req_data->srq;	event->param.conn.qp_num = req_data->remote_qpn;}",11718
300,1007,CVE-2014-4503,24,"int sock_full(struct pool *pool){	if (strlen(pool->sockbuf))		return true;	return (socket_full(pool, 0));}",10875
341,998,CVE-2014-4503,24,"int fulltest(const unsigned char *hash, const unsigned char *target){	int *hash32 = (int *)hash;	int *target32 = (int *)target;	int rc = true;	int i;	for (i = 28 / 4; i >= 0; i--) {		int h32tmp = le32toh(hash32[i]);		int t32tmp = le32toh(target32[i]);		if (h32tmp > t32tmp) {			rc = false;			break;		}		if (h32tmp < t32tmp) {			rc = true;			break;		}	}	if (opt_debug) {		unsigned char hash_swap[32], target_swap[32];		char *hash_str, *target_str;		swab256(hash_swap, hash);		swab256(target_swap, target);		hash_str = bin2hex(hash_swap, 32);		target_str = bin2hex(target_swap, 32);		applog(LOG_DEBUG, "" Proof: %s\nTarget: %s\nTrgVal? %s"",			hash_str,			target_str,			rc ? ""YES (hash <= target)"" :			     ""no (false positive; hash > target)"");		free(hash_str);		free(target_str);	}	return rc;}",10866
543,1562,CVE-2013-7271,24,"static int ipxitf_create_internal(struct ipx_interface_definition *idef){	struct ipx_interface *intrfc;	int rc = -EEXIST;	 	if (ipx_primary_net)		goto out;	 	rc = -EADDRNOTAVAIL;	if (!idef->ipx_network)		goto out;	intrfc = ipxitf_find_using_net(idef->ipx_network);	rc = -EADDRINUSE;	if (intrfc) {		ipxitf_put(intrfc);		goto out;	}	intrfc = ipxitf_alloc(NULL, idef->ipx_network, 0, NULL, 1, 0);	rc = -EAGAIN;	if (!intrfc)		goto out;	memcpy((char *)&(intrfc->if_node), idef->ipx_node, IPX_NODE_LEN);	ipx_internal_net = ipx_primary_net = intrfc;	ipxitf_hold(intrfc);	ipxitf_insert(intrfc);	rc = ipxitf_add_local_route(intrfc);	ipxitf_put(intrfc);out:	return rc;}",12450
265,2101,CVE-2017-15951,24,static int request_key_auth_preparse(struct key_preparsed_payload *prep){	return 0;},19924
234,394,CVE-2011-3936,24,"static const int* dv_extract_pack(int* frame, enum dv_pack_type t){    int offs;    switch (t) {    case dv_audio_source:        offs = (80*6 + 80*16*3 + 3);        break;    case dv_audio_control:        offs = (80*6 + 80*16*4 + 3);        break;    case dv_video_control:        offs = (80*5 + 48 + 5);        break;    default:        return NULL;    }    return frame[offs] == t ? &frame[offs] : NULL;}",2222
502,1987,CVE-2008-7316,24,"static void shrink_readahead_size_eio(struct file *filp,					struct file_ra_state *ra){	if (!ra->ra_pages)		return;	ra->ra_pages /= 4;}",19439
299,779,CVE-2013-2146,24,static void intel_pmu_flush_branch_stack(void){	 	if (x86_pmu.lbr_nr)		intel_pmu_lbr_reset();},8804
105,495,CVE-2012-2136,24,"void sk_stop_timer(struct sock *sk, struct timer_list* timer){	if (timer_pending(timer) && del_timer(timer))		__sock_put(sk);}",3454
166,2089,CVE-2017-15951,24,"static int proc_keys_open(struct inode *inode, struct file *file){	return seq_open(file, &proc_keys_ops);}",19912
625,1420,CVE-2014-0203,24,"int vfs_path_lookup(struct dentry *dentry, struct vfsmount *mnt,		    const char *name, unsigned int flags,		    struct nameidata *nd){	int retval;	 	nd->last_type = LAST_ROOT;	nd->flags = flags;	nd->depth = 0;	nd->path.dentry = dentry;	nd->path.mnt = mnt;	path_get(&nd->path);	nd->root = nd->path;	path_get(&nd->root);	retval = path_walk(name, nd);	if (unlikely(!retval && !audit_dummy_context() && nd->path.dentry &&				nd->path.dentry->d_inode))		audit_inode(name, nd->path.dentry);	path_put(&nd->root);	nd->root.mnt = NULL;	return retval;}",12130
376,519,CVE-2012-2136,24,"void sock_prot_inuse_add(struct net *net, struct proto *prot, int val){	__this_cpu_add(prot_inuse.val[prot->inuse_idx], val);}",3478
456,1744,CVE-2015-8215,24,"	__acquires(rcu_bh){	rcu_read_lock_bh();	return if6_get_first(seq, *pos);}",12954
489,1607,CVE-2013-7271,24,"netlink_lookup_frame(const struct netlink_ring *ring, unsigned int pos,		     enum nl_mmap_status status){	struct nl_mmap_hdr *hdr;	hdr = __netlink_lookup_frame(ring, pos);	if (netlink_get_status(hdr) != status)		return NULL;	return hdr;}",12495
194,2611,CVE-2018-18347,24,  ChromeNavigationPortMappedBrowserTest() {},29974
585,2630,CVE-2018-17467,24,  InputMethodStateAuraTest() {},30045
363,1785,CVE-2015-8215,24,"static int inet6_dump_ifacaddr(struct sk_buff *skb, struct netlink_callback *cb){	enum addr_type_t type = ANYCAST_ADDR;	return inet6_dump_addr(skb, cb, type);}",12995
169,2396,CVE-2017-18200,24,"static int f2fs_quota_sync(struct super_block *sb, int type){	struct quota_info *dqopt = sb_dqopt(sb);	int cnt;	int ret;	ret = dquot_writeback_dquots(sb, type);	if (ret)		return ret;	 	for (cnt = 0; cnt < MAXQUOTAS; cnt++) {		if (type != -1 && cnt != type)			continue;		if (!sb_has_quota_active(sb, cnt))			continue;		ret = filemap_write_and_wait(dqopt->files[cnt]->i_mapping);		if (ret)			return ret;		inode_lock(dqopt->files[cnt]);		truncate_inode_pages(&dqopt->files[cnt]->i_data, 0);		inode_unlock(dqopt->files[cnt]);	}	return 0;}",26056
79,2142,CVE-2017-11665,24,"void ff_amf_write_int(int **dst, int val){    bytestream_put_byte(dst, AMF_DATA_TYPE_BOOL);    bytestream_put_byte(dst, val);}",20457
446,652,CVE-2013-6368,24,"void kvm_arch_free_memslot(struct kvm *kvm, struct kvm_memory_slot *free,			   struct kvm_memory_slot *dont){	int i;	for (i = 0; i < KVM_NR_PAGE_SIZES; ++i) {		if (!dont || free->arch.rmap[i] != dont->arch.rmap[i]) {			kvm_kvfree(free->arch.rmap[i]);			free->arch.rmap[i] = NULL;		}		if (i == 0)			continue;		if (!dont || free->arch.lpage_info[i - 1] !=			     dont->arch.lpage_info[i - 1]) {			kvm_kvfree(free->arch.lpage_info[i - 1]);			free->arch.lpage_info[i - 1] = NULL;		}	}}",7419
403,1816,CVE-2015-7509,24,"static int ext4_dx_csum_verify(struct inode *inode,			       struct ext4_dir_entry *dirent){	struct dx_countlimit *c;	struct dx_tail *t;	int count_offset, limit, count;	if (!EXT4_HAS_RO_COMPAT_FEATURE(inode->i_sb,					EXT4_FEATURE_RO_COMPAT_METADATA_CSUM))		return 1;	c = get_dx_countlimit(inode, dirent, &count_offset);	if (!c) {		EXT4_ERROR_INODE(inode, ""dir seems corrupt?  Run e2fsck -D."");		return 1;	}	limit = le16_to_cpu(c->limit);	count = le16_to_cpu(c->count);	if (count_offset + (limit * sizeof(struct dx_entry)) >	    EXT4_BLOCK_SIZE(inode->i_sb) - sizeof(struct dx_tail)) {		EXT4_ERROR_INODE(inode, ""metadata_csum set but no space for ""				 ""tree checksum found.  Run e2fsck -D."");		return 1;	}	t = (struct dx_tail *)(((struct dx_entry *)c) + limit);	if (t->dt_checksum != ext4_dx_csum(inode, dirent, count_offset,					    count, t))		return 0;	return 1;}",13097
36,1759,CVE-2015-8215,24,static void addrconf_del_dad_work(struct inet6_ifaddr *ifp){	if (cancel_delayed_work(&ifp->dad_work))		__in6_ifa_put(ifp);},12969
361,1140,CVE-2014-2739,24,"static int cm_alloc_msg(struct cm_id_private *cm_id_priv,			struct ib_mad_send_buf **msg){	struct ib_mad_agent *mad_agent;	struct ib_mad_send_buf *m;	struct ib_ah *ah;	mad_agent = cm_id_priv->av.port->mad_agent;	ah = ib_create_ah(mad_agent->qp->pd, &cm_id_priv->av.ah_attr);	if (IS_ERR(ah))		return PTR_ERR(ah);	m = ib_create_send_mad(mad_agent, cm_id_priv->id.remote_cm_qpn,			       cm_id_priv->av.pkey_index,			       0, IB_MGMT_MAD_HDR, IB_MGMT_MAD_DATA,			       GFP_ATOMIC);	if (IS_ERR(m)) {		ib_destroy_ah(ah);		return PTR_ERR(m);	}	 	m->ah = ah;	m->retries = cm_id_priv->max_cm_retries;	atomic_inc(&cm_id_priv->refcount);	m->context[0] = cm_id_priv;	*msg = m;	return 0;}",11615
208,1525,CVE-2013-7271,24,"static int handle_ip_over_ddp(struct sk_buff *skb){	struct net_device *dev = __dev_get_by_name(&init_net, ""ipddp0"");	struct net_device_stats *stats;	 	if (!dev) {		kfree_skb(skb);		return NET_RX_DROP;	}	skb->protocol = htons(ETH_P_IP);	skb_pull(skb, 13);	skb->dev   = dev;	skb_reset_transport_header(skb);	stats = netdev_priv(dev);	stats->rx_packets++;	stats->rx_bytes += skb->len + 13;	return netif_rx(skb);   }",12413
47,849,CVE-2013-1828,24,"void sctp_sock_rfree(struct sk_buff *skb){	struct sock *sk = skb->sk;	struct sctp_ulpevent *event = sctp_skb2event(skb);	atomic_sub(event->rmem_len, &sk->sk_rmem_alloc);	 	sk_mem_uncharge(sk, event->rmem_len);}",9405
249,539,CVE-2011-4914,24,"static int rose_getname(struct socket *sock, struct sockaddr *uaddr,	int *uaddr_len, int peer){	struct full_sockaddr_rose *srose = (struct full_sockaddr_rose *)uaddr;	struct sock *sk = sock->sk;	struct rose_sock *rose = rose_sk(sk);	int n;	memset(srose, 0, sizeof(*srose));	if (peer != 0) {		if (sk->sk_state != TCP_ESTABLISHED)			return -ENOTCONN;		srose->srose_family = AF_ROSE;		srose->srose_addr   = rose->dest_addr;		srose->srose_call   = rose->dest_call;		srose->srose_ndigis = rose->dest_ndigis;		for (n = 0; n < rose->dest_ndigis; n++)			srose->srose_digis[n] = rose->dest_digis[n];	} else {		srose->srose_family = AF_ROSE;		srose->srose_addr   = rose->source_addr;		srose->srose_call   = rose->source_call;		srose->srose_ndigis = rose->source_ndigis;		for (n = 0; n < rose->source_ndigis; n++)			srose->srose_digis[n] = rose->source_digis[n];	}	*uaddr_len = sizeof(struct full_sockaddr_rose);	return 0;}",4386
443,736,CVE-2013-4254,24,armpmu_read(struct perf_event *event){	armpmu_event_update(event);},7887
542,166,CVE-2011-1428,24,"irc_server_autojoin_channels (struct t_irc_server *server){    struct t_irc_channel *ptr_channel;    const char *autojoin;             if (!server->disable_autojoin && server->reconnect_join && server->channels)    {        for (ptr_channel = server->channels; ptr_channel;             ptr_channel = ptr_channel->next_channel)        {            if (ptr_channel->type == IRC_CHANNEL_TYPE_CHANNEL)            {                if (ptr_channel->key)                {                    irc_server_sendf (server,                                      IRC_SERVER_SEND_OUTQ_PRIO_LOW, NULL,                                      ""JOIN %s %s"",                                      ptr_channel->name, ptr_channel->key);                }                else                {                    irc_server_sendf (server,                                      IRC_SERVER_SEND_OUTQ_PRIO_LOW, NULL,                                      ""JOIN %s"",                                      ptr_channel->name);                }            }        }        server->reconnect_join = 0;    }    else    {                 autojoin = IRC_SERVER_OPTION_STRING(server, IRC_SERVER_OPTION_AUTOJOIN);        if (!server->disable_autojoin && autojoin && autojoin[0])            irc_command_join_server (server, autojoin);    }        server->disable_autojoin = 0;}",660
125,782,CVE-2013-2146,24,"static void intel_pmu_reset(void){	struct debug_store *ds = __this_cpu_read(cpu_hw_events.ds);	unsigned long flags;	int idx;	if (!x86_pmu.num_counters)		return;	local_irq_save(flags);	pr_info(""clearing PMU state on CPU#%d\n"", smp_processor_id());	for (idx = 0; idx < x86_pmu.num_counters; idx++) {		wrmsrl_safe(x86_pmu_config_addr(idx), 0ull);		wrmsrl_safe(x86_pmu_event_addr(idx),  0ull);	}	for (idx = 0; idx < x86_pmu.num_counters_fixed; idx++)		wrmsrl_safe(MSR_ARCH_PERFMON_FIXED_CTR0 + idx, 0ull);	if (ds)		ds->bts_index = ds->bts_buffer_base;	local_irq_restore(flags);}",8807
369,2420,CVE-2019-12439,24,"switch_to_user_with_privs (void){     if (opt_unshare_user)    drop_cap_bounding_set (FALSE);  if (!is_privileged)    return;     if (prctl (PR_SET_KEEPCAPS, 1, 0, 0, 0) < 0)    die_with_error (""prctl(PR_SET_KEEPCAPS) failed"");  if (setuid (opt_sandbox_uid) < 0)    die_with_error (""unable to drop root uid"");     set_required_caps ();}",26877
304,2113,CVE-2017-15868,24,static void __bnep_unlink_session(struct bnep_session *s){	list_del(&s->list);},19957
610,1834,CVE-2016-9191,24,"static void drop_sysctl_table(struct ctl_table_header *header){	struct ctl_dir *parent = header->parent;	if (--header->nreg)		return;	put_links(header);	start_unregistering(header);	if (!--header->count)		kfree_rcu(header, rcu);	if (parent)		drop_sysctl_table(&parent->header);}",15195
28,1308,CVE-2014-2038,24,"static struct nfs_page *nfs_find_and_lock_request(struct page *page, int nonblock){	struct inode *inode = page_file_mapping(page)->host;	struct nfs_page *req;	int ret;	spin_lock(&inode->i_lock);	for (;;) {		req = nfs_page_find_request_locked(NFS_I(inode), page);		if (req == NULL)			break;		if (nfs_lock_request(req))			break;		 		spin_unlock(&inode->i_lock);		if (!nonblock)			ret = nfs_wait_on_request(req);		else			ret = -EAGAIN;		nfs_release_request(req);		if (ret != 0)			return ERR_PTR(ret);		spin_lock(&inode->i_lock);	}	spin_unlock(&inode->i_lock);	return req;}",11855
80,1017,CVE-2014-4503,24,"int tq_push(struct thread_q *tq, void *data){	struct tq_ent *ent;	int rc = true;	ent = (struct tq_ent *)calloc(1, sizeof(*ent));	if (!ent)		return false;	ent->data = data;	INIT_LIST_HEAD(&ent->q_node);	mutex_lock(&tq->mutex);	if (!tq->frozen) {		list_add_tail(&ent->q_node, &tq->q);	} else {		free(ent);		rc = false;	}	pthread_cond_signal(&tq->cond);	mutex_unlock(&tq->mutex);	return rc;}",10885
241,2264,CVE-2014-8324,24,"static int net_get_monitor(struct wif *wi){	return net_cmd(wi_priv(wi), NET_GET_MONITOR, NULL, 0);}",23115
583,2714,CVE-2016-3760,24,"int btif_config_get_int(const char *section, const char *key, int *value) {  assert(config != NULL);  assert(section != NULL);  assert(key != NULL);  assert(value != NULL);  pthread_mutex_lock(&lock); int ret = config_has_key(config, section, key); if (ret) *value = config_get_int(config, section, key, *value);  pthread_mutex_unlock(&lock); return ret;}",30525
381,2709,CVE-2016-3760,24,static int read_energy_info(){ if (interface_ready() == FALSE) return BT_STATUS_NOT_READY;    btif_dm_read_energy_info(); return BT_STATUS_SUCCESS;},30520
587,2496,CVE-2012-0879,24,static void posix_cpu_timers_init_group(struct signal_struct *sig){	 	thread_group_cputime_init(sig);	 	sig->it[CPUCLOCK_PROF].expires = cputime_zero;	sig->it[CPUCLOCK_PROF].incr = cputime_zero;	sig->it[CPUCLOCK_VIRT].expires = cputime_zero;	sig->it[CPUCLOCK_VIRT].incr = cputime_zero;	 	sig->cputime_expires.prof_exp = cputime_zero;	sig->cputime_expires.virt_exp = cputime_zero;	sig->cputime_expires.sched_exp = 0;	if (sig->rlim[RLIMIT_CPU].rlim_cur != RLIM_INFINITY) {		sig->cputime_expires.prof_exp =			secs_to_cputime(sig->rlim[RLIMIT_CPU].rlim_cur);		sig->cputimer.running = 1;	}	 	INIT_LIST_HEAD(&sig->cpu_timers[0]);	INIT_LIST_HEAD(&sig->cpu_timers[1]);	INIT_LIST_HEAD(&sig->cpu_timers[2]);},28253
157,2779,CVE-2013-7271,24,"static void unix_copy_addr(struct msghdr *msg, struct sock *sk) { 	struct unix_sock *u = unix_sk(sk); 	msg->msg_namelen = 0; 	if (u->addr) { 		msg->msg_namelen = u->addr->len; 		memcpy(msg->msg_name, u->addr->name, u->addr->len);	}}",31174
274,617,CVE-2011-1080,24,"static int ebt_buf_add(struct ebt_entries_buf_state *state,		       void *data, unsigned int sz){	if (state->buf_kern_start == NULL)		goto count_only;	BUG_ON(state->buf_kern_offset + sz > state->buf_kern_len);	memcpy(state->buf_kern_start + state->buf_kern_offset, data, sz); count_only:	state->buf_user_offset += sz;	return ebt_buf_count(state, sz);}",6920
500,1391,CVE-2014-0203,24,"struct file *filp_open(const char *filename, int flags, int mode){	return do_filp_open(AT_FDCWD, filename, flags, mode, 0);}",12101
463,510,CVE-2012-2136,24,"int sock_no_bind(struct socket *sock, struct sockaddr *saddr, int len){	return -EOPNOTSUPP;}",3469
338,1563,CVE-2013-7271,24,"static void ipxitf_def_skb_handler(struct sock *sock, struct sk_buff *skb){	if (sock_queue_rcv_skb(sock, skb) < 0)		kfree_skb(skb);}",12451
39,2412,CVE-2019-12439,24,"drop_cap_bounding_set (int drop_all){  if (!drop_all)    prctl_caps (requested_caps, TRUE, FALSE);  else    {      int no_caps[2] = {0, 0};      prctl_caps (no_caps, TRUE, FALSE);    }}",26869
622,1076,CVE-2014-3645,24,static int mmu_alloc_roots(struct kvm_vcpu *vcpu){	if (vcpu->arch.mmu.direct_map)		return mmu_alloc_direct_roots(vcpu);	else		return mmu_alloc_shadow_roots(vcpu);},11210
651,1110,CVE-2014-3645,24,"static int alloc_identity_pagetable(struct kvm *kvm){	struct page *page;	struct kvm_userspace_memory_region kvm_userspace_mem;	int r = 0;	mutex_lock(&kvm->slots_lock);	if (kvm->arch.ept_identity_pagetable)		goto out;	kvm_userspace_mem.slot = IDENTITY_PAGETABLE_PRIVATE_MEMSLOT;	kvm_userspace_mem.flags = 0;	kvm_userspace_mem.guest_phys_addr =		kvm->arch.ept_identity_map_addr;	kvm_userspace_mem.memory_size = PAGE_SIZE;	r = __kvm_set_memory_region(kvm, &kvm_userspace_mem);	if (r)		goto out;	page = gfn_to_page(kvm, kvm->arch.ept_identity_map_addr >> PAGE_SHIFT);	if (is_error_page(page)) {		r = -EFAULT;		goto out;	}	kvm->arch.ept_identity_pagetable = page;out:	mutex_unlock(&kvm->slots_lock);	return r;}",11244
608,295,CVE-2014-7840,24,"int qemu_uuid_parse(const char *str, int *uuid){    int ret;    if (strlen(str) != 36) {        return -1;    }    ret = sscanf(str, UUID_FMT, &uuid[0], &uuid[1], &uuid[2], &uuid[3],                 &uuid[4], &uuid[5], &uuid[6], &uuid[7], &uuid[8], &uuid[9],                 &uuid[10], &uuid[11], &uuid[12], &uuid[13], &uuid[14],                 &uuid[15]);    if (ret != 16) {        return -1;    }    return 0;}",1295
377,1204,CVE-2014-2739,24,"static int cma_comp_exch(struct rdma_id_private *id_priv,			 enum rdma_cm_state comp, enum rdma_cm_state exch){	unsigned long flags;	int ret;	spin_lock_irqsave(&id_priv->lock, flags);	if ((ret = (id_priv->state == comp)))		id_priv->state = exch;	spin_unlock_irqrestore(&id_priv->lock, flags);	return ret;}",11679
582,2010,CVE-2017-1000201,24,"static void dev_removed(struct tcmu_device *dev){	struct tcmur_device *rdev = tcmu_get_daemon_dev_private(dev);	int ret;	 	cleanup_io_work_queue_threads(dev);	tcmulib_cleanup_cmdproc_thread(dev);	cleanup_io_work_queue(dev, false);	cleanup_aio_tracking(rdev);	ret = pthread_mutex_destroy(&rdev->format_lock);	if (ret != 0)		tcmu_err(""could not cleanup format lock %d\n"", ret);	ret = pthread_mutex_destroy(&rdev->caw_lock);	if (ret != 0)		tcmu_err(""could not cleanup caw lock %d\n"", ret);	ret = pthread_spin_destroy(&rdev->lock);	if (ret != 0)		tcmu_err(""could not cleanup mailbox lock %d\n"", ret);	free(rdev);}",19500
73,211,CVE-2011-1428,24,"irc_server_timer_sasl_cb (void *data, int remaining_calls){    struct t_irc_server *server;             (void) remaining_calls;        server = (struct t_irc_server *)data;        if (!server)        return WEECHAT_RC_ERROR;        server->hook_timer_sasl = NULL;        if (!server->is_connected)    {        weechat_printf (server->buffer,                        _(""%s%s: sasl authentication timeout""),                        weechat_prefix (""error""), IRC_PLUGIN_NAME);        irc_server_sendf (server, 0, NULL, ""CAP END"");    }        return WEECHAT_RC_OK;}",705
448,2408,CVE-2019-1010251,24,"const char *PktSrcToString(enum PktSrcEnum pkt_src){    const char *pkt_src_str = ""<unknown>"";    switch (pkt_src) {        case PKT_SRC_WIRE:            pkt_src_str = ""wire/pcap"";            break;        case PKT_SRC_DECODER_GRE:            pkt_src_str = ""gre tunnel"";            break;        case PKT_SRC_DECODER_IPV4:            pkt_src_str = ""ipv4 tunnel"";            break;        case PKT_SRC_DECODER_IPV6:            pkt_src_str = ""ipv6 tunnel"";            break;        case PKT_SRC_DECODER_TEREDO:            pkt_src_str = ""teredo tunnel"";            break;        case PKT_SRC_DEFRAG:            pkt_src_str = ""defrag"";            break;        case PKT_SRC_STREAM_TCP_STREAM_END_PSEUDO:            pkt_src_str = ""stream"";            break;        case PKT_SRC_STREAM_TCP_DETECTLOG_FLUSH:            pkt_src_str = ""stream (detect/log)"";            break;        case PKT_SRC_FFR:            pkt_src_str = ""stream (flow timeout)"";            break;    }    return pkt_src_str;}",26386
353,490,CVE-2012-2136,24,"void sk_release_kernel(struct sock *sk){	if (sk == NULL || sk->sk_socket == NULL)		return;	sock_hold(sk);	sock_release(sk->sk_socket);	release_net(sock_net(sk));	sock_net_set(sk, get_net(&init_net));	sock_put(sk);}",3449
130,2321,CVE-2018-17456,24,"int fsck_walk(struct object *obj, void *data, struct fsck_options *options){	if (!obj)		return -1;	if (obj->type == OBJ_NONE)		parse_object(&obj->oid);	switch (obj->type) {	case OBJ_BLOB:		return 0;	case OBJ_TREE:		return fsck_walk_tree((struct tree *)obj, data, options);	case OBJ_COMMIT:		return fsck_walk_commit((struct commit *)obj, data, options);	case OBJ_TAG:		return fsck_walk_tag((struct tag *)obj, data, options);	default:		error(""Unknown object type for %s"", describe_object(options, obj));		return -1;	}}",23613
136,746,CVE-2013-4254,24,unsigned long perf_instruction_pointer(struct pt_regs *regs){	if (perf_guest_cbs && perf_guest_cbs->is_in_guest())		return perf_guest_cbs->get_guest_ip();	return instruction_pointer(regs);},7897
247,2753,CVE-2017-8933,24,"static void get_socket_name( char* buf, int len ){    char* dpy = g_strdup(g_getenv(""DISPLAY""));    if(dpy && *dpy)    {        char* p = strchr(dpy, ':');        for(++p; *p && *p != '.' && *p != '\n';)            ++p;         if(*p)             *p = '\0';     }     g_snprintf( buf, len, ""%s/.menu-cached-%s-%s"", g_get_tmp_dir(),                 dpy ? dpy : "":0"", g_get_user_name() );     g_free(dpy); }",30895
548,1513,CVE-2013-7271,24,static inline void atalk_remove_socket(struct sock *sk){	write_lock_bh(&atalk_sockets_lock);	sk_del_node_init(sk);	write_unlock_bh(&atalk_sockets_lock);},12401
27,684,CVE-2013-6368,24,"static int kvm_vcpu_ioctl_get_lapic(struct kvm_vcpu *vcpu,				    struct kvm_lapic_state *s){	kvm_x86_ops->sync_pir_to_irr(vcpu);	memcpy(s->regs, vcpu->arch.apic->regs, sizeof *s);	return 0;}",7451
544,945,CVE-2011-3619,24,"static int param_get_aalockpolicy(char *buffer, const struct kernel_param *kp){	if (!capable(CAP_MAC_ADMIN))		return -EPERM;	return param_get_int(buffer, kp);}",10116
260,658,CVE-2013-6368,24,void kvm_arch_unregister_noncoherent_dma(struct kvm *kvm){	atomic_dec(&kvm->arch.noncoherent_dma_count);},7425
373,2761,CVE-2011-3637,24,"static void m_stop(struct seq_file *m, void *v){ 	struct proc_maps_private *priv = m->private; 	struct vm_area_struct *vma = v; 	vma_stop(priv, vma); 	if (priv->task) 		put_task_struct(priv->task); }",30990
458,1605,CVE-2013-7271,24,"int netlink_has_listeners(struct sock *sk, unsigned int group){	int res = 0;	struct listeners *listeners;	BUG_ON(!netlink_is_kernel(sk));	rcu_read_lock();	listeners = rcu_dereference(nl_table[sk->sk_protocol].listeners);	if (listeners && group - 1 < nl_table[sk->sk_protocol].groups)		res = test_bit(group - 1, listeners->masks);	rcu_read_unlock();	return res;}",12493
427,907,CVE-2013-0290,24,"int skb_kill_datagram(struct sock *sk, struct sk_buff *skb, unsigned int flags){	int err = 0;	if (flags & MSG_PEEK) {		err = -ENOENT;		spin_lock_bh(&sk->sk_receive_queue.lock);		if (skb == skb_peek(&sk->sk_receive_queue)) {			__skb_unlink(skb, &sk->sk_receive_queue);			atomic_dec(&skb->users);			err = 0;		}		spin_unlock_bh(&sk->sk_receive_queue.lock);	}	kfree_skb(skb);	atomic_inc(&sk->sk_drops);	sk_mem_reclaim_partial(sk);	return err;}",9759
392,2280,CVE-2018-18955,24,"static int cmp_extents_reverse(const void *a, const void *b){	const struct uid_gid_extent *e1 = a;	const struct uid_gid_extent *e2 = b;	if (e1->lower_first < e2->lower_first)		return -1;	if (e1->lower_first > e2->lower_first)		return 1;	return 0;}",23409
596,2036,CVE-2017-17862,24,"static void clear_all_pkt_pointers(struct bpf_verifier_env *env){	struct bpf_verifier_state *state = env->cur_state;	struct bpf_reg_state *regs = state->regs, *reg;	int i;	for (i = 0; i < MAX_BPF_REG; i++)		if (reg_is_pkt_pointer_any(&regs[i]))			mark_reg_unknown(env, regs, i);	for (i = 0; i < state->allocated_stack / BPF_REG_SIZE; i++) {		if (state->stack[i].slot_type[0] != STACK_SPILL)			continue;		reg = &state->stack[i].spilled_ptr;		if (reg_is_pkt_pointer_any(reg))			__mark_reg_unknown(reg);	}}",19534
10,411,CVE-2018-0494,24,"load_cookies (void){  if (!wget_cookie_jar)    wget_cookie_jar = cookie_jar_new ();  if (opt.cookies_input && !cookies_loaded_p)    {      cookie_jar_load (wget_cookie_jar, opt.cookies_input);      cookies_loaded_p = true;    }}",2367
633,1704,CVE-2013-7271,24,"static int unix_listen(struct socket *sock, int backlog){	int err;	struct sock *sk = sock->sk;	struct unix_sock *u = unix_sk(sk);	struct pid *old_pid = NULL;	err = -EOPNOTSUPP;	if (sock->type != SOCK_STREAM && sock->type != SOCK_SEQPACKET)		goto out;	 	err = -EINVAL;	if (!u->addr)		goto out;	 	unix_state_lock(sk);	if (sk->sk_state != TCP_CLOSE && sk->sk_state != TCP_LISTEN)		goto out_unlock;	if (backlog > sk->sk_max_ack_backlog)		wake_up_interruptible_all(&u->peer_wait);	sk->sk_max_ack_backlog	= backlog;	sk->sk_state		= TCP_LISTEN;	 	init_peercred(sk);	err = 0;out_unlock:	unix_state_unlock(sk);	put_pid(old_pid);out:	return err;}",12592
328,741,CVE-2013-4254,24,static int armpmu_runtime_suspend(struct device *dev){	struct arm_pmu_platdata *plat = dev_get_platdata(dev);	if (plat && plat->runtime_suspend)		return plat->runtime_suspend(dev);	return 0;},7892
514,183,CVE-2011-1428,24,"irc_server_get_prefix_mode_index (struct t_irc_server *server, char mode){    const char *prefix_modes;    char *pos;        if (server)    {        prefix_modes = irc_server_get_prefix_modes (server);        pos = strchr (prefix_modes, mode);        if (pos)            return pos - prefix_modes;    }        return -1;}",677
221,69,CVE-2015-5296,24,int smb1cli_conn_encryption_on(struct smbXcli_conn *conn){	return common_encryption_on(conn->smb1.trans_enc);},477
549,2724,CVE-2016-3760,24,"void bdt_disable(void){    bdt_log(""DISABLE BT""); if (!bt_enabled) {        bdt_log(""Bluetooth is already disabled""); return; }    status = sBtInterface->disable();    check_return_status(status);}",30535
295,269,CVE-2012-5534,24,"string_match (const char *string, const char *mask, int case_sensitive){    char last, *mask2;    int len_string, len_mask, rc;    if (!mask || !mask[0])        return 0;         if (strcmp (mask, ""*"") == 0)        return 1;    len_string = strlen (string);    len_mask = strlen (mask);    last = mask[len_mask - 1];         if ((mask[0] == '*') && (last != '*'))    {                 if (len_string < len_mask - 1)            return 0;                 if ((case_sensitive && (strcmp (string + len_string - (len_mask - 1),                                        mask + 1) == 0))            || (!case_sensitive && (string_strcasecmp (string + len_string - (len_mask - 1),                                                       mask + 1) == 0)))            return 1;                 return 0;    }         if ((mask[0] != '*') && (last == '*'))    {                 if (len_string < len_mask - 1)            return 0;                 if ((case_sensitive && (strncmp (string, mask, len_mask - 1) == 0))            || (!case_sensitive && (string_strncasecmp (string,                                                        mask,                                                        len_mask - 1) == 0)))            return 1;                 return 0;    }         if ((mask[0] == '*') && (last == '*'))    {                 if (len_string < len_mask - 1)            return 0;                 mask2 = string_strndup (mask + 1, len_mask - 2);        if (!mask2)            return 0;                 rc = ((case_sensitive && strstr (string, mask2))              || (!case_sensitive && string_strcasestr (string, mask2))) ?            1 : 0;                 free (mask2);        return rc;    }         if ((case_sensitive && (strcmp (string, mask) == 0))        || (!case_sensitive && (string_strcasecmp (string, mask) == 0)))        return 1;         return 0;}",1200
289,893,CVE-2013-1798,24,void kvm_ioapic_reset(struct kvm_ioapic *ioapic){	int i;	for (i = 0; i < IOAPIC_NUM_PINS; i++)		ioapic->redirtbl[i].fields.mask = 1;	ioapic->base_address = IOAPIC_DEFAULT_BASE_ADDRESS;	ioapic->ioregsel = 0;	ioapic->irr = 0;	ioapic->id = 0;	update_handled_vectors(ioapic);},9500
404,1650,CVE-2013-7271,24,static void fanout_release(struct sock *sk){	struct packet_sock *po = pkt_sk(sk);	struct packet_fanout *f;	f = po->fanout;	if (!f)		return;	mutex_lock(&fanout_mutex);	po->fanout = NULL;	if (atomic_dec_and_test(&f->sk_ref)) {		list_del(&f->list);		dev_remove_pack(&f->prot_hook);		kfree(f);	}	mutex_unlock(&fanout_mutex);},12538
335,2328,CVE-2018-17456,24,"static int parse_msg_id(const char *text){	int i;	if (!msg_id_info[0].downcased) {		 		for (i = 0; i < FSCK_MSG_MAX; i++) {			const char *p = msg_id_info[i].id_string;			int len = strlen(p);			char *q = xmalloc(len);			msg_id_info[i].downcased = q;			while (*p)				if (*p == '_')					p++;				else					*(q)++ = tolower(*(p)++);			*q = '\0';		}	}	for (i = 0; i < FSCK_MSG_MAX; i++)		if (!strcmp(text, msg_id_info[i].downcased))			return i;	return -1;}",23620
474,876,CVE-2013-1819,24,"xfs_buf_stale(	struct xfs_buf	*bp){	ASSERT(xfs_buf_islocked(bp));	bp->b_flags |= XBF_STALE;	 	bp->b_flags &= ~_XBF_DELWRI_Q;	atomic_set(&(bp)->b_lru_ref, 0);	if (!list_empty(&bp->b_lru)) {		struct xfs_buftarg *btp = bp->b_target;		spin_lock(&btp->bt_lru_lock);		if (!list_empty(&bp->b_lru) &&		    !(bp->b_lru_flags & _XBF_LRU_DISPOSE)) {			list_del_init(&bp->b_lru);			btp->bt_lru_nr--;			atomic_dec(&bp->b_hold);		}		spin_unlock(&btp->bt_lru_lock);	}	ASSERT(atomic_read(&bp->b_hold) >= 1);}",9483
428,248,CVE-2012-5534,24,"hook_completion_exec (struct t_weechat_plugin *plugin,                      const char *completion_item,                      struct t_gui_buffer *buffer,                      struct t_gui_completion *completion){    struct t_hook *ptr_hook, *next_hook;         (void) plugin;    hook_exec_start ();    ptr_hook = weechat_hooks[HOOK_TYPE_COMPLETION];    while (ptr_hook)    {        next_hook = ptr_hook->next_hook;        if (!ptr_hook->deleted            && !ptr_hook->running            && (string_strcasecmp (HOOK_COMPLETION(ptr_hook, completion_item),                                   completion_item) == 0))        {            ptr_hook->running = 1;            (void) (HOOK_COMPLETION(ptr_hook, callback))                (ptr_hook->callback_data, completion_item, buffer, completion);            ptr_hook->running = 0;        }        ptr_hook = next_hook;    }    hook_exec_end ();}",1179
314,2160,CVE-2017-9242,24,"static int ip6_finish_output2(struct net *net, struct sock *sk, struct sk_buff *skb){	struct dst_entry *dst = skb_dst(skb);	struct net_device *dev = dst->dev;	struct neighbour *neigh;	struct in6_addr *nexthop;	int ret;	skb->protocol = htons(ETH_P_IPV6);	skb->dev = dev;	if (ipv6_addr_is_multicast(&ipv6_hdr(skb)->daddr)) {		struct inet6_dev *idev = ip6_dst_idev(skb_dst(skb));		if (!(dev->flags & IFF_LOOPBACK) && sk_mc_loop(sk) &&		    ((mroute6_socket(net, skb) &&		     !(IP6CB(skb)->flags & IP6SKB_FORWARDED)) ||		     ipv6_chk_mcast_addr(dev, &ipv6_hdr(skb)->daddr,					 &ipv6_hdr(skb)->saddr))) {			struct sk_buff *newskb = skb_clone(skb, GFP_ATOMIC);			 			if (newskb)				NF_HOOK(NFPROTO_IPV6, NF_INET_POST_ROUTING,					net, sk, newskb, NULL, newskb->dev,					dev_loopback_xmit);			if (ipv6_hdr(skb)->hop_limit == 0) {				IP6_INC_STATS(net, idev,					      IPSTATS_MIB_OUTDISCARDS);				kfree_skb(skb);				return 0;			}		}		IP6_UPD_PO_STATS(net, idev, IPSTATS_MIB_OUTMCAST, skb->len);		if (IPV6_ADDR_MC_SCOPE(&ipv6_hdr(skb)->daddr) <=		    IPV6_ADDR_SCOPE_NODELOCAL &&		    !(dev->flags & IFF_LOOPBACK)) {			kfree_skb(skb);			return 0;		}	}	if (lwtunnel_xmit_redirect(dst->lwtstate)) {		int res = lwtunnel_xmit(skb);		if (res < 0 || res == LWTUNNEL_XMIT_DONE)			return res;	}	rcu_read_lock_bh();	nexthop = rt6_nexthop((struct rt6_info *)dst, &ipv6_hdr(skb)->daddr);	neigh = __ipv6_neigh_lookup_noref(dst->dev, nexthop);	if (unlikely(!neigh))		neigh = __neigh_create(&nd_tbl, nexthop, dst->dev, false);	if (!IS_ERR(neigh)) {		sock_confirm_neigh(skb, neigh);		ret = neigh_output(neigh, skb);		rcu_read_unlock_bh();		return ret;	}	rcu_read_unlock_bh();	IP6_INC_STATS(net, ip6_dst_idev(dst), IPSTATS_MIB_OUTNOROUTES);	kfree_skb(skb);	return -EINVAL;}",20741
145,1600,CVE-2013-7271,24,"static int netlink_dump_space(struct netlink_sock *nlk){	struct netlink_ring *ring = &nlk->rx_ring;	struct nl_mmap_hdr *hdr;	unsigned int n;	hdr = netlink_current_frame(ring, NL_MMAP_STATUS_UNUSED);	if (hdr == NULL)		return false;	n = ring->head + ring->frame_max / 2;	if (n > ring->frame_max)		n -= ring->frame_max;	hdr = __netlink_lookup_frame(ring, n);	return hdr->nm_status == NL_MMAP_STATUS_UNUSED;}",12488
525,2241,CVE-2015-5195,24,"create_attr_ival(	int attr,	int value	){	attr_val *my_val;	my_val = emalloc_zero(sizeof(*my_val));	my_val->attr = attr;	my_val->value.i = value;	my_val->type = T_Integer;	return my_val;}",22907
334,968,CVE-2014-5472,24,"isofs_hashi_ms(const struct dentry *dentry, struct qstr *qstr){	return isofs_hashi_common(qstr, 1);}",10625
452,345,CVE-2016-4072,24,ZEND_INI_MH(phar_ini_cache_list)  {	PHAR_G(cache_list) = ZSTR_VAL(new_value);	if (stage == ZEND_INI_STAGE_STARTUP) {		phar_split_cache_list();	}	return SUCCESS;} ,1915
528,22,CVE-2017-16227,24,aspath_empty_get (void){  struct aspath *aspath;  aspath = aspath_new ();  aspath_make_str_count (aspath);  return aspath;},344
538,2591,CVE-2017-5104,24,"  int FocusInputAndSelectText() {    return ExecuteScript(interstitial_->GetMainFrame(), ""focus_select_input()"");  }",29848
347,117,CVE-2011-2200,24,_dbus_marshal_header_test (void){  return TRUE;},588
191,880,CVE-2013-1819,24,xfs_buf_vmap_len(	struct xfs_buf	*bp){	return (bp->b_page_count * PAGE_SIZE) - bp->b_offset;},9487
52,2166,CVE-2017-9242,24,"static inline int ip6_rt_check(const struct rt6key *rt_key,			       const struct in6_addr *fl_addr,			       const struct in6_addr *addr_cache){	return (rt_key->plen != 128 || !ipv6_addr_equal(fl_addr, &rt_key->addr)) &&		(!addr_cache || !ipv6_addr_equal(fl_addr, addr_cache));}",20747
677,2189,CVE-2017-7645,24,"nfsd_svc(int nrservs, struct net *net){	int	error;	int	nfsd_up_before;	struct nfsd_net *nn = net_generic(net, nfsd_net_id);	mutex_lock(&nfsd_mutex);	dprintk(""nfsd: creating service\n"");	nrservs = max(nrservs, 0);	nrservs = min(nrservs, NFSD_MAXSERVS);	error = 0;	if (nrservs == 0 && nn->nfsd_serv == NULL)		goto out;	error = nfsd_create_serv(net);	if (error)		goto out;	nfsd_up_before = nn->nfsd_net_up;	error = nfsd_startup_net(nrservs, net);	if (error)		goto out_destroy;	error = nn->nfsd_serv->sv_ops->svo_setup(nn->nfsd_serv,			NULL, nrservs);	if (error)		goto out_shutdown;	 	error = nn->nfsd_serv->sv_nrthreads - 1;out_shutdown:	if (error < 0 && !nfsd_up_before)		nfsd_shutdown_net(net);out_destroy:	nfsd_destroy(net);		 out:	mutex_unlock(&nfsd_mutex);	return error;}",21517
245,1691,CVE-2013-7271,24,"static int sock_close(struct inode *inode, struct file *filp){	sock_release(SOCKET_I(inode));	return 0;}",12579
396,2411,CVE-2019-12439,24,"drop_all_caps (int keep_requested_caps){  struct __user_cap_header_struct hdr = { _LINUX_CAPABILITY_VERSION_3, 0 };  struct __user_cap_data_struct data[2] = { { 0 } };  if (keep_requested_caps)    {             if (!opt_cap_add_or_drop_used && real_uid == 0)        {          assert (!is_privileged);          return;        }      data[0].effective = requested_caps[0];      data[0].permitted = requested_caps[0];      data[0].inheritable = requested_caps[0];      data[1].effective = requested_caps[1];      data[1].permitted = requested_caps[1];      data[1].inheritable = requested_caps[1];    }  if (capset (&hdr, data) < 0)    {             if (errno == EPERM && real_uid == 0 && !is_privileged)        return;      else        die_with_error (""capset failed"");    }}",26868
217,1510,CVE-2013-7271,24,static struct atalk_addr *atalk_find_primary(void){	struct atalk_iface *fiface = NULL;	struct atalk_addr *retval;	struct atalk_iface *iface;	 	read_lock_bh(&atalk_interfaces_lock);	for (iface = atalk_interfaces; iface; iface = iface->next) {		if (!fiface && !(iface->dev->flags & IFF_LOOPBACK))			fiface = iface;		if (!(iface->dev->flags & (IFF_LOOPBACK | IFF_POINTOPOINT))) {			retval = &iface->address;			goto out;		}	}	if (fiface)		retval = &fiface->address;	else if (atalk_interfaces)		retval = &atalk_interfaces->address;	else		retval = NULL;out:	read_unlock_bh(&atalk_interfaces_lock);	return retval;},12398
133,738,CVE-2013-4254,24,armpmu_release_hardware(struct arm_pmu *armpmu){	armpmu->free_irq(armpmu);	pm_runtime_put_sync(&armpmu->plat_device->dev);},7889
83,656,CVE-2013-6368,24,"int kvm_arch_prepare_memory_region(struct kvm *kvm,				struct kvm_memory_slot *memslot,				struct kvm_userspace_memory_region *mem,				enum kvm_mr_change change){	 	if ((memslot->id >= KVM_USER_MEM_SLOTS) && (change == KVM_MR_CREATE)) {		unsigned long userspace_addr;		 		userspace_addr = vm_mmap(NULL, 0, memslot->npages * PAGE_SIZE,					 PROT_READ | PROT_WRITE,					 MAP_SHARED | MAP_ANONYMOUS, 0);		if (IS_ERR((void *)userspace_addr))			return PTR_ERR((void *)userspace_addr);		memslot->userspace_addr = userspace_addr;	}	return 0;}",7423
99,2483,CVE-2012-0879,24,"static int eligible_child(struct wait_opts *wo, struct task_struct *p){	if (!eligible_pid(wo, p))		return 0;	 	if (((p->exit_signal != SIGCHLD) ^ !!(wo->wo_flags & __WCLONE))	    && !(wo->wo_flags & __WALL))		return 0;	return 1;}",28240
255,2363,CVE-2017-18221,24,int can_do_mlock(void){	if (rlimit(RLIMIT_MEMLOCK) != 0)		return true;	if (capable(CAP_IPC_LOCK))		return true;	return false;},25828
383,543,CVE-2011-4914,24,"static int rose_listen(struct socket *sock, int backlog){	struct sock *sk = sock->sk;	if (sk->sk_state != TCP_LISTEN) {		struct rose_sock *rose = rose_sk(sk);		rose->dest_ndigis = 0;		memset(&rose->dest_addr, 0, ROSE_ADDR_LEN);		memset(&rose->dest_call, 0, AX25_ADDR_LEN);		memset(rose->dest_digis, 0, AX25_ADDR_LEN * ROSE_MAX_DIGIS);		sk->sk_max_ack_backlog = backlog;		sk->sk_state           = TCP_LISTEN;		return 0;	}	return -EOPNOTSUPP;}",4390
619,1371,CVE-2014-1874,24,int security_mls_enabled(void){	return policydb.mls_enabled;},11921
151,1862,CVE-2016-9191,24,"static int register_leaf_sysctl_tables(const char *path, char *pos,	struct ctl_table_header ***subheader, struct ctl_table_set *set,	struct ctl_table *table){	struct ctl_table *ctl_table_arg = NULL;	struct ctl_table *entry, *files;	int nr_files = 0;	int nr_dirs = 0;	int err = -ENOMEM;	for (entry = table; entry->procname; entry++) {		if (entry->child)			nr_dirs++;		else			nr_files++;	}	files = table;	 	if (nr_dirs && nr_files) {		struct ctl_table *new;		files = kzalloc(sizeof(struct ctl_table) * (nr_files + 1),				GFP_KERNEL);		if (!files)			goto out;		ctl_table_arg = files;		for (new = files, entry = table; entry->procname; entry++) {			if (entry->child)				continue;			*new = *entry;			new++;		}	}	 	if (nr_files || !nr_dirs) {		struct ctl_table_header *header;		header = __register_sysctl_table(set, path, files);		if (!header) {			kfree(ctl_table_arg);			goto out;		}		 		header->ctl_table_arg = ctl_table_arg;		**subheader = header;		(*subheader)++;	}	 	for (entry = table; entry->procname; entry++) {		char *child_pos;		if (!entry->child)			continue;		err = -ENAMETOOLONG;		child_pos = append_path(path, pos, entry->procname);		if (!child_pos)			goto out;		err = register_leaf_sysctl_tables(path, child_pos, subheader,						  set, entry->child);		pos[0] = '\0';		if (err)			goto out;	}	err = 0;out:	 	return err;}",15223
63,2105,CVE-2017-15951,24,"static int key_unseal(struct trusted_key_payload *p,		      struct trusted_key_options *o){	struct tpm_buf *tb;	int ret;	tb = kzalloc(sizeof *tb, GFP_KERNEL);	if (!tb)		return -ENOMEM;	ret = tpm_unseal(tb, o->keyhandle, o->keyauth, p->blob, p->blob_len,			 o->blobauth, p->key, &p->key_len);	if (ret < 0)		pr_info(""trusted_key: srkunseal failed (%d)\n"", ret);	else		 		p->migratable = p->key[--p->key_len];	kzfree(tb);	return ret;}",19928
88,1803,CVE-2015-8215,24,static inline int ipv6_saddr_preferred(int type){	if (type & (IPV6_ADDR_MAPPED|IPV6_ADDR_COMPATv4|IPV6_ADDR_LOOPBACK))		return 1;	return 0;},13013
511,2211,CVE-2017-6345,24,"static void llc_sap_state_process(struct llc_sap *sap, struct sk_buff *skb){	struct llc_sap_state_ev *ev = llc_sap_ev(skb);	 	skb_get(skb);	ev->ind_cfm_flag = 0;	llc_sap_next_state(sap, skb);	if (ev->ind_cfm_flag == LLC_IND) {		if (skb->sk->sk_state == TCP_LISTEN)			kfree_skb(skb);		else {			llc_save_primitive(skb->sk, skb, ev->prim);			 			if (sock_queue_rcv_skb(skb->sk, skb))				kfree_skb(skb);		}	}	kfree_skb(skb);}",21844
100,2656,CVE-2018-6041,24,  void Wait() {    if (deleted_)      return;    message_loop_runner_->Run();  },30079
658,142,CVE-2011-1428,24,"hook_process_timer_cb (void *arg_hook_process, int remaining_calls){    struct t_hook *hook_process;    int status, rc;             (void) remaining_calls;        hook_process = (struct t_hook *)arg_hook_process;        if (hook_process->deleted)        return WEECHAT_RC_OK;        if (remaining_calls == 0)    {        hook_process_send_buffers (hook_process, WEECHAT_HOOK_PROCESS_ERROR);        gui_chat_printf (NULL,                         _(""End of command '%s', timeout reached (%.1fs)""),                         HOOK_PROCESS(hook_process, command),                         ((float)HOOK_PROCESS(hook_process, timeout)) / 1000);        kill (HOOK_PROCESS(hook_process, child_pid), SIGKILL);        usleep (1000);        unhook (hook_process);    }    else    {        if (!HOOK_PROCESS(hook_process, hook_fd[HOOK_PROCESS_STDOUT])            && !HOOK_PROCESS(hook_process, hook_fd[HOOK_PROCESS_STDERR]))        {            if (waitpid (HOOK_PROCESS(hook_process, child_pid), &status, WNOHANG) > 0)            {                rc = WEXITSTATUS(status);                hook_process_send_buffers (hook_process, rc);                unhook (hook_process);            }        }    }        return WEECHAT_RC_OK;}",636
45,246,CVE-2012-5534,24,"hook_add_to_infolist (struct t_infolist *infolist, const char *arguments){    const char *pos_arguments;    char *type;    int i, type_int;    if (!infolist)        return 0;    type = NULL;    pos_arguments = NULL;    if (arguments && arguments[0])    {        pos_arguments = strchr (arguments, ',');        if (pos_arguments)        {            type = string_strndup (arguments, pos_arguments - arguments);            pos_arguments++;        }        else            type = strdup (arguments);    }    type_int = (type) ? hook_search_type (type) : -1;    for (i = 0; i < HOOK_NUM_TYPES; i++)    {        if ((type_int < 0) || (type_int == i))            hook_add_to_infolist_type (infolist, i, pos_arguments);    }    if (type)        free (type);    return 1;}",1177
77,342,CVE-2016-4072,24,"PHP_MINIT_FUNCTION(phar)  {	REGISTER_INI_ENTRIES();	phar_orig_compile_file = zend_compile_file;	zend_compile_file = phar_compile_file;	phar_save_resolve_path = zend_resolve_path;	zend_resolve_path = phar_resolve_path;	phar_object_init();	phar_intercept_functions_init();	phar_save_orig_functions();	return php_register_url_stream_wrapper(""phar"", &php_stream_phar_wrapper);} ",1912
687,1115,CVE-2014-3645,24,"static void exit_lmode(struct kvm_vcpu *vcpu){	vmcs_write32(VM_ENTRY_CONTROLS,		     vmcs_read32(VM_ENTRY_CONTROLS)		     & ~VM_ENTRY_IA32E_MODE);	vmx_set_efer(vcpu, vcpu->arch.efer & ~EFER_LMA);}",11249
9,2425,CVE-2017-18509,24,"static int __ip6mr_fill_mroute(struct mr6_table *mrt, struct sk_buff *skb,			       struct mfc6_cache *c, struct rtmsg *rtm){	struct rta_mfc_stats mfcs;	struct nlattr *mp_attr;	struct rtnexthop *nhp;	unsigned long lastuse;	int ct;	 	if (c->mf6c_parent >= MAXMIFS) {		rtm->rtm_flags |= RTNH_F_UNRESOLVED;		return -ENOENT;	}	if (MIF_EXISTS(mrt, c->mf6c_parent) &&	    nla_put_u32(skb, RTA_IIF, mrt->vif6_table[c->mf6c_parent].dev->ifindex) < 0)		return -EMSGSIZE;	mp_attr = nla_nest_start(skb, RTA_MULTIPATH);	if (!mp_attr)		return -EMSGSIZE;	for (ct = c->mfc_un.res.minvif; ct < c->mfc_un.res.maxvif; ct++) {		if (MIF_EXISTS(mrt, ct) && c->mfc_un.res.ttls[ct] < 255) {			nhp = nla_reserve_nohdr(skb, sizeof(*nhp));			if (!nhp) {				nla_nest_cancel(skb, mp_attr);				return -EMSGSIZE;			}			nhp->rtnh_flags = 0;			nhp->rtnh_hops = c->mfc_un.res.ttls[ct];			nhp->rtnh_ifindex = mrt->vif6_table[ct].dev->ifindex;			nhp->rtnh_len = sizeof(*nhp);		}	}	nla_nest_end(skb, mp_attr);	lastuse = READ_ONCE(c->mfc_un.res.lastuse);	lastuse = time_after_eq(jiffies, lastuse) ? jiffies - lastuse : 0;	mfcs.mfcs_packets = c->mfc_un.res.pkt;	mfcs.mfcs_bytes = c->mfc_un.res.bytes;	mfcs.mfcs_wrong_if = c->mfc_un.res.wrong_if;	if (nla_put_64bit(skb, RTA_MFC_STATS, sizeof(mfcs), &mfcs, RTA_PAD) ||	    nla_put_u64_64bit(skb, RTA_EXPIRES, jiffies_to_clock_t(lastuse),			      RTA_PAD))		return -EMSGSIZE;	rtm->rtm_type = RTN_MULTICAST;	return 1;}",28039
339,2618,CVE-2018-18358,24,  SameProxyWithDifferentSchemesProxyResolver() {},30024
57,1549,CVE-2013-7271,24,"static int sco_sock_getname(struct socket *sock, struct sockaddr *addr, int *len, int peer){	struct sockaddr_sco *sa = (struct sockaddr_sco *) addr;	struct sock *sk = sock->sk;	BT_DBG(""sock %p, sk %p"", sock, sk);	addr->sa_family = AF_BLUETOOTH;	*len = sizeof(struct sockaddr_sco);	if (peer)		bacpy(&sa->sco_bdaddr, &sco_pi(sk)->dst);	else		bacpy(&sa->sco_bdaddr, &sco_pi(sk)->src);	return 0;}",12437
592,544,CVE-2011-4914,24,"unsigned int rose_new_lci(struct rose_neigh *neigh){	int lci;	if (neigh->dce_mode) {		for (lci = 1; lci <= sysctl_rose_maximum_vcs; lci++)			if (rose_find_socket(lci, neigh) == NULL && rose_route_free_lci(lci, neigh) == NULL)				return lci;	} else {		for (lci = sysctl_rose_maximum_vcs; lci > 0; lci--)			if (rose_find_socket(lci, neigh) == NULL && rose_route_free_lci(lci, neigh) == NULL)				return lci;	}	return 0;}",4391
155,404,CVE-2018-0494,24,check_end (const char *p){  if (!p)    return false;  while (c_isspace (*p))    ++p;  if (!*p      || (p[0] == 'G' && p[1] == 'M' && p[2] == 'T')      || ((p[0] == '+' || p[0] == '-') && c_isdigit (p[1])))    return true;  else    return false;},2360
672,2196,CVE-2017-6345,24,"static int llc_find_offset(int state, int ev_type){	int rc = 0;	 	switch (ev_type) {	case LLC_CONN_EV_TYPE_PRIM:		rc = llc_offset_table[state][0]; break;	case LLC_CONN_EV_TYPE_PDU:		rc = llc_offset_table[state][4]; break;	case LLC_CONN_EV_TYPE_SIMPLE:		rc = llc_offset_table[state][1]; break;	case LLC_CONN_EV_TYPE_P_TMR:	case LLC_CONN_EV_TYPE_ACK_TMR:	case LLC_CONN_EV_TYPE_REJ_TMR:	case LLC_CONN_EV_TYPE_BUSY_TMR:		rc = llc_offset_table[state][3]; break;	}	return rc;}",21829
283,629,CVE-2011-1080,24,struct ebt_entry *ebt_next_entry(const struct ebt_entry *entry){	return (void *)entry + entry->next_offset;},6932
86,2282,CVE-2018-18955,24,"static void dec_user_namespaces(struct ucounts *ucounts){	return dec_ucount(ucounts, UCOUNT_USER_NAMESPACES);}",23411
219,1046,CVE-2014-3645,24,"int kvm_init_shadow_ept_mmu(struct kvm_vcpu *vcpu, struct kvm_mmu *context,		int execonly){	ASSERT(vcpu);	ASSERT(!VALID_PAGE(vcpu->arch.mmu.root_hpa));	context->shadow_root_level = kvm_x86_ops->get_tdp_level();	context->nx = true;	context->new_cr3 = paging_new_cr3;	context->page_fault = ept_page_fault;	context->gva_to_gpa = ept_gva_to_gpa;	context->sync_page = ept_sync_page;	context->invlpg = ept_invlpg;	context->update_pte = ept_update_pte;	context->free = paging_free;	context->root_level = context->shadow_root_level;	context->root_hpa = INVALID_PAGE;	context->direct_map = false;	update_permission_bitmask(vcpu, context, true);	reset_rsvds_bits_mask_ept(vcpu, context, execonly);	return 0;}",11180
505,1713,CVE-2013-7271,24,"static int vsock_auto_bind(struct vsock_sock *vsk){	struct sock *sk = sk_vsock(vsk);	struct sockaddr_vm local_addr;	if (vsock_addr_bound(&vsk->local_addr))		return 0;	vsock_addr_init(&local_addr, VMADDR_CID_ANY, VMADDR_PORT_ANY);	return __vsock_bind(sk, &local_addr);}",12601
2,2537,CVE-2017-12843,24,"static int parse_metadata_store_data(const char *tag,                                     struct entryattlist **entryatts){    int c;    const char *name;    const char *att;    static struct buf entry, value;    struct attvaluelist *attvalues = NULL;    struct entryattlist *entryp;    int need_add;    *entryatts = NULL;    c = prot_getc(imapd_in);    if (c != '(') {        prot_printf(imapd_out,                    ""%s BAD Missing metadata entry list\r\n"", tag);        goto baddata;    }    do {                 c = getastring(imapd_in, imapd_out, &entry);        if (c != ' ') {            prot_printf(imapd_out,                        ""%s BAD Missing metadata entry\r\n"", tag);            goto baddata;        }        lcase(entry.s);                 c = getbnstring(imapd_in, imapd_out, &value);        if (c == EOF) {            prot_printf(imapd_out,                        ""%s BAD Missing metadata value\r\n"", tag);            goto baddata;        }        if (!strncmp(entry.s, ""/private"", 8) &&            (entry.s[8] == '\0' || entry.s[8] == '/')) {            att = ""value.priv"";            name = entry.s + 8;        }        else if (!strncmp(entry.s, ""/shared"", 7) &&                 (entry.s[7] == '\0' || entry.s[7] == '/')) {            att = ""value.shared"";            name = entry.s + 7;        }        else {            prot_printf(imapd_out,                        ""%s BAD entry must begin with /shared or /private\r\n"",                        tag);            goto baddata;        }        need_add = 1;        for (entryp = *entryatts; entryp; entryp = entryp->next) {            if (strcmp(entryp->entry, name)) continue;                         appendattvalue(&entryp->attvalues, att, &value);            need_add = 0;            break;        }        if (need_add) {            appendattvalue(&attvalues, att, &value);            appendentryatt(entryatts, name, attvalues);            attvalues = NULL;        }    } while (c == ' ');    if (c != ')') {        prot_printf(imapd_out,                    ""%s BAD Missing close paren in annotation entry list \r\n"",                    tag);        goto baddata;    }    c = prot_getc(imapd_in);    return c;  baddata:    if (attvalues) freeattvalues(attvalues);    if (c != EOF) prot_ungetc(c, imapd_in);    return EOF;}",28538
467,2580,CVE-2012-5148,24,  void Stop() {    animation_.Stop();  },29459
638,1991,CVE-2017-1000252,24,ioeventfd_release(struct _ioeventfd *p){	eventfd_ctx_put(p->eventfd);	list_del(&p->list);	kfree(p);},19452
614,1338,CVE-2014-2038,24,"void nfs_retry_commit(struct list_head *page_list,		      struct pnfs_layout_segment *lseg,		      struct nfs_commit_info *cinfo){	struct nfs_page *req;	while (!list_empty(page_list)) {		req = nfs_list_entry(page_list->next);		nfs_list_remove_request(req);		nfs_mark_request_commit(req, lseg, cinfo);		if (!cinfo->dreq) {			dec_zone_page_state(req->wb_page, NR_UNSTABLE_NFS);			dec_bdi_stat(page_file_mapping(req->wb_page)->backing_dev_info,				     BDI_RECLAIMABLE);		}		nfs_unlock_and_release_request(req);	}}",11885
142,742,CVE-2013-4254,24,"armpmu_stop(struct perf_event *event, int flags){	struct arm_pmu *armpmu = to_arm_pmu(event->pmu);	struct hw_perf_event *hwc = &event->hw;	 	if (!(hwc->state & PERF_HES_STOPPED)) {		armpmu->disable(event);		armpmu_event_update(event);		hwc->state |= PERF_HES_STOPPED | PERF_HES_UPTODATE;	}}",7893
301,986,CVE-2014-5336,24,"void mk_vhost_init(char *path){    DIR *dir;    unsigned long len;    char *buf = 0;    char *sites = 0;    char *file;    struct host *p_host;          struct dirent *ent;    struct file_info f_info;    int ret;         mk_string_build(&sites, &len, ""%s/%s/"", path, config->sites_conf_dir);    ret = mk_file_get_info(sites, &f_info);    if (ret == -1 || f_info.is_directory == MK_FALSE) {        mk_mem_free(sites);        sites = config->sites_conf_dir;    }    mk_string_build(&buf, &len, ""%s/default"", sites);    p_host = mk_vhost_read(buf);    if (!p_host) {        mk_err(""Error parsing main configuration file 'default'"");    }    mk_list_add(&p_host->_head, &config->hosts);    config->nhosts++;    mk_mem_free(buf);    buf = NULL;         if (!(dir = opendir(sites))) {        mk_mem_free(sites);        mk_err(""Could not open %s"", sites);        exit(EXIT_FAILURE);    }         while ((ent = readdir(dir)) != NULL) {        if (ent->d_name[0] == '.') {            continue;        }        if (strcmp((char *) ent->d_name, "".."") == 0) {            continue;        }        if (ent->d_name[strlen(ent->d_name) - 1] ==  '~') {            continue;        }        if (strcasecmp((char *) ent->d_name, ""default"") == 0) {            continue;        }        file = NULL;        mk_string_build(&file, &len, ""%s/%s"", sites, ent->d_name);        p_host = mk_vhost_read(file);        mk_mem_free(file);        if (!p_host) {            continue;        }        else {            mk_list_add(&p_host->_head, &config->hosts);            config->nhosts++;        }    }    closedir(dir);    mk_mem_free(sites);}",10643
615,145,CVE-2011-1428,24,"hook_search_command (struct t_weechat_plugin *plugin, const char *command){    struct t_hook *ptr_hook;        for (ptr_hook = weechat_hooks[HOOK_TYPE_COMMAND]; ptr_hook;         ptr_hook = ptr_hook->next_hook)    {        if (!ptr_hook->deleted            && (ptr_hook->plugin == plugin)            && (string_strcasecmp (HOOK_COMMAND(ptr_hook, command), command) == 0))            return ptr_hook;    }             return NULL;}",639
554,1060,CVE-2014-3645,24,"static int kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,				    struct list_head *invalid_list){	int ret;	trace_kvm_mmu_prepare_zap_page(sp);	++kvm->stat.mmu_shadow_zapped;	ret = mmu_zap_unsync_children(kvm, sp, invalid_list);	kvm_mmu_page_unlink_children(kvm, sp);	kvm_mmu_unlink_parents(kvm, sp);	if (!sp->role.invalid && !sp->role.direct)		unaccount_shadowed(kvm, sp->gfn);	if (sp->unsync)		kvm_unlink_unsync_page(kvm, sp);	if (!sp->root_count) {		 		ret++;		list_move(&sp->link, invalid_list);		kvm_mod_used_mmu_pages(kvm, -1);	} else {		list_move(&sp->link, &kvm->arch.active_mmu_pages);		 		if (!sp->role.invalid && !is_obsolete_sp(kvm, sp))			kvm_reload_remote_mmus(kvm);	}	sp->role.invalid = 1;	return ret;}",11194
261,2515,CVE-2017-12843,24,"static void cmd_xstats(char *tag, int c){    int metric;    if (backend_current) {                 const char *cmd = ""Xstats"";        prot_printf(backend_current->out, ""%s %s "", tag, cmd);        if (!pipe_command(backend_current, 65536)) {            pipe_including_tag(backend_current, tag, 0);        }        return;    }    if (c == EOF) {        prot_printf(imapd_out, ""%s BAD Syntax error in Xstats arguments\r\n"", tag);        goto error;    }    if (c == '\r') c = prot_getc(imapd_in);    if (c != '\n') {        prot_printf(imapd_out,                    ""%s BAD Unexpected extra arguments to Xstats\r\n"", tag);        goto error;    }    prot_printf(imapd_out, ""* XSTATS"");    for (metric = 0 ; metric < XSTATS_NUM_METRICS ; metric++)        prot_printf(imapd_out, "" %s %u"", xstats_names[metric], xstats[metric]);    prot_printf(imapd_out, ""\r\n"");    prot_printf(imapd_out, ""%s OK %s\r\n"", tag,                error_message(IMAP_OK_COMPLETED));    return;error:    eatline(imapd_in, (c == EOF ? ' ' : c));}",28516
333,2009,CVE-2017-1000201,24,"static int dev_added(struct tcmu_device *dev){	struct tcmur_handler *rhandler = tcmu_get_runner_handler(dev);	struct tcmur_device *rdev;	int block_size, max_sectors;	int dev_size;	int ret;	rdev = calloc(1, sizeof(*rdev));	if (!rdev)		return -ENOMEM;	tcmu_set_daemon_dev_private(dev, rdev);	ret = -EINVAL;	block_size = tcmu_get_attribute(dev, ""hw_block_size"");	if (block_size <= 0) {		tcmu_dev_err(dev, ""Could not get hw_block_size\n"");		goto free_rdev;	}	tcmu_set_dev_block_size(dev, block_size);	dev_size = tcmu_get_device_size(dev);	if (dev_size < 0) {		tcmu_dev_err(dev, ""Could not get device size\n"");		goto free_rdev;	}	tcmu_set_dev_num_lbas(dev, dev_size / block_size);	max_sectors = tcmu_get_attribute(dev, ""hw_max_sectors"");	if (max_sectors < 0)		goto free_rdev;	tcmu_set_dev_max_xfer_len(dev, max_sectors);	tcmu_dev_dbg(dev, ""Got block_size %ld, size in bytes %lld\n"",		     block_size, dev_size);	ret = pthread_spin_init(&rdev->lock, 0);	if (ret != 0)		goto free_rdev;	ret = pthread_mutex_init(&rdev->caw_lock, NULL);	if (ret != 0)		goto cleanup_dev_lock;	ret = pthread_mutex_init(&rdev->format_lock, NULL);	if (ret != 0)		goto cleanup_caw_lock;	ret = setup_io_work_queue(dev);	if (ret < 0)		goto cleanup_format_lock;	ret = setup_aio_tracking(rdev);	if (ret < 0)		goto cleanup_io_work_queue;	ret = rhandler->open(dev);	if (ret)		goto cleanup_aio_tracking;	ret = tcmulib_start_cmdproc_thread(dev, tcmur_cmdproc_thread);	if (ret < 0)		goto close_dev;	return 0;close_dev:	rhandler->close(dev);cleanup_aio_tracking:	cleanup_aio_tracking(rdev);cleanup_io_work_queue:	cleanup_io_work_queue(dev, true);cleanup_format_lock:	pthread_mutex_destroy(&rdev->format_lock);cleanup_caw_lock:	pthread_mutex_destroy(&rdev->caw_lock);cleanup_dev_lock:	pthread_spin_destroy(&rdev->lock);free_rdev:	free(rdev);	return ret;}",19499
16,2103,CVE-2017-15951,24,"static int TSS_sha1(const unsigned char *data, unsigned int datalen,		    unsigned char *digest){	struct sdesc *sdesc;	int ret;	sdesc = init_sdesc(hashalg);	if (IS_ERR(sdesc)) {		pr_info(""trusted_key: can't alloc %s\n"", hash_alg);		return PTR_ERR(sdesc);	}	ret = crypto_shash_digest(&sdesc->shash, data, datalen, digest);	kzfree(sdesc);	return ret;}",19926
122,1760,CVE-2015-8215,24,"static void addrconf_dev_config(struct net_device *dev){	struct inet6_dev *idev;	ASSERT_RTNL();	if ((dev->type != ARPHRD_ETHER) &&	    (dev->type != ARPHRD_FDDI) &&	    (dev->type != ARPHRD_ARCNET) &&	    (dev->type != ARPHRD_INFINIBAND) &&	    (dev->type != ARPHRD_IEEE802154) &&	    (dev->type != ARPHRD_IEEE1394) &&	    (dev->type != ARPHRD_TUNNEL6) &&	    (dev->type != ARPHRD_6LOWPAN)) {		 		return;	}	idev = addrconf_add_dev(dev);	if (IS_ERR(idev))		return;	addrconf_addr_gen(idev, false);}",12970
174,2221,CVE-2017-5226,24,"drop_privs (void){  if (!is_privileged)    return;     if (setuid (opt_sandbox_uid) < 0)    die_with_error (""unable to drop root uid"");  drop_all_caps ();}",22136
432,1191,CVE-2014-2739,24,"static int cma_accept_iw(struct rdma_id_private *id_priv,		  struct rdma_conn_param *conn_param){	struct iw_cm_conn_param iw_param;	int ret;	ret = cma_modify_qp_rtr(id_priv, conn_param);	if (ret)		return ret;	iw_param.ord = conn_param->initiator_depth;	iw_param.ird = conn_param->responder_resources;	iw_param.private_data = conn_param->private_data;	iw_param.private_data_len = conn_param->private_data_len;	if (id_priv->id.qp) {		iw_param.qpn = id_priv->qp_num;	} else		iw_param.qpn = conn_param->qp_num;	return iw_cm_accept(id_priv->cm_id.iw, &iw_param);}",11666
624,1850,CVE-2016-9191,24,"static void next_entry(struct ctl_table_header **phead, struct ctl_table **pentry){	struct ctl_table_header *head = *phead;	struct ctl_table *entry = *pentry;	struct ctl_node *ctl_node = &head->node[entry - head->ctl_table];	spin_lock(&sysctl_lock);	unuse_table(head);	ctl_node = first_usable_entry(rb_next(&ctl_node->node));	spin_unlock(&sysctl_lock);	head = NULL;	if (ctl_node) {		head = ctl_node->header;		entry = &head->ctl_table[ctl_node - head->node];	}	*phead = head;	*pentry = entry;}",15211
292,693,CVE-2013-6368,24,"static int kvm_vm_ioctl_set_tss_addr(struct kvm *kvm, unsigned long addr){	int ret;	if (addr > (unsigned int)(-3 * PAGE_SIZE))		return -EINVAL;	ret = kvm_x86_ops->set_tss_addr(kvm, addr);	return ret;}",7460
148,823,CVE-2013-1848,24,static int ext3_mark_dquot_dirty(struct dquot *dquot){	 	if (EXT3_SB(dquot->dq_sb)->s_qf_names[USRQUOTA] ||	    EXT3_SB(dquot->dq_sb)->s_qf_names[GRPQUOTA]) {		dquot_mark_dquot_dirty(dquot);		return ext3_write_dquot(dquot);	} else {		return dquot_mark_dquot_dirty(dquot);	}},9379
24,1966,CVE-2015-3288,24,"static void unmap_mapping_range_vma(struct vm_area_struct *vma,		unsigned long start_addr, unsigned long end_addr,		struct zap_details *details){	zap_page_range_single(vma, start_addr, end_addr - start_addr, details);}",19127
139,2559,CVE-2019-1010251,24,"static int AppLayerProtoDetectTest12(void){    AppLayerProtoDetectUnittestCtxBackup();    AppLayerProtoDetectSetup();    int r = 0;    AppLayerProtoDetectPMRegisterPatternCS(IPPROTO_TCP, ALPROTO_HTTP, ""HTTP"", 4, 0, STREAM_TOSERVER);    if (alpd_ctx.ctx_ipp[FLOW_PROTO_TCP].ctx_pm[0].head == NULL ||        alpd_ctx.ctx_ipp[FLOW_PROTO_TCP].ctx_pm[0].map != NULL)    {        printf(""failure 1\n"");        goto end;    }    AppLayerProtoDetectPrepareState();    if (alpd_ctx.ctx_ipp[FLOW_PROTO_TCP].ctx_pm[0].max_pat_id != 1) {        printf(""failure 2\n"");        goto end;    }    if (alpd_ctx.ctx_ipp[FLOW_PROTO_TCP].ctx_pm[0].head != NULL ||        alpd_ctx.ctx_ipp[FLOW_PROTO_TCP].ctx_pm[0].map == NULL)    {        printf(""failure 3\n"");        goto end;    }    if (alpd_ctx.ctx_ipp[FLOW_PROTO_TCP].ctx_pm[0].map[0]->alproto != ALPROTO_HTTP) {        printf(""failure 4\n"");        goto end;    }    if (alpd_ctx.ctx_ipp[FLOW_PROTO_TCP].ctx_pm[0].map[0]->cd->id != 0) {        printf(""failure 5\n"");        goto end;    }    if (alpd_ctx.ctx_ipp[FLOW_PROTO_TCP].ctx_pm[0].map[0]->next != NULL) {        printf(""failure 6\n"");        goto end;    }    r = 1; end:    AppLayerProtoDetectDeSetup();    AppLayerProtoDetectUnittestCtxRestore();    return r;}",28860
276,2099,CVE-2017-15951,24,static void request_key_auth_free_preparse(struct key_preparsed_payload *prep){},19922
141,1898,CVE-2016-6197,24,"static void ovl_remove_opaque(struct dentry *upperdentry){	int err;	err = ovl_do_removexattr(upperdentry, OVL_XATTR_OPAQUE);	if (err) {		pr_warn(""overlayfs: failed to remove opaque from '%s' (%i)\n"",			upperdentry->d_name.name, err);	}}",16253
204,167,CVE-2011-1428,24,"irc_server_check_away (struct t_irc_server *server){    struct t_irc_channel *ptr_channel;        if (server->is_connected)    {        for (ptr_channel = server->channels; ptr_channel;             ptr_channel = ptr_channel->next_channel)        {            if (ptr_channel->type == IRC_CHANNEL_TYPE_CHANNEL)                irc_channel_check_away (server, ptr_channel);        }        server->last_away_check = time (NULL);    }}",661
69,1953,CVE-2015-3288,24,"static inline int check_stack_guard_page(struct vm_area_struct *vma, unsigned long address){	address &= PAGE_MASK;	if ((vma->vm_flags & VM_GROWSDOWN) && address == vma->vm_start) {		struct vm_area_struct *prev = vma->vm_prev;		 		if (prev && prev->vm_end == address)			return prev->vm_flags & VM_GROWSDOWN ? 0 : -ENOMEM;		return expand_downwards(vma, address - PAGE_SIZE);	}	if ((vma->vm_flags & VM_GROWSUP) && address + PAGE_SIZE == vma->vm_end) {		struct vm_area_struct *next = vma->vm_next;		 		if (next && next->vm_start == address + PAGE_SIZE)			return next->vm_flags & VM_GROWSUP ? 0 : -ENOMEM;		return expand_upwards(vma, address + PAGE_SIZE);	}	return 0;}",19114
488,2721,CVE-2016-3760,24,"int HAL_unload(void){ int err = 0;    bdt_log(""Unloading HAL lib"");    sBtInterface = NULL;    bdt_log(""HAL library unloaded (%s)"", strerror(err)); return err;}",30532
46,953,CVE-2011-3619,24,"static int param_set_mode(const char *val, struct kernel_param *kp){	int i;	if (!capable(CAP_MAC_ADMIN))		return -EPERM;	if (!apparmor_enabled)		return -EINVAL;	if (!val)		return -EINVAL;	for (i = 0; i < APPARMOR_NAMES_MAX_INDEX; i++) {		if (strcmp(val, profile_mode_names[i]) == 0) {			aa_g_profile_mode = i;			return 0;		}	}	return -EINVAL;}",10124
400,476,CVE-2012-2136,24,static char proto_method_implemented(const void *method){	return method == NULL ? 'n' : 'y';},3435
575,592,CVE-2011-3363,24,"extract_hostname(const char *unc){	const char *src;	char *dst, *delim;	unsigned int len;	 	 	src = unc + 2;	 	delim = strchr(src, '\\');	if (!delim)		return ERR_PTR(-EINVAL);	len = delim - src;	dst = kmalloc((len + 1), GFP_KERNEL);	if (dst == NULL)		return ERR_PTR(-ENOMEM);	memcpy(dst, src, len);	dst[len] = '\0';	return dst;}",5539
156,1727,CVE-2013-7271,24,static void x25_destroy_timer(unsigned long data){	x25_destroy_socket_from_timer((struct sock *)data);},12615
60,72,CVE-2015-5296,24,int smb1cli_conn_server_lockread(struct smbXcli_conn *conn){	return conn->smb1.server.lockread;},480
563,1702,CVE-2013-7271,24,"static int unix_accept(struct socket *sock, struct socket *newsock, int flags){	struct sock *sk = sock->sk;	struct sock *tsk;	struct sk_buff *skb;	int err;	err = -EOPNOTSUPP;	if (sock->type != SOCK_STREAM && sock->type != SOCK_SEQPACKET)		goto out;	err = -EINVAL;	if (sk->sk_state != TCP_LISTEN)		goto out;	 	skb = skb_recv_datagram(sk, 0, flags&O_NONBLOCK, &err);	if (!skb) {		 		if (err == 0)			err = -EINVAL;		goto out;	}	tsk = skb->sk;	skb_free_datagram(sk, skb);	wake_up_interruptible(&unix_sk(sk)->peer_wait);	 	unix_state_lock(tsk);	newsock->state = SS_CONNECTED;	unix_sock_inherit_flags(sock, newsock);	sock_graft(tsk, newsock);	unix_state_unlock(tsk);	return 0;out:	return err;}",12590
222,2250,CVE-2015-5195,24,"get_pfxmatch(	char ** s,	struct masks *m	){	while (m->name) {		if (strncmp(*s, m->name, strlen(m->name)) == 0) {			*s += strlen(m->name);			return m->mask;		} else {			m++;		}	}	return 0;}",22916
91,1550,CVE-2013-7271,24,"static long caif_wait_for_flow_on(struct caifsock *cf_sk,				  int wait_writeable, long timeo, int *err){	struct sock *sk = &cf_sk->sk;	DEFINE_WAIT(wait);	for (;;) {		*err = 0;		if (tx_flow_is_on(cf_sk) &&			(!wait_writeable || sock_writeable(&cf_sk->sk)))			break;		*err = -ETIMEDOUT;		if (!timeo)			break;		*err = -ERESTARTSYS;		if (signal_pending(current))			break;		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);		*err = -ECONNRESET;		if (sk->sk_shutdown & SHUTDOWN_MASK)			break;		*err = -sk->sk_err;		if (sk->sk_err)			break;		*err = -EPIPE;		if (cf_sk->sk.sk_state != CAIF_CONNECTED)			break;		timeo = schedule_timeout(timeo);	}	finish_wait(sk_sleep(sk), &wait);	return timeo;}",12438
445,1038,CVE-2014-3645,24,"static int is_obsolete_sp(struct kvm *kvm, struct kvm_mmu_page *sp){	return unlikely(sp->mmu_valid_gen != kvm->arch.mmu_valid_gen);}",11172
414,1694,CVE-2013-7271,24,"static int release(struct socket *sock){	struct sock *sk = sock->sk;	struct tipc_port *tport;	struct sk_buff *buf;	int res;	 	if (sk == NULL)		return 0;	tport = tipc_sk_port(sk);	lock_sock(sk);	 	while (sock->state != SS_DISCONNECTING) {		buf = __skb_dequeue(&sk->sk_receive_queue);		if (buf == NULL)			break;		if (TIPC_SKB_CB(buf)->handle != NULL)			kfree_skb(buf);		else {			if ((sock->state == SS_CONNECTING) ||			    (sock->state == SS_CONNECTED)) {				sock->state = SS_DISCONNECTING;				tipc_disconnect(tport->ref);			}			tipc_reject_msg(buf, TIPC_ERR_NO_PORT);		}	}	 	res = tipc_deleteport(tport->ref);	 	__skb_queue_purge(&sk->sk_receive_queue);	 	sock->state = SS_DISCONNECTING;	release_sock(sk);	sock_put(sk);	sock->sk = NULL;	return res;}",12582
70,538,CVE-2011-4914,24,"static int rose_device_event(struct notifier_block *this, unsigned long event,	void *ptr){	struct net_device *dev = (struct net_device *)ptr;	if (!net_eq(dev_net(dev), &init_net))		return NOTIFY_DONE;	if (event != NETDEV_DOWN)		return NOTIFY_DONE;	switch (dev->type) {	case ARPHRD_ROSE:		rose_kill_by_device(dev);		break;	case ARPHRD_AX25:		rose_link_device_down(dev);		rose_rt_device_down(dev);		break;	}	return NOTIFY_DONE;}",4385
429,2413,CVE-2019-12439,24,"drop_privs (int keep_requested_caps){  assert (!keep_requested_caps || !is_privileged);     if (getuid () == 0 && setuid (opt_sandbox_uid) < 0)    die_with_error (""unable to drop root uid"");  drop_all_caps (keep_requested_caps);}",26870
236,355,CVE-2016-4072,24,"PHP_METHOD(Phar, stopBuffering){	char *error;	PHAR_ARCHIVE_OBJECT();	if (zend_parse_parameters_none() == FAILURE) {		return;	}	if (PHAR_G(readonly) && !phar_obj->archive->is_data) {		zend_throw_exception_ex(spl_ce_UnexpectedValueException, 0,			""Cannot write out phar archive, phar is read-only"");		return;	}	phar_obj->archive->donotflush = 0;	phar_flush(phar_obj->archive, 0, 0, 0, &error);	if (error) {		zend_throw_exception_ex(phar_ce_PharException, 0, ""%s"", error);		efree(error);	}}",1925
38,2,CVE-2017-9373,7,"static void ahci_irq_set(void *opaque, int n, int level){}",986
32,272,CVE-2019-16995,7,static int is_admin_up(struct net_device *dev){	return dev && (dev->flags & IFF_UP);},26446
1,25,CVE-2017-6386,7,static inline int should_invert_viewport(struct vrend_context *ctx){       return !(ctx->sub->viewport_is_negative ^ ctx->sub->inverted_fbo_content);},1437
53,112,CVE-2017-6386,7,"void vrend_set_num_vbo(struct vrend_context *ctx,                       int num_vbo){   int old_num = ctx->sub->num_vbos;   int i;   ctx->sub->num_vbos = num_vbo;   ctx->sub->old_num_vbos = old_num;   if (old_num != num_vbo)      ctx->sub->vbo_dirty = true;   for (i = num_vbo; i < old_num; i++) {      vrend_resource_reference((struct vrend_resource **)&ctx->sub->vbo[i].buffer, NULL);      ctx->sub->vbo_res_ids[i] = 0;   }}",1524
17,151,CVE-2017-12190,7,"int bio_uncopy_user(struct bio *bio){	struct bio_map_data *bmd = bio->bi_private;	int ret = 0;	if (!bio_flagged(bio, BIO_NULL_MAPPED)) {		 		if (!current->mm)			ret = -EINTR;		else if (bio_data_dir(bio) == READ)			ret = bio_copy_to_iter(bio, bmd->iter);		if (bmd->is_our_pages)			bio_free_pages(bio);	}	kfree(bmd);	bio_put(bio);	return ret;}",20324
29,80,CVE-2017-6386,7,"void vrend_object_bind_rasterizer(struct vrend_context *ctx,                                  int handle){   struct pipe_rasterizer_state *state;   if (handle == 0) {      memset(&ctx->sub->rs_state, 0, sizeof(ctx->sub->rs_state));      return;   }   state = vrend_object_lookup(ctx->sub->object_hash, handle, VIRGL_OBJECT_RASTERIZER);   if (!state) {      report_context_error(ctx, VIRGL_ERROR_CTX_ILLEGAL_HANDLE, handle);      return;   }   ctx->sub->rs_state = *state;   ctx->sub->scissor_state_dirty = (1 << 0);   ctx->sub->shader_dirty = true;   vrend_hw_emit_rs(ctx);}",1492
3,246,CVE-2019-17178,7,unsigned lodepng_chunk_length(const unsigned char* chunk){  return lodepng_read32bitInt(&chunk[0]);},26419
10,268,CVE-2019-16995,7,static int hsr_dev_close(struct net_device *dev){	 	return 0;},26442
23,77,CVE-2017-6386,7,int vrend_is_ds_format(enum virgl_formats format){   return vrend_format_is_ds(format);},1489
54,148,CVE-2017-12190,7,"static inline int bio_remaining_done(struct bio *bio){	 	if (!bio_flagged(bio, BIO_CHAIN))		return true;	BUG_ON(atomic_read(&bio->__bi_remaining) <= 0);	if (atomic_dec_and_test(&bio->__bi_remaining)) {		bio_clear_flag(bio, BIO_CHAIN);		return true;	}	return false;}",20321
48,16,CVE-2017-6386,7,static inline int conv_dst_blend(int blend_factor){   if (blend_factor == PIPE_BLENDFACTOR_DST_ALPHA)      return PIPE_BLENDFACTOR_ONE;   if (blend_factor == PIPE_BLENDFACTOR_INV_DST_ALPHA)      return PIPE_BLENDFACTOR_ZERO;   return blend_factor;},1428
7,229,CVE-2018-7757,7,"static int sas_rediscover(struct domain_device *dev, const int phy_id){	struct expander_device *ex = &dev->ex_dev;	struct ex_phy *changed_phy = &ex->ex_phy[phy_id];	int res = 0;	int i;	int last = true;	 	SAS_DPRINTK(""ex %016llx phy%d originated BROADCAST(CHANGE)\n"",		    SAS_ADDR(dev->sas_addr), phy_id);	if (SAS_ADDR(changed_phy->attached_sas_addr) != 0) {		for (i = 0; i < ex->num_phys; i++) {			struct ex_phy *phy = &ex->ex_phy[i];			if (i == phy_id)				continue;			if (SAS_ADDR(phy->attached_sas_addr) ==			    SAS_ADDR(changed_phy->attached_sas_addr)) {				SAS_DPRINTK(""phy%d part of wide port with ""					    ""phy%d\n"", phy_id, i);				last = false;				break;			}		}		res = sas_rediscover_dev(dev, phy_id, last);	} else		res = sas_discover_new(dev, phy_id);	return res;}",25354
8,168,CVE-2018-8087,7,"static inline void hwsim_check_magic(struct ieee80211_vif *vif){	struct hwsim_vif_priv *vp = (void *)vif->drv_priv;	WARN(vp->magic != HWSIM_VIF_MAGIC,	     ""Invalid VIF (%p) magic %#x, %pM, %d/%d\n"",	     vif, vp->magic, vif->addr, vif->type, vif->p2p);}",25290
4,99,CVE-2017-6386,7,"void vrend_renderer_resource_detach_iov(int res_handle,                                        struct iovec **iov_p,                                        int *num_iovs_p){   struct vrend_resource *res;   res = vrend_resource_lookup(res_handle, 0);   if (!res) {      return;   }   if (iov_p)      *iov_p = res->iov;   if (num_iovs_p)      *num_iovs_p = res->num_iovs;   res->iov = NULL;   res->num_iovs = 0;}",1511
47,261,CVE-2019-17178,7,"static void string_init(char** out){  *out = NULL;  string_resize(out, 0);}",26434
37,219,CVE-2018-7757,7,"static int sas_ex_manuf_info(struct domain_device *dev){	u8 *mi_req;	u8 *mi_resp;	int res;	mi_req = alloc_smp_req(MI_REQ_SIZE);	if (!mi_req)		return -ENOMEM;	mi_resp = alloc_smp_resp(MI_RESP_SIZE);	if (!mi_resp) {		kfree(mi_req);		return -ENOMEM;	}	mi_req[1] = SMP_REPORT_MANUF_INFO;	res = smp_execute_task(dev, mi_req, MI_REQ_SIZE, mi_resp,MI_RESP_SIZE);	if (res) {		SAS_DPRINTK(""MI: ex %016llx failed:0x%x\n"",			    SAS_ADDR(dev->sas_addr), res);		goto out;	} else if (mi_resp[2] != SMP_RESP_FUNC_ACC) {		SAS_DPRINTK(""MI ex %016llx returned SMP result:0x%x\n"",			    SAS_ADDR(dev->sas_addr), mi_resp[2]);		goto out;	}	ex_assign_manuf_info(dev, mi_resp);out:	kfree(mi_req);	kfree(mi_resp);	return res;}",25344
41,102,CVE-2017-6386,7,"static int vrend_renderer_transfer_send_iov(struct vrend_context *ctx,                                            struct vrend_resource *res,                                            struct iovec *iov, int num_iovs,                                            const struct vrend_transfer_info *info){   if (res->target == 0 && res->ptr) {      int send_size = info->box->width * util_format_get_blocksize(res->base.format);      vrend_write_to_iovec(iov, num_iovs, info->offset, res->ptr + info->box->x, send_size);      return 0;   }   if (res->target == GL_ELEMENT_ARRAY_BUFFER_ARB ||       res->target == GL_ARRAY_BUFFER_ARB ||       res->target == GL_TRANSFORM_FEEDBACK_BUFFER ||       res->target == GL_TEXTURE_BUFFER ||       res->target == GL_UNIFORM_BUFFER) {      int send_size = info->box->width * util_format_get_blocksize(res->base.format);      void *data;      glBindBufferARB(res->target, res->id);      data = glMapBufferRange(res->target, info->box->x, info->box->width, GL_MAP_READ_BIT);      if (!data)         fprintf(stderr,""unable to open buffer for reading %d\n"", res->target);      else         vrend_write_to_iovec(iov, num_iovs, info->offset, data, send_size);      glUnmapBuffer(res->target);   } else {      int can_readpixels = true;      can_readpixels = vrend_format_can_render(res->base.format) || vrend_format_is_ds(res->base.format);      if (can_readpixels) {         return vrend_transfer_send_readpixels(ctx, res,                                               iov, num_iovs, info);      }      return vrend_transfer_send_getteximage(ctx, res,                                             iov, num_iovs, info);   }   return 0;}",1514
9,147,CVE-2017-12190,7,"void bio_put(struct bio *bio){	if (!bio_flagged(bio, BIO_REFFED))		bio_free(bio);	else {		BIO_BUG_ON(!atomic_read(&bio->__bi_cnt));		 		if (atomic_dec_and_test(&bio->__bi_cnt))			bio_free(bio);	}}",20320
58,204,CVE-2018-7757,7,"static inline void *alloc_smp_resp(int size){	return kzalloc(size, GFP_KERNEL);}",25329
21,257,CVE-2019-17178,7,unsigned lodepng_read32bitInt(const unsigned char* buffer){  return (unsigned)((buffer[0] << 24) | (buffer[1] << 16) | (buffer[2] << 8) | buffer[3]);},26430
35,86,CVE-2017-6386,7,"static struct vrend_resource *vrend_renderer_ctx_res_lookup(struct vrend_context *ctx, int res_handle){   struct vrend_resource *res = vrend_object_lookup(ctx->res_hash, res_handle, 1);   return res;}",1498
42,142,CVE-2017-12190,7,"static struct kmem_cache *bio_find_or_create_slab(unsigned int extra_size){	unsigned int sz = sizeof(struct bio) + extra_size;	struct kmem_cache *slab = NULL;	struct bio_slab *bslab, *new_bio_slabs;	unsigned int new_bio_slab_max;	unsigned int i, entry = -1;	mutex_lock(&bio_slab_lock);	i = 0;	while (i < bio_slab_nr) {		bslab = &bio_slabs[i];		if (!bslab->slab && entry == -1)			entry = i;		else if (bslab->slab_size == sz) {			slab = bslab->slab;			bslab->slab_ref++;			break;		}		i++;	}	if (slab)		goto out_unlock;	if (bio_slab_nr == bio_slab_max && entry == -1) {		new_bio_slab_max = bio_slab_max << 1;		new_bio_slabs = krealloc(bio_slabs,					 new_bio_slab_max * sizeof(struct bio_slab),					 GFP_KERNEL);		if (!new_bio_slabs)			goto out_unlock;		bio_slab_max = new_bio_slab_max;		bio_slabs = new_bio_slabs;	}	if (entry == -1)		entry = bio_slab_nr++;	bslab = &bio_slabs[entry];	snprintf(bslab->name, sizeof(bslab->name), ""bio-%d"", entry);	slab = kmem_cache_create(bslab->name, sz, ARCH_KMALLOC_MINALIGN,				 SLAB_HWCACHE_ALIGN, NULL);	if (!slab)		goto out_unlock;	bslab->slab = slab;	bslab->slab_ref = 1;	bslab->slab_size = sz;out_unlock:	mutex_unlock(&bio_slab_lock);	return slab;}",20315
52,164,CVE-2018-16640,7,Magick_Orientation_from_Exif_Orientation(const int orientation){  switch (orientation)  {    case 1:      return TopLeftOrientation;    case 2:      return TopRightOrientation;    case 3:      return BottomRightOrientation;    case 4:      return BottomLeftOrientation;    case 5:      return LeftTopOrientation;    case 6:      return RightTopOrientation;    case 7:      return RightBottomOrientation;    case 8:      return LeftBottomOrientation;    case 0:    default:      return UndefinedOrientation;  }},24241
22,45,CVE-2017-6386,7,"static void vrend_destroy_sampler_state_object(void *obj_ptr){   struct vrend_sampler_state *state = obj_ptr;   glDeleteSamplers(1, &state->id);   FREE(state);}",1457
56,139,CVE-2017-12190,7,"static void bio_dirty_fn(struct work_struct *work){	unsigned long flags;	struct bio *bio;	spin_lock_irqsave(&bio_dirty_lock, flags);	bio = bio_dirty_list;	bio_dirty_list = NULL;	spin_unlock_irqrestore(&bio_dirty_lock, flags);	while (bio) {		struct bio *next = bio->bi_private;		bio_set_pages_dirty(bio);		bio_release_pages(bio);		bio_put(bio);		bio = next;	}}",20312
25,9,CVE-2017-6414,7,"vcard_response_new_data(unsigned char *buf, int len){    VCardResponse *new_response;    new_response = g_new(VCardResponse, 1);    new_response->b_data = g_malloc(len + 2);    memcpy(new_response->b_data, buf, len);    new_response->b_total_len = len+2;    new_response->b_len = len;    new_response->b_type = VCARD_MALLOC;    return new_response;}",1406
72,236,CVE-2018-7757,7,"static void smp_task_timedout(struct timer_list *t){	struct sas_task_slow *slow = from_timer(slow, t, timer);	struct sas_task *task = slow->task;	unsigned long flags;	spin_lock_irqsave(&task->task_state_lock, flags);	if (!(task->task_state_flags & SAS_TASK_STATE_DONE))		task->task_state_flags |= SAS_TASK_STATE_ABORTED;	spin_unlock_irqrestore(&task->task_state_lock, flags);	complete(&task->slow_task->completion);}",25361
19,88,CVE-2017-6386,7,"static void vrend_renderer_detach_res_ctx_p(struct vrend_context *ctx, int res_handle){   struct vrend_resource *res;   res = vrend_object_lookup(ctx->res_hash, res_handle, 1);   if (!res)      return;   vrend_object_remove(ctx->res_hash, res_handle, 1);}",1500
69,222,CVE-2018-7757,7,"struct domain_device *sas_ex_to_ata(struct domain_device *ex_dev, int phy_id){	struct ex_phy *ex_phy = &ex_dev->ex_dev.ex_phy[phy_id];	struct domain_device *dev;	struct sas_rphy *rphy;	if (!ex_phy->port)		return NULL;	rphy = ex_phy->port->rphy;	if (!rphy)		return NULL;	dev = sas_find_dev_by_rphy(rphy);	if (dev && dev_is_sata(dev))		return dev;	return NULL;}",25347
34,27,CVE-2017-6386,7,"void vrend_begin_query(struct vrend_context *ctx, int handle){   struct vrend_query *q;   q = vrend_object_lookup(ctx->sub->object_hash, handle, VIRGL_OBJECT_QUERY);   if (!q)      return;   if (q->gltype == GL_TIMESTAMP)      return;   glBeginQuery(q->gltype, q->id);}",1439
63,225,CVE-2018-7757,7,"static int sas_get_ex_change_count(struct domain_device *dev, int *ecc){	int res;	u8  *rg_req;	struct smp_resp  *rg_resp;	rg_req = alloc_smp_req(RG_REQ_SIZE);	if (!rg_req)		return -ENOMEM;	rg_resp = alloc_smp_resp(RG_RESP_SIZE);	if (!rg_resp) {		kfree(rg_req);		return -ENOMEM;	}	rg_req[1] = SMP_REPORT_GENERAL;	res = smp_execute_task(dev, rg_req, RG_REQ_SIZE, rg_resp,			       RG_RESP_SIZE);	if (res)		goto out;	if (rg_resp->result != SMP_RESP_FUNC_ACC) {		res = rg_resp->result;		goto out;	}	*ecc = be16_to_cpu(rg_resp->rg.change_count);out:	kfree(rg_resp);	kfree(rg_req);	return res;}",25350
6,21,CVE-2017-6386,7,"static void iov_buffer_upload(void *cookie, int doff, void *src, int len){   struct virgl_sub_upload_data *d = cookie;   glBufferSubData(d->target, d->box->x + doff, len, src);}",1433
66,223,CVE-2018-7757,7,"static int sas_expander_discover(struct domain_device *dev){	struct expander_device *ex = &dev->ex_dev;	int res = -ENOMEM;	ex->ex_phy = kzalloc(sizeof(*ex->ex_phy)*ex->num_phys, GFP_KERNEL);	if (!ex->ex_phy)		return -ENOMEM;	res = sas_ex_phy_discover(dev, -1);	if (res)		goto out_err;	return 0; out_err:	kfree(ex->ex_phy);	ex->ex_phy = NULL;	return res;}",25348
27,83,CVE-2017-6386,7,"void vrend_renderer_attach_res_ctx(int ctx_id, int resource_id){   struct vrend_context *ctx = vrend_lookup_renderer_ctx(ctx_id);   struct vrend_resource *res;   if (!ctx)      return;   res = vrend_resource_lookup(resource_id, 0);   if (!res)      return;   vrend_object_insert_nofree(ctx->res_hash, res, sizeof(*res), resource_id, 1, false);}",1495
57,141,CVE-2017-12190,7,"void bio_endio(struct bio *bio){again:	if (!bio_remaining_done(bio))		return;	if (!bio_integrity_endio(bio))		return;	 	if (bio->bi_end_io == bio_chain_endio) {		bio = __bio_chain_endio(bio);		goto again;	}	if (bio->bi_disk && bio_flagged(bio, BIO_TRACE_COMPLETION)) {		trace_block_bio_complete(bio->bi_disk->queue, bio,					 blk_status_to_errno(bio->bi_status));		bio_clear_flag(bio, BIO_TRACE_COMPLETION);	}	blk_throtl_bio_endio(bio);	 	bio_uninit(bio);	if (bio->bi_end_io)		bio->bi_end_io(bio);}",20314
43,192,CVE-2018-8087,7,"static void mac80211_hwsim_remove_chanctx(struct ieee80211_hw *hw,					  struct ieee80211_chanctx_conf *ctx){	wiphy_dbg(hw->wiphy,		  ""remove channel context control: %d MHz/width: %d/cfreqs:%d/%d MHz\n"",		  ctx->def.chan->center_freq, ctx->def.width,		  ctx->def.center_freq1, ctx->def.center_freq2);	hwsim_check_chanctx_magic(ctx);	hwsim_clear_chanctx_magic(ctx);}",25314
0,217,CVE-2018-7757,7,"static void sas_ex_get_linkrate(struct domain_device *parent,				       struct domain_device *child,				       struct ex_phy *parent_phy){	struct expander_device *parent_ex = &parent->ex_dev;	struct sas_port *port;	int i;	child->pathways = 0;	port = parent_phy->port;	for (i = 0; i < parent_ex->num_phys; i++) {		struct ex_phy *phy = &parent_ex->ex_phy[i];		if (phy->phy_state == PHY_VACANT ||		    phy->phy_state == PHY_NOT_PRESENT)			continue;		if (SAS_ADDR(phy->attached_sas_addr) ==		    SAS_ADDR(child->sas_addr)) {			child->min_linkrate = min(parent->min_linkrate,						  phy->linkrate);			child->max_linkrate = max(parent->max_linkrate,						  phy->linkrate);			child->pathways++;			sas_port_add_phy(port, phy->phy);		}	}	child->linkrate = min(parent_phy->linkrate, child->max_linkrate);	child->pathways = min(child->pathways, parent->pathways);}",25342
64,270,CVE-2019-16995,7,"static int hsr_dev_xmit(struct sk_buff *skb, struct net_device *dev){	struct hsr_priv *hsr = netdev_priv(dev);	struct hsr_port *master;	master = hsr_port_get_hsr(hsr, HSR_PT_MASTER);	skb->dev = master->dev;	hsr_forward_skb(skb, master);	return NETDEV_TX_OK;}",26444
50,122,CVE-2017-5993,7,"static void blitter_set_texcoords(struct vrend_blitter_ctx *blit_ctx,                                  struct vrend_resource *src_res,                                  int level,                                  float layer, unsigned sample,                                  int x1, int y1, int x2, int y2){   float coord[4];   float face_coord[4][2];   int i;   get_texcoords(src_res, level, x1, y1, x2, y2, coord);   if (src_res->base.target == PIPE_TEXTURE_CUBE ||       src_res->base.target == PIPE_TEXTURE_CUBE_ARRAY) {      set_texcoords_in_vertices(coord, &face_coord[0][0], 2);      util_map_texcoords2d_onto_cubemap((unsigned)layer % 6,                                                                                 &face_coord[0][0], 2,                                        &blit_ctx->vertices[0][1][0], 8,                                        FALSE);   } else {      set_texcoords_in_vertices(coord, &blit_ctx->vertices[0][1][0], 8);   }   switch (src_res->base.target) {   case PIPE_TEXTURE_3D:   {      float r = layer / (float)u_minify(src_res->base.depth0,                                        level);      for (i = 0; i < 4; i++)         blit_ctx->vertices[i][1][2] = r;     }   break;   case PIPE_TEXTURE_1D_ARRAY:      for (i = 0; i < 4; i++)         blit_ctx->vertices[i][1][1] = (float) layer;        break;   case PIPE_TEXTURE_2D_ARRAY:      for (i = 0; i < 4; i++) {         blit_ctx->vertices[i][1][2] = (float) layer;            blit_ctx->vertices[i][1][3] = (float) sample;        }      break;   case PIPE_TEXTURE_CUBE_ARRAY:      for (i = 0; i < 4; i++)         blit_ctx->vertices[i][1][3] = (float) ((unsigned)layer / 6);        break;   case PIPE_TEXTURE_2D:      for (i = 0; i < 4; i++) {         blit_ctx->vertices[i][1][3] = (float) sample;        }      break;   default:;   }}",1610
26,166,CVE-2018-8087,7,"static int hwsim_chans_compat(struct ieee80211_channel *c1,			       struct ieee80211_channel *c2){	if (!c1 || !c2)		return false;	return c1->center_freq == c2->center_freq;}",25288
44,161,CVE-2017-10810,7,"int virtio_gpu_object_get_sg_table(struct virtio_gpu_device *qdev,				   struct virtio_gpu_object *bo){	int ret;	struct page **pages = bo->tbo.ttm->pages;	int nr_pages = bo->tbo.num_pages;	 	if (bo->pages)		return 0;	if (bo->tbo.ttm->state == tt_unpopulated)		bo->tbo.ttm->bdev->driver->ttm_tt_populate(bo->tbo.ttm);	bo->pages = kmalloc(sizeof(struct sg_table), GFP_KERNEL);	if (!bo->pages)		goto out;	ret = sg_alloc_table_from_pages(bo->pages, pages, nr_pages, 0,					nr_pages << PAGE_SHIFT, GFP_KERNEL);	if (ret)		goto out;	return 0;out:	kfree(bo->pages);	bo->pages = NULL;	return -ENOMEM;}",20603
65,156,CVE-2017-12190,7,"void generic_start_io_acct(struct request_queue *q, int rw,			   unsigned long sectors, struct hd_struct *part){	int cpu = part_stat_lock();	part_round_stats(q, cpu, part);	part_stat_inc(cpu, part, ios[rw]);	part_stat_add(cpu, part, sectors[rw], sectors);	part_inc_in_flight(q, part, rw);	part_stat_unlock();}",20329
59,210,CVE-2018-7757,7,int sas_discover_root_expander(struct domain_device *dev){	int res;	struct sas_expander_device *ex = rphy_to_expander_device(dev->rphy);	res = sas_rphy_add(dev->rphy);	if (res)		goto out_err;	ex->level = dev->port->disc.max_level;  	res = sas_discover_expander(dev);	if (res)		goto out_err2;	sas_ex_bfs_disc(dev->port);	return res;out_err2:	sas_rphy_remove(dev->rphy);out_err:	return res;},25335
68,51,CVE-2017-6386,7,"static void vrend_destroy_streamout_object(struct vrend_streamout_object *obj){   int i;   list_del(&obj->head);   for (i = 0; i < obj->num_targets; i++)      vrend_so_target_reference(&obj->so_targets[i], NULL);   if (vrend_state.have_tf2)      glDeleteTransformFeedbacks(1, &obj->id);   FREE(obj);}",1463
71,70,CVE-2017-6386,7,"static void vrend_hw_emit_rs(struct vrend_context *ctx){   struct pipe_rasterizer_state *state = &ctx->sub->rs_state;   int i;   if (state->depth_clip) {      glDisable(GL_DEPTH_CLAMP);   } else {      glEnable(GL_DEPTH_CLAMP);   }   if (state->point_size_per_vertex) {      glEnable(GL_PROGRAM_POINT_SIZE);   } else {      glDisable(GL_PROGRAM_POINT_SIZE);      if (state->point_size)         glPointSize(state->point_size);   }   if (state->rasterizer_discard != ctx->sub->hw_rs_state.rasterizer_discard) {      ctx->sub->hw_rs_state.rasterizer_discard = state->rasterizer_discard;      if (state->rasterizer_discard)         glEnable(GL_RASTERIZER_DISCARD);      else         glDisable(GL_RASTERIZER_DISCARD);   }   if (vrend_state.use_core_profile == false) {      glPolygonMode(GL_FRONT, translate_fill(state->fill_front));      glPolygonMode(GL_BACK, translate_fill(state->fill_back));   } else if (state->fill_front == state->fill_back) {      glPolygonMode(GL_FRONT_AND_BACK, translate_fill(state->fill_front));   } else      report_core_warn(ctx, CORE_PROFILE_WARN_POLYGON_MODE, 0);   if (state->offset_tri)      glEnable(GL_POLYGON_OFFSET_FILL);   else      glDisable(GL_POLYGON_OFFSET_FILL);   if (state->offset_line)      glEnable(GL_POLYGON_OFFSET_LINE);   else      glDisable(GL_POLYGON_OFFSET_LINE);   if (state->offset_point)      glEnable(GL_POLYGON_OFFSET_POINT);   else      glDisable(GL_POLYGON_OFFSET_POINT);   if (state->flatshade != ctx->sub->hw_rs_state.flatshade) {      ctx->sub->hw_rs_state.flatshade = state->flatshade;      if (vrend_state.use_core_profile == false) {         if (state->flatshade) {            glShadeModel(GL_FLAT);         } else {            glShadeModel(GL_SMOOTH);         }      }   }   if (state->flatshade_first != ctx->sub->hw_rs_state.flatshade_first) {      ctx->sub->hw_rs_state.flatshade_first = state->flatshade_first;      if (state->flatshade_first)         glProvokingVertexEXT(GL_FIRST_VERTEX_CONVENTION_EXT);      else         glProvokingVertexEXT(GL_LAST_VERTEX_CONVENTION_EXT);   }   glPolygonOffset(state->offset_scale, state->offset_units);   if (vrend_state.use_core_profile == false) {      if (state->poly_stipple_enable)         glEnable(GL_POLYGON_STIPPLE);      else         glDisable(GL_POLYGON_STIPPLE);   } else if (state->poly_stipple_enable) {      if (!ctx->pstip_inited)         vrend_init_pstipple_texture(ctx);   }   if (state->point_quad_rasterization) {      if (vrend_state.use_core_profile == false)         glEnable(GL_POINT_SPRITE);      glPointParameteri(GL_POINT_SPRITE_COORD_ORIGIN, state->sprite_coord_mode ? GL_UPPER_LEFT : GL_LOWER_LEFT);   } else {      if (vrend_state.use_core_profile == false)         glDisable(GL_POINT_SPRITE);   }   if (state->cull_face != PIPE_FACE_NONE) {      switch (state->cull_face) {      case PIPE_FACE_FRONT:         glCullFace(GL_FRONT);         break;      case PIPE_FACE_BACK:         glCullFace(GL_BACK);         break;      case PIPE_FACE_FRONT_AND_BACK:         glCullFace(GL_FRONT_AND_BACK);         break;      default:         fprintf(stderr, ""unhandled cull-face: %x\n"", state->cull_face);      }      glEnable(GL_CULL_FACE);   } else      glDisable(GL_CULL_FACE);       if (vrend_state.use_core_profile == false) {      if (state->light_twoside)         glEnable(GL_VERTEX_PROGRAM_TWO_SIDE);      else         glDisable(GL_VERTEX_PROGRAM_TWO_SIDE);   }   if (state->clip_plane_enable != ctx->sub->hw_rs_state.clip_plane_enable) {      ctx->sub->hw_rs_state.clip_plane_enable = state->clip_plane_enable;      for (i = 0; i < 8; i++) {         if (state->clip_plane_enable & (1 << i))            glEnable(GL_CLIP_PLANE0 + i);         else            glDisable(GL_CLIP_PLANE0 + i);      }   }   if (vrend_state.use_core_profile == false) {      glLineStipple(state->line_stipple_factor, state->line_stipple_pattern);      if (state->line_stipple_enable)         glEnable(GL_LINE_STIPPLE);      else         glDisable(GL_LINE_STIPPLE);   } else if (state->line_stipple_enable)      report_core_warn(ctx, CORE_PROFILE_WARN_STIPPLE, 0);   if (state->line_smooth)      glEnable(GL_LINE_SMOOTH);   else      glDisable(GL_LINE_SMOOTH);   if (state->poly_smooth)      glEnable(GL_POLYGON_SMOOTH);   else      glDisable(GL_POLYGON_SMOOTH);   if (vrend_state.use_core_profile == false) {      if (state->clamp_vertex_color)         glClampColor(GL_CLAMP_VERTEX_COLOR_ARB, GL_TRUE);      else         glClampColor(GL_CLAMP_VERTEX_COLOR_ARB, GL_FALSE);      if (state->clamp_fragment_color)         glClampColor(GL_CLAMP_FRAGMENT_COLOR_ARB, GL_TRUE);      else         glClampColor(GL_CLAMP_FRAGMENT_COLOR_ARB, GL_FALSE);   } else {      if (state->clamp_vertex_color || state->clamp_fragment_color)         report_core_warn(ctx, CORE_PROFILE_WARN_CLAMP, 0);   }   if (vrend_state.have_multisample) {      if (state->multisample) {         glEnable(GL_MULTISAMPLE);         glEnable(GL_SAMPLE_MASK);      } else {         glDisable(GL_MULTISAMPLE);         glDisable(GL_SAMPLE_MASK);      }   }}",1482
67,60,CVE-2017-6386,7,"static void vrend_finish_context_switch(struct vrend_context *ctx){   if (ctx->ctx_switch_pending == false)      return;   ctx->ctx_switch_pending = false;   if (vrend_state.current_hw_ctx == ctx)      return;   vrend_state.current_hw_ctx = ctx;   vrend_clicbs->make_current(0, ctx->sub->gl_context);}",1472
49,175,CVE-2018-8087,7,"static void hwsim_mcast_del_radio(int id, const char *hwname,				  struct genl_info *info){	struct sk_buff *skb;	void *data;	int ret;	skb = genlmsg_new(GENLMSG_DEFAULT_SIZE, GFP_KERNEL);	if (!skb)		return;	data = genlmsg_put(skb, 0, 0, &hwsim_genl_family, 0,			   HWSIM_CMD_DEL_RADIO);	if (!data)		goto error;	ret = nla_put_u32(skb, HWSIM_ATTR_RADIO_ID, id);	if (ret < 0)		goto error;	ret = nla_put(skb, HWSIM_ATTR_RADIO_NAME, strlen(hwname),		      hwname);	if (ret < 0)		goto error;	genlmsg_end(skb, data);	hwsim_mcast_config_msg(skb, info);	return;error:	nlmsg_free(skb);}",25297
24,287,CVE-2019-16994,7,"static int ipip_rcv(struct sk_buff *skb){	return sit_tunnel_rcv(skb, IPPROTO_IPIP);}",26461
11,212,CVE-2018-7757,7,"static void sas_ex_disable_phy(struct domain_device *dev, int phy_id){	struct expander_device *ex = &dev->ex_dev;	struct ex_phy *phy = &ex->ex_phy[phy_id];	sas_smp_phy_control(dev, phy_id, PHY_FUNC_DISABLE, NULL);	phy->linkrate = SAS_PHY_DISABLED;}",25337
20,100,CVE-2017-6386,7,"int vrend_renderer_resource_get_info(int res_handle,                                     struct vrend_renderer_resource_info *info){   struct vrend_resource *res;   int elsize;   if (!info)      return EINVAL;   res = vrend_resource_lookup(res_handle, 0);   if (!res)      return EINVAL;   elsize = util_format_get_blocksize(res->base.format);   info->handle = res_handle;   info->tex_id = res->id;   info->width = res->base.width0;   info->height = res->base.height0;   info->depth = res->base.depth0;   info->format = res->base.format;   info->flags = res->y_0_top ? VIRGL_RESOURCE_Y_0_TOP : 0;   info->stride = util_format_get_nblocksx(res->base.format, u_minify(res->base.width0, 0)) * elsize;   return 0;}",1512
55,24,CVE-2017-6386,7,"static void read_transfer_data(struct pipe_resource *res,                               struct iovec *iov,                               unsigned int num_iovs,                               char *data,                               int src_stride,                               struct pipe_box *box,                               int offset, int invert){   int blsize = util_format_get_blocksize(res->format);   int size = vrend_get_iovec_size(iov, num_iovs);   int send_size = util_format_get_nblocks(res->format, box->width,                                              box->height) * blsize * box->depth;   int bwx = util_format_get_nblocksx(res->format, box->width) * blsize;   int bh = util_format_get_nblocksy(res->format, box->height);   int h;   int myoffset = offset;   if ((send_size == size || bh == 1) && !invert)      vrend_read_from_iovec(iov, num_iovs, offset, data, send_size);   else {      if (invert) {         for (h = bh - 1; h >= 0; h--) {            void *ptr = data + (h * bwx);            vrend_read_from_iovec(iov, num_iovs, myoffset, ptr, bwx);            myoffset += src_stride;         }      } else {         for (h = 0; h < bh; h++) {            void *ptr = data + (h * bwx);            vrend_read_from_iovec(iov, num_iovs, myoffset, ptr, bwx);            myoffset += src_stride;         }      }   }}",1436
13,54,CVE-2017-6386,7,"static void vrend_destroy_vertex_elements_object(void *obj_ptr){   struct vrend_vertex_element_array *v = obj_ptr;   if (vrend_state.have_vertex_attrib_binding) {      glDeleteVertexArrays(1, &v->id);   }   FREE(v);}",1466
15,275,CVE-2019-16995,7,"static struct hsr_port *get_late_port(struct hsr_priv *hsr,				      struct hsr_node *node){	if (node->time_in_stale[HSR_PT_SLAVE_A])		return hsr_port_get_hsr(hsr, HSR_PT_SLAVE_A);	if (node->time_in_stale[HSR_PT_SLAVE_B])		return hsr_port_get_hsr(hsr, HSR_PT_SLAVE_B);	if (time_after(node->time_in[HSR_PT_SLAVE_B],		       node->time_in[HSR_PT_SLAVE_A] +					msecs_to_jiffies(MAX_SLAVE_DIFF)))		return hsr_port_get_hsr(hsr, HSR_PT_SLAVE_A);	if (time_after(node->time_in[HSR_PT_SLAVE_A],		       node->time_in[HSR_PT_SLAVE_B] +					msecs_to_jiffies(MAX_SLAVE_DIFF)))		return hsr_port_get_hsr(hsr, HSR_PT_SLAVE_B);	return NULL;}",26449
12,127,CVE-2017-12190,7,static struct bio *__bio_chain_endio(struct bio *bio){	struct bio *parent = bio->bi_private;	if (!parent->bi_status)		parent->bi_status = bio->bi_status;	bio_put(bio);	return parent;},20300
18,281,CVE-2019-16994,7,"static int ipip6_netlink_6rd_parms(struct nlattr *data[],				    struct ip_tunnel_6rd *ip6rd){	int ret = false;	memset(ip6rd, 0, sizeof(*ip6rd));	if (!data)		return ret;	if (data[IFLA_IPTUN_6RD_PREFIX]) {		ret = true;		ip6rd->prefix = nla_get_in6_addr(data[IFLA_IPTUN_6RD_PREFIX]);	}	if (data[IFLA_IPTUN_6RD_RELAY_PREFIX]) {		ret = true;		ip6rd->relay_prefix =			nla_get_be32(data[IFLA_IPTUN_6RD_RELAY_PREFIX]);	}	if (data[IFLA_IPTUN_6RD_PREFIXLEN]) {		ret = true;		ip6rd->prefixlen = nla_get_u16(data[IFLA_IPTUN_6RD_PREFIXLEN]);	}	if (data[IFLA_IPTUN_6RD_RELAY_PREFIXLEN]) {		ret = true;		ip6rd->relay_prefixlen =			nla_get_u16(data[IFLA_IPTUN_6RD_RELAY_PREFIXLEN]);	}	return ret;}",26455
5,93,CVE-2017-6386,7,"void vrend_renderer_get_rect(int res_handle, struct iovec *iov, unsigned int num_iovs,                             int offset, int x, int y, int width, int height){   struct vrend_resource *res = vrend_resource_lookup(res_handle, 0);   struct vrend_transfer_info transfer_info;   struct pipe_box box;   int elsize;   memset(&transfer_info, 0, sizeof(transfer_info));   elsize = util_format_get_blocksize(res->base.format);   box.x = x;   box.y = y;   box.z = 0;   box.width = width;   box.height = height;   box.depth = 1;   transfer_info.box = &box;   transfer_info.stride = util_format_get_nblocksx(res->base.format, res->base.width0) * elsize;   transfer_info.offset = offset;   transfer_info.handle = res->handle;   transfer_info.iovec = iov;   transfer_info.iovec_cnt = num_iovs;   vrend_renderer_transfer_iov(&transfer_info, VREND_TRANSFER_READ);}",1505
39,262,CVE-2019-17178,7,"static unsigned update_adler32(unsigned adler, const unsigned char* data, unsigned len){   unsigned s1 = adler & 0xffff;   unsigned s2 = (adler >> 16) & 0xffff;  while(len > 0)  {         unsigned amount = len > 5550 ? 5550 : len;    len -= amount;    while(amount > 0)    {      s1 += (*data++);      s2 += s1;      amount--;    }    s1 %= 65521;    s2 %= 65521;  }  return (s2 << 16) | s1;}",26435
40,126,CVE-2017-12664,7,static inline double MagickRound(double x){     if ((x-floor(x)) < (ceil(x)-x))    return(floor(x));  return(ceil(x));},20299
46,42,CVE-2017-6386,7,static void vrend_destroy_program(struct vrend_linked_shader_program *ent){   int i;   glDeleteProgram(ent->id);   list_del(&ent->head);   for (i = PIPE_SHADER_VERTEX; i <= PIPE_SHADER_GEOMETRY; i++) {      if (ent->ss[i])         list_del(&ent->sl[i]);      free(ent->shadow_samp_mask_locs[i]);      free(ent->shadow_samp_add_locs[i]);      free(ent->samp_locs[i]);      free(ent->const_locs[i]);      free(ent->ubo_locs[i]);   }   free(ent->attrib_locs);   free(ent);},1454
16,107,CVE-2017-6386,7,"vrend_sampler_view_reference(struct vrend_sampler_view **ptr, struct vrend_sampler_view *view){   struct vrend_sampler_view *old_view = *ptr;   if (pipe_reference(&(*ptr)->reference, &view->reference))      vrend_destroy_sampler_view(old_view);   *ptr = view;}",1519
33,79,CVE-2017-6386,7,"void vrend_object_bind_dsa(struct vrend_context *ctx,                           int handle){   struct pipe_depth_stencil_alpha_state *state;   if (handle == 0) {      memset(&ctx->sub->dsa_state, 0, sizeof(ctx->sub->dsa_state));      ctx->sub->dsa = NULL;      ctx->sub->stencil_state_dirty = true;      ctx->sub->shader_dirty = true;      vrend_hw_emit_dsa(ctx);      return;   }   state = vrend_object_lookup(ctx->sub->object_hash, handle, VIRGL_OBJECT_DSA);   if (!state) {      report_context_error(ctx, VIRGL_ERROR_CTX_ILLEGAL_HANDLE, handle);      return;   }   if (ctx->sub->dsa != state) {      ctx->sub->stencil_state_dirty = true;      ctx->sub->shader_dirty = true;   }   ctx->sub->dsa_state = *state;   ctx->sub->dsa = state;   vrend_hw_emit_dsa(ctx);}",1491
14,199,CVE-2018-8087,7,"static int mac80211_hwsim_start(struct ieee80211_hw *hw){	struct mac80211_hwsim_data *data = hw->priv;	wiphy_dbg(hw->wiphy, ""%s\n"", __func__);	data->started = true;	return 0;}",25321
28,57,CVE-2017-6386,7,"static void vrend_draw_bind_vertex_binding(struct vrend_context *ctx,                                           struct vrend_vertex_element_array *va){   int i;   glBindVertexArray(va->id);   if (ctx->sub->vbo_dirty) {      for (i = 0; i < ctx->sub->num_vbos; i++) {         struct vrend_resource *res = (struct vrend_resource *)ctx->sub->vbo[i].buffer;         if (!res)            glBindVertexBuffer(i, 0, 0, 0);         else            glBindVertexBuffer(i,                               res->id,                               ctx->sub->vbo[i].buffer_offset,                               ctx->sub->vbo[i].stride);      }      for (i = ctx->sub->num_vbos; i < ctx->sub->old_num_vbos; i++) {         glBindVertexBuffer(i, 0, 0, 0);      }      ctx->sub->vbo_dirty = false;   }}",1469
31,38,CVE-2017-6386,7,"static void *vrend_create_shader_state(struct vrend_context *ctx,                                       const struct pipe_stream_output_info *so_info,                                       unsigned pipe_shader_type){   struct vrend_shader_selector *sel = CALLOC_STRUCT(vrend_shader_selector);   if (!sel)      return NULL;   sel->type = pipe_shader_type;   sel->sinfo.so_info = *so_info;   pipe_reference_init(&sel->reference, 1);   return sel;}",1450
60,69,CVE-2017-6386,7,"static void vrend_hw_emit_dsa(struct vrend_context *ctx){   struct pipe_depth_stencil_alpha_state *state = &ctx->sub->dsa_state;   if (state->depth.enabled) {      vrend_depth_test_enable(ctx, true);      glDepthFunc(GL_NEVER + state->depth.func);      if (state->depth.writemask)         glDepthMask(GL_TRUE);      else         glDepthMask(GL_FALSE);   } else      vrend_depth_test_enable(ctx, false);   if (state->alpha.enabled) {      vrend_alpha_test_enable(ctx, true);      if (!vrend_state.use_core_profile)         glAlphaFunc(GL_NEVER + state->alpha.func, state->alpha.ref_value);   } else      vrend_alpha_test_enable(ctx, false);}",1481
51,174,CVE-2018-8087,7,"static void hwsim_mcast_config_msg(struct sk_buff *mcast_skb,				   struct genl_info *info){	if (info)		genl_notify(&hwsim_genl_family, mcast_skb, info,			    HWSIM_MCGRP_CONFIG, GFP_KERNEL);	else		genlmsg_multicast(&hwsim_genl_family, mcast_skb, 0,				  HWSIM_MCGRP_CONFIG, GFP_KERNEL);}",25296
61,46,CVE-2017-6386,7,"static void vrend_destroy_sampler_view(struct vrend_sampler_view *samp){   vrend_resource_reference(&samp->texture, NULL);   free(samp);}",1458
36,34,CVE-2017-6386,7,"int vrend_create_query(struct vrend_context *ctx, int handle,                       int query_type, int query_index,                       int res_handle, int offset){   struct vrend_query *q;   struct vrend_resource *res;   int ret_handle;   res = vrend_renderer_ctx_res_lookup(ctx, res_handle);   if (!res) {      report_context_error(ctx, VIRGL_ERROR_CTX_ILLEGAL_RESOURCE, res_handle);      return EINVAL;   }   q = CALLOC_STRUCT(vrend_query);   if (!q)      return ENOMEM;   list_inithead(&q->waiting_queries);   q->type = query_type;   q->index = query_index;   q->ctx_id = ctx->ctx_id;   vrend_resource_reference(&q->res, res);   switch (q->type) {   case PIPE_QUERY_OCCLUSION_COUNTER:      q->gltype = GL_SAMPLES_PASSED_ARB;      break;   case PIPE_QUERY_OCCLUSION_PREDICATE:      q->gltype = GL_ANY_SAMPLES_PASSED;      break;   case PIPE_QUERY_TIMESTAMP:      q->gltype = GL_TIMESTAMP;      break;   case PIPE_QUERY_TIME_ELAPSED:      q->gltype = GL_TIME_ELAPSED;      break;   case PIPE_QUERY_PRIMITIVES_GENERATED:      q->gltype = GL_PRIMITIVES_GENERATED;      break;   case PIPE_QUERY_PRIMITIVES_EMITTED:      q->gltype = GL_TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN;      break;   default:      fprintf(stderr,""unknown query object received %d\n"", q->type);      break;   }   glGenQueries(1, &q->id);   ret_handle = vrend_renderer_object_insert(ctx, q, sizeof(struct vrend_query), handle,                                             VIRGL_OBJECT_QUERY);   if (!ret_handle) {      FREE(q);      return ENOMEM;   }   return 0;}",1446
70,91,CVE-2017-6386,7,"void vrend_renderer_get_cap_set(int cap_set, int *max_ver,                                int *max_size){   if (cap_set != VREND_CAP_SET) {      *max_ver = 0;      *max_size = 0;      return;   }   *max_ver = 1;   *max_size = sizeof(union virgl_caps);}",1503
62,63,CVE-2017-6386,7,static inline int vrend_format_can_sample(enum virgl_formats format){   return tex_conv_table[format].bindings & VREND_BIND_SAMPLER;},1475
30,155,CVE-2017-12190,7,"void generic_end_io_acct(struct request_queue *q, int rw,			 struct hd_struct *part, unsigned long start_time){	unsigned long duration = jiffies - start_time;	int cpu = part_stat_lock();	part_stat_add(cpu, part, ticks[rw], duration);	part_round_stats(q, cpu, part);	part_dec_in_flight(q, part, rw);	part_stat_unlock();}",20328
45,103,CVE-2017-6386,7,"static void vrend_renderer_use_threaded_sync(void){   struct virgl_gl_ctx_param ctx_params;   if (getenv(""VIRGL_DISABLE_MT""))      return;   ctx_params.shared = true;   ctx_params.major_ver = vrend_state.gl_major_ver;   ctx_params.minor_ver = vrend_state.gl_minor_ver;   vrend_state.stop_sync_thread = false;   vrend_state.sync_context = vrend_clicbs->create_gl_context(0, &ctx_params);   if (vrend_state.sync_context == NULL) {      fprintf(stderr, ""failed to create sync opengl context\n"");      return;   }   vrend_state.eventfd = eventfd(0, EFD_CLOEXEC | EFD_NONBLOCK);   if (vrend_state.eventfd == -1) {      fprintf(stderr, ""Failed to create eventfd\n"");      vrend_clicbs->destroy_gl_context(vrend_state.sync_context);      return;   }   pipe_condvar_init(vrend_state.fence_cond);   pipe_mutex_init(vrend_state.fence_mutex);   vrend_state.sync_thread = pipe_thread_create(thread_sync, NULL);   if (!vrend_state.sync_thread) {      close(vrend_state.eventfd);      vrend_state.eventfd = -1;      vrend_clicbs->destroy_gl_context(vrend_state.sync_context);      pipe_condvar_destroy(vrend_state.fence_cond);      pipe_mutex_destroy(vrend_state.fence_mutex);   }}",1515
2,133,CVE-2017-12190,7,"int bio_associate_current(struct bio *bio){	struct io_context *ioc;	if (bio->bi_css)		return -EBUSY;	ioc = current->io_context;	if (!ioc)		return -ENOENT;	get_io_context_active(ioc);	bio->bi_ioc = ioc;	bio->bi_css = task_get_css(current, io_cgrp_id);	return 0;}",20306
636,2044,CVE-2014-9644,25,static void free(struct crypto_instance *inst){	crypto_drop_spawn(crypto_instance_ctx(inst));	kfree(inst);},14378
641,2382,CVE-2013-7421,25,"static int deflate_decomp_init(struct deflate_ctx *ctx){	int ret = 0;	struct z_stream_s *stream = &ctx->decomp_stream;	stream->workspace = vzalloc(zlib_inflate_workspacesize());	if (!stream->workspace) {		ret = -ENOMEM;		goto out;	}	ret = zlib_inflateInit2(stream, -DEFLATE_DEF_WINBITS);	if (ret != Z_OK) {		ret = -EINVAL;		goto out_free;	}out:	return ret;out_free:	vfree(stream->workspace);	goto out;}",14812
251,2493,CVE-2013-7421,25,static void ap_device_release(struct device *dev){	struct ap_device *ap_dev = to_ap_dev(dev);	kfree(ap_dev);},14923
171,1479,CVE-2014-3610,25,static int pause_interception(struct vcpu_svm *svm){	kvm_vcpu_on_spin(&(svm->vcpu));	return 1;},11341
629,542,CVE-2011-4112,25,static int bond_should_change_active(struct bonding *bond){	struct slave *prim = bond->primary_slave;	struct slave *curr = bond->curr_active_slave;	if (!prim || !curr || curr->link != BOND_LINK_UP)		return true;	if (bond->force_primary) {		bond->force_primary = false;		return true;	}	if (bond->params.primary_reselect == BOND_PRI_RESELECT_BETTER &&	    (prim->speed < curr->speed ||	     (prim->speed == curr->speed && prim->duplex <= curr->duplex)))		return false;	if (bond->params.primary_reselect == BOND_PRI_RESELECT_FAILURE)		return false;	return true;},5267
126,1666,CVE-2014-1738,25,"static void floppy_release_regions(int fdc){	floppy_release_allocated_regions(fdc, ARRAY_END(io_regions));}",11959
154,2857,CVE-2014-9922,25,int ovl_want_write(struct dentry *dentry){	struct ovl_fs *ofs = dentry->d_sb->s_fs_info;	return mnt_want_write(ofs->upper_mnt);},23091
132,1403,CVE-2014-4014,25,"void lock_two_nondirectories(struct inode *inode1, struct inode *inode2){	if (inode1 > inode2)		swap(inode1, inode2);	if (inode1 && !S_ISDIR(inode1->i_mode))		mutex_lock(&inode1->i_mutex);	if (inode2 && !S_ISDIR(inode2->i_mode) && inode2 != inode1)		mutex_lock_nested(&inode2->i_mutex, I_MUTEX_NONDIR2);}",10949
244,2248,CVE-2013-7421,25,"static int cbc_des_encrypt(struct blkcipher_desc *desc,			   struct scatterlist *dst, struct scatterlist *src,			   unsigned int nbytes){	struct blkcipher_walk walk;	blkcipher_walk_init(&walk, dst, src, nbytes);	return cbc_desall_crypt(desc, KMC_DEA_ENCRYPT, &walk);}",14678
580,1092,CVE-2013-1957,25,int mnt_want_write_file(struct file *file){	int ret;	sb_start_write(file->f_path.mnt->mnt_sb);	ret = __mnt_want_write_file(file);	if (ret)		sb_end_write(file->f_path.mnt->mnt_sb);	return ret;},9173
72,1183,CVE-2011-4347,25,"static int assigned_device_enable_guest_msi(struct kvm *kvm,			struct kvm_assigned_dev_kernel *dev,			struct kvm_assigned_irq *irq){	dev->guest_irq = irq->guest_irq;	dev->ack_notifier.gsi = -1;	dev->host_irq_disabled = false;	return 0;}",10042
480,907,CVE-2011-2211,25,SYSCALL_DEFINE0(getpagesize){	return PAGE_SIZE;},6717
393,48,CVE-2015-5352,25,enter_non_blocking(void){	in_non_blocking_mode = 1;	set_nonblock(fileno(stdin));},448
66,2105,CVE-2014-9644,25,static void vmac_exit_tfm(struct crypto_tfm *tfm){	struct vmac_ctx_t *ctx = crypto_tfm_ctx(tfm);	crypto_free_cipher(ctx->child);},14439
284,2862,CVE-2019-13272,25,"void __ptrace_link(struct task_struct *child, struct task_struct *new_parent,		   const struct cred *ptracer_cred){	BUG_ON(!list_empty(&child->ptrace_entry));	list_add(&child->ptrace_entry, &new_parent->ptraced);	child->parent = new_parent;	child->ptracer_cred = get_cred(ptracer_cred);}",26722
101,1715,CVE-2014-1738,25,"static int transfer_size(int ssize, int max_sector, int max_size){	SUPBOUND(max_sector, fsector_t + max_size);	 	max_sector -= (max_sector % _floppy->sect) % ssize;	 	current_count_sectors = max_sector - fsector_t;	return max_sector;}",12008
385,1563,CVE-2014-3534,25,"void ptrace_disable(struct task_struct *task){	memset(&task->thread.per_user, 0, sizeof(task->thread.per_user));	memset(&task->thread.per_event, 0, sizeof(task->thread.per_event));	clear_tsk_thread_flag(task, TIF_SINGLE_STEP);	clear_pt_regs_flag(task_pt_regs(task), PIF_PER_TRAP);	task->thread.per_flags = 0;}",11452
58,2259,CVE-2013-7421,25,static int sha1_init(struct shash_desc *desc){	struct s390_sha_ctx *sctx = shash_desc_ctx(desc);	sctx->state[0] = SHA1_H0;	sctx->state[1] = SHA1_H1;	sctx->state[2] = SHA1_H2;	sctx->state[3] = SHA1_H3;	sctx->state[4] = SHA1_H4;	sctx->count = 0;	sctx->func = KIMD_SHA_1;	return 0;},14689
492,1764,CVE-2015-2150,25,"static void bar_reset(struct pci_dev *dev, int offset, void *data){	struct pci_bar_info *bar = data;	bar->which = 0;}",13765
313,617,CVE-2011-4112,25,"static int veth_change_mtu(struct net_device *dev, int new_mtu){	if (!is_valid_veth_mtu(new_mtu))		return -EINVAL;	dev->mtu = new_mtu;	return 0;}",5342
535,876,CVE-2011-2486,25,"static int do_help(const char *prog){  printf(""%s, NPAPI plugin viewer. Version %s\n"", NPW_VIEWER, NPW_VERSION);  printf(""\n"");  printf(""usage: %s [GTK flags] [flags]\n"", prog);  printf(""   -h --help               print this message\n"");  printf(""   -t --test               check plugin is compatible\n"");  printf(""   -i --info               print plugin information\n"");  printf(""   -p --plugin             set plugin path\n"");  printf(""   -c --connection         set connection path\n"");  return 0;}",6686
402,2079,CVE-2014-9644,25,"static void pcrypt_aead_done(struct crypto_async_request *areq, int err){	struct aead_request *req = areq->data;	struct pcrypt_request *preq = aead_request_ctx(req);	struct padata_priv *padata = pcrypt_request_padata(preq);	padata->info = err;	req->base.flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;	padata_do_serial(padata);}",14413
179,2391,CVE-2013-7421,25,static int md4_init(struct shash_desc *desc){	struct md4_ctx *mctx = shash_desc_ctx(desc);	mctx->hash[0] = 0x67452301;	mctx->hash[1] = 0xefcdab89;	mctx->hash[2] = 0x98badcfe;	mctx->hash[3] = 0x10325476;	mctx->byte_count = 0;	return 0;},14821
693,2885,CVE-2011-4127,25,"static unsigned int sd_check_events(struct gendisk *disk, unsigned int clearing){	struct scsi_disk *sdkp = scsi_disk(disk);	struct scsi_device *sdp = sdkp->device;	struct scsi_sense_hdr *sshdr = NULL;	int retval;	SCSI_LOG_HLQUEUE(3, sd_printk(KERN_INFO, sdkp, ""sd_check_events\n""));	 	if (!scsi_device_online(sdp)) {		set_media_not_present(sdkp);		goto out;	}	 	retval = -ENODEV;	if (scsi_block_when_processing_errors(sdp)) {		sshdr  = kzalloc(sizeof(*sshdr), GFP_KERNEL);		retval = scsi_test_unit_ready(sdp, SD_TIMEOUT, SD_MAX_RETRIES,					      sshdr);	}	 	if (host_byte(retval)) {		set_media_not_present(sdkp);		goto out;	}	if (media_not_present(sdkp, sshdr))		goto out;	 	if (!sdkp->media_present)		sdp->changed = 1;	sdkp->media_present = 1;out:	 	kfree(sshdr);	retval = sdp->changed ? DISK_EVENT_MEDIA_CHANGE : 0;	sdp->changed = 0;	return retval;}",28268
566,1713,CVE-2014-1738,25,"static int start_motor(void (*function)(void)){	int mask;	int data;	mask = 0xfc;	data = UNIT(current_drive);	if (!(raw_cmd->flags & FD_RAW_NO_MOTOR)) {		if (!(FDCS->dor & (0x10 << UNIT(current_drive)))) {			set_debugt();			 			DRS->first_read_date = 0;			 			DRS->spinup_date = jiffies;			data |= (0x10 << UNIT(current_drive));		}	} else if (FDCS->dor & (0x10 << UNIT(current_drive)))		mask &= ~(0x10 << UNIT(current_drive));	 	del_timer(motor_off_timer + current_drive);	set_dor(fdc, mask, data);	 	return fd_wait_for_completion(DRS->select_date + DP->select_delay,				      function);}",12006
205,1024,CVE-2013-2929,25,"static int ptrace_check_attach(struct task_struct *child, int ignore_state){	int ret = -ESRCH;	 	read_lock(&tasklist_lock);	if (child->ptrace && child->parent == current) {		WARN_ON(child->state == __TASK_TRACED);		 		if (ignore_state || ptrace_freeze_traced(child))			ret = 0;	}	read_unlock(&tasklist_lock);	if (!ret && !ignore_state) {		if (!wait_task_inactive(child, __TASK_TRACED)) {			 			WARN_ON(child->state == __TASK_TRACED);			ret = -ESRCH;		}	}	return ret;}",8478
539,148,CVE-2012-2121,25,"static int hardware_enable_all(void){	int r = 0;	raw_spin_lock(&kvm_lock);	kvm_usage_count++;	if (kvm_usage_count == 1) {		atomic_set(&hardware_enable_failed, 0);		on_each_cpu(hardware_enable_nolock, NULL, 1);		if (atomic_read(&hardware_enable_failed)) {			hardware_disable_all_nolock();			r = -EBUSY;		}	}	raw_spin_unlock(&kvm_lock);	return r;}",3546
82,45,CVE-2007-4849,25,"static void jffs2_iset_acl(struct inode *inode, struct posix_acl **i_acl, struct posix_acl *acl){	spin_lock(&inode->i_lock);	if (*i_acl != JFFS2_ACL_NOT_CACHED)		posix_acl_release(*i_acl);	*i_acl = posix_acl_dup(acl);        spin_unlock(&inode->i_lock); }",392
460,2858,CVE-2014-9922,25,struct dentry *ovl_workdir(struct dentry *dentry){	struct ovl_fs *ofs = dentry->d_sb->s_fs_info;	return ofs->workdir;},23092
197,243,CVE-2012-1179,25,"void mem_cgroup_commit_charge_swapin(struct page *page,				     struct mem_cgroup *memcg){	__mem_cgroup_commit_charge_swapin(page, memcg,					  MEM_CGROUP_CHARGE_TYPE_MAPPED);}",3901
515,1744,CVE-2015-6564,25,"monitor_child_handler(int sig){	kill(monitor_child_pid, sig);}",13106
120,2230,CVE-2013-7421,25,"static int ecb_aes_decrypt(struct blkcipher_desc *desc,			   struct scatterlist *dst, struct scatterlist *src,			   unsigned int nbytes){	struct s390_aes_ctx *sctx = crypto_blkcipher_ctx(desc->tfm);	struct blkcipher_walk walk;	if (unlikely(need_fallback(sctx->key_len)))		return fallback_blk_dec(desc, dst, src, nbytes);	blkcipher_walk_init(&walk, dst, src, nbytes);	return ecb_aes_crypt(desc, sctx->dec, sctx->key, &walk);}",14660
431,3017,CVE-2015-6640,25,"SYSCALL_DEFINE2(setreuid, uid_t, ruid, uid_t, euid){ const struct cred *old; struct cred *new; int retval; new = prepare_creds(); if (!new) return -ENOMEM;	old = current_cred();	retval = -EPERM; if (ruid != (uid_t) -1) { new->uid = ruid; if (old->uid != ruid &&		    old->euid != ruid && !nsown_capable(CAP_SETUID)) goto error; } if (euid != (uid_t) -1) { new->euid = euid; if (old->uid != euid &&		    old->euid != euid &&		    old->suid != euid && !nsown_capable(CAP_SETUID)) goto error; } if (new->uid != old->uid) {		retval = set_user(new); if (retval < 0) goto error; } if (ruid != (uid_t) -1 || (euid != (uid_t) -1 && euid != old->uid)) new->suid = new->euid; new->fsuid = new->euid;	retval = security_task_fix_setuid(new, old, LSM_SETID_RE); if (retval < 0) goto error; return commit_creds(new);error:	abort_creds(new); return retval;}",30705
569,644,CVE-2011-4112,25,"static int airo_set_nick(struct net_device *dev,			 struct iw_request_info *info,			 struct iw_point *dwrq,			 char *extra){	struct airo_info *local = dev->ml_priv;	 	if(dwrq->length > 16) {		return -E2BIG;	}	readConfigRid(local, 1);	memset(local->config.nodeName, 0, sizeof(local->config.nodeName));	memcpy(local->config.nodeName, extra, dwrq->length);	set_bit (FLAG_COMMIT, &local->flags);	return -EINPROGRESS;		 }",5369
23,2299,CVE-2013-7421,25,"static inline int cast5_fpu_begin(int fpu_enabled, unsigned int nbytes){	return glue_fpu_begin(CAST5_BLOCK_SIZE, CAST5_PARALLEL_BLOCKS,			      NULL, fpu_enabled, nbytes);}",14729
551,3078,CVE-2014-4014,25,"int generic_permission(struct inode *inode, int mask){	int ret;	 	ret = acl_permission_check(inode, mask);	if (ret != -EACCES)		return ret;  	if (S_ISDIR(inode->i_mode)) { 		 		if (inode_capable(inode, CAP_DAC_OVERRIDE)) 			return 0; 		if (!(mask & MAY_WRITE))			if (inode_capable(inode, CAP_DAC_READ_SEARCH)) 				return 0; 		return -EACCES; 	}	  	if (!(mask & MAY_EXEC) || (inode->i_mode & S_IXUGO))		if (inode_capable(inode, CAP_DAC_OVERRIDE)) 			return 0;  	  	mask &= MAY_READ | MAY_WRITE | MAY_EXEC; 	if (mask == MAY_READ)		if (inode_capable(inode, CAP_DAC_READ_SEARCH)) 			return 0;  	return -EACCES;}",31149
198,1316,CVE-2014-5207,25,static struct mountpoint *lock_mount(struct path *path){	struct vfsmount *mnt;	struct dentry *dentry = path->dentry;retry:	mutex_lock(&dentry->d_inode->i_mutex);	if (unlikely(cant_mount(dentry))) {		mutex_unlock(&dentry->d_inode->i_mutex);		return ERR_PTR(-ENOENT);	}	namespace_lock();	mnt = lookup_mnt(path);	if (likely(!mnt)) {		struct mountpoint *mp = new_mountpoint(dentry);		if (IS_ERR(mp)) {			namespace_unlock();			mutex_unlock(&dentry->d_inode->i_mutex);			return mp;		}		return mp;	}	namespace_unlock();	mutex_unlock(&path->dentry->d_inode->i_mutex);	path_put(path);	path->mnt = mnt;	dentry = path->dentry = dget(mnt->mnt_root);	goto retry;},10665
207,2397,CVE-2013-7421,25,"static int rmd160_init(struct shash_desc *desc){	struct rmd160_ctx *rctx = shash_desc_ctx(desc);	rctx->byte_count = 0;	rctx->state[0] = RMD_H0;	rctx->state[1] = RMD_H1;	rctx->state[2] = RMD_H2;	rctx->state[3] = RMD_H3;	rctx->state[4] = RMD_H4;	memset(rctx->buffer, 0, sizeof(rctx->buffer));	return 0;}",14827
96,351,CVE-2012-1179,25,"void tlb_table_flush(struct mmu_gather *tlb){	struct mmu_table_batch **batch = &tlb->batch;	if (*batch) {		call_rcu_sched(&(*batch)->rcu, tlb_remove_table_rcu);		*batch = NULL;	}}",4009
760,2830,CVE-2014-9922,25,struct dentry *ovl_dentry_lower(struct dentry *dentry){	struct ovl_entry *oe = dentry->d_fsdata;	return oe->lowerdentry;},23064
512,1517,CVE-2014-3610,25,"static int svm_hardware_enable(void){	struct svm_cpu_data *sd;	int efer;	struct desc_ptr gdt_descr;	struct desc_struct *gdt;	int me = raw_smp_processor_id();	rdmsrl(MSR_EFER, efer);	if (efer & EFER_SVME)		return -EBUSY;	if (!has_svm()) {		pr_err(""%s: err EOPNOTSUPP on %d\n"", __func__, me);		return -EINVAL;	}	sd = per_cpu(svm_data, me);	if (!sd) {		pr_err(""%s: svm_data is NULL on %d\n"", __func__, me);		return -EINVAL;	}	sd->asid_generation = 1;	sd->max_asid = cpuid_ebx(SVM_CPUID_FUNC) - 1;	sd->next_asid = sd->max_asid + 1;	native_store_gdt(&gdt_descr);	gdt = (struct desc_struct *)gdt_descr.address;	sd->tss_desc = (struct kvm_ldttss_desc *)(gdt + GDT_ENTRY_TSS);	wrmsrl(MSR_EFER, efer | EFER_SVME);	wrmsrl(MSR_VM_HSAVE_PA, page_to_pfn(sd->save_area) << PAGE_SHIFT);	if (static_cpu_has(X86_FEATURE_TSCRATEMSR)) {		wrmsrl(MSR_AMD64_TSC_RATIO, TSC_RATIO_DEFAULT);		__this_cpu_write(current_tsc_ratio, TSC_RATIO_DEFAULT);	}	 	if (cpu_has(&boot_cpu_data, X86_FEATURE_OSVW)) {		int len, status = 0;		int err;		len = native_read_msr_safe(MSR_AMD64_OSVW_ID_LENGTH, &err);		if (!err)			status = native_read_msr_safe(MSR_AMD64_OSVW_STATUS,						      &err);		if (err)			osvw_status = osvw_len = 0;		else {			if (len < osvw_len)				osvw_len = len;			osvw_status |= status;			osvw_status &= (1ULL << osvw_len) - 1;		}	} else		osvw_status = osvw_len = 0;	svm_init_erratum_383();	amd_pmu_enable_virt();	return 0;}",11379
195,1114,CVE-2013-1957,25,"static struct mount *get_peer_under_root(struct mount *mnt,					 struct mnt_namespace *ns,					 const struct path *root){	struct mount *m = mnt;	do {		 		if (m->mnt_ns == ns && is_path_reachable(m, m->mnt.mnt_root, root))			return m;		m = next_peer(m);	} while (m != mnt);	return NULL;}",9195
346,1039,CVE-2013-1957,25,int __mnt_want_write(struct vfsmount *m){	struct mount *mnt = real_mount(m);	int ret = 0;	preempt_disable();	mnt_inc_writers(mnt);	 	smp_mb();	while (ACCESS_ONCE(mnt->mnt.mnt_flags) & MNT_WRITE_HOLD)		cpu_relax();	 	smp_rmb();	if (mnt_is_readonly(m)) {		mnt_dec_writers(mnt);		ret = -EROFS;	}	preempt_enable();	return ret;},9120
611,1400,CVE-2014-4014,25,int inode_wait(void *word){	schedule();	return 0;},10946
564,308,CVE-2012-1179,25,"static int register_memsw_files(struct cgroup *cont, struct cgroup_subsys *ss){	if (!do_swap_account)		return 0;	return cgroup_add_files(cont, ss, memsw_cgroup_files,				ARRAY_SIZE(memsw_cgroup_files));};",3966
768,1993,CVE-2014-9644,25,"static void __gcm_hash_final_done(struct aead_request *req, int err){	struct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;	if (!err)		crypto_xor(pctx->auth_tag, pctx->iauth_tag, 16);	gctx->complete(req, err);}",14327
485,257,CVE-2012-1179,25,"int mem_cgroup_inactive_file_is_low(struct mem_cgroup *memcg, struct zone *zone){	unsigned long active;	unsigned long inactive;	int zid = zone_idx(zone);	int nid = zone_to_nid(zone);	inactive = mem_cgroup_zone_nr_lru_pages(memcg, nid, zid,						BIT(LRU_INACTIVE_FILE));	active = mem_cgroup_zone_nr_lru_pages(memcg, nid, zid,					      BIT(LRU_ACTIVE_FILE));	return (active > inactive);}",3915
177,688,CVE-2011-4112,25,"void ar6000_dtimexpiry_event(struct ar6_softc *ar){    int isMcastQueued = false;    struct sk_buff *skb = NULL;         if (ar->sta_list_index == 0) {        return;    }    A_MUTEX_LOCK(&ar->mcastpsqLock);    isMcastQueued = A_NETBUF_QUEUE_EMPTY(&ar->mcastpsq);    A_MUTEX_UNLOCK(&ar->mcastpsqLock);    A_ASSERT(isMcastQueued == false);              ar->DTIMExpired = true;    A_MUTEX_LOCK(&ar->mcastpsqLock);    while (!A_NETBUF_QUEUE_EMPTY(&ar->mcastpsq)) {        skb = A_NETBUF_DEQUEUE(&ar->mcastpsq);        A_MUTEX_UNLOCK(&ar->mcastpsqLock);        ar6000_data_tx(skb, ar->arNetDev);        A_MUTEX_LOCK(&ar->mcastpsqLock);    }    A_MUTEX_UNLOCK(&ar->mcastpsqLock);         ar->DTIMExpired = false;         wmi_set_pvb_cmd(ar->arWmi, MCAST_AID, 0);}",5413
309,911,CVE-2011-2211,25,"jiffies_to_timeval32(unsigned long jiffies, struct timeval32 *value){	value->tv_usec = (jiffies % HZ) * (1000000L / HZ);	value->tv_sec = jiffies / HZ;}",6721
473,1442,CVE-2014-3610,25,"static int emulate_on_interception(struct vcpu_svm *svm){	return emulate_instruction(&svm->vcpu, 0) == EMULATE_DONE;}",11304
487,12,CVE-2015-8467,25,"static int samldb_prim_group_change(struct samldb_ctx *ac){	struct ldb_context *ldb = ldb_module_get_ctx(ac->module);	const char * const attrs[] = {		""primaryGroupID"",		""memberOf"",		""userAccountControl"",		NULL };	struct ldb_result *res, *group_res;	struct ldb_message_element *el;	struct ldb_message *msg;	int prev_rid, new_rid, uac;	struct dom_sid *prev_sid, *new_sid;	struct ldb_dn *prev_prim_group_dn, *new_prim_group_dn;	int ret;	const char * const noattrs[] = { NULL };	el = dsdb_get_single_valued_attr(ac->msg, ""primaryGroupID"",					 ac->req->operation);	if (el == NULL) {		 		return LDB_SUCCESS;	}	 	ret = dsdb_module_search_dn(ac->module, ac, &res, ac->msg->dn, attrs,				    DSDB_FLAG_NEXT_MODULE, ac->req);	if (ret != LDB_SUCCESS) {		return ret;	}	uac = ldb_msg_find_attr_as_uint(res->msgs[0], ""userAccountControl"", 0);	 	prev_rid = ldb_msg_find_attr_as_uint(res->msgs[0], ""primaryGroupID"",					     (int) -1);	if (prev_rid == (int) -1) {		 		return LDB_ERR_OBJECT_CLASS_VIOLATION;	}	prev_sid = dom_sid_add_rid(ac, samdb_domain_sid(ldb), prev_rid);	if (prev_sid == NULL) {		return ldb_operr(ldb);	}	 	msg = ldb_msg_new(ac->msg);	if (msg == NULL) {		return ldb_module_oom(ac->module);	}	ret = ldb_msg_add(msg, el, 0);	if (ret != LDB_SUCCESS) {		return ret;	}	new_rid = ldb_msg_find_attr_as_uint(msg, ""primaryGroupID"", (int) -1);	talloc_free(msg);	if (new_rid == (int) -1) {		 		return LDB_SUCCESS;	}	if (prev_rid == new_rid) {		return LDB_SUCCESS;	}	if ((uac & UF_SERVER_TRUST_ACCOUNT) && new_rid != DOMAIN_RID_DCS) {		ldb_asprintf_errstring(ldb,			""%08X: samldb: UF_SERVER_TRUST_ACCOUNT requires ""			""primaryGroupID=%u!"",			W_ERROR_V(WERR_DS_CANT_MOD_PRIMARYGROUPID),			DOMAIN_RID_DCS);		return LDB_ERR_UNWILLING_TO_PERFORM;	}	if ((uac & UF_PARTIAL_SECRETS_ACCOUNT) && new_rid != DOMAIN_RID_READONLY_DCS) {		ldb_asprintf_errstring(ldb,			""%08X: samldb: UF_PARTIAL_SECRETS_ACCOUNT requires ""			""primaryGroupID=%u!"",			W_ERROR_V(WERR_DS_CANT_MOD_PRIMARYGROUPID),			DOMAIN_RID_READONLY_DCS);		return LDB_ERR_UNWILLING_TO_PERFORM;	}	ret = dsdb_module_search(ac->module, ac, &group_res,				 ldb_get_default_basedn(ldb),				 LDB_SCOPE_SUBTREE,				 noattrs, DSDB_FLAG_NEXT_MODULE,				 ac->req,				 ""(objectSid=%s)"",				 ldap_encode_ndr_dom_sid(ac, prev_sid));	if (ret != LDB_SUCCESS) {		return ret;	}	if (group_res->count != 1) {		return ldb_operr(ldb);	}	prev_prim_group_dn = group_res->msgs[0]->dn;	new_sid = dom_sid_add_rid(ac, samdb_domain_sid(ldb), new_rid);	if (new_sid == NULL) {		return ldb_operr(ldb);	}	ret = dsdb_module_search(ac->module, ac, &group_res,				 ldb_get_default_basedn(ldb),				 LDB_SCOPE_SUBTREE,				 noattrs, DSDB_FLAG_NEXT_MODULE,				 ac->req,				 ""(objectSid=%s)"",				 ldap_encode_ndr_dom_sid(ac, new_sid));	if (ret != LDB_SUCCESS) {		return ret;	}	if (group_res->count != 1) {		 		return LDB_ERR_UNWILLING_TO_PERFORM;	}	new_prim_group_dn = group_res->msgs[0]->dn;	 	el = samdb_find_attribute(ldb, res->msgs[0], ""memberOf"",				  ldb_dn_get_linearized(new_prim_group_dn));	if (el == NULL) {		return LDB_ERR_UNWILLING_TO_PERFORM;	}	 	msg = ldb_msg_new(ac->msg);	if (msg == NULL) {		return ldb_module_oom(ac->module);	}	msg->dn = new_prim_group_dn;	ret = samdb_msg_add_delval(ldb, msg, msg, ""member"",				   ldb_dn_get_linearized(ac->msg->dn));	if (ret != LDB_SUCCESS) {		return ret;	}	ret = dsdb_module_modify(ac->module, msg, DSDB_FLAG_NEXT_MODULE, ac->req);	if (ret != LDB_SUCCESS) {		return ret;	}	talloc_free(msg);	 	msg = ldb_msg_new(ac->msg);	if (msg == NULL) {		return ldb_module_oom(ac->module);	}	msg->dn = prev_prim_group_dn;	ret = samdb_msg_add_addval(ldb, msg, msg, ""member"",				   ldb_dn_get_linearized(ac->msg->dn));	if (ret != LDB_SUCCESS) {		return ret;	}	ret = dsdb_module_modify(ac->module, msg, DSDB_FLAG_NEXT_MODULE, ac->req);	if (ret != LDB_SUCCESS) {		return ret;	}	talloc_free(msg);	return LDB_SUCCESS;}",13
291,2574,CVE-2016-6787,25,"static void perf_sample_regs_intr(struct perf_regs *regs_intr,				  struct pt_regs *regs){	regs_intr->regs = regs;	regs_intr->abi  = perf_reg_abi(current);}",15979
61,1455,CVE-2014-3610,25,"static inline int is_cr_intercept(struct vcpu_svm *svm, int bit){	struct vmcb *vmcb = get_host_vmcb(svm);	return vmcb->control.intercept_cr & (1U << bit);}",11317
486,1191,CVE-2011-4347,25,"static void kvm_free_assigned_irq(struct kvm *kvm,				  struct kvm_assigned_dev_kernel *assigned_dev){	kvm_deassign_irq(kvm, assigned_dev, assigned_dev->irq_requested_type);}",10050
351,1619,CVE-2014-3122,25,"void page_add_anon_rmap(struct page *page,	struct vm_area_struct *vma, unsigned long address){	do_page_add_anon_rmap(page, vma, address, 0);}",11590
190,1833,CVE-2015-1342,25," static char *get_next_cgroup_dir(const char *taskcg, const char *querycg) { 	char *start, *end;	if (strlen(taskcg) <= strlen(querycg)) {		fprintf(stderr, ""%s: I was fed bad input\n"", __func__);		return NULL;	}	if (strcmp(querycg, ""/"") == 0)		start =  strdup(taskcg + 1);	else		start = strdup(taskcg + strlen(querycg) + 1);	if (!start)		return NULL;	end = strchr(start, '/');	if (end)		*end = '\0';	return start;}",13893
713,2955,CVE-2015-6769,25,  int fill_data_id() { return fill_data_id_; },29619
577,1682,CVE-2014-1738,25,static void main_command_interrupt(void){	cancel_delayed_work(&fd_timer);	cont->interrupt();},11975
206,1206,CVE-2011-1019,25,"static inline void ____napi_schedule(struct softnet_data *sd,				     struct napi_struct *napi){	list_add_tail(&napi->poll_list, &sd->poll_list);	__raise_softirq_irqoff(NET_RX_SOFTIRQ);}",10295
453,1005,CVE-2013-2929,25,static void put_arg_page(struct page *page){	put_page(page);},8459
13,2337,CVE-2013-7421,25,"static inline int serpent_fpu_begin(int fpu_enabled, unsigned int nbytes){	return glue_fpu_begin(SERPENT_BLOCK_SIZE, SERPENT_PARALLEL_BLOCKS,			      NULL, fpu_enabled, nbytes);}",14767
437,2369,CVE-2013-7421,25,static void crypto_larval_destroy(struct crypto_alg *alg){	struct crypto_larval *larval = (void *)alg;	BUG_ON(!crypto_is_larval(alg));	if (larval->adult)		crypto_mod_put(larval->adult);	kfree(larval);},14799
664,1397,CVE-2014-4014,25,"void inode_sb_list_add(struct inode *inode){	spin_lock(&inode_sb_list_lock);	list_add(&inode->i_sb_list, &inode->i_sb->s_inodes);	spin_unlock(&inode_sb_list_lock);}",10943
81,342,CVE-2012-1179,25,"int make_pages_present(unsigned long addr, unsigned long end){	int ret, len, write;	struct vm_area_struct * vma;	vma = find_vma(current->mm, addr);	if (!vma)		return -ENOMEM;	 	write = (vma->vm_flags & (VM_WRITE | VM_SHARED)) == VM_WRITE;	BUG_ON(addr >= end);	BUG_ON(end > vma->vm_end);	len = DIV_ROUND_UP(end, PAGE_SIZE) - addr/PAGE_SIZE;	ret = get_user_pages(current, current->mm, addr,			len, write, 0, NULL, NULL);	if (ret < 0)		return ret;	return ret == len ? 0 : -EFAULT;}",4000
160,2069,CVE-2014-9644,25,struct shash_desc *mcryptd_shash_desc(struct ahash_request *req){	struct mcryptd_hash_request_ctx *rctx = ahash_request_ctx(req);	return &rctx->desc;},14403
337,76,CVE-2015-8325,25,"auth_input_request_forwarding(struct passwd * pw){	Channel *nc;	int sock = -1;	if (auth_sock_name != NULL) {		error(""authentication forwarding requested twice."");		return 0;	}	 	temporarily_use_uid(pw);	 	auth_sock_dir = xstrdup(""/tmp/ssh-XXXXXXXXXX"");	 	if (mkdtemp(auth_sock_dir) == NULL) {		packet_send_debug(""Agent forwarding disabled: ""		    ""mkdtemp() failed: %.100s"", strerror(errno));		restore_uid();		free(auth_sock_dir);		auth_sock_dir = NULL;		goto authsock_err;	}	xasprintf(&auth_sock_name, ""%s/agent.%ld"",	    auth_sock_dir, (long) getpid());	 	sock = unix_listener(auth_sock_name, SSH_LISTEN_BACKLOG, 0);	 	restore_uid();	 	if (sock < 0)		goto authsock_err;	 	nc = channel_new(""auth socket"",	    SSH_CHANNEL_AUTH_SOCKET, sock, sock, -1,	    CHAN_X11_WINDOW_DEFAULT, CHAN_X11_PACKET_DEFAULT,	    0, ""auth socket"", 1);	nc->path = xstrdup(auth_sock_name);	return 1; authsock_err:	free(auth_sock_name);	if (auth_sock_dir != NULL) {		rmdir(auth_sock_dir);		free(auth_sock_dir);	}	if (sock != -1)		close(sock);	auth_sock_name = NULL;	auth_sock_dir = NULL;	return 0;}",2254
520,2461,CVE-2013-7421,25,"int hash_check_hw(struct hash_device_data *device_data){	 	if (HASH_P_ID0 == readl_relaxed(&device_data->base->periphid0) &&	    HASH_P_ID1 == readl_relaxed(&device_data->base->periphid1) &&	    HASH_P_ID2 == readl_relaxed(&device_data->base->periphid2) &&	    HASH_P_ID3 == readl_relaxed(&device_data->base->periphid3) &&	    HASH_CELL_ID0 == readl_relaxed(&device_data->base->cellid0) &&	    HASH_CELL_ID1 == readl_relaxed(&device_data->base->cellid1) &&	    HASH_CELL_ID2 == readl_relaxed(&device_data->base->cellid2) &&	    HASH_CELL_ID3 == readl_relaxed(&device_data->base->cellid3)) {		return 0;	}	dev_err(device_data->dev, ""%s: HASH_UNSUPPORTED_HW!\n"", __func__);	return -ENOTSUPP;}",14891
340,2558,CVE-2016-6787,25,"static int perf_event_mmap_match(struct perf_event *event,				 void *data){	struct perf_mmap_event *mmap_event = data;	struct vm_area_struct *vma = mmap_event->vma;	int executable = vma->vm_flags & VM_EXEC;	return (!executable && event->attr.mmap_data) ||	       (executable && (event->attr.mmap || event->attr.mmap2));}",15963
588,296,CVE-2012-1179,25,"mem_cgroup_zoneinfo(struct mem_cgroup *memcg, int nid, int zid){	return &memcg->info.nodeinfo[nid]->zoneinfo[zid];}",3954
242,3089,CVE-2015-1593,25,static unsigned int stack_maxrandom_size(void) {	unsigned int max = 0; 	if ((current->flags & PF_RANDOMIZE) && 		!(current->personality & ADDR_NO_RANDOMIZE)) {		max = ((-1U) & STACK_RND_MASK) << PAGE_SHIFT; 	}  	return max;},31202
17,2019,CVE-2014-9644,25,"static void gcm_dec_hash_done(struct aead_request *req, int err){	struct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);	struct ablkcipher_request *abreq = &pctx->u.abreq;	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;	if (!err) {		ablkcipher_request_set_callback(abreq, aead_request_flags(req),						gcm_decrypt_done, req);		crypto_gcm_init_crypt(abreq, req, gctx->cryptlen);		err = crypto_ablkcipher_decrypt(abreq);		if (err == -EINPROGRESS || err == -EBUSY)			return;		else if (!err)			err = crypto_gcm_verify(req, pctx);	}	aead_request_complete(req, err);}",14353
751,2324,CVE-2013-7421,25,"static int ghash_async_init_tfm(struct crypto_tfm *tfm){	struct cryptd_ahash *cryptd_tfm;	struct ghash_async_ctx *ctx = crypto_tfm_ctx(tfm);	cryptd_tfm = cryptd_alloc_ahash(""__ghash-pclmulqdqni"", 0, 0);	if (IS_ERR(cryptd_tfm))		return PTR_ERR(cryptd_tfm);	ctx->cryptd_tfm = cryptd_tfm;	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),				 sizeof(struct ahash_request) +				 crypto_ahash_reqsize(&cryptd_tfm->base));	return 0;}",14754
633,304,CVE-2012-1179,25,"struct mem_cgroup *parent_mem_cgroup(struct mem_cgroup *memcg){	if (!memcg->res.parent)		return NULL;	return mem_cgroup_from_res_counter(memcg->res.parent, res);}",3962
85,1017,CVE-2013-2929,25,"static int __ptrace_detach(struct task_struct *tracer, struct task_struct *p){	int dead;	__ptrace_unlink(p);	if (p->exit_state != EXIT_ZOMBIE)		return false;	dead = !thread_group_leader(p);	if (!dead && thread_group_empty(p)) {		if (!same_thread_group(p->real_parent, tracer))			dead = do_notify_parent(p, p->exit_signal);		else if (ignoring_children(tracer->sighand)) {			__wake_up_parent(p, tracer);			dead = true;		}	}	 	if (dead)		p->exit_state = EXIT_DEAD;	return dead;}",8471
159,742,CVE-2011-4112,25,"static int ieee80211_open(struct net_device *dev){	struct ieee80211_sub_if_data *sdata = IEEE80211_DEV_TO_SUB_IF(dev);	int err;	 	if (!is_valid_ether_addr(dev->dev_addr))		return -EADDRNOTAVAIL;	err = ieee80211_check_concurrent_iface(sdata, sdata->vif.type);	if (err)		return err;	return ieee80211_do_open(dev, true);}",5467
762,1084,CVE-2013-1957,25,static int mnt_make_readonly(struct mount *mnt){	int ret = 0;	br_write_lock(&vfsmount_lock);	mnt->mnt.mnt_flags |= MNT_WRITE_HOLD;	 	smp_mb();	 	if (mnt_get_writers(mnt) > 0)		ret = -EBUSY;	else		mnt->mnt.mnt_flags |= MNT_READONLY;	 	smp_wmb();	mnt->mnt.mnt_flags &= ~MNT_WRITE_HOLD;	br_write_unlock(&vfsmount_lock);	return ret;},9165
598,528,CVE-2011-4112,25,static void bond_netpoll_cleanup(struct net_device *bond_dev){},5253
646,463,CVE-2012-0028,25,"static int unshare_sighand(unsigned long unshare_flags, struct sighand_struct **new_sighp){	struct sighand_struct *sigh = current->sighand;	if ((unshare_flags & CLONE_SIGHAND) && atomic_read(&sigh->count) > 1)		return -EINVAL;	else		return 0;}",4376
134,2567,CVE-2016-6787,25,"perf_install_in_context(struct perf_event_context *ctx,			struct perf_event *event,			int cpu){	struct task_struct *task = ctx->task;	lockdep_assert_held(&ctx->mutex);	event->ctx = ctx;	if (event->cpu != -1)		event->cpu = cpu;	if (!task) {		 		cpu_function_call(cpu, __perf_install_in_context, event);		return;	}retry:	if (!task_function_call(task, __perf_install_in_context, event))		return;	raw_spin_lock_irq(&ctx->lock);	 	if (ctx->is_active) {		raw_spin_unlock_irq(&ctx->lock);		 		task = ctx->task;		goto retry;	}	 	add_event_to_ctx(event, ctx);	raw_spin_unlock_irq(&ctx->lock);}",15972
165,823,CVE-2011-2495,25,static unsigned name_to_int(struct dentry *dentry){	const char *name = dentry->d_name.name;	int len = dentry->d_name.len;	unsigned n = 0;	if (len > 1 && *name == '0')		goto out;	while (len-- > 0) {		unsigned c = *name++ - '0';		if (c > 9)			goto out;		if (n >= (~0U-9)/10)			goto out;		n *= 10;		n += c;	}	return n;out:	return ~0U;},6620
434,135,CVE-2012-2123,25,"int cap_vm_enough_memory(struct mm_struct *mm, long pages){	int cap_sys_admin = 0;	if (cap_capable(current_cred(), &init_user_ns, CAP_SYS_ADMIN,			SECURITY_CAP_NOAUDIT) == 0)		cap_sys_admin = 1;	return __vm_enough_memory(mm, pages, cap_sys_admin);}",3533
630,2173,CVE-2014-7822,25,"static int reiserfs_file_open(struct inode *inode, struct file *file){	int err = dquot_file_open(inode, file);        if (!atomic_inc_not_zero(&REISERFS_I(inode)->openers)) {		 		mutex_lock(&(REISERFS_I(inode)->tailpack));		atomic_inc(&REISERFS_I(inode)->openers);		mutex_unlock(&(REISERFS_I(inode)->tailpack));	}	return err;}",14588
113,1486,CVE-2014-3610,25,"static inline void set_exception_intercept(struct vcpu_svm *svm, int bit){	struct vmcb *vmcb = get_host_vmcb(svm);	vmcb->control.intercept_exceptions |= (1U << bit);	recalc_intercepts(svm);}",11348
715,1535,CVE-2014-3610,25,"static void svm_set_dr7(struct kvm_vcpu *vcpu, unsigned long value){	struct vcpu_svm *svm = to_svm(vcpu);	svm->vmcb->save.dr7 = value;	mark_dirty(svm->vmcb, VMCB_DR);}",11397
533,884,CVE-2011-2486,25,static int get_appcontext_input_count(void){  static int input_count_offset = -1;  if (input_count_offset < 0)	input_count_offset = get_appcontext_input_count_offset();  if (input_count_offset == 0)	return 1;    return get_appcontext_input_count_at(input_count_offset);},6694
390,516,CVE-2011-4112,25,"static void bond_detach_slave(struct bonding *bond, struct slave *slave){	if (slave->next)		slave->next->prev = slave->prev;	if (slave->prev)		slave->prev->next = slave->next;	if (bond->first_slave == slave) {  		if (bond->slave_cnt > 1) {  			bond->first_slave = slave->next;		} else {			bond->first_slave = NULL;  		}	}	slave->next = NULL;	slave->prev = NULL;	bond->slave_cnt--;}",5241
583,2249,CVE-2013-7421,25,"static int ctr_des3_decrypt(struct blkcipher_desc *desc,			    struct scatterlist *dst, struct scatterlist *src,			    unsigned int nbytes){	struct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);	struct blkcipher_walk walk;	blkcipher_walk_init(&walk, dst, src, nbytes);	return ctr_desall_crypt(desc, KMCTR_TDEA_192_DECRYPT, ctx, &walk);}",14679
746,1456,CVE-2014-3610,25,static inline void mark_all_clean(struct vmcb *vmcb){	vmcb->control.clean = ((1 << VMCB_DIRTY_MAX) - 1)			       & ~VMCB_ALWAYS_DIRTY_MASK;},11318
394,366,CVE-2012-1179,25,"static void migrate_page_add(struct page *page, struct list_head *pagelist,				unsigned long flags){	 	if ((flags & MPOL_MF_MOVE_ALL) || page_mapcount(page) == 1) {		if (!isolate_lru_page(page)) {			list_add_tail(&page->lru, pagelist);			inc_zone_page_state(page, NR_ISOLATED_ANON +					    page_is_file_cache(page));		}	}}",4024
67,435,CVE-2012-0028,25,void __mmdrop(struct mm_struct *mm){	BUG_ON(mm == &init_mm);	mm_free_pgd(mm);	destroy_context(mm);	mmu_notifier_mm_destroy(mm);	free_mm(mm);},4348
740,1956,CVE-2014-9644,25,"static void cryptd_hash_finup(struct crypto_async_request *req_async, int err){	struct ahash_request *req = ahash_request_cast(req_async);	struct cryptd_hash_request_ctx *rctx = ahash_request_ctx(req);	if (unlikely(err == -EINPROGRESS))		goto out;	err = shash_ahash_finup(req, &rctx->desc);	req->base.complete = rctx->complete;out:	local_bh_disable();	rctx->complete(&req->base, err);	local_bh_enable();}",14290
423,3074,CVE-2014-5207,25,"static int do_remount(struct path *path, int flags, int mnt_flags,		      void *data){	int err;	struct super_block *sb = path->mnt->mnt_sb;	struct mount *mnt = real_mount(path->mnt);	if (!check_mnt(mnt))		return -EINVAL;	if (path->dentry != path->mnt->mnt_root)		return -EINVAL;	 	if ((mnt->mnt.mnt_flags & MNT_LOCK_READONLY) && 	    !(mnt_flags & MNT_READONLY)) { 		return -EPERM; 	} 	err = security_sb_remount(sb, data); 	if (err) 		return err;	down_write(&sb->s_umount);	if (flags & MS_BIND)		err = change_mount_flags(path->mnt, flags);	else if (!capable(CAP_SYS_ADMIN))		err = -EPERM;	else		err = do_remount_sb(sb, flags, data, 0);	if (!err) {		lock_mount_hash();		mnt_flags |= mnt->mnt.mnt_flags & ~MNT_USER_SETTABLE_MASK;		mnt->mnt.mnt_flags = mnt_flags;		touch_mnt_namespace(mnt->mnt_ns);		unlock_mount_hash();	}	up_write(&sb->s_umount);	return err;}",31135
742,687,CVE-2011-4112,25,ar6000_disconnect(struct ar6_softc *ar){    if ((ar->arConnected == true) || (ar->arConnectPending == true)) {        wmi_disconnect_cmd(ar->arWmi);                 ar->arConnectPending = false;    }    return 0;},5412
421,2094,CVE-2014-9644,25,"static void seqiv_aead_complete(struct crypto_async_request *base, int err){	struct aead_givcrypt_request *req = base->data;	seqiv_aead_complete2(req, err);	aead_givcrypt_complete(req, err);}",14428
235,1309,CVE-2014-5207,25,"static int do_umount(struct mount *mnt, int flags){	struct super_block *sb = mnt->mnt.mnt_sb;	int retval;	retval = security_sb_umount(&mnt->mnt, flags);	if (retval)		return retval;	 	if (flags & MNT_EXPIRE) {		if (&mnt->mnt == current->fs->root.mnt ||		    flags & (MNT_FORCE | MNT_DETACH))			return -EINVAL;		 		lock_mount_hash();		if (mnt_get_count(mnt) != 2) {			unlock_mount_hash();			return -EBUSY;		}		unlock_mount_hash();		if (!xchg(&mnt->mnt_expiry_mark, 1))			return -EAGAIN;	}	 	if (flags & MNT_FORCE && sb->s_op->umount_begin) {		sb->s_op->umount_begin(sb);	}	 	if (&mnt->mnt == current->fs->root.mnt && !(flags & MNT_DETACH)) {		 		down_write(&sb->s_umount);		if (!(sb->s_flags & MS_RDONLY))			retval = do_remount_sb(sb, MS_RDONLY, NULL, 0);		up_write(&sb->s_umount);		return retval;	}	namespace_lock();	lock_mount_hash();	event++;	if (flags & MNT_DETACH) {		if (!list_empty(&mnt->mnt_list))			umount_tree(mnt, 2);		retval = 0;	} else {		shrink_submounts(mnt);		retval = -EBUSY;		if (!propagate_mount_busy(mnt, 2)) {			if (!list_empty(&mnt->mnt_list))				umount_tree(mnt, 1);			retval = 0;		}	}	unlock_mount_hash();	namespace_unlock();	return retval;}",10658
11,770,CVE-2011-4080,25,int sysctl_is_seen(struct ctl_table_header *p){	struct ctl_table_set *set = p->set;	int res;	spin_lock(&sysctl_lock);	if (p->unregistering)		res = 0;	else if (!set->is_seen)		res = 1;	else		res = set->is_seen(set);	spin_unlock(&sysctl_lock);	return res;},5509
89,2177,CVE-2014-7822,25,"static int opipe_prep(struct pipe_inode_info *pipe, unsigned int flags){	int ret;	 	if (pipe->nrbufs < pipe->buffers)		return 0;	ret = 0;	pipe_lock(pipe);	while (pipe->nrbufs >= pipe->buffers) {		if (!pipe->readers) {			send_sig(SIGPIPE, current, 0);			ret = -EPIPE;			break;		}		if (flags & SPLICE_F_NONBLOCK) {			ret = -EAGAIN;			break;		}		if (signal_pending(current)) {			ret = -ERESTARTSYS;			break;		}		pipe->waiting_writers++;		pipe_wait(pipe);		pipe->waiting_writers--;	}	pipe_unlock(pipe);	return ret;}",14592
610,945,CVE-2013-4470,25,"struct sk_buff *ip_make_skb(struct sock *sk,			    struct flowi4 *fl4,			    int getfrag(void *from, char *to, int offset,					int len, int odd, struct sk_buff *skb),			    void *from, int length, int transhdrlen,			    struct ipcm_cookie *ipc, struct rtable **rtp,			    unsigned int flags){	struct inet_cork cork;	struct sk_buff_head queue;	int err;	if (flags & MSG_PROBE)		return NULL;	__skb_queue_head_init(&queue);	cork.flags = 0;	cork.addr = 0;	cork.opt = NULL;	err = ip_setup_cork(sk, &cork, ipc, rtp);	if (err)		return ERR_PTR(err);	err = __ip_append_data(sk, fl4, &queue, &cork,			       &current->task_frag, getfrag,			       from, length, transhdrlen, flags);	if (err) {		__ip_flush_pending_frames(sk, &queue, &cork);		return ERR_PTR(err);	}	return __ip_make_skb(sk, fl4, &queue, &cork);}",7809
461,1238,CVE-2011-1019,25,static inline struct list_head *ptype_head(const struct packet_type *pt){	if (pt->type == htons(ETH_P_ALL))		return &ptype_all;	else		return &ptype_base[ntohs(pt->type) & PTYPE_HASH_MASK];},10327
618,1193,CVE-2011-4347,25,"static int kvm_vm_ioctl_deassign_dev_irq(struct kvm *kvm,					 struct kvm_assigned_irq					 *assigned_irq){	int r = -ENODEV;	struct kvm_assigned_dev_kernel *match;	mutex_lock(&kvm->lock);	match = kvm_find_assigned_dev(&kvm->arch.assigned_dev_head,				      assigned_irq->assigned_dev_id);	if (!match)		goto out;	r = kvm_deassign_irq(kvm, match, assigned_irq->flags);out:	mutex_unlock(&kvm->lock); 	return r; }",10052
220,846,CVE-2011-2495,25,"static struct dentry *proc_pid_instantiate(struct inode *dir,					   struct dentry * dentry,					   struct task_struct *task, const void *ptr){	struct dentry *error = ERR_PTR(-ENOENT);	struct inode *inode;	inode = proc_pid_make_inode(dir->i_sb, task);	if (!inode)		goto out;	inode->i_mode = S_IFDIR|S_IRUGO|S_IXUGO;	inode->i_op = &proc_tgid_base_inode_operations;	inode->i_fop = &proc_tgid_base_operations;	inode->i_flags|=S_IMMUTABLE;	inode->i_nlink = 2 + pid_entry_count_dirs(tgid_base_stuff,		ARRAY_SIZE(tgid_base_stuff));	d_set_d_op(dentry, &pid_dentry_operations);	d_add(dentry, inode);	 	if (pid_revalidate(dentry, NULL))		error = NULL;out:	return error;}",6643
356,2914,CVE-2011-4127,25,"static void sd_unprep_fn(struct request_queue *q, struct request *rq){	if (rq->cmd_flags & REQ_DISCARD) {		free_page((unsigned long)rq->buffer);		rq->buffer = NULL;	}}",28297
263,1097,CVE-2013-1957,25,static unsigned int mntns_inum(void *ns){	struct mnt_namespace *mnt_ns = ns;	return mnt_ns->proc_inum;},9178
281,2001,CVE-2014-9644,25,"static int crypto_gcm_init_tfm(struct crypto_tfm *tfm){	struct crypto_instance *inst = (void *)tfm->__crt_alg;	struct gcm_instance_ctx *ictx = crypto_instance_ctx(inst);	struct crypto_gcm_ctx *ctx = crypto_tfm_ctx(tfm);	struct crypto_ablkcipher *ctr;	struct crypto_ahash *ghash;	unsigned long align;	int err;	ghash = crypto_spawn_ahash(&ictx->ghash);	if (IS_ERR(ghash))		return PTR_ERR(ghash);	ctr = crypto_spawn_skcipher(&ictx->ctr);	err = PTR_ERR(ctr);	if (IS_ERR(ctr))		goto err_free_hash;	ctx->ctr = ctr;	ctx->ghash = ghash;	align = crypto_tfm_alg_alignmask(tfm);	align &= ~(crypto_tfm_ctx_alignment() - 1);	tfm->crt_aead.reqsize = align +		offsetof(struct crypto_gcm_req_priv_ctx, u) +		max(sizeof(struct ablkcipher_request) +		    crypto_ablkcipher_reqsize(ctr),		    sizeof(struct ahash_request) +		    crypto_ahash_reqsize(ghash));	return 0;err_free_hash:	crypto_free_ahash(ghash);	return err;}",14335
33,1848,CVE-2014-9644,25,"int crypto_enqueue_request(struct crypto_queue *queue,			   struct crypto_async_request *request){	int err = -EINPROGRESS;	if (unlikely(queue->qlen >= queue->max_qlen)) {		err = -EBUSY;		if (!(request->flags & CRYPTO_TFM_REQ_MAY_BACKLOG))			goto out;		if (queue->backlog == &queue->list)			queue->backlog = &request->list;	}	queue->qlen++;	list_add_tail(&request->list, &queue->list);out:	return err;}",14182
187,2674,CVE-2016-4565,25,"static unsigned int hfi1_poll(struct file *fp, struct poll_table_struct *pt){	struct hfi1_ctxtdata *uctxt;	unsigned pollflag;	uctxt = ((struct hfi1_filedata *)fp->private_data)->uctxt;	if (!uctxt)		pollflag = POLLERR;	else if (uctxt->poll_type == HFI1_POLL_TYPE_URGENT)		pollflag = poll_urgent(fp, pt);	else  if (uctxt->poll_type == HFI1_POLL_TYPE_ANYRCV)		pollflag = poll_next(fp, pt);	else  		pollflag = POLLERR;	return pollflag;}",16828
382,1754,CVE-2015-6520,25,void tcp_close(struct tcp_sock_t *this){	close(this->sd);	free(this);},13128
380,968,CVE-2013-2930,25,"int perf_ftrace_event_register(struct ftrace_event_call *call,			       enum trace_reg type, void *data){	switch (type) {	case TRACE_REG_REGISTER:	case TRACE_REG_UNREGISTER:		break;	case TRACE_REG_PERF_REGISTER:	case TRACE_REG_PERF_UNREGISTER:		return 0;	case TRACE_REG_PERF_OPEN:		return perf_ftrace_function_register(data);	case TRACE_REG_PERF_CLOSE:		return perf_ftrace_function_unregister(data);	case TRACE_REG_PERF_ADD:		perf_ftrace_function_enable(data);		return 0;	case TRACE_REG_PERF_DEL:		perf_ftrace_function_disable(data);		return 0;	}	return -EINVAL;}",8422
398,425,CVE-2012-0028,25,"void put_files_struct(struct files_struct *files){	struct fdtable *fdt;	if (atomic_dec_and_test(&files->count)) {		close_files(files);		 		fdt = files_fdtable(files);		if (fdt != &files->fdtab)			kmem_cache_free(files_cachep, files);		free_fdtable(fdt);	}}",4338
288,238,CVE-2012-1179,25,"static void mem_cgroup_cancel_attach(struct cgroup_subsys *ss,				struct cgroup *cgroup,				struct cgroup_taskset *tset){	mem_cgroup_clear_mc();}",3896
119,2444,CVE-2013-7421,25,"static int cryp_dma_write(struct cryp_ctx *ctx, struct scatterlist *sg,			  int len){	int error = cryp_set_dma_transfer(ctx, sg, len, DMA_TO_DEVICE);	dev_dbg(ctx->device->dev, ""[%s]: "", __func__);	if (error) {		dev_dbg(ctx->device->dev, ""[%s]: cryp_set_dma_transfer() ""			""failed"", __func__);		return error;	}	return len;}",14874
213,4,CVE-2015-8467,25,"static int samldb_check_user_account_control_invariants(struct samldb_ctx *ac,						    int user_account_control){	int i, ret = 0;	int need_check = false;	const struct uac_to_guid {		int uac;		int never;		int needs;		int not_with;		const char *error_string;	} map[] = {		{			.uac = UF_TEMP_DUPLICATE_ACCOUNT,			.never = true,			.error_string = ""Updating the UF_TEMP_DUPLICATE_ACCOUNT flag is never allowed""		},		{			.uac = UF_PARTIAL_SECRETS_ACCOUNT,			.needs = UF_WORKSTATION_TRUST_ACCOUNT,			.error_string = ""Setting UF_PARTIAL_SECRETS_ACCOUNT only permitted with UF_WORKSTATION_TRUST_ACCOUNT""		},		{			.uac = UF_TRUSTED_FOR_DELEGATION,			.not_with = UF_PARTIAL_SECRETS_ACCOUNT,			.error_string = ""Setting UF_TRUSTED_FOR_DELEGATION not allowed with UF_PARTIAL_SECRETS_ACCOUNT""		},		{			.uac = UF_NORMAL_ACCOUNT,			.not_with = UF_ACCOUNT_TYPE_MASK & ~UF_NORMAL_ACCOUNT,			.error_string = ""Setting more than one account type not permitted""		},		{			.uac = UF_WORKSTATION_TRUST_ACCOUNT,			.not_with = UF_ACCOUNT_TYPE_MASK & ~UF_WORKSTATION_TRUST_ACCOUNT,			.error_string = ""Setting more than one account type not permitted""		},		{			.uac = UF_INTERDOMAIN_TRUST_ACCOUNT,			.not_with = UF_ACCOUNT_TYPE_MASK & ~UF_INTERDOMAIN_TRUST_ACCOUNT,			.error_string = ""Setting more than one account type not permitted""		},		{			.uac = UF_SERVER_TRUST_ACCOUNT,			.not_with = UF_ACCOUNT_TYPE_MASK & ~UF_SERVER_TRUST_ACCOUNT,			.error_string = ""Setting more than one account type not permitted""		},		{			.uac = UF_TRUSTED_FOR_DELEGATION,			.not_with = UF_PARTIAL_SECRETS_ACCOUNT,			.error_string = ""Setting UF_TRUSTED_FOR_DELEGATION not allowed with UF_PARTIAL_SECRETS_ACCOUNT""		}	};	for (i = 0; i < ARRAY_SIZE(map); i++) {		if (user_account_control & map[i].uac) {			need_check = true;			break;		}	}	if (need_check == false) {		return LDB_SUCCESS;	}	for (i = 0; i < ARRAY_SIZE(map); i++) {		int this_uac = user_account_control & map[i].uac;		if (this_uac != 0) {			if (map[i].never) {				ret = LDB_ERR_OTHER;				break;			} else if (map[i].needs != 0) {				if ((map[i].needs & user_account_control) == 0) {					ret = LDB_ERR_OTHER;					break;				}			} else if (map[i].not_with != 0) {				if ((map[i].not_with & user_account_control) != 0) {					ret = LDB_ERR_OTHER;					break;				}			}		}	}	if (ret != LDB_SUCCESS) {		switch (ac->req->operation) {		case LDB_ADD:			ldb_asprintf_errstring(ldb_module_get_ctx(ac->module),					       ""Failed to add %s: %s"",					       ldb_dn_get_linearized(ac->msg->dn),					       map[i].error_string);			break;		case LDB_MODIFY:			ldb_asprintf_errstring(ldb_module_get_ctx(ac->module),					       ""Failed to modify %s: %s"",					       ldb_dn_get_linearized(ac->msg->dn),					       map[i].error_string);			break;		default:			return ldb_module_operr(ac->module);		}	}	return ret;}",5
131,515,CVE-2011-4112,25,static void bond_destructor(struct net_device *bond_dev){	struct bonding *bond = netdev_priv(bond_dev);	if (bond->wq)		destroy_workqueue(bond->wq);	free_netdev(bond_dev);},5240
622,2409,CVE-2013-7421,25,static void zlib_comp_exit(struct zlib_ctx *ctx){	struct z_stream_s *stream = &ctx->comp_stream;	if (stream->workspace) {		zlib_deflateEnd(stream);		vfree(stream->workspace);		stream->workspace = NULL;	}},14839
397,1965,CVE-2014-9644,25,"static struct crypto_instance *crypto_ctr_alloc(struct rtattr **tb){	struct crypto_instance *inst;	struct crypto_alg *alg;	int err;	err = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_BLKCIPHER);	if (err)		return ERR_PTR(err);	alg = crypto_attr_alg(tb[1], CRYPTO_ALG_TYPE_CIPHER,				  CRYPTO_ALG_TYPE_MASK);	if (IS_ERR(alg))		return ERR_CAST(alg);	 	err = -EINVAL;	if (alg->cra_blocksize < 4)		goto out_put_alg;	 	if (alg->cra_blocksize % 4)		goto out_put_alg;	inst = crypto_alloc_instance(""ctr"", alg);	if (IS_ERR(inst))		goto out;	inst->alg.cra_flags = CRYPTO_ALG_TYPE_BLKCIPHER;	inst->alg.cra_priority = alg->cra_priority;	inst->alg.cra_blocksize = 1;	inst->alg.cra_alignmask = alg->cra_alignmask | (__alignof__(u32) - 1);	inst->alg.cra_type = &crypto_blkcipher_type;	inst->alg.cra_blkcipher.ivsize = alg->cra_blocksize;	inst->alg.cra_blkcipher.min_keysize = alg->cra_cipher.cia_min_keysize;	inst->alg.cra_blkcipher.max_keysize = alg->cra_cipher.cia_max_keysize;	inst->alg.cra_ctxsize = sizeof(struct crypto_ctr_ctx);	inst->alg.cra_init = crypto_ctr_init_tfm;	inst->alg.cra_exit = crypto_ctr_exit_tfm;	inst->alg.cra_blkcipher.setkey = crypto_ctr_setkey;	inst->alg.cra_blkcipher.encrypt = crypto_ctr_crypt;	inst->alg.cra_blkcipher.decrypt = crypto_ctr_crypt;	inst->alg.cra_blkcipher.geniv = ""chainiv"";out:	crypto_mod_put(alg);	return inst;out_put_alg:	inst = ERR_PTR(err);	goto out;}",14299
320,1813,CVE-2015-1344,25,"static char *get_next_cgroup_dir(const char *taskcg, const char *querycg){	char *start, *end;	if (strlen(taskcg) <= strlen(querycg)) {		fprintf(stderr, ""%s: I was fed bad input\n"", __func__);		return NULL;	}	if (strcmp(querycg, ""/"") == 0)		start =  strdup(taskcg + 1);	else		start = strdup(taskcg + strlen(querycg) + 1);	if (!start)		return NULL;	end = strchr(start, '/');	if (end)		*end = '\0';	return start;}",13873
395,117,CVE-2012-2123,25,"int cap_capable(const struct cred *cred, struct user_namespace *targ_ns,		int cap, int audit){	for (;;) {		 		if (targ_ns != &init_user_ns && targ_ns->creator == cred->user)			return 0;		 		if (targ_ns == cred->user->user_ns)			return cap_raised(cred->cap_effective, cap) ? 0 : -EPERM;		 		if (targ_ns == &init_user_ns)			return -EPERM;		 		targ_ns = targ_ns->creator->user_ns;	}	 }",3515
747,624,CVE-2011-4112,25,"static int veth_validate(struct nlattr *tb[], struct nlattr *data[]){	if (tb[IFLA_ADDRESS]) {		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN)			return -EINVAL;		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS])))			return -EADDRNOTAVAIL;	}	if (tb[IFLA_MTU]) {		if (!is_valid_veth_mtu(nla_get_u32(tb[IFLA_MTU])))			return -EINVAL;	}	return 0;}",5349
290,633,CVE-2011-4112,25,"static int airo_get_sens(struct net_device *dev,			 struct iw_request_info *info,			 struct iw_param *vwrq,			 char *extra){	struct airo_info *local = dev->ml_priv;	readConfigRid(local, 1);	vwrq->value = le16_to_cpu(local->config.rssiThreshold);	vwrq->disabled = (vwrq->value == 0);	vwrq->fixed = 1;	return 0;}",5358
50,2788,CVE-2014-9870,25,"static inline void dump_backtrace(struct pt_regs *regs, struct task_struct *tsk){	unwind_backtrace(regs, tsk);}",19337
726,1110,CVE-2013-1957,25,"static void __propagate_umount(struct mount *mnt){	struct mount *parent = mnt->mnt_parent;	struct mount *m;	BUG_ON(parent == mnt);	for (m = propagation_next(parent, parent); m;			m = propagation_next(m, parent)) {		struct mount *child = __lookup_mnt(&m->mnt,					mnt->mnt_mountpoint, 0);		 		if (child && list_empty(&child->mnt_mounts))			list_move_tail(&child->mnt_hash, &mnt->mnt_hash);	}}",9191
178,114,CVE-2012-2313,25,"static int rio_set_settings(struct net_device *dev, struct ethtool_cmd *cmd){	struct netdev_private *np = netdev_priv(dev);	netif_carrier_off(dev);	if (cmd->autoneg == AUTONEG_ENABLE) {		if (np->an_enable)			return 0;		else {			np->an_enable = 1;			mii_set_media(dev);			return 0;		}	} else {		np->an_enable = 0;		if (np->speed == 1000) {			ethtool_cmd_speed_set(cmd, SPEED_100);			cmd->duplex = DUPLEX_FULL;			printk(""Warning!! Can't disable Auto negotiation in 1000Mbps, change to Manual 100Mbps, Full duplex.\n"");		}		switch (ethtool_cmd_speed(cmd)) {		case SPEED_10:			np->speed = 10;			np->full_duplex = (cmd->duplex == DUPLEX_FULL);			break;		case SPEED_100:			np->speed = 100;			np->full_duplex = (cmd->duplex == DUPLEX_FULL);			break;		case SPEED_1000:  		default:			return -EINVAL;		}		mii_set_media(dev);	}	return 0;}",3425
724,1830,CVE-2015-1344,25,"void swallow_arg(int *argcp, char *argv[], char *which){	int i;	for (i = 1; argv[i]; i++) {		if (strcmp(argv[i], which) != 0)			continue;		for (; argv[i]; i++) {			argv[i] = argv[i+1];		}		(*argcp)--;		return;	}}",13890
196,956,CVE-2013-4299,25,"static struct disk_exception *get_exception(struct pstore *ps, int index){	BUG_ON(index >= ps->exceptions_per_area);	return ((struct disk_exception *) ps->area) + index;}",7853
439,137,CVE-2012-2121,25,static void ack_flush(void *_completed){},3535
732,1662,CVE-2014-1738,25,"static void floppy_end_request(struct request *req, int error){	unsigned int nr_sectors = current_count_sectors;	unsigned int drive = (unsigned long)req->rq_disk->private_data;	 	if (error)		nr_sectors = blk_rq_cur_sectors(req);	if (__blk_end_request(req, error, nr_sectors << 9))		return;	 	floppy_off(drive);	current_req = NULL;}",11955
714,2667,CVE-2016-4565,25,"static int assign_ctxt(struct file *fp, struct hfi1_user_info *uinfo){	int i_minor, ret = 0;	unsigned swmajor, swminor, alg = HFI1_ALG_ACROSS;	swmajor = uinfo->userversion >> 16;	if (swmajor != HFI1_USER_SWMAJOR) {		ret = -ENODEV;		goto done;	}	swminor = uinfo->userversion & 0xffff;	if (uinfo->hfi1_alg < HFI1_ALG_COUNT)		alg = uinfo->hfi1_alg;	mutex_lock(&hfi1_mutex);	 	if (uinfo->subctxt_cnt) {		struct hfi1_filedata *fd = fp->private_data;		ret = find_shared_ctxt(fp, uinfo);		if (ret < 0)			goto done_unlock;		if (ret)			fd->rec_cpu_num = hfi1_get_proc_affinity(				fd->uctxt->dd, fd->uctxt->numa_id);	}	 	if (!ret) {		i_minor = iminor(file_inode(fp)) - HFI1_USER_MINOR_BASE;		ret = get_user_context(fp, uinfo, i_minor - 1, alg);	}done_unlock:	mutex_unlock(&hfi1_mutex);done:	return ret;}",16821
272,1542,CVE-2014-3610,25,"static void svm_set_segment(struct kvm_vcpu *vcpu,			    struct kvm_segment *var, int seg){	struct vcpu_svm *svm = to_svm(vcpu);	struct vmcb_seg *s = svm_seg(vcpu, seg);	s->base = var->base;	s->limit = var->limit;	s->selector = var->selector;	if (var->unusable)		s->attrib = 0;	else {		s->attrib = (var->type & SVM_SELECTOR_TYPE_MASK);		s->attrib |= (var->s & 1) << SVM_SELECTOR_S_SHIFT;		s->attrib |= (var->dpl & 3) << SVM_SELECTOR_DPL_SHIFT;		s->attrib |= (var->present & 1) << SVM_SELECTOR_P_SHIFT;		s->attrib |= (var->avl & 1) << SVM_SELECTOR_AVL_SHIFT;		s->attrib |= (var->l & 1) << SVM_SELECTOR_L_SHIFT;		s->attrib |= (var->db & 1) << SVM_SELECTOR_DB_SHIFT;		s->attrib |= (var->g & 1) << SVM_SELECTOR_G_SHIFT;	}	 	if (seg == VCPU_SREG_SS)		svm->vmcb->save.cpl = (s->attrib >> SVM_SELECTOR_DPL_SHIFT) & 3;	mark_dirty(svm->vmcb, VMCB_SEG);}",11404
688,2586,CVE-2016-6787,25,"static void unaccount_event_cpu(struct perf_event *event, int cpu){	if (event->parent)		return;	if (has_branch_stack(event)) {		if (!(event->attach_state & PERF_ATTACH_TASK))			atomic_dec(&per_cpu(perf_branch_stack_events, cpu));	}	if (is_cgroup_event(event))		atomic_dec(&per_cpu(perf_cgroup_events, cpu));}",15991
734,1819,CVE-2015-1344,25,"static int lxcfs_open(const char *path, struct fuse_file_info *fi){	if (strncmp(path, ""/cgroup"", 7) == 0)		return cg_open(path, fi);	if (strncmp(path, ""/proc"", 5) == 0)		return proc_open(path, fi);	return -EINVAL;}",13879
42,2054,CVE-2014-9644,25,static inline struct mcryptd_queue *mcryptd_get_queue(struct crypto_tfm *tfm){	struct crypto_instance *inst = crypto_tfm_alg_instance(tfm);	struct mcryptd_instance_ctx *ictx = crypto_instance_ctx(inst);	return ictx->queue;},14388
186,1899,CVE-2014-9644,25,static int crypto_ccm_init_tfm(struct crypto_tfm *tfm){	struct crypto_instance *inst = (void *)tfm->__crt_alg;	struct ccm_instance_ctx *ictx = crypto_instance_ctx(inst);	struct crypto_ccm_ctx *ctx = crypto_tfm_ctx(tfm);	struct crypto_cipher *cipher;	struct crypto_ablkcipher *ctr;	unsigned long align;	int err;	cipher = crypto_spawn_cipher(&ictx->cipher);	if (IS_ERR(cipher))		return PTR_ERR(cipher);	ctr = crypto_spawn_skcipher(&ictx->ctr);	err = PTR_ERR(ctr);	if (IS_ERR(ctr))		goto err_free_cipher;	ctx->cipher = cipher;	ctx->ctr = ctr;	align = crypto_tfm_alg_alignmask(tfm);	align &= ~(crypto_tfm_ctx_alignment() - 1);	tfm->crt_aead.reqsize = align +				sizeof(struct crypto_ccm_req_priv_ctx) +				crypto_ablkcipher_reqsize(ctr);	return 0;err_free_cipher:	crypto_free_cipher(cipher);	return err;},14233
342,986,CVE-2013-2929,25,"static int bprm_mm_init(struct linux_binprm *bprm){	int err;	struct mm_struct *mm = NULL;	bprm->mm = mm = mm_alloc();	err = -ENOMEM;	if (!mm)		goto err;	err = init_new_context(current, mm);	if (err)		goto err;	err = __bprm_mm_init(bprm);	if (err)		goto err;	return 0;err:	if (mm) {		bprm->mm = NULL;		mmdrop(mm);	}	return err;}",8440
561,1391,CVE-2014-4014,25,static void init_once(void *foo){	struct inode *inode = (struct inode *) foo;	inode_init_once(inode);},10937
440,550,CVE-2011-4112,25,static inline int slave_dev_support_netpoll(struct net_device *slave_dev){	if (slave_dev->priv_flags & IFF_DISABLE_NETPOLL)		return false;	if (!slave_dev->netdev_ops->ndo_poll_controller)		return false;	return true;},5275
552,521,CVE-2011-4112,25,"static int bond_init(struct net_device *bond_dev){	struct bonding *bond = netdev_priv(bond_dev);	struct bond_net *bn = net_generic(dev_net(bond_dev), bond_net_id);	struct alb_bond_info *bond_info = &(BOND_ALB_INFO(bond));	pr_debug(""Begin bond_init for %s\n"", bond_dev->name);	 	spin_lock_init(&(bond_info->tx_hashtbl_lock));	spin_lock_init(&(bond_info->rx_hashtbl_lock));	bond->wq = create_singlethread_workqueue(bond_dev->name);	if (!bond->wq)		return -ENOMEM;	bond_set_lockdep_class(bond_dev);	bond_create_proc_entry(bond);	list_add_tail(&bond->bond_list, &bn->dev_list);	bond_prepare_sysfs_group(bond);	bond_debug_register(bond);	__hw_addr_init(&bond->mc_list);	return 0;}",5246
433,543,CVE-2011-4112,25,"static int bond_should_deliver_exact_match(struct sk_buff *skb,					    struct slave *slave,					    struct bonding *bond){	if (bond_is_slave_inactive(slave)) {		if (bond->params.mode == BOND_MODE_ALB &&		    skb->pkt_type != PACKET_BROADCAST &&		    skb->pkt_type != PACKET_MULTICAST)			return false;		return true;	}	return false;}",5268
138,1209,CVE-2011-1019,25,"void __napi_schedule(struct napi_struct *n){	unsigned long flags;	local_irq_save(flags);	____napi_schedule(&__get_cpu_var(softnet_data), n);	local_irq_restore(flags);}",10298
617,338,CVE-2012-1179,25,"struct page *get_dump_page(unsigned long addr){	struct vm_area_struct *vma;	struct page *page;	if (__get_user_pages(current, current->mm, addr, 1,			     FOLL_FORCE | FOLL_DUMP | FOLL_GET, &page, &vma,			     NULL) < 1)		return NULL;	flush_cache_page(vma, addr, page_to_pfn(page));	return page;}",3996
128,2965,CVE-2016-1632,25,  void EnableRecording() { provider_.OnRecordingEnabled(); },29756
307,2542,CVE-2016-6787,25,"list_del_event(struct perf_event *event, struct perf_event_context *ctx){	struct perf_cpu_context *cpuctx;	WARN_ON_ONCE(event->ctx != ctx);	lockdep_assert_held(&ctx->lock);	 	if (!(event->attach_state & PERF_ATTACH_CONTEXT))		return;	event->attach_state &= ~PERF_ATTACH_CONTEXT;	if (is_cgroup_event(event)) {		ctx->nr_cgroups--;		cpuctx = __get_cpu_context(ctx);		 		if (!ctx->nr_cgroups)			cpuctx->cgrp = NULL;	}	if (has_branch_stack(event))		ctx->nr_branch_stack--;	ctx->nr_events--;	if (event->attr.inherit_stat)		ctx->nr_stat--;	list_del_rcu(&event->event_entry);	if (event->group_leader == event)		list_del_init(&event->group_entry);	update_group_times(event);	 	if (event->state > PERF_EVENT_STATE_OFF)		event->state = PERF_EVENT_STATE_OFF;	ctx->generation++;}",15947
224,1215,CVE-2011-1019,25,"int dev_change_net_namespace(struct net_device *dev, struct net *net, const char *pat){	int err;	ASSERT_RTNL();	 	err = -EINVAL;	if (dev->features & NETIF_F_NETNS_LOCAL)		goto out;	 	err = -EINVAL;	if (dev->reg_state != NETREG_REGISTERED)		goto out;	 	err = 0;	if (net_eq(dev_net(dev), net))		goto out;	 	err = -EEXIST;	if (__dev_get_by_name(net, dev->name)) {		 		if (!pat)			goto out;		if (dev_get_valid_name(dev, pat, 1))			goto out;	}	 	 	dev_close(dev);	 	err = -ENODEV;	unlist_netdevice(dev);	synchronize_net();	 	dev_shutdown(dev);	 	call_netdevice_notifiers(NETDEV_UNREGISTER, dev);	call_netdevice_notifiers(NETDEV_UNREGISTER_BATCH, dev);	 	dev_uc_flush(dev);	dev_mc_flush(dev);	 	dev_net_set(dev, net);	 	if (__dev_get_by_index(net, dev->ifindex)) {		int iflink = (dev->iflink == dev->ifindex);		dev->ifindex = dev_new_index(net);		if (iflink)			dev->iflink = dev->ifindex;	}	 	err = device_rename(&dev->dev, dev->name);	WARN_ON(err);	 	list_netdevice(dev);	 	call_netdevice_notifiers(NETDEV_REGISTER, dev);	 	rtmsg_ifinfo(RTM_NEWLINK, dev, ~0U);	synchronize_net();	err = 0;out:	return err;}",10304
230,1053,CVE-2013-1957,25,"static int do_loopback(struct path *path, const char *old_name,				int recurse){	LIST_HEAD(umount_list);	struct path old_path;	struct mount *mnt = NULL, *old;	int err;	if (!old_name || !*old_name)		return -EINVAL;	err = kern_path(old_name, LOOKUP_FOLLOW|LOOKUP_AUTOMOUNT, &old_path);	if (err)		return err;	err = -EINVAL;	if (mnt_ns_loop(&old_path))		goto out; 	err = lock_mount(path);	if (err)		goto out;	old = real_mount(old_path.mnt);	err = -EINVAL;	if (IS_MNT_UNBINDABLE(old))		goto out2;	if (!check_mnt(real_mount(path->mnt)) || !check_mnt(old))		goto out2;	if (recurse)		mnt = copy_tree(old, old_path.dentry, 0);	else		mnt = clone_mnt(old, old_path.dentry, 0);	if (IS_ERR(mnt)) {		err = PTR_ERR(mnt);		goto out;	}	err = graft_tree(mnt, path);	if (err) {		br_write_lock(&vfsmount_lock);		umount_tree(mnt, 0, &umount_list);		br_write_unlock(&vfsmount_lock);	}out2:	unlock_mount(path);	release_mounts(&umount_list);out:	path_put(&old_path);	return err;}",9134
256,2003,CVE-2014-9644,25,"static void crypto_gcm_setkey_done(struct crypto_async_request *req, int err){	struct crypto_gcm_setkey_result *result = req->data;	if (err == -EINPROGRESS)		return;	result->err = err;	complete(&result->completion);}",14337
702,2147,CVE-2014-7822,25,"int sync_blockdev(struct block_device *bdev){	return __sync_blockdev(bdev, 1);}",14562
657,136,CVE-2012-2121,25,int kvm_iommu_unmap_guest(struct kvm *kvm){	struct iommu_domain *domain = kvm->arch.iommu_domain;	 	if (!domain)		return 0;	kvm_iommu_unmap_memslots(kvm);	iommu_domain_free(domain);	return 0;},3534
660,27,CVE-2015-8467,25,"static int samldb_fill_foreignSecurityPrincipal_object(struct samldb_ctx *ac){	struct ldb_context *ldb;	const struct ldb_val *rdn_value;	struct dom_sid *sid;	int ret;	ldb = ldb_module_get_ctx(ac->module);	sid = samdb_result_dom_sid(ac->msg, ac->msg, ""objectSid"");	if (sid == NULL) {		rdn_value = ldb_dn_get_rdn_val(ac->msg->dn);		if (rdn_value == NULL) {			return ldb_operr(ldb);		}		sid = dom_sid_parse_talloc(ac->msg,					   (const char *)rdn_value->data);		if (sid == NULL) {			ldb_set_errstring(ldb,					  ""samldb: No valid SID found in ForeignSecurityPrincipal CN!"");			return LDB_ERR_CONSTRAINT_VIOLATION;		}		if (! samldb_msg_add_sid(ac->msg, ""objectSid"", sid)) {			return ldb_operr(ldb);		}	}	 	ret = samldb_add_step(ac, samldb_add_entry);	if (ret != LDB_SUCCESS) return ret;	return samldb_first_step(ac);}",136
294,2495,CVE-2013-7421,25,"int ap_driver_register(struct ap_driver *ap_drv, struct module *owner,		       char *name){	struct device_driver *drv = &ap_drv->driver;	drv->bus = &ap_bus_type;	drv->probe = ap_device_probe;	drv->remove = ap_device_remove;	drv->owner = owner;	drv->name = name;	return driver_register(drv);}",14925
591,22,CVE-2015-8467,25,"static int check_rodc_critical_attribute(struct ldb_message *msg){	int schemaFlagsEx, searchFlags, rodc_filtered_flags;	schemaFlagsEx = ldb_msg_find_attr_as_uint(msg, ""schemaFlagsEx"", 0);	searchFlags = ldb_msg_find_attr_as_uint(msg, ""searchFlags"", 0);	rodc_filtered_flags = (SEARCH_FLAG_RODC_ATTRIBUTE			      | SEARCH_FLAG_CONFIDENTIAL);	if ((schemaFlagsEx & SCHEMA_FLAG_ATTR_IS_CRITICAL) &&		((searchFlags & rodc_filtered_flags) == rodc_filtered_flags)) {		return true;	} else {		return false;	}}",131
325,939,CVE-2013-6383,25,"static long aac_compat_cfg_ioctl(struct file *file, unsigned cmd, unsigned long arg){	if (!capable(CAP_SYS_RAWIO))		return -EPERM;	return aac_compat_do_ioctl(file->private_data, cmd, arg);}",7207
405,1894,CVE-2014-9644,25,"static struct crypto_instance *crypto_ccm_alloc_common(struct rtattr **tb,						       const char *full_name,						       const char *ctr_name,						       const char *cipher_name){	struct crypto_attr_type *algt;	struct crypto_instance *inst;	struct crypto_alg *ctr;	struct crypto_alg *cipher;	struct ccm_instance_ctx *ictx;	int err;	algt = crypto_get_attr_type(tb);	if (IS_ERR(algt))		return ERR_CAST(algt);	if ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)		return ERR_PTR(-EINVAL);	cipher = crypto_alg_mod_lookup(cipher_name,  CRYPTO_ALG_TYPE_CIPHER,				       CRYPTO_ALG_TYPE_MASK);	if (IS_ERR(cipher))		return ERR_CAST(cipher);	err = -EINVAL;	if (cipher->cra_blocksize != 16)		goto out_put_cipher;	inst = kzalloc(sizeof(*inst) + sizeof(*ictx), GFP_KERNEL);	err = -ENOMEM;	if (!inst)		goto out_put_cipher;	ictx = crypto_instance_ctx(inst);	err = crypto_init_spawn(&ictx->cipher, cipher, inst,				CRYPTO_ALG_TYPE_MASK);	if (err)		goto err_free_inst;	crypto_set_skcipher_spawn(&ictx->ctr, inst);	err = crypto_grab_skcipher(&ictx->ctr, ctr_name, 0,				   crypto_requires_sync(algt->type,							algt->mask));	if (err)		goto err_drop_cipher;	ctr = crypto_skcipher_spawn_alg(&ictx->ctr);	 	err = -EINVAL;	if (ctr->cra_blocksize != 1)		goto err_drop_ctr;	 	if (ctr->cra_ablkcipher.ivsize != 16)		goto err_drop_ctr;	err = -ENAMETOOLONG;	if (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,		     ""ccm_base(%s,%s)"", ctr->cra_driver_name,		     cipher->cra_driver_name) >= CRYPTO_MAX_ALG_NAME)		goto err_drop_ctr;	memcpy(inst->alg.cra_name, full_name, CRYPTO_MAX_ALG_NAME);	inst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;	inst->alg.cra_flags |= ctr->cra_flags & CRYPTO_ALG_ASYNC;	inst->alg.cra_priority = cipher->cra_priority + ctr->cra_priority;	inst->alg.cra_blocksize = 1;	inst->alg.cra_alignmask = cipher->cra_alignmask | ctr->cra_alignmask |				  (__alignof__(u32) - 1);	inst->alg.cra_type = &crypto_aead_type;	inst->alg.cra_aead.ivsize = 16;	inst->alg.cra_aead.maxauthsize = 16;	inst->alg.cra_ctxsize = sizeof(struct crypto_ccm_ctx);	inst->alg.cra_init = crypto_ccm_init_tfm;	inst->alg.cra_exit = crypto_ccm_exit_tfm;	inst->alg.cra_aead.setkey = crypto_ccm_setkey;	inst->alg.cra_aead.setauthsize = crypto_ccm_setauthsize;	inst->alg.cra_aead.encrypt = crypto_ccm_encrypt;	inst->alg.cra_aead.decrypt = crypto_ccm_decrypt;out:	crypto_mod_put(cipher);	return inst;err_drop_ctr:	crypto_drop_skcipher(&ictx->ctr);err_drop_cipher:	crypto_drop_spawn(&ictx->cipher);err_free_inst:	kfree(inst);out_put_cipher:	inst = ERR_PTR(err);	goto out;}",14228
127,1633,CVE-2014-3122,25,"int rmap_walk(struct page *page, struct rmap_walk_control *rwc){	if (unlikely(PageKsm(page)))		return rmap_walk_ksm(page, rwc);	else if (PageAnon(page))		return rmap_walk_anon(page, rwc);	else		return rmap_walk_file(page, rwc);}",11604
62,576,CVE-2011-4112,25,"static void macvlan_port_destroy(struct net_device *dev){	struct macvlan_port *port = macvlan_port_get(dev);	dev->priv_flags &= ~IFF_MACVLAN_PORT;	netdev_rx_handler_unregister(dev);	kfree_rcu(port, rcu);}",5301
465,1694,CVE-2014-1738,25,"static void redo_fd_request(void){	int drive;	int tmp;	lastredo = jiffies;	if (current_drive < N_DRIVE)		floppy_off(current_drive);do_request:	if (!current_req) {		int pending;		spin_lock_irq(&floppy_lock);		pending = set_next_request();		spin_unlock_irq(&floppy_lock);		if (!pending) {			do_floppy = NULL;			unlock_fdc();			return;		}	}	drive = (long)current_req->rq_disk->private_data;	set_fdc(drive);	reschedule_timeout(current_reqD, ""redo fd request"");	set_floppy(drive);	raw_cmd = &default_raw_cmd;	raw_cmd->flags = 0;	if (start_motor(redo_fd_request))		return;	disk_change(current_drive);	if (test_bit(current_drive, &fake_change) ||	    test_bit(FD_DISK_CHANGED_BIT, &DRS->flags)) {		DPRINT(""disk absent or changed during operation\n"");		request_done(0);		goto do_request;	}	if (!_floppy) {	 		if (!probing) {			DRS->probed_format = 0;			if (next_valid_format()) {				DPRINT(""no autodetectable formats\n"");				_floppy = NULL;				request_done(0);				goto do_request;			}		}		probing = 1;		_floppy = floppy_type + DP->autodetect[DRS->probed_format];	} else		probing = 0;	errors = &(current_req->errors);	tmp = make_raw_rw_request();	if (tmp < 2) {		request_done(tmp);		goto do_request;	}	if (test_bit(FD_NEED_TWADDLE_BIT, &DRS->flags))		twaddle();	schedule_bh(floppy_start);	debugt(__func__, ""queue fd request"");	return;}",11987
699,217,CVE-2012-1179,25,unsigned long task_vsize(struct mm_struct *mm){	return PAGE_SIZE * mm->total_vm;},3875
532,2832,CVE-2014-9922,25,"static void ovl_dentry_release(struct dentry *dentry){	struct ovl_entry *oe = dentry->d_fsdata;	if (oe) {		dput(oe->__upperdentry);		dput(oe->lowerdentry);		kfree_rcu(oe, rcu);	}}",23066
738,554,CVE-2011-4112,25,static inline int slave_enable_netpoll(struct slave *slave){	return 0;},5279
623,2650,CVE-2016-4565,25,"static int qib_compatible_subctxts(int user_swmajor, int user_swminor){	 	if (QIB_USER_SWMAJOR != user_swmajor) {		 		return 0;	}	if (QIB_USER_SWMAJOR == 1) {		switch (QIB_USER_SWMINOR) {		case 0:		case 1:		case 2:			 			return 0;		case 3:			 			return user_swminor == 3;		default:			 			return user_swminor <= QIB_USER_SWMINOR;		}	}	 	return 0;}",16804
481,248,CVE-2012-1179,25,"static void mem_cgroup_do_uncharge(struct mem_cgroup *memcg,				   unsigned int nr_pages,				   const enum charge_type ctype){	struct memcg_batch_info *batch = NULL;	int uncharge_memsw = true;	 	if (!do_swap_account || ctype == MEM_CGROUP_CHARGE_TYPE_SWAPOUT)		uncharge_memsw = false;	batch = &current->memcg_batch;	 	if (!batch->memcg)		batch->memcg = memcg;	 	if (!batch->do_batch || test_thread_flag(TIF_MEMDIE))		goto direct_uncharge;	if (nr_pages > 1)		goto direct_uncharge;	 	if (batch->memcg != memcg)		goto direct_uncharge;	 	batch->nr_pages++;	if (uncharge_memsw)		batch->memsw_nr_pages++;	return;direct_uncharge:	res_counter_uncharge(&memcg->res, nr_pages * PAGE_SIZE);	if (uncharge_memsw)		res_counter_uncharge(&memcg->memsw, nr_pages * PAGE_SIZE);	if (unlikely(batch->memcg != memcg))		memcg_oom_recover(memcg);	return;}",3906
654,2996,CVE-2016-2494,25,static void* start_handler(void* data){ struct fuse_handler* handler = data;    handle_fuse_requests(handler); return NULL;},30665
655,2496,CVE-2013-7421,25,void ap_driver_unregister(struct ap_driver *ap_drv){	driver_unregister(&ap_drv->driver);},14926
343,1406,CVE-2014-4014,25,struct inode *new_inode_pseudo(struct super_block *sb){	struct inode *inode = alloc_inode(sb);	if (inode) {		spin_lock(&inode->i_lock);		inode->i_state = 0;		spin_unlock(&inode->i_lock);		INIT_LIST_HEAD(&inode->i_sb_list);	}	return inode;},10952
632,2417,CVE-2013-7421,25,static void zlib_exit(struct crypto_tfm *tfm){	struct zlib_ctx *ctx = crypto_tfm_ctx(tfm);	zlib_comp_exit(ctx);	zlib_decomp_exit(ctx);},14847
92,656,CVE-2011-4112,25,"struct net_device *init_airo_card( unsigned short irq, int port, int is_pcmcia,				  struct device *dmdev){	return _init_airo_card ( irq, port, is_pcmcia, NULL, dmdev);}",5381
672,1352,CVE-2014-4943,25,"static int pppol2tp_session_setsockopt(struct sock *sk,				       struct l2tp_session *session,				       int optname, int val){	int err = 0;	struct pppol2tp_session *ps = l2tp_session_priv(session);	switch (optname) {	case PPPOL2TP_SO_RECVSEQ:		if ((val != 0) && (val != 1)) {			err = -EINVAL;			break;		}		session->recv_seq = val ? -1 : 0;		l2tp_info(session, PPPOL2TP_MSG_CONTROL,			  ""%s: set recv_seq=%d\n"",			  session->name, session->recv_seq);		break;	case PPPOL2TP_SO_SENDSEQ:		if ((val != 0) && (val != 1)) {			err = -EINVAL;			break;		}		session->send_seq = val ? -1 : 0;		{			struct sock *ssk      = ps->sock;			struct pppox_sock *po = pppox_sk(ssk);			po->chan.hdrlen = val ? PPPOL2TP_L2TP_HDR_SIZE_SEQ :				PPPOL2TP_L2TP_HDR_SIZE_NOSEQ;		}		l2tp_session_set_header_len(session, session->tunnel->version);		l2tp_info(session, PPPOL2TP_MSG_CONTROL,			  ""%s: set send_seq=%d\n"",			  session->name, session->send_seq);		break;	case PPPOL2TP_SO_LNSMODE:		if ((val != 0) && (val != 1)) {			err = -EINVAL;			break;		}		session->lns_mode = val ? -1 : 0;		l2tp_info(session, PPPOL2TP_MSG_CONTROL,			  ""%s: set lns_mode=%d\n"",			  session->name, session->lns_mode);		break;	case PPPOL2TP_SO_DEBUG:		session->debug = val;		l2tp_info(session, PPPOL2TP_MSG_CONTROL, ""%s: set debug=%x\n"",			  session->name, session->debug);		break;	case PPPOL2TP_SO_REORDERTO:		session->reorder_timeout = msecs_to_jiffies(val);		l2tp_info(session, PPPOL2TP_MSG_CONTROL,			  ""%s: set reorder_timeout=%d\n"",			  session->name, session->reorder_timeout);		break;	default:		err = -ENOPROTOOPT;		break;	}	return err;}",10799
209,537,CVE-2011-4112,25,"static void bond_set_lockdep_class_one(struct net_device *dev,				       struct netdev_queue *txq,				       void *_unused){	lockdep_set_class(&txq->_xmit_lock,			  &bonding_netdev_xmit_lock_key);}",5262
240,1510,CVE-2014-3610,25,"static void svm_get_idt(struct kvm_vcpu *vcpu, struct desc_ptr *dt){	struct vcpu_svm *svm = to_svm(vcpu);	dt->size = svm->vmcb->save.idtr.limit;	dt->address = svm->vmcb->save.idtr.base;}",11372
64,841,CVE-2011-2495,25,"static struct dentry *proc_lookupfdinfo(struct inode *dir,					struct dentry *dentry,					struct nameidata *nd){	return proc_lookupfd_common(dir, dentry, proc_fdinfo_instantiate);}",6638
447,1784,CVE-2015-1593,25,static unsigned long mmap_base(void){	unsigned long gap = rlimit(RLIMIT_STACK);	if (gap < MIN_GAP)		gap = MIN_GAP;	else if (gap > MAX_GAP)		gap = MAX_GAP;	return PAGE_ALIGN(TASK_SIZE - gap - mmap_rnd());},13817
175,1495,CVE-2014-3610,25,"static void svm_clear_vintr(struct vcpu_svm *svm){	clr_intercept(svm, INTERCEPT_VINTR);}",11357
315,2099,CVE-2014-9644,25,"static void seqiv_complete(struct crypto_async_request *base, int err){	struct skcipher_givcrypt_request *req = base->data;	seqiv_complete2(req, err);	skcipher_givcrypt_complete(req, err);}",14433
55,1609,CVE-2014-3122,25,"static inline void anon_vma_free(struct anon_vma *anon_vma){	VM_BUG_ON(atomic_read(&anon_vma->refcount));	 	if (rwsem_is_locked(&anon_vma->root->rwsem)) {		anon_vma_lock_write(anon_vma);		anon_vma_unlock_write(anon_vma);	}	kmem_cache_free(anon_vma_cachep, anon_vma);}",11580
731,2012,CVE-2014-9644,25,"static int crypto_rfc4543_decrypt(struct aead_request *req){	int err;	if (req->src != req->dst) {		err = crypto_rfc4543_copy_src_to_dst(req, false);		if (err)			return err;	}	req = crypto_rfc4543_crypt(req, false);	return crypto_aead_decrypt(req);}",14346
56,2309,CVE-2013-7421,25,"static int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,		     struct scatterlist *src, unsigned int nbytes){	return glue_ctr_crypt_128bit(&cast6_ctr, desc, dst, src, nbytes);}",14739
326,2358,CVE-2013-7421,25,"static int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,		       struct scatterlist *src, unsigned int nbytes){	struct twofish_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);	return glue_xts_crypt_128bit(&twofish_enc_xts, desc, dst, src, nbytes,				     XTS_TWEAK_CAST(twofish_enc_blk),				     &ctx->tweak_ctx, &ctx->crypt_ctx);}",14788
233,1482,CVE-2014-3610,25,"static void recalc_intercepts(struct vcpu_svm *svm){	struct vmcb_control_area *c, *h;	struct nested_state *g;	mark_dirty(svm->vmcb, VMCB_INTERCEPTS);	if (!is_guest_mode(&svm->vcpu))		return;	c = &svm->vmcb->control;	h = &svm->nested.hsave->control;	g = &svm->nested;	c->intercept_cr = h->intercept_cr | g->intercept_cr;	c->intercept_dr = h->intercept_dr | g->intercept_dr;	c->intercept_exceptions = h->intercept_exceptions | g->intercept_exceptions;	c->intercept = h->intercept | g->intercept;}",11344
211,880,CVE-2011-2486,25,"g_NPN_MemAlloc(int size){  D(bugiI(""NPN_MemAlloc size=%d\n"", size));  void *ptr = NPW_MemAlloc(size);  D(bugiD(""NPN_MemAlloc return: %p\n"", ptr));  return ptr;}",6690
278,2924,CVE-2011-3084,25,   void set_privileged_process_id(int process_id) {    browser_client_.set_privileged_process_id(process_id);  },29326
305,2518,CVE-2016-9566,25,int close_debug_log(void) {	if(debug_file_fp != NULL)		fclose(debug_file_fp);	debug_file_fp = NULL;	return OK;	},15163
176,245,CVE-2012-1179,25,"void mem_cgroup_count_vm_event(struct mm_struct *mm, enum vm_event_item idx){	struct mem_cgroup *memcg;	if (!mm)		return;	rcu_read_lock();	memcg = mem_cgroup_from_task(rcu_dereference(mm->owner));	if (unlikely(!memcg))		goto out;	switch (idx) {	case PGFAULT:		this_cpu_inc(memcg->stat->events[MEM_CGROUP_EVENTS_PGFAULT]);		break;	case PGMAJFAULT:		this_cpu_inc(memcg->stat->events[MEM_CGROUP_EVENTS_PGMAJFAULT]);		break;	default:		BUG();	}out:	rcu_read_unlock();}",3903
496,2631,CVE-2016-4565,25,"static void ucma_set_event_context(struct ucma_context *ctx,				   struct rdma_cm_event *event,				   struct ucma_event *uevent){	uevent->ctx = ctx;	switch (event->event) {	case RDMA_CM_EVENT_MULTICAST_JOIN:	case RDMA_CM_EVENT_MULTICAST_ERROR:		uevent->mc = (struct ucma_multicast *)			     event->param.ud.private_data;		uevent->resp.uid = uevent->mc->uid;		uevent->resp.id = uevent->mc->id;		break;	default:		uevent->resp.uid = ctx->uid;		uevent->resp.id = ctx->id;		break;	}}",16785
243,1046,CVE-2013-1957,25,"struct vfsmount *collect_mounts(struct path *path){	struct mount *tree;	down_write(&namespace_sem);	tree = copy_tree(real_mount(path->mnt), path->dentry,			 CL_COPY_ALL | CL_PRIVATE);	up_write(&namespace_sem);	if (IS_ERR(tree))		return NULL;	return &tree->mnt;}",9127
270,2431,CVE-2013-7421,25,"static int padlock_sha_import_nano(struct shash_desc *desc,				const void *in){	int statesize = crypto_shash_statesize(desc->tfm);	void *sctx = shash_desc_ctx(desc);	memcpy(sctx, in, statesize);	return 0;}",14861
616,2972,CVE-2019-5779,25,"  void AppendContentBrowserClientSwitches() {    client_.AppendExtraCommandLineSwitches(&command_line_, kFakeChildProcessId);  }",30235
730,1491,CVE-2014-3610,25,"static int stgi_interception(struct vcpu_svm *svm){	if (nested_svm_check_permissions(svm))		return 1;	svm->next_rip = kvm_rip_read(&svm->vcpu) + 3;	skip_emulated_instruction(&svm->vcpu);	kvm_make_request(KVM_REQ_EVENT, &svm->vcpu);	enable_gif(svm);	return 1;}",11353
223,2769,CVE-2014-9870,25,"void exit_thread(void){	thread_notify(THREAD_NOTIFY_EXIT, current_thread_info());}",19318
755,807,CVE-2011-2495,25,"static struct mm_struct *__check_mem_permission(struct task_struct *task){	struct mm_struct *mm;	mm = get_task_mm(task);	if (!mm)		return ERR_PTR(-EINVAL);	 	if (task == current)		return mm;	 	if (task_is_stopped_or_traced(task)) {		int match;		rcu_read_lock();		match = (tracehook_tracer_task(task) == current);		rcu_read_unlock();		if (match && ptrace_may_access(task, PTRACE_MODE_ATTACH))			return mm;	}	 	mmput(mm);	return ERR_PTR(-EPERM);}",6604
161,487,CVE-2011-4127,25,static void flush_multipath_work(struct multipath *m){	flush_workqueue(kmpath_handlerd);	multipath_wait_for_pg_init_completion(m);	flush_workqueue(kmultipathd);	flush_work_sync(&m->trigger_event);},5212
670,2181,CVE-2014-7822,25,"int pipe_to_file(struct pipe_inode_info *pipe, struct pipe_buffer *buf,		 struct splice_desc *sd){	struct file *file = sd->u.file;	struct address_space *mapping = file->f_mapping;	unsigned int offset, this_len;	struct page *page;	void *fsdata;	int ret;	offset = sd->pos & ~PAGE_CACHE_MASK;	this_len = sd->len;	if (this_len + offset > PAGE_CACHE_SIZE)		this_len = PAGE_CACHE_SIZE - offset;	ret = pagecache_write_begin(file, mapping, sd->pos, this_len,				AOP_FLAG_UNINTERRUPTIBLE, &page, &fsdata);	if (unlikely(ret))		goto out;	if (buf->page != page) {		char *src = kmap_atomic(buf->page);		char *dst = kmap_atomic(page);		memcpy(dst + offset, src + buf->offset, this_len);		flush_dcache_page(page);		kunmap_atomic(dst);		kunmap_atomic(src);	}	ret = pagecache_write_end(file, mapping, sd->pos, this_len, this_len,				page, fsdata);out:	return ret;}",14596
506,2344,CVE-2013-7421,25,"static int sha256_ssse3_import(struct shash_desc *desc, const void *in){	struct sha256_state *sctx = shash_desc_ctx(desc);	memcpy(sctx, in, sizeof(*sctx));	return 0;}",14774
149,5,CVE-2015-8467,25,"static int samldb_fill_foreignSecurityPrincipal_object(struct samldb_ctx *ac){	struct ldb_context *ldb;	const struct ldb_val *rdn_value;	struct dom_sid *sid;	int ret;	ldb = ldb_module_get_ctx(ac->module);	sid = samdb_result_dom_sid(ac->msg, ac->msg, ""objectSid"");	if (sid == NULL) {		rdn_value = ldb_dn_get_rdn_val(ac->msg->dn);		if (rdn_value == NULL) {			return ldb_operr(ldb);		}		sid = dom_sid_parse_talloc(ac->msg,					   (const char *)rdn_value->data);		if (sid == NULL) {			ldb_set_errstring(ldb,					  ""samldb: No valid SID found in ForeignSecurityPrincipal CN!"");			return LDB_ERR_CONSTRAINT_VIOLATION;		}		if (! samldb_msg_add_sid(ac->msg, ""objectSid"", sid)) {			return ldb_operr(ldb);		}	}	 	ret = samldb_add_step(ac, samldb_add_entry);	if (ret != LDB_SUCCESS) return ret;	return samldb_first_step(ac);}",6
550,1607,CVE-2014-3122,25,"static void anon_vma_ctor(void *data){	struct anon_vma *anon_vma = data;	init_rwsem(&anon_vma->rwsem);	atomic_set(&anon_vma->refcount, 0);	anon_vma->rb_root = RB_ROOT;}",11578
587,2241,CVE-2013-7421,25,"static int xts_fallback_decrypt(struct blkcipher_desc *desc,		struct scatterlist *dst, struct scatterlist *src,		unsigned int nbytes){	struct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);	struct crypto_blkcipher *tfm;	unsigned int ret;	tfm = desc->tfm;	desc->tfm = xts_ctx->fallback;	ret = crypto_blkcipher_decrypt_iv(desc, dst, src, nbytes);	desc->tfm = tfm;	return ret;}",14671
608,166,CVE-2012-2121,25,int kvm_is_error_hva(unsigned long addr){	return addr == bad_hva();},3564
387,2297,CVE-2013-7421,25,static int is_blacklisted_cpu(void){	if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)		return false;	if (boot_cpu_data.x86 == 0x0f) {		 		return true;	}	return false;},14727
634,514,CVE-2011-4112,25,"int bond_create(struct net *net, const char *name){	struct net_device *bond_dev;	int res;	rtnl_lock();	bond_dev = alloc_netdev_mq(sizeof(struct bonding),				   name ? name : ""bond%d"",				   bond_setup, tx_queues);	if (!bond_dev) {		pr_err(""%s: eek! can't alloc netdev!\n"", name);		rtnl_unlock();		return -ENOMEM;	}	dev_net_set(bond_dev, net);	bond_dev->rtnl_link_ops = &bond_link_ops;	res = register_netdevice(bond_dev);	netif_carrier_off(bond_dev);	rtnl_unlock();	if (res < 0)		bond_destructor(bond_dev);	return res;}",5239
613,1873,CVE-2014-9644,25,static void crypto_authenc_free(struct crypto_instance *inst){	struct authenc_instance_ctx *ctx = crypto_instance_ctx(inst);	crypto_drop_skcipher(&ctx->enc);	crypto_drop_ahash(&ctx->auth);	kfree(inst);},14207
364,1804,CVE-2015-1344,25,"static int cg_rmdir(const char *path){	struct fuse_context *fc = fuse_get_context();	char *fpath = NULL, *cgdir = NULL, *controller, *next = NULL;	const char *cgroup;	int ret;	if (!fc)		return -EIO;	controller = pick_controller_from_path(fc, path);	if (!controller)		return -EINVAL;	cgroup = find_cgroup_in_path(path);	if (!cgroup)		return -EINVAL;	get_cgdir_and_path(cgroup, &cgdir, &fpath);	if (!fpath) {		ret = -EINVAL;		goto out;	}	if (!caller_is_in_ancestor(fc->pid, controller, cgroup, &next)) {		if (!fpath || strcmp(next, fpath) == 0)			ret = -EBUSY;		else			ret = -ENOENT;		goto out;	}	if (!fc_may_access(fc, controller, cgdir, NULL, O_WRONLY)) {		ret = -EACCES;		goto out;	}	if (!caller_is_in_ancestor(fc->pid, controller, cgroup, NULL)) {		ret = -EACCES;		goto out;	}	if (!cgfs_remove(controller, cgroup)) {		ret = -EINVAL;		goto out;	}	ret = 0;out:	free(cgdir);	free(next);	return ret;}",13864
484,322,CVE-2012-1179,25,"int access_remote_vm(struct mm_struct *mm, unsigned long addr,		void *buf, int len, int write){	return __access_remote_vm(NULL, mm, addr, buf, len, write);}",3980
318,1409,CVE-2014-4014,25,"void set_nlink(struct inode *inode, unsigned int nlink){	if (!nlink) {		clear_nlink(inode);	} else {		 		if (inode->i_nlink == 0)			atomic_long_dec(&inode->i_sb->s_remove_count);		inode->__i_nlink = nlink;	}}",10955
517,1605,CVE-2014-3122,25,"static void anon_vma_chain_free(struct anon_vma_chain *anon_vma_chain){	kmem_cache_free(anon_vma_chain_cachep, anon_vma_chain);}",11576
666,2036,CVE-2014-9644,25,"static int hmac_export(struct shash_desc *pdesc, void *out){	struct shash_desc *desc = shash_desc_ctx(pdesc);	desc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;	return crypto_shash_export(desc, out);}",14370
707,1683,CVE-2014-1738,25,"static void motor_off_callback(unsigned long nr){	unsigned char mask = ~(0x10 << UNIT(nr));	set_dor(FDC(nr), mask, 0);}",11976
541,2125,CVE-2014-7822,25,"static struct block_device *bd_start_claiming(struct block_device *bdev,					      void *holder){	struct gendisk *disk;	struct block_device *whole;	int partno, err;	might_sleep();	 	disk = get_gendisk(bdev->bd_dev, &partno);	if (!disk)		return ERR_PTR(-ENXIO);	 	if (partno)		whole = bdget_disk(disk, 0);	else		whole = bdgrab(bdev);	module_put(disk->fops->owner);	put_disk(disk);	if (!whole)		return ERR_PTR(-ENOMEM);	 	spin_lock(&bdev_lock);	err = bd_prepare_to_claim(bdev, whole, holder);	if (err == 0) {		whole->bd_claiming = holder;		spin_unlock(&bdev_lock);		return whole;	} else {		spin_unlock(&bdev_lock);		bdput(whole);		return ERR_PTR(err);	}}",14540
331,524,CVE-2011-4112,25,"const char *bond_mode_name(int mode){	static const char *names[] = {		[BOND_MODE_ROUNDROBIN] = ""load balancing (round-robin)"",		[BOND_MODE_ACTIVEBACKUP] = ""fault-tolerance (active-backup)"",		[BOND_MODE_XOR] = ""load balancing (xor)"",		[BOND_MODE_BROADCAST] = ""fault-tolerance (broadcast)"",		[BOND_MODE_8023AD] = ""IEEE 802.3ad Dynamic link aggregation"",		[BOND_MODE_TLB] = ""transmit load balancing"",		[BOND_MODE_ALB] = ""adaptive load balancing"",	};	if (mode < 0 || mode > BOND_MODE_ALB)		return ""unknown"";	return names[mode];}",5249
94,2606,CVE-2016-4565,25,"static struct ib_ucm_context *ib_ucm_ctx_alloc(struct ib_ucm_file *file){	struct ib_ucm_context *ctx;	ctx = kzalloc(sizeof *ctx, GFP_KERNEL);	if (!ctx)		return NULL;	atomic_set(&ctx->ref, 1);	init_completion(&ctx->comp);	ctx->file = file;	INIT_LIST_HEAD(&ctx->events);	mutex_lock(&ctx_id_mutex);	ctx->id = idr_alloc(&ctx_id_table, ctx, 0, 0, GFP_KERNEL);	mutex_unlock(&ctx_id_mutex);	if (ctx->id < 0)		goto error;	list_add_tail(&ctx->file_list, &file->ctxs);	return ctx;error:	kfree(ctx);	return NULL;}",16760
523,1678,CVE-2014-1738,25,"static void is_alive(const char *func, const char *message){	 	if (test_bit(0, &fdc_busy) && command_status < 2 &&	    !delayed_work_pending(&fd_timeout)) {		DPRINT(""%s: timeout handler died.  %s\n"", func, message);	}}",11971
44,374,CVE-2012-1179,25,"static struct page *new_node_page(struct page *page, unsigned long node, int **x){	return alloc_pages_exact_node(node, GFP_HIGHUSER_MOVABLE, 0);}",4032
451,476,CVE-2011-4127,25,"static void linear_map_bio(struct dm_target *ti, struct bio *bio){	struct linear_c *lc = ti->private;	bio->bi_bdev = lc->dev->bdev;	if (bio_sectors(bio))		bio->bi_sector = linear_map_sector(ti, bio->bi_sector);}",5201
21,2715,CVE-2015-8955,25,"armpmu_stop(struct perf_event *event, int flags){	struct arm_pmu *armpmu = to_arm_pmu(event->pmu);	struct hw_perf_event *hwc = &event->hw;	 	if (!(hwc->state & PERF_HES_STOPPED)) {		armpmu->disable(hwc, hwc->idx);		barrier();  		armpmu_event_update(event, hwc, hwc->idx);		hwc->state |= PERF_HES_STOPPED | PERF_HES_UPTODATE;	}}",18418
262,394,CVE-2012-1179,25,"static unsigned int find_next_to_unuse(struct swap_info_struct *si,					unsigned int prev){	unsigned int max = si->max;	unsigned int i = prev;	unsigned char count;	 	for (;;) {		if (++i >= max) {			if (!prev) {				i = 0;				break;			}			 			max = prev + 1;			prev = 0;			i = 1;		}		count = si->swap_map[i];		if (count && swap_count(count) != SWAP_MAP_BAD)			break;	}	return i;}",4052
378,2523,CVE-2016-9566,25,"int write_to_syslog(char *buffer, unsigned long data_type) {	if(buffer == NULL)		return ERROR;	 	if(verify_config || test_scheduling == TRUE)		return OK;	 	if(use_syslog == FALSE)		return OK;	 	if(!(data_type & syslog_options))		return OK;	 	syslog(LOG_USER | LOG_INFO, ""%s"", buffer);	return OK;	}",15168
736,673,CVE-2011-4112,25,"static int wll_header_parse(const struct sk_buff *skb, unsigned char *haddr){	memcpy(haddr, skb_mac_header(skb) + 10, ETH_ALEN);	return ETH_ALEN;}",5398
311,1295,CVE-2014-7826,25,"static void unreg_event_syscall_enter(struct ftrace_event_file *file,				      struct ftrace_event_call *call){	struct trace_array *tr = file->tr;	int num;	num = ((struct syscall_metadata *)call->data)->syscall_nr;	if (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))		return;	mutex_lock(&syscall_trace_lock);	tr->sys_refcount_enter--;	RCU_INIT_POINTER(tr->enter_syscall_files[num], NULL);	if (!tr->sys_refcount_enter)		unregister_trace_sys_enter(ftrace_syscall_enter, tr);	mutex_unlock(&syscall_trace_lock);}",10538
250,25,CVE-2015-8467,25,"static int samldb_check_sAMAccountName(struct samldb_ctx *ac){	struct ldb_context *ldb = ldb_module_get_ctx(ac->module);	const char *name;	int ret;	struct ldb_result *res;	const char * const noattrs[] = { NULL };	if (ldb_msg_find_element(ac->msg, ""sAMAccountName"") == NULL) {		ret = samldb_generate_sAMAccountName(ldb, ac->msg);		if (ret != LDB_SUCCESS) {			return ret;		}	}	name = ldb_msg_find_attr_as_string(ac->msg, ""sAMAccountName"", NULL);	if (name == NULL) {		 		ldb_set_errstring(ldb,				  ""samldb: Empty account names aren't allowed!"");		return LDB_ERR_CONSTRAINT_VIOLATION;	}	ret = dsdb_module_search(ac->module, ac, &res,				 ldb_get_default_basedn(ldb), LDB_SCOPE_SUBTREE, noattrs,				 DSDB_FLAG_NEXT_MODULE,				 ac->req,				 ""(sAMAccountName=%s)"",				 ldb_binary_encode_string(ac, name));	if (ret != LDB_SUCCESS) {		return ret;	}	if (res->count != 0) {		ldb_asprintf_errstring(ldb,				       ""samldb: Account name (sAMAccountName) '%s' already in use!"",				       name);		talloc_free(res);		return LDB_ERR_ENTRY_ALREADY_EXISTS;	}	talloc_free(res);	return samldb_next_step(ac);}",134
182,795,CVE-2011-2898,25,static void packet_mm_open(struct vm_area_struct *vma){	struct file *file = vma->vm_file;	struct socket *sock = file->private_data;	struct sock *sk = sock->sk;	if (sk)		atomic_inc(&pkt_sk(sk)->mapped);},6505
185,2782,CVE-2014-9870,25,"void __bad_xchg(volatile void *ptr, int size){	printk(""xchg: bad data size: pc 0x%p, ptr 0x%p, size %d\n"",		__builtin_return_address(0), ptr, size);	BUG();}",19331
354,1693,CVE-2014-1738,25,"static void raw_cmd_free(struct floppy_raw_cmd **ptr){	struct floppy_raw_cmd *next;	struct floppy_raw_cmd *this;	this = *ptr;	*ptr = NULL;	while (this) {		if (this->buffer_length) {			fd_dma_mem_free((unsigned long)this->kernel_data,					this->buffer_length);			this->buffer_length = 0;		}		next = this->next;		kfree(this);		this = next;	}}",11986
770,2878,CVE-2011-4127,25,"static int read_capacity_16(struct scsi_disk *sdkp, struct scsi_device *sdp,						unsigned char *buffer){	unsigned char cmd[16];	struct scsi_sense_hdr sshdr;	int sense_valid = 0;	int the_result;	int retries = 3, reset_retries = READ_CAPACITY_RETRIES_ON_RESET;	unsigned int alignment;	unsigned long long lba;	unsigned sector_size;	if (sdp->no_read_capacity_16)		return -EINVAL;	do {		memset(cmd, 0, 16);		cmd[0] = SERVICE_ACTION_IN;		cmd[1] = SAI_READ_CAPACITY_16;		cmd[13] = RC16_LEN;		memset(buffer, 0, RC16_LEN);		the_result = scsi_execute_req(sdp, cmd, DMA_FROM_DEVICE,					buffer, RC16_LEN, &sshdr,					SD_TIMEOUT, SD_MAX_RETRIES, NULL);		if (media_not_present(sdkp, &sshdr))			return -ENODEV;		if (the_result) {			sense_valid = scsi_sense_valid(&sshdr);			if (sense_valid &&			    sshdr.sense_key == ILLEGAL_REQUEST &&			    (sshdr.asc == 0x20 || sshdr.asc == 0x24) &&			    sshdr.ascq == 0x00)				 				return -EINVAL;			if (sense_valid &&			    sshdr.sense_key == UNIT_ATTENTION &&			    sshdr.asc == 0x29 && sshdr.ascq == 0x00)				 				if (--reset_retries > 0)					continue;		}		retries--;	} while (the_result && retries);	if (the_result) {		sd_printk(KERN_NOTICE, sdkp, ""READ CAPACITY(16) failed\n"");		read_capacity_error(sdkp, sdp, &sshdr, sense_valid, the_result);		return -EINVAL;	}	sector_size = get_unaligned_be32(&buffer[8]);	lba = get_unaligned_be64(&buffer[0]);	sd_read_protection_type(sdkp, buffer);	if ((sizeof(sdkp->capacity) == 4) && (lba >= 0xffffffffULL)) {		sd_printk(KERN_ERR, sdkp, ""Too big for this kernel. Use a ""			""kernel compiled with support for large block ""			""devices.\n"");		sdkp->capacity = 0;		return -EOVERFLOW;	}	 	sdkp->physical_block_size = (1 << (buffer[13] & 0xf)) * sector_size;	 	alignment = ((buffer[14] & 0x3f) << 8 | buffer[15]) * sector_size;	blk_queue_alignment_offset(sdp->request_queue, alignment);	if (alignment && sdkp->first_scan)		sd_printk(KERN_NOTICE, sdkp,			  ""physical block alignment offset: %u\n"", alignment);	if (buffer[14] & 0x80) {  		sdkp->lbpme = 1;		if (buffer[14] & 0x40)  			sdkp->lbprz = 1;		sd_config_discard(sdkp, SD_LBP_WS16);	}	sdkp->capacity = lba + 1;	return sector_size;}",28261
719,1101,CVE-2013-1957,25,int our_mnt(struct vfsmount *mnt){	return check_mnt(real_mount(mnt));},9182
662,2704,CVE-2015-8955,25,"armpmu_del(struct perf_event *event, int flags){	struct arm_pmu *armpmu = to_arm_pmu(event->pmu);	struct pmu_hw_events *hw_events = armpmu->get_hw_events();	struct hw_perf_event *hwc = &event->hw;	int idx = hwc->idx;	WARN_ON(idx < 0);	armpmu_stop(event, PERF_EF_UPDATE);	hw_events->events[idx] = NULL;	clear_bit(idx, hw_events->used_mask);	perf_event_update_userpage(event);}",18407
455,1650,CVE-2014-1738,25,static void empty(void){},11943
97,1803,CVE-2015-1344,25,"static int cg_releasedir(const char *path, struct fuse_file_info *fi){	struct file_info *d = (struct file_info *)fi->fh;	do_release_file_info(d);	return 0;}",13863
184,2089,CVE-2014-9644,25,"static void pcrypt_fini_padata(struct padata_pcrypt *pcrypt){	free_cpumask_var(pcrypt->cb_cpumask->mask);	kfree(pcrypt->cb_cpumask);	padata_stop(pcrypt->pinst);	padata_unregister_cpumask_notifier(pcrypt->pinst, &pcrypt->nblock);	destroy_workqueue(pcrypt->wq);	padata_free(pcrypt->pinst);}",14423
259,2959,CVE-2016-1631,25,  void set_quit_called() { quit_called_ = true; },29750
635,1674,CVE-2014-1738,25,static void generic_failure(void){	cont->done(0);},11967
164,309,CVE-2012-1179,25,"static int register_memsw_files(struct cgroup *cont, struct cgroup_subsys *ss){	return 0;}",3967
374,1227,CVE-2011-1019,25,static inline void net_timestamp_check(struct sk_buff *skb){	if (!skb->tstamp.tv64 && atomic_read(&netstamp_needed))		__net_timestamp(skb);},10316
576,183,CVE-2012-2121,25,"void kvm_vcpu_block(struct kvm_vcpu *vcpu){	DEFINE_WAIT(wait);	for (;;) {		prepare_to_wait(&vcpu->wq, &wait, TASK_INTERRUPTIBLE);		if (kvm_arch_vcpu_runnable(vcpu)) {			kvm_make_request(KVM_REQ_UNHALT, vcpu);			break;		}		if (kvm_cpu_has_pending_timer(vcpu))			break;		if (signal_pending(current))			break;		schedule();	}	finish_wait(&vcpu->wq, &wait);}",3581
279,908,CVE-2011-2211,25,SYSCALL_DEFINE0(getdtablesize){	return sysctl_nr_open;},6718
282,2100,CVE-2014-9644,25,"static void seqiv_complete2(struct skcipher_givcrypt_request *req, int err){	struct ablkcipher_request *subreq = skcipher_givcrypt_reqctx(req);	struct crypto_ablkcipher *geniv;	if (err == -EINPROGRESS)		return;	if (err)		goto out;	geniv = skcipher_givcrypt_reqtfm(req);	memcpy(req->creq.info, subreq->info, crypto_ablkcipher_ivsize(geniv));out:	kfree(subreq->info);}",14434
417,2420,CVE-2013-7421,25,"static inline struct aes_ctx *aes_ctx_common(void *ctx){	unsigned long addr = (unsigned long)ctx;	unsigned long align = PADLOCK_ALIGNMENT;	if (align <= crypto_tfm_ctx_alignment())		align = 1;	return (struct aes_ctx *)ALIGN(addr, align);}",14850
375,2215,CVE-2013-7421,25,"static int sha1_neon_export(struct shash_desc *desc, void *out){	struct sha1_state *sctx = shash_desc_ctx(desc);	memcpy(out, sctx, sizeof(*sctx));	return 0;}",14645
435,2087,CVE-2014-9644,25,"static struct crypto_instance *pcrypt_alloc_instance(struct crypto_alg *alg){	struct crypto_instance *inst;	struct pcrypt_instance_ctx *ctx;	int err;	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);	if (!inst) {		inst = ERR_PTR(-ENOMEM);		goto out;	}	err = -ENAMETOOLONG;	if (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,		     ""pcrypt(%s)"", alg->cra_driver_name) >= CRYPTO_MAX_ALG_NAME)		goto out_free_inst;	memcpy(inst->alg.cra_name, alg->cra_name, CRYPTO_MAX_ALG_NAME);	ctx = crypto_instance_ctx(inst);	err = crypto_init_spawn(&ctx->spawn, alg, inst,				CRYPTO_ALG_TYPE_MASK);	if (err)		goto out_free_inst;	inst->alg.cra_priority = alg->cra_priority + 100;	inst->alg.cra_blocksize = alg->cra_blocksize;	inst->alg.cra_alignmask = alg->cra_alignmask;out:	return inst;out_free_inst:	kfree(inst);	inst = ERR_PTR(err);	goto out;}",14421
330,951,CVE-2013-4300,25,"static int scm_fp_copy(struct cmsghdr *cmsg, struct scm_fp_list **fplp){	int *fdp = (int*)CMSG_DATA(cmsg);	struct scm_fp_list *fpl = *fplp;	struct file **fpp;	int i, num;	num = (cmsg->cmsg_len - CMSG_ALIGN(sizeof(struct cmsghdr)))/sizeof(int);	if (num <= 0)		return 0;	if (num > SCM_MAX_FD)		return -EINVAL;	if (!fpl)	{		fpl = kmalloc(sizeof(struct scm_fp_list), GFP_KERNEL);		if (!fpl)			return -ENOMEM;		*fplp = fpl;		fpl->count = 0;		fpl->max = SCM_MAX_FD;	}	fpp = &fpl->fp[fpl->count];	if (fpl->count + num > fpl->max)		return -EINVAL;	 	for (i=0; i< num; i++)	{		int fd = fdp[i];		struct file *file;		if (fd < 0 || !(file = fget_raw(fd)))			return -EBADF;		*fpp++ = file;		fpl->count++;	}	return num;}",7848
711,2870,CVE-2019-13272,25,"static void ptrace_unfreeze_traced(struct task_struct *task){	if (task->state != __TASK_TRACED)		return;	WARN_ON(!task->ptrace || task->parent != current);	 	spin_lock_irq(&task->sighand->siglock);	if (task->state == __TASK_TRACED) {		if (__fatal_signal_pending(task))			wake_up_state(task, __TASK_TRACED);		else			task->state = TASK_TRACED;	}	spin_unlock_irq(&task->sighand->siglock);}",26730
109,2433,CVE-2013-7421,25,"static void adf_chr_drv_destroy(void){	device_destroy(adt_ctl_drv.drv_class, MKDEV(adt_ctl_drv.major, 0));	cdev_del(&adt_ctl_drv.drv_cdev);	class_destroy(adt_ctl_drv.drv_class);	unregister_chrdev_region(MKDEV(adt_ctl_drv.major, 0), 1);}",14863
118,975,CVE-2013-2930,25,"static void perf_trace_event_close(struct perf_event *p_event){	struct ftrace_event_call *tp_event = p_event->tp_event;	tp_event->class->reg(tp_event, TRACE_REG_PERF_CLOSE, p_event);}",8429
749,24,CVE-2015-8467,25,"static int samldb_allocate_sid(struct samldb_ctx *ac){	int rid;	struct dom_sid *sid;	struct ldb_context *ldb = ldb_module_get_ctx(ac->module);	int ret;	ret = ridalloc_allocate_rid(ac->module, &rid, ac->req);	if (ret != LDB_SUCCESS) {		return ret;	}	sid = dom_sid_add_rid(ac, samdb_domain_sid(ldb), rid);	if (sid == NULL) {		return ldb_module_oom(ac->module);	}	if ( ! samldb_msg_add_sid(ac->msg, ""objectSid"", sid)) {		return ldb_operr(ldb);	}	return samldb_next_step(ac);}",133
306,1870,CVE-2014-9644,25,"static void authenc_verify_ahash_update_done(struct crypto_async_request *areq,					     int err){	u8 *ihash;	unsigned int authsize;	struct ablkcipher_request *abreq;	struct aead_request *req = areq->data;	struct crypto_aead *authenc = crypto_aead_reqtfm(req);	struct crypto_authenc_ctx *ctx = crypto_aead_ctx(authenc);	struct authenc_request_ctx *areq_ctx = aead_request_ctx(req);	struct ahash_request *ahreq = (void *)(areq_ctx->tail + ctx->reqoff);	unsigned int cryptlen = req->cryptlen;	if (err)		goto out;	ahash_request_set_crypt(ahreq, areq_ctx->sg, ahreq->result,				areq_ctx->cryptlen);	ahash_request_set_callback(ahreq, aead_request_flags(req) &					  CRYPTO_TFM_REQ_MAY_SLEEP,				   areq_ctx->complete, req);	err = crypto_ahash_finup(ahreq);	if (err)		goto out;	authsize = crypto_aead_authsize(authenc);	cryptlen -= authsize;	ihash = ahreq->result + authsize;	scatterwalk_map_and_copy(ihash, areq_ctx->sg, areq_ctx->cryptlen,				 authsize, 0);	err = crypto_memneq(ihash, ahreq->result, authsize) ? -EBADMSG : 0;	if (err)		goto out;	abreq = aead_request_ctx(req);	ablkcipher_request_set_tfm(abreq, ctx->enc);	ablkcipher_request_set_callback(abreq, aead_request_flags(req),					req->base.complete, req->base.data);	ablkcipher_request_set_crypt(abreq, req->src, req->dst,				     cryptlen, req->iv);	err = crypto_ablkcipher_decrypt(abreq);out:	authenc_request_complete(req, err);}",14204
547,1033,CVE-2013-1959,25,"void free_user_ns(struct user_namespace *ns){	struct user_namespace *parent;	do {		parent = ns->parent;		proc_free_inum(ns->proc_inum);		kmem_cache_free(user_ns_cachep, ns);		ns = parent;	} while (atomic_dec_and_test(&parent->count));}",9114
754,204,CVE-2012-1179,25,"static inline void set_vflags_short(unsigned short flags, struct kernel_vm86_regs *regs){	set_flags(VFLAGS, flags, current->thread.v86mask);	set_flags(regs->pt.flags, flags, SAFE_MASK);	if (flags & X86_EFLAGS_IF)		set_IF(regs);	else		clear_IF(regs);}",3862
508,2620,CVE-2016-4565,25,"static void ucma_copy_conn_param(struct rdma_cm_id *id,				 struct rdma_conn_param *dst,				 struct rdma_ucm_conn_param *src){	dst->private_data = src->private_data;	dst->private_data_len = src->private_data_len;	dst->responder_resources =src->responder_resources;	dst->initiator_depth = src->initiator_depth;	dst->flow_control = src->flow_control;	dst->retry_count = src->retry_count;	dst->rnr_retry_count = src->rnr_retry_count;	dst->srq = src->srq;	dst->qp_num = src->qp_num;	dst->qkey = (id->route.addr.src_addr.ss_family == AF_IB) ? src->qkey : 0;}",16774
464,1761,CVE-2015-2150,25,"int xen_pcibk_config_init_dev(struct pci_dev *dev){	int err = 0;	struct xen_pcibk_dev_data *dev_data = pci_get_drvdata(dev);	dev_dbg(&dev->dev, ""initializing virtual configuration space\n"");	INIT_LIST_HEAD(&dev_data->config_fields);	err = xen_pcibk_config_header_add_fields(dev);	if (err)		goto out;	err = xen_pcibk_config_capability_add_fields(dev);	if (err)		goto out;	err = xen_pcibk_config_quirks_init(dev);out:	return err;}",13762
586,2201,CVE-2014-7822,25,"static int ubifs_readpage(struct file *file, struct page *page){	if (ubifs_bulk_read(page))		return 0;	do_readpage(page);	unlock_page(page);	return 0;}",14616
401,490,CVE-2011-4127,25,static void multipath_dtr(struct dm_target *ti){	struct multipath *m = ti->private;	flush_multipath_work(m);	free_multipath(m);},5215
479,2472,CVE-2013-7421,25,"static int hmac_sha1_digest(struct ahash_request *req){	int ret2, ret1;	ret1 = hmac_sha1_init(req);	if (ret1)		goto out;	ret1 = ahash_update(req);	ret2 = ahash_final(req);out:	return ret1 ? ret1 : ret2;}",14902
287,1767,CVE-2015-1867,25,"__xml_acl_mode_test(enum xml_private_flags allowed, enum xml_private_flags requested){    if(is_set(allowed, xpf_acl_deny)) {        return FALSE;    } else if(is_set(allowed, requested)) {        return TRUE;    } else if(is_set(requested, xpf_acl_read) && is_set(allowed, xpf_acl_write)) {        return TRUE;    } else if(is_set(requested, xpf_acl_create) && is_set(allowed, xpf_acl_write)) {        return TRUE;    } else if(is_set(requested, xpf_acl_create) && is_set(allowed, xpf_created)) {        return TRUE;    }    return FALSE;}",13770
84,2167,CVE-2014-7822,25,"static int gfs2_release(struct inode *inode, struct file *file){	struct gfs2_inode *ip = GFS2_I(inode);	kfree(file->private_data);	file->private_data = NULL;	if (!(file->f_mode & FMODE_WRITE))		return 0;	gfs2_rs_delete(ip, &inode->i_writecount);	return 0;}",14582
107,2572,CVE-2016-6787,25,"static void perf_remove_from_context(struct perf_event *event, int detach_group){	struct perf_event_context *ctx = event->ctx;	struct task_struct *task = ctx->task;	struct remove_event re = {		.event = event,		.detach_group = detach_group,	};	lockdep_assert_held(&ctx->mutex);	if (!task) {		 		cpu_function_call(event->cpu, __perf_remove_from_context, &re);		return;	}retry:	if (!task_function_call(task, __perf_remove_from_context, &re))		return;	raw_spin_lock_irq(&ctx->lock);	 	if (ctx->is_active) {		raw_spin_unlock_irq(&ctx->lock);		 		task = ctx->task;		goto retry;	}	 	if (detach_group)		perf_group_detach(event);	list_del_event(event, ctx);	raw_spin_unlock_irq(&ctx->lock);}",15977
254,674,CVE-2011-4112,25,"static int hostap_80211_header_parse(const struct sk_buff *skb,				     unsigned char *haddr){	memcpy(haddr, skb_mac_header(skb) + 10, ETH_ALEN);  	return ETH_ALEN;}",5399
35,155,CVE-2012-2121,25,"void kvm_flush_remote_tlbs(struct kvm *kvm){	int dirty_count = kvm->tlbs_dirty;	smp_mb();	if (make_all_cpus_request(kvm, KVM_REQ_TLB_FLUSH))		++kvm->stat.remote_tlb_flush;	cmpxchg(&kvm->tlbs_dirty, dirty_count, 0);}",3553
697,1420,CVE-2014-4014,25,"int has_capability(struct task_struct *t, int cap){	return has_ns_capability(t, &init_user_ns, cap);}",10966
123,1438,CVE-2014-3610,25,"static int cr_interception(struct vcpu_svm *svm){	int reg, cr;	unsigned long val;	int err;	if (!static_cpu_has(X86_FEATURE_DECODEASSISTS))		return emulate_on_interception(svm);	if (unlikely((svm->vmcb->control.exit_info_1 & CR_VALID) == 0))		return emulate_on_interception(svm);	reg = svm->vmcb->control.exit_info_1 & SVM_EXITINFO_REG_MASK;	cr = svm->vmcb->control.exit_code - SVM_EXIT_READ_CR0;	err = 0;	if (cr >= 16) {  		cr -= 16;		val = kvm_register_read(&svm->vcpu, reg);		switch (cr) {		case 0:			if (!check_selective_cr0_intercepted(svm, val))				err = kvm_set_cr0(&svm->vcpu, val);			else				return 1;			break;		case 3:			err = kvm_set_cr3(&svm->vcpu, val);			break;		case 4:			err = kvm_set_cr4(&svm->vcpu, val);			break;		case 8:			err = kvm_set_cr8(&svm->vcpu, val);			break;		default:			WARN(1, ""unhandled write to CR%d"", cr);			kvm_queue_exception(&svm->vcpu, UD_VECTOR);			return 1;		}	} else {  		switch (cr) {		case 0:			val = kvm_read_cr0(&svm->vcpu);			break;		case 2:			val = svm->vcpu.arch.cr2;			break;		case 3:			val = kvm_read_cr3(&svm->vcpu);			break;		case 4:			val = kvm_read_cr4(&svm->vcpu);			break;		case 8:			val = kvm_get_cr8(&svm->vcpu);			break;		default:			WARN(1, ""unhandled read from CR%d"", cr);			kvm_queue_exception(&svm->vcpu, UD_VECTOR);			return 1;		}		kvm_register_write(&svm->vcpu, reg, val);	}	kvm_complete_insn_gp(&svm->vcpu, err);	return 1;}",11300
0,2884,CVE-2011-4127,25,"static int scsi_setup_flush_cmnd(struct scsi_device *sdp, struct request *rq){	rq->timeout = SD_FLUSH_TIMEOUT;	rq->retries = SD_MAX_RETRIES;	rq->cmd[0] = SYNCHRONIZE_CACHE;	rq->cmd_len = 10;	return scsi_setup_blk_pc_cmnd(sdp, rq);}",28267
420,391,CVE-2012-1179,25,"static int claim_swapfile(struct swap_info_struct *p, struct inode *inode){	int error;	if (S_ISBLK(inode->i_mode)) {		p->bdev = bdgrab(I_BDEV(inode));		error = blkdev_get(p->bdev,				   FMODE_READ | FMODE_WRITE | FMODE_EXCL,				   sys_swapon);		if (error < 0) {			p->bdev = NULL;			return -EINVAL;		}		p->old_block_size = block_size(p->bdev);		error = set_blocksize(p->bdev, PAGE_SIZE);		if (error < 0)			return error;		p->flags |= SWP_BLKDEV;	} else if (S_ISREG(inode->i_mode)) {		p->bdev = inode->i_sb->s_bdev;		mutex_lock(&inode->i_mutex);		if (IS_SWAPFILE(inode))			return -EBUSY;	} else		return -EINVAL;	return 0;}",4049
355,2160,CVE-2014-7822,25,"void truncate_data_blocks(struct dnode_of_data *dn){	truncate_data_blocks_range(dn, ADDRS_PER_BLOCK);}",14575
188,721,CVE-2011-4112,25,"static int vlan_dev_set_mac_address(struct net_device *dev, void *p){	struct net_device *real_dev = vlan_dev_info(dev)->real_dev;	struct sockaddr *addr = p;	int err;	if (!is_valid_ether_addr(addr->sa_data))		return -EADDRNOTAVAIL;	if (!(dev->flags & IFF_UP))		goto out;	if (compare_ether_addr(addr->sa_data, real_dev->dev_addr)) {		err = dev_uc_add(real_dev, addr->sa_data);		if (err < 0)			return err;	}	if (compare_ether_addr(dev->dev_addr, real_dev->dev_addr))		dev_uc_del(real_dev, dev->dev_addr);out:	memcpy(dev->dev_addr, addr->sa_data, ETH_ALEN);	return 0;}",5446
54,17,CVE-2009-4411,25,"acl_get_file_mode(const char *path_p){	struct stat st;	if (stat(path_p, &st) != 0)		return NULL;	return acl_from_mode(st.st_mode);}",18
712,1991,CVE-2014-9644,25,"static void __gcm_hash_crypt_done(struct aead_request *req, int err){	struct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);	struct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;	unsigned int remain;	if (!err) {		remain = gcm_remain(gctx->cryptlen);		BUG_ON(!remain);		err = gcm_hash_remain(req, pctx, remain,				      gcm_hash_crypt_remain_done);		if (err == -EINPROGRESS || err == -EBUSY)			return;	}	__gcm_hash_crypt_remain_done(req, err);}",14325
690,191,CVE-2012-2121,25,"void vcpu_load(struct kvm_vcpu *vcpu){	int cpu;	mutex_lock(&vcpu->mutex);	if (unlikely(vcpu->pid != current->pids[PIDTYPE_PID].pid)) {		 		struct pid *oldpid = vcpu->pid;		struct pid *newpid = get_task_pid(current, PIDTYPE_PID);		rcu_assign_pointer(vcpu->pid, newpid);		synchronize_rcu();		put_pid(oldpid);	}	cpu = get_cpu();	preempt_notifier_register(&vcpu->preempt_notifier);	kvm_arch_vcpu_load(vcpu, cpu);	put_cpu();}",3589
671,875,CVE-2011-2486,25,"static inline int add_appcontext_input(int fd, int n){  return XtAppAddInput(x_app_context,					   fd,					   GUINT_TO_POINTER(XtInputWriteMask),					   xt_dummy_input_cb,					   GUINT_TO_POINTER(0xdead0000));}",6685
349,1031,CVE-2013-2929,25,static int ptrace_trapping_sleep_fn(void *flags){	schedule();	return 0;},8485
744,2222,CVE-2013-7421,25,"static int ccm_setauthsize(struct crypto_aead *tfm, unsigned int authsize){	if ((authsize & 1) || authsize < 4)		return -EINVAL;	return 0;}",14652
124,2964,CVE-2016-1632,25,  void DisableRecording() { provider_.OnRecordingDisabled(); },29755
412,1544,CVE-2014-3610,25,"static void svm_set_vintr(struct vcpu_svm *svm){	set_intercept(svm, INTERCEPT_VINTR);}",11406
675,668,CVE-2011-4112,25,"static int takedown_proc_entry( struct net_device *dev,				struct airo_info *apriv ) {	if ( !apriv->proc_entry->namelen ) return 0;	remove_proc_entry(""Stats"",apriv->proc_entry);	remove_proc_entry(""StatsDelta"",apriv->proc_entry);	remove_proc_entry(""Status"",apriv->proc_entry);	remove_proc_entry(""Config"",apriv->proc_entry);	remove_proc_entry(""SSID"",apriv->proc_entry);	remove_proc_entry(""APList"",apriv->proc_entry);	remove_proc_entry(""BSSList"",apriv->proc_entry);	remove_proc_entry(""WepKey"",apriv->proc_entry);	remove_proc_entry(apriv->proc_name,airo_entry);	return 0;}",5393
490,1357,CVE-2014-4943,25,"static int pppol2tp_tunnel_getsockopt(struct sock *sk,				      struct l2tp_tunnel *tunnel,				      int optname, int *val){	int err = 0;	switch (optname) {	case PPPOL2TP_SO_DEBUG:		*val = tunnel->debug;		l2tp_info(tunnel, PPPOL2TP_MSG_CONTROL, ""%s: get debug=%x\n"",			  tunnel->name, tunnel->debug);		break;	default:		err = -ENOPROTOOPT;		break;	}	return err;}",10804
350,665,CVE-2011-4112,25,"static int setup_proc_entry( struct net_device *dev,			     struct airo_info *apriv ) {	struct proc_dir_entry *entry;	 	strcpy(apriv->proc_name,dev->name);	apriv->proc_entry = proc_mkdir_mode(apriv->proc_name, airo_perm,					    airo_entry);	if (!apriv->proc_entry)		goto fail;	apriv->proc_entry->uid = proc_uid;	apriv->proc_entry->gid = proc_gid;	 	entry = proc_create_data(""StatsDelta"", S_IRUGO & proc_perm,				 apriv->proc_entry, &proc_statsdelta_ops, dev);	if (!entry)		goto fail_stats_delta;	entry->uid = proc_uid;	entry->gid = proc_gid;	 	entry = proc_create_data(""Stats"", S_IRUGO & proc_perm,				 apriv->proc_entry, &proc_stats_ops, dev);	if (!entry)		goto fail_stats;	entry->uid = proc_uid;	entry->gid = proc_gid;	 	entry = proc_create_data(""Status"", S_IRUGO & proc_perm,				 apriv->proc_entry, &proc_status_ops, dev);	if (!entry)		goto fail_status;	entry->uid = proc_uid;	entry->gid = proc_gid;	 	entry = proc_create_data(""Config"", proc_perm,				 apriv->proc_entry, &proc_config_ops, dev);	if (!entry)		goto fail_config;	entry->uid = proc_uid;	entry->gid = proc_gid;	 	entry = proc_create_data(""SSID"", proc_perm,				 apriv->proc_entry, &proc_SSID_ops, dev);	if (!entry)		goto fail_ssid;	entry->uid = proc_uid;	entry->gid = proc_gid;	 	entry = proc_create_data(""APList"", proc_perm,				 apriv->proc_entry, &proc_APList_ops, dev);	if (!entry)		goto fail_aplist;	entry->uid = proc_uid;	entry->gid = proc_gid;	 	entry = proc_create_data(""BSSList"", proc_perm,				 apriv->proc_entry, &proc_BSSList_ops, dev);	if (!entry)		goto fail_bsslist;	entry->uid = proc_uid;	entry->gid = proc_gid;	 	entry = proc_create_data(""WepKey"", proc_perm,				 apriv->proc_entry, &proc_wepkey_ops, dev);	if (!entry)		goto fail_wepkey;	entry->uid = proc_uid;	entry->gid = proc_gid;	return 0;fail_wepkey:	remove_proc_entry(""BSSList"", apriv->proc_entry);fail_bsslist:	remove_proc_entry(""APList"", apriv->proc_entry);fail_aplist:	remove_proc_entry(""SSID"", apriv->proc_entry);fail_ssid:	remove_proc_entry(""Config"", apriv->proc_entry);fail_config:	remove_proc_entry(""Status"", apriv->proc_entry);fail_status:	remove_proc_entry(""Stats"", apriv->proc_entry);fail_stats:	remove_proc_entry(""StatsDelta"", apriv->proc_entry);fail_stats_delta:	remove_proc_entry(apriv->proc_name, airo_entry);fail:	return -ENOMEM;}",5390
757,2448,CVE-2013-7421,25,"static int ux500_cryp_probe(struct platform_device *pdev){	int ret;	int cryp_error = 0;	struct resource *res = NULL;	struct resource *res_irq = NULL;	struct cryp_device_data *device_data;	struct cryp_protection_config prot = {		.privilege_access = CRYP_STATE_ENABLE	};	struct device *dev = &pdev->dev;	dev_dbg(dev, ""[%s]"", __func__);	device_data = kzalloc(sizeof(struct cryp_device_data), GFP_ATOMIC);	if (!device_data) {		dev_err(dev, ""[%s]: kzalloc() failed!"", __func__);		ret = -ENOMEM;		goto out;	}	device_data->dev = dev;	device_data->current_ctx = NULL;	 	mem_to_engine = &((struct cryp_platform_data *)			 dev->platform_data)->mem_to_engine;	engine_to_mem = &((struct cryp_platform_data *)			 dev->platform_data)->engine_to_mem;	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);	if (!res) {		dev_err(dev, ""[%s]: platform_get_resource() failed"",				__func__);		ret = -ENODEV;		goto out_kfree;	}	res = request_mem_region(res->start, resource_size(res), pdev->name);	if (res == NULL) {		dev_err(dev, ""[%s]: request_mem_region() failed"",				__func__);		ret = -EBUSY;		goto out_kfree;	}	device_data->phybase = res->start;	device_data->base = ioremap(res->start, resource_size(res));	if (!device_data->base) {		dev_err(dev, ""[%s]: ioremap failed!"", __func__);		ret = -ENOMEM;		goto out_free_mem;	}	spin_lock_init(&device_data->ctx_lock);	spin_lock_init(&device_data->power_state_spinlock);	 	device_data->pwr_regulator = regulator_get(&pdev->dev, ""v-ape"");	if (IS_ERR(device_data->pwr_regulator)) {		dev_err(dev, ""[%s]: could not get cryp regulator"", __func__);		ret = PTR_ERR(device_data->pwr_regulator);		device_data->pwr_regulator = NULL;		goto out_unmap;	}	 	device_data->clk = clk_get(&pdev->dev, NULL);	if (IS_ERR(device_data->clk)) {		dev_err(dev, ""[%s]: clk_get() failed!"", __func__);		ret = PTR_ERR(device_data->clk);		goto out_regulator;	}	ret = clk_prepare(device_data->clk);	if (ret) {		dev_err(dev, ""[%s]: clk_prepare() failed!"", __func__);		goto out_clk;	}	 	ret = cryp_enable_power(device_data->dev, device_data, false);	if (ret) {		dev_err(dev, ""[%s]: cryp_enable_power() failed!"", __func__);		goto out_clk_unprepare;	}	cryp_error = cryp_check(device_data);	if (cryp_error != 0) {		dev_err(dev, ""[%s]: cryp_init() failed!"", __func__);		ret = -EINVAL;		goto out_power;	}	cryp_error = cryp_configure_protection(device_data, &prot);	if (cryp_error != 0) {		dev_err(dev, ""[%s]: cryp_configure_protection() failed!"",			__func__);		ret = -EINVAL;		goto out_power;	}	res_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);	if (!res_irq) {		dev_err(dev, ""[%s]: IORESOURCE_IRQ unavailable"",			__func__);		ret = -ENODEV;		goto out_power;	}	ret = request_irq(res_irq->start,			  cryp_interrupt_handler,			  0,			  ""cryp1"",			  device_data);	if (ret) {		dev_err(dev, ""[%s]: Unable to request IRQ"", __func__);		goto out_power;	}	if (cryp_mode == CRYP_MODE_DMA)		cryp_dma_setup_channel(device_data, dev);	platform_set_drvdata(pdev, device_data);	 	klist_add_tail(&device_data->list_node, &driver_data.device_list);	 	up(&driver_data.device_allocation);	atomic_set(&session_id, 1);	ret = cryp_algs_register_all();	if (ret) {		dev_err(dev, ""[%s]: cryp_algs_register_all() failed!"",			__func__);		goto out_power;	}	dev_info(dev, ""successfully registered\n"");	return 0;out_power:	cryp_disable_power(device_data->dev, device_data, false);out_clk_unprepare:	clk_unprepare(device_data->clk);out_clk:	clk_put(device_data->clk);out_regulator:	regulator_put(device_data->pwr_regulator);out_unmap:	iounmap(device_data->base);out_free_mem:	release_mem_region(res->start, resource_size(res));out_kfree:	kfree(device_data);out:	return ret;}",14878
202,65,CVE-2015-2348,25,"PHP_FUNCTION(sys_getloadavg){	double load[3];	if (zend_parse_parameters_none() == FAILURE) {		return;	}	if (getloadavg(load, 3) == -1) {		RETURN_FALSE;	} else {		array_init(return_value);		add_index_double(return_value, 0, load[0]);		add_index_double(return_value, 1, load[1]);		add_index_double(return_value, 2, load[2]);	}}",786
449,1665,CVE-2014-1738,25,"static void floppy_release_allocated_regions(int fdc, const struct io_region *p){	while (p != io_regions) {		p--;		release_region(FDCS->address + p->offset, p->size);	}}",11958
524,3070,CVE-2014-7826,25,"static void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id){	struct syscall_metadata *sys_data;	struct syscall_trace_enter *rec;	struct hlist_head *head;	int syscall_nr;	int rctx; 	int size;  	syscall_nr = trace_get_syscall_nr(current, regs);	if (syscall_nr < 0) 		return; 	if (!test_bit(syscall_nr, enabled_perf_enter_syscalls)) 		return;	sys_data = syscall_nr_to_meta(syscall_nr);	if (!sys_data)		return;	head = this_cpu_ptr(sys_data->enter_event->perf_events);	if (hlist_empty(head))		return;	 	size = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);	size = ALIGN(size + sizeof(u32), sizeof(u64));	size -= sizeof(u32);	rec = (struct syscall_trace_enter *)perf_trace_buf_prepare(size,				sys_data->enter_event->event.type, regs, &rctx);	if (!rec)		return;	rec->nr = syscall_nr;	syscall_get_arguments(current, regs, 0, sys_data->nb_args,			       (unsigned long *)&rec->args);	perf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);}",31123
25,977,CVE-2013-2930,25,"static int perf_trace_event_open(struct perf_event *p_event){	struct ftrace_event_call *tp_event = p_event->tp_event;	return tp_event->class->reg(tp_event, TRACE_REG_PERF_OPEN, p_event);}",8431
20,1111,CVE-2013-1957,25,"void change_mnt_propagation(struct mount *mnt, int type){	if (type == MS_SHARED) {		set_mnt_shared(mnt);		return;	}	do_make_slave(mnt);	if (type != MS_SLAVE) {		list_del_init(&mnt->mnt_slave);		mnt->mnt_master = NULL;		if (type == MS_UNBINDABLE)			mnt->mnt.mnt_flags |= MNT_UNBINDABLE;		else			mnt->mnt.mnt_flags &= ~MNT_UNBINDABLE;	}}",9192
466,711,CVE-2011-4112,25,"static void vlan_dev_change_rx_flags(struct net_device *dev, int change){	struct net_device *real_dev = vlan_dev_info(dev)->real_dev;	if (change & IFF_ALLMULTI)		dev_set_allmulti(real_dev, dev->flags & IFF_ALLMULTI ? 1 : -1);	if (change & IFF_PROMISC)		dev_set_promiscuity(real_dev, dev->flags & IFF_PROMISC ? 1 : -1);}",5436
59,814,CVE-2011-2495,25,"static int lstats_open(struct inode *inode, struct file *file){	return single_open(file, lstats_show_proc, inode);}",6611
558,957,CVE-2013-4299,25,static struct pstore *get_info(struct dm_exception_store *store){	return (struct pstore *) store->context;},7854
555,732,CVE-2011-4112,25,static void l2tp_eth_dev_uninit(struct net_device *dev){	struct l2tp_eth *priv = netdev_priv(dev);	struct l2tp_eth_net *pn = l2tp_eth_pernet(dev_net(dev));	spin_lock(&pn->l2tp_eth_lock);	list_del_init(&priv->list);	spin_unlock(&pn->l2tp_eth_lock);	dev_put(dev);},5457
162,1600,CVE-2014-3122,25,"void munlock_vma_pages_range(struct vm_area_struct *vma,			     unsigned long start, unsigned long end){	vma->vm_flags &= ~VM_LOCKED;	while (start < end) {		struct page *page = NULL;		unsigned int page_mask;		unsigned long page_increm;		struct pagevec pvec;		struct zone *zone;		int zoneid;		pagevec_init(&pvec, 0);		 		page = follow_page_mask(vma, start, FOLL_GET | FOLL_DUMP,				&page_mask);		if (page && !IS_ERR(page)) {			if (PageTransHuge(page)) {				lock_page(page);				 				page_mask = munlock_vma_page(page);				unlock_page(page);				put_page(page);  			} else {				 				pagevec_add(&pvec, page);				zone = page_zone(page);				zoneid = page_zone_id(page);				 				start = __munlock_pagevec_fill(&pvec, vma,						zoneid, start, end);				__munlock_pagevec(&pvec, zone);				goto next;			}		}		 		VM_BUG_ON((start >> PAGE_SHIFT) & page_mask);		page_increm = 1 + page_mask;		start += page_increm * PAGE_SIZE;next:		cond_resched();	}}",11571
410,3001,CVE-2016-2420,25,"static const char* get_sigcode(int signo, int code) { switch (signo) { case SIGILL: switch (code) { case ILL_ILLOPC: return ""ILL_ILLOPC""; case ILL_ILLOPN: return ""ILL_ILLOPN""; case ILL_ILLADR: return ""ILL_ILLADR""; case ILL_ILLTRP: return ""ILL_ILLTRP""; case ILL_PRVOPC: return ""ILL_PRVOPC""; case ILL_PRVREG: return ""ILL_PRVREG""; case ILL_COPROC: return ""ILL_COPROC""; case ILL_BADSTK: return ""ILL_BADSTK""; } static_assert(NSIGILL == ILL_BADSTK, ""missing ILL_* si_code""); break; case SIGBUS: switch (code) { case BUS_ADRALN: return ""BUS_ADRALN""; case BUS_ADRERR: return ""BUS_ADRERR""; case BUS_OBJERR: return ""BUS_OBJERR""; case BUS_MCEERR_AR: return ""BUS_MCEERR_AR""; case BUS_MCEERR_AO: return ""BUS_MCEERR_AO""; } static_assert(NSIGBUS == BUS_MCEERR_AO, ""missing BUS_* si_code""); break; case SIGFPE: switch (code) { case FPE_INTDIV: return ""FPE_INTDIV""; case FPE_INTOVF: return ""FPE_INTOVF""; case FPE_FLTDIV: return ""FPE_FLTDIV""; case FPE_FLTOVF: return ""FPE_FLTOVF""; case FPE_FLTUND: return ""FPE_FLTUND""; case FPE_FLTRES: return ""FPE_FLTRES""; case FPE_FLTINV: return ""FPE_FLTINV""; case FPE_FLTSUB: return ""FPE_FLTSUB""; } static_assert(NSIGFPE == FPE_FLTSUB, ""missing FPE_* si_code""); break; case SIGSEGV: switch (code) { case SEGV_MAPERR: return ""SEGV_MAPERR""; case SEGV_ACCERR: return ""SEGV_ACCERR""; } static_assert(NSIGSEGV == SEGV_ACCERR, ""missing SEGV_* si_code""); break; case SIGTRAP: switch (code) { case TRAP_BRKPT: return ""TRAP_BRKPT""; case TRAP_TRACE: return ""TRAP_TRACE""; case TRAP_BRANCH: return ""TRAP_BRANCH""; case TRAP_HWBKPT: return ""TRAP_HWBKPT""; } static_assert(NSIGTRAP == TRAP_HWBKPT, ""missing TRAP_* si_code""); break; } switch (code) { case SI_USER: return ""SI_USER""; case SI_KERNEL: return ""SI_KERNEL""; case SI_QUEUE: return ""SI_QUEUE""; case SI_TIMER: return ""SI_TIMER""; case SI_MESGQ: return ""SI_MESGQ""; case SI_ASYNCIO: return ""SI_ASYNCIO""; case SI_SIGIO: return ""SI_SIGIO""; case SI_TKILL: return ""SI_TKILL""; case SI_DETHREAD: return ""SI_DETHREAD""; } return ""?"";}",30674
444,32,CVE-2015-8467,25,"static int samldb_next_step(struct samldb_ctx *ac){	if (ac->curstep->next) {		ac->curstep = ac->curstep->next;		return ac->curstep->fn(ac);	}	 	if (ac->ares) {		return ldb_module_done(ac->req, ac->ares->controls,				       ac->ares->response, LDB_SUCCESS);	} else {		return ldb_module_done(ac->req, NULL, NULL, LDB_SUCCESS);	}}",141
639,2967,CVE-2016-1632,25,  int HasPreviousSessionData() { return provider()->HasPreviousSessionData(); },29758
679,1428,CVE-2014-3647,25," static int em_grp45(struct x86_emulate_ctxt *ctxt){	int rc = X86EMUL_CONTINUE;	switch (ctxt->modrm_reg) {	case 2:   {		long int old_eip;		old_eip = ctxt->_eip;		rc = assign_eip_near(ctxt, ctxt->src.val);		if (rc != X86EMUL_CONTINUE)			break;		ctxt->src.val = old_eip;		rc = em_push(ctxt);		break;	}	case 4:  		rc = assign_eip_near(ctxt, ctxt->src.val);		break;	case 5:  		rc = em_jmp_far(ctxt);		break;	case 6:	 		rc = em_push(ctxt);		break;	}	return rc;}",11152
652,377,CVE-2012-1179,25,"static unsigned offset_il_node(struct mempolicy *pol,		struct vm_area_struct *vma, unsigned long off){	unsigned nnodes = nodes_weight(pol->v.nodes);	unsigned target;	int c;	int nid = -1;	if (!nnodes)		return numa_node_id();	target = (unsigned int)off % nnodes;	c = 0;	do {		nid = next_node(nid, pol->v.nodes);		c++;	} while (c <= target);	return nid;}",4035
684,1338,CVE-2014-4943,25,"static void pppol2tp_copy_stats(struct pppol2tp_ioc_stats *dest,				struct l2tp_stats *stats){	dest->tx_packets = atomic_long_read(&stats->tx_packets);	dest->tx_bytes = atomic_long_read(&stats->tx_bytes);	dest->tx_errors = atomic_long_read(&stats->tx_errors);	dest->rx_packets = atomic_long_read(&stats->rx_packets);	dest->rx_bytes = atomic_long_read(&stats->rx_bytes);	dest->rx_seq_discards = atomic_long_read(&stats->rx_seq_discards);	dest->rx_oos_packets = atomic_long_read(&stats->rx_oos_packets);	dest->rx_errors = atomic_long_read(&stats->rx_errors);}",10785
568,1796,CVE-2015-1593,25,"static struct elf_phdr *load_elf_phdrs(struct elfhdr *elf_ex,				       struct file *elf_file){	struct elf_phdr *elf_phdata = NULL;	int retval, size, err = -1;	 	if (elf_ex->e_phentsize != sizeof(struct elf_phdr))		goto out;	 	if (elf_ex->e_phnum < 1 ||		elf_ex->e_phnum > 65536U / sizeof(struct elf_phdr))		goto out;	 	size = sizeof(struct elf_phdr) * elf_ex->e_phnum;	if (size > ELF_MIN_ALIGN)		goto out;	elf_phdata = kmalloc(size, GFP_KERNEL);	if (!elf_phdata)		goto out;	 	retval = kernel_read(elf_file, elf_ex->e_phoff,			     (char *)elf_phdata, size);	if (retval != size) {		err = (retval < 0) ? retval : -EIO;		goto out;	}	 	err = 0;out:	if (err) {		kfree(elf_phdata);		elf_phdata = NULL;	}	return elf_phdata;}",13829
95,2539,CVE-2016-6787,25,static int is_orphaned_child(struct perf_event *event){	return is_orphaned_event(event->parent);},15944
384,1762,CVE-2015-2150,25,"static void *bar_init(struct pci_dev *dev, int offset){	struct pci_bar_info *bar = kmalloc(sizeof(*bar), GFP_KERNEL);	if (!bar)		return ERR_PTR(-ENOMEM);	read_dev_bar(dev, bar, offset, ~0);	bar->which = 0;	return bar;}",13763
581,324,CVE-2012-1179,25,"static inline void add_mm_rss_vec(struct mm_struct *mm, int *rss){	int i;	if (current->mm == mm)		sync_mm_rss(current, mm);	for (i = 0; i < NR_MM_COUNTERS; i++)		if (rss[i])			add_mm_counter(mm, i, rss[i]);}",3982
312,2343,CVE-2013-7421,25,"static int sha256_ssse3_export(struct shash_desc *desc, void *out){	struct sha256_state *sctx = shash_desc_ctx(desc);	memcpy(out, sctx, sizeof(*sctx));	return 0;}",14773
6,2556,CVE-2016-6787,25,"static void perf_event_init_cpu(int cpu){	struct swevent_htable *swhash = &per_cpu(swevent_htable, cpu);	mutex_lock(&swhash->hlist_mutex);	swhash->online = true;	if (swhash->hlist_refcount > 0) {		struct swevent_hlist *hlist;		hlist = kzalloc_node(sizeof(*hlist), GFP_KERNEL, cpu_to_node(cpu));		WARN_ON(!hlist);		rcu_assign_pointer(swhash->swevent_hlist, hlist);	}	mutex_unlock(&swhash->hlist_mutex);}",15961
556,1974,CVE-2014-9644,25,"static struct crypto_instance *crypto_cts_alloc(struct rtattr **tb){	struct crypto_instance *inst;	struct crypto_alg *alg;	int err;	err = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_BLKCIPHER);	if (err)		return ERR_PTR(err);	alg = crypto_attr_alg(tb[1], CRYPTO_ALG_TYPE_BLKCIPHER,				  CRYPTO_ALG_TYPE_MASK);	if (IS_ERR(alg))		return ERR_CAST(alg);	inst = ERR_PTR(-EINVAL);	if (!is_power_of_2(alg->cra_blocksize))		goto out_put_alg;	inst = crypto_alloc_instance(""cts"", alg);	if (IS_ERR(inst))		goto out_put_alg;	inst->alg.cra_flags = CRYPTO_ALG_TYPE_BLKCIPHER;	inst->alg.cra_priority = alg->cra_priority;	inst->alg.cra_blocksize = alg->cra_blocksize;	inst->alg.cra_alignmask = alg->cra_alignmask;	inst->alg.cra_type = &crypto_blkcipher_type;	 	inst->alg.cra_alignmask |= __alignof__(u32) - 1;	inst->alg.cra_blkcipher.ivsize = alg->cra_blocksize;	inst->alg.cra_blkcipher.min_keysize = alg->cra_blkcipher.min_keysize;	inst->alg.cra_blkcipher.max_keysize = alg->cra_blkcipher.max_keysize;	inst->alg.cra_blkcipher.geniv = ""seqiv"";	inst->alg.cra_ctxsize = sizeof(struct crypto_cts_ctx);	inst->alg.cra_init = crypto_cts_init_tfm;	inst->alg.cra_exit = crypto_cts_exit_tfm;	inst->alg.cra_blkcipher.setkey = crypto_cts_setkey;	inst->alg.cra_blkcipher.encrypt = crypto_cts_encrypt;	inst->alg.cra_blkcipher.decrypt = crypto_cts_decrypt;out_put_alg:	crypto_mod_put(alg);	return inst;}",14308
399,1579,CVE-2014-3153,25,static void get_futex_key_refs(union futex_key *key){	if (!key->both.ptr)		return;	switch (key->both.offset & (FUT_OFF_INODE|FUT_OFF_MMSHARED)) {	case FUT_OFF_INODE:		ihold(key->shared.inode);  		break;	case FUT_OFF_MMSHARED:		futex_get_mm(key);  		break;	}},11535
723,2203,CVE-2014-7822,25,"int ubifs_setattr(struct dentry *dentry, struct iattr *attr){	int err;	struct inode *inode = dentry->d_inode;	struct ubifs_info *c = inode->i_sb->s_fs_info;	dbg_gen(""ino %lu, mode %#x, ia_valid %#x"",		inode->i_ino, inode->i_mode, attr->ia_valid);	err = inode_change_ok(inode, attr);	if (err)		return err;	err = dbg_check_synced_i_size(c, inode);	if (err)		return err;	if ((attr->ia_valid & ATTR_SIZE) && attr->ia_size < inode->i_size)		 		err = do_truncation(c, inode, attr);	else		err = do_setattr(c, inode, attr);	return err;}",14618
745,676,CVE-2011-4112,25,"int hostap_set_string(struct net_device *dev, int rid, const char *val){	struct hostap_interface *iface;	char buf[MAX_SSID_LEN + 2];	int len;	iface = netdev_priv(dev);	len = strlen(val);	if (len > MAX_SSID_LEN)		return -1;	memset(buf, 0, sizeof(buf));	buf[0] = len;  	memcpy(buf + 2, val, len);	return iface->local->func->set_rid(dev, rid, &buf, MAX_SSID_LEN + 2);}",5401
430,329,CVE-2012-1179,25,"void clear_huge_page(struct page *page,		     unsigned long addr, unsigned int pages_per_huge_page){	int i;	if (unlikely(pages_per_huge_page > MAX_ORDER_NR_PAGES)) {		clear_gigantic_page(page, addr, pages_per_huge_page);		return;	}	might_sleep();	for (i = 0; i < pages_per_huge_page; i++) {		cond_resched();		clear_user_highpage(page + i, addr + i * PAGE_SIZE);	}}",3987
499,2258,CVE-2013-7421,25,"static int sha1_import(struct shash_desc *desc, const void *in){	struct s390_sha_ctx *sctx = shash_desc_ctx(desc);	const struct sha1_state *ictx = in;	sctx->count = ictx->count;	memcpy(sctx->state, ictx->state, sizeof(ictx->state));	memcpy(sctx->buf, ictx->buffer, sizeof(ictx->buffer));	sctx->func = KIMD_SHA_1;	return 0;}",14688
411,1785,CVE-2015-1593,25,static int mmap_is_legacy(void){	if (current->personality & ADDR_COMPAT_LAYOUT)		return 1;	if (rlimit(RLIMIT_STACK) == RLIM_INFINITY)		return 1;	return sysctl_legacy_va_layout;},13818
494,180,CVE-2012-2121,25,"static void kvm_sched_out(struct preempt_notifier *pn,			  struct task_struct *next){	struct kvm_vcpu *vcpu = preempt_notifier_to_vcpu(pn);	kvm_arch_vcpu_put(vcpu);}",3578
1,173,CVE-2012-2121,25,void kvm_put_kvm(struct kvm *kvm){	if (atomic_dec_and_test(&kvm->users_count))		kvm_destroy_vm(kvm);},3571
389,2563,CVE-2016-6787,25,"static void perf_event_task(struct task_struct *task,			      struct perf_event_context *task_ctx,			      int new){	struct perf_task_event task_event;	if (!atomic_read(&nr_comm_events) &&	    !atomic_read(&nr_mmap_events) &&	    !atomic_read(&nr_task_events))		return;	task_event = (struct perf_task_event){		.task	  = task,		.task_ctx = task_ctx,		.event_id    = {			.header = {				.type = new ? PERF_RECORD_FORK : PERF_RECORD_EXIT,				.misc = 0,				.size = sizeof(task_event.event_id),			},			 			 			 			 			.time = perf_clock(),		},	};	perf_event_aux(perf_event_task_output,		       &task_event,		       task_ctx);}",15968
530,698,CVE-2011-4112,25,"ar6000_set_multicast_list(struct net_device *dev){    AR_DEBUG_PRINTF(ATH_DEBUG_ERR,(""ar6000: Multicast filter not supported\n""));}",5423
645,500,CVE-2011-4127,25,"static int parse_path_selector(struct dm_arg_set *as, struct priority_group *pg,			       struct dm_target *ti){	int r;	struct path_selector_type *pst;	unsigned ps_argc;	static struct dm_arg _args[] = {		{0, 1024, ""invalid number of path selector args""},	};	pst = dm_get_path_selector(dm_shift_arg(as));	if (!pst) {		ti->error = ""unknown path selector type"";		return -EINVAL;	}	r = dm_read_arg_group(_args, as, &ps_argc, &ti->error);	if (r) {		dm_put_path_selector(pst);		return -EINVAL;	}	r = pst->create(&pg->ps, ps_argc, as->argv);	if (r) {		dm_put_path_selector(pst);		ti->error = ""path selector constructor failed"";		return r;	}	pg->ps.type = pst;	dm_consume_args(as, ps_argc);	return 0;}",5225
442,2280,CVE-2013-7421,25,static int sha512_sparc64_init(struct shash_desc *desc){	struct sha512_state *sctx = shash_desc_ctx(desc);	sctx->state[0] = SHA512_H0;	sctx->state[1] = SHA512_H1;	sctx->state[2] = SHA512_H2;	sctx->state[3] = SHA512_H3;	sctx->state[4] = SHA512_H4;	sctx->state[5] = SHA512_H5;	sctx->state[6] = SHA512_H6;	sctx->state[7] = SHA512_H7;	sctx->count[0] = sctx->count[1] = 0;	return 0;},14710
238,2986,CVE-2016-2494,25,"static int handle_flush(struct fuse* fuse, struct fuse_handler* handler, const struct fuse_in_header* hdr){    TRACE(""[%d] FLUSH\n"", handler->token); return 0;}",30655
121,438,CVE-2012-0028,25,static void cleanup_signal(struct task_struct *tsk){	struct signal_struct *sig = tsk->signal;	atomic_dec(&sig->live);	if (atomic_dec_and_test(&sig->count))		__cleanup_signal(sig);},4351
560,2111,CVE-2014-9644,25,"static struct crypto_instance *alloc(struct rtattr **tb){	struct crypto_instance *inst;	struct crypto_alg *alg;	int err;	err = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_BLKCIPHER);	if (err)		return ERR_PTR(err);	alg = crypto_get_attr_alg(tb, CRYPTO_ALG_TYPE_CIPHER,				  CRYPTO_ALG_TYPE_MASK);	if (IS_ERR(alg))		return ERR_CAST(alg);	inst = crypto_alloc_instance(""xts"", alg);	if (IS_ERR(inst))		goto out_put_alg;	inst->alg.cra_flags = CRYPTO_ALG_TYPE_BLKCIPHER;	inst->alg.cra_priority = alg->cra_priority;	inst->alg.cra_blocksize = alg->cra_blocksize;	if (alg->cra_alignmask < 7)		inst->alg.cra_alignmask = 7;	else		inst->alg.cra_alignmask = alg->cra_alignmask;	inst->alg.cra_type = &crypto_blkcipher_type;	inst->alg.cra_blkcipher.ivsize = alg->cra_blocksize;	inst->alg.cra_blkcipher.min_keysize =		2 * alg->cra_cipher.cia_min_keysize;	inst->alg.cra_blkcipher.max_keysize =		2 * alg->cra_cipher.cia_max_keysize;	inst->alg.cra_ctxsize = sizeof(struct priv);	inst->alg.cra_init = init_tfm;	inst->alg.cra_exit = exit_tfm;	inst->alg.cra_blkcipher.setkey = setkey;	inst->alg.cra_blkcipher.encrypt = encrypt;	inst->alg.cra_blkcipher.decrypt = decrypt;out_put_alg:	crypto_mod_put(alg);	return inst;}",14445
146,1978,CVE-2014-9644,25,static void crypto_cts_free(struct crypto_instance *inst){	crypto_drop_spawn(crypto_instance_ctx(inst));	kfree(inst);},14312
589,2679,CVE-2016-4565,25,"static unsigned int poll_urgent(struct file *fp,				struct poll_table_struct *pt){	struct hfi1_filedata *fd = fp->private_data;	struct hfi1_ctxtdata *uctxt = fd->uctxt;	struct hfi1_devdata *dd = uctxt->dd;	unsigned pollflag;	poll_wait(fp, &uctxt->wait, pt);	spin_lock_irq(&dd->uctxt_lock);	if (uctxt->urgent != uctxt->urgent_poll) {		pollflag = POLLIN | POLLRDNORM;		uctxt->urgent_poll = uctxt->urgent;	} else {		pollflag = 0;		set_bit(HFI1_CTXT_WAITING_URG, &uctxt->event_flags);	}	spin_unlock_irq(&dd->uctxt_lock);	return pollflag;}",16833
228,852,CVE-2011-2495,25,"static int proc_pid_stack(struct seq_file *m, struct pid_namespace *ns,			  struct pid *pid, struct task_struct *task){	struct stack_trace trace;	unsigned long *entries;	int err;	int i;	entries = kmalloc(MAX_STACK_TRACE_DEPTH * sizeof(*entries), GFP_KERNEL);	if (!entries)		return -ENOMEM;	trace.nr_entries	= 0;	trace.max_entries	= MAX_STACK_TRACE_DEPTH;	trace.entries		= entries;	trace.skip		= 0;	err = lock_trace(task);	if (!err) {		save_stack_trace_tsk(task, &trace);		for (i = 0; i < trace.nr_entries; i++) {			seq_printf(m, ""[<%pK>] %pS\n"",				   (void *)entries[i], (void *)entries[i]);		}		unlock_trace(task);	}	kfree(entries);	return err;}",6649
471,2762,CVE-2014-9888,25,"void arm_iommu_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,			enum dma_data_direction dir, struct dma_attrs *attrs){	__iommu_unmap_sg(dev, sg, nents, dir, attrs, false);}",19311
216,1776,CVE-2015-1867,25,"get_schema_path(const char *name, const char *file){    const char *base = get_schema_root();    if(file) {        return crm_strdup_printf(""%s/%s"", base, file);    }    return crm_strdup_printf(""%s/%s.rng"", base, name);}",13779
34,609,CVE-2011-4112,25,static void tun_poll_controller(struct net_device *dev){	 	return;},5334
49,206,CVE-2012-1179,25,"static void gather_stats(struct page *page, struct numa_maps *md, int pte_dirty,			unsigned long nr_pages){	int count = page_mapcount(page);	md->pages += nr_pages;	if (pte_dirty || PageDirty(page))		md->dirty += nr_pages;	if (PageSwapCache(page))		md->swapcache += nr_pages;	if (PageActive(page) || PageUnevictable(page))		md->active += nr_pages;	if (PageWriteback(page))		md->writeback += nr_pages;	if (PageAnon(page))		md->anon += nr_pages;	if (count > md->mapcount_max)		md->mapcount_max = count;	md->node[page_to_nid(page)] += nr_pages;}",3864
53,2827,CVE-2014-9922,25,"void ecryptfs_put_lower_file(struct inode *inode){	struct ecryptfs_inode_info *inode_info;	inode_info = ecryptfs_inode_to_private(inode);	if (atomic_dec_and_mutex_lock(&inode_info->lower_file_count,				      &inode_info->lower_file_mutex)) {		filemap_write_and_wait(inode->i_mapping);		fput(inode_info->lower_file);		inode_info->lower_file = NULL;		mutex_unlock(&inode_info->lower_file_mutex);	}}",23061
599,300,CVE-2012-1179,25,"static void memcg_wakeup_oom(struct mem_cgroup *memcg){	 	__wake_up(&memcg_oom_waitq, TASK_NORMAL, 0, memcg);}",3958
683,2476,CVE-2013-7421,25,"static int init_hash_hw(struct hash_device_data *device_data,			struct hash_ctx *ctx){	int ret = 0;	ret = hash_setconfiguration(device_data, &ctx->config);	if (ret) {		dev_err(device_data->dev, ""%s: hash_setconfiguration() failed!\n"",			__func__);		return ret;	}	hash_begin(device_data, ctx);	if (ctx->config.oper_mode == HASH_OPER_MODE_HMAC)		hash_hw_write_key(device_data, ctx->key, ctx->keylen);	return ret;}",14906
559,570,CVE-2011-4112,25,"static void macvlan_hash_change_addr(struct macvlan_dev *vlan,					const unsigned char *addr){	macvlan_hash_del(vlan, true);	 	memcpy(vlan->dev->dev_addr, addr, ETH_ALEN);	macvlan_hash_add(vlan);}",5295
362,1889,CVE-2014-9644,25,"static int crypto_cbc_encrypt(struct blkcipher_desc *desc,			      struct scatterlist *dst, struct scatterlist *src,			      unsigned int nbytes){	struct blkcipher_walk walk;	struct crypto_blkcipher *tfm = desc->tfm;	struct crypto_cbc_ctx *ctx = crypto_blkcipher_ctx(tfm);	struct crypto_cipher *child = ctx->child;	int err;	blkcipher_walk_init(&walk, dst, src, nbytes);	err = blkcipher_walk_virt(desc, &walk);	while ((nbytes = walk.nbytes)) {		if (walk.src.virt.addr == walk.dst.virt.addr)			nbytes = crypto_cbc_encrypt_inplace(desc, &walk, child);		else			nbytes = crypto_cbc_encrypt_segment(desc, &walk, child);		err = blkcipher_walk_done(desc, &walk, nbytes);	}	return err;}",14223
438,283,CVE-2012-1179,25,"static void mem_cgroup_swap_statistics(struct mem_cgroup *memcg,					 int charge){	int val = (charge) ? 1 : -1;	this_cpu_add(memcg->stat->count[MEM_CGROUP_STAT_SWAPOUT], val);}",3941
302,51,CVE-2015-5352,25,signal_handler(int sig){	received_signal = sig;	quit_pending = 1;},451
271,2264,CVE-2013-7421,25,"static int sha512_import(struct shash_desc *desc, const void *in){	struct s390_sha_ctx *sctx = shash_desc_ctx(desc);	const struct sha512_state *ictx = in;	if (unlikely(ictx->count[1]))		return -ERANGE;	sctx->count = ictx->count[0];	memcpy(sctx->state, ictx->state, sizeof(ictx->state));	memcpy(sctx->buf, ictx->buf, sizeof(ictx->buf));	sctx->func = KIMD_SHA_512;	return 0;}",14694
705,3064,CVE-2013-0914,25,"flush_signal_handlers(struct task_struct *t, int force_default){	int i;	struct k_sigaction *ka = &t->sighand->action[0];	for (i = _NSIG ; i != 0 ; i--) { 		if (force_default || ka->sa.sa_handler != SIG_IGN) 			ka->sa.sa_handler = SIG_DFL; 		ka->sa.sa_flags = 0; 		sigemptyset(&ka->sa.sa_mask); 		ka++; 	}}",31093
501,652,CVE-2011-4112,25,"static int flashgchar(struct airo_info *ai,int matchbyte,int dwelltime){	int           rchar;	unsigned char rbyte=0;	do {		rchar = IN4500(ai,SWS1);		if(dwelltime && !(0x8000 & rchar)){			dwelltime -= 10;			mdelay(10);			continue;		}		rbyte = 0xff & rchar;		if( (rbyte == matchbyte) && (0x8000 & rchar) ){			OUT4500(ai,SWS1,0);			return 0;		}		if( rbyte == 0x81 || rbyte == 0x82 || rbyte == 0x83 || rbyte == 0x1a || 0xffff == rchar)			break;		OUT4500(ai,SWS1,0);	}while(dwelltime > 0);	return -EIO;}",5377
386,2919,CVE-2011-2782,25,  NavigationControllerTest() {},29126
771,1950,CVE-2014-9644,25,"static void cryptd_hash_digest(struct crypto_async_request *req_async, int err){	struct cryptd_hash_ctx *ctx = crypto_tfm_ctx(req_async->tfm);	struct crypto_shash *child = ctx->child;	struct ahash_request *req = ahash_request_cast(req_async);	struct cryptd_hash_request_ctx *rctx = ahash_request_ctx(req);	struct shash_desc *desc = &rctx->desc;	if (unlikely(err == -EINPROGRESS))		goto out;	desc->tfm = child;	desc->flags = CRYPTO_TFM_REQ_MAY_SLEEP;	err = shash_ahash_digest(req, desc);	req->base.complete = rctx->complete;out:	local_bh_disable();	rctx->complete(&req->base, err);	local_bh_enable();}",14284
51,1475,CVE-2014-3610,25,static int nm_interception(struct vcpu_svm *svm){	svm_fpu_activate(&svm->vcpu);	return 1;},11337
454,1816,CVE-2015-1344,25,"static int lxcfs_flush(const char *path, struct fuse_file_info *fi){	return 0;}",13876
87,1825,CVE-2015-1344,25,"static int proc_getattr(const char *path, struct stat *sb){	struct timespec now;	memset(sb, 0, sizeof(struct stat));	if (clock_gettime(CLOCK_REALTIME, &now) < 0)		return -EINVAL;	sb->st_uid = sb->st_gid = 0;	sb->st_atim = sb->st_mtim = sb->st_ctim = now;	if (strcmp(path, ""/proc"") == 0) {		sb->st_mode = S_IFDIR | 00555;		sb->st_nlink = 2;		return 0;	}	if (strcmp(path, ""/proc/meminfo"") == 0 ||			strcmp(path, ""/proc/cpuinfo"") == 0 ||			strcmp(path, ""/proc/uptime"") == 0 ||			strcmp(path, ""/proc/stat"") == 0 ||			strcmp(path, ""/proc/diskstats"") == 0) {		sb->st_size = 0;		sb->st_mode = S_IFREG | 00444;		sb->st_nlink = 1;		return 0;	}	return -ENOENT;}",13885
545,2457,CVE-2013-7421,25,static int ahash_sha1_init(struct ahash_request *req){	struct crypto_ahash *tfm = crypto_ahash_reqtfm(req);	struct hash_ctx *ctx = crypto_ahash_ctx(tfm);	ctx->config.data_format = HASH_DATA_8_BITS;	ctx->config.algorithm = HASH_ALGO_SHA1;	ctx->config.oper_mode = HASH_OPER_MODE_HASH;	ctx->digestsize = SHA1_DIGEST_SIZE;	return hash_init(req);},14887
192,2429,CVE-2013-7421,25,"static int padlock_sha_export_nano(struct shash_desc *desc,				void *out){	int statesize = crypto_shash_statesize(desc->tfm);	void *sctx = shash_desc_ctx(desc);	memcpy(out, sctx, statesize);	return 0;}",14859
30,20,CVE-2009-4411,25,int max_name_length(struct name_list *names){	int max_len = 0;	while (names != NULL) {		struct name_list *next = names->next;		int len = strlen(names->name);		if (len > max_len)			max_len = len;		names = next;	}	return max_len;},21
612,456,CVE-2012-0028,25,"void mmput(struct mm_struct *mm){	might_sleep();	if (atomic_dec_and_test(&mm->mm_users)) {		exit_aio(mm);		exit_mmap(mm);		set_mm_exe_file(mm, NULL);		if (!list_empty(&mm->mmlist)) {			spin_lock(&mmlist_lock);			list_del(&mm->mmlist);			spin_unlock(&mmlist_lock);		}		put_swap_token(mm);		mmdrop(mm);	}}",4369
227,95,CVE-2010-0011,25,"dump_config() {    g_hash_table_foreach(uzbl.comm.proto_var, dump_var_hash, NULL);}",2659
327,3010,CVE-2016-0809,25,"void wifi_socket_set_local_port(struct nl_sock *sock, int port){ int pid = getpid() & 0x3FFFFF;    nl_socket_set_local_port(sock, pid + (port << 22));}",30698
606,105,CVE-2012-2319,25,"static int hfsplus_symlink(struct inode *dir, struct dentry *dentry,			   const char *symname){	struct hfsplus_sb_info *sbi = HFSPLUS_SB(dir->i_sb);	struct inode *inode;	int res = -ENOSPC;	mutex_lock(&sbi->vh_mutex);	inode = hfsplus_new_inode(dir->i_sb, S_IFLNK | S_IRWXUGO);	if (!inode)		goto out;	res = page_symlink(inode, symname, strlen(symname) + 1);	if (res)		goto out_err;	res = hfsplus_create_cat(inode->i_ino, dir, &dentry->d_name, inode);	if (res)		goto out_err;	hfsplus_instantiate(dentry, inode, inode->i_ino);	mark_inode_dirty(inode);	goto out;out_err:	clear_nlink(inode);	hfsplus_delete_inode(inode);	iput(inode);out:	mutex_unlock(&sbi->vh_mutex);	return res;}",3416
513,504,CVE-2011-4127,25,"static int queue_if_no_path(struct multipath *m, unsigned queue_if_no_path,			    unsigned save_old_value){	unsigned long flags;	spin_lock_irqsave(&m->lock, flags);	if (save_old_value)		m->saved_queue_if_no_path = m->queue_if_no_path;	else		m->saved_queue_if_no_path = queue_if_no_path;	m->queue_if_no_path = queue_if_no_path;	if (!m->queue_if_no_path && m->queue_size)		queue_work(kmultipathd, &m->process_queued_ios);	spin_unlock_irqrestore(&m->lock, flags);	return 0;}",5229
519,2477,CVE-2013-7421,25,static void release_hash_device(struct hash_device_data *device_data){	spin_lock(&device_data->ctx_lock);	device_data->current_ctx->device = NULL;	device_data->current_ctx = NULL;	spin_unlock(&device_data->ctx_lock);	 	up(&driver_data.device_allocation);},14907
573,2211,CVE-2014-7822,25,"xfs_rw_iunlock(	struct xfs_inode	*ip,	int			type){	xfs_iunlock(ip, type);	if (type & XFS_IOLOCK_EXCL)		mutex_unlock(&VFS_I(ip)->i_mutex);}",14626
601,996,CVE-2013-2929,25,static void free_arg_pages(struct linux_binprm *bprm){},8450
277,3066,CVE-2011-1585,25,"cifs_get_smb_ses(struct TCP_Server_Info *server, struct smb_vol *volume_info){	int rc = -ENOMEM, xid;	struct cifsSesInfo *ses;  	xid = GetXid(); 	ses = cifs_find_smb_ses(server, volume_info->username); 	if (ses) { 		cFYI(1, ""Existing smb sess found (status=%d)"", ses->status); 		 		cifs_put_tcp_session(server);		mutex_lock(&ses->session_mutex);		rc = cifs_negotiate_protocol(xid, ses);		if (rc) {			mutex_unlock(&ses->session_mutex);			 			cifs_put_smb_ses(ses);			FreeXid(xid);			return ERR_PTR(rc);		}		if (ses->need_reconnect) {			cFYI(1, ""Session needs reconnect"");			rc = cifs_setup_session(xid, ses,						volume_info->local_nls);			if (rc) {				mutex_unlock(&ses->session_mutex);				 				cifs_put_smb_ses(ses);				FreeXid(xid);				return ERR_PTR(rc);			}		}		mutex_unlock(&ses->session_mutex);		FreeXid(xid);		return ses;	}	cFYI(1, ""Existing smb sess not found"");	ses = sesInfoAlloc();	if (ses == NULL)		goto get_ses_fail;	 	ses->server = server;	if (server->addr.sockAddr6.sin6_family == AF_INET6)		sprintf(ses->serverName, ""%pI6"",			&server->addr.sockAddr6.sin6_addr);	else		sprintf(ses->serverName, ""%pI4"",			&server->addr.sockAddr.sin_addr.s_addr);	if (volume_info->username)		strncpy(ses->userName, volume_info->username,			MAX_USERNAME_SIZE);	 	if (volume_info->password) {		ses->password = kstrdup(volume_info->password, GFP_KERNEL);		if (!ses->password)			goto get_ses_fail;	}	if (volume_info->domainname) {		int len = strlen(volume_info->domainname);		ses->domainName = kmalloc(len + 1, GFP_KERNEL);		if (ses->domainName)			strcpy(ses->domainName, volume_info->domainname);	}	ses->linux_uid = volume_info->linux_uid;	ses->overrideSecFlg = volume_info->secFlg;	mutex_lock(&ses->session_mutex);	rc = cifs_negotiate_protocol(xid, ses);	if (!rc)		rc = cifs_setup_session(xid, ses, volume_info->local_nls);	mutex_unlock(&ses->session_mutex);	if (rc)		goto get_ses_fail;	 	write_lock(&cifs_tcp_ses_lock);	list_add(&ses->smb_ses_list, &server->smb_ses_list);	write_unlock(&cifs_tcp_ses_lock);	FreeXid(xid);	return ses;get_ses_fail:	sesInfoFree(ses);	FreeXid(xid);	return ERR_PTR(rc);}",31117
408,1859,CVE-2014-9644,25,static struct crypto_alg *crypto_spawn_alg(struct crypto_spawn *spawn){	struct crypto_alg *alg;	struct crypto_alg *alg2;	down_read(&crypto_alg_sem);	alg = spawn->alg;	alg2 = alg;	if (alg2)		alg2 = crypto_mod_get(alg2);	up_read(&crypto_alg_sem);	if (!alg2) {		if (alg)			crypto_shoot_alg(alg);		return ERR_PTR(-EAGAIN);	}	return alg;},14193
310,2350,CVE-2013-7421,25,"static int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,		       struct scatterlist *src, unsigned int nbytes){	return glue_cbc_decrypt_128bit(&twofish_dec_cbc, desc, dst, src,				       nbytes);}",14780
26,1852,CVE-2014-9644,25,int crypto_register_alg(struct crypto_alg *alg){	struct crypto_larval *larval;	int err;	err = crypto_check_alg(alg);	if (err)		return err;	down_write(&crypto_alg_sem);	larval = __crypto_register_alg(alg);	up_write(&crypto_alg_sem);	if (IS_ERR(larval))		return PTR_ERR(larval);	crypto_wait_for_test(larval);	return 0;},14186
150,2526,CVE-2016-6787,25,"static int __perf_event_enable(void *info){	struct perf_event *event = info;	struct perf_event_context *ctx = event->ctx;	struct perf_event *leader = event->group_leader;	struct perf_cpu_context *cpuctx = __get_cpu_context(ctx);	int err;	 	if (!ctx->is_active)		return -EINVAL;	raw_spin_lock(&ctx->lock);	update_context_time(ctx);	if (event->state >= PERF_EVENT_STATE_INACTIVE)		goto unlock;	 	perf_cgroup_set_timestamp(current, ctx);	__perf_event_mark_enabled(event);	if (!event_filter_match(event)) {		if (is_cgroup_event(event))			perf_cgroup_defer_enabled(event);		goto unlock;	}	 	if (leader != event && leader->state != PERF_EVENT_STATE_ACTIVE)		goto unlock;	if (!group_can_go_on(event, cpuctx, 1)) {		err = -EEXIST;	} else {		if (event == leader)			err = group_sched_in(event, cpuctx, ctx);		else			err = event_sched_in(event, cpuctx, ctx);	}	if (err) {		 		if (leader != event) {			group_sched_out(leader, cpuctx, ctx);			perf_cpu_hrtimer_restart(cpuctx);		}		if (leader->attr.pinned) {			update_group_times(leader);			leader->state = PERF_EVENT_STATE_ERROR;		}	}unlock:	raw_spin_unlock(&ctx->lock);	return 0;}",15931
303,2645,CVE-2016-4565,25,"static int do_qib_user_sdma_queue_create(struct file *fp){	struct qib_filedata *fd = fp->private_data;	struct qib_ctxtdata *rcd = fd->rcd;	struct qib_devdata *dd = rcd->dd;	if (dd->flags & QIB_HAS_SEND_DMA) {		fd->pq = qib_user_sdma_queue_create(&dd->pcidev->dev,						    dd->unit,						    rcd->ctxt,						    fd->subctxt);		if (!fd->pq)			return -ENOMEM;	}	return 0;}",16799
604,299,CVE-2012-1179,25,static void memcg_oom_recover(struct mem_cgroup *memcg){	if (memcg && atomic_read(&memcg->under_oom))		memcg_wakeup_oom(memcg);},3957
181,1706,CVE-2014-1738,25,static inline void set_debugt(void) { },11999
103,511,CVE-2011-4112,25,"static void bond_attach_slave(struct bonding *bond, struct slave *new_slave){	if (bond->first_slave == NULL) {  		new_slave->next = new_slave;		new_slave->prev = new_slave;		bond->first_slave = new_slave;	} else {		new_slave->next = bond->first_slave;		new_slave->prev = bond->first_slave->prev;		new_slave->next->prev = new_slave;		new_slave->prev->next = new_slave;	}	bond->slave_cnt++;}",5236
239,1658,CVE-2014-1738,25,"static void fdc_specify(void){	unsigned char spec1;	unsigned char spec2;	unsigned long srt;	unsigned long hlt;	unsigned long hut;	unsigned long dtr = NOMINAL_DTR;	unsigned long scale_dtr = NOMINAL_DTR;	int hlt_max_code = 0x7f;	int hut_max_code = 0xf;	if (FDCS->need_configure && FDCS->version >= FDC_82072A) {		fdc_configure();		FDCS->need_configure = 0;	}	switch (raw_cmd->rate & 0x03) {	case 3:		dtr = 1000;		break;	case 1:		dtr = 300;		if (FDCS->version >= FDC_82078) {			 			output_byte(FD_DRIVESPEC);			if (need_more_output() == MORE_OUTPUT) {				output_byte(UNIT(current_drive));				output_byte(0xc0);			}		}		break;	case 2:		dtr = 250;		break;	}	if (FDCS->version >= FDC_82072) {		scale_dtr = dtr;		hlt_max_code = 0x00;	 		hut_max_code = 0x0;	 	}	 	srt = 16 - DIV_ROUND_UP(DP->srt * scale_dtr / 1000, NOMINAL_DTR);	if (slow_floppy)		srt = srt / 4;	SUPBOUND(srt, 0xf);	INFBOUND(srt, 0);	hlt = DIV_ROUND_UP(DP->hlt * scale_dtr / 2, NOMINAL_DTR);	if (hlt < 0x01)		hlt = 0x01;	else if (hlt > 0x7f)		hlt = hlt_max_code;	hut = DIV_ROUND_UP(DP->hut * scale_dtr / 16, NOMINAL_DTR);	if (hut < 0x1)		hut = 0x1;	else if (hut > 0xf)		hut = hut_max_code;	spec1 = (srt << 4) | hut;	spec2 = (hlt << 1) | (use_virtual_dma & 1);	 	if (FDCS->spec1 != spec1 || FDCS->spec2 != spec2) {		 		output_byte(FD_SPECIFY);		output_byte(FDCS->spec1 = spec1);		output_byte(FDCS->spec2 = spec2);	}}				 ",11951
269,2459,CVE-2013-7421,25,"static int ahash_update(struct ahash_request *req){	int ret = 0;	struct hash_req_ctx *req_ctx = ahash_request_ctx(req);	if (hash_mode != HASH_MODE_DMA || !req_ctx->dma_mode)		ret = hash_hw_update(req);	 	if (ret) {		pr_err(""%s: hash_hw_update() failed!\n"", __func__);	}	return ret;}",14889
111,2961,CVE-2016-1631,25,  void set_run_called() { run_called_ = true; },29752
76,859,CVE-2011-2495,25,"int proc_setattr(struct dentry *dentry, struct iattr *attr){	int error;	struct inode *inode = dentry->d_inode;	if (attr->ia_valid & ATTR_MODE)		return -EPERM;	error = inode_change_ok(inode, attr);	if (error)		return error;	if ((attr->ia_valid & ATTR_SIZE) &&	    attr->ia_size != i_size_read(inode)) {		error = vmtruncate(inode, attr->ia_size);		if (error)			return error;	}	setattr_copy(inode, attr);	mark_inode_dirty(inode);	return 0;}",6656
172,404,CVE-2012-1090,25,"build_path_from_dentry(struct dentry *direntry){	struct dentry *temp;	int namelen;	int dfsplen;	char *full_path;	char dirsep;	struct cifs_sb_info *cifs_sb = CIFS_SB(direntry->d_sb);	struct cifs_tcon *tcon = cifs_sb_master_tcon(cifs_sb);	unsigned seq;	dirsep = CIFS_DIR_SEP(cifs_sb);	if (tcon->Flags & SMB_SHARE_IS_IN_DFS)		dfsplen = strnlen(tcon->treeName, MAX_TREE_SIZE + 1);	else		dfsplen = 0;cifs_bp_rename_retry:	namelen = dfsplen;	seq = read_seqbegin(&rename_lock);	rcu_read_lock();	for (temp = direntry; !IS_ROOT(temp);) {		namelen += (1 + temp->d_name.len);		temp = temp->d_parent;		if (temp == NULL) {			cERROR(1, ""corrupt dentry"");			rcu_read_unlock();			return NULL;		}	}	rcu_read_unlock();	full_path = kmalloc(namelen+1, GFP_KERNEL);	if (full_path == NULL)		return full_path;	full_path[namelen] = 0;	 	rcu_read_lock();	for (temp = direntry; !IS_ROOT(temp);) {		spin_lock(&temp->d_lock);		namelen -= 1 + temp->d_name.len;		if (namelen < 0) {			spin_unlock(&temp->d_lock);			break;		} else {			full_path[namelen] = dirsep;			strncpy(full_path + namelen + 1, temp->d_name.name,				temp->d_name.len);			cFYI(0, ""name: %s"", full_path + namelen);		}		spin_unlock(&temp->d_lock);		temp = temp->d_parent;		if (temp == NULL) {			cERROR(1, ""corrupt dentry"");			rcu_read_unlock();			kfree(full_path);			return NULL;		}	}	rcu_read_unlock();	if (namelen != dfsplen || read_seqretry(&rename_lock, seq)) {		cFYI(1, ""did not end path lookup where expected. namelen=%d ""			""dfsplen=%d"", namelen, dfsplen);		 		kfree(full_path);		goto cifs_bp_rename_retry;	}	 	 	if (dfsplen) {		strncpy(full_path, tcon->treeName, dfsplen);		if (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_POSIX_PATHS) {			int i;			for (i = 0; i < dfsplen; i++) {				if (full_path[i] == '\\')					full_path[i] = '/';			}		}	}	return full_path;}",4079
371,2407,CVE-2013-7421,25,static int tgr192_init(struct shash_desc *desc){	struct tgr192_ctx *tctx = shash_desc_ctx(desc);	tctx->a = 0x0123456789abcdefULL;	tctx->b = 0xfedcba9876543210ULL;	tctx->c = 0xf096a5b4c3b2e187ULL;	tctx->nblocks = 0;	tctx->count = 0;	return 0;},14837
698,1924,CVE-2014-9644,25,struct crypto_blkcipher *cryptd_ablkcipher_child(struct cryptd_ablkcipher *tfm){	struct cryptd_blkcipher_ctx *ctx = crypto_ablkcipher_ctx(&tfm->base);	return ctx->child;},14258
267,2143,CVE-2014-7822,25,"int revalidate_disk(struct gendisk *disk){	struct block_device *bdev;	int ret = 0;	if (disk->fops->revalidate_disk)		ret = disk->fops->revalidate_disk(disk);	bdev = bdget_disk(disk, 0);	if (!bdev)		return ret;	mutex_lock(&bdev->bd_mutex);	check_disk_size_change(disk, bdev);	bdev->bd_invalidated = 0;	mutex_unlock(&bdev->bd_mutex);	bdput(bdev);	return ret;}",14558
498,736,CVE-2011-4112,25,"static inline int identical_mac_addr_allowed(int type1, int type2){	return type1 == NL80211_IFTYPE_MONITOR ||		type2 == NL80211_IFTYPE_MONITOR ||		(type1 == NL80211_IFTYPE_AP && type2 == NL80211_IFTYPE_WDS) ||		(type1 == NL80211_IFTYPE_WDS &&			(type2 == NL80211_IFTYPE_WDS ||			 type2 == NL80211_IFTYPE_AP)) ||		(type1 == NL80211_IFTYPE_AP && type2 == NL80211_IFTYPE_AP_VLAN) ||		(type1 == NL80211_IFTYPE_AP_VLAN &&			(type2 == NL80211_IFTYPE_AP ||			 type2 == NL80211_IFTYPE_AP_VLAN));}",5461
482,2753,CVE-2015-2686,25,"void sock_release(struct socket *sock){	if (sock->ops) {		struct module *owner = sock->ops->owner;		sock->ops->release(sock);		sock->ops = NULL;		module_put(owner);	}	if (rcu_dereference_protected(sock->wq, 1)->fasync_list)		pr_err(""%s: fasync list not empty!\n"", __func__);	if (test_bit(SOCK_EXTERNALLY_ALLOCATED, &sock->flags))		return;	this_cpu_sub(sockets_in_use, 1);	if (!sock->file) {		iput(SOCK_INODE(sock));		return;	}	sock->file = NULL;}",19135
669,2673,CVE-2016-4565,25,"static int hfi1_file_open(struct inode *inode, struct file *fp){	 	fp->private_data = kzalloc(sizeof(struct hfi1_filedata), GFP_KERNEL);	if (fp->private_data)  		((struct hfi1_filedata *)fp->private_data)->rec_cpu_num = -1;	return fp->private_data ? 0 : -ENOMEM;}",16827
695,1850,CVE-2014-9644,25,"void crypto_init_queue(struct crypto_queue *queue, unsigned int max_qlen){	INIT_LIST_HEAD(&queue->list);	queue->backlog = &queue->list;	queue->qlen = 0;	queue->max_qlen = max_qlen;}",14184
65,1277,CVE-2014-9322,25,"void math_state_restore(void){	struct task_struct *tsk = current;	if (!tsk_used_math(tsk)) {		local_irq_enable();		 		if (init_fpu(tsk)) {			 			do_group_exit(SIGKILL);			return;		}		local_irq_disable();	}	__thread_fpu_begin(tsk);	 	if (unlikely(restore_fpu_checking(tsk))) {		drop_init_fpu(tsk);		force_sig_info(SIGSEGV, SEND_SIG_PRIV, tsk);		return;	}	tsk->thread.fpu_counter++;}",10380
475,915,CVE-2011-1833,25,"static int ecryptfs_init_kmem_caches(void){	int i;	for (i = 0; i < ARRAY_SIZE(ecryptfs_cache_infos); i++) {		struct ecryptfs_cache_info *info;		info = &ecryptfs_cache_infos[i];		*(info->cache) = kmem_cache_create(info->name, info->size,				0, SLAB_HWCACHE_ALIGN, info->ctor);		if (!*(info->cache)) {			ecryptfs_free_kmem_caches();			ecryptfs_printk(KERN_WARNING, ""%s: ""					""kmem_cache_create failed\n"",					info->name);			return -ENOMEM;		}	}	return 0;}",6771
173,1727,CVE-2012-6657,25,"void release_sock(struct sock *sk){	 	mutex_release(&sk->sk_lock.dep_map, 1, _RET_IP_);	spin_lock_bh(&sk->sk_lock.slock);	if (sk->sk_backlog.tail)		__release_sock(sk);	if (sk->sk_prot->release_cb)		sk->sk_prot->release_cb(sk);	sk->sk_lock.owned = 0;	if (waitqueue_active(&sk->sk_lock.wq))		wake_up(&sk->sk_lock.wq);	spin_unlock_bh(&sk->sk_lock.slock);}",12666
572,2690,CVE-2016-3699,25,"void arch_show_smap(struct seq_file *m, struct vm_area_struct *vma){	if (!boot_cpu_has(X86_FEATURE_OSPKE))		return;	seq_printf(m, ""ProtectionKey:  %8u\n"", vma_pkey(vma));}",17202
739,261,CVE-2012-1179,25,"struct lruvec *mem_cgroup_lru_add_list(struct zone *zone, struct page *page,				       enum lru_list lru){	struct mem_cgroup_per_zone *mz;	struct mem_cgroup *memcg;	struct page_cgroup *pc;	if (mem_cgroup_disabled())		return &zone->lruvec;	pc = lookup_page_cgroup(page);	memcg = pc->mem_cgroup;	 	if (!PageCgroupUsed(pc) && memcg != root_mem_cgroup)		pc->mem_cgroup = memcg = root_mem_cgroup;	mz = page_cgroup_zoneinfo(memcg, page);	 	MEM_CGROUP_ZSTAT(mz, lru) += 1 << compound_order(page);	return &mz->lruvec;}",3919
595,1168,CVE-2013-1774,25,"static int edge_startup(struct usb_serial *serial){	struct edgeport_serial *edge_serial;	int status;	 	edge_serial = kzalloc(sizeof(struct edgeport_serial), GFP_KERNEL);	if (edge_serial == NULL) {		dev_err(&serial->dev->dev, ""%s - Out of memory\n"", __func__);		return -ENOMEM;	}	mutex_init(&edge_serial->es_lock);	edge_serial->serial = serial;	usb_set_serial_data(serial, edge_serial);	status = download_fw(edge_serial);	if (status) {		kfree(edge_serial);		return status;	}	return 0;}",9553
701,1157,CVE-2013-1774,25,"static int edge_chars_in_buffer(struct tty_struct *tty){	struct usb_serial_port *port = tty->driver_data;	struct edgeport_port *edge_port = usb_get_serial_port_data(port);	int chars = 0;	unsigned long flags;	if (edge_port == NULL)		return 0;	if (edge_port->close_pending == 1)		return 0;	spin_lock_irqsave(&edge_port->ep_lock, flags);	chars = kfifo_len(&edge_port->write_fifo);	spin_unlock_irqrestore(&edge_port->ep_lock, flags);	dev_dbg(&port->dev, ""%s - returns %d\n"", __func__, chars);	return chars;}",9542
706,1704,CVE-2014-1738,25,"static void schedule_bh(void (*handler)(void)){	WARN_ON(work_pending(&floppy_work));	floppy_work_fn = handler;	queue_work(floppy_wq, &floppy_work);}",11997
344,1504,CVE-2014-3610,25,static void svm_flush_tlb(struct kvm_vcpu *vcpu){	struct vcpu_svm *svm = to_svm(vcpu);	if (static_cpu_has(X86_FEATURE_FLUSHBYASID))		svm->vmcb->control.tlb_ctl = TLB_CONTROL_FLUSH_ASID;	else		svm->asid_generation--;},11366
29,1040,CVE-2013-1957,25,int __mnt_want_write_file(struct file *file){	struct inode *inode = file_inode(file);	if (!(file->f_mode & FMODE_WRITE) || special_file(inode->i_mode))		return __mnt_want_write(file->f_path.mnt);	else		return mnt_clone_write(file->f_path.mnt);},9121
644,1298,CVE-2014-5207,25,int __mnt_want_write_file(struct file *file){	if (!(file->f_mode & FMODE_WRITER))		return __mnt_want_write(file->f_path.mnt);	else		return mnt_clone_write(file->f_path.mnt);},10647
273,78,CVE-2015-8325,25,child_close_fds(void){	extern int auth_sock;	if (auth_sock != -1) {		close(auth_sock);		auth_sock = -1;	}	if (packet_get_connection_in() == packet_get_connection_out())		close(packet_get_connection_in());	else {		close(packet_get_connection_in());		close(packet_get_connection_out());	}	 	 	channel_close_all();	 	endpwent();	 	closefrom(STDERR_FILENO + 1);},2256
112,3068,CVE-2014-7826,25,"static void ftrace_syscall_enter(void *data, struct pt_regs *regs, long id){	struct trace_array *tr = data;	struct ftrace_event_file *ftrace_file;	struct syscall_trace_enter *entry;	struct syscall_metadata *sys_data;	struct ring_buffer_event *event;	struct ring_buffer *buffer;	unsigned long irq_flags;	int pc;	int syscall_nr; 	int size;  	syscall_nr = trace_get_syscall_nr(current, regs);	if (syscall_nr < 0) 		return;  	 	ftrace_file = rcu_dereference_sched(tr->enter_syscall_files[syscall_nr]);	if (!ftrace_file)		return;	if (ftrace_trigger_soft_disabled(ftrace_file))		return;	sys_data = syscall_nr_to_meta(syscall_nr);	if (!sys_data)		return;	size = sizeof(*entry) + sizeof(unsigned long) * sys_data->nb_args;	local_save_flags(irq_flags);	pc = preempt_count();	buffer = tr->trace_buffer.buffer;	event = trace_buffer_lock_reserve(buffer,			sys_data->enter_event->event.type, size, irq_flags, pc);	if (!event)		return;	entry = ring_buffer_event_data(event);	entry->nr = syscall_nr;	syscall_get_arguments(current, regs, 0, sys_data->nb_args, entry->args);	event_trigger_unlock_commit(ftrace_file, buffer, event, entry,				    irq_flags, pc);}",31121
600,341,CVE-2012-1179,25,static inline int is_zero_pfn(unsigned long pfn){	return pfn == zero_pfn;},3999
18,1370,CVE-2014-4014,25,"void address_space_init_once(struct address_space *mapping){	memset(mapping, 0, sizeof(*mapping));	INIT_RADIX_TREE(&mapping->page_tree, GFP_ATOMIC);	spin_lock_init(&mapping->tree_lock);	mutex_init(&mapping->i_mmap_mutex);	INIT_LIST_HEAD(&mapping->private_list);	spin_lock_init(&mapping->private_lock);	mapping->i_mmap = RB_ROOT;	INIT_LIST_HEAD(&mapping->i_mmap_nonlinear);}",10916
370,1794,CVE-2015-1593,25,"static unsigned long load_elf_interp(struct elfhdr *interp_elf_ex,		struct file *interpreter, unsigned long *interp_map_addr,		unsigned long no_base, struct elf_phdr *interp_elf_phdata){	struct elf_phdr *eppnt;	unsigned long load_addr = 0;	int load_addr_set = 0;	unsigned long last_bss = 0, elf_bss = 0;	unsigned long error = ~0UL;	unsigned long total_size;	int i;	 	if (interp_elf_ex->e_type != ET_EXEC &&	    interp_elf_ex->e_type != ET_DYN)		goto out;	if (!elf_check_arch(interp_elf_ex))		goto out;	if (!interpreter->f_op->mmap)		goto out;	total_size = total_mapping_size(interp_elf_phdata,					interp_elf_ex->e_phnum);	if (!total_size) {		error = -EINVAL;		goto out;	}	eppnt = interp_elf_phdata;	for (i = 0; i < interp_elf_ex->e_phnum; i++, eppnt++) {		if (eppnt->p_type == PT_LOAD) {			int elf_type = MAP_PRIVATE | MAP_DENYWRITE;			int elf_prot = 0;			unsigned long vaddr = 0;			unsigned long k, map_addr;			if (eppnt->p_flags & PF_R)		    		elf_prot = PROT_READ;			if (eppnt->p_flags & PF_W)				elf_prot |= PROT_WRITE;			if (eppnt->p_flags & PF_X)				elf_prot |= PROT_EXEC;			vaddr = eppnt->p_vaddr;			if (interp_elf_ex->e_type == ET_EXEC || load_addr_set)				elf_type |= MAP_FIXED;			else if (no_base && interp_elf_ex->e_type == ET_DYN)				load_addr = -vaddr;			map_addr = elf_map(interpreter, load_addr + vaddr,					eppnt, elf_prot, elf_type, total_size);			total_size = 0;			if (!*interp_map_addr)				*interp_map_addr = map_addr;			error = map_addr;			if (BAD_ADDR(map_addr))				goto out;			if (!load_addr_set &&			    interp_elf_ex->e_type == ET_DYN) {				load_addr = map_addr - ELF_PAGESTART(vaddr);				load_addr_set = 1;			}			 			k = load_addr + eppnt->p_vaddr;			if (BAD_ADDR(k) ||			    eppnt->p_filesz > eppnt->p_memsz ||			    eppnt->p_memsz > TASK_SIZE ||			    TASK_SIZE - eppnt->p_memsz < k) {				error = -ENOMEM;				goto out;			}			 			k = load_addr + eppnt->p_vaddr + eppnt->p_filesz;			if (k > elf_bss)				elf_bss = k;			 			k = load_addr + eppnt->p_memsz + eppnt->p_vaddr;			if (k > last_bss)				last_bss = k;		}	}	if (last_bss > elf_bss) {		 		if (padzero(elf_bss)) {			error = -EFAULT;			goto out;		}		 		elf_bss = ELF_PAGESTART(elf_bss + ELF_MIN_ALIGN - 1);		 		error = vm_brk(elf_bss, last_bss - elf_bss);		if (BAD_ADDR(error))			goto out;	}	error = load_addr;out:	return error;}",13827
733,142,CVE-2012-2121,25,"int get_user_page_nowait(struct task_struct *tsk, struct mm_struct *mm,	unsigned long start, int write, struct page **page){	int flags = FOLL_TOUCH | FOLL_NOWAIT | FOLL_HWPOISON | FOLL_GET;	if (write)		flags |= FOLL_WRITE;	return __get_user_pages(tsk, mm, start, 1, flags, page, NULL, NULL);}",3540
415,2971,CVE-2016-1622,25,  void NotifyPass() { FinishTesting(); },29812
605,2901,CVE-2011-4127,25,"sd_show_cache_type(struct device *dev, struct device_attribute *attr,		   char *buf){	struct scsi_disk *sdkp = to_scsi_disk(dev);	int ct = sdkp->RCD + 2*sdkp->WCE;	return snprintf(buf, 40, ""%s\n"", sd_cache_types[ct]);}",28284
658,2295,CVE-2013-7421,25,"static int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,		       struct scatterlist *src, unsigned int nbytes){	struct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);	return glue_xts_crypt_128bit(&camellia_dec_xts, desc, dst, src, nbytes,				     XTS_TWEAK_CAST(camellia_enc_blk),				     &ctx->tweak_ctx, &ctx->crypt_ctx);}",14725
518,1738,CVE-2015-8660,25,"static int ovl_need_xattr_filter(struct dentry *dentry,				  enum ovl_path_type type){	if ((type & (__OVL_PATH_PURE | __OVL_PATH_UPPER)) == __OVL_PATH_UPPER)		return S_ISDIR(dentry->d_inode->i_mode);	else		return false;}",12842
526,3092,CVE-2015-1342,25,"static int cg_opendir(const char *path, struct fuse_file_info *fi){	struct fuse_context *fc = fuse_get_context();	const char *cgroup;	struct file_info *dir_info;	char *controller = NULL;	if (!fc)		return -EIO;	if (strcmp(path, ""/cgroup"") == 0) {		cgroup = NULL;		controller = NULL;	} else {		controller = pick_controller_from_path(fc, path);		if (!controller)			return -EIO;		cgroup = find_cgroup_in_path(path);		if (!cgroup) {			 			cgroup = ""/""; 		} 	} 	if (cgroup && !fc_may_access(fc, controller, cgroup, NULL, O_RDONLY)) {		return -EACCES; 	}  	 	dir_info = malloc(sizeof(*dir_info));	if (!dir_info)		return -ENOMEM;	dir_info->controller = must_copy_string(controller);	dir_info->cgroup = must_copy_string(cgroup);	dir_info->type = LXC_TYPE_CGDIR;	dir_info->buf = NULL;	dir_info->file = NULL;	dir_info->buflen = 0;	fi->fh = (unsigned long)dir_info;	return 0;}",31205
268,1900,CVE-2014-9644,25,"static int crypto_ccm_setauthsize(struct crypto_aead *tfm,				  unsigned int authsize){	switch (authsize) {	case 4:	case 6:	case 8:	case 10:	case 12:	case 14:	case 16:		break;	default:		return -EINVAL;	}	return 0;}",14234
37,3054,CVE-2011-4112,25, static void l2tp_eth_dev_setup(struct net_device *dev) { 	ether_setup(dev); 	dev->netdev_ops		= &l2tp_eth_netdev_ops; 	dev->destructor		= free_netdev; },30988
594,985,CVE-2013-2929,25,"int bprm_change_interp(char *interp, struct linux_binprm *bprm){	 	if (bprm->interp != bprm->filename)		kfree(bprm->interp);	bprm->interp = kstrdup(interp, GFP_KERNEL);	if (!bprm->interp)		return -ENOMEM;	return 0;}",8439
317,1641,CVE-2014-1738,25,static void cancel_activity(void){	do_floppy = NULL;	cancel_delayed_work_sync(&fd_timer);	cancel_work_sync(&floppy_work);},11934
557,3050,CVE-2011-4112,25,static void veth_setup(struct net_device *dev) { 	ether_setup(dev);  	dev->netdev_ops = &veth_netdev_ops; 	dev->ethtool_ops = &veth_ethtool_ops; 	dev->features |= NETIF_F_LLTX;	dev->destructor = veth_dev_free;	dev->hw_features = NETIF_F_NO_CSUM | NETIF_F_SG | NETIF_F_RXCSUM;},30984
472,2960,CVE-2016-1631,25,  void set_result(int result) { result_ = result; },29751
703,2909,CVE-2011-4127,25,"static int sd_start_stop_device(struct scsi_disk *sdkp, int start){	unsigned char cmd[6] = { START_STOP };	 	struct scsi_sense_hdr sshdr;	struct scsi_device *sdp = sdkp->device;	int res;	if (start)		cmd[4] |= 1;	 	if (sdp->start_stop_pwr_cond)		cmd[4] |= start ? 1 << 4 : 3 << 4;	 	if (!scsi_device_online(sdp))		return -ENODEV;	res = scsi_execute_req(sdp, cmd, DMA_NONE, NULL, 0, &sshdr,			       SD_TIMEOUT, SD_MAX_RETRIES, NULL);	if (res) {		sd_printk(KERN_WARNING, sdkp, ""START_STOP FAILED\n"");		sd_print_result(sdkp, res);		if (driver_byte(res) & DRIVER_SENSE)			sd_print_sense_hdr(sdkp, &sshdr);	}	return res;}",28292
285,2256,CVE-2013-7421,25,"static int ecb_des_encrypt(struct blkcipher_desc *desc,			   struct scatterlist *dst, struct scatterlist *src,			   unsigned int nbytes){	struct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);	struct blkcipher_walk walk;	blkcipher_walk_init(&walk, dst, src, nbytes);	return ecb_desall_crypt(desc, KM_DEA_ENCRYPT, ctx->key, &walk);}",14686
297,34,CVE-2015-8467,25,"static int samldb_prim_group_change(struct samldb_ctx *ac){	struct ldb_context *ldb = ldb_module_get_ctx(ac->module);	const char * const attrs[] = {		""primaryGroupID"",		""memberOf"",		""userAccountControl"",		NULL };	struct ldb_result *res, *group_res;	struct ldb_message_element *el;	struct ldb_message *msg;	int prev_rid, new_rid, uac;	struct dom_sid *prev_sid, *new_sid;	struct ldb_dn *prev_prim_group_dn, *new_prim_group_dn;	int ret;	const char * const noattrs[] = { NULL };	el = dsdb_get_single_valued_attr(ac->msg, ""primaryGroupID"",					 ac->req->operation);	if (el == NULL) {		 		return LDB_SUCCESS;	}	 	ret = dsdb_module_search_dn(ac->module, ac, &res, ac->msg->dn, attrs,				    DSDB_FLAG_NEXT_MODULE, ac->req);	if (ret != LDB_SUCCESS) {		return ret;	}	uac = ldb_msg_find_attr_as_uint(res->msgs[0], ""userAccountControl"", 0);	 	prev_rid = ldb_msg_find_attr_as_uint(res->msgs[0], ""primaryGroupID"",					     (int) -1);	if (prev_rid == (int) -1) {		 		return LDB_ERR_OBJECT_CLASS_VIOLATION;	}	prev_sid = dom_sid_add_rid(ac, samdb_domain_sid(ldb), prev_rid);	if (prev_sid == NULL) {		return ldb_operr(ldb);	}	 	msg = ldb_msg_new(ac->msg);	if (msg == NULL) {		return ldb_module_oom(ac->module);	}	ret = ldb_msg_add(msg, el, 0);	if (ret != LDB_SUCCESS) {		return ret;	}	new_rid = ldb_msg_find_attr_as_uint(msg, ""primaryGroupID"", (int) -1);	talloc_free(msg);	if (new_rid == (int) -1) {		 		return LDB_SUCCESS;	}	if (prev_rid == new_rid) {		return LDB_SUCCESS;	}	if ((uac & UF_SERVER_TRUST_ACCOUNT) && new_rid != DOMAIN_RID_DCS) {		ldb_asprintf_errstring(ldb,			""%08X: samldb: UF_SERVER_TRUST_ACCOUNT requires ""			""primaryGroupID=%u!"",			W_ERROR_V(WERR_DS_CANT_MOD_PRIMARYGROUPID),			DOMAIN_RID_DCS);		return LDB_ERR_UNWILLING_TO_PERFORM;	}	if ((uac & UF_PARTIAL_SECRETS_ACCOUNT) && new_rid != DOMAIN_RID_READONLY_DCS) {		ldb_asprintf_errstring(ldb,			""%08X: samldb: UF_PARTIAL_SECRETS_ACCOUNT requires ""			""primaryGroupID=%u!"",			W_ERROR_V(WERR_DS_CANT_MOD_PRIMARYGROUPID),			DOMAIN_RID_READONLY_DCS);		return LDB_ERR_UNWILLING_TO_PERFORM;	}	ret = dsdb_module_search(ac->module, ac, &group_res,				 ldb_get_default_basedn(ldb),				 LDB_SCOPE_SUBTREE,				 noattrs, DSDB_FLAG_NEXT_MODULE,				 ac->req,				 ""(objectSid=%s)"",				 ldap_encode_ndr_dom_sid(ac, prev_sid));	if (ret != LDB_SUCCESS) {		return ret;	}	if (group_res->count != 1) {		return ldb_operr(ldb);	}	prev_prim_group_dn = group_res->msgs[0]->dn;	new_sid = dom_sid_add_rid(ac, samdb_domain_sid(ldb), new_rid);	if (new_sid == NULL) {		return ldb_operr(ldb);	}	ret = dsdb_module_search(ac->module, ac, &group_res,				 ldb_get_default_basedn(ldb),				 LDB_SCOPE_SUBTREE,				 noattrs, DSDB_FLAG_NEXT_MODULE,				 ac->req,				 ""(objectSid=%s)"",				 ldap_encode_ndr_dom_sid(ac, new_sid));	if (ret != LDB_SUCCESS) {		return ret;	}	if (group_res->count != 1) {		 		return LDB_ERR_UNWILLING_TO_PERFORM;	}	new_prim_group_dn = group_res->msgs[0]->dn;	 	el = samdb_find_attribute(ldb, res->msgs[0], ""memberOf"",				  ldb_dn_get_linearized(new_prim_group_dn));	if (el == NULL) {		return LDB_ERR_UNWILLING_TO_PERFORM;	}	 	msg = ldb_msg_new(ac->msg);	if (msg == NULL) {		return ldb_module_oom(ac->module);	}	msg->dn = new_prim_group_dn;	ret = samdb_msg_add_delval(ldb, msg, msg, ""member"",				   ldb_dn_get_linearized(ac->msg->dn));	if (ret != LDB_SUCCESS) {		return ret;	}	ret = dsdb_module_modify(ac->module, msg, DSDB_FLAG_NEXT_MODULE, ac->req);	if (ret != LDB_SUCCESS) {		return ret;	}	talloc_free(msg);	 	msg = ldb_msg_new(ac->msg);	if (msg == NULL) {		return ldb_module_oom(ac->module);	}	msg->dn = prev_prim_group_dn;	ret = samdb_msg_add_addval(ldb, msg, msg, ""member"",				   ldb_dn_get_linearized(ac->msg->dn));	if (ret != LDB_SUCCESS) {		return ret;	}	ret = dsdb_module_modify(ac->module, msg, DSDB_FLAG_NEXT_MODULE, ac->req);	if (ret != LDB_SUCCESS) {		return ret;	}	talloc_free(msg);	return LDB_SUCCESS;}",143
681,1908,CVE-2014-9644,25,"static void async_chainiv_exit(struct crypto_tfm *tfm){	struct async_chainiv_ctx *ctx = crypto_tfm_ctx(tfm);	BUG_ON(test_bit(CHAINIV_STATE_INUSE, &ctx->state) || ctx->queue.qlen);	skcipher_geniv_exit(tfm);}",14242
388,998,CVE-2013-2929,25,void free_bprm(struct linux_binprm *bprm){	free_arg_pages(bprm);	if (bprm->cred) {		mutex_unlock(&current->signal->cred_guard_mutex);		abort_creds(bprm->cred);	}	 	if (bprm->interp != bprm->filename)		kfree(bprm->interp);	kfree(bprm);},8452
258,1232,CVE-2011-1019,25,"void netdev_rx_handler_unregister(struct net_device *dev){	ASSERT_RTNL();	rcu_assign_pointer(dev->rx_handler, NULL);	rcu_assign_pointer(dev->rx_handler_data, NULL);}",10321
661,544,CVE-2011-4112,25,"static int bond_should_notify_peers(struct bonding *bond){	struct slave *slave = bond->curr_active_slave;	pr_debug(""bond_should_notify_peers: bond %s slave %s\n"",		 bond->dev->name, slave ? slave->dev->name : ""NULL"");	if (!slave || !bond->send_peer_notif ||	    test_bit(__LINK_STATE_LINKWATCH_PENDING, &slave->dev->state))		return false;	bond->send_peer_notif--;	return true;}",5269
359,1688,CVE-2014-1738,25,"static void perpendicular_mode(void){	unsigned char perp_mode;	if (raw_cmd->rate & 0x40) {		switch (raw_cmd->rate & 3) {		case 0:			perp_mode = 2;			break;		case 3:			perp_mode = 3;			break;		default:			DPRINT(""Invalid data rate for perpendicular mode!\n"");			cont->done(0);			FDCS->reset = 1;					 			return;		}	} else		perp_mode = 0;	if (FDCS->perp_mode == perp_mode)		return;	if (FDCS->version >= FDC_82077_ORIG) {		output_byte(FD_PERPENDICULAR);		output_byte(perp_mode);		FDCS->perp_mode = perp_mode;	} else if (perp_mode) {		DPRINT(""perpendicular mode not supported by this FDC.\n"");	}}				 ",11981
709,1748,CVE-2015-6564,25,"monitor_reinit(struct monitor *mon){	monitor_openfds(mon, 0);}",13110
229,1525,CVE-2014-3610,25,static int svm_mpx_supported(void){	return false;},11387
203,804,CVE-2011-2898,25,static inline struct packet_sock *pkt_sk(struct sock *sk){	return (struct packet_sock *)sk;},6514
527,2755,CVE-2014-9888,25,"static struct page **__iommu_get_pages(void *cpu_addr, struct dma_attrs *attrs){	struct vm_struct *area;	if (__in_atomic_pool(cpu_addr, PAGE_SIZE))		return __atomic_get_pages(cpu_addr);	if (dma_get_attr(DMA_ATTR_NO_KERNEL_MAPPING, attrs))		return cpu_addr;	area = find_vm_area(cpu_addr);	if (area && (area->flags & VM_ARM_DMA_CONSISTENT))		return area->pages;	return NULL;}",19304
567,478,CVE-2011-4127,25,static int __must_push_back(struct multipath *m){	return (m->queue_if_no_path != m->saved_queue_if_no_path &&		dm_noflush_suspending(m->ti));},5203
503,2981,CVE-2016-2494,25,"static void add_node_to_parent_locked(struct node *node, struct node *parent) {    node->parent = parent;    node->next = parent->child;    parent->child = node;    acquire_node_locked(parent);}",30650
143,707,CVE-2011-4112,25,static int ath6kl_init_netdev_wmi(struct net_device *dev){	if (!eppingtest && bypasswmi)		return 0;	return __ath6kl_init_netdev(dev);},5432
468,2511,CVE-2013-7421,25,"static void ap_reset_domain(void){	int i;	if (ap_domain_index != -1)		for (i = 0; i < AP_DEVICES; i++)			ap_reset_queue(AP_MKQID(i, ap_domain_index));}",14941
200,926,CVE-2013-6431,25,"static int fib6_dump_table(struct fib6_table *table, struct sk_buff *skb,			   struct netlink_callback *cb){	struct fib6_walker_t *w;	int res;	w = (void *)cb->args[2];	w->root = &table->tb6_root;	if (cb->args[4] == 0) {		w->count = 0;		w->skip = 0;		read_lock_bh(&table->tb6_lock);		res = fib6_walk(w);		read_unlock_bh(&table->tb6_lock);		if (res > 0) {			cb->args[4] = 1;			cb->args[5] = w->root->fn_sernum;		}	} else {		if (cb->args[5] != w->root->fn_sernum) {			 			cb->args[5] = w->root->fn_sernum;			w->state = FWS_INIT;			w->node = w->root;			w->skip = w->count;		} else			w->skip = 0;		read_lock_bh(&table->tb6_lock);		res = fib6_walk_continue(w);		read_unlock_bh(&table->tb6_lock);		if (res <= 0) {			fib6_walker_unlink(w);			cb->args[4] = 0;		}	}	return res;}",7194
546,1845,CVE-2014-9644,25,"struct crypto_async_request *crypto_dequeue_request(struct crypto_queue *queue){	return __crypto_dequeue_request(queue, 0);}",14179
218,877,CVE-2011-2486,25,"static int do_info(void){  if (do_test() != 0)	return 1;  const char *plugin_name = NULL;  if (g_NP_GetValue(NPPVpluginNameString, &plugin_name) == NPERR_NO_ERROR && plugin_name)	printf(""PLUGIN_NAME %zd\n%s\n"", strlen(plugin_name), plugin_name);  const char *plugin_desc = NULL;  if (g_NP_GetValue(NPPVpluginDescriptionString, &plugin_desc) == NPERR_NO_ERROR && plugin_desc)	printf(""PLUGIN_DESC %zd\n%s\n"", strlen(plugin_desc), plugin_desc);  const char *mime_info = g_NP_GetMIMEDescription();  if (mime_info)	printf(""PLUGIN_MIME %zd\n%s\n"", strlen(mime_info), mime_info);  return 0;}",6687
104,1503,CVE-2014-3610,25,static void svm_decache_cr4_guest_bits(struct kvm_vcpu *vcpu){},11365
226,1318,CVE-2014-5207,25,"static inline struct hlist_head *m_hash(struct vfsmount *mnt, struct dentry *dentry){	unsigned long tmp = ((unsigned long)mnt / L1_CACHE_BYTES);	tmp += ((unsigned long)dentry / L1_CACHE_BYTES);	tmp = tmp + (tmp >> m_hash_shift);	return &mount_hashtable[tmp & m_hash_mask];}",10667
663,2308,CVE-2013-7421,25,"static int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,		       struct scatterlist *src, unsigned int nbytes){	return glue_cbc_encrypt_128bit(GLUE_FUNC_CAST(__cast6_encrypt), desc,				       dst, src, nbytes);}",14738
316,2951,CVE-2013-0838,25,int XDisplayExists() {  return (GetXDisplay() != NULL);},29491
728,1243,CVE-2011-1019,25,"static int softnet_seq_show(struct seq_file *seq, void *v){	struct softnet_data *sd = v;	seq_printf(seq, ""%08x %08x %08x %08x %08x %08x %08x %08x %08x %08x\n"",		   sd->processed, sd->dropped, sd->time_squeeze, 0,		   0, 0, 0, 0,  		   sd->cpu_collision, sd->received_rps);	return 0;}",10332
93,2789,CVE-2014-9870,25,static unsigned long oops_begin(void){	int cpu;	unsigned long flags;	oops_enter();	 	raw_local_irq_save(flags);	cpu = smp_processor_id();	if (!arch_spin_trylock(&die_lock)) {		if (cpu == die_owner)			 ;		else			arch_spin_lock(&die_lock);	}	die_nest_count++;	die_owner = cpu;	console_verbose();	bust_spinlocks(1);	return flags;},19338
441,275,CVE-2012-1179,25,"int mem_cgroup_reclaimable(struct mem_cgroup *memcg, int noswap){	return test_mem_cgroup_node_reclaimable(memcg, 0, noswap);}",3933
3,1851,CVE-2014-9644,25,"int crypto_init_spawn2(struct crypto_spawn *spawn, struct crypto_alg *alg,		       struct crypto_instance *inst,		       const struct crypto_type *frontend){	int err = -EINVAL;	if ((alg->cra_flags ^ frontend->type) & frontend->maskset)		goto out;	spawn->frontend = frontend;	err = crypto_init_spawn(spawn, alg, inst, frontend->maskset);out:	return err;}",14185
4,1815,CVE-2015-1344,25,"static int is_processor_line(const char *line){	int cpu;	if (sscanf(line, ""processor       : %d"", &cpu) == 1)		return true;	return false;}",13875
536,1521,CVE-2014-3610,25,"static inline void svm_inject_irq(struct vcpu_svm *svm, int irq){	struct vmcb_control_area *control;	control = &svm->vmcb->control;	control->int_vector = irq;	control->int_ctl &= ~V_INTR_PRIO_MASK;	control->int_ctl |= V_IRQ_MASK |		((  0xf) << V_INTR_PRIO_SHIFT);	mark_dirty(svm->vmcb, VMCB_INTR);}",11383
319,1863,CVE-2014-9644,25,"int crypto_unregister_instance(struct crypto_alg *alg){	int err;	struct crypto_instance *inst = (void *)alg;	struct crypto_template *tmpl = inst->tmpl;	LIST_HEAD(users);	if (!(alg->cra_flags & CRYPTO_ALG_INSTANCE))		return -EINVAL;	BUG_ON(atomic_read(&alg->cra_refcnt) != 1);	down_write(&crypto_alg_sem);	hlist_del_init(&inst->list);	err = crypto_remove_alg(alg, &users);	up_write(&crypto_alg_sem);	if (err)		return err;	tmpl->free(inst);	crypto_remove_final(&users);	return 0;}",14197
579,3013,CVE-2015-6640,25,"SYSCALL_DEFINE1(setuid, uid_t, uid){ const struct cred *old; struct cred *new; int retval; new = prepare_creds(); if (!new) return -ENOMEM;	old = current_cred();	retval = -EPERM; if (nsown_capable(CAP_SETUID)) { new->suid = new->uid = uid; if (uid != old->uid) {			retval = set_user(new); if (retval < 0) goto error; } } else if (uid != old->uid && uid != new->suid) { goto error; } new->fsuid = new->euid = uid;	retval = security_task_fix_setuid(new, old, LSM_SETID_ID); if (retval < 0) goto error; return commit_creds(new);error:	abort_creds(new); return retval;}",30701
75,2551,CVE-2016-6787,25,"static void perf_event_comm_event(struct perf_comm_event *comm_event){	char comm[TASK_COMM_LEN];	unsigned int size;	memset(comm, 0, sizeof(comm));	strlcpy(comm, comm_event->task->comm, sizeof(comm));	size = ALIGN(strlen(comm)+1, sizeof(u64));	comm_event->comm = comm;	comm_event->comm_size = size;	comm_event->event_id.header.size = sizeof(comm_event->event_id) + size;	perf_event_aux(perf_event_comm_output,		       comm_event,		       NULL);}",15956
48,849,CVE-2011-2495,25,"struct inode *proc_pid_make_inode(struct super_block * sb, struct task_struct *task){	struct inode * inode;	struct proc_inode *ei;	const struct cred *cred;	 	inode = new_inode(sb);	if (!inode)		goto out;	 	ei = PROC_I(inode);	inode->i_ino = get_next_ino();	inode->i_mtime = inode->i_atime = inode->i_ctime = CURRENT_TIME;	inode->i_op = &proc_def_inode_operations;	 	ei->pid = get_task_pid(task, PIDTYPE_PID);	if (!ei->pid)		goto out_unlock;	if (task_dumpable(task)) {		rcu_read_lock();		cred = __task_cred(task);		inode->i_uid = cred->euid;		inode->i_gid = cred->egid;		rcu_read_unlock();	}	security_task_to_inode(task, inode);out:	return inode;out_unlock:	iput(inode);	return NULL;}",6646
366,2970,CVE-2016-1632,25,  void RunTasks() {    task_runner_->RunPendingTasks();    task_runner_->RunPendingTasks();  },29761
117,553,CVE-2011-4112,25,"static inline int slave_enable_netpoll(struct slave *slave){	struct netpoll *np;	int err = 0;	np = kzalloc(sizeof(*np), GFP_KERNEL);	err = -ENOMEM;	if (!np)		goto out;	np->dev = slave->dev;	strlcpy(np->dev_name, slave->dev->name, IFNAMSIZ);	err = __netpoll_setup(np);	if (err) {		kfree(np);		goto out;	}	slave->np = np;out:	return err;}",5278
516,1261,CVE-2011-1019,25,static void ipip_tunnel_setup(struct net_device *dev){	dev->netdev_ops		= &ipip_netdev_ops;	dev->destructor		= ipip_dev_free;	dev->type		= ARPHRD_TUNNEL;	dev->hard_header_len 	= LL_MAX_HEADER + sizeof(struct iphdr);	dev->mtu		= ETH_DATA_LEN - sizeof(struct iphdr);	dev->flags		= IFF_NOARP;	dev->iflink		= 0;	dev->addr_len		= 4;	dev->features		|= NETIF_F_NETNS_LOCAL;	dev->features		|= NETIF_F_LLTX;	dev->priv_flags		&= ~IFF_XMIT_DST_RELEASE;},10350
529,169,CVE-2012-2121,25,"static void kvm_mmu_notifier_invalidate_range_end(struct mmu_notifier *mn,						  struct mm_struct *mm,						  unsigned long start,						  unsigned long end){	struct kvm *kvm = mmu_notifier_to_kvm(mn);	spin_lock(&kvm->mmu_lock);	 	kvm->mmu_notifier_seq++;	 	kvm->mmu_notifier_count--;	spin_unlock(&kvm->mmu_lock);	BUG_ON(kvm->mmu_notifier_count < 0);}",3567
425,1405,CVE-2014-4014,25,struct inode *new_inode(struct super_block *sb){	struct inode *inode;	spin_lock_prefetch(&inode_sb_list_lock);	inode = new_inode_pseudo(sb);	if (inode)		inode_sb_list_add(inode);	return inode;},10951
43,2234,CVE-2013-7421,25,static void fallback_exit_blk(struct crypto_tfm *tfm){	struct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);	crypto_free_blkcipher(sctx->fallback.blk);	sctx->fallback.blk = NULL;},14664
352,1154,CVE-2013-1774,25,"static void edge_break(struct tty_struct *tty, int break_state){	struct usb_serial_port *port = tty->driver_data;	struct edgeport_port *edge_port = usb_get_serial_port_data(port);	int status;	int bv = 0;	 	 	chase_port(edge_port, 0, 0);	if (break_state == -1)		bv = 1;	 	status = ti_do_config(edge_port, UMPC_SET_CLR_BREAK, bv);	if (status)		dev_dbg(&port->dev, ""%s - error %d sending break set/clear command.\n"",			__func__, status);}",9539
470,3005,CVE-2016-0846,25, static inline void dump_heaps() {        gHeapCache->dump_heaps(); },30689
553,1134,CVE-2013-1858,25,"static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm){	struct vm_area_struct *mpnt, *tmp, *prev, **pprev;	struct rb_node **rb_link, *rb_parent;	int retval;	unsigned long charge;	struct mempolicy *pol;	uprobe_start_dup_mmap();	down_write(&oldmm->mmap_sem);	flush_cache_dup_mm(oldmm);	uprobe_dup_mmap(oldmm, mm);	 	down_write_nested(&mm->mmap_sem, SINGLE_DEPTH_NESTING);	mm->locked_vm = 0;	mm->mmap = NULL;	mm->mmap_cache = NULL;	mm->free_area_cache = oldmm->mmap_base;	mm->cached_hole_size = ~0UL;	mm->map_count = 0;	cpumask_clear(mm_cpumask(mm));	mm->mm_rb = RB_ROOT;	rb_link = &mm->mm_rb.rb_node;	rb_parent = NULL;	pprev = &mm->mmap;	retval = ksm_fork(mm, oldmm);	if (retval)		goto out;	retval = khugepaged_fork(mm, oldmm);	if (retval)		goto out;	prev = NULL;	for (mpnt = oldmm->mmap; mpnt; mpnt = mpnt->vm_next) {		struct file *file;		if (mpnt->vm_flags & VM_DONTCOPY) {			vm_stat_account(mm, mpnt->vm_flags, mpnt->vm_file,							-vma_pages(mpnt));			continue;		}		charge = 0;		if (mpnt->vm_flags & VM_ACCOUNT) {			unsigned long len = vma_pages(mpnt);			if (security_vm_enough_memory_mm(oldmm, len))  				goto fail_nomem;			charge = len;		}		tmp = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);		if (!tmp)			goto fail_nomem;		*tmp = *mpnt;		INIT_LIST_HEAD(&tmp->anon_vma_chain);		pol = mpol_dup(vma_policy(mpnt));		retval = PTR_ERR(pol);		if (IS_ERR(pol))			goto fail_nomem_policy;		vma_set_policy(tmp, pol);		tmp->vm_mm = mm;		if (anon_vma_fork(tmp, mpnt))			goto fail_nomem_anon_vma_fork;		tmp->vm_flags &= ~VM_LOCKED;		tmp->vm_next = tmp->vm_prev = NULL;		file = tmp->vm_file;		if (file) {			struct inode *inode = file_inode(file);			struct address_space *mapping = file->f_mapping;			get_file(file);			if (tmp->vm_flags & VM_DENYWRITE)				atomic_dec(&inode->i_writecount);			mutex_lock(&mapping->i_mmap_mutex);			if (tmp->vm_flags & VM_SHARED)				mapping->i_mmap_writable++;			flush_dcache_mmap_lock(mapping);			 			if (unlikely(tmp->vm_flags & VM_NONLINEAR))				vma_nonlinear_insert(tmp,						&mapping->i_mmap_nonlinear);			else				vma_interval_tree_insert_after(tmp, mpnt,							&mapping->i_mmap);			flush_dcache_mmap_unlock(mapping);			mutex_unlock(&mapping->i_mmap_mutex);		}		 		if (is_vm_hugetlb_page(tmp))			reset_vma_resv_huge_pages(tmp);		 		*pprev = tmp;		pprev = &tmp->vm_next;		tmp->vm_prev = prev;		prev = tmp;		__vma_link_rb(mm, tmp, rb_link, rb_parent);		rb_link = &tmp->vm_rb.rb_right;		rb_parent = &tmp->vm_rb;		mm->map_count++;		retval = copy_page_range(mm, oldmm, mpnt);		if (tmp->vm_ops && tmp->vm_ops->open)			tmp->vm_ops->open(tmp);		if (retval)			goto out;	}	 	arch_dup_mmap(oldmm, mm);	retval = 0;out:	up_write(&mm->mmap_sem);	flush_tlb_mm(oldmm);	up_write(&oldmm->mmap_sem);	uprobe_end_dup_mmap();	return retval;fail_nomem_anon_vma_fork:	mpol_put(pol);fail_nomem_policy:	kmem_cache_free(vm_area_cachep, tmp);fail_nomem:	retval = -ENOMEM;	vm_unacct_memory(charge);	goto out;}",9346
627,443,CVE-2012-0028,25,"static int copy_mm(unsigned long clone_flags, struct task_struct * tsk){	struct mm_struct * mm, *oldmm;	int retval;	tsk->min_flt = tsk->maj_flt = 0;	tsk->nvcsw = tsk->nivcsw = 0;	tsk->mm = NULL;	tsk->active_mm = NULL;	 	oldmm = current->mm;	if (!oldmm)		return 0;	if (clone_flags & CLONE_VM) {		atomic_inc(&oldmm->mm_users);		mm = oldmm;		goto good_mm;	}	retval = -ENOMEM;	mm = dup_mm(tsk);	if (!mm)		goto fail_nomem;good_mm:	 	mm->token_priority = 0;	mm->last_interval = 0;	tsk->mm = mm;	tsk->active_mm = mm;	return 0;fail_nomem:	return retval;}",4356
574,2239,CVE-2013-7421,25,"static int xts_aes_decrypt(struct blkcipher_desc *desc,			   struct scatterlist *dst, struct scatterlist *src,			   unsigned int nbytes){	struct s390_xts_ctx *xts_ctx = crypto_blkcipher_ctx(desc->tfm);	struct blkcipher_walk walk;	if (unlikely(xts_ctx->key_len == 48))		return xts_fallback_decrypt(desc, dst, src, nbytes);	blkcipher_walk_init(&walk, dst, src, nbytes);	return xts_aes_crypt(desc, xts_ctx->dec, xts_ctx, &walk);}",14669
537,3088,CVE-2015-6520,25,"struct tcp_sock_t *tcp_open(int port) { 	struct tcp_sock_t *this = calloc(1, sizeof *this); 	if (this == NULL) {		ERR(""callocing this failed""); 		goto error; 	}  	this->sd = -1; 	this->sd = socket(AF_INET6, SOCK_STREAM, 0); 	if (this->sd < 0) {		ERR(""sockect open failed""); 		goto error; 	} 	struct sockaddr_in6 addr; 	memset(&addr, 0, sizeof addr); 	addr.sin6_family = AF_INET6; 	addr.sin6_port = htons(port);	addr.sin6_addr = in6addr_any;  	if (bind(this->sd, 	        (struct sockaddr *)&addr, 	        sizeof addr) < 0) { 		if (g_options.only_desired_port == 1)			ERR(""Bind on port failed. "" 			    ""Requested port may be taken or require root permissions.""); 		goto error; 	}  	if (listen(this->sd, HTTP_MAX_PENDING_CONNS) < 0) {		ERR(""listen failed on socket""); 		goto error; 	} 	return this;error:	if (this != NULL) {		if (this->sd != -1) {			close(this->sd);		}		free(this);	}	return NULL;}",31189
40,444,CVE-2012-0028,25,"static int copy_sighand(unsigned long clone_flags, struct task_struct *tsk){	struct sighand_struct *sig;	if (clone_flags & (CLONE_SIGHAND | CLONE_THREAD)) {		atomic_inc(&current->sighand->count);		return 0;	}	sig = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);	rcu_assign_pointer(tsk->sighand, sig);	if (!sig)		return -ENOMEM;	atomic_set(&sig->count, 1);	memcpy(sig->action, current->sighand->action, sizeof(sig->action));	return 0;}",4357
41,1440,CVE-2014-3610,25,"static int dr_interception(struct vcpu_svm *svm){	int reg, dr;	unsigned long val;	int err;	if (svm->vcpu.guest_debug == 0) {		 		clr_dr_intercepts(svm);		svm->vcpu.arch.switch_db_regs |= KVM_DEBUGREG_WONT_EXIT;		return 1;	}	if (!boot_cpu_has(X86_FEATURE_DECODEASSISTS))		return emulate_on_interception(svm);	reg = svm->vmcb->control.exit_info_1 & SVM_EXITINFO_REG_MASK;	dr = svm->vmcb->control.exit_code - SVM_EXIT_READ_DR0;	if (dr >= 16) {  		val = kvm_register_read(&svm->vcpu, reg);		kvm_set_dr(&svm->vcpu, dr - 16, val);	} else {		err = kvm_get_dr(&svm->vcpu, dr, &val);		if (!err)			kvm_register_write(&svm->vcpu, reg, val);	}	skip_emulated_instruction(&svm->vcpu);	return 1;}",11302
323,9,CVE-2015-8467,25,"static int samldb_generate_sAMAccountName(struct ldb_context *ldb,					  struct ldb_message *msg){	char *name;	 	name = talloc_asprintf(msg, ""$%.6X-%.6X%.6X"",				(unsigned int)generate_random(),				(unsigned int)generate_random(),				(unsigned int)generate_random());	if (name == NULL) {		return ldb_oom(ldb);	}	return ldb_msg_add_steal_string(msg, ""sAMAccountName"", name);}",10
116,495,CVE-2011-4127,25,"static void multipath_resume(struct dm_target *ti){	struct multipath *m = (struct multipath *) ti->private;	unsigned long flags;	spin_lock_irqsave(&m->lock, flags);	m->queue_if_no_path = m->saved_queue_if_no_path;	spin_unlock_irqrestore(&m->lock, flags);}",5220
682,1498,CVE-2014-3610,25,"static void svm_cpu_uninit(int cpu){	struct svm_cpu_data *sd = per_cpu(svm_data, raw_smp_processor_id());	if (!sd)		return;	per_cpu(svm_data, raw_smp_processor_id()) = NULL;	__free_page(sd->save_area);	kfree(sd);}",11360
253,2940,CVE-2013-0922,25,    AuthInfo() {},29440
631,1702,CVE-2014-1738,25,"static void rw_interrupt(void){	int eoc;	int ssize;	int heads;	int nr_sectors;	if (R_HEAD >= 2) {		 		return;	}	if (!DRS->first_read_date)		DRS->first_read_date = jiffies;	nr_sectors = 0;	ssize = DIV_ROUND_UP(1 << SIZECODE, 4);	if (ST1 & ST1_EOC)		eoc = 1;	else		eoc = 0;	if (COMMAND & 0x80)		heads = 2;	else		heads = 1;	nr_sectors = (((R_TRACK - TRACK) * heads +		       R_HEAD - HEAD) * SECT_PER_TRACK +		      R_SECTOR - SECTOR + eoc) << SIZECODE >> 2;	if (nr_sectors / ssize >	    DIV_ROUND_UP(in_sector_offset + current_count_sectors, ssize)) {		DPRINT(""long rw: %x instead of %lx\n"",		       nr_sectors, current_count_sectors);		pr_info(""rs=%d s=%d\n"", R_SECTOR, SECTOR);		pr_info(""rh=%d h=%d\n"", R_HEAD, HEAD);		pr_info(""rt=%d t=%d\n"", R_TRACK, TRACK);		pr_info(""heads=%d eoc=%d\n"", heads, eoc);		pr_info(""spt=%d st=%d ss=%d\n"",			SECT_PER_TRACK, fsector_t, ssize);		pr_info(""in_sector_offset=%d\n"", in_sector_offset);	}	nr_sectors -= in_sector_offset;	INFBOUND(nr_sectors, 0);	SUPBOUND(current_count_sectors, nr_sectors);	switch (interpret_errors()) {	case 2:		cont->redo();		return;	case 1:		if (!current_count_sectors) {			cont->error();			cont->redo();			return;		}		break;	case 0:		if (!current_count_sectors) {			cont->redo();			return;		}		current_type[current_drive] = _floppy;		floppy_sizes[TOMINOR(current_drive)] = _floppy->size;		break;	}	if (probing) {		if (DP->flags & FTD_MSG)			DPRINT(""Auto-detected floppy type %s in fd%d\n"",			       _floppy->name, current_drive);		current_type[current_drive] = _floppy;		floppy_sizes[TOMINOR(current_drive)] = _floppy->size;		probing = 0;	}	if (CT(COMMAND) != FD_READ ||	    raw_cmd->kernel_data == current_req->buffer) {		 		cont->done(1);	} else if (CT(COMMAND) == FD_READ) {		buffer_track = raw_cmd->track;		buffer_drive = current_drive;		INFBOUND(buffer_max, nr_sectors + fsector_t);	}	cont->redo();}",11995
231,2047,CVE-2014-9644,25,struct crypto_shash *mcryptd_ahash_child(struct mcryptd_ahash *tfm){	struct mcryptd_hash_ctx *ctx = crypto_ahash_ctx(&tfm->base);	return ctx->child;},14381
8,1599,CVE-2014-3122,25,"void clear_page_mlock(struct page *page){	if (!TestClearPageMlocked(page))		return;	mod_zone_page_state(page_zone(page), NR_MLOCK,			    -hpage_nr_pages(page));	count_vm_event(UNEVICTABLE_PGCLEARED);	if (!isolate_lru_page(page)) {		putback_lru_page(page);	} else {		 		if (PageUnevictable(page))			count_vm_event(UNEVICTABLE_PGSTRANDED);	}}",11570
491,1493,CVE-2014-3610,25,static void svm_cancel_injection(struct kvm_vcpu *vcpu){	struct vcpu_svm *svm = to_svm(vcpu);	struct vmcb_control_area *control = &svm->vmcb->control;	control->exit_int_info = control->event_inj;	control->exit_int_info_err = control->event_inj_err;	control->event_inj = 0;	svm_complete_interrupts(svm);},11355
298,872,CVE-2011-2495,25,"static int sched_show(struct seq_file *m, void *v){	struct inode *inode = m->private;	struct task_struct *p;	p = get_proc_task(inode);	if (!p)		return -ESRCH;	proc_sched_show_task(p, m);	put_task_struct(p);	return 0;}",6669
108,2455,CVE-2013-7421,25,"static int ahash_final(struct ahash_request *req){	int ret = 0;	struct hash_req_ctx *req_ctx = ahash_request_ctx(req);	pr_debug(""%s: data size: %d\n"", __func__, req->nbytes);	if ((hash_mode == HASH_MODE_DMA) && req_ctx->dma_mode)		ret = hash_dma_final(req);	else		ret = hash_hw_final(req);	if (ret) {		pr_err(""%s: hash_hw/dma_final() failed\n"", __func__);	}	return ret;}",14885
643,592,CVE-2011-4112,25,"static int tun_chr_close(struct inode *inode, struct file *file){	struct tun_file *tfile = file->private_data;	struct tun_struct *tun;	tun = __tun_get(tfile);	if (tun) {		struct net_device *dev = tun->dev;		tun_debug(KERN_INFO, tun, ""tun_chr_close\n"");		__tun_detach(tun);		 		if (!(tun->flags & TUN_PERSIST)) {			rtnl_lock();			if (dev->reg_state == NETREG_REGISTERED)				unregister_netdevice(dev);			rtnl_unlock();		}	}	tun = tfile->tun;	if (tun)		sock_put(tun->socket.sk);	put_net(tfile->net);	kfree(tfile);	return 0;}",5317
708,943,CVE-2013-4470,25,"int ip_append_data(struct sock *sk, struct flowi4 *fl4,		   int getfrag(void *from, char *to, int offset, int len,			       int odd, struct sk_buff *skb),		   void *from, int length, int transhdrlen,		   struct ipcm_cookie *ipc, struct rtable **rtp,		   unsigned int flags){	struct inet_sock *inet = inet_sk(sk);	int err;	if (flags&MSG_PROBE)		return 0;	if (skb_queue_empty(&sk->sk_write_queue)) {		err = ip_setup_cork(sk, &inet->cork.base, ipc, rtp);		if (err)			return err;	} else {		transhdrlen = 0;	}	return __ip_append_data(sk, fl4, &sk->sk_write_queue, &inet->cork.base,				sk_page_frag(sk), getfrag,				from, length, transhdrlen, flags);}",7807
767,2462,CVE-2013-7421,25,"static int hash_disable_power(struct hash_device_data *device_data,			      int save_device_state){	int ret = 0;	struct device *dev = device_data->dev;	spin_lock(&device_data->power_state_lock);	if (!device_data->power_state)		goto out;	if (save_device_state) {		hash_save_state(device_data,				&device_data->state);		device_data->restore_dev_state = true;	}	clk_disable(device_data->clk);	ret = regulator_disable(device_data->regulator);	if (ret)		dev_err(dev, ""%s: regulator_disable() failed!\n"", __func__);	device_data->power_state = false;out:	spin_unlock(&device_data->power_state_lock);	return ret;}",14892
372,663,CVE-2011-4112,25,"static int reset_card( struct net_device *dev , int lock) {	struct airo_info *ai = dev->ml_priv;	if (lock && down_interruptible(&ai->sem))		return -1;	waitbusy (ai);	OUT4500(ai,COMMAND,CMD_SOFTRESET);	msleep(200);	waitbusy (ai);	msleep(200);	if (lock)		up(&ai->sem);	return 0;}",5388
419,2467,CVE-2013-7421,25,"static int hash_dma_write(struct hash_ctx *ctx,			  struct scatterlist *sg, int len){	int error = hash_set_dma_transfer(ctx, sg, len, DMA_TO_DEVICE);	if (error) {		dev_dbg(ctx->device->dev,			""%s: hash_set_dma_transfer() failed\n"", __func__);		return error;	}	return len;}",14897
391,236,CVE-2012-1179,25,"static int mem_cgroup_can_attach(struct cgroup_subsys *ss,				struct cgroup *cgroup,				struct cgroup_taskset *tset){	struct task_struct *p = cgroup_taskset_first(tset);	int ret = 0;	struct mem_cgroup *memcg = mem_cgroup_from_cont(cgroup);	if (memcg->move_charge_at_immigrate) {		struct mm_struct *mm;		struct mem_cgroup *from = mem_cgroup_from_task(p);		VM_BUG_ON(from == memcg);		mm = get_task_mm(p);		if (!mm)			return 0;		 		if (mm->owner == p) {			VM_BUG_ON(mc.from);			VM_BUG_ON(mc.to);			VM_BUG_ON(mc.precharge);			VM_BUG_ON(mc.moved_charge);			VM_BUG_ON(mc.moved_swap);			mem_cgroup_start_move(from);			spin_lock(&mc.lock);			mc.from = from;			mc.to = memcg;			spin_unlock(&mc.lock);			 			ret = mem_cgroup_precharge_mc(mm);			if (ret)				mem_cgroup_clear_mc();		}		mmput(mm);	}	return ret;}",3894
759,2785,CVE-2014-9870,25,"void arm_notify_die(const char *str, struct pt_regs *regs,		struct siginfo *info, unsigned long err, unsigned long trap){	if (user_mode(regs)) {		current->thread.error_code = err;		current->thread.trap_no = trap;		force_sig_info(info->si_signo, info, current);	} else {		die(str, regs, err);	}}",19334
252,1604,CVE-2014-3122,25,"static inline struct anon_vma *anon_vma_alloc(void){	struct anon_vma *anon_vma;	anon_vma = kmem_cache_alloc(anon_vma_cachep, GFP_KERNEL);	if (anon_vma) {		atomic_set(&anon_vma->refcount, 1);		 		anon_vma->root = anon_vma;	}	return anon_vma;}",11575
667,392,CVE-2012-1179,25,"unsigned int count_swap_pages(int type, int free){	unsigned int n = 0;	spin_lock(&swap_lock);	if ((unsigned int)type < nr_swapfiles) {		struct swap_info_struct *sis = swap_info[type];		if (sis->flags & SWP_WRITEOK) {			n = sis->pages;			if (free)				n -= sis->inuse_pages;		}	}	spin_unlock(&swap_lock);	return n;}",4050
170,1471,CVE-2014-3610,25,"static int nested_svm_vmexit(struct vcpu_svm *svm){	struct vmcb *nested_vmcb;	struct vmcb *hsave = svm->nested.hsave;	struct vmcb *vmcb = svm->vmcb;	struct page *page;	trace_kvm_nested_vmexit_inject(vmcb->control.exit_code,				       vmcb->control.exit_info_1,				       vmcb->control.exit_info_2,				       vmcb->control.exit_int_info,				       vmcb->control.exit_int_info_err,				       KVM_ISA_SVM);	nested_vmcb = nested_svm_map(svm, svm->nested.vmcb, &page);	if (!nested_vmcb)		return 1;	 	leave_guest_mode(&svm->vcpu);	svm->nested.vmcb = 0;	 	disable_gif(svm);	nested_vmcb->save.es     = vmcb->save.es;	nested_vmcb->save.cs     = vmcb->save.cs;	nested_vmcb->save.ss     = vmcb->save.ss;	nested_vmcb->save.ds     = vmcb->save.ds;	nested_vmcb->save.gdtr   = vmcb->save.gdtr;	nested_vmcb->save.idtr   = vmcb->save.idtr;	nested_vmcb->save.efer   = svm->vcpu.arch.efer;	nested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);	nested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);	nested_vmcb->save.cr2    = vmcb->save.cr2;	nested_vmcb->save.cr4    = svm->vcpu.arch.cr4;	nested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);	nested_vmcb->save.rip    = vmcb->save.rip;	nested_vmcb->save.rsp    = vmcb->save.rsp;	nested_vmcb->save.rax    = vmcb->save.rax;	nested_vmcb->save.dr7    = vmcb->save.dr7;	nested_vmcb->save.dr6    = vmcb->save.dr6;	nested_vmcb->save.cpl    = vmcb->save.cpl;	nested_vmcb->control.int_ctl           = vmcb->control.int_ctl;	nested_vmcb->control.int_vector        = vmcb->control.int_vector;	nested_vmcb->control.int_state         = vmcb->control.int_state;	nested_vmcb->control.exit_code         = vmcb->control.exit_code;	nested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;	nested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;	nested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;	nested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;	nested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;	nested_vmcb->control.next_rip          = vmcb->control.next_rip;	 	if (vmcb->control.event_inj & SVM_EVTINJ_VALID) {		struct vmcb_control_area *nc = &nested_vmcb->control;		nc->exit_int_info     = vmcb->control.event_inj;		nc->exit_int_info_err = vmcb->control.event_inj_err;	}	nested_vmcb->control.tlb_ctl           = 0;	nested_vmcb->control.event_inj         = 0;	nested_vmcb->control.event_inj_err     = 0;	 	if (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))		nested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;	 	copy_vmcb_control_area(vmcb, hsave);	kvm_clear_exception_queue(&svm->vcpu);	kvm_clear_interrupt_queue(&svm->vcpu);	svm->nested.nested_cr3 = 0;	 	svm->vmcb->save.es = hsave->save.es;	svm->vmcb->save.cs = hsave->save.cs;	svm->vmcb->save.ss = hsave->save.ss;	svm->vmcb->save.ds = hsave->save.ds;	svm->vmcb->save.gdtr = hsave->save.gdtr;	svm->vmcb->save.idtr = hsave->save.idtr;	kvm_set_rflags(&svm->vcpu, hsave->save.rflags);	svm_set_efer(&svm->vcpu, hsave->save.efer);	svm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);	svm_set_cr4(&svm->vcpu, hsave->save.cr4);	if (npt_enabled) {		svm->vmcb->save.cr3 = hsave->save.cr3;		svm->vcpu.arch.cr3 = hsave->save.cr3;	} else {		(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);	}	kvm_register_write(&svm->vcpu, VCPU_REGS_RAX, hsave->save.rax);	kvm_register_write(&svm->vcpu, VCPU_REGS_RSP, hsave->save.rsp);	kvm_register_write(&svm->vcpu, VCPU_REGS_RIP, hsave->save.rip);	svm->vmcb->save.dr7 = 0;	svm->vmcb->save.cpl = 0;	svm->vmcb->control.exit_int_info = 0;	mark_all_dirty(svm->vmcb);	nested_svm_unmap(page);	nested_svm_uninit_mmu_context(&svm->vcpu);	kvm_mmu_reset_context(&svm->vcpu);	kvm_mmu_load(&svm->vcpu);	return 0;}",11333
436,844,CVE-2011-2495,25,"static int proc_pid_cmdline(struct task_struct *task, char * buffer){	int res = 0;	unsigned int len;	struct mm_struct *mm = get_task_mm(task);	if (!mm)		goto out;	if (!mm->arg_end)		goto out_mm;	  	len = mm->arg_end - mm->arg_start; 	if (len > PAGE_SIZE)		len = PAGE_SIZE; 	res = access_process_vm(task, mm->arg_start, buffer, len, 0);	if (res > 0 && buffer[res-1] != '\0' && len < PAGE_SIZE) {		len = strnlen(buffer, res);		if (len < res) {		    res = len;		} else {			len = mm->env_end - mm->env_start;			if (len > PAGE_SIZE - res)				len = PAGE_SIZE - res;			res += access_process_vm(task, mm->env_start, buffer+res, len, 0);			res = strnlen(buffer, res);		}	}out_mm:	mmput(mm);out:	return res;}",6641
642,2205,CVE-2014-7822,25,"static int update_mctime(struct inode *inode){	struct timespec now = ubifs_current_time(inode);	struct ubifs_inode *ui = ubifs_inode(inode);	struct ubifs_info *c = inode->i_sb->s_fs_info;	if (mctime_update_needed(inode, &now)) {		int err, release;		struct ubifs_budget_req req = { .dirtied_ino = 1,				.dirtied_ino_d = ALIGN(ui->data_len, 8) };		err = ubifs_budget_space(c, &req);		if (err)			return err;		mutex_lock(&ui->ui_mutex);		inode->i_mtime = inode->i_ctime = ubifs_current_time(inode);		release = ui->dirty;		mark_inode_dirty_sync(inode);		mutex_unlock(&ui->ui_mutex);		if (release)			ubifs_release_budget(c, &req);	}	return 0;}",14620
7,411,CVE-2012-0028,25,static inline void check_stack_usage(void) {},4324
534,1564,CVE-2014-3534,25,"unsigned long regs_get_kernel_stack_nth(struct pt_regs *regs, unsigned int n){	unsigned long addr;	addr = kernel_stack_pointer(regs) + n * sizeof(long);	if (!regs_within_kernel_stack(regs, addr))		return 0;	return *(unsigned long *)addr;}",11453
571,2916,CVE-2014-3647,25," static int em_in(struct x86_emulate_ctxt *ctxt){	if (!pio_in_emulated(ctxt, ctxt->dst.bytes, ctxt->src.val,			     &ctxt->dst.val))		return X86EMUL_IO_NEEDED;	return X86EMUL_CONTINUE;}",28352
422,764,CVE-2011-4080,25,void sysctl_head_finish(struct ctl_table_header *head){	if (!head)		return;	spin_lock(&sysctl_lock);	unuse_table(head);	spin_unlock(&sysctl_lock);},5503
416,850,CVE-2011-2495,25,"static int proc_pid_personality(struct seq_file *m, struct pid_namespace *ns,				struct pid *pid, struct task_struct *task){	int err = lock_trace(task);	if (!err) {		seq_printf(m, ""%08x\n"", task->personality);		unlock_trace(task);	}	return err;}",6647
329,893,CVE-2011-2486,25,static void thread_check_init(void){  g_main_thread = pthread_self();},6703
686,2573,CVE-2016-6787,25,"static int perf_rotate_context(struct perf_cpu_context *cpuctx){	struct perf_event_context *ctx = NULL;	int rotate = 0, remove = 1;	if (cpuctx->ctx.nr_events) {		remove = 0;		if (cpuctx->ctx.nr_events != cpuctx->ctx.nr_active)			rotate = 1;	}	ctx = cpuctx->task_ctx;	if (ctx && ctx->nr_events) {		remove = 0;		if (ctx->nr_events != ctx->nr_active)			rotate = 1;	}	if (!rotate)		goto done;	perf_ctx_lock(cpuctx, cpuctx->task_ctx);	perf_pmu_disable(cpuctx->ctx.pmu);	cpu_ctx_sched_out(cpuctx, EVENT_FLEXIBLE);	if (ctx)		ctx_sched_out(ctx, cpuctx, EVENT_FLEXIBLE);	rotate_ctx(&cpuctx->ctx);	if (ctx)		rotate_ctx(ctx);	perf_event_sched_in(cpuctx, ctx, current);	perf_pmu_enable(cpuctx->ctx.pmu);	perf_ctx_unlock(cpuctx, cpuctx->task_ctx);done:	if (remove)		list_del_init(&cpuctx->rotation_list);	return rotate;}",15978
590,2122,CVE-2014-7822,25,"int bd_link_disk_holder(struct block_device *bdev, struct gendisk *disk){	struct bd_holder_disk *holder;	int ret = 0;	mutex_lock(&bdev->bd_mutex);	WARN_ON_ONCE(!bdev->bd_holder);	 	if (WARN_ON(!disk->slave_dir || !bdev->bd_part->holder_dir))		goto out_unlock;	holder = bd_find_holder_disk(bdev, disk);	if (holder) {		holder->refcnt++;		goto out_unlock;	}	holder = kzalloc(sizeof(*holder), GFP_KERNEL);	if (!holder) {		ret = -ENOMEM;		goto out_unlock;	}	INIT_LIST_HEAD(&holder->list);	holder->disk = disk;	holder->refcnt = 1;	ret = add_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);	if (ret)		goto out_free;	ret = add_symlink(bdev->bd_part->holder_dir, &disk_to_dev(disk)->kobj);	if (ret)		goto out_del;	 	kobject_get(bdev->bd_part->holder_dir);	list_add(&holder->list, &bdev->bd_holder_disks);	goto out_unlock;out_del:	del_symlink(disk->slave_dir, &part_to_dev(bdev->bd_part)->kobj);out_free:	kfree(holder);out_unlock:	mutex_unlock(&bdev->bd_mutex);	return ret;}",14537
717,1026,CVE-2013-2929,25,"static int ptrace_has_cap(struct user_namespace *ns, unsigned int mode){	if (mode & PTRACE_MODE_NOAUDIT)		return has_ns_capability_noaudit(current, ns, CAP_SYS_PTRACE);	else		return has_ns_capability(current, ns, CAP_SYS_PTRACE);}",8480
483,2413,CVE-2013-7421,25,static void zlib_decomp_exit(struct zlib_ctx *ctx){	struct z_stream_s *stream = &ctx->decomp_stream;	if (stream->workspace) {		zlib_inflateEnd(stream);		vfree(stream->workspace);		stream->workspace = NULL;	}},14843
266,701,CVE-2011-4112,25,"ar6000_sysfs_bmi_deinit(struct ar6_softc *ar){    AR_DEBUG_PRINTF(ATH_DEBUG_INFO,(""BMI: Deleting sysfs entry\n""));    sysfs_remove_bin_file(&(((struct device *)ar->osDevInfo.pOSDevice)->kobj), &bmi_attr);}",5426
31,1202,CVE-2011-1585,25,"int cifs_setup_session(unsigned int xid, struct cifsSesInfo *ses,			struct nls_table *nls_info){	int rc = 0;	struct TCP_Server_Info *server = ses->server;	ses->flags = 0;	ses->capabilities = server->capabilities;	if (linuxExtEnabled == 0)		ses->capabilities &= (~CAP_UNIX);	cFYI(1, ""Security Mode: 0x%x Capabilities: 0x%x TimeAdjust: %d"",		 server->secMode, server->capabilities, server->timeAdj);	rc = CIFS_SessSetup(xid, ses, nls_info);	if (rc) {		cERROR(1, ""Send error in SessSetup = %d"", rc);	} else {		cFYI(1, ""CIFS Session Established successfully"");		spin_lock(&GlobalMid_Lock);		ses->status = CifsGood;		ses->need_reconnect = false;		spin_unlock(&GlobalMid_Lock);	}	return rc;}",10275
135,2605,CVE-2016-4565,25,"static int find_overflow_devnum(void){	int ret;	if (!overflow_maj) {		ret = alloc_chrdev_region(&overflow_maj, 0, IB_UCM_MAX_DEVICES,					  ""infiniband_cm"");		if (ret) {			pr_err(""ucm: couldn't register dynamic device number\n"");			return ret;		}	}	ret = find_first_zero_bit(overflow_map, IB_UCM_MAX_DEVICES);	if (ret >= IB_UCM_MAX_DEVICES)		return -1;	return ret;}",16759
650,2010,CVE-2014-9644,25,"static struct crypto_instance *crypto_rfc4543_alloc(struct rtattr **tb){	struct crypto_attr_type *algt;	struct crypto_instance *inst;	struct crypto_aead_spawn *spawn;	struct crypto_alg *alg;	struct crypto_rfc4543_instance_ctx *ctx;	const char *ccm_name;	int err;	algt = crypto_get_attr_type(tb);	if (IS_ERR(algt))		return ERR_CAST(algt);	if ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & algt->mask)		return ERR_PTR(-EINVAL);	ccm_name = crypto_attr_alg_name(tb[1]);	if (IS_ERR(ccm_name))		return ERR_CAST(ccm_name);	inst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);	if (!inst)		return ERR_PTR(-ENOMEM);	ctx = crypto_instance_ctx(inst);	spawn = &ctx->aead;	crypto_set_aead_spawn(spawn, inst);	err = crypto_grab_aead(spawn, ccm_name, 0,			       crypto_requires_sync(algt->type, algt->mask));	if (err)		goto out_free_inst;	alg = crypto_aead_spawn_alg(spawn);	crypto_set_skcipher_spawn(&ctx->null, inst);	err = crypto_grab_skcipher(&ctx->null, ""ecb(cipher_null)"", 0,				   CRYPTO_ALG_ASYNC);	if (err)		goto out_drop_alg;	crypto_skcipher_spawn_alg(&ctx->null);	err = -EINVAL;	 	if (alg->cra_aead.ivsize != 16)		goto out_drop_ecbnull;	 	if (alg->cra_blocksize != 1)		goto out_drop_ecbnull;	err = -ENAMETOOLONG;	if (snprintf(inst->alg.cra_name, CRYPTO_MAX_ALG_NAME,		     ""rfc4543(%s)"", alg->cra_name) >= CRYPTO_MAX_ALG_NAME ||	    snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,		     ""rfc4543(%s)"", alg->cra_driver_name) >=	    CRYPTO_MAX_ALG_NAME)		goto out_drop_ecbnull;	inst->alg.cra_flags = CRYPTO_ALG_TYPE_AEAD;	inst->alg.cra_flags |= alg->cra_flags & CRYPTO_ALG_ASYNC;	inst->alg.cra_priority = alg->cra_priority;	inst->alg.cra_blocksize = 1;	inst->alg.cra_alignmask = alg->cra_alignmask;	inst->alg.cra_type = &crypto_nivaead_type;	inst->alg.cra_aead.ivsize = 8;	inst->alg.cra_aead.maxauthsize = 16;	inst->alg.cra_ctxsize = sizeof(struct crypto_rfc4543_ctx);	inst->alg.cra_init = crypto_rfc4543_init_tfm;	inst->alg.cra_exit = crypto_rfc4543_exit_tfm;	inst->alg.cra_aead.setkey = crypto_rfc4543_setkey;	inst->alg.cra_aead.setauthsize = crypto_rfc4543_setauthsize;	inst->alg.cra_aead.encrypt = crypto_rfc4543_encrypt;	inst->alg.cra_aead.decrypt = crypto_rfc4543_decrypt;	inst->alg.cra_aead.geniv = ""seqiv"";out:	return inst;out_drop_ecbnull:	crypto_drop_skcipher(&ctx->null);out_drop_alg:	crypto_drop_aead(spawn);out_free_inst:	kfree(inst);	inst = ERR_PTR(err);	goto out;}",14344
368,2441,CVE-2013-7421,25,"static void cryp_dma_out_callback(void *data){	struct cryp_ctx *ctx = (struct cryp_ctx *) data;	dev_dbg(ctx->device->dev, ""[%s]: "", __func__);	complete(&ctx->device->dma.cryp_dma_complete);}",14871
332,693,CVE-2011-4112,25,"ar6000_open(struct net_device *dev){    unsigned long  flags;    struct ar6_softc    *ar = (struct ar6_softc *)ar6k_priv(dev);    spin_lock_irqsave(&ar->arLock, flags);    if(ar->arWlanState == WLAN_DISABLED) {        ar->arWlanState = WLAN_ENABLED;    }    if( ar->arConnected || bypasswmi) {        netif_carrier_on(dev);                 netif_wake_queue(dev);    }    else        netif_carrier_off(dev);    spin_unlock_irqrestore(&ar->arLock, flags);    return 0;}",5418
15,1651,CVE-2014-1738,25,static inline int fd_eject(int drive){	return -EINVAL;},11944
321,1067,CVE-2013-1957,25,"int is_path_reachable(struct mount *mnt, struct dentry *dentry,			 const struct path *root){	while (&mnt->mnt != root->mnt && mnt_has_parent(mnt)) {		dentry = mnt->mnt_mountpoint;		mnt = mnt->mnt_parent;	}	return &mnt->mnt == root->mnt && is_subdir(dentry, root->dentry);}",9148
725,847,CVE-2011-2495,25,"static int proc_pid_limits(struct task_struct *task, char *buffer){	unsigned int i;	int count = 0;	unsigned long flags;	char *bufptr = buffer;	struct rlimit rlim[RLIM_NLIMITS];	if (!lock_task_sighand(task, &flags))		return 0;	memcpy(rlim, task->signal->rlim, sizeof(struct rlimit) * RLIM_NLIMITS);	unlock_task_sighand(task, &flags);	 	count += sprintf(&bufptr[count], ""%-25s %-20s %-20s %-10s\n"",			""Limit"", ""Soft Limit"", ""Hard Limit"", ""Units"");	for (i = 0; i < RLIM_NLIMITS; i++) {		if (rlim[i].rlim_cur == RLIM_INFINITY)			count += sprintf(&bufptr[count], ""%-25s %-20s "",					 lnames[i].name, ""unlimited"");		else			count += sprintf(&bufptr[count], ""%-25s %-20lu "",					 lnames[i].name, rlim[i].rlim_cur);		if (rlim[i].rlim_max == RLIM_INFINITY)			count += sprintf(&bufptr[count], ""%-20s "", ""unlimited"");		else			count += sprintf(&bufptr[count], ""%-20lu "",					 rlim[i].rlim_max);		if (lnames[i].unit)			count += sprintf(&bufptr[count], ""%-10s\n"",					 lnames[i].unit);		else			count += sprintf(&bufptr[count], ""\n"");	}	return count;}",6644
137,3037,CVE-2016-2496,25,static int isMainDisplay(int displayId) { return displayId == ADISPLAY_ID_DEFAULT || displayId == ADISPLAY_ID_NONE;},30815
38,1081,CVE-2013-1957,25,void mnt_drop_write_file(struct file *file){	mnt_drop_write(file->f_path.mnt);},9162
275,1691,CVE-2014-1738,25,static void process_fd_request(void){	cont = &rw_cont;	schedule_bh(redo_fd_request);},11984
232,2428,CVE-2013-7421,25,"static int padlock_sha_export(struct shash_desc *desc, void *out){	struct padlock_sha_desc *dctx = shash_desc_ctx(desc);	return crypto_shash_export(&dctx->fallback, out);}",14858
477,2138,CVE-2014-7822,25,struct super_block *freeze_bdev(struct block_device *bdev){	struct super_block *sb;	int error = 0;	mutex_lock(&bdev->bd_fsfreeze_mutex);	if (++bdev->bd_fsfreeze_count > 1) {		 		sb = get_super(bdev);		drop_super(sb);		mutex_unlock(&bdev->bd_fsfreeze_mutex);		return sb;	}	sb = get_active_super(bdev);	if (!sb)		goto out;	error = freeze_super(sb);	if (error) {		deactivate_super(sb);		bdev->bd_fsfreeze_count--;		mutex_unlock(&bdev->bd_fsfreeze_mutex);		return ERR_PTR(error);	}	deactivate_super(sb); out:	sync_blockdev(bdev);	mutex_unlock(&bdev->bd_fsfreeze_mutex);	return sb;	 },14553
637,2128,CVE-2014-7822,25,"static void bdev_destroy_inode(struct inode *inode){	call_rcu(&inode->i_rcu, bdev_i_callback);}",14543
32,2590,CVE-2016-4997,25,"static inline int unconditional(const struct arpt_entry *e){	static const struct arpt_arp uncond;	return e->target_offset == sizeof(struct arpt_entry) &&	       memcmp(&e->arp, &uncond, sizeof(uncond)) == 0;}",16591
246,69,CVE-2011-4718,25, static inline void php_rinit_session_globals(TSRMLS_D)   {	PS(mod_data) = NULL;	PS(mod_user_is_open) = 0;	 	PS(http_session_vars) = NULL;} ,1171
620,715,CVE-2011-4112,25,"void vlan_dev_get_realdev_name(const struct net_device *dev, char *result){	strncpy(result, vlan_dev_info(dev)->real_dev->name, 23);}",5440
522,510,CVE-2011-4112,25,"static int bond_add_vlan(struct bonding *bond, unsigned short vlan_id){	struct vlan_entry *vlan;	pr_debug(""bond: %s, vlan id %d\n"",		 (bond ? bond->dev->name : ""None""), vlan_id);	vlan = kzalloc(sizeof(struct vlan_entry), GFP_KERNEL);	if (!vlan)		return -ENOMEM;	INIT_LIST_HEAD(&vlan->vlan_list);	vlan->vlan_id = vlan_id;	write_lock_bh(&bond->lock);	list_add_tail(&vlan->vlan_list, &bond->vlan_list);	write_unlock_bh(&bond->lock);	pr_debug(""added VLAN ID %d on bond %s\n"", vlan_id, bond->dev->name);	return 0;}",5235
71,2321,CVE-2013-7421,25,static void ghash_async_exit_tfm(struct crypto_tfm *tfm){	struct ghash_async_ctx *ctx = crypto_tfm_ctx(tfm);	cryptd_free_ahash(ctx->cryptd_tfm);},14751
129,1065,CVE-2013-1957,25,"static inline unsigned long hash(struct vfsmount *mnt, struct dentry *dentry){	unsigned long tmp = ((unsigned long)mnt / L1_CACHE_BYTES);	tmp += ((unsigned long)dentry / L1_CACHE_BYTES);	tmp = tmp + (tmp >> HASH_SHIFT);	return tmp & (HASH_SIZE - 1);}",9146
406,2815,CVE-2016-10010,25,"notify_setup(void){	if (pipe(notify_pipe) < 0) {		error(""pipe(notify_pipe) failed %s"", strerror(errno));	} else if ((fcntl(notify_pipe[0], F_SETFD, FD_CLOEXEC) == -1) ||	    (fcntl(notify_pipe[1], F_SETFD, FD_CLOEXEC) == -1)) {		error(""fcntl(notify_pipe, F_SETFD) failed %s"", strerror(errno));		close(notify_pipe[0]);		close(notify_pipe[1]);	} else {		set_nonblock(notify_pipe[0]);		set_nonblock(notify_pipe[1]);		return;	}	notify_pipe[0] = -1;	 	notify_pipe[1] = -1;	 }",22643
476,1673,CVE-2014-1738,25,static void generic_done(int result){	command_status = result;	cont = &wakeup_cont;},11966
696,2876,CVE-2011-4127,25,static struct scsi_disk *__scsi_disk_get(struct gendisk *disk){	struct scsi_disk *sdkp = NULL;	if (disk->private_data) {		sdkp = scsi_disk(disk);		if (scsi_device_get(sdkp->device) == 0)			get_device(&sdkp->dev);		else			sdkp = NULL;	}	return sdkp;},28259
280,539,CVE-2011-4112,25,static void bond_set_xmit_hash_policy(struct bonding *bond){	switch (bond->params.xmit_policy) {	case BOND_XMIT_POLICY_LAYER23:		bond->xmit_hash_policy = bond_xmit_hash_policy_l23;		break;	case BOND_XMIT_POLICY_LAYER34:		bond->xmit_hash_policy = bond_xmit_hash_policy_l34;		break;	case BOND_XMIT_POLICY_LAYER2:	default:		bond->xmit_hash_policy = bond_xmit_hash_policy_l2;		break;	}},5264
626,249,CVE-2012-1179,25,"static void mem_cgroup_drain_pcp_counter(struct mem_cgroup *memcg, int cpu){	int i;	spin_lock(&memcg->pcp_counter_lock);	for (i = 0; i < MEM_CGROUP_STAT_DATA; i++) {		long x = per_cpu(memcg->stat->count[i], cpu);		per_cpu(memcg->stat->count[i], cpu) = 0;		memcg->nocpu_base.count[i] += x;	}	for (i = 0; i < MEM_CGROUP_EVENTS_NSTATS; i++) {		unsigned long x = per_cpu(memcg->stat->events[i], cpu);		per_cpu(memcg->stat->events[i], cpu) = 0;		memcg->nocpu_base.events[i] += x;	}	 	per_cpu(memcg->stat->count[MEM_CGROUP_ON_MOVE], cpu) = 0;	spin_unlock(&memcg->pcp_counter_lock);}",3907
215,150,CVE-2012-2121,25,"static int kvm_create_dirty_bitmap(struct kvm_memory_slot *memslot){	unsigned long dirty_bytes = 2 * kvm_dirty_bitmap_bytes(memslot);	if (dirty_bytes > PAGE_SIZE)		memslot->dirty_bitmap = vzalloc(dirty_bytes);	else		memslot->dirty_bitmap = kzalloc(dirty_bytes, GFP_KERNEL);	if (!memslot->dirty_bitmap)		return -ENOMEM;	memslot->dirty_bitmap_head = memslot->dirty_bitmap;	memslot->nr_dirty_pages = 0;	return 0;}",3548
114,2165,CVE-2014-7822,25,"int gfs2_open_common(struct inode *inode, struct file *file){	struct gfs2_file *fp;	int ret;	if (S_ISREG(inode->i_mode)) {		ret = generic_file_open(inode, file);		if (ret)			return ret;	}	fp = kzalloc(sizeof(struct gfs2_file), GFP_NOFS);	if (!fp)		return -ENOMEM;	mutex_init(&fp->f_fl_mutex);	gfs2_assert_warn(GFS2_SB(inode), !file->private_data);	file->private_data = fp;	return 0;}",14580
531,637,CVE-2011-4112,25,"static void airo_handle_cisco_mic(struct airo_info *ai){	if (test_bit(FLAG_MIC_CAPABLE, &ai->flags)) {		set_bit(JOB_MIC, &ai->jobs);		wake_up_interruptible(&ai->thr_wait);	}}",5362
286,2639,CVE-2016-4565,25,"void ib_uverbs_free_async_event_file(struct ib_uverbs_file *file){	kref_put(&file->async_file->ref, ib_uverbs_release_event_file);	file->async_file = NULL;}",16793
379,2009,CVE-2014-9644,25,"static int crypto_rfc4106_setauthsize(struct crypto_aead *parent,				      unsigned int authsize){	struct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(parent);	switch (authsize) {	case 8:	case 12:	case 16:		break;	default:		return -EINVAL;	}	return crypto_aead_setauthsize(ctx->child, authsize);}",14343
264,355,CVE-2012-1179,25,"int vm_insert_mixed(struct vm_area_struct *vma, unsigned long addr,			unsigned long pfn){	BUG_ON(!(vma->vm_flags & VM_MIXEDMAP));	if (addr < vma->vm_start || addr >= vma->vm_end)		return -EFAULT;	 	if (!HAVE_PTE_SPECIAL && pfn_valid(pfn)) {		struct page *page;		page = pfn_to_page(pfn);		return insert_page(vma, addr, page, vma->vm_page_prot);	}	return insert_pfn(vma, addr, pfn, vma->vm_page_prot);}",4013
562,643,CVE-2011-4112,25,"static void airo_set_multicast_list(struct net_device *dev) {	struct airo_info *ai = dev->ml_priv;	if ((dev->flags ^ ai->flags) & IFF_PROMISC) {		change_bit(FLAG_PROMISC, &ai->flags);		if (down_trylock(&ai->sem) != 0) {			set_bit(JOB_PROMISC, &ai->jobs);			wake_up_interruptible(&ai->thr_wait);		} else			airo_set_promisc(ai);	}	if ((dev->flags&IFF_ALLMULTI) || !netdev_mc_empty(dev)) {		 	}}",5368
214,2910,CVE-2011-4127,25,"static int sd_sync_cache(struct scsi_disk *sdkp){	int retries, res;	struct scsi_device *sdp = sdkp->device;	struct scsi_sense_hdr sshdr;	if (!scsi_device_online(sdp))		return -ENODEV;	for (retries = 3; retries > 0; --retries) {		unsigned char cmd[10] = { 0 };		cmd[0] = SYNCHRONIZE_CACHE;		 		res = scsi_execute_req(sdp, cmd, DMA_NONE, NULL, 0, &sshdr,				       SD_FLUSH_TIMEOUT, SD_MAX_RETRIES, NULL);		if (res == 0)			break;	}	if (res) {		sd_print_result(sdkp, res);		if (driver_byte(res) & DRIVER_SENSE)			sd_print_sense_hdr(sdkp, &sshdr);	}	if (res)		return -EIO;	return 0;}",28293
168,1862,CVE-2014-9644,25,"int crypto_unregister_algs(struct crypto_alg *algs, int count){	int i, ret;	for (i = 0; i < count; i++) {		ret = crypto_unregister_alg(&algs[i]);		if (ret)			pr_err(""Failed to unregister %s %s: %d\n"",			       algs[i].cra_driver_name, algs[i].cra_name, ret);	}	return 0;}",14196
593,2875,CVE-2011-4127,25,static int sg_get_timeout(struct request_queue *q){	return jiffies_to_clock_t(q->sg_timeout);},28258
603,1526,CVE-2014-3610,25,static int svm_nmi_allowed(struct kvm_vcpu *vcpu){	struct vcpu_svm *svm = to_svm(vcpu);	struct vmcb *vmcb = svm->vmcb;	int ret;	ret = !(vmcb->control.int_state & SVM_INTERRUPT_SHADOW_MASK) &&	      !(svm->vcpu.arch.hflags & HF_NMI_MASK);	ret = ret && gif_set(svm) && nested_svm_nmi(svm);	return ret;},11388
225,167,CVE-2012-2121,25,"static int kvm_mmu_notifier_clear_flush_young(struct mmu_notifier *mn,					      struct mm_struct *mm,					      unsigned long address){	struct kvm *kvm = mmu_notifier_to_kvm(mn);	int young, idx;	idx = srcu_read_lock(&kvm->srcu);	spin_lock(&kvm->mmu_lock);	young = kvm_age_hva(kvm, address);	spin_unlock(&kvm->mmu_lock);	srcu_read_unlock(&kvm->srcu, idx);	if (young)		kvm_flush_remote_tlbs(kvm);	return young;}",3565
158,2754,CVE-2014-9888,25,static struct page **__atomic_get_pages(void *addr){	struct dma_pool *pool = &atomic_pool;	struct page **pages = pool->pages;	int offs = (addr - pool->vaddr) >> PAGE_SHIFT;	return pages + offs;},19303
199,704,CVE-2011-4112,25,"ar6000_unavail_ev(void *context, void *hif_handle){    struct ar6_softc *ar = (struct ar6_softc *)context;             ar6000_devices[ar->arDeviceIndex] = NULL;    ar6000_destroy(ar->arNetDev, 1);    return 0;}",5429
106,745,CVE-2011-4112,25,"static void ieee80211_setup_sdata(struct ieee80211_sub_if_data *sdata,				  enum nl80211_iftype type){	 	memset(&sdata->u, 0, sizeof(sdata->u));	 	sdata->vif.type = type;	sdata->vif.p2p = false;	sdata->dev->netdev_ops = &ieee80211_dataif_ops;	sdata->wdev.iftype = type;	sdata->control_port_protocol = cpu_to_be16(ETH_P_PAE);	sdata->control_port_no_encrypt = false;	 	sdata->dev->type = ARPHRD_ETHER;	skb_queue_head_init(&sdata->skb_queue);	INIT_WORK(&sdata->work, ieee80211_iface_work);	switch (type) {	case NL80211_IFTYPE_P2P_GO:		type = NL80211_IFTYPE_AP;		sdata->vif.type = type;		sdata->vif.p2p = true;		 	case NL80211_IFTYPE_AP:		skb_queue_head_init(&sdata->u.ap.ps_bc_buf);		INIT_LIST_HEAD(&sdata->u.ap.vlans);		break;	case NL80211_IFTYPE_P2P_CLIENT:		type = NL80211_IFTYPE_STATION;		sdata->vif.type = type;		sdata->vif.p2p = true;		 	case NL80211_IFTYPE_STATION:		ieee80211_sta_setup_sdata(sdata);		break;	case NL80211_IFTYPE_ADHOC:		ieee80211_ibss_setup_sdata(sdata);		break;	case NL80211_IFTYPE_MESH_POINT:		if (ieee80211_vif_is_mesh(&sdata->vif))			ieee80211_mesh_init_sdata(sdata);		break;	case NL80211_IFTYPE_MONITOR:		sdata->dev->type = ARPHRD_IEEE80211_RADIOTAP;		sdata->dev->netdev_ops = &ieee80211_monitorif_ops;		sdata->u.mntr_flags = MONITOR_FLAG_CONTROL |				      MONITOR_FLAG_OTHER_BSS;		break;	case NL80211_IFTYPE_WDS:	case NL80211_IFTYPE_AP_VLAN:		break;	case NL80211_IFTYPE_UNSPECIFIED:	case NUM_NL80211_IFTYPES:		BUG();		break;	}	ieee80211_debugfs_add_netdev(sdata);}",5470
459,1288,CVE-2014-7826,25,"static int perf_sysexit_enable(struct ftrace_event_call *call){	int ret = 0;	int num;	num = ((struct syscall_metadata *)call->data)->syscall_nr;	mutex_lock(&syscall_trace_lock);	if (!sys_perf_refcount_exit)		ret = register_trace_sys_exit(perf_syscall_exit, NULL);	if (ret) {		pr_info(""event trace: Could not activate""				""syscall exit trace point"");	} else {		set_bit(num, enabled_perf_exit_syscalls);		sys_perf_refcount_exit++;	}	mutex_unlock(&syscall_trace_lock);	return ret;}",10531
648,39,CVE-2009-4411,25,"acl_get_file_mode(const char *path_p){	struct stat st;	if (stat(path_p, &st) != 0)		return NULL;	return acl_from_mode(st.st_mode);}",148
752,885,CVE-2011-2486,25,static inline int get_appcontext_input_count_at(int offset){  return *((short *)((char *)x_app_context + offset));},6695
685,145,CVE-2012-2121,25,"static void hardware_disable_all_nolock(void){	BUG_ON(!kvm_usage_count);	kvm_usage_count--;	if (!kvm_usage_count)		on_each_cpu(hardware_disable_nolock, NULL, 1);}",3543
640,381,CVE-2012-1179,25,"static void sp_delete(struct shared_policy *sp, struct sp_node *n){	pr_debug(""deleting %lx-l%lx\n"", n->start, n->end);	rb_erase(&n->nd, &sp->root);	mpol_put(n->policy);	kmem_cache_free(sn_cache, n);}",4039
418,2544,CVE-2016-6787,25,"perf_cgroup_match(struct perf_event *event){	struct perf_event_context *ctx = event->ctx;	struct perf_cpu_context *cpuctx = __get_cpu_context(ctx);	 	if (!event->cgrp)		return true;	 	if (!cpuctx->cgrp)		return false;	 	return cgroup_is_descendant(cpuctx->cgrp->css.cgroup,				    event->cgrp->css.cgroup);}",15949
212,362,CVE-2012-1179,25,"struct mempolicy *get_vma_policy(struct task_struct *task,		struct vm_area_struct *vma, unsigned long addr){	struct mempolicy *pol = task->mempolicy;	if (vma) {		if (vma->vm_ops && vma->vm_ops->get_policy) {			struct mempolicy *vpol = vma->vm_ops->get_policy(vma,									addr);			if (vpol)				pol = vpol;		} else if (vma->vm_policy)			pol = vma->vm_policy;	}	if (!pol)		pol = &default_policy;	return pol;}",4020
90,2371,CVE-2013-7421,25,"static struct crypto_alg *crypto_larval_wait(struct crypto_alg *alg){	struct crypto_larval *larval = (void *)alg;	long timeout;	timeout = wait_for_completion_interruptible_timeout(		&larval->completion, 60 * HZ);	alg = larval->adult;	if (timeout < 0)		alg = ERR_PTR(-EINTR);	else if (!timeout)		alg = ERR_PTR(-ETIMEDOUT);	else if (!alg)		alg = ERR_PTR(-ENOENT);	else if (crypto_is_test_larval(larval) &&		 !(alg->cra_flags & CRYPTO_ALG_TESTED))		alg = ERR_PTR(-EAGAIN);	else if (!crypto_mod_get(alg))		alg = ERR_PTR(-EAGAIN);	crypto_mod_put(&larval->alg);	return alg;}",14801
578,1431,CVE-2014-3610,25,"static int clgi_interception(struct vcpu_svm *svm){	if (nested_svm_check_permissions(svm))		return 1;	svm->next_rip = kvm_rip_read(&svm->vcpu) + 3;	skip_emulated_instruction(&svm->vcpu);	disable_gif(svm);	 	svm_clear_vintr(svm);	svm->vmcb->control.int_ctl &= ~V_IRQ_MASK;	mark_dirty(svm->vmcb, VMCB_INTR);	return 1;}",11293
424,682,CVE-2011-4112,25,"static void ar6000_cleanup_amsdu_rxbufs(struct ar6_softc *ar){    struct htc_packet  *pPacket;    void        *osBuf;             while (true) {        AR6000_SPIN_LOCK(&ar->arLock, 0);        pPacket = HTC_PACKET_DEQUEUE(&ar->amsdu_rx_buffer_queue);        AR6000_SPIN_UNLOCK(&ar->arLock, 0);        if (NULL == pPacket) {            break;        }        osBuf = pPacket->pPktContext;        if (NULL == osBuf) {            A_ASSERT(false);            break;        }        A_NETBUF_FREE(osBuf);    }}",5407
721,678,CVE-2011-4112,25,"static int __ath6kl_init_netdev(struct net_device *dev){	int r;	rtnl_lock();	r = ar6000_init(dev);	rtnl_unlock();	if (r) {		AR_DEBUG_PRINTF(ATH_DEBUG_ERR,(""ar6000_avail: ar6000_init\n""));		return r;	}	return 0;}",5403
509,2728,CVE-2015-8539,25,"static void __ekey_init(struct encrypted_key_payload *epayload,			const char *format, const char *master_desc,			const char *datalen){	unsigned int format_len;	format_len = (!format) ? strlen(key_format_default) : strlen(format);	epayload->format = epayload->payload_data + epayload->payload_datalen;	epayload->master_desc = epayload->format + format_len + 1;	epayload->datalen = epayload->master_desc + strlen(master_desc) + 1;	epayload->iv = epayload->datalen + strlen(datalen) + 1;	epayload->encrypted_data = epayload->iv + ivsize + 1;	epayload->decrypted_data = epayload->payload_data;	if (!format)		memcpy(epayload->format, key_format_default, format_len);	else {		if (!strcmp(format, key_format_ecryptfs))			epayload->decrypted_data =				ecryptfs_get_auth_tok_key((struct ecryptfs_auth_tok *)epayload->payload_data);		memcpy(epayload->format, format, format_len);	}	memcpy(epayload->master_desc, master_desc, strlen(master_desc));	memcpy(epayload->datalen, datalen, strlen(datalen));}",18936
248,1246,CVE-2011-1019,25,"static void ipgre_destroy_tunnels(struct ipgre_net *ign, struct list_head *head){	int prio;	for (prio = 0; prio < 4; prio++) {		int h;		for (h = 0; h < HASH_SIZE; h++) {			struct ip_tunnel *t;			t = rtnl_dereference(ign->tunnels[prio][h]);			while (t != NULL) {				unregister_netdevice_queue(t->dev, head);				t = rtnl_dereference(t->next);			}		}	}}",10335
507,365,CVE-2012-1179,25,"static int lookup_node(struct mm_struct *mm, unsigned long addr){	struct page *p;	int err;	err = get_user_pages(current, mm, addr & PAGE_MASK, 1, 0, 0, &p, NULL);	if (err >= 0) {		err = page_to_nid(p);		put_page(p);	}	return err;}",4023
607,2702,CVE-2015-8955,25,"__hw_perf_event_init(struct perf_event *event){	struct arm_pmu *armpmu = to_arm_pmu(event->pmu);	struct hw_perf_event *hwc = &event->hw;	int mapping, err;	mapping = armpmu->map_event(event);	if (mapping < 0) {		pr_debug(""event %x:%llx not supported\n"", event->attr.type,			 event->attr.config);		return mapping;	}	 	hwc->idx		= -1;	hwc->config_base	= 0;	hwc->config		= 0;	hwc->event_base		= 0;	 	if ((!armpmu->set_event_filter ||	     armpmu->set_event_filter(hwc, &event->attr)) &&	     event_requires_mode_exclusion(&event->attr)) {		pr_debug(""ARM performance counters do not support mode exclusion\n"");		return -EPERM;	}	 	hwc->config_base	    |= (unsigned long)mapping;	if (!hwc->sample_period) {		 		hwc->sample_period  = armpmu->max_period >> 1;		hwc->last_period    = hwc->sample_period;		local64_set(&hwc->period_left, hwc->sample_period);	}	err = 0;	if (event->group_leader != event) {		err = validate_group(event);		if (err)			return -EINVAL;	}	return err;}",18405
322,629,CVE-2011-4112,25,"static int airo_get_name(struct net_device *dev,			 struct iw_request_info *info,			 char *cwrq,			 char *extra){	strcpy(cwrq, ""IEEE 802.11-DS"");	return 0;}",5354
257,3093,CVE-2015-1342,25," static int cg_rmdir(const char *path) { 	struct fuse_context *fc = fuse_get_context();	char *fpath = NULL, *cgdir = NULL, *controller; 	const char *cgroup; 	int ret; 	if (!fc)		return -EIO;	controller = pick_controller_from_path(fc, path);	if (!controller)		return -EINVAL;	cgroup = find_cgroup_in_path(path);	if (!cgroup)		return -EINVAL;	get_cgdir_and_path(cgroup, &cgdir, &fpath);	if (!fpath) {		ret = -EINVAL; 		goto out; 	} 	fprintf(stderr, ""rmdir: verifying access to %s:%s (req path %s)\n"",			controller, cgdir, path); 	if (!fc_may_access(fc, controller, cgdir, NULL, O_WRONLY)) { 		ret = -EACCES; 		goto out;	}	if (!caller_is_in_ancestor(fc->pid, controller, cgroup, NULL)) {		ret = -EACCES;		goto out;	}	if (!cgfs_remove(controller, cgroup)) {		ret = -EINVAL;		goto out;	}	ret = 0;  out: 	free(cgdir); 	return ret; }",31206
167,56,CVE-2013-2007,25,"static void ga_disable_non_whitelisted(void){    char **list_head, **list;    int whitelisted;    int i;    list_head = list = qmp_get_command_list();    while (*list != NULL) {        whitelisted = false;        i = 0;        while (ga_freeze_whitelist[i] != NULL) {            if (strcmp(*list, ga_freeze_whitelist[i]) == 0) {                whitelisted = true;            }            i++;        }        if (!whitelisted) {            g_debug(""disabling command: %s"", *list);            qmp_disable_command(*list);        }        g_free(*list);        list++;    }    g_free(list_head);}",756
12,1697,CVE-2014-1738,25,"static void reschedule_timeout(int drive, const char *message){	unsigned long flags;	spin_lock_irqsave(&floppy_lock, flags);	__reschedule_timeout(drive, message);	spin_unlock_irqrestore(&floppy_lock, flags);}",11990
293,2498,CVE-2013-7421,25,"static void ap_increase_queue_count(struct ap_device *ap_dev){	int timeout = ap_dev->drv->request_timeout;	ap_dev->queue_count++;	if (ap_dev->queue_count == 1) {		mod_timer(&ap_dev->timeout, jiffies + timeout);		ap_dev->reset = AP_RESET_ARMED;	}}",14928
628,861,CVE-2011-2495,25,"static int proc_single_show(struct seq_file *m, void *v){	struct inode *inode = m->private;	struct pid_namespace *ns;	struct pid *pid;	struct task_struct *task;	int ret;	ns = inode->i_sb->s_fs_info;	pid = proc_pid(inode);	task = get_pid_task(pid, PIDTYPE_PID);	if (!task)		return -ESRCH;	ret = PROC_I(inode)->op.proc_show(m, ns, pid, task);	put_task_struct(task);	return ret;}",6658
741,2064,CVE-2014-9644,25,"static void mcryptd_hash_init(struct crypto_async_request *req_async, int err){	struct mcryptd_hash_ctx *ctx = crypto_tfm_ctx(req_async->tfm);	struct crypto_shash *child = ctx->child;	struct ahash_request *req = ahash_request_cast(req_async);	struct mcryptd_hash_request_ctx *rctx = ahash_request_ctx(req);	struct shash_desc *desc = &rctx->desc;	if (unlikely(err == -EINPROGRESS))		goto out;	desc->tfm = child;	desc->flags = CRYPTO_TFM_REQ_MAY_SLEEP;	err = crypto_shash_init(desc);	req->base.complete = rctx->complete;out:	local_bh_disable();	rctx->complete(&req->base, err);	local_bh_enable();}",14398
469,3072,CVE-2014-5207,25,"static struct mount *clone_mnt(struct mount *old, struct dentry *root,					int flag){	struct super_block *sb = old->mnt.mnt_sb;	struct mount *mnt;	int err;	mnt = alloc_vfsmnt(old->mnt_devname);	if (!mnt)		return ERR_PTR(-ENOMEM);	if (flag & (CL_SLAVE | CL_PRIVATE | CL_SHARED_TO_SLAVE))		mnt->mnt_group_id = 0;  	else		mnt->mnt_group_id = old->mnt_group_id;	if ((flag & CL_MAKE_SHARED) && !mnt->mnt_group_id) {		err = mnt_alloc_group_id(mnt);		if (err)			goto out_free;	}  	mnt->mnt.mnt_flags = old->mnt.mnt_flags & ~(MNT_WRITE_HOLD|MNT_MARKED); 	 	if ((flag & CL_UNPRIVILEGED) && (mnt->mnt.mnt_flags & MNT_READONLY))		mnt->mnt.mnt_flags |= MNT_LOCK_READONLY;  	  	if ((flag & CL_UNPRIVILEGED) && list_empty(&old->mnt_expire))		mnt->mnt.mnt_flags |= MNT_LOCKED;	atomic_inc(&sb->s_active);	mnt->mnt.mnt_sb = sb;	mnt->mnt.mnt_root = dget(root);	mnt->mnt_mountpoint = mnt->mnt.mnt_root;	mnt->mnt_parent = mnt;	lock_mount_hash();	list_add_tail(&mnt->mnt_instance, &sb->s_mounts);	unlock_mount_hash();	if ((flag & CL_SLAVE) ||	    ((flag & CL_SHARED_TO_SLAVE) && IS_MNT_SHARED(old))) {		list_add(&mnt->mnt_slave, &old->mnt_slave_list);		mnt->mnt_master = old;		CLEAR_MNT_SHARED(mnt);	} else if (!(flag & CL_PRIVATE)) {		if ((flag & CL_MAKE_SHARED) || IS_MNT_SHARED(old))			list_add(&mnt->mnt_share, &old->mnt_share);		if (IS_MNT_SLAVE(old))			list_add(&mnt->mnt_slave, &old->mnt_slave);		mnt->mnt_master = old->mnt_master;	}	if (flag & CL_MAKE_SHARED)		set_mnt_shared(mnt);	 	if (flag & CL_EXPIRE) {		if (!list_empty(&old->mnt_expire))			list_add(&mnt->mnt_expire, &old->mnt_expire);	}	return mnt; out_free:	mnt_free_id(mnt);	free_vfsmnt(mnt);	return ERR_PTR(err);}",31133
336,1135,CVE-2013-1858,25,"static inline void free_signal_struct(struct signal_struct *sig){	taskstats_tgid_free(sig);	sched_autogroup_exit(sig);	kmem_cache_free(signal_cachep, sig);}",9347
180,619,CVE-2011-4112,25,"static void veth_dellink(struct net_device *dev, struct list_head *head){	struct veth_priv *priv;	struct net_device *peer;	priv = netdev_priv(dev);	peer = priv->peer;	unregister_netdevice_queue(dev, head);	unregister_netdevice_queue(peer, head);}",5344
585,2053,CVE-2014-9644,25,void mcryptd_free_ahash(struct mcryptd_ahash *tfm){	crypto_free_ahash(&tfm->base);},14387
773,2284,CVE-2013-7421,25,"static int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,		     struct scatterlist *src, unsigned int nbytes){	struct blkcipher_walk walk;	int err;	blkcipher_walk_init(&walk, dst, src, nbytes);	err = blkcipher_walk_virt_block(desc, &walk, BF_BLOCK_SIZE);	while ((nbytes = walk.nbytes) >= BF_BLOCK_SIZE) {		nbytes = __ctr_crypt(desc, &walk);		err = blkcipher_walk_done(desc, &walk, nbytes);	}	if (walk.nbytes) {		ctr_crypt_final(crypto_blkcipher_ctx(desc->tfm), &walk);		err = blkcipher_walk_done(desc, &walk, 0);	}	return err;}",14714
102,2364,CVE-2013-7421,25,"static void xor_vectors(unsigned char *in1, unsigned char *in2,			unsigned char *out, unsigned int size){	int i;	for (i = 0; i < size; i++)		out[i] = in1[i] ^ in2[i];}",14794
152,1856,CVE-2014-9644,25,"static int crypto_remove_alg(struct crypto_alg *alg, struct list_head *list){	if (unlikely(list_empty(&alg->cra_list)))		return -ENOENT;	alg->cra_flags |= CRYPTO_ALG_DEAD;	crypto_notify(CRYPTO_MSG_ALG_UNREGISTER, alg);	list_del_init(&alg->cra_list);	crypto_remove_spawns(alg, list, NULL);	return 0;}",14190
210,932,CVE-2013-6431,25,"static void fib6_prune_clones(struct net *net, struct fib6_node *fn,			      struct rt6_info *rt){	fib6_clean_tree(net, fn, fib6_prune_clone, 1, rt);}",7200
14,525,CVE-2011-4112,25,"static int bond_neigh_setup(struct net_device *dev, struct neigh_parms *parms){	struct bonding *bond = netdev_priv(dev);	struct slave *slave = bond->first_slave;	if (slave) {		const struct net_device_ops *slave_ops			= slave->dev->netdev_ops;		if (slave_ops->ndo_neigh_setup)			return slave_ops->ndo_neigh_setup(slave->dev, parms);	}	return 0;}",5250
360,1273,CVE-2014-9322,25,"show_stack_log_lvl(struct task_struct *task, struct pt_regs *regs,		   unsigned long *sp, unsigned long bp, char *log_lvl){	unsigned long *irq_stack_end;	unsigned long *irq_stack;	unsigned long *stack;	int cpu;	int i;	preempt_disable();	cpu = smp_processor_id();	irq_stack_end	= (unsigned long *)(per_cpu(irq_stack_ptr, cpu));	irq_stack	= (unsigned long *)(per_cpu(irq_stack_ptr, cpu) - IRQ_STACK_SIZE);	 	if (sp == NULL) {		if (task)			sp = (unsigned long *)task->thread.sp;		else			sp = (unsigned long *)&sp;	}	stack = sp;	for (i = 0; i < kstack_depth_to_print; i++) {		if (stack >= irq_stack && stack <= irq_stack_end) {			if (stack == irq_stack_end) {				stack = (unsigned long *) (irq_stack_end[-1]);				pr_cont("" <EOI> "");			}		} else {		if (((long) stack & (THREAD_SIZE-1)) == 0)			break;		}		if (i && ((i % STACKSLOTS_PER_LINE) == 0))			pr_cont(""\n"");		pr_cont("" %016lx"", *stack++);		touch_nmi_watchdog();	}	preempt_enable();	pr_cont(""\n"");	show_trace_log_lvl(task, regs, sp, bp, log_lvl);}",10376
597,1139,CVE-2013-1858,25,"static void free_thread_info(struct thread_info *ti){	kmem_cache_free(thread_info_cache, ti);}",9351
365,1573,CVE-2014-3153,25,"double_lock_hb(struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2){	if (hb1 <= hb2) {		spin_lock(&hb1->lock);		if (hb1 < hb2)			spin_lock_nested(&hb2->lock, SINGLE_DEPTH_NESTING);	} else {  		spin_lock(&hb2->lock);		spin_lock_nested(&hb1->lock, SINGLE_DEPTH_NESTING);	}}",11529
763,563,CVE-2011-4112,25,"static int macvlan_changelink(struct net_device *dev,		struct nlattr *tb[], struct nlattr *data[]){	struct macvlan_dev *vlan = netdev_priv(dev);	if (data && data[IFLA_MACVLAN_MODE])		vlan->mode = nla_get_u32(data[IFLA_MACVLAN_MODE]);	return 0;}",5288
345,2113,CVE-2014-9644,25,"static int encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,		   struct scatterlist *src, unsigned int nbytes){	struct priv *ctx = crypto_blkcipher_ctx(desc->tfm);	struct blkcipher_walk w;	blkcipher_walk_init(&w, dst, src, nbytes);	return crypt(desc, &w, ctx, crypto_cipher_alg(ctx->tweak)->cia_encrypt,		     crypto_cipher_alg(ctx->child)->cia_encrypt);}",14447
493,1638,CVE-2014-3122,25,"vma_address(struct page *page, struct vm_area_struct *vma){	unsigned long address = __vma_address(page, vma);	 	VM_BUG_ON(address < vma->vm_start || address >= vma->vm_end);	return address;}",11609
504,2953,CVE-2015-6768,25,    ParseQualifiedNameResult() { },29617
765,1115,CVE-2013-1957,25,"static struct mount *get_source(struct mount *dest,				struct mount *last_dest,				struct mount *last_src,				int *type){	struct mount *p_last_src = NULL;	struct mount *p_last_dest = NULL;	while (last_dest != dest->mnt_master) {		p_last_dest = last_dest;		p_last_src = last_src;		last_dest = last_dest->mnt_master;		last_src = last_src->mnt_master;	}	if (p_last_dest) {		do {			p_last_dest = next_peer(p_last_dest);		} while (IS_MNT_NEW(p_last_dest));		 		if (dest == p_last_dest) {			*type = CL_MAKE_SHARED;			return p_last_src;		}	}	 	*type = CL_SLAVE;	 	if (IS_MNT_SHARED(dest))		*type |= CL_MAKE_SHARED;	return last_src;}",9196
237,1217,CVE-2011-1019,25,"int dev_forward_skb(struct net_device *dev, struct sk_buff *skb){	skb_orphan(skb);	nf_reset(skb);	if (unlikely(!(dev->flags & IFF_UP) ||		     (skb->len > (dev->mtu + dev->hard_header_len + VLAN_HLEN)))) {		atomic_long_inc(&dev->rx_dropped);		kfree_skb(skb);		return NET_RX_DROP;	}	skb_set_dev(skb, dev);	skb->tstamp.tv64 = 0;	skb->pkt_type = PACKET_HOST;	skb->protocol = eth_type_trans(skb, dev);	return netif_rx(skb);}",10306
348,1709,CVE-2014-1738,25,"static int set_geometry(unsigned int cmd, struct floppy_struct *g,			       int drive, int type, struct block_device *bdev){	int cnt;	 	if (g->sect <= 0 ||	    g->head <= 0 ||	    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||	     	    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)		return -EINVAL;	if (type) {		if (!capable(CAP_SYS_ADMIN))			return -EPERM;		mutex_lock(&open_lock);		if (lock_fdc(drive, true)) {			mutex_unlock(&open_lock);			return -EINTR;		}		floppy_type[type] = *g;		floppy_type[type].name = ""user format"";		for (cnt = type << 2; cnt < (type << 2) + 4; cnt++)			floppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =			    floppy_type[type].size + 1;		process_fd_request();		for (cnt = 0; cnt < N_DRIVE; cnt++) {			struct block_device *bdev = opened_bdev[cnt];			if (!bdev || ITYPE(drive_state[cnt].fd_device) != type)				continue;			__invalidate_device(bdev, true);		}		mutex_unlock(&open_lock);	} else {		int oldStretch;		if (lock_fdc(drive, true))			return -EINTR;		if (cmd != FDDEFPRM) {			 			if (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)				return -EINTR;		}		oldStretch = g->stretch;		user_params[drive] = *g;		if (buffer_drive == drive)			SUPBOUND(buffer_max, user_params[drive].sect);		current_type[drive] = &user_params[drive];		floppy_sizes[drive] = user_params[drive].size;		if (cmd == FDDEFPRM)			DRS->keep_data = -1;		else			DRS->keep_data = 1;		 		if (DRS->maxblock > user_params[drive].sect ||		    DRS->maxtrack ||		    ((user_params[drive].sect ^ oldStretch) &		     (FD_SWAPSIDES | FD_SECTBASEMASK)))			invalidate_drive(bdev);		else			process_fd_request();	}	return 0;}",12002
450,1430,CVE-2014-3610,25,static int bp_interception(struct vcpu_svm *svm){	struct kvm_run *kvm_run = svm->vcpu.run;	kvm_run->exit_reason = KVM_EXIT_DEBUG;	kvm_run->debug.arch.pc = svm->vmcb->save.cs.base + svm->vmcb->save.rip;	kvm_run->debug.arch.exception = BP_VECTOR;	return 0;},11292
772,1922,CVE-2014-9644,25,static void cmac_exit_tfm(struct crypto_tfm *tfm){	struct cmac_tfm_ctx *ctx = crypto_tfm_ctx(tfm);	crypto_free_cipher(ctx->child);},14256
413,3002,CVE-2016-2420,25,static int signal_has_si_addr(int sig) { switch (sig) { case SIGBUS: case SIGFPE: case SIGILL: case SIGSEGV: case SIGTRAP: return true; default: return false; }},30675
510,156,CVE-2012-2121,25,"static void kvm_free_physmem_slot(struct kvm_memory_slot *free,				  struct kvm_memory_slot *dont){	int i;	if (!dont || free->rmap != dont->rmap)		vfree(free->rmap);	if (!dont || free->dirty_bitmap != dont->dirty_bitmap)		kvm_destroy_dirty_bitmap(free);	for (i = 0; i < KVM_NR_PAGE_SIZES - 1; ++i) {		if (!dont || free->lpage_info[i] != dont->lpage_info[i]) {			vfree(free->lpage_info[i]);			free->lpage_info[i] = NULL;		}	}	free->npages = 0;	free->rmap = NULL;}",3554
565,700,CVE-2011-4112,25,int ar6000_stop_ap_interface(struct ar6_softc *ar){    struct ar_virtual_interface *arApDev;         arApDev = (struct ar_virtual_interface *)ar->arApDev;    if (arApDev) {        ar->arNetDev = arApDev->arStaNetDev;    }    return 0;},5425
78,3026,CVE-2015-6640,25,"static void migrate_to_reboot_cpu(void){   int cpu = 0;	cpu_hotplug_disable();   if (!cpu_online(cpu))		cpu = cpumask_first(cpu_online_mask);  	current->flags |= PF_NO_SETAFFINITY;  	set_cpus_allowed_ptr(current, cpumask_of(cpu));}",30714
495,1187,CVE-2011-4347,25,"static int assigned_device_enable_host_msix(struct kvm *kvm,					    struct kvm_assigned_dev_kernel *dev){	int i, r = -EINVAL;	 	if (dev->entries_nr == 0)		return r;	r = pci_enable_msix(dev->dev, dev->host_msix_entries, dev->entries_nr);	if (r)		return r;	for (i = 0; i < dev->entries_nr; i++) {		r = request_threaded_irq(dev->host_msix_entries[i].vector,					 NULL, kvm_assigned_dev_thread,					 0, dev->irq_name, (void *)dev);		if (r)			goto err;	}	return 0;err:	for (i -= 1; i >= 0; i--)		free_irq(dev->host_msix_entries[i].vector, (void *)dev);	pci_disable_msix(dev->dev);	return r;}",10046
621,1060,CVE-2013-1957,25,"int finish_automount(struct vfsmount *m, struct path *path){	struct mount *mnt = real_mount(m);	int err;	 	BUG_ON(mnt_get_count(mnt) < 2);	if (m->mnt_sb == path->mnt->mnt_sb &&	    m->mnt_root == path->dentry) {		err = -ELOOP;		goto fail;	}	err = do_add_mount(mnt, path, path->mnt->mnt_flags | MNT_SHRINKABLE);	if (!err)		return 0;fail:	 	if (!list_empty(&mnt->mnt_expire)) {		down_write(&namespace_sem);		br_write_lock(&vfsmount_lock);		list_del_init(&mnt->mnt_expire);		br_write_unlock(&vfsmount_lock);		up_write(&namespace_sem);	}	mntput(m);	mntput(m);	return err;}",9141
720,1587,CVE-2014-3122,25,SYSCALL_DEFINE0(munlockall){	int ret;	down_write(&current->mm->mmap_sem);	ret = do_mlockall(0);	up_write(&current->mm->mmap_sem);	return ret;},11558
540,2028,CVE-2014-9644,25,"static void gcm_hash_final_done(struct crypto_async_request *areq, int err){	struct aead_request *req = areq->data;	__gcm_hash_final_done(req, err);}",14362
609,1562,CVE-2014-3610,25,"static int vcpu_enter_guest(struct kvm_vcpu *vcpu){	int r;	int req_int_win = !irqchip_in_kernel(vcpu->kvm) &&		vcpu->run->request_interrupt_window;	int req_immediate_exit = false;	if (vcpu->requests) {		if (kvm_check_request(KVM_REQ_MMU_RELOAD, vcpu))			kvm_mmu_unload(vcpu);		if (kvm_check_request(KVM_REQ_MIGRATE_TIMER, vcpu))			__kvm_migrate_timers(vcpu);		if (kvm_check_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu))			kvm_gen_update_masterclock(vcpu->kvm);		if (kvm_check_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu))			kvm_gen_kvmclock_update(vcpu);		if (kvm_check_request(KVM_REQ_CLOCK_UPDATE, vcpu)) {			r = kvm_guest_time_update(vcpu);			if (unlikely(r))				goto out;		}		if (kvm_check_request(KVM_REQ_MMU_SYNC, vcpu))			kvm_mmu_sync_roots(vcpu);		if (kvm_check_request(KVM_REQ_TLB_FLUSH, vcpu))			kvm_vcpu_flush_tlb(vcpu);		if (kvm_check_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu)) {			vcpu->run->exit_reason = KVM_EXIT_TPR_ACCESS;			r = 0;			goto out;		}		if (kvm_check_request(KVM_REQ_TRIPLE_FAULT, vcpu)) {			vcpu->run->exit_reason = KVM_EXIT_SHUTDOWN;			r = 0;			goto out;		}		if (kvm_check_request(KVM_REQ_DEACTIVATE_FPU, vcpu)) {			vcpu->fpu_active = 0;			kvm_x86_ops->fpu_deactivate(vcpu);		}		if (kvm_check_request(KVM_REQ_APF_HALT, vcpu)) {			 			vcpu->arch.apf.halted = true;			r = 1;			goto out;		}		if (kvm_check_request(KVM_REQ_STEAL_UPDATE, vcpu))			record_steal_time(vcpu);		if (kvm_check_request(KVM_REQ_NMI, vcpu))			process_nmi(vcpu);		if (kvm_check_request(KVM_REQ_PMU, vcpu))			kvm_handle_pmu_event(vcpu);		if (kvm_check_request(KVM_REQ_PMI, vcpu))			kvm_deliver_pmi(vcpu);		if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu))			vcpu_scan_ioapic(vcpu);		if (kvm_check_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu))			kvm_vcpu_reload_apic_access_page(vcpu);	}	if (kvm_check_request(KVM_REQ_EVENT, vcpu) || req_int_win) {		kvm_apic_accept_events(vcpu);		if (vcpu->arch.mp_state == KVM_MP_STATE_INIT_RECEIVED) {			r = 1;			goto out;		}		if (inject_pending_event(vcpu, req_int_win) != 0)			req_immediate_exit = true;		 		else if (vcpu->arch.nmi_pending)			kvm_x86_ops->enable_nmi_window(vcpu);		else if (kvm_cpu_has_injectable_intr(vcpu) || req_int_win)			kvm_x86_ops->enable_irq_window(vcpu);		if (kvm_lapic_enabled(vcpu)) {			 			if (kvm_x86_ops->hwapic_irr_update)				kvm_x86_ops->hwapic_irr_update(vcpu,					kvm_lapic_find_highest_irr(vcpu));			update_cr8_intercept(vcpu);			kvm_lapic_sync_to_vapic(vcpu);		}	}	r = kvm_mmu_reload(vcpu);	if (unlikely(r)) {		goto cancel_injection;	}	preempt_disable();	kvm_x86_ops->prepare_guest_switch(vcpu);	if (vcpu->fpu_active)		kvm_load_guest_fpu(vcpu);	kvm_load_guest_xcr0(vcpu);	vcpu->mode = IN_GUEST_MODE;	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);	 	smp_mb__after_srcu_read_unlock();	local_irq_disable();	if (vcpu->mode == EXITING_GUEST_MODE || vcpu->requests	    || need_resched() || signal_pending(current)) {		vcpu->mode = OUTSIDE_GUEST_MODE;		smp_wmb();		local_irq_enable();		preempt_enable();		vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);		r = 1;		goto cancel_injection;	}	if (req_immediate_exit)		smp_send_reschedule(vcpu->cpu);	kvm_guest_enter();	if (unlikely(vcpu->arch.switch_db_regs)) {		set_debugreg(0, 7);		set_debugreg(vcpu->arch.eff_db[0], 0);		set_debugreg(vcpu->arch.eff_db[1], 1);		set_debugreg(vcpu->arch.eff_db[2], 2);		set_debugreg(vcpu->arch.eff_db[3], 3);		set_debugreg(vcpu->arch.dr6, 6);	}	trace_kvm_entry(vcpu->vcpu_id);	kvm_x86_ops->run(vcpu);	 	if (unlikely(vcpu->arch.switch_db_regs & KVM_DEBUGREG_WONT_EXIT)) {		int i;		WARN_ON(vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP);		kvm_x86_ops->sync_dirty_debug_regs(vcpu);		for (i = 0; i < KVM_NR_DB_REGS; i++)			vcpu->arch.eff_db[i] = vcpu->arch.db[i];	}	 	if (hw_breakpoint_active())		hw_breakpoint_restore();	vcpu->arch.last_guest_tsc = kvm_x86_ops->read_l1_tsc(vcpu,							   native_read_tsc());	vcpu->mode = OUTSIDE_GUEST_MODE;	smp_wmb();	 	kvm_x86_ops->handle_external_intr(vcpu);	++vcpu->stat.exits;	 	barrier();	kvm_guest_exit();	preempt_enable();	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);	 	if (unlikely(prof_on == KVM_PROFILING)) {		unsigned long rip = kvm_rip_read(vcpu);		profile_hit(KVM_PROFILING, (void *)rip);	}	if (unlikely(vcpu->arch.tsc_always_catchup))		kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);	if (vcpu->arch.apic_attention)		kvm_lapic_sync_from_vapic(vcpu);	r = kvm_x86_ops->handle_exit(vcpu);	return r;cancel_injection:	kvm_x86_ops->cancel_injection(vcpu);	if (unlikely(vcpu->arch.apic_attention))		kvm_lapic_sync_from_vapic(vcpu);out:	return r;}",11424
497,2150,CVE-2014-7822,25,"static int ext2_release_file (struct inode * inode, struct file * filp){	if (filp->f_mode & FMODE_WRITE) {		mutex_lock(&EXT2_I(inode)->truncate_mutex);		ext2_discard_reservation(inode);		mutex_unlock(&EXT2_I(inode)->truncate_mutex);	}	return 0;}",14565
769,70,CVE-2014-7815,25,static const char *code2name(int keycode){    return QKeyCode_lookup[qemu_input_key_number_to_qcode(keycode)];},1313
98,1241,CVE-2011-1019,25,"static inline int skb_needs_linearize(struct sk_buff *skb,				      int features){	return skb_is_nonlinear(skb) &&			((skb_has_frag_list(skb) &&				!(features & NETIF_F_FRAGLIST)) ||			(skb_shinfo(skb)->nr_frags &&				!(features & NETIF_F_SG)));}",10330
750,1163,CVE-2013-1774,25,static int edge_port_remove(struct usb_serial_port *port){	struct edgeport_port *edge_port;	edge_port = usb_get_serial_port_data(port);	edge_remove_sysfs_attrs(port);	kfifo_free(&edge_port->write_fifo);	kfree(edge_port);	return 0;},9548
761,2204,CVE-2014-7822,25,"static int ubifs_vm_page_mkwrite(struct vm_area_struct *vma,				 struct vm_fault *vmf){	struct page *page = vmf->page;	struct inode *inode = file_inode(vma->vm_file);	struct ubifs_info *c = inode->i_sb->s_fs_info;	struct timespec now = ubifs_current_time(inode);	struct ubifs_budget_req req = { .new_page = 1 };	int err, update_time;	dbg_gen(""ino %lu, pg %lu, i_size %lld"",	inode->i_ino, page->index,		i_size_read(inode));	ubifs_assert(!c->ro_media && !c->ro_mount);	if (unlikely(c->ro_error))		return VM_FAULT_SIGBUS;  	 	update_time = mctime_update_needed(inode, &now);	if (update_time)		 		req.dirtied_ino = 1;	err = ubifs_budget_space(c, &req);	if (unlikely(err)) {		if (err == -ENOSPC)			ubifs_warn(""out of space for mmapped file (inode number %lu)"",				   inode->i_ino);		return VM_FAULT_SIGBUS;	}	lock_page(page);	if (unlikely(page->mapping != inode->i_mapping ||		     page_offset(page) > i_size_read(inode))) {		 		err = -EINVAL;		goto out_unlock;	}	if (PagePrivate(page))		release_new_page_budget(c);	else {		if (!PageChecked(page))			ubifs_convert_page_budget(c);		SetPagePrivate(page);		atomic_long_inc(&c->dirty_pg_cnt);		__set_page_dirty_nobuffers(page);	}	if (update_time) {		int release;		struct ubifs_inode *ui = ubifs_inode(inode);		mutex_lock(&ui->ui_mutex);		inode->i_mtime = inode->i_ctime = ubifs_current_time(inode);		release = ui->dirty;		mark_inode_dirty_sync(inode);		mutex_unlock(&ui->ui_mutex);		if (release)			ubifs_release_dirty_inode_budget(c, ui);	}	wait_for_stable_page(page);	unlock_page(page);	return 0;out_unlock:	unlock_page(page);	ubifs_release_budget(c, &req);	if (err)		err = VM_FAULT_SIGBUS;	return err;}",14619
716,2148,CVE-2014-7822,25,"int thaw_bdev(struct block_device *bdev, struct super_block *sb){	int error = -EINVAL;	mutex_lock(&bdev->bd_fsfreeze_mutex);	if (!bdev->bd_fsfreeze_count)		goto out;	error = 0;	if (--bdev->bd_fsfreeze_count > 0)		goto out;	if (!sb)		goto out;	error = thaw_super(sb);	if (error) {		bdev->bd_fsfreeze_count++;		mutex_unlock(&bdev->bd_fsfreeze_mutex);		return error;	}out:	mutex_unlock(&bdev->bd_fsfreeze_mutex);	return 0;}",14563
189,1461,CVE-2014-3610,25,"static int nested_svm_check_permissions(struct vcpu_svm *svm){	if (!(svm->vcpu.arch.efer & EFER_SVME)	    || !is_paging(&svm->vcpu)) {		kvm_queue_exception(&svm->vcpu, UD_VECTOR);		return 1;	}	if (svm->vmcb->save.cpl) {		kvm_inject_gp(&svm->vcpu, 0);		return 1;	}       return 0;}",11323
357,2578,CVE-2016-6787,25,"inline void perf_swevent_put_recursion_context(int rctx){	struct swevent_htable *swhash = this_cpu_ptr(&swevent_htable);	put_recursion_context(swhash->recursion, rctx);}",15983
409,1140,CVE-2013-1858,25,struct file *get_mm_exe_file(struct mm_struct *mm){	struct file *exe_file;	 	down_read(&mm->mmap_sem);	exe_file = mm->exe_file;	if (exe_file)		get_file(exe_file);	up_read(&mm->mmap_sem);	return exe_file;},9352
140,1795,CVE-2015-1593,25,"static int load_elf_library(struct file *file){	struct elf_phdr *elf_phdata;	struct elf_phdr *eppnt;	unsigned long elf_bss, bss, len;	int retval, error, i, j;	struct elfhdr elf_ex;	error = -ENOEXEC;	retval = kernel_read(file, 0, (char *)&elf_ex, sizeof(elf_ex));	if (retval != sizeof(elf_ex))		goto out;	if (memcmp(elf_ex.e_ident, ELFMAG, SELFMAG) != 0)		goto out;	 	if (elf_ex.e_type != ET_EXEC || elf_ex.e_phnum > 2 ||	    !elf_check_arch(&elf_ex) || !file->f_op->mmap)		goto out;	 	j = sizeof(struct elf_phdr) * elf_ex.e_phnum;	 	error = -ENOMEM;	elf_phdata = kmalloc(j, GFP_KERNEL);	if (!elf_phdata)		goto out;	eppnt = elf_phdata;	error = -ENOEXEC;	retval = kernel_read(file, elf_ex.e_phoff, (char *)eppnt, j);	if (retval != j)		goto out_free_ph;	for (j = 0, i = 0; i<elf_ex.e_phnum; i++)		if ((eppnt + i)->p_type == PT_LOAD)			j++;	if (j != 1)		goto out_free_ph;	while (eppnt->p_type != PT_LOAD)		eppnt++;	 	error = vm_mmap(file,			ELF_PAGESTART(eppnt->p_vaddr),			(eppnt->p_filesz +			 ELF_PAGEOFFSET(eppnt->p_vaddr)),			PROT_READ | PROT_WRITE | PROT_EXEC,			MAP_FIXED | MAP_PRIVATE | MAP_DENYWRITE,			(eppnt->p_offset -			 ELF_PAGEOFFSET(eppnt->p_vaddr)));	if (error != ELF_PAGESTART(eppnt->p_vaddr))		goto out_free_ph;	elf_bss = eppnt->p_vaddr + eppnt->p_filesz;	if (padzero(elf_bss)) {		error = -EFAULT;		goto out_free_ph;	}	len = ELF_PAGESTART(eppnt->p_filesz + eppnt->p_vaddr +			    ELF_MIN_ALIGN - 1);	bss = eppnt->p_memsz + eppnt->p_vaddr;	if (bss > len)		vm_brk(len, bss - len);	error = 0;out_free_ph:	kfree(elf_phdata);out:	return error;}",13828
462,1192,CVE-2011-4347,25,"static int kvm_vm_ioctl_assign_irq(struct kvm *kvm,				   struct kvm_assigned_irq *assigned_irq){	int r = -EINVAL;	struct kvm_assigned_dev_kernel *match;	unsigned long host_irq_type, guest_irq_type;	if (!irqchip_in_kernel(kvm))		return r;	mutex_lock(&kvm->lock);	r = -ENODEV;	match = kvm_find_assigned_dev(&kvm->arch.assigned_dev_head,				      assigned_irq->assigned_dev_id);	if (!match)		goto out;	host_irq_type = (assigned_irq->flags & KVM_DEV_IRQ_HOST_MASK);	guest_irq_type = (assigned_irq->flags & KVM_DEV_IRQ_GUEST_MASK);	r = -EINVAL;	 	if (hweight_long(host_irq_type) > 1)		goto out;	if (hweight_long(guest_irq_type) > 1)		goto out;	if (host_irq_type == 0 && guest_irq_type == 0)		goto out;	r = 0;	if (host_irq_type)		r = assign_host_irq(kvm, match, host_irq_type);	if (r)		goto out;	if (guest_irq_type)		r = assign_guest_irq(kvm, match, assigned_irq, guest_irq_type);out:	mutex_unlock(&kvm->lock);	return r;}",10051
718,1069,CVE-2013-1957,25,void kern_unmount(struct vfsmount *mnt){	 	if (!IS_ERR_OR_NULL(mnt)) {		br_write_lock(&vfsmount_lock);		real_mount(mnt)->mnt_ns = NULL;		br_write_unlock(&vfsmount_lock);		mntput(mnt);	}},9150
358,2418,CVE-2013-7421,25,static int zlib_init(struct crypto_tfm *tfm){	return 0;},14848
758,575,CVE-2011-4112,25,"static int macvlan_port_create(struct net_device *dev){	struct macvlan_port *port;	unsigned int i;	int err;	if (dev->type != ARPHRD_ETHER || dev->flags & IFF_LOOPBACK)		return -EINVAL;	port = kzalloc(sizeof(*port), GFP_KERNEL);	if (port == NULL)		return -ENOMEM;	port->passthru = false;	port->dev = dev;	INIT_LIST_HEAD(&port->vlans);	for (i = 0; i < MACVLAN_HASH_SIZE; i++)		INIT_HLIST_HEAD(&port->vlan_hash[i]);	err = netdev_rx_handler_register(dev, macvlan_handle_frame, port);	if (err)		kfree(port);	else		dev->priv_flags |= IFF_MACVLAN_PORT;	return err;}",5300
521,1798,CVE-2015-1593,25,"static int write_note_info(struct elf_note_info *info,			   struct coredump_params *cprm){	int first = true;	struct elf_thread_core_info *t = info->thread;	do {		int i;		if (!writenote(&t->notes[0], cprm))			return 0;		if (first && !writenote(&info->psinfo, cprm))			return 0;		if (first && !writenote(&info->signote, cprm))			return 0;		if (first && !writenote(&info->auxv, cprm))			return 0;		if (first && info->files.data &&				!writenote(&info->files, cprm))			return 0;		for (i = 1; i < info->thread_notes; ++i)			if (t->notes[i].data &&			    !writenote(&t->notes[i], cprm))				return 0;		first = false;		t = t->next;	} while (t);	return 1;}",13831
110,2771,CVE-2014-9870,25,struct vm_area_struct *get_gate_vma(struct mm_struct *mm){	return &gate_vma;},19320
727,802,CVE-2011-2898,25,"static int packet_seq_show(struct seq_file *seq, void *v){	if (v == SEQ_START_TOKEN)		seq_puts(seq, ""sk       RefCnt Type Proto  Iface R Rmem   User   Inode\n"");	else {		struct sock *s = sk_entry(v);		const struct packet_sock *po = pkt_sk(s);		seq_printf(seq,			   ""%pK %-6d %-4d %04x   %-5d %1d %-6u %-6u %-6lu\n"",			   s,			   atomic_read(&s->sk_refcnt),			   s->sk_type,			   ntohs(po->num),			   po->ifindex,			   po->running,			   atomic_read(&s->sk_rmem_alloc),			   sock_i_uid(s),			   sock_i_ino(s));	}	return 0;}",6512
570,685,CVE-2011-4112,25,ar6000_cookie_cleanup(struct ar6_softc *ar){         ar->arCookieList = NULL;    ar->arCookieCount = 0;},5410
710,1407,CVE-2014-4014,25,"long prune_icache_sb(struct super_block *sb, unsigned long nr_to_scan,		     int nid){	LIST_HEAD(freeable);	long freed;	freed = list_lru_walk_node(&sb->s_inode_lru, nid, inode_lru_isolate,				       &freeable, &nr_to_scan);	dispose_list(&freeable);	return freed;}",10953
367,797,CVE-2011-2898,25,"static inline void *packet_previous_frame(struct packet_sock *po,		struct packet_ring_buffer *rb,		int status){	unsigned int previous = rb->head ? rb->head - 1 : rb->frame_max;	return packet_lookup_frame(po, rb, previous, status);}",6507
147,2440,CVE-2013-7421,25,"static void cryp_dma_done(struct cryp_ctx *ctx){	struct dma_chan *chan;	dev_dbg(ctx->device->dev, ""[%s]: "", __func__);	chan = ctx->device->dma.chan_mem2cryp;	dmaengine_device_control(chan, DMA_TERMINATE_ALL, 0);	dma_unmap_sg(chan->device->dev, ctx->device->dma.sg_src,		     ctx->device->dma.sg_src_len, DMA_TO_DEVICE);	chan = ctx->device->dma.chan_cryp2mem;	dmaengine_device_control(chan, DMA_TERMINATE_ALL, 0);	dma_unmap_sg(chan->device->dev, ctx->device->dma.sg_dst,		     ctx->device->dma.sg_dst_len, DMA_FROM_DEVICE);}",14870
308,628,CVE-2011-4112,25,"static int airo_get_frag(struct net_device *dev,			 struct iw_request_info *info,			 struct iw_param *vwrq,			 char *extra){	struct airo_info *local = dev->ml_priv;	readConfigRid(local, 1);	vwrq->value = le16_to_cpu(local->config.fragThresh);	vwrq->disabled = (vwrq->value >= AIRO_DEF_MTU);	vwrq->fixed = 1;	return 0;}",5353
478,219,CVE-2012-1179,25,"static void __mem_cgroup_cancel_charge(struct mem_cgroup *memcg,				       unsigned int nr_pages){	if (!mem_cgroup_is_root(memcg)) {		unsigned long bytes = nr_pages * PAGE_SIZE;		res_counter_uncharge(&memcg->res, bytes);		if (do_swap_account)			res_counter_uncharge(&memcg->memsw, bytes);	}}",3877
163,112,CVE-2012-2313,25,rio_init (void){	return pci_register_driver(&rio_driver);},3423
694,2293,CVE-2013-7421,25,"static int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,		       struct scatterlist *src, unsigned int nbytes){	return glue_ecb_crypt_128bit(&camellia_dec, desc, dst, src, nbytes);}",14723
457,798,CVE-2011-2898,25,"static int packet_rcv_spkt(struct sk_buff *skb, struct net_device *dev,			   struct packet_type *pt, struct net_device *orig_dev){	struct sock *sk;	struct sockaddr_pkt *spkt;	 	sk = pt->af_packet_priv;	 	if (skb->pkt_type == PACKET_LOOPBACK)		goto out;	if (!net_eq(dev_net(dev), sock_net(sk)))		goto out;	skb = skb_share_check(skb, GFP_ATOMIC);	if (skb == NULL)		goto oom;	 	skb_dst_drop(skb);	 	nf_reset(skb);	spkt = &PACKET_SKB_CB(skb)->sa.pkt;	skb_push(skb, skb->data - skb_mac_header(skb));	 	spkt->spkt_family = dev->type;	strlcpy(spkt->spkt_device, dev->name, sizeof(spkt->spkt_device));	spkt->spkt_protocol = skb->protocol;	 	if (sock_queue_rcv_skb(sk, skb) == 0)		return 0;out:	kfree_skb(skb);oom:	return 0;}",6508
183,1976,CVE-2014-9644,25,"static int crypto_cts_encrypt(struct blkcipher_desc *desc,			      struct scatterlist *dst, struct scatterlist *src,			      unsigned int nbytes){	struct crypto_cts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);	int bsize = crypto_blkcipher_blocksize(desc->tfm);	int tot_blocks = (nbytes + bsize - 1) / bsize;	int cbc_blocks = tot_blocks > 2 ? tot_blocks - 2 : 0;	struct blkcipher_desc lcldesc;	int err;	lcldesc.tfm = ctx->child;	lcldesc.info = desc->info;	lcldesc.flags = desc->flags;	if (tot_blocks == 1) {		err = crypto_blkcipher_encrypt_iv(&lcldesc, dst, src, bsize);	} else if (nbytes <= bsize * 2) {		err = cts_cbc_encrypt(ctx, desc, dst, src, 0, nbytes);	} else {		 		err = crypto_blkcipher_encrypt_iv(&lcldesc, dst, src,							cbc_blocks * bsize);		if (err == 0) {			 			err = cts_cbc_encrypt(ctx, desc, dst, src,						cbc_blocks * bsize,						nbytes - (cbc_blocks * bsize));		}	}	return err;}",14310
407,1576,CVE-2014-3153,25,"static void free_pi_state(struct futex_pi_state *pi_state){	if (!atomic_dec_and_test(&pi_state->refcount))		return;	 	if (pi_state->owner) {		raw_spin_lock_irq(&pi_state->owner->pi_lock);		list_del_init(&pi_state->list);		raw_spin_unlock_irq(&pi_state->owner->pi_lock);		rt_mutex_proxy_unlock(&pi_state->pi_mutex, pi_state->owner);	}	if (current->pi_state_cache)		kfree(pi_state);	else {		 		pi_state->owner = NULL;		atomic_set(&pi_state->refcount, 1);		current->pi_state_cache = pi_state;	}}",11532
68,2666,CVE-2016-4565,25,"static int allocate_ctxt(struct file *fp, struct hfi1_devdata *dd,			 struct hfi1_user_info *uinfo){	struct hfi1_filedata *fd = fp->private_data;	struct hfi1_ctxtdata *uctxt;	unsigned ctxt;	int ret, numa;	if (dd->flags & HFI1_FROZEN) {		 		return -EIO;	}	for (ctxt = dd->first_user_ctxt; ctxt < dd->num_rcv_contexts; ctxt++)		if (!dd->rcd[ctxt])			break;	if (ctxt == dd->num_rcv_contexts)		return -EBUSY;	fd->rec_cpu_num = hfi1_get_proc_affinity(dd, -1);	if (fd->rec_cpu_num != -1)		numa = cpu_to_node(fd->rec_cpu_num);	else		numa = numa_node_id();	uctxt = hfi1_create_ctxtdata(dd->pport, ctxt, numa);	if (!uctxt) {		dd_dev_err(dd,			   ""Unable to allocate ctxtdata memory, failing open\n"");		return -ENOMEM;	}	hfi1_cdbg(PROC, ""[%u:%u] pid %u assigned to CPU %d (NUMA %u)"",		  uctxt->ctxt, fd->subctxt, current->pid, fd->rec_cpu_num,		  uctxt->numa_id);	 	uctxt->sc = sc_alloc(dd, SC_USER, uctxt->rcvhdrqentsize,			     uctxt->dd->node);	if (!uctxt->sc)		return -ENOMEM;	hfi1_cdbg(PROC, ""allocated send context %u(%u)\n"", uctxt->sc->sw_index,		  uctxt->sc->hw_context);	ret = sc_enable(uctxt->sc);	if (ret)		return ret;	 	if (uinfo->subctxt_cnt && !fd->subctxt) {		ret = init_subctxts(uctxt, uinfo);		 		if (ret)			return ret;	}	uctxt->userversion = uinfo->userversion;	uctxt->pid = current->pid;	uctxt->flags = HFI1_CAP_UGET(MASK);	init_waitqueue_head(&uctxt->wait);	strlcpy(uctxt->comm, current->comm, sizeof(uctxt->comm));	memcpy(uctxt->uuid, uinfo->uuid, sizeof(uctxt->uuid));	uctxt->jkey = generate_jkey(current_uid());	INIT_LIST_HEAD(&uctxt->sdma_queues);	spin_lock_init(&uctxt->sdma_qlock);	hfi1_stats.sps_ctxts++;	 	if (dd->freectxts-- == dd->num_user_contexts)		aspm_disable_all(dd);	fd->uctxt = uctxt;	return 0;}",16820
653,2630,CVE-2016-4565,25,static void ucma_put_ctx(struct ucma_context *ctx){	if (atomic_dec_and_test(&ctx->ref))		complete(&ctx->comp);},16784
324,2917,CVE-2014-3647,25,"static int emulate_nm(struct x86_emulate_ctxt *ctxt){ 	return emulate_exception(ctxt, NM_VECTOR, 0, false); }",28353
201,1022,CVE-2013-2929,25,static int ignoring_children(struct sighand_struct *sigh){	int ret;	spin_lock(&sigh->siglock);	ret = (sigh->action[SIGCHLD-1].sa.sa_handler == SIG_IGN) ||	      (sigh->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDWAIT);	spin_unlock(&sigh->siglock);	return ret;},8476
5,216,CVE-2012-1179,25,"unsigned long task_statm(struct mm_struct *mm,			 unsigned long *shared, unsigned long *text,			 unsigned long *data, unsigned long *resident){	*shared = get_mm_counter(mm, MM_FILEPAGES);	*text = (PAGE_ALIGN(mm->end_code) - (mm->start_code & PAGE_MASK))								>> PAGE_SHIFT;	*data = mm->total_vm - mm->shared_vm;	*resident = *shared + get_mm_counter(mm, MM_ANONPAGES);	return mm->total_vm;}",3874
153,1042,CVE-2013-1957,25,"static void attach_mnt(struct mount *mnt, struct path *path){	mnt_set_mountpoint(real_mount(path->mnt), path->dentry, mnt);	list_add_tail(&mnt->mnt_hash, mount_hashtable +			hash(path->mnt, path->dentry));	list_add_tail(&mnt->mnt_child, &real_mount(path->mnt)->mnt_mounts);}",9123
193,2221,CVE-2013-7421,25,static int sha512_neon_init(struct shash_desc *desc){	struct sha512_state *sctx = shash_desc_ctx(desc);	sctx->state[0] = SHA512_H0;	sctx->state[1] = SHA512_H1;	sctx->state[2] = SHA512_H2;	sctx->state[3] = SHA512_H3;	sctx->state[4] = SHA512_H4;	sctx->state[5] = SHA512_H5;	sctx->state[6] = SHA512_H6;	sctx->state[7] = SHA512_H7;	sctx->count[0] = sctx->count[1] = 0;	return 0;},14651
296,1240,CVE-2011-1019,25,"static void rps_trigger_softirq(void *data){	struct softnet_data *sd = data;	____napi_schedule(sd, &sd->backlog);	sd->received_rps++;}",10329
74,538,CVE-2011-4112,25,"void bond_set_mode_ops(struct bonding *bond, int mode){	struct net_device *bond_dev = bond->dev;	switch (mode) {	case BOND_MODE_ROUNDROBIN:		break;	case BOND_MODE_ACTIVEBACKUP:		break;	case BOND_MODE_XOR:		bond_set_xmit_hash_policy(bond);		break;	case BOND_MODE_BROADCAST:		break;	case BOND_MODE_8023AD:		bond_set_xmit_hash_policy(bond);		break;	case BOND_MODE_ALB:		 	case BOND_MODE_TLB:		break;	default:		 		pr_err(""%s: Error: Unknown bonding mode %d\n"",		       bond_dev->name, mode);		break;	}}",5263
22,2310,CVE-2013-7421,25,"static int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,		       struct scatterlist *src, unsigned int nbytes){	return glue_ecb_crypt_128bit(&cast6_dec, desc, dst, src, nbytes);}",14740
19,2187,CVE-2014-7822,25,"int splice_grow_spd(const struct pipe_inode_info *pipe, struct splice_pipe_desc *spd){	unsigned int buffers = ACCESS_ONCE(pipe->buffers);	spd->nr_pages_max = buffers;	if (buffers <= PIPE_DEF_BUFFERS)		return 0;	spd->pages = kmalloc(buffers * sizeof(struct page *), GFP_KERNEL);	spd->partial = kmalloc(buffers * sizeof(struct partial_page), GFP_KERNEL);	if (spd->pages && spd->partial)		return 0;	kfree(spd->pages);	kfree(spd->partial);	return -ENOMEM;}",14602
144,2649,CVE-2016-4565,25,"void qib_cdev_cleanup(struct cdev **cdevp, struct device **devp){	struct device *device = *devp;	if (device) {		device_unregister(device);		*devp = NULL;	}	if (*cdevp) {		cdev_del(*cdevp);		*cdevp = NULL;	}}",16803
426,519,CVE-2011-4112,25,static int bond_event_changename(struct bonding *bond){	bond_remove_proc_entry(bond);	bond_create_proc_entry(bond);	bond_debug_reregister(bond);	return NOTIFY_DONE;},5244
115,306,CVE-2012-1179,25,"static int register_kmem_files(struct cgroup *cont, struct cgroup_subsys *ss){	 	return mem_cgroup_sockets_init(cont, ss);};",3964
691,3022,CVE-2015-6640,25,"void ctrl_alt_del(void){ static DECLARE_WORK(cad_work, deferred_cad); if (C_A_D)		schedule_work(&cad_work); else		kill_cad_pid(SIGINT, 1);}",30710
300,2101,CVE-2014-9644,25,static void seqiv_free(struct crypto_instance *inst){	if ((inst->alg.cra_flags ^ CRYPTO_ALG_TYPE_AEAD) & CRYPTO_ALG_TYPE_MASK)		skcipher_geniv_free(inst);	else		aead_geniv_free(inst);	crypto_put_default_rng();},14435
341,1007,CVE-2013-2929,25,"int remove_arg_zero(struct linux_binprm *bprm){	int ret = 0;	unsigned long offset;	char *kaddr;	struct page *page;	if (!bprm->argc)		return 0;	do {		offset = bprm->p & ~PAGE_MASK;		page = get_arg_page(bprm, bprm->p, 0);		if (!page) {			ret = -EFAULT;			goto out;		}		kaddr = kmap_atomic(page);		for (; offset < PAGE_SIZE && kaddr[offset];				offset++, bprm->p++)			;		kunmap_atomic(kaddr);		put_arg_page(page);		if (offset == PAGE_SIZE)			free_arg_page(bprm, (bprm->p >> PAGE_SHIFT) - 1);	} while (offset == PAGE_SIZE);	bprm->p++;	bprm->argc--;	ret = 0;out:	return ret;}",8461
543,1921,CVE-2014-9644,25,static void chainiv_module_exit(void){	crypto_unregister_template(&chainiv_tmpl);},14255
265,2638,CVE-2016-4565,25,"static unsigned int ib_uverbs_event_poll(struct file *filp,					 struct poll_table_struct *wait){	unsigned int pollflags = 0;	struct ib_uverbs_event_file *file = filp->private_data;	poll_wait(filp, &file->poll_wait, wait);	spin_lock_irq(&file->lock);	if (!list_empty(&file->event_list))		pollflags = POLLIN | POLLRDNORM;	spin_unlock_irq(&file->lock);	return pollflags;}",16792
234,1435,CVE-2014-3610,25,"static inline void clr_intercept(struct vcpu_svm *svm, int bit){	struct vmcb *vmcb = get_host_vmcb(svm);	vmcb->control.intercept &= ~(1ULL << bit);	recalc_intercepts(svm);}",11297
502,2758,CVE-2014-9888,25,"int arm_iommu_attach_device(struct device *dev,			    struct dma_iommu_mapping *mapping){	int err;	err = iommu_attach_device(mapping->domain, dev);	if (err)		return err;	kref_get(&mapping->kref);	dev->archdata.mapping = mapping;	set_dma_ops(dev, &iommu_ops);	pr_debug(""Attached IOMMU controller to %s device.\n"", dev_name(dev));	return 0;}",19307
299,2609,CVE-2016-4565,25,"static int ib_ucm_event_process(struct ib_cm_event *evt,				struct ib_ucm_event *uvt){	void *info = NULL;	switch (evt->event) {	case IB_CM_REQ_RECEIVED:		ib_ucm_event_req_get(&uvt->resp.u.req_resp,				     &evt->param.req_rcvd);		uvt->data_len      = IB_CM_REQ_PRIVATE_DATA_SIZE;		uvt->resp.present  = IB_UCM_PRES_PRIMARY;		uvt->resp.present |= (evt->param.req_rcvd.alternate_path ?				      IB_UCM_PRES_ALTERNATE : 0);		break;	case IB_CM_REP_RECEIVED:		ib_ucm_event_rep_get(&uvt->resp.u.rep_resp,				     &evt->param.rep_rcvd);		uvt->data_len = IB_CM_REP_PRIVATE_DATA_SIZE;		break;	case IB_CM_RTU_RECEIVED:		uvt->data_len = IB_CM_RTU_PRIVATE_DATA_SIZE;		uvt->resp.u.send_status = evt->param.send_status;		break;	case IB_CM_DREQ_RECEIVED:		uvt->data_len = IB_CM_DREQ_PRIVATE_DATA_SIZE;		uvt->resp.u.send_status = evt->param.send_status;		break;	case IB_CM_DREP_RECEIVED:		uvt->data_len = IB_CM_DREP_PRIVATE_DATA_SIZE;		uvt->resp.u.send_status = evt->param.send_status;		break;	case IB_CM_MRA_RECEIVED:		uvt->resp.u.mra_resp.timeout =					evt->param.mra_rcvd.service_timeout;		uvt->data_len = IB_CM_MRA_PRIVATE_DATA_SIZE;		break;	case IB_CM_REJ_RECEIVED:		uvt->resp.u.rej_resp.reason = evt->param.rej_rcvd.reason;		uvt->data_len = IB_CM_REJ_PRIVATE_DATA_SIZE;		uvt->info_len = evt->param.rej_rcvd.ari_length;		info	      = evt->param.rej_rcvd.ari;		break;	case IB_CM_LAP_RECEIVED:		ib_copy_path_rec_to_user(&uvt->resp.u.lap_resp.path,					 evt->param.lap_rcvd.alternate_path);		uvt->data_len = IB_CM_LAP_PRIVATE_DATA_SIZE;		uvt->resp.present = IB_UCM_PRES_ALTERNATE;		break;	case IB_CM_APR_RECEIVED:		uvt->resp.u.apr_resp.status = evt->param.apr_rcvd.ap_status;		uvt->data_len = IB_CM_APR_PRIVATE_DATA_SIZE;		uvt->info_len = evt->param.apr_rcvd.info_len;		info	      = evt->param.apr_rcvd.apr_info;		break;	case IB_CM_SIDR_REQ_RECEIVED:		uvt->resp.u.sidr_req_resp.pkey =					evt->param.sidr_req_rcvd.pkey;		uvt->resp.u.sidr_req_resp.port =					evt->param.sidr_req_rcvd.port;		uvt->data_len = IB_CM_SIDR_REQ_PRIVATE_DATA_SIZE;		break;	case IB_CM_SIDR_REP_RECEIVED:		ib_ucm_event_sidr_rep_get(&uvt->resp.u.sidr_rep_resp,					  &evt->param.sidr_rep_rcvd);		uvt->data_len = IB_CM_SIDR_REP_PRIVATE_DATA_SIZE;		uvt->info_len = evt->param.sidr_rep_rcvd.info_len;		info	      = evt->param.sidr_rep_rcvd.info;		break;	default:		uvt->resp.u.send_status = evt->param.send_status;		break;	}	if (uvt->data_len) {		uvt->data = kmemdup(evt->private_data, uvt->data_len, GFP_KERNEL);		if (!uvt->data)			goto err1;		uvt->resp.present |= IB_UCM_PRES_DATA;	}	if (uvt->info_len) {		uvt->info = kmemdup(info, uvt->info_len, GFP_KERNEL);		if (!uvt->info)			goto err2;		uvt->resp.present |= IB_UCM_PRES_INFO;	}	return 0;err2:	kfree(uvt->data);err1:	return -ENOMEM;}",16763
105,2209,CVE-2014-7822,25,"xfs_rw_ilock(	struct xfs_inode	*ip,	int			type){	if (type & XFS_IOLOCK_EXCL)		mutex_lock(&VFS_I(ip)->i_mutex);	xfs_ilock(ip, type);}",14624
166,1425,CVE-2014-4014,25,"static void warn_deprecated_v2(void){	char name[sizeof(current->comm)];	pr_info_once(""warning: `%s' uses deprecated v2 capabilities in a way that may be insecure\n"",		     get_task_comm(name, current));}",10971
692,1076,CVE-2013-1957,25,"int may_umount_tree(struct vfsmount *m){	struct mount *mnt = real_mount(m);	int actual_refs = 0;	int minimum_refs = 0;	struct mount *p;	BUG_ON(!m);	 	br_write_lock(&vfsmount_lock);	for (p = mnt; p; p = next_mnt(p, mnt)) {		actual_refs += mnt_get_count(p);		minimum_refs += 2;	}	br_write_unlock(&vfsmount_lock);	if (actual_refs > minimum_refs)		return 0;	return 1;}",9157
376,77,CVE-2015-8325,25,auth_sock_cleanup_proc(struct passwd *pw){	if (auth_sock_name != NULL) {		temporarily_use_uid(pw);		unlink(auth_sock_name);		rmdir(auth_sock_dir);		auth_sock_name = NULL;		restore_uid();	}},2255
456,2381,CVE-2013-7421,25,static void deflate_decomp_exit(struct deflate_ctx *ctx){	zlib_inflateEnd(&ctx->decomp_stream);	vfree(ctx->decomp_stream.workspace);},14811
489,2341,CVE-2013-7421,25,"static int sha1_ssse3_init(struct shash_desc *desc){	struct sha1_state *sctx = shash_desc_ctx(desc);	*sctx = (struct sha1_state){		.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },	};	return 0;}",14771
194,2057,CVE-2014-9644,25,static void mcryptd_hash_exit_tfm(struct crypto_tfm *tfm){	struct mcryptd_hash_ctx *ctx = crypto_tfm_ctx(tfm);	crypto_free_shash(ctx->child);},14391
649,334,CVE-2012-1179,25,"struct page *follow_page(struct vm_area_struct *vma, unsigned long address,			unsigned int flags){	pgd_t *pgd;	pud_t *pud;	pmd_t *pmd;	pte_t *ptep, pte;	spinlock_t *ptl;	struct page *page;	struct mm_struct *mm = vma->vm_mm;	page = follow_huge_addr(mm, address, flags & FOLL_WRITE);	if (!IS_ERR(page)) {		BUG_ON(flags & FOLL_GET);		goto out;	}	page = NULL;	pgd = pgd_offset(mm, address);	if (pgd_none(*pgd) || unlikely(pgd_bad(*pgd)))		goto no_page_table;	pud = pud_offset(pgd, address);	if (pud_none(*pud))		goto no_page_table;	if (pud_huge(*pud) && vma->vm_flags & VM_HUGETLB) {		BUG_ON(flags & FOLL_GET);		page = follow_huge_pud(mm, address, pud, flags & FOLL_WRITE);		goto out;	}	if (unlikely(pud_bad(*pud)))		goto no_page_table;	pmd = pmd_offset(pud, address);	if (pmd_none(*pmd))		goto no_page_table;	if (pmd_huge(*pmd) && vma->vm_flags & VM_HUGETLB) {		BUG_ON(flags & FOLL_GET);		page = follow_huge_pmd(mm, address, pmd, flags & FOLL_WRITE);		goto out;	}	if (pmd_trans_huge(*pmd)) {		if (flags & FOLL_SPLIT) {			split_huge_page_pmd(mm, pmd);			goto split_fallthrough;		}		spin_lock(&mm->page_table_lock);		if (likely(pmd_trans_huge(*pmd))) {			if (unlikely(pmd_trans_splitting(*pmd))) {				spin_unlock(&mm->page_table_lock);				wait_split_huge_page(vma->anon_vma, pmd);			} else {				page = follow_trans_huge_pmd(mm, address,							     pmd, flags);				spin_unlock(&mm->page_table_lock);				goto out;			}		} else			spin_unlock(&mm->page_table_lock);		 	}split_fallthrough:	if (unlikely(pmd_bad(*pmd)))		goto no_page_table;	ptep = pte_offset_map_lock(mm, pmd, address, &ptl);	pte = *ptep;	if (!pte_present(pte))		goto no_page;	if ((flags & FOLL_WRITE) && !pte_write(pte))		goto unlock;	page = vm_normal_page(vma, address, pte);	if (unlikely(!page)) {		if ((flags & FOLL_DUMP) ||		    !is_zero_pfn(pte_pfn(pte)))			goto bad_page;		page = pte_page(pte);	}	if (flags & FOLL_GET)		get_page_foll(page);	if (flags & FOLL_TOUCH) {		if ((flags & FOLL_WRITE) &&		    !pte_dirty(pte) && !PageDirty(page))			set_page_dirty(page);		 		mark_page_accessed(page);	}	if ((flags & FOLL_MLOCK) && (vma->vm_flags & VM_LOCKED)) {		 		if (page->mapping && trylock_page(page)) {			lru_add_drain();   			 			if (page->mapping)				mlock_vma_page(page);			unlock_page(page);		}	}unlock:	pte_unmap_unlock(ptep, ptl);out:	return page;bad_page:	pte_unmap_unlock(ptep, ptl);	return ERR_PTR(-EFAULT);no_page:	pte_unmap_unlock(ptep, ptl);	if (!pte_none(pte))		return page;no_page_table:	 	if ((flags & FOLL_DUMP) &&	    (!vma->vm_ops || !vma->vm_ops->fault))		return ERR_PTR(-EFAULT);	return page;}",3992
363,2480,CVE-2013-7421,25,"static int ux500_hash_resume(struct device *dev){	int ret = 0;	struct hash_device_data *device_data;	struct hash_ctx *temp_ctx = NULL;	device_data = dev_get_drvdata(dev);	if (!device_data) {		dev_err(dev, ""%s: platform_get_drvdata() failed!\n"", __func__);		return -ENOMEM;	}	spin_lock(&device_data->ctx_lock);	if (device_data->current_ctx == ++temp_ctx)		device_data->current_ctx = NULL;	spin_unlock(&device_data->ctx_lock);	if (!device_data->current_ctx)		up(&driver_data.device_allocation);	else		ret = hash_enable_power(device_data, true);	if (ret)		dev_err(dev, ""%s: hash_enable_power() failed!\n"", __func__);	return ret;}",14910
169,808,CVE-2011-2495,25,static struct mm_struct *check_mem_permission(struct task_struct *task){	struct mm_struct *mm;	int err;	 	err = mutex_lock_killable(&task->signal->cred_guard_mutex);	if (err)		return ERR_PTR(err);	mm = __check_mem_permission(task);	mutex_unlock(&task->signal->cred_guard_mutex);	return mm;},6605
79,2889,CVE-2011-4127,25,"static void sd_print_result(struct scsi_disk *sdkp, int result){	sd_printk(KERN_INFO, sdkp, "" "");	scsi_show_result(result);}",28272
446,2411,CVE-2013-7421,25,static int zlib_compress_init(struct crypto_pcomp *tfm){	int ret;	struct zlib_ctx *dctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));	struct z_stream_s *stream = &dctx->comp_stream;	ret = zlib_deflateReset(stream);	if (ret != Z_OK)		return -EINVAL;	return 0;},14841
403,925,CVE-2013-6431,25,"static int fib6_dump_node(struct fib6_walker_t *w){	int res;	struct rt6_info *rt;	for (rt = w->leaf; rt; rt = rt->dst.rt6_next) {		res = rt6_dump_route(rt, w->args);		if (res < 0) {			 			w->leaf = rt;			return 1;		}		WARN_ON(res == 0);	}	w->leaf = NULL;	return 0;}",7193
36,1759,CVE-2015-2150,25,"int xen_pcibk_config_add_field_offset(struct pci_dev *dev,				    const struct config_field *field,				    unsigned int base_offset){	int err = 0;	struct xen_pcibk_dev_data *dev_data = pci_get_drvdata(dev);	struct config_field_entry *cfg_entry;	void *tmp;	cfg_entry = kmalloc(sizeof(*cfg_entry), GFP_KERNEL);	if (!cfg_entry) {		err = -ENOMEM;		goto out;	}	cfg_entry->data = NULL;	cfg_entry->field = field;	cfg_entry->base_offset = base_offset;	 	err = xen_pcibk_field_is_dup(dev, OFFSET(cfg_entry));	if (err)		goto out;	if (field->init) {		tmp = field->init(dev, OFFSET(cfg_entry));		if (IS_ERR(tmp)) {			err = PTR_ERR(tmp);			goto out;		}		cfg_entry->data = tmp;	}	dev_dbg(&dev->dev, ""added config field at offset 0x%02x\n"",		OFFSET(cfg_entry));	list_add_tail(&cfg_entry->list, &dev_data->config_fields);out:	if (err)		kfree(cfg_entry);	return err;}",13760
361,1942,CVE-2014-9644,25,"static int cryptd_create_blkcipher(struct crypto_template *tmpl,				   struct rtattr **tb,				   struct cryptd_queue *queue){	struct cryptd_instance_ctx *ctx;	struct crypto_instance *inst;	struct crypto_alg *alg;	int err;	alg = crypto_get_attr_alg(tb, CRYPTO_ALG_TYPE_BLKCIPHER,				  CRYPTO_ALG_TYPE_MASK);	if (IS_ERR(alg))		return PTR_ERR(alg);	inst = cryptd_alloc_instance(alg, 0, sizeof(*ctx));	err = PTR_ERR(inst);	if (IS_ERR(inst))		goto out_put_alg;	ctx = crypto_instance_ctx(inst);	ctx->queue = queue;	err = crypto_init_spawn(&ctx->spawn, alg, inst,				CRYPTO_ALG_TYPE_MASK | CRYPTO_ALG_ASYNC);	if (err)		goto out_free_inst;	inst->alg.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC;	inst->alg.cra_type = &crypto_ablkcipher_type;	inst->alg.cra_ablkcipher.ivsize = alg->cra_blkcipher.ivsize;	inst->alg.cra_ablkcipher.min_keysize = alg->cra_blkcipher.min_keysize;	inst->alg.cra_ablkcipher.max_keysize = alg->cra_blkcipher.max_keysize;	inst->alg.cra_ablkcipher.geniv = alg->cra_blkcipher.geniv;	inst->alg.cra_ctxsize = sizeof(struct cryptd_blkcipher_ctx);	inst->alg.cra_init = cryptd_blkcipher_init_tfm;	inst->alg.cra_exit = cryptd_blkcipher_exit_tfm;	inst->alg.cra_ablkcipher.setkey = cryptd_blkcipher_setkey;	inst->alg.cra_ablkcipher.encrypt = cryptd_blkcipher_encrypt_enqueue;	inst->alg.cra_ablkcipher.decrypt = cryptd_blkcipher_decrypt_enqueue;	err = crypto_register_instance(tmpl, inst);	if (err) {		crypto_drop_spawn(&ctx->spawn);out_free_inst:		kfree(inst);	}out_put_alg:	crypto_mod_put(alg);	return err;}",14276
602,2591,CVE-2016-4997,25,"static int check_underflow(const struct ipt_entry *e){	const struct xt_entry_target *t;	unsigned int verdict;	if (!unconditional(e))		return false;	t = ipt_get_target_c(e);	if (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)		return false;	verdict = ((struct xt_standard_target *)t)->verdict;	verdict = -verdict - 1;	return verdict == NF_DROP || verdict == NF_ACCEPT;}",16592
208,2108,CVE-2014-9644,25,"static int xcbc_create(struct crypto_template *tmpl, struct rtattr **tb){	struct shash_instance *inst;	struct crypto_alg *alg;	unsigned long alignmask;	int err;	err = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SHASH);	if (err)		return err;	alg = crypto_get_attr_alg(tb, CRYPTO_ALG_TYPE_CIPHER,				  CRYPTO_ALG_TYPE_MASK);	if (IS_ERR(alg))		return PTR_ERR(alg);	switch(alg->cra_blocksize) {	case 16:		break;	default:		goto out_put_alg;	}	inst = shash_alloc_instance(""xcbc"", alg);	err = PTR_ERR(inst);	if (IS_ERR(inst))		goto out_put_alg;	err = crypto_init_spawn(shash_instance_ctx(inst), alg,				shash_crypto_instance(inst),				CRYPTO_ALG_TYPE_MASK);	if (err)		goto out_free_inst;	alignmask = alg->cra_alignmask | 3;	inst->alg.base.cra_alignmask = alignmask;	inst->alg.base.cra_priority = alg->cra_priority;	inst->alg.base.cra_blocksize = alg->cra_blocksize;	inst->alg.digestsize = alg->cra_blocksize;	inst->alg.descsize = ALIGN(sizeof(struct xcbc_desc_ctx),				   crypto_tfm_ctx_alignment()) +			     (alignmask &			      ~(crypto_tfm_ctx_alignment() - 1)) +			     alg->cra_blocksize * 2;	inst->alg.base.cra_ctxsize = ALIGN(sizeof(struct xcbc_tfm_ctx),					   alignmask + 1) +				     alg->cra_blocksize * 2;	inst->alg.base.cra_init = xcbc_init_tfm;	inst->alg.base.cra_exit = xcbc_exit_tfm;	inst->alg.init = crypto_xcbc_digest_init;	inst->alg.update = crypto_xcbc_digest_update;	inst->alg.final = crypto_xcbc_digest_final;	inst->alg.setkey = crypto_xcbc_digest_setkey;	err = shash_register_instance(tmpl, inst);	if (err) {out_free_inst:		shash_free_instance(shash_crypto_instance(inst));	}out_put_alg:	crypto_mod_put(alg);	return err;}",14442
584,1668,CVE-2014-1738,25,"static int floppy_resume(struct device *dev){	int fdc;	for (fdc = 0; fdc < N_FDC; fdc++)		if (FDCS->address != -1)			user_reset_fdc(-1, FD_RESET_ALWAYS, false);	return 0;}",11961
47,953,CVE-2013-4299,25,"static void clear_exception(struct pstore *ps, int index){	struct disk_exception *de = get_exception(ps, index);	 	de->old_chunk = 0;	de->new_chunk = 0;}",7850
249,1072,CVE-2013-1957,25,"static void m_stop(struct seq_file *m, void *v){	up_read(&namespace_sem);}",9153
443,241,CVE-2012-1179,25,"static void mem_cgroup_charge_statistics(struct mem_cgroup *memcg,					 int file, int nr_pages){	preempt_disable();	if (file)		__this_cpu_add(memcg->stat->count[MEM_CGROUP_STAT_CACHE],				nr_pages);	else		__this_cpu_add(memcg->stat->count[MEM_CGROUP_STAT_RSS],				nr_pages);	 	if (nr_pages > 0)		__this_cpu_inc(memcg->stat->events[MEM_CGROUP_EVENTS_PGPGIN]);	else {		__this_cpu_inc(memcg->stat->events[MEM_CGROUP_EVENTS_PGPGOUT]);		nr_pages = -nr_pages;  	}	__this_cpu_add(memcg->stat->events[MEM_CGROUP_EVENTS_COUNT], nr_pages);	preempt_enable();}",3899
542,2237,CVE-2013-7421,25,"static int fallback_init_cip(struct crypto_tfm *tfm){	const char *name = tfm->__crt_alg->cra_name;	struct s390_aes_ctx *sctx = crypto_tfm_ctx(tfm);	sctx->fallback.cip = crypto_alloc_cipher(name, 0,			CRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);	if (IS_ERR(sctx->fallback.cip)) {		pr_err(""Allocating AES fallback algorithm %s failed\n"",		       name);		return PTR_ERR(sctx->fallback.cip);	}	return 0;}",14667
125,2076,CVE-2014-9644,25,static void crypto_pcbc_free(struct crypto_instance *inst){	crypto_drop_spawn(crypto_instance_ctx(inst));	kfree(inst);},14410
369,900,CVE-2011-2486,25,"int id_create(void *ptr){  static int id = 0;  id_link(++id, ptr);  return id;}",6710
304,2538,CVE-2016-6787,25,static int is_kernel_event(struct perf_event *event){	return event->owner == EVENT_OWNER_KERNEL;},15943
677,2269,CVE-2013-7421,25,"static int md5_sparc64_export(struct shash_desc *desc, void *out){	struct md5_state *sctx = shash_desc_ctx(desc);	memcpy(out, sctx, sizeof(*sctx));	return 0;}",14699
28,1308,CVE-2014-5207,25,"static int do_move_mount(struct path *path, const char *old_name){	struct path old_path, parent_path;	struct mount *p;	struct mount *old;	struct mountpoint *mp;	int err;	if (!old_name || !*old_name)		return -EINVAL;	err = kern_path(old_name, LOOKUP_FOLLOW, &old_path);	if (err)		return err;	mp = lock_mount(path);	err = PTR_ERR(mp);	if (IS_ERR(mp))		goto out;	old = real_mount(old_path.mnt);	p = real_mount(path->mnt);	err = -EINVAL;	if (!check_mnt(p) || !check_mnt(old))		goto out1;	if (old->mnt.mnt_flags & MNT_LOCKED)		goto out1;	err = -EINVAL;	if (old_path.dentry != old_path.mnt->mnt_root)		goto out1;	if (!mnt_has_parent(old))		goto out1;	if (S_ISDIR(path->dentry->d_inode->i_mode) !=	      S_ISDIR(old_path.dentry->d_inode->i_mode))		goto out1;	 	if (IS_MNT_SHARED(old->mnt_parent))		goto out1;	 	if (IS_MNT_SHARED(p) && tree_contains_unbindable(old))		goto out1;	err = -ELOOP;	for (; mnt_has_parent(p); p = p->mnt_parent)		if (p == old)			goto out1;	err = attach_recursive_mnt(old, real_mount(path->mnt), mp, &parent_path);	if (err)		goto out1;	 	list_del_init(&old->mnt_expire);out1:	unlock_mount(mp);out:	if (!err)		path_put(&parent_path);	path_put(&old_path);	return err;}",10657
80,1967,CVE-2014-9644,25,static void crypto_ctr_exit_tfm(struct crypto_tfm *tfm){	struct crypto_ctr_ctx *ctx = crypto_tfm_ctx(tfm);	crypto_free_cipher(ctx->child);},14301
241,2172,CVE-2014-7822,25,"int reiserfs_commit_page(struct inode *inode, struct page *page,			 unsigned from, unsigned to){	unsigned block_start, block_end;	int partial = 0;	unsigned blocksize;	struct buffer_head *bh, *head;	unsigned long i_size_index = inode->i_size >> PAGE_CACHE_SHIFT;	int new;	int logit = reiserfs_file_data_log(inode);	struct super_block *s = inode->i_sb;	int bh_per_page = PAGE_CACHE_SIZE / s->s_blocksize;	struct reiserfs_transaction_handle th;	int ret = 0;	th.t_trans_id = 0;	blocksize = 1 << inode->i_blkbits;	if (logit) {		reiserfs_write_lock(s);		ret = journal_begin(&th, s, bh_per_page + 1);		if (ret)			goto drop_write_lock;		reiserfs_update_inode_transaction(inode);	}	for (bh = head = page_buffers(page), block_start = 0;	     bh != head || !block_start;	     block_start = block_end, bh = bh->b_this_page) {		new = buffer_new(bh);		clear_buffer_new(bh);		block_end = block_start + blocksize;		if (block_end <= from || block_start >= to) {			if (!buffer_uptodate(bh))				partial = 1;		} else {			set_buffer_uptodate(bh);			if (logit) {				reiserfs_prepare_for_journal(s, bh, 1);				journal_mark_dirty(&th, s, bh);			} else if (!buffer_dirty(bh)) {				mark_buffer_dirty(bh);				 				if (reiserfs_data_ordered(inode->i_sb) &&				    (new || page->index >= i_size_index)) {					reiserfs_add_ordered_list(inode, bh);				}			}		}	}	if (logit) {		ret = journal_end(&th, s, bh_per_page + 1);	      drop_write_lock:		reiserfs_write_unlock(s);	}	 	if (!partial)		SetPageUptodate(page);	return ret;}",14587
647,1362,CVE-2014-4027,25,static void rd_free_device(struct se_device *dev){	struct rd_dev *rd_dev = RD_DEV(dev);	rd_release_device_space(rd_dev);	kfree(rd_dev);},10908
381,2328,CVE-2013-7421,25,"static int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,		     struct scatterlist *src, unsigned int nbytes){	return glue_ctr_crypt_128bit(&serpent_ctr, desc, dst, src, nbytes);}",14758
651,3023,CVE-2015-6640,25,"int do_prlimit(struct task_struct *tsk, unsigned int resource, struct rlimit *new_rlim, struct rlimit *old_rlim){ struct rlimit *rlim; int retval = 0; if (resource >= RLIM_NLIMITS) return -EINVAL; if (new_rlim) { if (new_rlim->rlim_cur > new_rlim->rlim_max) return -EINVAL; if (resource == RLIMIT_NOFILE &&				new_rlim->rlim_max > sysctl_nr_open) return -EPERM; }  	read_lock(&tasklist_lock); if (!tsk->sighand) {		retval = -ESRCH; goto out; }	rlim = tsk->signal->rlim + resource;	task_lock(tsk->group_leader); if (new_rlim) {   if (new_rlim->rlim_max > rlim->rlim_max && !capable(CAP_SYS_RESOURCE))			retval = -EPERM; if (!retval)			retval = security_task_setrlimit(tsk->group_leader,					resource, new_rlim); if (resource == RLIMIT_CPU && new_rlim->rlim_cur == 0) {  			new_rlim->rlim_cur = 1; } } if (!retval) { if (old_rlim) *old_rlim = *rlim; if (new_rlim) *rlim = *new_rlim; }	task_unlock(tsk->group_leader);   if (!retval && new_rlim && resource == RLIMIT_CPU &&			 new_rlim->rlim_cur != RLIM_INFINITY)		update_rlimit_cpu(tsk, new_rlim->rlim_cur);out:	read_unlock(&tasklist_lock); return retval;}",30711
157,1898,CVE-2014-9644,25,static void crypto_ccm_free(struct crypto_instance *inst){	struct ccm_instance_ctx *ctx = crypto_instance_ctx(inst);	crypto_drop_spawn(&ctx->cipher);	crypto_drop_skcipher(&ctx->ctr);	kfree(inst);},14232
756,488,CVE-2011-4127,25,static void free_pgpath(struct pgpath *pgpath){	kfree(pgpath);},5213
274,2277,CVE-2013-7421,25,"static int sha256_sparc64_import(struct shash_desc *desc, const void *in){	struct sha256_state *sctx = shash_desc_ctx(desc);	memcpy(sctx, in, sizeof(*sctx));	return 0;}",14707
500,1038,CVE-2013-1957,25,static void __mnt_unmake_readonly(struct mount *mnt){	br_write_lock(&vfsmount_lock);	mnt->mnt.mnt_flags &= ~MNT_READONLY;	br_write_unlock(&vfsmount_lock);},9119
463,201,CVE-2012-1179,25,"struct pt_regs *save_v86_state(struct kernel_vm86_regs *regs){	struct tss_struct *tss;	struct pt_regs *ret;	unsigned long tmp;	 	local_irq_enable();	if (!current->thread.vm86_info) {		printk(""no vm86_info: BAD\n"");		do_exit(SIGSEGV);	}	set_flags(regs->pt.flags, VEFLAGS, X86_EFLAGS_VIF | current->thread.v86mask);	tmp = copy_vm86_regs_to_user(&current->thread.vm86_info->regs, regs);	tmp += put_user(current->thread.screen_bitmap, &current->thread.vm86_info->screen_bitmap);	if (tmp) {		printk(""vm86: could not access userspace vm86_info\n"");		do_exit(SIGSEGV);	}	tss = &per_cpu(init_tss, get_cpu());	current->thread.sp0 = current->thread.saved_sp0;	current->thread.sysenter_cs = __KERNEL_CS;	load_sp0(tss, &current->thread);	current->thread.saved_sp0 = 0;	put_cpu();	ret = KVM86->regs32;	ret->fs = current->thread.saved_fs;	set_user_gs(ret, current->thread.saved_gs);	return ret;}",3859
338,1565,CVE-2014-3534,25,"unsigned long regs_get_register(struct pt_regs *regs, unsigned int offset){	if (offset >= NUM_GPRS)		return 0;	return regs->gprs[offset];}",11454
39,2694,CVE-2016-3699,25,static void acpi_os_drop_map_ref(struct acpi_ioremap *map){	if (!--map->refcount)		list_del_rcu(&map->list);},17206
689,1371,CVE-2014-4014,25,"static struct inode *alloc_inode(struct super_block *sb){	struct inode *inode;	if (sb->s_op->alloc_inode)		inode = sb->s_op->alloc_inode(sb);	else		inode = kmem_cache_alloc(inode_cachep, GFP_KERNEL);	if (!inode)		return NULL;	if (unlikely(inode_init_always(sb, inode))) {		if (inode->i_sb->s_op->destroy_inode)			inode->i_sb->s_op->destroy_inode(inode);		else			kmem_cache_free(inode_cachep, inode);		return NULL;	}	return inode;}",10917
665,1907,CVE-2014-9644,25,"static int crypto_rfc4309_setauthsize(struct crypto_aead *parent,				      unsigned int authsize){	struct crypto_rfc4309_ctx *ctx = crypto_aead_ctx(parent);	switch (authsize) {	case 8:	case 12:	case 16:		break;	default:		return -EINVAL;	}	return crypto_aead_setauthsize(ctx->child, authsize);}",14241
674,1016,CVE-2013-2929,25,"void would_dump(struct linux_binprm *bprm, struct file *file){	if (inode_permission(file_inode(file), MAY_READ) < 0)		bprm->interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP;}",8470
377,2216,CVE-2013-7421,25,"static int sha1_neon_import(struct shash_desc *desc, const void *in){	struct sha1_state *sctx = shash_desc_ctx(desc);	memcpy(sctx, in, sizeof(*sctx));	return 0;}",14646
582,2976,CVE-2016-3900,25,"void svcinfo_death(struct binder_state *bs, void *ptr){ struct svcinfo *si = (struct svcinfo* ) ptr;    ALOGI(""service '%s' died\n"", str8(si->name, si->len)); if (si->handle) {        binder_release(bs, si->handle);        si->handle = 0; }}",30387
73,1953,CVE-2014-9644,25,"static int cryptd_hash_export(struct ahash_request *req, void *out){	struct cryptd_hash_request_ctx *rctx = ahash_request_ctx(req);	return crypto_shash_export(&rctx->desc, out);}",14287
448,2818,CVE-2016-10010,25,"server_request_session(void){	Channel *c;	debug(""input_session_request"");	packet_check_eom();	if (no_more_sessions) {		packet_disconnect(""Possible attack: attempt to open a session ""		    ""after additional sessions disabled"");	}	 	c = channel_new(""session"", SSH_CHANNEL_LARVAL,	    -1, -1, -1,  0, CHAN_SES_PACKET_DEFAULT,	    0, ""server-session"", 1);	if (session_open(the_authctxt, c->self) != 1) {		debug(""session open failed, free channel %d"", c->self);		channel_free(c);		return NULL;	}	channel_register_cleanup(c->self, session_close_by_channel, 0);	return c;}",22646
353,541,CVE-2011-4112,25,"static void bond_setup_by_slave(struct net_device *bond_dev,				struct net_device *slave_dev){	struct bonding *bond = netdev_priv(bond_dev);	bond_dev->header_ops	    = slave_dev->header_ops;	bond_dev->type		    = slave_dev->type;	bond_dev->hard_header_len   = slave_dev->hard_header_len;	bond_dev->addr_len	    = slave_dev->addr_len;	memcpy(bond_dev->broadcast, slave_dev->broadcast,		slave_dev->addr_len);	bond->setup_by_slave = 1;}",5266
130,2529,CVE-2016-6787,25,"static int __perf_remove_from_context(void *info){	struct remove_event *re = info;	struct perf_event *event = re->event;	struct perf_event_context *ctx = event->ctx;	struct perf_cpu_context *cpuctx = __get_cpu_context(ctx);	raw_spin_lock(&ctx->lock);	event_sched_out(event, cpuctx, ctx);	if (re->detach_group)		perf_group_detach(event);	list_del_event(event, ctx);	if (!ctx->nr_events && cpuctx->task_ctx == ctx) {		ctx->is_active = 0;		cpuctx->task_ctx = NULL;	}	raw_spin_unlock(&ctx->lock);	return 0;}",15934
136,1760,CVE-2015-2150,25,int xen_pcibk_config_init(void){	return xen_pcibk_config_capability_init();},13761
247,2250,CVE-2013-7421,25,"static int ctr_des3_encrypt(struct blkcipher_desc *desc,			    struct scatterlist *dst, struct scatterlist *src,			    unsigned int nbytes){	struct s390_des_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);	struct blkcipher_walk walk;	blkcipher_walk_init(&walk, dst, src, nbytes);	return ctr_desall_crypt(desc, KMCTR_TDEA_192_ENCRYPT, ctx, &walk);}",14680
548,1916,CVE-2014-9644,25,static void chainiv_free(struct crypto_instance *inst){	skcipher_geniv_free(inst);	crypto_put_default_rng();},14250
27,684,CVE-2011-4112,25,"static int ar6000_connectservice(struct ar6_softc               *ar,                                      struct htc_service_connect_req  *pConnect,                                      char *pDesc){    int                 status;    struct htc_service_connect_resp response;    do {        A_MEMZERO(&response,sizeof(response));        status = HTCConnectService(ar->arHtcTarget,                                   pConnect,                                   &response);        if (status) {            AR_DEBUG_PRINTF(ATH_DEBUG_ERR,("" Failed to connect to %s service status:%d \n"",                              pDesc, status));            break;        }        switch (pConnect->ServiceID) {            case WMI_CONTROL_SVC :                if (ar->arWmiEnabled) {                                             wmi_set_control_ep(ar->arWmi, response.Endpoint);                }                                     ar->arControlEp = response.Endpoint;                break;            case WMI_DATA_BE_SVC :                arSetAc2EndpointIDMap(ar, WMM_AC_BE, response.Endpoint);                break;            case WMI_DATA_BK_SVC :                arSetAc2EndpointIDMap(ar, WMM_AC_BK, response.Endpoint);                break;            case WMI_DATA_VI_SVC :                arSetAc2EndpointIDMap(ar, WMM_AC_VI, response.Endpoint);                 break;           case WMI_DATA_VO_SVC :                arSetAc2EndpointIDMap(ar, WMM_AC_VO, response.Endpoint);                break;           default:                AR_DEBUG_PRINTF(ATH_DEBUG_ERR,(""ServiceID not mapped %d\n"", pConnect->ServiceID));                status = A_EINVAL;            break;        }    } while (false);    return status;}",5409
544,2405,CVE-2013-7421,25,sha384_init(struct shash_desc *desc){	struct sha512_state *sctx = shash_desc_ctx(desc);	sctx->state[0] = SHA384_H0;	sctx->state[1] = SHA384_H1;	sctx->state[2] = SHA384_H2;	sctx->state[3] = SHA384_H3;	sctx->state[4] = SHA384_H4;	sctx->state[5] = SHA384_H5;	sctx->state[6] = SHA384_H6;	sctx->state[7] = SHA384_H7;	sctx->count[0] = sctx->count[1] = 0;	return 0;},14835
656,1377,CVE-2014-4014,25,"int file_remove_suid(struct file *file){	struct dentry *dentry = file->f_path.dentry;	struct inode *inode = dentry->d_inode;	int killsuid;	int killpriv;	int error = 0;	 	if (IS_NOSEC(inode))		return 0;	killsuid = should_remove_suid(dentry);	killpriv = security_inode_need_killpriv(dentry);	if (killpriv < 0)		return killpriv;	if (killpriv)		error = security_inode_killpriv(dentry);	if (!error && killsuid)		error = __remove_suid(dentry, killsuid);	if (!error && (inode->i_sb->s_flags & MS_NOSEC))		inode->i_flags |= S_NOSEC;	return error;}",10923
260,326,CVE-2012-1179,25,"static void check_sync_rss_stat(struct task_struct *task){	if (unlikely(task != current))		return;	if (unlikely(task->rss_stat.events++ > TASK_RSS_EVENTS_THRESH))		__sync_task_rss_stat(task, task->mm);}",3984
373,741,CVE-2011-4112,25,int ieee80211_iface_init(void){	return register_netdevice_notifier(&mac80211_netdev_notifier);},5466
458,891,CVE-2011-2486,25,static void npidentifier_cache_reserve(int n_entries){  if (G_UNLIKELY(g_npidentifier_cache == NULL))	npidentifier_cache_create();  if (g_hash_table_size(g_npidentifier_cache) + n_entries > NPIDENTIFIER_CACHE_SIZE)	npidentifier_cache_invalidate();},6701
427,1204,CVE-2011-1585,25,"match_address(struct TCP_Server_Info *server, struct sockaddr *addr){	struct sockaddr_in *addr4 = (struct sockaddr_in *)addr;	struct sockaddr_in6 *addr6 = (struct sockaddr_in6 *)addr;	switch (addr->sa_family) {	case AF_INET:		if (addr4->sin_addr.s_addr !=		    server->addr.sockAddr.sin_addr.s_addr)			return false;		if (addr4->sin_port &&		    addr4->sin_port != server->addr.sockAddr.sin_port)			return false;		break;	case AF_INET6:		if (!ipv6_addr_equal(&addr6->sin6_addr,				     &server->addr.sockAddr6.sin6_addr))			return false;		if (addr6->sin6_scope_id !=		    server->addr.sockAddr6.sin6_scope_id)			return false;		if (addr6->sin6_port &&		    addr6->sin6_port != server->addr.sockAddr6.sin6_port)			return false;		break;	}	return true;}",10277
392,1099,CVE-2013-1957,25,void mntput(struct vfsmount *mnt){	if (mnt) {		struct mount *m = real_mount(mnt);		 		if (unlikely(m->mnt_expiry_mark))			m->mnt_expiry_mark = 0;		mntput_no_expire(m);	}},9180
596,2474,CVE-2013-7421,25,"static int hmac_sha256_digest(struct ahash_request *req){	int ret2, ret1;	ret1 = hmac_sha256_init(req);	if (ret1)		goto out;	ret1 = ahash_update(req);	ret2 = ahash_final(req);out:	return ret1 ? ret1 : ret2;}",14904
10,1071,CVE-2013-1957,25,"struct vfsmount *lookup_mnt(struct path *path){	struct mount *child_mnt;	br_read_lock(&vfsmount_lock);	child_mnt = __lookup_mnt(path->mnt, path->dentry, 1);	if (child_mnt) {		mnt_add_count(child_mnt, 1);		br_read_unlock(&vfsmount_lock);		return &child_mnt->mnt;	} else {		br_read_unlock(&vfsmount_lock);		return NULL;	}}",9152
625,47,CVE-2015-5352,25,"channel_lookup(int id){	Channel *c;	if ((c = channel_by_id(id)) == NULL)		return (NULL);	switch (c->type) {	case SSH_CHANNEL_X11_OPEN:	case SSH_CHANNEL_LARVAL:	case SSH_CHANNEL_CONNECTING:	case SSH_CHANNEL_DYNAMIC:	case SSH_CHANNEL_OPENING:	case SSH_CHANNEL_OPEN:	case SSH_CHANNEL_INPUT_DRAINING:	case SSH_CHANNEL_OUTPUT_DRAINING:	case SSH_CHANNEL_ABANDONED:		return (c);	}	logit(""Non-public channel %d, type %d."", id, c->type);	return (NULL);}",447
700,1817,CVE-2015-1344,25,"static int lxcfs_fsync(const char *path, int datasync, struct fuse_file_info *fi){	return 0;}",13877
328,1839,CVE-2014-9644,25,static void crypto_fpu_free(struct crypto_instance *inst){	crypto_drop_spawn(crypto_instance_ctx(inst));	kfree(inst);},14173
668,2058,CVE-2014-9644,25,"static int mcryptd_hash_export(struct ahash_request *req, void *out){	struct mcryptd_hash_request_ctx *rctx = ahash_request_ctx(req);	return crypto_shash_export(&rctx->desc, out);}",14392
514,3084,CVE-2014-0185,25,"int fpm_unix_resolve_socket_premissions(struct fpm_worker_pool_s *wp)  {	struct fpm_worker_pool_config_s *c = wp->config; 	  	wp->socket_uid = -1; 	wp->socket_gid = -1;	wp->socket_mode = 0666;  	if (!c) { 		return 0;	}	if (c->listen_owner && *c->listen_owner) {		struct passwd *pwd;		pwd = getpwnam(c->listen_owner);		if (!pwd) {			zlog(ZLOG_SYSERROR, ""[pool %s] cannot get uid for user '%s'"", wp->config->name, c->listen_owner);			return -1;		}		wp->socket_uid = pwd->pw_uid;		wp->socket_gid = pwd->pw_gid;	}	if (c->listen_group && *c->listen_group) {		struct group *grp;		grp = getgrnam(c->listen_group);		if (!grp) {			zlog(ZLOG_SYSERROR, ""[pool %s] cannot get gid for group '%s'"", wp->config->name, c->listen_group);			return -1;		}		wp->socket_gid = grp->gr_gid;	}	if (c->listen_mode && *c->listen_mode) {		wp->socket_mode = strtoul(c->listen_mode, 0, 8);	}	return 0;} ",31171
221,1737,CVE-2015-8660,25,"static int ovl_is_private_xattr(const char *name){	return strncmp(name, OVL_XATTR_PRE_NAME, OVL_XATTR_PRE_LEN) == 0;}",12841
549,3031,CVE-2015-6640,25,"static void rlim_to_rlim64(const struct rlimit *rlim, struct rlimit64 *rlim64){ if (rlim->rlim_cur == RLIM_INFINITY)		rlim64->rlim_cur = RLIM64_INFINITY; else		rlim64->rlim_cur = rlim->rlim_cur; if (rlim->rlim_max == RLIM_INFINITY)		rlim64->rlim_max = RLIM64_INFINITY; else		rlim64->rlim_max = rlim->rlim_max;}",30719
295,2806,CVE-2016-10044,25,"static int aio_ring_mremap(struct vm_area_struct *vma){	struct file *file = vma->vm_file;	struct mm_struct *mm = vma->vm_mm;	struct kioctx_table *table;	int i, res = -EINVAL;	spin_lock(&mm->ioctx_lock);	rcu_read_lock();	table = rcu_dereference(mm->ioctx_table);	for (i = 0; i < table->nr; i++) {		struct kioctx *ctx;		ctx = table->table[i];		if (ctx && ctx->aio_ring_file == file) {			if (!atomic_read(&ctx->dead)) {				ctx->user_id = ctx->mmap_base = vma->vm_start;				res = 0;			}			break;		}	}	rcu_read_unlock();	spin_unlock(&mm->ioctx_lock);	return res;}",22565
289,1468,CVE-2014-3610,25,"static void nested_svm_set_tdp_cr3(struct kvm_vcpu *vcpu,				   unsigned long root){	struct vcpu_svm *svm = to_svm(vcpu);	svm->vmcb->control.nested_cr3 = root;	mark_dirty(svm->vmcb, VMCB_NPT);	svm_flush_tlb(vcpu);}",11330
404,426,CVE-2012-0028,25,"void put_fs_struct(struct fs_struct *fs){	 	if (atomic_dec_and_test(&fs->count)) {		path_put(&fs->root);		path_put(&fs->pwd);		kmem_cache_free(fs_cachep, fs);	}}",4339
335,269,CVE-2012-1179,25,"static int mem_cgroup_oom_control_read(struct cgroup *cgrp,	struct cftype *cft,  struct cgroup_map_cb *cb){	struct mem_cgroup *memcg = mem_cgroup_from_cont(cgrp);	cb->fill(cb, ""oom_kill_disable"", memcg->oom_kill_disable);	if (atomic_read(&memcg->under_oom))		cb->fill(cb, ""under_oom"", 1);	else		cb->fill(cb, ""under_oom"", 0);	return 0;}",3927
474,1236,CVE-2011-1019,25,"int netif_set_real_num_rx_queues(struct net_device *dev, unsigned int rxq){	int rc;	if (rxq < 1 || rxq > dev->num_rx_queues)		return -EINVAL;	if (dev->reg_state == NETREG_REGISTERED) {		ASSERT_RTNL();		rc = net_rx_queue_update_kobjects(dev, dev->real_num_rx_queues,						  rxq);		if (rc)			return rc;	}	dev->real_num_rx_queues = rxq;	return 0;}",10325
428,2188,CVE-2014-7822,25,void splice_shrink_spd(struct splice_pipe_desc *spd){	if (spd->nr_pages_max <= PIPE_DEF_BUFFERS)		return;	kfree(spd->pages);	kfree(spd->partial);},14603
314,1606,CVE-2014-3122,25,"static void anon_vma_chain_link(struct vm_area_struct *vma,				struct anon_vma_chain *avc,				struct anon_vma *anon_vma){	avc->vma = vma;	avc->anon_vma = anon_vma;	list_add(&avc->same_vma, &vma->anon_vma_chain);	anon_vma_interval_tree_insert(avc, &anon_vma->rb_root);}",11577
145,1189,CVE-2011-4347,25,"static void deassign_host_irq(struct kvm *kvm,			      struct kvm_assigned_dev_kernel *assigned_dev){	 	if (assigned_dev->irq_requested_type & KVM_DEV_IRQ_HOST_MSIX) {		int i;		for (i = 0; i < assigned_dev->entries_nr; i++)			disable_irq(assigned_dev->host_msix_entries[i].vector);		for (i = 0; i < assigned_dev->entries_nr; i++)			free_irq(assigned_dev->host_msix_entries[i].vector,				 (void *)assigned_dev);		assigned_dev->entries_nr = 0;		kfree(assigned_dev->host_msix_entries);		kfree(assigned_dev->guest_msix_entries);		pci_disable_msix(assigned_dev->dev);	} else {		 		disable_irq(assigned_dev->host_irq);		free_irq(assigned_dev->host_irq, (void *)assigned_dev);		if (assigned_dev->irq_requested_type & KVM_DEV_IRQ_HOST_MSI)			pci_disable_msi(assigned_dev->dev);	}	assigned_dev->irq_requested_type &= ~(KVM_DEV_IRQ_HOST_MASK);}",10048
525,1102,CVE-2013-1957,25,"int path_is_under(struct path *path1, struct path *path2){	int res;	br_read_lock(&vfsmount_lock);	res = is_path_reachable(real_mount(path1->mnt), path1->dentry, path2);	br_read_unlock(&vfsmount_lock);	return res;}",9183
334,239,CVE-2012-1179,25,"static void mem_cgroup_cancel_attach(struct cgroup_subsys *ss,				struct cgroup *cgroup,				struct cgroup_taskset *tset){}",3897
452,1300,CVE-2014-5207,25,"struct vfsmount *collect_mounts(struct path *path){	struct mount *tree;	namespace_lock();	tree = copy_tree(real_mount(path->mnt), path->dentry,			 CL_COPY_ALL | CL_PRIVATE);	namespace_unlock();	if (IS_ERR(tree))		return ERR_CAST(tree);	return &tree->mnt;}",10649
528,612,CVE-2011-4112,25,static void tun_setup(struct net_device *dev){	struct tun_struct *tun = netdev_priv(dev);	tun->owner = -1;	tun->group = -1;	dev->ethtool_ops = &tun_ethtool_ops;	dev->destructor = tun_free_netdev;},5337
538,2146,CVE-2014-7822,25,"int set_blocksize(struct block_device *bdev, int size){	 	if (size > PAGE_SIZE || size < 512 || !is_power_of_2(size))		return -EINVAL;	 	if (size < bdev_logical_block_size(bdev))		return -EINVAL;	 	if (bdev->bd_block_size != size) {		sync_blockdev(bdev);		bdev->bd_block_size = size;		bdev->bd_inode->i_blkbits = blksize_bits(size);		kill_bdev(bdev);	}	return 0;}",14561
347,1961,CVE-2014-9644,25,"static int cryptd_hash_init_tfm(struct crypto_tfm *tfm){	struct crypto_instance *inst = crypto_tfm_alg_instance(tfm);	struct hashd_instance_ctx *ictx = crypto_instance_ctx(inst);	struct crypto_shash_spawn *spawn = &ictx->spawn;	struct cryptd_hash_ctx *ctx = crypto_tfm_ctx(tfm);	struct crypto_shash *hash;	hash = crypto_spawn_shash(spawn);	if (IS_ERR(hash))		return PTR_ERR(hash);	ctx->child = hash;	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),				 sizeof(struct cryptd_hash_request_ctx) +				 crypto_shash_descsize(hash));	return 0;}",14295
191,1331,CVE-2014-5207,25,"int path_is_under(struct path *path1, struct path *path2){	int res;	read_seqlock_excl(&mount_lock);	res = is_path_reachable(real_mount(path1->mnt), path1->dentry, path2);	read_sequnlock_excl(&mount_lock);	return res;}",10680
52,2555,CVE-2016-6787,25,static int perf_event_idx_default(struct perf_event *event){	return 0;},15960
753,2189,CVE-2014-7822,25,"static int user_page_pipe_buf_steal(struct pipe_inode_info *pipe,				    struct pipe_buffer *buf){	if (!(buf->flags & PIPE_BUF_FLAG_GIFT))		return 1;	buf->flags |= PIPE_BUF_FLAG_LRU;	return generic_pipe_buf_steal(pipe, buf);}",14604
245,2509,CVE-2013-7421,25,"static void ap_reset(struct ap_device *ap_dev){	int rc;	ap_dev->reset = AP_RESET_IGNORE;	atomic_sub(ap_dev->queue_count, &ap_poll_requests);	ap_dev->queue_count = 0;	list_splice_init(&ap_dev->pendingq, &ap_dev->requestq);	ap_dev->requestq_count += ap_dev->pendingq_count;	ap_dev->pendingq_count = 0;	rc = ap_init_queue(ap_dev->qid);	if (rc == -ENODEV)		ap_dev->unregistered = 1;	else		__ap_schedule_poll_timer();}",14939
396,2835,CVE-2014-9922,25,struct dentry *ovl_dentry_upper(struct dentry *dentry){	struct ovl_entry *oe = dentry->d_fsdata;	return ovl_upperdentry_dereference(oe);},23069
217,600,CVE-2011-4112,25,"static void tun_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info){	struct tun_struct *tun = netdev_priv(dev);	strcpy(info->driver, DRV_NAME);	strcpy(info->version, DRV_VERSION);	strcpy(info->fw_version, ""N/A"");	switch (tun->flags & TUN_TYPE_MASK) {	case TUN_TUN_DEV:		strcpy(info->bus_info, ""tun"");		break;	case TUN_TAP_DEV:		strcpy(info->bus_info, ""tap"");		break;	}}",5325
133,1903,CVE-2014-9644,25,static int crypto_rfc4309_encrypt(struct aead_request *req){	req = crypto_rfc4309_crypt(req);	return crypto_aead_encrypt(req);},14237
83,2142,CVE-2014-7822,25,"struct block_device *lookup_bdev(const char *pathname){	struct block_device *bdev;	struct inode *inode;	struct path path;	int error;	if (!pathname || !*pathname)		return ERR_PTR(-EINVAL);	error = kern_path(pathname, LOOKUP_FOLLOW, &path);	if (error)		return ERR_PTR(error);	inode = path.dentry->d_inode;	error = -ENOTBLK;	if (!S_ISBLK(inode->i_mode))		goto fail;	error = -EACCES;	if (path.mnt->mnt_flags & MNT_NODEV)		goto fail;	error = -ENOMEM;	bdev = bd_acquire(inode);	if (!bdev)		goto fail;out:	path_put(&path);	return bdev;fail:	bdev = ERR_PTR(error);	goto out;}",14557
99,371,CVE-2012-1179,25,"void mpol_shared_policy_init(struct shared_policy *sp, struct mempolicy *mpol){	int ret;	sp->root = RB_ROOT;		 	spin_lock_init(&sp->lock);	if (mpol) {		struct vm_area_struct pvma;		struct mempolicy *new;		NODEMASK_SCRATCH(scratch);		if (!scratch)			goto put_mpol;		 		new = mpol_new(mpol->mode, mpol->flags, &mpol->w.user_nodemask);		if (IS_ERR(new))			goto free_scratch;  		task_lock(current);		ret = mpol_set_nodemask(new, &mpol->w.user_nodemask, scratch);		task_unlock(current);		if (ret)			goto put_new;		 		memset(&pvma, 0, sizeof(struct vm_area_struct));		pvma.vm_end = TASK_SIZE;	 		mpol_set_shared_policy(sp, &pvma, new);  put_new:		mpol_put(new);			 free_scratch:		NODEMASK_SCRATCH_FREE(scratch);put_mpol:		mpol_put(mpol);	 	}}",4029
255,2385,CVE-2013-7421,25,static void lz4_exit(struct crypto_tfm *tfm){	struct lz4_ctx *ctx = crypto_tfm_ctx(tfm);	vfree(ctx->lz4_comp_mem);},14815
743,122,CVE-2012-2123,25,"int cap_inode_need_killpriv(struct dentry *dentry){	struct inode *inode = dentry->d_inode;	int error;	if (!inode->i_op->getxattr)	       return 0;	error = inode->i_op->getxattr(dentry, XATTR_NAME_CAPS, NULL, 0);	if (error <= 0)		return 0;	return 1;}",3520
680,1834,CVE-2015-0278,25,"int uv_kill(int pid, int signum) {  if (kill(pid, signum))    return -errno;  else    return 0;}",14068
659,2822,CVE-2015-9004,25,static void perf_remove_from_owner(struct perf_event *event){	struct task_struct *owner;	rcu_read_lock();	owner = ACCESS_ONCE(event->owner);	 	smp_read_barrier_depends();	if (owner) {		 		get_task_struct(owner);	}	rcu_read_unlock();	if (owner) {		mutex_lock(&owner->perf_event_mutex);		 		if (event->owner)			list_del_init(&event->owner_entry);		mutex_unlock(&owner->perf_event_mutex);		put_task_struct(owner);	}},22884
383,2664,CVE-2016-4565,25,"static int setup_ctxt(struct qib_pportdata *ppd, int ctxt,		      struct file *fp, const struct qib_user_info *uinfo){	struct qib_filedata *fd = fp->private_data;	struct qib_devdata *dd = ppd->dd;	struct qib_ctxtdata *rcd;	void *ptmp = NULL;	int ret;	int numa_id;	assign_ctxt_affinity(fp, dd);	numa_id = qib_numa_aware ? ((fd->rec_cpu_num != -1) ?		cpu_to_node(fd->rec_cpu_num) :		numa_node_id()) : dd->assigned_node_id;	rcd = qib_create_ctxtdata(ppd, ctxt, numa_id);	 	if (rcd)		ptmp = kmalloc(dd->rcvtidcnt * sizeof(u16) +			       dd->rcvtidcnt * sizeof(struct page **),			       GFP_KERNEL);	if (!rcd || !ptmp) {		qib_dev_err(dd,			""Unable to allocate ctxtdata memory, failing open\n"");		ret = -ENOMEM;		goto bailerr;	}	rcd->userversion = uinfo->spu_userversion;	ret = init_subctxts(dd, rcd, uinfo);	if (ret)		goto bailerr;	rcd->tid_pg_list = ptmp;	rcd->pid = current->pid;	init_waitqueue_head(&dd->rcd[ctxt]->wait);	strlcpy(rcd->comm, current->comm, sizeof(rcd->comm));	ctxt_fp(fp) = rcd;	qib_stats.sps_ctxts++;	dd->freectxts--;	ret = 0;	goto bail;bailerr:	if (fd->rec_cpu_num != -1)		__clear_bit(fd->rec_cpu_num, qib_cpulist);	dd->rcd[ctxt] = NULL;	kfree(rcd);	kfree(ptmp);bail:	return ret;}",16818
619,2494,CVE-2013-7421,25,"static int ap_device_remove(struct device *dev){	struct ap_device *ap_dev = to_ap_dev(dev);	struct ap_driver *ap_drv = ap_dev->drv;	ap_flush_queue(ap_dev);	del_timer_sync(&ap_dev->timeout);	spin_lock_bh(&ap_device_list_lock);	list_del_init(&ap_dev->list);	spin_unlock_bh(&ap_device_list_lock);	if (ap_drv->remove)		ap_drv->remove(ap_dev);	spin_lock_bh(&ap_dev->lock);	atomic_sub(ap_dev->queue_count, &ap_poll_requests);	spin_unlock_bh(&ap_dev->lock);	return 0;}",14924
151,746,CVE-2011-4112,25,"static int ieee80211_stop(struct net_device *dev){	struct ieee80211_sub_if_data *sdata = IEEE80211_DEV_TO_SUB_IF(dev);	ieee80211_do_stop(sdata, true);	return 0;}",5471
63,72,CVE-2014-7815,25,"static void vnc_listen_regular_read(void *opaque){    vnc_listen_read(opaque, false);}",1315
88,2218,CVE-2013-7421,25,static int sha384_neon_init(struct shash_desc *desc){	struct sha512_state *sctx = shash_desc_ctx(desc);	sctx->state[0] = SHA384_H0;	sctx->state[1] = SHA384_H1;	sctx->state[2] = SHA384_H2;	sctx->state[3] = SHA384_H3;	sctx->state[4] = SHA384_H4;	sctx->state[5] = SHA384_H5;	sctx->state[6] = SHA384_H6;	sctx->state[7] = SHA384_H7;	sctx->count[0] = sctx->count[1] = 0;	return 0;},14648
511,345,CVE-2012-1179,25,"void print_vma_addr(char *prefix, unsigned long ip){	struct mm_struct *mm = current->mm;	struct vm_area_struct *vma;	 	if (preempt_count())		return;	down_read(&mm->mmap_sem);	vma = find_vma(mm, ip);	if (vma && vma->vm_file) {		struct file *f = vma->vm_file;		char *buf = (char *)__get_free_page(GFP_KERNEL);		if (buf) {			char *p, *s;			p = d_path(&f->f_path, buf, PAGE_SIZE);			if (IS_ERR(p))				p = ""?"";			s = strrchr(p, '/');			if (s)				p = s+1;			printk(""%s%s[%lx+%lx]"", prefix, p,					vma->vm_start,					vma->vm_end - vma->vm_start);			free_page((unsigned long)buf);		}	}	up_read(&current->mm->mmap_sem);}",4003
100,1550,CVE-2014-3610,25,"static int ud_interception(struct vcpu_svm *svm){	int er;	er = emulate_instruction(&svm->vcpu, EMULTYPE_TRAP_UD);	if (er != EMULATE_DONE)		kvm_queue_exception(&svm->vcpu, UD_VECTOR);	return 1;}",11412
729,505,CVE-2011-4127,25,"static int reinstate_path(struct pgpath *pgpath){	int r = 0;	unsigned long flags;	struct multipath *m = pgpath->pg->m;	spin_lock_irqsave(&m->lock, flags);	if (pgpath->is_active)		goto out;	if (!pgpath->pg->ps.type->reinstate_path) {		DMWARN(""Reinstate path not supported by path selector %s"",		       pgpath->pg->ps.type->name);		r = -EINVAL;		goto out;	}	r = pgpath->pg->ps.type->reinstate_path(&pgpath->pg->ps, &pgpath->path);	if (r)		goto out;	pgpath->is_active = 1;	if (!m->nr_valid_paths++ && m->queue_size) {		m->current_pgpath = NULL;		queue_work(kmultipathd, &m->process_queued_ios);	} else if (m->hw_handler_name && (m->current_pg == pgpath->pg)) {		if (queue_work(kmpath_handlerd, &pgpath->activate_path.work))			m->pg_init_in_progress++;	}	dm_path_uevent(DM_UEVENT_PATH_REINSTATED, m->ti,		      pgpath->path.dev->name, m->nr_valid_paths);	schedule_work(&m->trigger_event);out:	spin_unlock_irqrestore(&m->lock, flags);	return r;}",5230
45,860,CVE-2011-2495,25,"static int proc_single_open(struct inode *inode, struct file *filp){	return single_open(filp, proc_single_show, inode);}",6657
77,211,CVE-2012-1179,25,"static int pagemap_pte_hole(unsigned long start, unsigned long end,				struct mm_walk *walk){	struct pagemapread *pm = walk->private;	unsigned long addr;	int err = 0;	for (addr = start; addr < end; addr += PAGE_SIZE) {		err = add_to_pagemap(addr, PM_NOT_PRESENT, pm);		if (err)			break;	}	return err;}",3869
766,1469,CVE-2014-3610,25,static void nested_svm_uninit_mmu_context(struct kvm_vcpu *vcpu){	vcpu->arch.walk_mmu = &vcpu->arch.mmu;},11331
9,756,CVE-2011-4080,25,"struct ctl_table_header *register_sysctl_paths(const struct ctl_path *path,						struct ctl_table *table){	return __register_sysctl_paths(&sysctl_table_root, current->nsproxy,					path, table);}",5495
678,295,CVE-2012-1179,25,"struct lruvec *mem_cgroup_zone_lruvec(struct zone *zone,				      struct mem_cgroup *memcg){	struct mem_cgroup_per_zone *mz;	if (mem_cgroup_disabled())		return &zone->lruvec;	mz = mem_cgroup_zoneinfo(memcg, zone_to_nid(zone), zone_idx(zone));	return &mz->lruvec;}",3953
339,779,CVE-2011-2898,25,"static int __packet_get_status(struct packet_sock *po, void *frame){	union {		struct tpacket_hdr *h1;		struct tpacket2_hdr *h2;		void *raw;	} h;	smp_rmb();	h.raw = frame;	switch (po->tp_version) {	case TPACKET_V1:		flush_dcache_page(pgv_to_page(&h.h1->tp_status));		return h.h1->tp_status;	case TPACKET_V2:		flush_dcache_page(pgv_to_page(&h.h2->tp_status));		return h.h2->tp_status;	default:		pr_err(""TPACKET version not supported\n"");		BUG();		return 0;	}}",6489
57,2437,CVE-2013-7421,25,static void add_session_id(struct cryp_ctx *ctx){	 	if (unlikely(atomic_inc_and_test(&session_id)))		atomic_inc(&session_id);	ctx->session_id = atomic_read(&session_id);},14867
592,1043,CVE-2013-1957,25,"static int change_mount_flags(struct vfsmount *mnt, int ms_flags){	int error = 0;	int readonly_request = 0;	if (ms_flags & MS_RDONLY)		readonly_request = 1;	if (readonly_request == __mnt_is_readonly(mnt))		return 0;	if (mnt->mnt_flags & MNT_LOCK_READONLY)		return -EPERM;	if (readonly_request)		error = mnt_make_readonly(real_mount(mnt));	else		__mnt_unmake_readonly(real_mount(mnt));	return error;}",9124
155,1731,CVE-2012-6657,25,"int sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb){	int err;	int skb_len;	unsigned long flags;	struct sk_buff_head *list = &sk->sk_receive_queue;	if (atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf) {		atomic_inc(&sk->sk_drops);		trace_sock_rcvqueue_full(sk, skb);		return -ENOMEM;	}	err = sk_filter(sk, skb);	if (err)		return err;	if (!sk_rmem_schedule(sk, skb, skb->truesize)) {		atomic_inc(&sk->sk_drops);		return -ENOBUFS;	}	skb->dev = NULL;	skb_set_owner_r(skb, sk);	 	skb_len = skb->len;	 	skb_dst_force(skb);	spin_lock_irqsave(&list->lock, flags);	skb->dropcount = atomic_read(&sk->sk_drops);	__skb_queue_tail(list, skb);	spin_unlock_irqrestore(&list->lock, flags);	if (!sock_flag(sk, SOCK_DEAD))		sk->sk_data_ready(sk, skb_len);	return 0;}",12670
748,2196,CVE-2014-7822,25,"static void release_existing_page_budget(struct ubifs_info *c){	struct ubifs_budget_req req = { .dd_growth = c->bi.page_budget};	ubifs_release_budget(c, &req);}",14611
283,2640,CVE-2016-4565,25,struct ib_uverbs_event_file *ib_uverbs_lookup_comp_file(int fd){	struct ib_uverbs_event_file *ev_file = NULL;	struct fd f = fdget(fd);	if (!f.file)		return NULL;	if (f.file->f_op != &uverbs_event_fops)		goto out;	ev_file = f.file->private_data;	if (ev_file->is_async) {		ev_file = NULL;		goto out;	}	kref_get(&ev_file->ref);out:	fdput(f);	return ev_file;},16794
86,2729,CVE-2015-8539,25,"static int aes_get_sizes(void){	struct crypto_blkcipher *tfm;	tfm = crypto_alloc_blkcipher(blkcipher_alg, 0, CRYPTO_ALG_ASYNC);	if (IS_ERR(tfm)) {		pr_err(""encrypted_key: failed to alloc_cipher (%ld)\n"",		       PTR_ERR(tfm));		return PTR_ERR(tfm);	}	ivsize = crypto_blkcipher_ivsize(tfm);	blksize = crypto_blkcipher_blocksize(tfm);	crypto_free_blkcipher(tfm);	return 0;}",18937
219,2422,CVE-2013-7421,25,"static int cbc_aes_decrypt(struct blkcipher_desc *desc,			   struct scatterlist *dst, struct scatterlist *src,			   unsigned int nbytes){	struct aes_ctx *ctx = blk_aes_ctx(desc->tfm);	struct blkcipher_walk walk;	int err;	int ts_state;	padlock_reset_key(&ctx->cword.encrypt);	blkcipher_walk_init(&walk, dst, src, nbytes);	err = blkcipher_walk_virt(desc, &walk);	ts_state = irq_ts_save();	while ((nbytes = walk.nbytes)) {		padlock_xcrypt_cbc(walk.src.virt.addr, walk.dst.virt.addr,				   ctx->D, walk.iv, &ctx->cword.decrypt,				   nbytes / AES_BLOCK_SIZE);		nbytes &= AES_BLOCK_SIZE - 1;		err = blkcipher_walk_done(desc, &walk, nbytes);	}	irq_ts_restore(ts_state);	padlock_store_cword(&ctx->cword.encrypt);	return err;}",14852
505,2408,CVE-2013-7421,25,"static int wp512_init(struct shash_desc *desc) {	struct wp512_ctx *wctx = shash_desc_ctx(desc);	int i;	memset(wctx->bitLength, 0, 32);	wctx->bufferBits = wctx->bufferPos = 0;	wctx->buffer[0] = 0;	for (i = 0; i < 8; i++) {		wctx->hash[i] = 0L;	}	return 0;}",14838
2,2121,CVE-2014-7822,25,"static struct block_device *bd_acquire(struct inode *inode){	struct block_device *bdev;	spin_lock(&bdev_lock);	bdev = inode->i_bdev;	if (bdev) {		ihold(bdev->bd_inode);		spin_unlock(&bdev_lock);		return bdev;	}	spin_unlock(&bdev_lock);	bdev = bdget(inode->i_rdev);	if (bdev) {		spin_lock(&bdev_lock);		if (!inode->i_bdev) {			 			ihold(bdev->bd_inode);			inode->i_bdev = bdev;			inode->i_mapping = bdev->bd_inode->i_mapping;			list_add(&inode->i_devices, &bdev->bd_inodes);		}		spin_unlock(&bdev_lock);	}	return bdev;}",14536
467,1995,CVE-2014-9644,25,"static struct crypto_instance *crypto_gcm_alloc(struct rtattr **tb){	const char *cipher_name;	char ctr_name[CRYPTO_MAX_ALG_NAME];	char full_name[CRYPTO_MAX_ALG_NAME];	cipher_name = crypto_attr_alg_name(tb[1]);	if (IS_ERR(cipher_name))		return ERR_CAST(cipher_name);	if (snprintf(ctr_name, CRYPTO_MAX_ALG_NAME, ""ctr(%s)"", cipher_name) >=	    CRYPTO_MAX_ALG_NAME)		return ERR_PTR(-ENAMETOOLONG);	if (snprintf(full_name, CRYPTO_MAX_ALG_NAME, ""gcm(%s)"", cipher_name) >=	    CRYPTO_MAX_ALG_NAME)		return ERR_PTR(-ENAMETOOLONG);	return crypto_gcm_alloc_common(tb, full_name, ctr_name, ""ghash"");}",14329
764,222,CVE-2012-1179,25,"static void __mem_cgroup_put(struct mem_cgroup *memcg, int count){	if (atomic_sub_and_test(count, &memcg->refcnt)) {		struct mem_cgroup *parent = parent_mem_cgroup(memcg);		__mem_cgroup_free(memcg);		if (parent)			mem_cgroup_put(parent);	}}",3880
638,1265,CVE-2011-1019,25,"ipip6_tunnel_add_prl(struct ip_tunnel *t, struct ip_tunnel_prl *a, int chg){	struct ip_tunnel_prl_entry *p;	int err = 0;	if (a->addr == htonl(INADDR_ANY))		return -EINVAL;	ASSERT_RTNL();	for (p = rtnl_dereference(t->prl); p; p = rtnl_dereference(p->next)) {		if (p->addr == a->addr) {			if (chg) {				p->flags = a->flags;				goto out;			}			err = -EEXIST;			goto out;		}	}	if (chg) {		err = -ENXIO;		goto out;	}	p = kzalloc(sizeof(struct ip_tunnel_prl_entry), GFP_KERNEL);	if (!p) {		err = -ENOBUFS;		goto out;	}	p->next = t->prl;	p->addr = a->addr;	p->flags = a->flags;	t->prl_count++;	rcu_assign_pointer(t->prl, p);out:	return err;}",10354
614,1513,CVE-2014-3610,25,static unsigned long svm_get_rflags(struct kvm_vcpu *vcpu){	return to_svm(vcpu)->vmcb->save.rflags;},11375
142,285,CVE-2012-1179,25,"static void mem_cgroup_threshold(struct mem_cgroup *memcg){	while (memcg) {		__mem_cgroup_threshold(memcg, false);		if (do_swap_account)			__mem_cgroup_threshold(memcg, true);		memcg = parent_mem_cgroup(memcg);	}}",3943
704,789,CVE-2011-2898,25,"static int packet_getname_spkt(struct socket *sock, struct sockaddr *uaddr,			       int *uaddr_len, int peer){	struct net_device *dev;	struct sock *sk	= sock->sk;	if (peer)		return -EOPNOTSUPP;	uaddr->sa_family = AF_PACKET;	rcu_read_lock();	dev = dev_get_by_index_rcu(sock_net(sk), pkt_sk(sk)->ifindex);	if (dev)		strncpy(uaddr->sa_data, dev->name, 14);	else		memset(uaddr->sa_data, 0, 14);	rcu_read_unlock();	*uaddr_len = sizeof(*uaddr);	return 0;}",6499
673,1733,CVE-2015-8660,25,"static int ovl_copy_up_last(struct dentry *dentry, struct iattr *attr,			    int no_data){	int err;	struct dentry *parent;	struct kstat stat;	struct path lowerpath;	parent = dget_parent(dentry);	err = ovl_copy_up(parent);	if (err)		goto out_dput_parent;	ovl_path_lower(dentry, &lowerpath);	err = vfs_getattr(&lowerpath, &stat);	if (err)		goto out_dput_parent;	if (no_data)		stat.size = 0;	err = ovl_copy_up_one(parent, dentry, &lowerpath, &stat, attr);out_dput_parent:	dput(parent);	return err;}",12837
301,2415,CVE-2013-7421,25,"static int zlib_decompress_setup(struct crypto_pcomp *tfm, void *params,				 unsigned int len){	struct zlib_ctx *ctx = crypto_tfm_ctx(crypto_pcomp_tfm(tfm));	struct z_stream_s *stream = &ctx->decomp_stream;	struct nlattr *tb[ZLIB_DECOMP_MAX + 1];	int ret = 0;	ret = nla_parse(tb, ZLIB_DECOMP_MAX, params, len, NULL);	if (ret)		return ret;	zlib_decomp_exit(ctx);	ctx->decomp_windowBits = tb[ZLIB_DECOMP_WINDOWBITS]				 ? nla_get_u32(tb[ZLIB_DECOMP_WINDOWBITS])				 : DEF_WBITS;	stream->workspace = vzalloc(zlib_inflate_workspacesize());	if (!stream->workspace)		return -ENOMEM;	ret = zlib_inflateInit2(stream, ctx->decomp_windowBits);	if (ret != Z_OK) {		vfree(stream->workspace);		stream->workspace = NULL;		return -EINVAL;	}	return 0;}",14845
615,2743,CVE-2015-8539,25,"static int pcrlock(const int pcrnum){	unsigned char hash[SHA1_DIGEST_SIZE];	int ret;	if (!capable(CAP_SYS_ADMIN))		return -EPERM;	ret = tpm_get_random(TPM_ANY_NUM, hash, SHA1_DIGEST_SIZE);	if (ret != SHA1_DIGEST_SIZE)		return ret;	return tpm_pcr_extend(TPM_ANY_NUM, pcrnum, hash) ? -EINVAL : 0;}",18951
554,810,CVE-2011-2495,25,"static int comm_show(struct seq_file *m, void *v){	struct inode *inode = m->private;	struct task_struct *p;	p = get_proc_task(inode);	if (!p)		return -ESRCH;	task_lock(p);	seq_printf(m, ""%s\n"", p->comm);	task_unlock(p);	put_task_struct(p);	return 0;}",6607
261,2685,CVE-2016-4565,25,"static int user_init(struct file *fp){	unsigned int rcvctrl_ops = 0;	struct hfi1_filedata *fd = fp->private_data;	struct hfi1_ctxtdata *uctxt = fd->uctxt;	 	if (!test_bit(HFI1_CTXT_SETUP_DONE, &uctxt->event_flags))		return -EFAULT;	 	uctxt->urgent = 0;	uctxt->urgent_poll = 0;	 	if (uctxt->rcvhdrtail_kvaddr)		clear_rcvhdrtail(uctxt);	 	hfi1_set_ctxt_jkey(uctxt->dd, uctxt->ctxt, uctxt->jkey);	rcvctrl_ops = HFI1_RCVCTRL_CTXT_ENB;	if (HFI1_CAP_KGET_MASK(uctxt->flags, HDRSUPP))		rcvctrl_ops |= HFI1_RCVCTRL_TIDFLOW_ENB;	 	if (!HFI1_CAP_KGET_MASK(uctxt->flags, MULTI_PKT_EGR))		rcvctrl_ops |= HFI1_RCVCTRL_ONE_PKT_EGR_ENB;	if (HFI1_CAP_KGET_MASK(uctxt->flags, NODROP_EGR_FULL))		rcvctrl_ops |= HFI1_RCVCTRL_NO_EGR_DROP_ENB;	if (HFI1_CAP_KGET_MASK(uctxt->flags, NODROP_RHQ_FULL))		rcvctrl_ops |= HFI1_RCVCTRL_NO_RHQ_DROP_ENB;	 	if (HFI1_CAP_KGET_MASK(uctxt->flags, DMA_RTAIL))		rcvctrl_ops |= HFI1_RCVCTRL_TAILUPD_ENB;	else		rcvctrl_ops |= HFI1_RCVCTRL_TAILUPD_DIS;	hfi1_rcvctrl(uctxt->dd, rcvctrl_ops, uctxt->ctxt);	 	if (uctxt->subctxt_cnt) {		clear_bit(HFI1_CTXT_MASTER_UNINIT, &uctxt->event_flags);		wake_up(&uctxt->wait);	}	return 0;}",16839
333,103,CVE-2012-2319,25,"static int hfsplus_dir_release(struct inode *inode, struct file *file){	struct hfsplus_readdir_data *rd = file->private_data;	if (rd) {		mutex_lock(&inode->i_mutex);		list_del(&rd->list);		mutex_unlock(&inode->i_mutex);		kfree(rd);	}	return 0;}",3414
16,242,CVE-2012-1179,25,static void mem_cgroup_clear_mc(void){	struct mem_cgroup *from = mc.from;	 	mc.moving_task = NULL;	__mem_cgroup_clear_mc();	spin_lock(&mc.lock);	mc.from = NULL;	mc.to = NULL;	spin_unlock(&mc.lock);	mem_cgroup_end_move(from);},3900
687,1552,CVE-2014-3610,25,"static void update_db_bp_intercept(struct kvm_vcpu *vcpu){	struct vcpu_svm *svm = to_svm(vcpu);	clr_exception_intercept(svm, DB_VECTOR);	clr_exception_intercept(svm, BP_VECTOR);	if (svm->nmi_singlestep)		set_exception_intercept(svm, DB_VECTOR);	if (vcpu->guest_debug & KVM_GUESTDBG_ENABLE) {		if (vcpu->guest_debug &		    (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))			set_exception_intercept(svm, DB_VECTOR);		if (vcpu->guest_debug & KVM_GUESTDBG_USE_SW_BP)			set_exception_intercept(svm, BP_VECTOR);	} else		vcpu->guest_debug = 0;}",11414
122,667,CVE-2011-4112,25,"void stop_airo_card( struct net_device *dev, int freeres ){	struct airo_info *ai = dev->ml_priv;	set_bit(FLAG_RADIO_DOWN, &ai->flags);	disable_MAC(ai, 1);	disable_interrupts(ai);	takedown_proc_entry( dev, ai );	if (test_bit(FLAG_REGISTERED, &ai->flags)) {		unregister_netdev( dev );		if (ai->wifidev) {			unregister_netdev(ai->wifidev);			free_netdev(ai->wifidev);			ai->wifidev = NULL;		}		clear_bit(FLAG_REGISTERED, &ai->flags);	}	 	if (test_bit(FLAG_MPI, &ai->flags) && !skb_queue_empty(&ai->txq)) {		struct sk_buff *skb = NULL;		for (;(skb = skb_dequeue(&ai->txq));)			dev_kfree_skb(skb);	}	airo_networks_free (ai);	kfree(ai->flash);	kfree(ai->rssi);	kfree(ai->APList);	kfree(ai->SSID);	if (freeres) {		 	        release_region( dev->base_addr, 64 );		if (test_bit(FLAG_MPI, &ai->flags)) {			if (ai->pci)				mpi_unmap_card(ai->pci);			if (ai->pcimem)				iounmap(ai->pcimem);			if (ai->pciaux)				iounmap(ai->pciaux);			pci_free_consistent(ai->pci, PCI_SHARED_LEN,				ai->shared, ai->shared_dma);		}        }	crypto_free_cipher(ai->tfm);	del_airo_dev(ai);	free_netdev( dev );}",5392
174,2629,CVE-2016-4565,25,"static unsigned int ucma_poll(struct file *filp, struct poll_table_struct *wait){	struct ucma_file *file = filp->private_data;	unsigned int mask = 0;	poll_wait(filp, &file->poll_wait, wait);	if (!list_empty(&file->event_list))		mask = POLLIN | POLLRDNORM;	return mask;}",16783
676,1990,CVE-2014-9644,25,"static void __gcm_hash_assoc_done(struct aead_request *req, int err){	struct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);	unsigned int remain;	if (!err) {		remain = gcm_remain(req->assoclen);		BUG_ON(!remain);		err = gcm_hash_remain(req, pctx, remain,				      gcm_hash_assoc_remain_done);		if (err == -EINPROGRESS || err == -EBUSY)			return;	}	__gcm_hash_assoc_remain_done(req, err);}",14324
432,2314,CVE-2013-7421,25,"static int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,		       struct scatterlist *src, unsigned int nbytes){	struct cast6_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);	return glue_xts_crypt_128bit(&cast6_enc_xts, desc, dst, src, nbytes,				     XTS_TWEAK_CAST(__cast6_encrypt),				     &ctx->tweak_ctx, &ctx->crypt_ctx);}",14744
624,1928,CVE-2014-9644,25,"static int cryptd_aead_encrypt_enqueue(struct aead_request *req){	return cryptd_aead_enqueue(req, cryptd_aead_encrypt );}",14262
292,658,CVE-2011-4112,25,"static int micsetup(struct airo_info *ai) {	int i;	if (ai->tfm == NULL)	        ai->tfm = crypto_alloc_cipher(""aes"", 0, CRYPTO_ALG_ASYNC);        if (IS_ERR(ai->tfm)) {                airo_print_err(ai->dev->name, ""failed to load transform for AES"");                ai->tfm = NULL;                return ERROR;        }	for (i=0; i < NUM_MODULES; i++) {		memset(&ai->mod[i].mCtx,0,sizeof(miccntx));		memset(&ai->mod[i].uCtx,0,sizeof(miccntx));	}	return SUCCESS;}",5383
148,738,CVE-2011-4112,25,"int ieee80211_if_change_type(struct ieee80211_sub_if_data *sdata,			     enum nl80211_iftype type){	int ret;	ASSERT_RTNL();	if (type == ieee80211_vif_type_p2p(&sdata->vif))		return 0;	 	if (sdata->local->oper_channel->flags & IEEE80211_CHAN_NO_IBSS &&	    type == NL80211_IFTYPE_ADHOC)		return -EOPNOTSUPP;	if (ieee80211_sdata_running(sdata)) {		ret = ieee80211_runtime_change_iftype(sdata, type);		if (ret)			return ret;	} else {		 		ieee80211_teardown_sdata(sdata->dev);		ieee80211_setup_sdata(sdata, type);	}	 	sdata->vif.bss_conf.basic_rates =		ieee80211_mandatory_rates(sdata->local,			sdata->local->hw.conf.channel->band);	sdata->drop_unencrypted = 0;	if (type == NL80211_IFTYPE_STATION)		sdata->u.mgd.use_4addr = false;	return 0;}",5463
24,1966,CVE-2014-9644,25,"static int crypto_ctr_crypt(struct blkcipher_desc *desc,			      struct scatterlist *dst, struct scatterlist *src,			      unsigned int nbytes){	struct blkcipher_walk walk;	struct crypto_blkcipher *tfm = desc->tfm;	struct crypto_ctr_ctx *ctx = crypto_blkcipher_ctx(tfm);	struct crypto_cipher *child = ctx->child;	unsigned int bsize = crypto_cipher_blocksize(child);	int err;	blkcipher_walk_init(&walk, dst, src, nbytes);	err = blkcipher_walk_virt_block(desc, &walk, bsize);	while (walk.nbytes >= bsize) {		if (walk.src.virt.addr == walk.dst.virt.addr)			nbytes = crypto_ctr_crypt_inplace(&walk, child);		else			nbytes = crypto_ctr_crypt_segment(&walk, child);		err = blkcipher_walk_done(desc, &walk, nbytes);	}	if (walk.nbytes) {		crypto_ctr_crypt_final(&walk, child);		err = blkcipher_walk_done(desc, &walk, 0);	}	return err;}",14300
139,782,CVE-2011-2898,25,"static struct pgv *alloc_pg_vec(struct tpacket_req *req, int order){	unsigned int block_nr = req->tp_block_nr;	struct pgv *pg_vec;	int i;	pg_vec = kcalloc(block_nr, sizeof(struct pgv), GFP_KERNEL);	if (unlikely(!pg_vec))		goto out;	for (i = 0; i < block_nr; i++) {		pg_vec[i].buffer = alloc_one_pg_vec_page(order);		if (unlikely(!pg_vec[i].buffer))			goto out_free_pgvec;	}out:	return pg_vec;out_free_pgvec:	free_pg_vec(pg_vec, order, block_nr);	pg_vec = NULL;	goto out;}",6492
276,1347,CVE-2014-4943,25,"static void pppol2tp_seq_stop(struct seq_file *p, void *v){	 }",10794
141,2773,CVE-2014-9870,25,"int in_gate_area_no_mm(unsigned long addr){	return in_gate_area(NULL, addr);}",19322
204,982,CVE-2013-2929,25,"void __register_binfmt(struct linux_binfmt * fmt, int insert){	BUG_ON(!fmt);	if (WARN_ON(!fmt->load_binary))		return;	write_lock(&binfmt_lock);	insert ? list_add(&fmt->lh, &formats) :		 list_add_tail(&fmt->lh, &formats);	write_unlock(&binfmt_lock);}",8436
722,57,CVE-2013-1813,25,"static void make_default_cur_rule(void){	memset(&G.cur_rule, 0, sizeof(G.cur_rule));	G.cur_rule.maj = -1;  	G.cur_rule.mode = 0660;}",758
69,856,CVE-2011-2495,25,"static struct dentry *proc_pident_lookup(struct inode *dir, 					 struct dentry *dentry,					 const struct pid_entry *ents,					 unsigned int nents){	struct dentry *error;	struct task_struct *task = get_proc_task(dir);	const struct pid_entry *p, *last;	error = ERR_PTR(-ENOENT);	if (!task)		goto out_no_task;	 	last = &ents[nents - 1];	for (p = ents; p <= last; p++) {		if (p->len != dentry->d_name.len)			continue;		if (!memcmp(dentry->d_name.name, p->name, p->len))			break;	}	if (p > last)		goto out;	error = proc_pident_instantiate(dir, dentry, task, p);out:	put_task_struct(task);out_no_task:	return error;}",6653
488,1763,CVE-2015-2150,25,"static void bar_release(struct pci_dev *dev, int offset, void *data){	kfree(data);}",13764
46,246,CVE-2012-1179,25,"static void mem_cgroup_destroy(struct cgroup_subsys *ss,				struct cgroup *cont){	struct mem_cgroup *memcg = mem_cgroup_from_cont(cont);	kmem_cgroup_destroy(ss, cont);	mem_cgroup_put(memcg);}",3904
400,1376,CVE-2014-4014,25,"static void evict(struct inode *inode){	const struct super_operations *op = inode->i_sb->s_op;	BUG_ON(!(inode->i_state & I_FREEING));	BUG_ON(!list_empty(&inode->i_lru));	if (!list_empty(&inode->i_wb_list))		inode_wb_list_del(inode);	inode_sb_list_del(inode);	 	inode_wait_for_writeback(inode);	if (op->evict_inode) {		op->evict_inode(inode);	} else {		truncate_inode_pages_final(&inode->i_data);		clear_inode(inode);	}	if (S_ISBLK(inode->i_mode) && inode->i_bdev)		bd_forget(inode);	if (S_ISCHR(inode->i_mode) && inode->i_cdev)		cd_forget(inode);	remove_inode_hash(inode);	spin_lock(&inode->i_lock);	wake_up_bit(&inode->i_state, __I_NEW);	BUG_ON(inode->i_state != (I_FREEING | I_CLEAR));	spin_unlock(&inode->i_lock);	destroy_inode(inode);}",10922
575,1481,CVE-2014-3610,25,"static int rdpmc_interception(struct vcpu_svm *svm){	int err;	if (!static_cpu_has(X86_FEATURE_NRIPS))		return emulate_on_interception(svm);	err = kvm_rdpmc(&svm->vcpu);	kvm_complete_insn_gp(&svm->vcpu, err);	return 1;}",11343
737,1325,CVE-2014-5207,25,"void mnt_set_mountpoint(struct mount *mnt,			struct mountpoint *mp,			struct mount *child_mnt){	mp->m_count++;	mnt_add_count(mnt, 1);	 	child_mnt->mnt_mountpoint = dget(mp->m_dentry);	child_mnt->mnt_parent = mnt;	child_mnt->mnt_mp = mp;}",10674
156,2323,CVE-2013-7421,25,"static int ghash_async_init(struct ahash_request *req){	struct crypto_ahash *tfm = crypto_ahash_reqtfm(req);	struct ghash_async_ctx *ctx = crypto_ahash_ctx(tfm);	struct ahash_request *cryptd_req = ahash_request_ctx(req);	struct cryptd_ahash *cryptd_tfm = ctx->cryptd_tfm;	if (!irq_fpu_usable()) {		memcpy(cryptd_req, req, sizeof(*req));		ahash_request_set_tfm(cryptd_req, &cryptd_tfm->base);		return crypto_ahash_init(cryptd_req);	} else {		struct shash_desc *desc = cryptd_shash_desc(cryptd_req);		struct crypto_shash *child = cryptd_ahash_child(cryptd_tfm);		desc->tfm = child;		desc->flags = req->base.flags;		return crypto_shash_init(desc);	}}",14753
735,3008,CVE-2016-0809,25,"static int internal_no_seq_check(struct nl_msg *msg, void *arg){ return NL_OK;}",30696
60,1549,CVE-2014-3610,25,"static inline void sync_cr8_to_lapic(struct kvm_vcpu *vcpu){	struct vcpu_svm *svm = to_svm(vcpu);	if (is_guest_mode(vcpu) && (vcpu->arch.hflags & HF_VINTR_MASK))		return;	if (!is_cr_intercept(svm, INTERCEPT_CR8_WRITE)) {		int cr8 = svm->vmcb->control.int_ctl & V_TPR_MASK;		kvm_set_cr8(vcpu, cr8);	}}",11411
563,1987,CVE-2014-9644,25,static void eseqiv_free(struct crypto_instance *inst){	skcipher_geniv_free(inst);	crypto_put_default_rng();},14321
222,455,CVE-2012-0028,25,"void mm_init_owner(struct mm_struct *mm, struct task_struct *p){	mm->owner = p;}",4368
91,2400,CVE-2013-7421,25,"static int encrypt(struct blkcipher_desc *desc,		   struct scatterlist *dst, struct scatterlist *src,		   unsigned int nbytes){	struct blkcipher_walk walk;	struct crypto_blkcipher *tfm = desc->tfm;	struct salsa20_ctx *ctx = crypto_blkcipher_ctx(tfm);	int err;	blkcipher_walk_init(&walk, dst, src, nbytes);	err = blkcipher_walk_virt_block(desc, &walk, 64);	salsa20_ivsetup(ctx, walk.iv);	if (likely(walk.nbytes == nbytes))	{		salsa20_encrypt_bytes(ctx, walk.dst.virt.addr,				      walk.src.virt.addr, nbytes);		return blkcipher_walk_done(desc, &walk, 0);	}	while (walk.nbytes >= 64) {		salsa20_encrypt_bytes(ctx, walk.dst.virt.addr,				      walk.src.virt.addr,				      walk.nbytes - (walk.nbytes % 64));		err = blkcipher_walk_done(desc, &walk, walk.nbytes % 64);	}	if (walk.nbytes) {		salsa20_encrypt_bytes(ctx, walk.dst.virt.addr,				      walk.src.virt.addr, walk.nbytes);		err = blkcipher_walk_done(desc, &walk, 0);	}	return err;}",14830
445,1519,CVE-2014-3610,25,"static void svm_hwapic_isr_update(struct kvm *kvm, int isr){	return;}",11381
414,620,CVE-2011-4112,25,static void veth_dev_free(struct net_device *dev){	struct veth_priv *priv;	priv = netdev_priv(dev);	free_percpu(priv->stats);	free_netdev(dev);},5345
70,1077,CVE-2013-1957,25,"static int mnt_alloc_group_id(struct mount *mnt){	int res;	if (!ida_pre_get(&mnt_group_ida, GFP_KERNEL))		return -ENOMEM;	res = ida_get_new_above(&mnt_group_ida,				mnt_group_start,				&mnt->mnt_group_id);	if (!res)		mnt_group_start = mnt->mnt_group_id + 1;	return res;}",9158
429,1958,CVE-2014-9644,25,"static int cryptd_hash_import(struct ahash_request *req, const void *in){	struct cryptd_hash_request_ctx *rctx = ahash_request_ctx(req);	return crypto_shash_import(&rctx->desc, in);}",14292
236,2488,CVE-2013-7421,25,"static int ap_bus_resume(struct device *dev){	struct ap_device *ap_dev = to_ap_dev(dev);	int rc;	if (ap_suspend_flag) {		ap_suspend_flag = 0;		if (ap_interrupts_available()) {			if (!ap_using_interrupts()) {				rc = register_adapter_interrupt(&ap_airq);				ap_airq_flag = (rc == 0);			}		} else {			if (ap_using_interrupts()) {				unregister_adapter_interrupt(&ap_airq);				ap_airq_flag = 0;			}		}		ap_query_configuration();		if (!user_set_domain) {			ap_domain_index = -1;			ap_select_domain();		}		init_timer(&ap_config_timer);		ap_config_timer.function = ap_config_timeout;		ap_config_timer.data = 0;		ap_config_timer.expires = jiffies + ap_config_time * HZ;		add_timer(&ap_config_timer);		ap_work_queue = create_singlethread_workqueue(""kapwork"");		if (!ap_work_queue)			return -ENOMEM;		tasklet_enable(&ap_tasklet);		if (!ap_using_interrupts())			ap_schedule_poll_timer();		else			tasklet_schedule(&ap_tasklet);		if (ap_thread_flag)			rc = ap_poll_thread_start();		else			rc = 0;	} else		rc = 0;	if (AP_QID_QUEUE(ap_dev->qid) != ap_domain_index) {		spin_lock_bh(&ap_dev->lock);		ap_dev->qid = AP_MKQID(AP_QID_DEVICE(ap_dev->qid),				       ap_domain_index);		spin_unlock_bh(&ap_dev->lock);	}	queue_work(ap_work_queue, &ap_config_work);	return rc;}",14918
41,279,CVE-2019-12904,8,"selftest_basic_192 (void){  RIJNDAEL_context *ctx;  unsigned char *ctxmem;  unsigned char scratch[16];  static unsigned char plaintext_192[16] =    {      0x76,0x77,0x74,0x75,0xF1,0xF2,0xF3,0xF4,      0xF8,0xF9,0xE6,0xE7,0x77,0x70,0x71,0x72    };  static unsigned char key_192[24] =    {      0x04,0x05,0x06,0x07,0x09,0x0A,0x0B,0x0C,      0x0E,0x0F,0x10,0x11,0x13,0x14,0x15,0x16,      0x18,0x19,0x1A,0x1B,0x1D,0x1E,0x1F,0x20    };  static const unsigned char ciphertext_192[16] =    {      0x5D,0x1E,0xF2,0x0D,0xCE,0xD6,0xBC,0xBC,      0x12,0x13,0x1A,0xC7,0xC5,0x47,0x88,0xAA    };  ctx = _gcry_cipher_selftest_alloc_ctx (sizeof *ctx, &ctxmem);  if (!ctx)    return ""failed to allocate memory"";  rijndael_setkey (ctx, key_192, sizeof(key_192), NULL);  rijndael_encrypt (ctx, scratch, plaintext_192);  if (memcmp (scratch, ciphertext_192, sizeof (ciphertext_192)))    {      xfree (ctxmem);      return ""AES-192 test encryption failed."";    }  rijndael_decrypt (ctx, scratch, scratch);  xfree (ctxmem);  if (memcmp (scratch, plaintext_192, sizeof (plaintext_192)))    return ""AES-192 test decryption failed."";  return NULL;}",28875
42,126,CVE-2013-2548,8,"static int crypto_pcomp_report(struct sk_buff *skb, struct crypto_alg *alg){	return -ENOSYS;}",8653
1,246,CVE-2013-6371,8,"struct json_tokener* json_tokener_new_ex(int depth){  struct json_tokener *tok;  tok = (struct json_tokener*)calloc(1, sizeof(struct json_tokener));  if (!tok) return NULL;  tok->stack = (struct json_tokener_srec *)calloc(depth, sizeof(struct json_tokener_srec));  if (!tok->stack) {    free(tok);    return NULL;  }  tok->pb = printbuf_new();  tok->max_depth = depth;  json_tokener_reset(tok);  return tok;}",12638
34,57,CVE-2013-2548,8,"const char *crypto_default_geniv(const struct crypto_alg *alg){	if (((alg->cra_flags & CRYPTO_ALG_TYPE_MASK) ==	     CRYPTO_ALG_TYPE_BLKCIPHER ? alg->cra_blkcipher.ivsize :					 alg->cra_ablkcipher.ivsize) !=	    alg->cra_blocksize)		return ""chainiv"";	return alg->cra_flags & CRYPTO_ALG_ASYNC ?	       ""eseqiv"" : skcipher_default_geniv;}",8584
21,286,CVE-2016-1618,8,    void runSingleTask()    {        if (m_tasks.isEmpty())            return;        m_tasks.takeFirst()->run();    },29778
74,222,CVE-2012-5375,8,"struct btrfs_trans_handle *btrfs_start_ioctl_transaction(struct btrfs_root *root){	return start_transaction(root, 0, TRANS_USERSPACE, 0);}",9962
3,20,CVE-2013-4350,8,"static int sctp_inet6_bind_verify(struct sctp_sock *opt, union sctp_addr *addr){	struct sctp_af *af;	 	if (addr->sa.sa_family != AF_INET6)		af = sctp_get_af_specific(addr->sa.sa_family);	else {		int type = ipv6_addr_type(&addr->v6.sin6_addr);		struct net_device *dev;		if (type & IPV6_ADDR_LINKLOCAL) {			struct net *net;			if (!addr->v6.sin6_scope_id)				return 0;			net = sock_net(&opt->inet.sk);			rcu_read_lock();			dev = dev_get_by_index_rcu(net, addr->v6.sin6_scope_id);			if (!dev ||			    !ipv6_chk_addr(net, &addr->v6.sin6_addr, dev, 0)) {				rcu_read_unlock();				return 0;			}			rcu_read_unlock();		} else if (type == IPV6_ADDR_MAPPED) {			if (!opt->v4mapped)				return 0;		}		af = opt->pf->af;	}	return af->available(addr, opt);}",7820
10,298,CVE-2016-1618,8,"    void testFrameFinalizedByTaskObserver1()    {        m_testSurface->initializeCurrentFrame();        expectDisplayListEnabled(true);        m_testSurface->getPicture();        EXPECT_EQ(1, m_fakeImageBufferClient->frameCount());        expectDisplayListEnabled(true);        m_fakeImageBufferClient->fakeDraw();        EXPECT_EQ(1, m_fakeImageBufferClient->frameCount());        expectDisplayListEnabled(true);        m_testSurface->getPicture();        EXPECT_EQ(2, m_fakeImageBufferClient->frameCount());        expectDisplayListEnabled(true);        m_fakeImageBufferClient->fakeDraw();        EXPECT_EQ(2, m_fakeImageBufferClient->frameCount());        expectDisplayListEnabled(true);    }",29790
29,45,CVE-2013-4350,8,"static void sctp_v6_to_sk_daddr(union sctp_addr *addr, struct sock *sk){	if (addr->sa.sa_family == AF_INET && sctp_sk(sk)->v4mapped) {		inet6_sk(sk)->daddr.s6_addr32[0] = 0;		inet6_sk(sk)->daddr.s6_addr32[1] = 0;		inet6_sk(sk)->daddr.s6_addr32[2] = htonl(0x0000ffff);		inet6_sk(sk)->daddr.s6_addr32[3] = addr->v4.sin_addr.s_addr;	} else {		inet6_sk(sk)->daddr = addr->v6.sin6_addr;	}}",7845
50,282,CVE-2019-12904,8,"selftest_cfb_128 (void){  const int nblocks = 8+2;  const int blocksize = BLOCKSIZE;  const int context_size = sizeof(RIJNDAEL_context);  return _gcry_selftest_helper_cfb(""AES"", &rijndael_setkey,           &rijndael_encrypt, &_gcry_aes_cfb_dec, nblocks, blocksize,	   context_size);}",28878
17,21,CVE-2013-4350,8,"static int sctp_inet6_cmp_addr(const union sctp_addr *addr1,			       const union sctp_addr *addr2,			       struct sctp_sock *opt){	struct sctp_af *af1, *af2;	struct sock *sk = sctp_opt2sk(opt);	af1 = sctp_get_af_specific(addr1->sa.sa_family);	af2 = sctp_get_af_specific(addr2->sa.sa_family);	if (!af1 || !af2)		return 0;	 	if (__ipv6_only_sock(sk) && af1 != af2)		return 0;	 	if (sctp_is_any(sk, addr1) || sctp_is_any(sk, addr2))		return 1;	if (addr1->sa.sa_family != addr2->sa.sa_family)		return 0;	return af1->cmp_addr(addr1, addr2);}",7821
58,24,CVE-2013-4350,8,"static int sctp_inet6_send_verify(struct sctp_sock *opt, union sctp_addr *addr){	struct sctp_af *af = NULL;	 	if (addr->sa.sa_family != AF_INET6)		af = sctp_get_af_specific(addr->sa.sa_family);	else {		int type = ipv6_addr_type(&addr->v6.sin6_addr);		struct net_device *dev;		if (type & IPV6_ADDR_LINKLOCAL) {			if (!addr->v6.sin6_scope_id)				return 0;			rcu_read_lock();			dev = dev_get_by_index_rcu(sock_net(&opt->inet.sk),						   addr->v6.sin6_scope_id);			rcu_read_unlock();			if (!dev)				return 0;		}		af = opt->pf->af;	}	return af != NULL;}",7824
52,175,CVE-2012-5375,8,"static int btrfs_init_inode_security(struct btrfs_trans_handle *trans,				     struct inode *inode,  struct inode *dir,				     const struct qstr *qstr){	int err;	err = btrfs_init_acl(trans, inode, dir);	if (!err)		err = btrfs_xattr_security_init(trans, inode, dir, qstr);	return err;}",9915
7,306,CVE-2013-2548,8,"static int crypto_report_comp(struct sk_buff *skb, struct crypto_alg *alg) { 	struct crypto_report_comp rcomp; 	snprintf(rcomp.type, CRYPTO_MAX_ALG_NAME, ""%s"", ""compression""); 	if (nla_put(skb, CRYPTOCFGA_REPORT_COMPRESS, 		    sizeof(struct crypto_report_comp), &rcomp)) 		goto nla_put_failure;	return 0;nla_put_failure:	return -EMSGSIZE;}",31070
8,140,CVE-2013-2548,8,"int crypto_register_shashes(struct shash_alg *algs, int count){	int i, ret;	for (i = 0; i < count; i++) {		ret = crypto_register_shash(&algs[i]);		if (ret)			goto err;	}	return 0;err:	for (--i; i >= 0; --i)		crypto_unregister_shash(&algs[i]);	return ret;}",8667
4,244,CVE-2013-6371,8,void json_tokener_free(struct json_tokener *tok){  json_tokener_reset(tok);  if (tok->pb) printbuf_free(tok->pb);  if (tok->stack) free(tok->stack);  free(tok);},12636
32,9,CVE-2012-2143,8,ascii_is_unsafe(char ch){	return !ch || ch == '\n' || ch == ':';},1867
59,139,CVE-2013-2548,8,int crypto_register_shash(struct shash_alg *alg){	struct crypto_alg *base = &alg->base;	int err;	err = shash_prepare_alg(alg);	if (err)		return err;	return crypto_register_alg(base);},8666
44,142,CVE-2013-2548,8,static int crypto_shash_init_tfm(struct crypto_tfm *tfm){	struct crypto_shash *hash = __crypto_shash_cast(tfm);	hash->descsize = crypto_shash_alg(hash)->descsize;	return 0;},8669
9,132,CVE-2013-2548,8,"static int crypto_rng_report(struct sk_buff *skb, struct crypto_alg *alg){	return -ENOSYS;}",8659
23,107,CVE-2013-2548,8,"static int blkcipher_walk_next(struct blkcipher_desc *desc,			       struct blkcipher_walk *walk){	struct crypto_blkcipher *tfm = desc->tfm;	unsigned int alignmask = crypto_blkcipher_alignmask(tfm);	unsigned int bsize;	unsigned int n;	int err;	n = walk->total;	if (unlikely(n < crypto_blkcipher_blocksize(tfm))) {		desc->flags |= CRYPTO_TFM_RES_BAD_BLOCK_LEN;		return blkcipher_walk_done(desc, walk, -EINVAL);	}	walk->flags &= ~(BLKCIPHER_WALK_SLOW | BLKCIPHER_WALK_COPY |			 BLKCIPHER_WALK_DIFF);	if (!scatterwalk_aligned(&walk->in, alignmask) ||	    !scatterwalk_aligned(&walk->out, alignmask)) {		walk->flags |= BLKCIPHER_WALK_COPY;		if (!walk->page) {			walk->page = (void *)__get_free_page(GFP_ATOMIC);			if (!walk->page)				n = 0;		}	}	bsize = min(walk->blocksize, n);	n = scatterwalk_clamp(&walk->in, n);	n = scatterwalk_clamp(&walk->out, n);	if (unlikely(n < bsize)) {		err = blkcipher_next_slow(desc, walk, bsize, alignmask);		goto set_phys_lowmem;	}	walk->nbytes = n;	if (walk->flags & BLKCIPHER_WALK_COPY) {		err = blkcipher_next_copy(walk);		goto set_phys_lowmem;	}	return blkcipher_next_fast(desc, walk);set_phys_lowmem:	if (walk->flags & BLKCIPHER_WALK_PHYS) {		walk->src.phys.page = virt_to_page(walk->src.virt.addr);		walk->dst.phys.page = virt_to_page(walk->dst.virt.addr);		walk->src.phys.offset &= PAGE_SIZE - 1;		walk->dst.phys.offset &= PAGE_SIZE - 1;	}	return err;}",8634
31,307,CVE-2013-2548,8," static int crypto_report_one(struct crypto_alg *alg, 			     struct crypto_user_alg *ualg, struct sk_buff *skb) {	memcpy(&ualg->cru_name, &alg->cra_name, sizeof(ualg->cru_name));	memcpy(&ualg->cru_driver_name, &alg->cra_driver_name,	       sizeof(ualg->cru_driver_name));	memcpy(&ualg->cru_module_name, module_name(alg->cra_module),	       CRYPTO_MAX_ALG_NAME); 	ualg->cru_flags = alg->cra_flags; 	ualg->cru_refcnt = atomic_read(&alg->cra_refcnt); 	if (nla_put_u32(skb, CRYPTOCFGA_PRIORITY_VAL, alg->cra_priority))		goto nla_put_failure; 	if (alg->cra_flags & CRYPTO_ALG_LARVAL) { 		struct crypto_report_larval rl; 		snprintf(rl.type, CRYPTO_MAX_ALG_NAME, ""%s"", ""larval""); 		if (nla_put(skb, CRYPTOCFGA_REPORT_LARVAL, 			    sizeof(struct crypto_report_larval), &rl)) 			goto nla_put_failure;		goto out;	}	if (alg->cra_type && alg->cra_type->report) {		if (alg->cra_type->report(skb, alg))			goto nla_put_failure;		goto out;	}	switch (alg->cra_flags & (CRYPTO_ALG_TYPE_MASK | CRYPTO_ALG_LARVAL)) {	case CRYPTO_ALG_TYPE_CIPHER:		if (crypto_report_cipher(skb, alg))			goto nla_put_failure;		break;	case CRYPTO_ALG_TYPE_COMPRESS:		if (crypto_report_comp(skb, alg))			goto nla_put_failure;		break;	}out:	return 0;nla_put_failure:	return -EMSGSIZE;}",31071
69,270,CVE-2013-7449,8,"traverse_socks (int print_fd, int sok, char *serverAddr, int port){	struct sock_connect sc;	unsigned char buf[256];	sc.version = 4;	sc.type = 1;	sc.port = htons (port);	sc.address = inet_addr (serverAddr);	strncpy (sc.username, prefs.hex_irc_user_name, 9);	send (sok, (char *) &sc, 8 + strlen (sc.username) + 1, 0);	buf[1] = 0;	recv (sok, buf, 10, 0);	if (buf[1] == 90)		return 0;	snprintf (buf, sizeof (buf), ""SOCKS\tServer reported error %d,%d.\n"", buf[0], buf[1]);	proxy_error (print_fd, buf);	return 1;}",19357
6,58,CVE-2013-2548,8,"static int crypto_givcipher_report(struct sk_buff *skb, struct crypto_alg *alg){	return -ENOSYS;}",8585
76,70,CVE-2013-2548,8,"static int crypto_nivaead_report(struct sk_buff *skb, struct crypto_alg *alg){	return -ENOSYS;}",8597
57,148,CVE-2013-2548,8,"int shash_ahash_update(struct ahash_request *req, struct shash_desc *desc){	struct crypto_hash_walk walk;	int nbytes;	for (nbytes = crypto_hash_walk_first(req, &walk); nbytes > 0;	     nbytes = crypto_hash_walk_done(&walk, nbytes))		nbytes = crypto_shash_update(desc, walk.data, nbytes);	return nbytes;}",8675
22,212,CVE-2012-5375,8,"struct btrfs_trans_handle *btrfs_attach_transaction(struct btrfs_root *root){	return start_transaction(root, 0, TRANS_ATTACH, 0);}",9952
37,290,CVE-2016-1618,8,     EmptyPlatform() {},29782
35,80,CVE-2013-2548,8,static int ahash_prepare_alg(struct ahash_alg *alg){	struct crypto_alg *base = &alg->halg.base;	if (alg->halg.digestsize > PAGE_SIZE / 8 ||	    alg->halg.statesize > PAGE_SIZE / 8)		return -EINVAL;	base->cra_type = &crypto_ahash_type;	base->cra_flags &= ~CRYPTO_ALG_TYPE_MASK;	base->cra_flags |= CRYPTO_ALG_TYPE_AHASH;	return 0;},8607
25,301,CVE-2016-1618,8,"    void testNonAnimatedCanvasUpdate()    {        m_testSurface->initializeCurrentFrame();        m_fakeImageBufferClient->fakeDraw();        m_testSurface->getPicture();        m_testSurface->getPicture();        EXPECT_EQ(2, m_fakeImageBufferClient->frameCount());        expectDisplayListEnabled(true);    }",29793
77,236,CVE-2012-5375,8,"static void wait_current_trans(struct btrfs_root *root){	struct btrfs_transaction *cur_trans;	spin_lock(&root->fs_info->trans_lock);	cur_trans = root->fs_info->running_transaction;	if (cur_trans && cur_trans->blocked) {		atomic_inc(&cur_trans->use_count);		spin_unlock(&root->fs_info->trans_lock);		wait_event(root->fs_info->transaction_wait,			   !cur_trans->blocked);		put_transaction(cur_trans);	} else {		spin_unlock(&root->fs_info->trans_lock);	}}",9976
19,168,CVE-2012-5375,8,void btrfs_destroy_cachep(void){	 	rcu_barrier();	if (btrfs_inode_cachep)		kmem_cache_destroy(btrfs_inode_cachep);	if (btrfs_trans_handle_cachep)		kmem_cache_destroy(btrfs_trans_handle_cachep);	if (btrfs_transaction_cachep)		kmem_cache_destroy(btrfs_transaction_cachep);	if (btrfs_path_cachep)		kmem_cache_destroy(btrfs_path_cachep);	if (btrfs_free_space_cachep)		kmem_cache_destroy(btrfs_free_space_cachep);	if (btrfs_delalloc_work_cachep)		kmem_cache_destroy(btrfs_delalloc_work_cachep);},9908
67,63,CVE-2013-2548,8,void aead_geniv_exit(struct crypto_tfm *tfm){	crypto_free_aead(tfm->crt_aead.base);},8590
43,102,CVE-2013-2548,8,"static inline int blkcipher_next_fast(struct blkcipher_desc *desc,				      struct blkcipher_walk *walk){	unsigned long diff;	walk->src.phys.page = scatterwalk_page(&walk->in);	walk->src.phys.offset = offset_in_page(walk->in.offset);	walk->dst.phys.page = scatterwalk_page(&walk->out);	walk->dst.phys.offset = offset_in_page(walk->out.offset);	if (walk->flags & BLKCIPHER_WALK_PHYS)		return 0;	diff = walk->src.phys.offset - walk->dst.phys.offset;	diff |= walk->src.virt.page - walk->dst.virt.page;	blkcipher_map_src(walk);	walk->dst.virt.addr = walk->src.virt.addr;	if (diff) {		walk->flags |= BLKCIPHER_WALK_DIFF;		blkcipher_map_dst(walk);	}	return 0;}",8629
66,46,CVE-2013-4350,8,"static void sctp_v6_to_sk_saddr(union sctp_addr *addr, struct sock *sk){	if (addr->sa.sa_family == AF_INET && sctp_sk(sk)->v4mapped) {		inet6_sk(sk)->rcv_saddr.s6_addr32[0] = 0;		inet6_sk(sk)->rcv_saddr.s6_addr32[1] = 0;		inet6_sk(sk)->rcv_saddr.s6_addr32[2] = htonl(0x0000ffff);		inet6_sk(sk)->rcv_saddr.s6_addr32[3] =			addr->v4.sin_addr.s_addr;	} else {		inet6_sk(sk)->rcv_saddr = addr->v6.sin6_addr;	}}",7846
27,100,CVE-2013-2548,8,static inline void blkcipher_map_dst(struct blkcipher_walk *walk){	walk->dst.virt.addr = scatterwalk_map(&walk->out);},8627
38,86,CVE-2013-2548,8,"static int crypto_ahash_op(struct ahash_request *req,			   int (*op)(struct ahash_request *)){	struct crypto_ahash *tfm = crypto_ahash_reqtfm(req);	unsigned long alignmask = crypto_ahash_alignmask(tfm);	if ((unsigned long)req->result & alignmask)		return ahash_op_unaligned(req, op);	return op(req);}",8613
65,295,CVE-2016-1618,8,"    void expectDisplayListEnabled(int displayListEnabled)    {        EXPECT_EQ(displayListEnabled, (int)m_testSurface->m_currentFrame.get());        EXPECT_EQ(!displayListEnabled, (int)m_testSurface->m_fallbackSurface.get());        int expectedSurfaceCreationCount = displayListEnabled ? 0 : 1;        EXPECT_EQ(expectedSurfaceCreationCount, m_surfaceFactory->createSurfaceCount());    }",29787
0,191,CVE-2012-5375,8,"void btrfs_wait_and_free_delalloc_work(struct btrfs_delalloc_work *work){	wait_for_completion(&work->completion);	kmem_cache_free(btrfs_delalloc_work_cachep, work);}",9931
33,166,CVE-2012-5375,8,static int btrfs_dentry_delete(const struct dentry *dentry){	struct btrfs_root *root;	struct inode *inode = dentry->d_inode;	if (!inode && !IS_ROOT(dentry))		inode = dentry->d_parent->d_inode;	if (inode) {		root = BTRFS_I(inode)->root;		if (btrfs_root_refs(&root->root_item) == 0)			return 1;		if (btrfs_ino(inode) == BTRFS_EMPTY_SUBVOL_DIR_OBJECTID)			return 1;	}	return 0;},9906
73,51,CVE-2013-2548,8,"static inline void ablkcipher_queue_write(struct ablkcipher_walk *walk,					  struct ablkcipher_buffer *p){	p->dst = walk->out;	list_add_tail(&p->entry, &walk->buffers);}",8578
55,164,CVE-2012-5375,8,"struct btrfs_delalloc_work *btrfs_alloc_delalloc_work(struct inode *inode,						    int wait, int delay_iput){	struct btrfs_delalloc_work *work;	work = kmem_cache_zalloc(btrfs_delalloc_work_cachep, GFP_NOFS);	if (!work)		return NULL;	init_completion(&work->completion);	INIT_LIST_HEAD(&work->list);	work->inode = inode;	work->wait = wait;	work->delay_iput = delay_iput;	work->work.func = btrfs_run_delalloc_work;	return work;}",9904
26,88,CVE-2013-2548,8,"static void crypto_ahash_show(struct seq_file *m, struct crypto_alg *alg){	seq_printf(m, ""type         : ahash\n"");	seq_printf(m, ""async        : %s\n"", alg->cra_flags & CRYPTO_ALG_ASYNC ?					     ""yes"" : ""no"");	seq_printf(m, ""blocksize    : %u\n"", alg->cra_blocksize);	seq_printf(m, ""digestsize   : %u\n"",		   __crypto_hash_alg_common(alg)->digestsize);}",8615
47,103,CVE-2013-2548,8,static inline void blkcipher_unmap_dst(struct blkcipher_walk *walk){	scatterwalk_unmap(walk->dst.virt.addr);},8630
56,112,CVE-2013-2548,8,static int crypto_init_blkcipher_ops_async(struct crypto_tfm *tfm){	struct ablkcipher_tfm *crt = &tfm->crt_ablkcipher;	struct blkcipher_alg *alg = &tfm->__crt_alg->cra_blkcipher;	crt->setkey = async_setkey;	crt->encrypt = async_encrypt;	crt->decrypt = async_decrypt;	if (!alg->ivsize) {		crt->givencrypt = skcipher_null_givencrypt;		crt->givdecrypt = skcipher_null_givdecrypt;	}	crt->base = __crypto_ablkcipher_cast(tfm);	crt->ivsize = alg->ivsize;	return 0;},8639
64,69,CVE-2013-2548,8,"int crypto_aead_setauthsize(struct crypto_aead *tfm, unsigned int authsize){	struct aead_tfm *crt = crypto_aead_crt(tfm);	int err;	if (authsize > crypto_aead_alg(tfm)->maxauthsize)		return -EINVAL;	if (crypto_aead_alg(tfm)->setauthsize) {		err = crypto_aead_alg(tfm)->setauthsize(crt->base, authsize);		if (err)			return err;	}	crypto_aead_crt(crt->base)->authsize = authsize;	crt->authsize = authsize;	return 0;}",8596
72,60,CVE-2013-2548,8,static void skcipher_module_exit(void){},8587
49,261,CVE-2014-3570,8,"int rand_neg(void)	{	static unsigned int neg=0;	static int sign[8]={0,0,0,1,1,0,1,1};	return(sign[(neg++)%8]);	}",14628
48,42,CVE-2013-4350,8,"static void sctp_v6_seq_dump_addr(struct seq_file *seq, union sctp_addr *addr){	seq_printf(seq, ""%pI6 "", &addr->v6.sin6_addr);}",7842
71,223,CVE-2012-5375,8,"struct btrfs_trans_handle *btrfs_start_transaction(struct btrfs_root *root,						   int num_items){	return start_transaction(root, num_items, TRANS_START,				 BTRFS_RESERVE_FLUSH_ALL);}",9963
54,174,CVE-2012-5375,8,"int btrfs_init_cachep(void){	btrfs_inode_cachep = kmem_cache_create(""btrfs_inode"",			sizeof(struct btrfs_inode), 0,			SLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD, init_once);	if (!btrfs_inode_cachep)		goto fail;	btrfs_trans_handle_cachep = kmem_cache_create(""btrfs_trans_handle"",			sizeof(struct btrfs_trans_handle), 0,			SLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD, NULL);	if (!btrfs_trans_handle_cachep)		goto fail;	btrfs_transaction_cachep = kmem_cache_create(""btrfs_transaction"",			sizeof(struct btrfs_transaction), 0,			SLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD, NULL);	if (!btrfs_transaction_cachep)		goto fail;	btrfs_path_cachep = kmem_cache_create(""btrfs_path"",			sizeof(struct btrfs_path), 0,			SLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD, NULL);	if (!btrfs_path_cachep)		goto fail;	btrfs_free_space_cachep = kmem_cache_create(""btrfs_free_space"",			sizeof(struct btrfs_free_space), 0,			SLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD, NULL);	if (!btrfs_free_space_cachep)		goto fail;	btrfs_delalloc_work_cachep = kmem_cache_create(""btrfs_delalloc_work"",			sizeof(struct btrfs_delalloc_work), 0,			SLAB_RECLAIM_ACCOUNT | SLAB_MEM_SPREAD,			NULL);	if (!btrfs_delalloc_work_cachep)		goto fail;	return 0;fail:	btrfs_destroy_cachep();	return -ENOMEM;}",9914
24,151,CVE-2013-2548,8,"static int shash_async_final(struct ahash_request *req){	return crypto_shash_final(ahash_request_ctx(req), req->result);}",8678
11,217,CVE-2012-5375,8,"int btrfs_end_transaction_throttle(struct btrfs_trans_handle *trans,				   struct btrfs_root *root){	int ret;	ret = __btrfs_end_transaction(trans, root, 1);	if (ret)		return ret;	return 0;}",9957
20,147,CVE-2013-2548,8,"int shash_ahash_finup(struct ahash_request *req, struct shash_desc *desc){	struct crypto_hash_walk walk;	int nbytes;	nbytes = crypto_hash_walk_first(req, &walk);	if (!nbytes)		return crypto_shash_final(desc, req->result);	do {		nbytes = crypto_hash_walk_last(&walk) ?			 crypto_shash_finup(desc, walk.data, nbytes,					    req->result) :			 crypto_shash_update(desc, walk.data, nbytes);		nbytes = crypto_hash_walk_done(&walk, nbytes);	} while (nbytes > 0);	return nbytes;}",8674
53,122,CVE-2013-2548,8,"static int crypto_report_alg(struct crypto_alg *alg,			     struct crypto_dump_info *info){	struct sk_buff *in_skb = info->in_skb;	struct sk_buff *skb = info->out_skb;	struct nlmsghdr *nlh;	struct crypto_user_alg *ualg;	int err = 0;	nlh = nlmsg_put(skb, NETLINK_CB(in_skb).portid, info->nlmsg_seq,			CRYPTO_MSG_GETALG, sizeof(*ualg), info->nlmsg_flags);	if (!nlh) {		err = -EMSGSIZE;		goto out;	}	ualg = nlmsg_data(nlh);	err = crypto_report_one(alg, ualg, skb);	if (err) {		nlmsg_cancel(skb, nlh);		goto out;	}	nlmsg_end(skb, nlh);out:	return err;}",8649
68,225,CVE-2012-5375,8,void btrfs_throttle(struct btrfs_root *root){	if (!atomic_read(&root->fs_info->open_ioctl_trans))		wait_current_trans(root);},9965
13,133,CVE-2013-2548,8,"static void crypto_rng_show(struct seq_file *m, struct crypto_alg *alg){	seq_printf(m, ""type         : rng\n"");	seq_printf(m, ""seedsize     : %u\n"", alg->cra_rng.seedsize);}",8660
15,99,CVE-2013-2548,8,"static inline unsigned int blkcipher_done_fast(struct blkcipher_walk *walk,					       unsigned int n){	if (walk->flags & BLKCIPHER_WALK_COPY) {		blkcipher_map_dst(walk);		memcpy(walk->dst.virt.addr, walk->page, n);		blkcipher_unmap_dst(walk);	} else if (!(walk->flags & BLKCIPHER_WALK_PHYS)) {		if (walk->flags & BLKCIPHER_WALK_DIFF)			blkcipher_unmap_dst(walk);		blkcipher_unmap_src(walk);	}	scatterwalk_advance(&walk->in, n);	scatterwalk_advance(&walk->out, n);	return n;}",8626
12,25,CVE-2013-4350,8,"static void sctp_inet6_skb_msgname(struct sk_buff *skb, char *msgname,				   int *addr_len){	struct sctphdr *sh;	struct sockaddr_in6 *sin6;	if (msgname) {		sctp_inet6_msgname(msgname, addr_len);		sin6 = (struct sockaddr_in6 *)msgname;		sh = sctp_hdr(skb);		sin6->sin6_port = sh->source;		 		if (sctp_sk(skb->sk)->v4mapped &&		    ip_hdr(skb)->version == 4) {			sctp_v4_map_v6((union sctp_addr *)sin6);			sin6->sin6_addr.s6_addr32[3] = ip_hdr(skb)->saddr;			return;		}		 		sin6->sin6_addr = ipv6_hdr(skb)->saddr;		if (ipv6_addr_type(&sin6->sin6_addr) & IPV6_ADDR_LINKLOCAL) {			struct sctp_ulpevent *ev = sctp_skb2event(skb);			sin6->sin6_scope_id = ev->iif;		}	}}",7825
18,255,CVE-2013-6371,8,void lh_table_free(struct lh_table *t){	struct lh_entry *c;	for(c = t->head; c != NULL; c = c->next) {		if(t->free_fn) {			t->free_fn(c);		}	}	free(t->table);	free(t);},12647
5,18,CVE-2014-0076,8,"void BN_set_params(int mult, int high, int low, int mont)	{	if (mult >= 0)		{		if (mult > (int)(sizeof(int)*8)-1)			mult=sizeof(int)*8-1;		bn_limit_bits=mult;		bn_limit_num=1<<mult;		}	if (high >= 0)		{		if (high > (int)(sizeof(int)*8)-1)			high=sizeof(int)*8-1;		bn_limit_bits_high=high;		bn_limit_num_high=1<<high;		}	if (low >= 0)		{		if (low > (int)(sizeof(int)*8)-1)			low=sizeof(int)*8-1;		bn_limit_bits_low=low;		bn_limit_num_low=1<<low;		}	if (mont >= 0)		{		if (mont > (int)(sizeof(int)*8)-1)			mont=sizeof(int)*8-1;		bn_limit_bits_mont=mont;		bn_limit_num_mont=1<<mont;		}	}",2273
39,219,CVE-2012-5375,8,"struct btrfs_trans_handle *btrfs_join_transaction_nolock(struct btrfs_root *root){	return start_transaction(root, 0, TRANS_JOIN_NOLOCK, 0);}",9959
40,2,CVE-2013-6449,8,long ssl3_default_timeout(void)	{	 	return(60*60*2);	},157
46,161,CVE-2013-2548,8,static int shash_prepare_alg(struct shash_alg *alg){	struct crypto_alg *base = &alg->base;	if (alg->digestsize > PAGE_SIZE / 8 ||	    alg->descsize > PAGE_SIZE / 8 ||	    alg->statesize > PAGE_SIZE / 8)		return -EINVAL;	base->cra_type = &crypto_shash_type;	base->cra_flags &= ~CRYPTO_ALG_TYPE_MASK;	base->cra_flags |= CRYPTO_ALG_TYPE_SHASH;	if (!alg->finup)		alg->finup = shash_finup_unaligned;	if (!alg->digest)		alg->digest = shash_digest_unaligned;	if (!alg->export) {		alg->export = shash_default_export;		alg->import = shash_default_import;		alg->statesize = alg->descsize;	}	if (!alg->setkey)		alg->setkey = shash_no_setkey;	return 0;},8688
16,93,CVE-2013-2548,8,int crypto_register_ahash(struct ahash_alg *alg){	struct crypto_alg *base = &alg->halg.base;	int err;	err = ahash_prepare_alg(alg);	if (err)		return err;	return crypto_register_alg(base);},8620
63,210,CVE-2012-5375,8,"static int __btrfs_end_transaction(struct btrfs_trans_handle *trans,			  struct btrfs_root *root, int throttle){	struct btrfs_transaction *cur_trans = trans->transaction;	struct btrfs_fs_info *info = root->fs_info;	int count = 0;	int lock = (trans->type != TRANS_JOIN_NOLOCK);	int err = 0;	if (--trans->use_count) {		trans->block_rsv = trans->orig_rsv;		return 0;	}	 	err = btrfs_delayed_refs_qgroup_accounting(trans, info);	btrfs_trans_release_metadata(trans, root);	trans->block_rsv = NULL;	 	WARN_ON(trans->root != root);	if (trans->qgroup_reserved) {		btrfs_qgroup_free(root, trans->qgroup_reserved);		trans->qgroup_reserved = 0;	}	if (!list_empty(&trans->new_bgs))		btrfs_create_pending_block_groups(trans, root);	while (count < 2) {		unsigned long cur = trans->delayed_ref_updates;		trans->delayed_ref_updates = 0;		if (cur &&		    trans->transaction->delayed_refs.num_heads_ready > 64) {			trans->delayed_ref_updates = 0;			btrfs_run_delayed_refs(trans, root, cur);		} else {			break;		}		count++;	}	btrfs_trans_release_metadata(trans, root);	trans->block_rsv = NULL;	if (!list_empty(&trans->new_bgs))		btrfs_create_pending_block_groups(trans, root);	if (lock && !atomic_read(&root->fs_info->open_ioctl_trans) &&	    should_end_transaction(trans, root)) {		trans->transaction->blocked = 1;		smp_wmb();	}	if (lock && cur_trans->blocked && !cur_trans->in_commit) {		if (throttle) {			 			trans->use_count++;			return btrfs_commit_transaction(trans, root);		} else {			wake_up_process(info->transaction_kthread);		}	}	if (trans->type < TRANS_JOIN_NOLOCK)		sb_end_intwrite(root->fs_info->sb);	WARN_ON(cur_trans != info->running_transaction);	WARN_ON(atomic_read(&cur_trans->num_writers) < 1);	atomic_dec(&cur_trans->num_writers);	smp_mb();	if (waitqueue_active(&cur_trans->writer_wait))		wake_up(&cur_trans->writer_wait);	put_transaction(cur_trans);	if (current->journal_info == trans)		current->journal_info = NULL;	if (throttle)		btrfs_run_delayed_iputs(root);	if (trans->aborted ||	    root->fs_info->fs_state & BTRFS_SUPER_FLAG_ERROR) {		err = -EIO;	}	assert_qgroups_uptodate(trans);	memset(trans, 0, sizeof(*trans));	kmem_cache_free(btrfs_trans_handle_cachep, trans);	return err;}",9950
14,83,CVE-2013-2548,8,static unsigned int crypto_ahash_extsize(struct crypto_alg *alg){	if (alg->cra_type == &crypto_ahash_type)		return alg->cra_ctxsize;	return sizeof(struct crypto_shash *);},8610
28,274,CVE-2013-7449,8,"__SSL_fill_err_buf (char *funcname){	int err;	char buf[256];	err = ERR_get_error ();	ERR_error_string (err, buf);	g_snprintf (err_buf, sizeof (err_buf), ""%s: %s (%d)\n"", funcname, buf, err);}",19361
60,276,CVE-2016-7798,8,ossl_cipher_free(void *ptr){    EVP_CIPHER_CTX_free(ptr);},22792
51,16,CVE-2016-6489,8,rsa_private_key_init(struct rsa_private_key *key){  mpz_init(key->d);  mpz_init(key->p);  mpz_init(key->q);  mpz_init(key->a);  mpz_init(key->b);  mpz_init(key->c);     key->size = 0;},2270
61,141,CVE-2013-2548,8,static unsigned int crypto_shash_extsize(struct crypto_alg *alg){	return alg->cra_ctxsize;},8668
36,155,CVE-2013-2548,8,"static int shash_async_update(struct ahash_request *req){	return shash_ahash_update(req, ahash_request_ctx(req));}",8682
75,91,CVE-2013-2548,8,"int crypto_hash_walk_first_compat(struct hash_desc *hdesc,				  struct crypto_hash_walk *walk,				  struct scatterlist *sg, unsigned int len){	walk->total = len;	if (!walk->total)		return 0;	walk->alignmask = crypto_hash_alignmask(hdesc->tfm);	walk->sg = sg;	walk->flags = hdesc->flags;	return hash_walk_new_entry(walk);}",8618
70,156,CVE-2013-2548,8,static int shash_compat_init(struct hash_desc *hdesc){	struct shash_desc **descp = crypto_hash_ctx(hdesc->tfm);	struct shash_desc *desc = *descp;	desc->flags = hdesc->flags;	return crypto_shash_init(desc);},8683
62,204,CVE-2012-5375,8,static long btrfs_ioctl_trans_start(struct file *file){	struct inode *inode = fdentry(file)->d_inode;	struct btrfs_root *root = BTRFS_I(inode)->root;	struct btrfs_trans_handle *trans;	int ret;	ret = -EPERM;	if (!capable(CAP_SYS_ADMIN))		goto out;	ret = -EINPROGRESS;	if (file->private_data)		goto out;	ret = -EROFS;	if (btrfs_root_readonly(root))		goto out;	ret = mnt_want_write_file(file);	if (ret)		goto out;	atomic_inc(&root->fs_info->open_ioctl_trans);	ret = -ENOMEM;	trans = btrfs_start_ioctl_transaction(root);	if (IS_ERR(trans))		goto out_drop;	file->private_data = trans;	return 0;out_drop:	atomic_dec(&root->fs_info->open_ioctl_trans);	mnt_drop_write_file(file);out:	return ret;},9944
30,77,CVE-2013-2548,8,"static int ahash_no_export(struct ahash_request *req, void *out){	return -ENOSYS;}",8604
45,192,CVE-2012-5375,8,"int btrfs_write_inode(struct inode *inode, struct writeback_control *wbc){	struct btrfs_root *root = BTRFS_I(inode)->root;	struct btrfs_trans_handle *trans;	int ret = 0;	int nolock = false;	if (test_bit(BTRFS_INODE_DUMMY, &BTRFS_I(inode)->runtime_flags))		return 0;	if (btrfs_fs_closing(root->fs_info) && btrfs_is_free_space_inode(inode))		nolock = true;	if (wbc->sync_mode == WB_SYNC_ALL) {		if (nolock)			trans = btrfs_join_transaction_nolock(root);		else			trans = btrfs_join_transaction(root);		if (IS_ERR(trans))			return PTR_ERR(trans);		ret = btrfs_commit_transaction(trans, root);	}	return ret;}",9932
2,52,CVE-2013-2548,8,"int ablkcipher_walk_done(struct ablkcipher_request *req,			 struct ablkcipher_walk *walk, int err){	struct crypto_tfm *tfm = req->base.tfm;	unsigned int nbytes = 0;	if (likely(err >= 0)) {		unsigned int n = walk->nbytes - err;		if (likely(!(walk->flags & ABLKCIPHER_WALK_SLOW)))			n = ablkcipher_done_fast(walk, n);		else if (WARN_ON(err)) {			err = -EINVAL;			goto err;		} else			n = ablkcipher_done_slow(walk, n);		nbytes = walk->total - n;		err = 0;	}	scatterwalk_done(&walk->in, 0, nbytes);	scatterwalk_done(&walk->out, 1, nbytes);err:	walk->total = nbytes;	walk->nbytes = nbytes;	if (nbytes) {		crypto_yield(req->base.flags);		return ablkcipher_walk_next(req, walk);	}	if (walk->iv != req->info)		memcpy(req->info, walk->iv, tfm->crt_ablkcipher.ivsize);	kfree(walk->iv_buffer);	return err;}",8579
41,2,CVE-2017-15906,9,flags_from_portable(int pflags){	int flags = 0;	if ((pflags & SSH2_FXF_READ) &&	    (pflags & SSH2_FXF_WRITE)) {		flags = O_RDWR;	} else if (pflags & SSH2_FXF_READ) {		flags = O_RDONLY;	} else if (pflags & SSH2_FXF_WRITE) {		flags = O_WRONLY;	}	if (pflags & SSH2_FXF_APPEND)		flags |= O_APPEND;	if (pflags & SSH2_FXF_CREAT)		flags |= O_CREAT;	if (pflags & SSH2_FXF_TRUNC)		flags |= O_TRUNC;	if (pflags & SSH2_FXF_EXCL)		flags |= O_EXCL;	return flags;},19942
42,280,CVE-2017-6903,9,"void FS_PureServerSetLoadedPaks( const char *pakSums, const char *pakNames ) {	int		i, c, d;	Cmd_TokenizeString( pakSums );	c = Cmd_Argc();	if ( c > MAX_SEARCH_PATHS ) {		c = MAX_SEARCH_PATHS;	}	fs_numServerPaks = c;	for ( i = 0 ; i < c ; i++ ) {		fs_serverPaks[i] = atoi( Cmd_Argv( i ) );	}	if (fs_numServerPaks) {		Com_DPrintf( ""Connected to a pure server.\n"" );	}	else	{		if (fs_reordered)		{			Com_DPrintf( ""FS search reorder is required\n"" );			FS_Restart(fs_checksumFeed);			return;		}	}	for ( i = 0 ; i < c ; i++ ) {		if (fs_serverPakNames[i]) {			Z_Free(fs_serverPakNames[i]);		}		fs_serverPakNames[i] = NULL;	}	if ( pakNames && *pakNames ) {		Cmd_TokenizeString( pakNames );		d = Cmd_Argc();		if ( d > MAX_SEARCH_PATHS ) {			d = MAX_SEARCH_PATHS;		}		for ( i = 0 ; i < d ; i++ ) {			fs_serverPakNames[i] = CopyString( Cmd_Argv( i ) );		}	}}",28800
1,310,CVE-2017-5940,9,"void notify_other(int fd) {	FILE* stream;	int newfd = dup(fd);	if (newfd == -1)		errExit(""dup"");	stream = fdopen(newfd, ""w"");	fprintf(stream, ""%u\n"", getpid());	fflush(stream);	fclose(stream);}",28830
34,166,CVE-2017-6903,9,"void *CL_RefMallocDebug( int size, char *label, char *file, int line ) {	return Z_TagMallocDebug( size, TAG_RENDERER, label, file, line );}",28686
21,168,CVE-2017-6903,9,"void CL_ReferencedPK3List_f( void ) {	Com_Printf( ""Referenced PK3 Names: %s\n"", FS_ReferencedPakNames() );}",28688
75,222,CVE-2017-6903,9,"int Sys_FileTime( char *path ){	struct stat buf;	if (stat (path,&buf) == -1)		return -1;	return buf.st_mtime;}",28742
3,248,CVE-2017-6903,9,"void CL_ClearState (void) {	Com_Memset( &cl, 0, sizeof( cl ) );}",28768
10,140,CVE-2017-6903,9,"void CL_AddToLimboChat( const char *str ) {	int len = 0;	char *p;	int i;	cl.limboChatPos = LIMBOCHAT_HEIGHT - 1;	for ( i = cl.limboChatPos; i > 0; i-- ) {		strcpy( cl.limboChatMsgs[i], cl.limboChatMsgs[i - 1] );	}	p = cl.limboChatMsgs[0];	*p = 0;	while ( *str ) {		if ( len > LIMBOCHAT_WIDTH - 1 ) {			break;		}		if ( Q_IsColorString( str ) ) {			*p++ = *str++;			*p++ = *str++;			continue;		}		*p++ = *str++;		len++;	}	*p = 0;}",28660
29,275,CVE-2017-6903,9,"const char *FS_LoadedPakChecksums( void ) {	static char	info[BIG_INFO_STRING];	searchpath_t	*search;	info[0] = 0;	for ( search = fs_searchpaths ; search ; search = search->next ) {		if ( !search->pack ) {			continue;		}		Q_strcat( info, sizeof( info ), va(""%i "", search->pack->checksum ) );	}	return info;}",28795
50,261,CVE-2017-6903,9,"void CL_RequestAuthorization( void ) {	char	nums[64];	int		i, j, l;	cvar_t	*fs;	if ( !cls.authorizeServer.port ) {		Com_Printf( ""Resolving %s\n"", AUTHORIZE_SERVER_NAME );		if ( !NET_StringToAdr( AUTHORIZE_SERVER_NAME, &cls.authorizeServer, NA_IP ) ) {			Com_Printf( ""Couldn't resolve address\n"" );			return;		}		cls.authorizeServer.port = BigShort( PORT_AUTHORIZE );		Com_Printf( ""%s resolved to %i.%i.%i.%i:%i\n"", AUTHORIZE_SERVER_NAME,			cls.authorizeServer.ip[0], cls.authorizeServer.ip[1],			cls.authorizeServer.ip[2], cls.authorizeServer.ip[3],			BigShort( cls.authorizeServer.port ) );	}	if ( cls.authorizeServer.type == NA_BAD ) {		return;	}	j = 0;	l = strlen( cl_cdkey );	if ( l > 32 ) {		l = 32;	}	for ( i = 0 ; i < l ; i++ ) {		if ( ( cl_cdkey[i] >= '0' && cl_cdkey[i] <= '9' )				|| ( cl_cdkey[i] >= 'a' && cl_cdkey[i] <= 'z' )				|| ( cl_cdkey[i] >= 'A' && cl_cdkey[i] <= 'Z' )			 ) {			nums[j] = cl_cdkey[i];			j++;		}	}	nums[j] = 0;	fs = Cvar_Get (""cl_anonymous"", ""0"", CVAR_INIT|CVAR_SYSTEMINFO );	NET_OutOfBandPrint(NS_CLIENT, cls.authorizeServer, ""getKeyAuthorize %i %s"", fs->integer, nums );}",28781
17,99,CVE-2017-6903,9,"void S_AL_MasterGain( float gain ){	qalListenerf(AL_GAIN, gain);}",28619
58,148,CVE-2017-6903,9,"void CL_Clientinfo_f( void ) {	Com_Printf( ""--------- Client Information ---------\n"" );	Com_Printf( ""state: %i\n"", clc.state );	Com_Printf( ""Server: %s\n"", clc.servername );	Com_Printf( ""User info settings:\n"" );	Info_Print( Cvar_InfoString( CVAR_USERINFO ) );	Com_Printf( ""--------------------------------------\n"" );}",28668
52,16,CVE-2017-5940,9,"static void copy_xauthority(void) {	char *src = RUN_XAUTHORITY_FILE ;	char *dest;	if (asprintf(&dest, ""%s/.Xauthority"", cfg.homedir) == -1)		errExit(""asprintf"");		if (is_link(dest)) {		fprintf(stderr, ""Error: %s is a symbolic link\n"", dest);		exit(1);	}	copy_file_as_user(src, dest, getuid(), getgid(), S_IRUSR | S_IWUSR);	fs_logger2(""clone"", dest);		unlink(src);}",21955
7,18,CVE-2017-5940,9,"void fs_check_private_dir(void) {	EUID_ASSERT();	invalid_filename(cfg.home_private);		char *tmp = expand_home(cfg.home_private, cfg.homedir);	cfg.home_private = realpath(tmp, NULL);	free(tmp);		if (!cfg.home_private	 || !is_dir(cfg.home_private)	 || is_link(cfg.home_private)	 || strstr(cfg.home_private, "".."")) {		fprintf(stderr, ""Error: invalid private directory\n"");		exit(1);	}	struct stat s2;	int rv = stat(cfg.home_private, &s2);	if (rv < 0) {		fprintf(stderr, ""Error: cannot find %s directory\n"", cfg.home_private);		exit(1);	}	struct stat s1;	rv = stat(cfg.homedir, &s1);	if (rv < 0) {		fprintf(stderr, ""Error: cannot find %s directory, full path name required\n"", cfg.homedir);		exit(1);	}	if (s1.st_uid != s2.st_uid) {		printf(""Error: --private directory should be owned by the current user\n"");		exit(1);	}}",21957
8,58,CVE-2017-6903,9,void Con_ClearNotify( void ) {	int		i;		for ( i = 0 ; i < NUM_CON_TIMES ; i++ ) {		con.times[i] = 0;	}},28578
4,52,CVE-2018-13405,9,"struct timespec64 timespec64_trunc(struct timespec64 t, unsigned gran){	 	if (gran == 1) {		 	} else if (gran == NSEC_PER_SEC) {		t.tv_nsec = 0;	} else if (gran > 1 && gran < NSEC_PER_SEC) {		t.tv_nsec -= t.tv_nsec % gran;	} else {		WARN(1, ""illegal file time granularity: %u"", gran);	}	return t;}",24617
32,308,CVE-2017-5940,9,"int mkpath_as_root(const char* path) {	assert(path && *path);		char *file_path = strdup(path);	if (!file_path)		errExit(""strdup"");	char* p;	int done = 0;	for (p=strchr(file_path+1, '/'); p; p=strchr(p+1, '/')) {		*p='\0';		if (mkdir(file_path, 0755)==-1) {			if (errno != EEXIST) {				*p='/';				free(file_path);				return -1;			}		}		else {			if (chmod(file_path, 0755) == -1)				errExit(""chmod"");			if (chown(file_path, 0, 0) == -1)				errExit(""chown"");			done = 1;		}					*p='/';	}	if (done)		fs_logger2(""mkpath"", path);			free(file_path);	return 0;}",28828
59,24,CVE-2018-13405,9,void clear_inode(struct inode *inode){	 	xa_lock_irq(&inode->i_data.i_pages);	BUG_ON(inode->i_data.nrpages);	BUG_ON(inode->i_data.nrexceptional);	xa_unlock_irq(&inode->i_data.i_pages);	BUG_ON(!list_empty(&inode->i_data.private_list));	BUG_ON(!(inode->i_state & I_FREEING));	BUG_ON(inode->i_state & I_CLEAR);	BUG_ON(!list_empty(&inode->i_wb_list));	 	inode->i_state = I_FREEING | I_CLEAR;},24589
44,102,CVE-2017-6903,9,void S_AL_SoundList( void ){},28622
9,307,CVE-2017-5940,9," int is_dir(const char *fname) { 	assert(fname);	if (*fname == '\0')		return 0;		int rv;	struct stat s;	if (fname[strlen(fname) - 1] == '/')		rv = stat(fname, &s);	else {		char *tmp;		if (asprintf(&tmp, ""%s/"", fname) == -1) {			fprintf(stderr, ""Error: cannot allocate memory, %s:%d\n"", __FILE__, __LINE__);			errExit(""asprintf"");		}				rv = stat(tmp, &s);		free(tmp);	}		if (rv == -1)		return 0;			if (S_ISDIR(s.st_mode))		return 1;	return 0;}",28827
23,212,CVE-2017-6903,9,"static int FS_ReturnPath( const char *zname, char *zpath, int *depth ) {	int len, at, newdep;	newdep = 0;	zpath[0] = 0;	len = 0;	at = 0;	while ( zname[at] != 0 )	{		if ( zname[at] == '/' || zname[at] == '\\' ) {			len = at;			newdep++;		}		at++;	}	strcpy( zpath, zname );	zpath[len] = 0;	*depth = newdep;	return len;}",28732
31,77,CVE-2017-6903,9,"int Com_FilterPath(char *filter, char *name, int casesensitive){	int i;	char new_filter[MAX_QPATH];	char new_name[MAX_QPATH];	for (i = 0; i < MAX_QPATH-1 && filter[i]; i++) {		if ( filter[i] == '\\' || filter[i] == ':' ) {			new_filter[i] = '/';		}		else {			new_filter[i] = filter[i];		}	}	new_filter[i] = '\0';	for (i = 0; i < MAX_QPATH-1 && name[i]; i++) {		if ( name[i] == '\\' || name[i] == ':' ) {			new_name[i] = '/';		}		else {			new_name[i] = name[i];		}	}	new_name[i] = '\0';	return Com_Filter(new_filter, new_name, casesensitive);}",28597
69,225,CVE-2017-6903,9,void Sys_Print( const char *msg ){	CON_LogWrite( msg );	CON_Print( msg );},28745
6,246,CVE-2017-6903,9,static unsigned int Sys_CountFileList( char **list ) {	int i = 0;	if (list)	{		while (*list)		{			list++;			i++;		}	}	return i;},28766
77,70,CVE-2017-6903,9,void Con_ToggleConsole_f (void) {	if ( clc.state == CA_DISCONNECTED && Key_GetCatcher( ) == KEYCATCH_CONSOLE ) {		return;	}	Field_Clear( &g_consoleField );	g_consoleField.widthInChars = g_console_field_width;	Con_ClearNotify ();	Key_SetCatcher( Key_GetCatcher( ) ^ KEYCATCH_CONSOLE );},28590
57,112,CVE-2017-6903,9,void Con_DrawConsole( void ) {	Con_CheckResize();	if ( clc.state == CA_DISCONNECTED ) {		if ( !( Key_GetCatcher( ) & (KEYCATCH_UI | KEYCATCH_CGAME)) ) {			Con_DrawSolidConsole( 1.0 );			return;		}	}	if ( con.displayFrac ) {		Con_DrawSolidConsole( con.displayFrac );	} else {		if ( clc.state == CA_ACTIVE ) {			Con_DrawNotify();		}	}},28632
22,147,CVE-2017-6903,9,void CL_ClientDamageCommand( void ) {},28667
37,155,CVE-2017-6903,9,void CL_FlushMemory(void){	CL_ClearMemory(qfalse);	CL_StartHunkUsers(qfalse);},28675
35,57,CVE-2017-6903,9,void Con_Bottom( void ) {	con.display = con.current;},28577
25,151,CVE-2017-6903,9,"void CL_Configstrings_f( void ) {	int	i;	int	ofs;	if ( clc.state != CA_ACTIVE ) {		Com_Printf( ""Not connected to a server.\n"" );		return;	}	for ( i = 0 ; i < MAX_CONFIGSTRINGS ; i++ ) {		ofs = cl.gameState.stringOffsets[ i ];		if ( !ofs ) {			continue;		}		Com_Printf( ""%4i: %s\n"", i, cl.gameState.stringData + ofs );	}}",28671
78,236,CVE-2017-6903,9,void CL_SetRecommended_f( void ) {	if ( Cmd_Argc() > 1 ) {		Com_SetRecommended( qtrue );	} else {		Com_SetRecommended( qfalse );	}},28756
19,21,CVE-2018-13405,9,"static int __remove_privs(struct dentry *dentry, int kill){	struct iattr newattrs;	newattrs.ia_valid = ATTR_FORCE | kill;	 	return notify_change(dentry, &newattrs, NULL);}",24586
67,46,CVE-2018-13405,9,"void lock_two_nondirectories(struct inode *inode1, struct inode *inode2){	if (inode1 > inode2)		swap(inode1, inode2);	if (inode1 && !S_ISDIR(inode1->i_mode))		inode_lock(inode1);	if (inode2 && !S_ISDIR(inode2->i_mode) && inode2 != inode1)		inode_lock_nested(inode2, I_MUTEX_NONDIR2);}",24611
43,126,CVE-2017-6903,9,"void Com_InitJournaling( void ) {	Com_StartupVariable( ""journal"" );	com_journal = Cvar_Get( ""journal"", ""0"", CVAR_INIT );	if ( !com_journal->integer ) {		return;	}	if ( com_journal->integer == 1 ) {		Com_Printf( ""Journaling events\n"" );		com_journalFile = FS_FOpenFileWrite( ""journal.dat"" );		com_journalDataFile = FS_FOpenFileWrite( ""journaldata.dat"" );	} else if ( com_journal->integer == 2 ) {		Com_Printf( ""Replaying journaled events\n"" );		FS_FOpenFileRead( ""journal.dat"", &com_journalFile, qtrue );		FS_FOpenFileRead( ""journaldata.dat"", &com_journalDataFile, qtrue );	}	if ( !com_journalFile || !com_journalDataFile ) {		Cvar_Set( ""com_journal"", ""0"" );		com_journalFile = 0;		com_journalDataFile = 0;		Com_Printf( ""Couldn't open journal files\n"" );	}}",28646
66,295,CVE-2017-5940,9,"void logmsg(const char *msg) {	if (!arg_debug)		return;	openlog(""firejail"", LOG_NDELAY | LOG_PID, LOG_USER);	syslog(LOG_INFO, ""%s\n"", msg);	closelog();}",28815
27,88,CVE-2017-6903,9,"char *Com_StringContains(char *str1, char *str2, int casesensitive) {	int len, i, j;	len = strlen(str1) - strlen(str2);	for (i = 0; i <= len; i++, str1++) {		for (j = 0; str2[j]; j++) {			if (casesensitive) {				if (str1[j] != str2[j]) {					break;				}			}			else {				if (toupper(str1[j]) != toupper(str2[j])) {					break;				}			}		}		if (!str2[j]) {			return str1;		}	}	return NULL;}",28608
38,291,CVE-2017-5940,9,"const char *gnu_basename(const char *path) {	const char *last_slash = strrchr(path, '/');	if (!last_slash)		return path;	return last_slash+1;}",28811
65,69,CVE-2017-6903,9,"void Con_Shutdown(void){	Cmd_RemoveCommand(""toggleconsole"");	Cmd_RemoveCommand(""togglemenu"");	Cmd_RemoveCommand(""messagemode"");	Cmd_RemoveCommand(""messagemode2"");	Cmd_RemoveCommand(""messagemode3"");	Cmd_RemoveCommand(""messagemode4"");	Cmd_RemoveCommand(""clear"");	Cmd_RemoveCommand(""condump"");}",28589
0,26,CVE-2018-13405,9,int dentry_needs_remove_privs(struct dentry *dentry){	struct inode *inode = d_inode(dentry);	int mask = 0;	int ret;	if (IS_NOSEC(inode))		return 0;	mask = should_remove_suid(dentry);	ret = security_inode_need_killpriv(dentry);	if (ret < 0)		return ret;	if (ret)		mask |= ATTR_KILL_PRIV;	return mask;},24591
33,9,CVE-2017-15906,9,"handle_to_name(int handle){	if (handle_is_ok(handle, HANDLE_DIR)||	    handle_is_ok(handle, HANDLE_FILE))		return handles[handle].name;	return NULL;}",19949
74,51,CVE-2018-13405,9,"static int relatime_need_update(const struct path *path, struct inode *inode,				struct timespec now, int rcu){	if (!(path->mnt->mnt_flags & MNT_RELATIME))		return 1;	update_ovl_inode_times(path->dentry, inode, rcu);	 	if (timespec64_compare(&inode->i_mtime, &inode->i_atime) >= 0)		return 1;	 	if (timespec64_compare(&inode->i_ctime, &inode->i_atime) >= 0)		return 1;	 	if ((long)(now.tv_sec - inode->i_atime.tv_sec) >= 24*60*60)		return 1;	 	return 0;}",24616
55,174,CVE-2017-6903,9,"void CL_SendPureChecksums( void ) {	char cMsg[MAX_INFO_VALUE];	Com_sprintf(cMsg, sizeof(cMsg), ""cp %d %s"", cl.serverId, FS_ReferencedPakPureChecksums());	CL_AddReliableCommand(cMsg, qfalse);}",28694
26,302,CVE-2017-5940,9,"char *split_comma(char *str) {	EUID_ASSERT();	if (str == NULL || *str == '\0')		return NULL;	char *ptr = strchr(str, ',');	if (!ptr)		return NULL;	*ptr = '\0';	ptr++;	if (*ptr == '\0')		return NULL;	return ptr;}",28822
47,161,CVE-2017-6903,9,"static void CL_OldGame(void){	if(cl_oldGameSet)	{		cl_oldGameSet = qfalse;		Cvar_Set2(""fs_game"", cl_oldGame, qtrue);		FS_ConditionalRestart(clc.checksumFeed, qfalse);	}}",28681
56,164,CVE-2017-6903,9,"void CL_Reconnect_f( void ) {	if ( !strlen( cl_reconnectArgs ) )		return;	Cvar_Set(""ui_singlePlayerActive"", ""0"");	Cbuf_AddText( va(""connect %s\n"", cl_reconnectArgs ) );}",28684
64,210,CVE-2017-6903,9,"void FS_Remove( const char *osPath ) {	FS_CheckFilenameIsMutable( osPath, __func__ );	remove( osPath );}",28730
72,223,CVE-2017-6903,9,void Sys_In_Restart_f( void ){	IN_Restart( );},28743
49,42,CVE-2018-13405,9,static inline void inode_sb_list_del(struct inode *inode){	if (!list_empty(&inode->i_sb_list)) {		spin_lock(&inode->i_sb->s_inode_list_lock);		list_del_init(&inode->i_sb_list);		spin_unlock(&inode->i_sb->s_inode_list_lock);	}},24607
48,103,CVE-2017-6903,9,void S_AL_SrcShutup( void ){	int i;	for(i = 0; i < srcCount; i++)		S_AL_SrcKill(i);},28623
71,156,CVE-2017-6903,9,"void CL_ForwardToServer_f( void ) {	if ( clc.state != CA_ACTIVE || clc.demoplaying ) {		Com_Printf( ""Not connected to a server.\n"" );		return;	}	if ( Cmd_Argc() > 1 ) {		CL_AddReliableCommand(Cmd_Args(), qfalse);	}}",28676
54,122,CVE-2017-6903,9,void Com_EndRedirect( void ) {	if ( rd_flush ) {		rd_flush( rd_buffer );	}	rd_buffer = NULL;	rd_buffersize = 0;	rd_flush = NULL;},28642
24,107,CVE-2017-6903,9,void S_AL_StopCapture( void ){	if (alCaptureDevice != NULL)		qalcCaptureStop(alCaptureDevice);},28627
11,132,CVE-2017-6903,9,"void Com_Quit_f( void ) {	char *p = Cmd_Args( );	if ( !com_errorEntered ) {		VM_Forced_Unload_Start();		SV_Shutdown(p[0] ? p : ""Server quit"");		CL_Shutdown(p[0] ? p : ""Client quit"", qtrue, qtrue);		VM_Forced_Unload_Done();		Com_Shutdown();		FS_Shutdown( qtrue );	}	Sys_Quit();}",28652
20,287,CVE-2017-6903,9,"void FS_SortFileList(char **filelist, int numfiles) {	int i, j, k, numsortedfiles;	char **sortedlist;	sortedlist = Z_Malloc( ( numfiles + 1 ) * sizeof( *sortedlist ) );	sortedlist[0] = NULL;	numsortedfiles = 0;	for (i = 0; i < numfiles; i++) {		for (j = 0; j < numsortedfiles; j++) {			if (FS_PathCmp(filelist[i], sortedlist[j]) < 0) {				break;			}		}		for (k = numsortedfiles; k > j; k--) {			sortedlist[k] = sortedlist[k-1];		}		sortedlist[j] = filelist[i];		numsortedfiles++;	}	Com_Memcpy(filelist, sortedlist, numfiles * sizeof( *filelist ) );	Z_Free(sortedlist);}",28807
53,175,CVE-2017-6903,9,void CL_SetRecommended_f( void ) {	Com_SetRecommended();},28695
68,63,CVE-2017-6903,9,void Con_MessageMode2_f (void) {	chat_playerNum = -1;	chat_team = qtrue;	Field_Clear( &chatField );	chatField.widthInChars = 25;	Key_SetCatcher( Key_GetCatcher( ) ^ KEYCATCH_MESSAGE );},28583
13,217,CVE-2017-6903,9,"static char** Sys_ConcatenateFileLists( char **list0, char **list1 ){	int totalLength = 0;	char** cat = NULL, **dst, **src;	totalLength += Sys_CountFileList(list0);	totalLength += Sys_CountFileList(list1);	 	dst = cat = Z_Malloc( ( totalLength + 1 ) * sizeof( char* ) );	 	if (list0)	{		for (src = list0; *src; src++, dst++)			*dst = *src;	}	if (list1)	{		for (src = list1; *src; src++, dst++)			*dst = *src;	}	*dst = NULL;	if (list0) Z_Free( list0 );	if (list1) Z_Free( list1 );	return cat;}",28737
15,133,CVE-2017-6903,9,void Com_Shutdown( void ) {	Com_WriteConfiguration();	if ( logfile ) {		FS_FCloseFile( logfile );		logfile = 0;	}	if ( com_journalFile ) {		FS_FCloseFile( com_journalFile );		com_journalFile = 0;	}	if( pipefile ) {		FS_FCloseFile( pipefile );		FS_HomeRemove( com_pipefile->string );	}},28653
12,299,CVE-2017-5940,9,"void notify_other(int fd) {	FILE* stream;	int newfd = dup(fd);	if (newfd == -1)		errExit(""dup"");	stream = fdopen(newfd, ""w"");	fprintf(stream, ""arg_noroot=%d\n"", arg_noroot);	fflush(stream);	fclose(stream);}",28819
18,93,CVE-2017-6903,9,void S_AL_BeginRegistration( void ){	if(!numSfx)		S_AL_BufferInit();},28613
5,20,CVE-2018-13405,9,"int __atime_needs_update(const struct path *path, struct inode *inode,			  int rcu){	struct vfsmount *mnt = path->mnt;	struct timespec64 now;	if (inode->i_flags & S_NOATIME)		return false;	 	if (HAS_UNMAPPED_ID(inode))		return false;	if (IS_NOATIME(inode))		return false;	if ((inode->i_sb->s_flags & SB_NODIRATIME) && S_ISDIR(inode->i_mode))		return false;	if (mnt->mnt_flags & MNT_NOATIME)		return false;	if ((mnt->mnt_flags & MNT_NODIRATIME) && S_ISDIR(inode->i_mode))		return false;	now = current_time(inode);	if (!relatime_need_update(path, inode, timespec64_to_timespec(now), rcu))		return false;	if (timespec64_equal(&inode->i_atime, &now))		return false;	return true;}",24585
39,86,CVE-2017-6903,9,void Com_Shutdown (void) {	if (logfile) {		FS_FCloseFile (logfile);		logfile = 0;	}	if ( com_journalFile ) {		FS_FCloseFile( com_journalFile );		com_journalFile = 0;	}	if( pipefile ) {		FS_FCloseFile( pipefile );		FS_HomeRemove( com_pipefile->string );	}},28606
40,219,CVE-2017-6903,9,char *Sys_BinaryPath(void){	return binaryPath;},28739
46,192,CVE-2017-6903,9,"void FS_FreeFile( void *buffer ) {	if ( !fs_searchpaths ) {		Com_Error( ERR_FATAL, ""Filesystem call made without initialization"" );	}	if ( !buffer ) {		Com_Error( ERR_FATAL, ""FS_FreeFile( NULL )"" );	}	fs_loadStack--;	Hunk_FreeTempMemory( buffer );	if ( fs_loadStack == 0 ) {		Hunk_ClearTempMemory();	}}",28712
16,83,CVE-2017-6903,9,"int Com_ModifyMsec( int msec ) {	int		clampTime;	if ( com_fixedtime->integer ) {		msec = com_fixedtime->integer;	} else if ( com_timescale->value ) {		msec *= com_timescale->value;	} else if (com_cameraMode->integer) {		msec *= com_timescale->value;	}		if ( msec < 1 && com_timescale->value) {		msec = 1;	}	if ( com_dedicated->integer ) {		if (com_sv_running->integer && msec > 500)			Com_Printf( ""Hitch warning: %i msec frame time\n"", msec );		clampTime = 5000;	} else 	if ( !com_sv_running->integer ) {		clampTime = 5000;	} else {		clampTime = 200;	}	if ( msec > clampTime ) {		msec = clampTime;	}	return msec;}",28603
63,204,CVE-2017-6903,9,"void FS_PureServerSetLoadedPaks( const char *pakSums, const char *pakNames ) {	int i, c, d;	Cmd_TokenizeString( pakSums );	c = Cmd_Argc();	if ( c > MAX_SEARCH_PATHS ) {		c = MAX_SEARCH_PATHS;	}	fs_numServerPaks = c;	for ( i = 0 ; i < c ; i++ ) {		fs_serverPaks[i] = atoi( Cmd_Argv( i ) );	}	if ( fs_numServerPaks ) {		Com_DPrintf( ""Connected to a pure server.\n"" );	} else	{		if ( fs_reordered ) {			Com_DPrintf( ""FS search reorder is required\n"" );			FS_Restart( fs_checksumFeed );			return;		}	}	for ( i = 0 ; i < c ; i++ ) {		if ( fs_serverPakNames[i] ) {			Z_Free( fs_serverPakNames[i] );		}		fs_serverPakNames[i] = NULL;	}	if ( pakNames && *pakNames ) {		Cmd_TokenizeString( pakNames );		d = Cmd_Argc();		if ( d > MAX_SEARCH_PATHS ) {			d = MAX_SEARCH_PATHS;		}		for ( i = 0 ; i < d ; i++ ) {			fs_serverPakNames[i] = CopyString( Cmd_Argv( i ) );		}	}}",28724
14,25,CVE-2018-13405,9,"struct timespec64 current_time(struct inode *inode){	struct timespec64 now = current_kernel_time64();	if (unlikely(!inode->i_sb)) {		WARN(1, ""current_time() called with uninitialized super_block in the inode"");		return now;	}	return timespec64_trunc(now, inode->i_sb->s_time_gran);}",24590
28,100,CVE-2017-6903,9,static void S_AL_MusicSourceFree( void ){	S_AL_SrcUnlock(musicSourceHandle);	S_AL_SrcKill(musicSourceHandle);	musicSource = 0;	musicSourceHandle = -1;},28620
60,139,CVE-2017-6903,9,int S_AL_GetVoiceAmplitude( int entityNum ) {	return 0;},28659
51,282,CVE-2017-6903,9,"const char *FS_ReferencedPakChecksums( void ) {	static char	info[BIG_INFO_STRING];	searchpath_t *search;	info[0] = 0;	for ( search = fs_searchpaths ; search ; search = search->next ) {		if ( search->pack ) {			if (search->pack->referenced || Q_stricmpn(search->pack->pakGamename, com_basegame->string, strlen(com_basegame->string))) {				Q_strcat( info, sizeof( info ), va(""%i "", search->pack->checksum ) );			}		}	}	return info;}",28802
61,276,CVE-2017-6903,9,"const char *FS_LoadedPakNames( void ) {	static char	info[BIG_INFO_STRING];	searchpath_t	*search;	info[0] = 0;	for ( search = fs_searchpaths ; search ; search = search->next ) {		if ( !search->pack ) {			continue;		}		if (*info) {			Q_strcat(info, sizeof( info ), "" "" );		}		Q_strcat( info, sizeof( info ), search->pack->pakBasename );	}	return info;}",28796
36,80,CVE-2017-6903,9,"void Com_InitPushEvent( void ) {  memset( com_pushedEvents, 0, sizeof(com_pushedEvents) );  com_pushedEventsHead = 0;  com_pushedEventsTail = 0;}",28600
76,91,CVE-2017-6903,9,static char *Field_FindFirstSeparator( char *s ){	int i;	for( i = 0; i < strlen( s ); i++ )	{		if( s[ i ] == ';' )			return &s[ i ];	}	return NULL;},28611
73,60,CVE-2017-6903,9,"void Con_DrawInput (void) {	int		y;	if ( clc.state != CA_DISCONNECTED && !(Key_GetCatcher( ) & KEYCATCH_CONSOLE ) ) {		return;	}	y = con.vislines - ( SMALLCHAR_HEIGHT * 2 );	re.SetColor( con.color );	SCR_DrawSmallChar( con.xadjust + 1 * SMALLCHAR_WIDTH, y, ']' );	Field_Draw( &g_consoleField, con.xadjust + 2 * SMALLCHAR_WIDTH, y,		SCREEN_WIDTH - 3 * SMALLCHAR_WIDTH, qtrue, qtrue );}",28580
70,270,CVE-2017-6903,9,void FS_ConvertPath( char *s ) {	while (*s) {		if ( *s == '\\' || *s == ':' ) {			*s = '/';		}		s++;	}},28790
62,141,CVE-2017-6903,9,"static void CL_Cache_EndGather_f( void ) {	int i, j, handle, cachePass;	char filename[MAX_QPATH];	cachePass = (int)floor( (float)cacheIndex * CACHE_HIT_RATIO );	for ( i = 0; i < CACHE_NUMGROUPS; i++ ) {		Q_strncpyz( filename, cacheGroups[i].name, MAX_QPATH );		Q_strcat( filename, MAX_QPATH, "".cache"" );		handle = FS_FOpenFileWrite( filename );		for ( j = 0; j < MAX_CACHE_ITEMS; j++ ) {			if ( cacheItems[i][j].hits >= cachePass && strstr( cacheItems[i][j].name, ""/"" ) ) {				FS_Write( cacheItems[i][j].name, strlen( cacheItems[i][j].name ), handle );				FS_Write( ""\n"", 1, handle );			}		}		FS_FCloseFile( handle );	}	Cvar_Set( ""cl_cacheGathering"", ""0"" );}",28661
30,45,CVE-2018-13405,9,"static void iput_final(struct inode *inode){	struct super_block *sb = inode->i_sb;	const struct super_operations *op = inode->i_sb->s_op;	int drop;	WARN_ON(inode->i_state & I_NEW);	if (op->drop_inode)		drop = op->drop_inode(inode);	else		drop = generic_drop_inode(inode);	if (!drop && (sb->s_flags & SB_ACTIVE)) {		inode_add_lru(inode);		spin_unlock(&inode->i_lock);		return;	}	if (!drop) {		inode->i_state |= I_WILL_FREE;		spin_unlock(&inode->i_lock);		write_inode_now(inode, 1);		spin_lock(&inode->i_lock);		WARN_ON(inode->i_state & I_NEW);		inode->i_state &= ~I_WILL_FREE;	}	inode->i_state |= I_FREEING;	if (!list_empty(&inode->i_lru))		inode_lru_list_del(inode);	spin_unlock(&inode->i_lock);	evict(inode);}",24610
45,142,CVE-2017-6903,9,static void CL_Cache_MapChange_f( void ) {	cacheIndex++;},28662
2,191,CVE-2017-6903,9,"int FS_FileIsInPAK( const char *filename, int *pChecksum ) {	searchpath_t    *search;	pack_t          *pak;	fileInPack_t    *pakFile;	long hash = 0;	if ( !fs_searchpaths ) {		Com_Error( ERR_FATAL, ""Filesystem call made without initialization"" );	}	if ( !filename ) {		Com_Error( ERR_FATAL, ""FS_FOpenFileRead: NULL 'filename' parameter passed"" );	}	if ( filename[0] == '/' || filename[0] == '\\' ) {		filename++;	}	if ( strstr( filename, "".."" ) || strstr( filename, ""::"" ) ) {		return -1;	}	for ( search = fs_searchpaths ; search ; search = search->next ) {		if ( search->pack ) {			hash = FS_HashFileName( filename, search->pack->hashSize );		}		if ( search->pack && search->pack->hashTable[hash] ) {			if ( !FS_PakIsPure( search->pack ) ) {				continue;			}			pak = search->pack;			pakFile = pak->hashTable[hash];			do {				if ( !FS_FilenameCompare( pakFile->name, filename ) ) {					if ( pChecksum ) {						*pChecksum = pak->pure_checksum;					}					return 1;				}				pakFile = pakFile->next;			} while ( pakFile != NULL );		}	}	return -1;}",28711
31,77,CVE-2017-9059,10,"dump_sessionid(const char *fn, struct nfs4_sessionid *sessionid){}",20963
56,175,CVE-2017-9059,10,"static int nfsd4_session_too_many_ops(struct svc_rqst *rqstp, struct nfsd4_session *session){	struct nfsd4_compoundargs *args = rqstp->rq_argp;	return args->opcnt > session->se_fchannel.maxops;}",21061
37,155,CVE-2017-9059,10,"nfsd4_get_delegreturnstateid(struct nfsd4_compound_state *cstate, struct nfsd4_delegreturn *drp){	get_stateid(cstate, &drp->dr_stateid);}",21041
59,164,CVE-2017-9059,10,"nfsd4_init_slabs(void){	openowner_slab = kmem_cache_create(""nfsd4_openowners"",			sizeof(struct nfs4_openowner), 0, 0, NULL);	if (openowner_slab == NULL)		goto out;	lockowner_slab = kmem_cache_create(""nfsd4_lockowners"",			sizeof(struct nfs4_lockowner), 0, 0, NULL);	if (lockowner_slab == NULL)		goto out_free_openowner_slab;	file_slab = kmem_cache_create(""nfsd4_files"",			sizeof(struct nfs4_file), 0, 0, NULL);	if (file_slab == NULL)		goto out_free_lockowner_slab;	stateid_slab = kmem_cache_create(""nfsd4_stateids"",			sizeof(struct nfs4_ol_stateid), 0, 0, NULL);	if (stateid_slab == NULL)		goto out_free_file_slab;	deleg_slab = kmem_cache_create(""nfsd4_delegations"",			sizeof(struct nfs4_delegation), 0, 0, NULL);	if (deleg_slab == NULL)		goto out_free_stateid_slab;	odstate_slab = kmem_cache_create(""nfsd4_odstate"",			sizeof(struct nfs4_clnt_odstate), 0, 0, NULL);	if (odstate_slab == NULL)		goto out_free_deleg_slab;	return 0;out_free_deleg_slab:	kmem_cache_destroy(deleg_slab);out_free_stateid_slab:	kmem_cache_destroy(stateid_slab);out_free_file_slab:	kmem_cache_destroy(file_slab);out_free_lockowner_slab:	kmem_cache_destroy(lockowner_slab);out_free_openowner_slab:	kmem_cache_destroy(openowner_slab);out:	dprintk(""nfsd4: out of memory while initializing nfsv4\n"");	return -ENOMEM;}",21050
80,91,CVE-2017-9059,10,find_writeable_file(struct nfs4_file *f){	struct file *ret;	spin_lock(&f->fi_lock);	ret = find_writeable_file_locked(f);	spin_unlock(&f->fi_lock);	return ret;},20977
41,219,CVE-2017-9059,10,"nfsd4_decode_create(struct nfsd4_compoundargs *argp, struct nfsd4_create *create){	DECODE_HEAD;	READ_BUF(4);	create->cr_type = be32_to_cpup(p++);	switch (create->cr_type) {	case NF4LNK:		READ_BUF(4);		create->cr_datalen = be32_to_cpup(p++);		READ_BUF(create->cr_datalen);		create->cr_data = svcxdr_dupstr(argp, p, create->cr_datalen);		if (!create->cr_data)			return nfserr_jukebox;		break;	case NF4BLK:	case NF4CHR:		READ_BUF(8);		create->cr_specdata1 = be32_to_cpup(p++);		create->cr_specdata2 = be32_to_cpup(p++);		break;	case NF4SOCK:	case NF4FIFO:	case NF4DIR:	default:		break;	}	READ_BUF(4);	create->cr_namelen = be32_to_cpup(p++);	READ_BUF(create->cr_namelen);	SAVEMEM(create->cr_name, create->cr_namelen);	if ((status = check_filename(create->cr_name, create->cr_namelen)))		return status;	status = nfsd4_decode_fattr(argp, create->cr_bmval, &create->cr_iattr,				    &create->cr_acl, &create->cr_label,				    &current->fs->umask);	if (status)		goto out;	DECODE_TAIL;}",21105
1,311,CVE-2017-9059,10,"static void svc_rdma_bc_detach(struct svc_xprt *xprt){	dprintk(""svcrdma: %s(%p)\n"", __func__, xprt);}",21197
10,304,CVE-2017-9059,10,"static void rdma_read_complete(struct svc_rqst *rqstp,			       struct svc_rdma_op_ctxt *head){	int page_no;	 	for (page_no = 0; page_no < head->count; page_no++) {		put_page(rqstp->rq_pages[page_no]);		rqstp->rq_pages[page_no] = head->pages[page_no];	}	 	if (head->position == 0) {		if (head->arg.len <= head->sge[0].length) {			head->arg.head[0].iov_len = head->arg.len -							head->byte_len;			head->arg.page_len = 0;		} else {			head->arg.head[0].iov_len = head->sge[0].length -								head->byte_len;			head->arg.page_len = head->arg.len -						head->sge[0].length;		}	}	 	rqstp->rq_arg.pages = &rqstp->rq_pages[head->hdr_count];	rqstp->rq_arg.page_len = head->arg.page_len;	rqstp->rq_arg.page_base = head->arg.page_base;	 	rqstp->rq_respages = &rqstp->rq_pages[page_no];	rqstp->rq_next_page = rqstp->rq_respages + 1;	 	rqstp->rq_arg.head[0] = head->arg.head[0];	rqstp->rq_arg.tail[0] = head->arg.tail[0];	rqstp->rq_arg.len = head->arg.len; 	rqstp->rq_arg.buflen = head->arg.buflen; }",21190
23,212,CVE-2017-9059,10,"nfsd42_encode_write_res(struct nfsd4_compoundres *resp, struct nfsd42_write_res *write){	__be32 *p;	p = xdr_reserve_space(&resp->xdr, 4 + 8 + 4 + NFS4_VERIFIER_SIZE);	if (!p)		return nfserr_resource;	*p++ = cpu_to_be32(0);	p = xdr_encode_hyper(p, write->wr_bytes_written);	*p++ = cpu_to_be32(write->wr_stable_how);	p = xdr_encode_opaque_fixed(p, write->wr_verifier.data,				    NFS4_VERIFIER_SIZE);	return nfs_ok;}",21098
12,191,CVE-2017-9059,10,"static void put_ol_stateid_locked(struct nfs4_ol_stateid *stp,				       struct list_head *reaplist){	struct nfs4_stid *s = &stp->st_stid;	struct nfs4_client *clp = s->sc_client;	lockdep_assert_held(&clp->cl_lock);	WARN_ON_ONCE(!list_empty(&stp->st_locks));	if (!atomic_dec_and_test(&s->sc_count)) {		wake_up_all(&close_wq);		return;	}	idr_remove(&clp->cl_stateids, s->sc_stateid.si_opaque.so_id);	list_add(&stp->st_locks, reaplist);}",21077
50,161,CVE-2017-9059,10,"nfsd4_get_writestateid(struct nfsd4_compound_state *cstate, struct nfsd4_write *write){	get_stateid(cstate, &write->wr_stateid);}",21047
8,145,CVE-2017-9059,10,"void nfsd4_cleanup_open_state(struct nfsd4_compound_state *cstate,			      struct nfsd4_open *open){	if (open->op_openowner) {		struct nfs4_stateowner *so = &open->op_openowner->oo_owner;		nfsd4_cstate_assign_replay(cstate, so);		nfs4_put_stateowner(so);	}	if (open->op_file)		kmem_cache_free(file_slab, open->op_file);	if (open->op_stp)		nfs4_put_stid(&open->op_stp->st_stid);	if (open->op_odstate)		kmem_cache_free(odstate_slab, open->op_odstate);}",21031
3,79,CVE-2017-9059,10,static unsigned int file_hashval(struct knfsd_fh *fh){	return nfsd_fh_hashval(fh) & (FILE_HASH_SIZE - 1);},20965
18,99,CVE-2017-9059,10,"grace_disallows_io(struct net *net, struct inode *inode){	return opens_in_grace(net) && mandatory_lock(inode);}",20985
79,222,CVE-2017-9059,10,"nfsd4_decode_exchange_id(struct nfsd4_compoundargs *argp,			 struct nfsd4_exchange_id *exid){	int dummy, tmp;	DECODE_HEAD;	READ_BUF(NFS4_VERIFIER_SIZE);	COPYMEM(exid->verifier.data, NFS4_VERIFIER_SIZE);	status = nfsd4_decode_opaque(argp, &exid->clname);	if (status)		return nfserr_bad_xdr;	READ_BUF(4);	exid->flags = be32_to_cpup(p++);	 	READ_BUF(4);	exid->spa_how = be32_to_cpup(p++);	switch (exid->spa_how) {	case SP4_NONE:		break;	case SP4_MACH_CRED:		 		status = nfsd4_decode_bitmap(argp,					exid->spo_must_enforce);		if (status)			goto out;		 		status = nfsd4_decode_bitmap(argp, exid->spo_must_allow);		if (status)			goto out;		break;	case SP4_SSV:		 		READ_BUF(4);		dummy = be32_to_cpup(p++);		READ_BUF(dummy * 4);		p += dummy;		READ_BUF(4);		dummy = be32_to_cpup(p++);		READ_BUF(dummy * 4);		p += dummy;		 		READ_BUF(4);		tmp = be32_to_cpup(p++);		while (tmp--) {			READ_BUF(4);			dummy = be32_to_cpup(p++);			READ_BUF(dummy);			p += XDR_QUADLEN(dummy);		}		 		READ_BUF(4);		tmp = be32_to_cpup(p++);		while (tmp--) {			READ_BUF(4);			dummy = be32_to_cpup(p++);			READ_BUF(dummy);			p += XDR_QUADLEN(dummy);		}		 		READ_BUF(8);		dummy = be32_to_cpup(p++);		dummy = be32_to_cpup(p++);		break;	default:		goto xdr_error;	}	 	READ_BUF(4);     	dummy = be32_to_cpup(p++);	if (dummy > 1)		goto xdr_error;	if (dummy == 1) {		 		READ_BUF(4);		dummy = be32_to_cpup(p++);		READ_BUF(dummy);		p += XDR_QUADLEN(dummy);		 		READ_BUF(4);		dummy = be32_to_cpup(p++);		READ_BUF(dummy);		p += XDR_QUADLEN(dummy);		 		READ_BUF(12);		p += 3;	}	DECODE_TAIL;}",21108
7,202,CVE-2017-9059,10,unhash_delegation_locked(struct nfs4_delegation *dp){	struct nfs4_file *fp = dp->dl_stid.sc_file;	lockdep_assert_held(&state_lock);	if (list_empty(&dp->dl_perfile))		return false;	dp->dl_stid.sc_type = NFS4_CLOSED_DELEG_STID;	 	++dp->dl_time;	spin_lock(&fp->fi_lock);	list_del_init(&dp->dl_perclnt);	list_del_init(&dp->dl_recall_lru);	list_del_init(&dp->dl_perfile);	spin_unlock(&fp->fi_lock);	return true;},21088
17,83,CVE-2017-9059,10,"find_lockowner_str(struct nfs4_client *clp, struct xdr_netobj *owner){	struct nfs4_lockowner *lo;	spin_lock(&clp->cl_lock);	lo = find_lockowner_str_locked(clp, owner);	spin_unlock(&clp->cl_lock);	return lo;}",20969
64,139,CVE-2017-9059,10,"static struct nfs4_file *nfsd4_alloc_file(void){	return kmem_cache_alloc(file_slab, GFP_KERNEL);}",21025
4,116,CVE-2017-9059,10,"nfs4_client_to_reclaim(const char *name, struct nfsd_net *nn){	unsigned int strhashval;	struct nfs4_client_reclaim *crp;	dprintk(""NFSD nfs4_client_to_reclaim NAME: %.*s\n"", HEXDIR_LEN, name);	crp = alloc_reclaim();	if (crp) {		strhashval = clientstr_hashval(name);		INIT_LIST_HEAD(&crp->cr_strhash);		list_add(&crp->cr_strhash, &nn->reclaim_str_hashtbl[strhashval]);		memcpy(crp->cr_recdir, name, HEXDIR_LEN);		crp->cr_clp = NULL;		nn->reclaim_str_hashtbl_size++;	}	return crp;}",21002
35,57,CVE-2017-9059,10,"static void __nfs4_file_put_access(struct nfs4_file *fp, int oflag){	might_lock(&fp->fi_lock);	if (atomic_dec_and_lock(&fp->fi_access[oflag], &fp->fi_lock)) {		struct file *f1 = NULL;		struct file *f2 = NULL;		swap(f1, fp->fi_fds[oflag]);		if (atomic_read(&fp->fi_access[1 - oflag]) == 0)			swap(f2, fp->fi_fds[O_RDWR]);		spin_unlock(&fp->fi_lock);		if (f1)			fput(f1);		if (f2)			fput(f2);	}}",20943
21,168,CVE-2017-9059,10,static void nfsd4_put_drc_mem(struct nfsd4_channel_attrs *ca){	int slotsize = slot_bytes(ca);	spin_lock(&nfsd_drc_lock);	nfsd_drc_mem_used -= slotsize * ca->maxreqs;	spin_unlock(&nfsd_drc_lock);},21054
53,261,CVE-2017-9059,10,nfsd_check_ignore_resizing(struct iattr *iap){	if ((iap->ia_valid & ATTR_SIZE) && (iap->ia_size == 0))		iap->ia_valid &= ~ATTR_SIZE;},21147
74,270,CVE-2017-9059,10,"nfsd_sanitize_attrs(struct inode *inode, struct iattr *iap){	 	if (iap->ia_valid & ATTR_MODE) {		iap->ia_mode &= S_IALLUGO;		iap->ia_mode |= (inode->i_mode & ~S_IALLUGO);	}	 	if (!S_ISDIR(inode->i_mode) &&	    ((iap->ia_valid & ATTR_UID) || (iap->ia_valid & ATTR_GID))) {		iap->ia_valid |= ATTR_KILL_PRIV;		if (iap->ia_valid & ATTR_MODE) {			 			iap->ia_mode &= ~S_ISUID;			if (iap->ia_mode & S_IXGRP)				iap->ia_mode &= ~S_ISGID;		} else {			 			iap->ia_valid |= (ATTR_KILL_SUID | ATTR_KILL_SGID);		}	}}",21156
9,13,CVE-2017-9059,10,"int lockd_up(struct net *net){	struct svc_serv *serv;	int error;	mutex_lock(&nlmsvc_mutex);	serv = lockd_create_svc();	if (IS_ERR(serv)) {		error = PTR_ERR(serv);		goto err_create;	}	error = lockd_up_net(serv, net);	if (error < 0)		goto err_net;	error = lockd_start_svc(serv);	if (error < 0)		goto err_start;	nlmsvc_users++;	 err_put:	svc_destroy(serv);err_create:	mutex_unlock(&nlmsvc_mutex);	return error;err_start:	lockd_down_net(serv, net);err_net:	lockd_unregister_notifiers();	goto err_put;}",20899
29,291,CVE-2017-9059,10,"svc_prepare_thread(struct svc_serv *serv, struct svc_pool *pool, int node){	struct svc_rqst	*rqstp;	rqstp = svc_rqst_alloc(serv, pool, node);	if (!rqstp)		return ERR_PTR(-ENOMEM);	serv->sv_nrthreads++;	spin_lock_bh(&pool->sp_lock);	pool->sp_nrthreads++;	list_add_rcu(&rqstp->rq_all, &pool->sp_all_threads);	spin_unlock_bh(&pool->sp_lock);	return rqstp;}",21177
52,42,CVE-2017-9059,10,"nfsd4_allocate(struct svc_rqst *rqstp, struct nfsd4_compound_state *cstate,	       struct nfsd4_fallocate *fallocate){	return nfsd4_fallocate(rqstp, cstate, fallocate, 0);}",20928
25,151,CVE-2017-9059,10,"nfsd4_enc_sequence_replay(struct nfsd4_compoundargs *args,			  struct nfsd4_compoundres *resp){	struct nfsd4_op *op;	struct nfsd4_slot *slot = resp->cstate.slot;	 	op = &args->ops[resp->opcnt - 1];	nfsd4_encode_operation(resp, op);	 	if (args->opcnt > 1 && !(slot->sl_flags & NFSD4_SLOT_CACHETHIS)) {		op = &args->ops[resp->opcnt++];		op->status = nfserr_retry_uncached_rep;		nfsd4_encode_operation(resp, op);	}	return op->status;}",21037
44,126,CVE-2017-9059,10,"static void nfs4_put_stateowner(struct nfs4_stateowner *sop){	struct nfs4_client *clp = sop->so_client;	might_lock(&clp->cl_lock);	if (!atomic_dec_and_lock(&sop->so_count, &clp->cl_lock))		return;	sop->so_ops->so_unhash(sop);	spin_unlock(&clp->cl_lock);	nfs4_free_stateowner(sop);}",21012
32,327,CVE-2017-8925,10,"static int omninet_write(struct tty_struct *tty, struct usb_serial_port *port,					const unsigned char *buf, int count){	struct usb_serial *serial = port->serial;	struct usb_serial_port *wport = serial->port[1];	struct omninet_data *od = usb_get_serial_port_data(port);	struct omninet_header *header = (struct omninet_header *)					wport->write_urb->transfer_buffer;	int			result;	if (count == 0) {		dev_dbg(&port->dev, ""%s - write request of 0 bytes\n"", __func__);		return 0;	}	if (!test_and_clear_bit(0, &port->write_urbs_free)) {		dev_dbg(&port->dev, ""%s - already writing\n"", __func__);		return 0;	}	count = (count > OMNINET_PAYLOADSIZE) ? OMNINET_PAYLOADSIZE : count;	memcpy(wport->write_urb->transfer_buffer + OMNINET_HEADERLEN,								buf, count);	usb_serial_debug_data(&port->dev, __func__, count,			      wport->write_urb->transfer_buffer);	header->oh_seq 	= od->od_outseq++;	header->oh_len 	= count;	header->oh_xxx  = 0x03;	header->oh_pad 	= 0x00;	 	wport->write_urb->transfer_buffer_length = OMNINET_BULKOUTSIZE;	result = usb_submit_urb(wport->write_urb, GFP_ATOMIC);	if (result) {		set_bit(0, &wport->write_urbs_free);		dev_err_console(port,			""%s - failed submitting write urb, error %d\n"",			__func__, result);	} else		result = count;	return result;}",21215
6,172,CVE-2017-9059,10,"nfsd4_replay_create_session(struct nfsd4_create_session *cr_ses,			    struct nfsd4_clid_slot *slot){	memcpy(cr_ses, &slot->sl_cr_ses, sizeof(*cr_ses));	return slot->sl_status;}",21058
54,282,CVE-2017-9059,10,"svc_exit_thread(struct svc_rqst *rqstp){	struct svc_serv	*serv = rqstp->rq_server;	struct svc_pool	*pool = rqstp->rq_pool;	spin_lock_bh(&pool->sp_lock);	pool->sp_nrthreads--;	if (!test_and_set_bit(RQ_VICTIM, &rqstp->rq_flags))		list_del_rcu(&rqstp->rq_all);	spin_unlock_bh(&pool->sp_lock);	svc_rqst_free(rqstp);	 	if (serv)		svc_destroy(serv);}",21168
15,217,CVE-2017-9059,10,"nfsd4_decode_compound(struct nfsd4_compoundargs *argp){	DECODE_HEAD;	struct nfsd4_op *op;	int cachethis = false;	int auth_slack= argp->rqstp->rq_auth_slack;	int max_reply = auth_slack + 8;  	int readcount = 0;	int readbytes = 0;	int i;	READ_BUF(4);	argp->taglen = be32_to_cpup(p++);	READ_BUF(argp->taglen);	SAVEMEM(argp->tag, argp->taglen);	READ_BUF(8);	argp->minorversion = be32_to_cpup(p++);	argp->opcnt = be32_to_cpup(p++);	max_reply += 4 + (XDR_QUADLEN(argp->taglen) << 2);	if (argp->taglen > NFSD4_MAX_TAGLEN)		goto xdr_error;	if (argp->opcnt > 100)		goto xdr_error;	if (argp->opcnt > ARRAY_SIZE(argp->iops)) {		argp->ops = kzalloc(argp->opcnt * sizeof(*argp->ops), GFP_KERNEL);		if (!argp->ops) {			argp->ops = argp->iops;			dprintk(""nfsd: couldn't allocate room for COMPOUND\n"");			goto xdr_error;		}	}	if (argp->minorversion > NFSD_SUPPORTED_MINOR_VERSION)		argp->opcnt = 0;	for (i = 0; i < argp->opcnt; i++) {		op = &argp->ops[i];		op->replay = NULL;		READ_BUF(4);		op->opnum = be32_to_cpup(p++);		if (nfsd4_opnum_in_range(argp, op))			op->status = nfsd4_dec_ops[op->opnum](argp, &op->u);		else {			op->opnum = OP_ILLEGAL;			op->status = nfserr_op_illegal;		}		 		cachethis |= nfsd4_cache_this_op(op);		if (op->opnum == OP_READ) {			readcount++;			readbytes += nfsd4_max_reply(argp->rqstp, op);		} else			max_reply += nfsd4_max_reply(argp->rqstp, op);		 		if (op->opnum == OP_LOCK || op->opnum == OP_LOCKT)			max_reply += NFS4_OPAQUE_LIMIT;		if (op->status) {			argp->opcnt = i+1;			break;		}	}	 	if (argp->minorversion)		cachethis = false;	svc_reserve(argp->rqstp, max_reply + readbytes);	argp->rqstp->rq_cachetype = cachethis ? RC_REPLBUFF : RC_NOCACHE;	if (readcount > 1 || max_reply > PAGE_SIZE - auth_slack)		clear_bit(RQ_SPLICE_OK, &argp->rqstp->rq_flags);	DECODE_TAIL;}",21103
34,166,CVE-2017-9059,10,"int nfsd4_mach_creds_match(struct nfs4_client *cl, struct svc_rqst *rqstp){	struct svc_cred *cr = &rqstp->rq_cred;	if (!cl->cl_mach_cred)		return true;	if (cl->cl_cred.cr_gss_mech != cr->cr_gss_mech)		return false;	if (!svc_rqst_integrity_protected(rqstp))		return false;	if (cl->cl_cred.cr_raw_principal)		return 0 == strcmp(cl->cl_cred.cr_raw_principal,						cr->cr_raw_principal);	if (!cr->cr_principal)		return false;	return 0 == strcmp(cl->cl_cred.cr_principal, cr->cr_principal);}",21052
22,147,CVE-2017-9059,10,"static int nfsd4_compound_in_session(struct nfsd4_session *session, struct nfs4_sessionid *sid){	if (!session)		return 0;	return !memcmp(sid, &session->se_sessionid, sizeof(*sid));}",21033
49,192,CVE-2017-9059,10,"release_all_access(struct nfs4_ol_stateid *stp){	int i;	struct nfs4_file *fp = stp->st_stid.sc_file;	if (fp && stp->st_deny_bmap != 0)		recalculate_deny_mode(fp);	for (i = 1; i < 4; i++) {		if (test_access(i, stp))			nfs4_file_put_access(stp->st_stid.sc_file, i);		clear_access(i, stp);	}}",21078
83,236,CVE-2017-9059,10,"nfsd4_decode_open_downgrade(struct nfsd4_compoundargs *argp, struct nfsd4_open_downgrade *open_down){	DECODE_HEAD;		    	status = nfsd4_decode_stateid(argp, &open_down->od_stateid);	if (status)		return status;	READ_BUF(4);	open_down->od_seqid = be32_to_cpup(p++);	status = nfsd4_decode_share_access(argp, &open_down->od_share_access,					   &open_down->od_deleg_want, NULL);	if (status)		return status;	status = nfsd4_decode_share_deny(argp, &open_down->od_share_deny);	if (status)		return status;	DECODE_TAIL;}",21122
19,255,CVE-2017-9059,10,"nfsd4_encode_security_label(struct xdr_stream *xdr, struct svc_rqst *rqstp,			    void *context, int len){ return 0; }",21141
72,63,CVE-2017-9059,10,"alloc_clnt_odstate(struct nfs4_client *clp){	struct nfs4_clnt_odstate *co;	co = kmem_cache_zalloc(odstate_slab, GFP_KERNEL);	if (co) {		co->co_client = clp;		atomic_set(&co->co_odcount, 1);	}	return co;}",20949
43,298,CVE-2017-9059,10,"static void svc_unregister(const struct svc_serv *serv, struct net *net){	struct svc_program *progp;	unsigned long flags;	unsigned int i;	clear_thread_flag(TIF_SIGPENDING);	for (progp = serv->sv_program; progp; progp = progp->pg_next) {		for (i = 0; i < progp->pg_nvers; i++) {			if (progp->pg_vers[i] == NULL)				continue;			if (progp->pg_vers[i]->vs_hidden)				continue;			dprintk(""svc: attempting to unregister %sv%u\n"",				progp->pg_name, i);			__svc_unregister(net, progp->pg_prog, i, progp->pg_name);		}	}	spin_lock_irqsave(&current->sighand->siglock, flags);	recalc_sigpending();	spin_unlock_irqrestore(&current->sighand->siglock, flags);}",21184
40,86,CVE-2017-9059,10,"find_or_allocate_block(struct nfs4_lockowner *lo, struct knfsd_fh *fh,			struct nfsd_net *nn){	struct nfsd4_blocked_lock *nbl;	nbl = find_blocked_lock(lo, fh, nn);	if (!nbl) {		nbl= kmalloc(sizeof(*nbl), GFP_KERNEL);		if (nbl) {			fh_copy_shallow(&nbl->nbl_fh, fh);			locks_init_lock(&nbl->nbl_lock);			nfsd4_init_cb(&nbl->nbl_cb, lo->lo_owner.so_client,					&nfsd4_cb_notify_lock_ops,					NFSPROC4_CLNT_CB_NOTIFY_LOCK);		}	}	return nbl;}",20972
38,309,CVE-2017-9059,10,"static int rdma_listen_handler(struct rdma_cm_id *cma_id,			       struct rdma_cm_event *event){	struct svcxprt_rdma *xprt = cma_id->context;	int ret = 0;	switch (event->event) {	case RDMA_CM_EVENT_CONNECT_REQUEST:		dprintk(""svcrdma: Connect request on cma_id=%p, xprt = %p, ""			""event = %s (%d)\n"", cma_id, cma_id->context,			rdma_event_msg(event->event), event->event);		handle_connect_req(cma_id, &event->param.conn);		break;	case RDMA_CM_EVENT_ESTABLISHED:		 		dprintk(""svcrdma: Connection completed on LISTEN xprt=%p, ""			""cm_id=%p\n"", xprt, cma_id);		break;	case RDMA_CM_EVENT_DEVICE_REMOVAL:		dprintk(""svcrdma: Device removal xprt=%p, cm_id=%p\n"",			xprt, cma_id);		if (xprt)			set_bit(XPT_CLOSE, &xprt->sc_xprt.xpt_flags);		break;	default:		dprintk(""svcrdma: Unexpected event on listening endpoint %p, ""			""event = %s (%d)\n"", cma_id,			rdma_event_msg(event->event), event->event);		break;	}	return ret;}",21195
71,46,CVE-2017-9059,10,"nfsd4_lookup(struct svc_rqst *rqstp, struct nfsd4_compound_state *cstate,	     struct nfsd4_lookup *lookup){	return nfsd_lookup(rqstp, &cstate->current_fh,			   lookup->lo_name, lookup->lo_len,			   &cstate->current_fh);}",20932
27,88,CVE-2017-9059,10,find_readable_file(struct nfs4_file *f){	struct file *ret;	spin_lock(&f->fi_lock);	ret = find_readable_file_locked(f);	spin_unlock(&f->fi_lock);	return ret;},20974
55,16,CVE-2017-9059,10,"static void set_grace_period(struct net *net){	unsigned long grace_period = get_lockd_grace_period();	struct lockd_net *ln = net_generic(net, lockd_net_id);	locks_start_grace(net, &ln->lockd_manager);	cancel_delayed_work_sync(&ln->grace_period_end);	schedule_delayed_work(&ln->grace_period_end, grace_period);}",20902
57,122,CVE-2017-9059,10,static inline void nfs4_free_stateowner(struct nfs4_stateowner *sop){	kfree(sop->so_owner.data);	sop->so_ops->so_free(sop);},21008
0,33,CVE-2017-9059,10,"check_gss_callback_principal(struct nfs_client *clp, struct svc_rqst *rqstp){	char *p = rqstp->rq_cred.cr_principal;	if (rqstp->rq_authop->flavour != RPC_AUTH_GSS)		return 1;	 	if (clp->cl_minorversion != 0)		return 0;	 	if (p == NULL)		return 0;	 	if (clp->cl_acceptor)		return !strcmp(p, clp->cl_acceptor);	 	 	if (memcmp(p, ""nfs@"", 4) != 0)		return 0;	p += 4;	if (strcmp(p, clp->cl_hostname) != 0)		return 0;	return 1;}",20919
33,9,CVE-2017-9059,10,"static int lockd_inet6addr_event(struct notifier_block *this,	unsigned long event, void *ptr){	struct inet6_ifaddr *ifa = (struct inet6_ifaddr *)ptr;	struct sockaddr_in6 sin6;	if (event != NETDEV_DOWN)		goto out;	if (nlmsvc_rqst) {		dprintk(""lockd_inet6addr_event: removed %pI6\n"", &ifa->addr);		sin6.sin6_family = AF_INET6;		sin6.sin6_addr = ifa->addr;		if (ipv6_addr_type(&sin6.sin6_addr) & IPV6_ADDR_LINKLOCAL)			sin6.sin6_scope_id = ifa->idev->dev->ifindex;		svc_age_temp_xprts_now(nlmsvc_rqst->rq_server,			(struct sockaddr *)&sin6);	}out:	return NOTIFY_DONE;}",20895
82,318,CVE-2017-9059,10,"int svc_rdma_send(struct svcxprt_rdma *xprt, struct ib_send_wr *wr){	struct ib_send_wr *bad_wr, *n_wr;	int wr_count;	int i;	int ret;	if (test_bit(XPT_CLOSE, &xprt->sc_xprt.xpt_flags))		return -ENOTCONN;	wr_count = 1;	for (n_wr = wr->next; n_wr; n_wr = n_wr->next)		wr_count++;	 	while (1) {		if ((atomic_sub_return(wr_count, &xprt->sc_sq_avail) < 0)) {			atomic_inc(&rdma_stat_sq_starve);			 			atomic_add(wr_count, &xprt->sc_sq_avail);			wait_event(xprt->sc_send_wait,				   atomic_read(&xprt->sc_sq_avail) > wr_count);			if (test_bit(XPT_CLOSE, &xprt->sc_xprt.xpt_flags))				return -ENOTCONN;			continue;		}		 		for (i = 0; i < wr_count; i++)			svc_xprt_get(&xprt->sc_xprt);		 		ret = ib_post_send(xprt->sc_qp, wr, &bad_wr);		if (ret) {			set_bit(XPT_CLOSE, &xprt->sc_xprt.xpt_flags);			for (i = 0; i < wr_count; i ++)				svc_xprt_put(&xprt->sc_xprt);			dprintk(""svcrdma: failed to post SQ WR rc=%d\n"", ret);			dprintk(""    sc_sq_avail=%d, sc_sq_depth=%d\n"",				atomic_read(&xprt->sc_sq_avail),				xprt->sc_sq_depth);			wake_up(&xprt->sc_send_wait);		}		break;	}	return ret;}",21204
67,204,CVE-2017-9059,10,static void unhash_lockowner_locked(struct nfs4_lockowner *lo){	struct nfs4_client *clp = lo->lo_owner.so_client;	lockdep_assert_held(&clp->cl_lock);	list_del_init(&lo->lo_owner.so_strhash);},21090
42,2,CVE-2017-1000369,10,function_dummy_free(void *block) { block = block; },19449
5,218,CVE-2017-9059,10,"nfsd4_decode_copy(struct nfsd4_compoundargs *argp, struct nfsd4_copy *copy){	DECODE_HEAD;	unsigned int tmp;	status = nfsd4_decode_stateid(argp, &copy->cp_src_stateid);	if (status)		return status;	status = nfsd4_decode_stateid(argp, &copy->cp_dst_stateid);	if (status)		return status;	READ_BUF(8 + 8 + 8 + 4 + 4 + 4);	p = xdr_decode_hyper(p, &copy->cp_src_pos);	p = xdr_decode_hyper(p, &copy->cp_dst_pos);	p = xdr_decode_hyper(p, &copy->cp_count);	copy->cp_consecutive = be32_to_cpup(p++);	copy->cp_synchronous = be32_to_cpup(p++);	tmp = be32_to_cpup(p);  	DECODE_TAIL;}",21104
26,321,CVE-2017-9059,10,"void svc_rdma_wc_inv(struct ib_cq *cq, struct ib_wc *wc){	svc_rdma_send_wc_common_put(cq, wc, ""localInv"");}",21207
58,174,CVE-2017-9059,10,nfsd4_sequence_done(struct nfsd4_compoundres *resp){	struct nfsd4_compound_state *cs = &resp->cstate;	if (nfsd4_has_session(cs)) {		if (cs->status != nfserr_replay_cache) {			nfsd4_store_cache_entry(resp);			cs->slot->sl_flags &= ~NFSD4_SLOT_INUSE;		}		 		nfsd4_put_session(cs->session);	} else if (cs->clp)		put_client_renew(cs->clp);},21060
66,141,CVE-2017-9059,10,"nfsd4_cb_notify_lock_done(struct nfsd4_callback *cb, struct rpc_task *task){	 	switch (task->tk_status) {	case -NFS4ERR_DELAY:		rpc_delay(task, 1 * HZ);		return 0;	default:		return 1;	}}",21027
69,69,CVE-2017-9059,10,"static inline void *alloc_stateowner(struct kmem_cache *slab, struct xdr_netobj *owner, struct nfs4_client *clp){	struct nfs4_stateowner *sop;	sop = kmem_cache_alloc(slab, GFP_KERNEL);	if (!sop)		return NULL;	sop->so_owner.data = kmemdup(owner->data, owner->len, GFP_KERNEL);	if (!sop->so_owner.data) {		kmem_cache_free(slab, sop);		return NULL;	}	sop->so_owner.len = owner->len;	INIT_LIST_HEAD(&sop->so_stateids);	sop->so_client = clp;	init_nfs4_replay(&sop->so_replay);	atomic_set(&sop->so_count, 1);	return sop;}",20955
47,142,CVE-2017-9059,10,"static int nfsd4_cb_recall_done(struct nfsd4_callback *cb,		struct rpc_task *task){	struct nfs4_delegation *dp = cb_to_delegation(cb);	if (dp->dl_stid.sc_type == NFS4_CLOSED_DELEG_STID)	        return 1;	switch (task->tk_status) {	case 0:		return 1;	case -EBADHANDLE:	case -NFS4ERR_BAD_STATEID:		 		if (dp->dl_retries--) {			rpc_delay(task, 2 * HZ);			return 0;		}		 	default:		return -1;	}}",21028
68,210,CVE-2017-9059,10,"static int get_parent_attributes(struct svc_export *exp, struct kstat *stat){	struct path path = exp->ex_path;	int err;	path_get(&path);	while (follow_up(&path)) {		if (path.dentry != path.mnt->mnt_root)			break;	}	err = vfs_getattr(&path, stat, STATX_BASIC_STATS, AT_STATX_SYNC_AS_STAT);	path_put(&path);	return err;}",21096
77,60,CVE-2017-9059,10,"access_permit_read(struct nfs4_ol_stateid *stp){	return test_access(NFS4_SHARE_ACCESS_READ, stp) ||		test_access(NFS4_SHARE_ACCESS_BOTH, stp) ||		test_access(NFS4_SHARE_ACCESS_WRITE, stp);}",20946
75,156,CVE-2017-9059,10,"nfsd4_get_freestateid(struct nfsd4_compound_state *cstate, struct nfsd4_free_stateid *fsp){	get_stateid(cstate, &fsp->fr_stateid);}",21042
78,51,CVE-2017-9059,10,"nfsd4_putfh(struct svc_rqst *rqstp, struct nfsd4_compound_state *cstate,	    struct nfsd4_putfh *putfh){	fh_put(&cstate->current_fh);	cstate->current_fh.fh_handle.fh_size = putfh->pf_fhlen;	memcpy(&cstate->current_fh.fh_handle.fh_base, putfh->pf_fhval,	       putfh->pf_fhlen);	return fh_verify(rqstp, &cstate->current_fh, 0, NFSD_MAY_BYPASS_GSS);}",20937
48,283,CVE-2017-9059,10,"svc_init_buffer(struct svc_rqst *rqstp, unsigned int size, int node){	unsigned int pages, arghi;	 	if (svc_is_backchannel(rqstp))		return 1;	pages = size / PAGE_SIZE + 1;  	arghi = 0;	WARN_ON_ONCE(pages > RPCSVC_MAXPAGES);	if (pages > RPCSVC_MAXPAGES)		pages = RPCSVC_MAXPAGES;	while (pages) {		struct page *p = alloc_pages_node(node, GFP_KERNEL, 0);		if (!p)			break;		rqstp->rq_pages[arghi++] = p;		pages--;	}	return pages == 0;}",21169
76,223,CVE-2017-9059,10,"nfsd4_decode_fallocate(struct nfsd4_compoundargs *argp,		       struct nfsd4_fallocate *fallocate){	DECODE_HEAD;	status = nfsd4_decode_stateid(argp, &fallocate->falloc_stateid);	if (status)		return status;	READ_BUF(16);	p = xdr_decode_hyper(p, &fallocate->falloc_offset);	xdr_decode_hyper(p, &fallocate->falloc_length);	DECODE_TAIL;}",21109
65,276,CVE-2017-9059,10,"param_get_pool_mode(char *buf, struct kernel_param *kp){	int *ip = (int *)kp->arg;	switch (*ip)	{	case SVC_POOL_AUTO:		return strlcpy(buf, ""auto"", 20);	case SVC_POOL_GLOBAL:		return strlcpy(buf, ""global"", 20);	case SVC_POOL_PERCPU:		return strlcpy(buf, ""percpu"", 20);	case SVC_POOL_PERNODE:		return strlcpy(buf, ""pernode"", 20);	default:		return sprintf(buf, ""%d"", *ip);	}}",21162
24,107,CVE-2017-9059,10,"static void init_session(struct svc_rqst *rqstp, struct nfsd4_session *new, struct nfs4_client *clp, struct nfsd4_create_session *cses){	int idx;	struct nfsd_net *nn = net_generic(SVC_NET(rqstp), nfsd_net_id);	new->se_client = clp;	gen_sessionid(new);	INIT_LIST_HEAD(&new->se_conns);	new->se_cb_seq_nr = 1;	new->se_flags = cses->flags;	new->se_cb_prog = cses->callback_prog;	new->se_cb_sec = cses->cb_sec;	atomic_set(&new->se_ref, 0);	idx = hash_sessionid(&new->se_sessionid);	list_add(&new->se_hash, &nn->sessionid_hashtbl[idx]);	spin_lock(&clp->cl_lock);	list_add(&new->se_perclnt, &clp->cl_sessions);	spin_unlock(&clp->cl_lock);	{		struct sockaddr *sa = svc_addr(rqstp);		 		rpc_copy_addr((struct sockaddr *)&clp->cl_cb_conn.cb_addr, sa);		clp->cl_cb_conn.cb_addrlen = svc_addr_len(sa);	}}",20993
11,26,CVE-2017-9059,10,"static void nlmsvc_release_block(struct nlm_block *block){	if (block != NULL)		kref_put_mutex(&block->b_count, nlmsvc_free_block, &block->b_file->f_mutex);}",20912
20,305,CVE-2017-9059,10,svc_rdma_get_read_chunk(struct rpcrdma_msg *rmsgp){	struct rpcrdma_read_chunk *ch =		(struct rpcrdma_read_chunk *)&rmsgp->rm_body.rm_chunks[0];	if (ch->rc_discrim == xdr_zero)		return NULL;	return ch;},21191
13,52,CVE-2017-9059,10,"nfsd4_restorefh(struct svc_rqst *rqstp, struct nfsd4_compound_state *cstate,		void *arg){	if (!cstate->save_fh.fh_dentry)		return nfserr_restorefh;	fh_dup2(&cstate->current_fh, &cstate->save_fh);	if (HAS_STATE_ID(cstate, SAVED_STATE_ID_FLAG)) {		memcpy(&cstate->current_stateid, &cstate->save_stateid, sizeof(stateid_t));		SET_STATE_ID(cstate, CURRENT_STATE_ID_FLAG);	}	return nfs_ok;}",20938
39,297,CVE-2017-9059,10,"void svc_shutdown_net(struct svc_serv *serv, struct net *net){	svc_close_net(serv, net);	if (serv->sv_ops->svo_shutdown)		serv->sv_ops->svo_shutdown(serv, net);}",21183
46,102,CVE-2017-9059,10,"hash_delegation_locked(struct nfs4_delegation *dp, struct nfs4_file *fp){	int status;	struct nfs4_client *clp = dp->dl_stid.sc_client;	lockdep_assert_held(&state_lock);	lockdep_assert_held(&fp->fi_lock);	status = nfs4_get_existing_delegation(clp, fp);	if (status)		return status;	++fp->fi_delegees;	atomic_inc(&dp->dl_stid.sc_count);	dp->dl_stid.sc_type = NFS4_DELEG_STID;	list_add(&dp->dl_perfile, &fp->fi_delegations);	list_add(&dp->dl_perclnt, &clp->cl_delegations);	return 0;}",20988
16,133,CVE-2017-9059,10,nfs4_state_shutdown(void){	destroy_workqueue(laundry_wq);	nfsd4_destroy_callback_queue();	cleanup_callback_cred();},21019
63,24,CVE-2017-9059,10,"static void nlmsvc_insert_block(struct nlm_block *block, unsigned long when){	spin_lock(&nlm_blocked_lock);	nlmsvc_insert_block_locked(block, when);	spin_unlock(&nlm_blocked_lock);}",20910
14,245,CVE-2017-9059,10,"nfsd4_decode_secinfo_no_name(struct nfsd4_compoundargs *argp,		     struct nfsd4_secinfo_no_name *sin){	DECODE_HEAD;	READ_BUF(4);	sin->sin_style = be32_to_cpup(p++);	DECODE_TAIL;}",21131
28,100,CVE-2017-9059,10,"static int groups_equal(struct group_info *g1, struct group_info *g2){	int i;	if (g1->ngroups != g2->ngroups)		return false;	for (i=0; i<g1->ngroups; i++)		if (!gid_eq(g1->gid[i], g2->gid[i]))			return false;	return true;}",20986
60,112,CVE-2017-9059,10,"move_to_confirmed(struct nfs4_client *clp){	unsigned int idhashval = clientid_hashval(clp->cl_clientid.cl_id);	struct nfsd_net *nn = net_generic(clp->net, nfsd_net_id);	lockdep_assert_held(&nn->client_lock);	dprintk(""NFSD: move_to_confirm nfs4_client %p\n"", clp);	list_move(&clp->cl_idhash, &nn->conf_id_hashtbl[idhashval]);	rb_erase(&clp->cl_namenode, &nn->unconf_name_tree);	add_clp_to_name_tree(clp, &nn->conf_name_tree);	set_bit(NFSD4_CLIENT_CONFIRMED, &clp->cl_flags);	renew_client_locked(clp);}",20998
51,103,CVE-2017-9059,10,"static void hash_openowner(struct nfs4_openowner *oo, struct nfs4_client *clp, unsigned int strhashval){	lockdep_assert_held(&clp->cl_lock);	list_add(&oo->oo_owner.so_strhash,		 &clp->cl_ownerstr_hashtbl[strhashval]);	list_add(&oo->oo_perclient, &clp->cl_openowners);}",20989
61,292,CVE-2017-9059,10,svc_release_buffer(struct svc_rqst *rqstp){	unsigned int i;	for (i = 0; i < ARRAY_SIZE(rqstp->rq_pages); i++)		if (rqstp->rq_pages[i])			put_page(rqstp->rq_pages[i]);},21178
36,80,CVE-2017-9059,10,"find_any_file(struct nfs4_file *f){	struct file *ret;	spin_lock(&f->fi_lock);	ret = __nfs4_get_fd(f, O_RDWR);	if (!ret) {		ret = __nfs4_get_fd(f, O_WRONLY);		if (!ret)			ret = __nfs4_get_fd(f, O_RDONLY);	}	spin_unlock(&f->fi_lock);	return ret;}",20966
81,70,CVE-2017-9059,10,"bmap_to_share_mode(unsigned long bmap) {	int i;	unsigned int access = 0;	for (i = 1; i < 4; i++) {		if (test_bit(i, &bmap))			access |= i;	}	return access;}",20956
73,225,CVE-2017-9059,10,"nfsd4_decode_getattr(struct nfsd4_compoundargs *argp, struct nfsd4_getattr *getattr){	return nfsd4_decode_bitmap(argp, getattr->ga_bmval);}",21111
70,295,CVE-2017-9059,10,"svc_rqst_alloc(struct svc_serv *serv, struct svc_pool *pool, int node){	struct svc_rqst	*rqstp;	rqstp = kzalloc_node(sizeof(*rqstp), GFP_KERNEL, node);	if (!rqstp)		return rqstp;	__set_bit(RQ_BUSY, &rqstp->rq_flags);	spin_lock_init(&rqstp->rq_lock);	rqstp->rq_server = serv;	rqstp->rq_pool = pool;	rqstp->rq_argp = kmalloc_node(serv->sv_xdrsize, GFP_KERNEL, node);	if (!rqstp->rq_argp)		goto out_enomem;	rqstp->rq_resp = kmalloc_node(serv->sv_xdrsize, GFP_KERNEL, node);	if (!rqstp->rq_resp)		goto out_enomem;	if (!svc_init_buffer(rqstp, serv->sv_max_mesg, node))		goto out_enomem;	return rqstp;out_enomem:	svc_rqst_free(rqstp);	return NULL;}",21181
62,148,CVE-2017-9059,10,"static void nfsd4_cstate_assign_replay(struct nfsd4_compound_state *cstate,		struct nfs4_stateowner *so){	if (!nfsd4_has_session(cstate)) {		mutex_lock(&so->so_replay.rp_mutex);		cstate->replay_owner = nfs4_get_stateowner(so);	}}",21034
30,45,CVE-2017-9059,10,"nfsd4_getfh(struct svc_rqst *rqstp, struct nfsd4_compound_state *cstate,	    struct svc_fh **getfh){	if (!cstate->current_fh.fh_dentry)		return nfserr_nofilehandle;	*getfh = &cstate->current_fh;	return nfs_ok;}",20931
45,294,CVE-2017-9059,10,"int svc_rpcb_setup(struct svc_serv *serv, struct net *net){	int err;	err = rpcb_create_local(net);	if (err)		return err;	 	svc_unregister(serv, net);	return 0;}",21180
2,301,CVE-2017-9059,10,"xprt_rdma_bc_put(struct rpc_xprt *xprt){	dprintk(""svcrdma: %s: xprt %p\n"", __func__, xprt);	xprt_free(xprt);	module_put(THIS_MODULE);}",21187
32,345,CVE-2015-1335,11," static int mount_entry_on_relative_rootfs(struct mntent *mntent,					  const char *rootfs){	char path[MAXPATHLEN];	int ret;	 	ret = snprintf(path, sizeof(path), ""%s/%s"", rootfs, mntent->mnt_dir);	if (ret >= sizeof(path)) {		ERROR(""path name too long""); 		return -1; 	} 	return mount_entry_on_generic(mntent, path); }",31209
65,148,CVE-2015-1335,11,"static int cgm_unfreeze(void *hdata){	struct cgm_data *d = hdata;	int ret = true;	if (!d || !d->cgroup_path)		return false;	if (!cgm_dbus_connect()) {		ERROR(""Error connecting to cgroup manager"");		return false;	}	if (cgmanager_set_value_sync(NULL, cgroup_manager, ""freezer"", d->cgroup_path,			""freezer.state"", ""THAWED"") != 0) {		NihError *nerr;		nerr = nih_error_get();		ERROR(""call to cgmanager_set_value_sync failed: %s"", nerr->message);		nih_free(nerr);		ERROR(""Error unfreezing %s"", d->cgroup_path);		ret = false;	}	cgm_dbus_disconnect();	return ret;}",13938
66,24,CVE-2014-5045,11,"static inline int d_revalidate(struct dentry *dentry, unsigned int flags){	return dentry->d_op->d_revalidate(dentry, flags);}",10706
40,313,CVE-2018-6198,11,keyPressEventProc(int c){    CurrentKey = c;    w3mFuncList[(int)GlobalKeymap[c]].func();},25428
43,219,CVE-2015-1335,11,"int detect_ramfs_rootfs(void){	char buf[LINELEN], *p;	FILE *f;	int i;	char *p2;	f = fopen(""/proc/self/mountinfo"", ""r"");	if (!f)		return 0;	while (fgets(buf, LINELEN, f)) {		for (p = buf, i=0; p && i < 4; i++)			p = strchr(p+1, ' ');		if (!p)			continue;		p2 = strchr(p+1, ' ');		if (!p2)			continue;		*p2 = '\0';		if (strcmp(p+1, ""/"") == 0) {			p = strchr(p2+1, '-');			if (p && strncmp(p, ""- rootfs rootfs "", 16) == 0) {				fclose(f);				return 1;			}		}	}	fclose(f);	return 0;}",14009
12,274,CVE-2018-19044,11,"get_free_alloc_entry(void){	MEMCHECK *entry;	 	if (free_list_size < 256)		entry = malloc(sizeof *entry);	else {		entry = list_first_entry(&free_list, MEMCHECK, l);		list_head_del(&entry->l);		free_list_size--;	}	entry->seq_num = seq_num++;	return entry;}",23386
50,283,CVE-2018-19044,11,"set_default_script_user(const char *username, const char *groupname){	if (!default_script_uid_set || username) {		 		default_script_uid_set = true;		if (set_uid_gid(username, groupname, &default_script_uid, &default_script_gid, true)) {			if (username || script_security)				default_user_fail = true;		}		else			default_user_fail = false;	}	return default_user_fail;}",23395
1,342,CVE-2014-5045,11,"mountpoint_last(struct nameidata *nd, struct path *path){	int error = 0;	struct dentry *dentry;	struct dentry *dir = nd->path.dentry;	 	if (nd->flags & LOOKUP_RCU) {		if (unlazy_walk(nd, NULL)) {			error = -ECHILD;			goto out;		}	}	nd->flags &= ~LOOKUP_PARENT;	if (unlikely(nd->last_type != LAST_NORM)) {		error = handle_dots(nd, nd->last_type);		if (error)			goto out;		dentry = dget(nd->path.dentry);		goto done;	}	mutex_lock(&dir->d_inode->i_mutex);	dentry = d_lookup(dir, &nd->last);	if (!dentry) {		 		dentry = d_alloc(dir, &nd->last);		if (!dentry) {			error = -ENOMEM;			mutex_unlock(&dir->d_inode->i_mutex);			goto out;		}		dentry = lookup_real(dir->d_inode, dentry, nd->flags);		error = PTR_ERR(dentry);		if (IS_ERR(dentry)) {			mutex_unlock(&dir->d_inode->i_mutex);			goto out;		}	}	mutex_unlock(&dir->d_inode->i_mutex);done:	if (!dentry->d_inode || d_is_negative(dentry)) {		error = -ENOENT;		dput(dentry); 		goto out; 	} 	path->dentry = dentry;	path->mnt = mntget(nd->path.mnt); 	if (should_follow_link(dentry, nd->flags & LOOKUP_FOLLOW)) 		return 1; 	follow_mount(path); 	error = 0; out:	terminate_walk(nd);	return error;}",31137
17,99,CVE-2014-5045,11,"int vfs_symlink(struct inode *dir, struct dentry *dentry, const char *oldname){	int error = may_create(dir, dentry);	if (error)		return error;	if (!dir->i_op->symlink)		return -EPERM;	error = security_inode_symlink(dir, dentry, oldname);	if (error)		return error;	error = dir->i_op->symlink(dir, dentry, oldname);	if (!error)		fsnotify_create(dir, dentry);	return error;}",10781
10,191,CVE-2015-1335,11,"int parse_mntopts(const char *mntopts, unsigned long *mntflags,			 char **mntdata){	char *s, *data;	char *p, *saveptr = NULL;	*mntdata = NULL;	*mntflags = 0L;	if (!mntopts)		return 0;	s = strdup(mntopts);	if (!s) {		SYSERROR(""failed to allocate memory"");		return -1;	}	data = malloc(strlen(s) + 1);	if (!data) {		SYSERROR(""failed to allocate memory"");		free(s);		return -1;	}	*data = 0;	for (p = strtok_r(s, "","", &saveptr); p != NULL;	     p = strtok_r(NULL, "","", &saveptr))		parse_mntopt(p, mntflags, &data);	if (*data)		*mntdata = data;	else		free(data);	free(s);	return 0;}",13981
21,168,CVE-2015-1335,11,static char* getuname(void){	struct passwd *result;	result = getpwuid(geteuid());	if (!result)		return NULL;	return strdup(result->pw_name);},13958
52,161,CVE-2015-1335,11,"static int verify_and_prune(const char *cgroup_use){	const char *p;	char *e;	int i, j;	for (p = cgroup_use; p && *p; p = e + 1) {		e = strchr(p, ',');		if (e)			*e = '\0';		if (!in_subsystem_list(p)) {			ERROR(""Controller %s required by lxc.cgroup.use but not available\n"", p);			return false;		}		if (e)			*e = ',';		if (!e)			break;	}	for (i = 0; i < nr_subsystems;) {		if (in_comma_list(subsystems[i], cgroup_use)) {			i++;			continue;		}		free(subsystems[i]);		for (j = i;  j < nr_subsystems-1; j++)			subsystems[j] = subsystems[j+1];		subsystems[nr_subsystems-1] = NULL;		nr_subsystems--;	}	return true;}",13951
8,321,CVE-2018-6198,11,"resize_screen(void){    need_resize_screen = FALSE;    setlinescols();    setupscreen();    if (CurrentTab)	displayBuffer(Currentbuf, B_FORCE_REDRAW);}",25436
3,221,CVE-2015-1335,11,"int dir_exists(const char *path){	struct stat sb;	int ret;	ret = stat(path, &sb);	if (ret < 0)		return false;	return S_ISDIR(sb.st_mode);}",14011
23,212,CVE-2015-1335,11,"static int shutdown_macvlan(struct lxc_handler *handler, struct lxc_netdev *netdev){	int err;	if (netdev->downscript) {		err = run_script(handler->name, ""net"", netdev->downscript,				 ""down"", ""macvlan"", netdev->link,				 (char*) NULL);		if (err)			return -1;	}	return 0;}",14002
29,307,CVE-2018-6198,11,"execdict(char *word){    char *w, *dictcmd;    Buffer *buf;    if (!UseDictCommand || word == NULL || *word == '\0') {	displayBuffer(Currentbuf, B_NORMAL);	return;    }    w = conv_to_system(word);    if (*w == '\0') {	displayBuffer(Currentbuf, B_NORMAL);	return;    }    dictcmd = Sprintf(""%s?%s"", DictCommand,		      Str_form_quote(Strnew_charp(w))->ptr)->ptr;    buf = loadGeneralFile(dictcmd, NULL, NO_REFERER, 0, NULL);    if (buf == NULL) {	disp_message(""Execution failed"", TRUE);	return;    }    else if (buf != NO_BUFFER) {	buf->filename = w;	buf->buffername = Sprintf(""%s %s"", DICTBUFFERNAME, word)->ptr;	if (buf->type == NULL)	    buf->type = ""text/plain"";	pushBuffer(buf);    }    displayBuffer(Currentbuf, B_FORCE_REDRAW);}",25422
7,13,CVE-2010-0787,11,"static char * check_for_domain(char **ppuser){	char * original_string;	char * usernm;	char * domainnm;	int    original_len;	int    len;	int    i;	if(ppuser == NULL)		return NULL;	original_string = *ppuser;	if (original_string == NULL)		return NULL;		original_len = strlen(original_string);	usernm = strchr(*ppuser,'/');	if (usernm == NULL) {		usernm = strchr(*ppuser,'\\');		if (usernm == NULL)			return NULL;	}	if(got_domain) {		fprintf(stderr, ""Domain name specified twice. Username probably malformed\n"");		return NULL;	}	usernm[0] = 0;	domainnm = *ppuser;	if (domainnm[0] != 0) {		got_domain = 1;	} else {		fprintf(stderr, ""null domain\n"");	}	len = strlen(domainnm);	 	domainnm = (char *)malloc(len+1);	if(domainnm == NULL)		return NULL;	strlcpy(domainnm,*ppuser,len+1); 	len = strlen(usernm+1);	if(len >= original_len) {		 		return domainnm;	}	for(i=0;i<original_len;i++) {		if(i<len)			original_string[i] = usernm[i+1];		else  			original_string[i] = ',';	}	 		return domainnm;}",2056
18,277,CVE-2018-19044,11,keepalived_free_final(void){	keepalived_alloc_log(true);},23389
67,139,CVE-2015-1335,11,static const char *cgm_canonical_path(void *hdata){	struct cgm_data *d = hdata;	if (!d || !d->cgroup_path)		return NULL;	return d->cgroup_path;},13929
4,37,CVE-2014-5045,11,static void follow_dotdot(struct nameidata *nd){	set_root(nd);	while(1) {		struct dentry *old = nd->path.dentry;		if (nd->path.dentry == nd->root.dentry &&		    nd->path.mnt == nd->root.mnt) {			break;		}		if (nd->path.dentry != nd->path.mnt->mnt_root) {			 			nd->path.dentry = dget_parent(nd->path.dentry);			dput(old);			break;		}		if (!follow_up(&nd->path))			break;	}	follow_mount(&nd->path);	nd->inode = nd->path.dentry->d_inode;},10719
37,155,CVE-2015-1335,11,"static int lxc_cgmanager_chmod(const char *controller,		const char *cgroup_path, const char *file, int mode){	if (cgmanager_chmod_sync(NULL, cgroup_manager, controller,			cgroup_path, file, mode) != 0) {		NihError *nerr;		nerr = nih_error_get();		ERROR(""call to cgmanager_chmod_sync failed: %s"", nerr->message);		nih_free(nerr);		return false;	}	return true;}",13945
35,57,CVE-2014-5045,11,"kern_path_mountpoint(int dfd, const char *name, struct path *path,			unsigned int flags){	struct filename s = {.name = name};	return filename_mountpoint(dfd, &s, path, flags);}",10739
55,42,CVE-2014-5045,11,static void follow_mount(struct path *path){	while (d_mountpoint(path->dentry)) {		struct vfsmount *mounted = lookup_mnt(path);		if (!mounted)			break;		dput(path->dentry);		mntput(path->mnt);		path->mnt = mounted;		path->dentry = dget(mounted->mnt_root);	}},10724
53,301,CVE-2018-6198,11,bufferA(void){    on_target = FALSE;    followA();    on_target = TRUE;},25416
9,26,CVE-2014-5045,11,"struct file *do_file_open_root(struct dentry *dentry, struct vfsmount *mnt,		const char *name, const struct open_flags *op){	struct nameidata nd;	struct file *file;	struct filename filename = { .name = name };	int flags = op->lookup_flags | LOOKUP_ROOT;	nd.root.mnt = mnt;	nd.root.dentry = dentry;	if (d_is_symlink(dentry) && op->intent & LOOKUP_OPEN)		return ERR_PTR(-ELOOP);	file = path_openat(-1, &filename, &nd, op, flags | LOOKUP_RCU);	if (unlikely(file == ERR_PTR(-ECHILD)))		file = path_openat(-1, &filename, &nd, op, flags);	if (unlikely(file == ERR_PTR(-ESTALE)))		file = path_openat(-1, &filename, &nd, op, flags | LOOKUP_REVAL);	return file;}",10708
59,175,CVE-2015-1335,11,int lxc_clear_automounts(struct lxc_conf *c){	c->auto_mounts = 0;	return 0;},13965
41,86,CVE-2014-5045,11,void path_put(const struct path *path){	dput(path->dentry);	mntput(path->mnt);},10768
25,151,CVE-2015-1335,11,"static void cull_user_controllers(void){	int i, j;	for (i = 0;  i < nr_subsystems; i++) {		if (strncmp(subsystems[i], ""name="", 5) != 0)			continue;		for (j = i;  j < nr_subsystems-1; j++)			subsystems[j] = subsystems[j+1];		nr_subsystems--;	}}",13941
31,77,CVE-2014-5045,11,"void *page_follow_link_light(struct dentry *dentry, struct nameidata *nd){	struct page *page = NULL;	nd_set_link(nd, page_getlink(dentry, &page));	return page;}",10759
84,91,CVE-2014-5045,11,"static inline int should_follow_link(struct dentry *dentry, int follow){	return unlikely(d_is_symlink(dentry)) ? follow : 0;}",10773
6,145,CVE-2015-1335,11,"static int cgm_mount_cgroup(void *hdata, const char *root, int type){	if (dir_exists(CGMANAGER_LOWER_SOCK))		return cgm_bind_dir(root, CGMANAGER_LOWER_SOCK);	if (dir_exists(CGMANAGER_UPPER_SOCK))		return cgm_bind_dir(root, CGMANAGER_UPPER_SOCK);	return false;}",13935
56,261,CVE-2018-19044,11,"dbus_send_reload_signal(void){	gchar *path;	if (global_connection == NULL)		return;	path = dbus_object_create_path_vrrp();	dbus_emit_signal(global_connection, path, DBUS_VRRP_INTERFACE, ""VrrpReloaded"", NULL);	g_free(path);}",23373
15,133,CVE-2015-1335,11,"static struct cgroup_process_info *lxc_cgroup_process_info_get_self(struct cgroup_meta_data *meta){	struct cgroup_process_info *i;	i = lxc_cgroup_process_info_getx(""/proc/self/cgroup"", meta);	if (!i)		i = lxc_cgroup_process_info_get(getpid(), meta);	return i;}",13923
54,103,CVE-2015-5287,11,"static int test_configuration(int setting_SaveFullCore, int setting_CreateCoreBacktrace){    if (!setting_SaveFullCore && !setting_CreateCoreBacktrace)    {        fprintf(stderr, ""Both SaveFullCore and CreateCoreBacktrace are disabled - ""                        ""at least one of them is needed for useful report.\n"");        return 1;    }    return 0;}",13423
22,147,CVE-2015-1335,11,"static void cgm_remove_cgroup(const char *controller, const char *path){	int existed;	if ( cgmanager_remove_sync(NULL, cgroup_manager, controller,				   path, CG_REMOVE_RECURSIVE, &existed) != 0) {		NihError *nerr;		nerr = nih_error_get();		ERROR(""call to cgmanager_remove_sync failed: %s"", nerr->message);		nih_free(nerr);		ERROR(""Error removing %s:%s"", controller, path);	}	if (existed == -1)		INFO(""cgroup removal attempt: %s:%s did not exist"", controller, path);}",13937
34,166,CVE-2015-1335,11,"static char *get_field(char *src, int nfields){	char *p = src;	int i;	for (i = 0; i < nfields; i++) {		while (*p && *p != ' ' && *p != '\t')			p++;		if (!*p)			break;		p++;	}	return p;}",13956
44,2,CVE-2019-13636,11,"report_revision (int found_revision){  char const *rev = quotearg (revision);  if (found_revision)    {      if (verbosity == VERBOSE)	say (""Good.  This file appears to be the %s version.\n"", rev);    }  else if (force)    {      if (verbosity != SILENT)	say (""Warning: this file doesn't appear to be the %s version -- patching anyway.\n"",	     rev);    }  else if (batch)    fatal (""This file doesn't appear to be the %s version -- aborting."",	   rev);  else    {      ask (""This file doesn't appear to be the %s version -- patch anyway? [n] "",	   rev);      if (*buf != 'y')	fatal (""aborted"");    }}",580
87,236,CVE-2015-1335,11,"int setproctitle(char *title){	char buf[2048], *tmp;	FILE *f;	int i, len, ret = 0;	unsigned long arg_start, arg_end, env_start, env_end;	f = fopen_cloexec(""/proc/self/stat"", ""r"");	if (!f) {		return -1;	}	tmp = fgets(buf, sizeof(buf), f);	fclose(f);	if (!tmp) {		return -1;	}	 	tmp = strchr(buf, ' ');	for (i = 0; i < 46; i++) {		if (!tmp)			return -1;		tmp = strchr(tmp+1, ' ');	}	if (!tmp)		return -1;	i = sscanf(tmp, ""%lu %lu %lu %lu"", &arg_start, &arg_end, &env_start, &env_end);	if (i != 4) {		return -1;	}	 	len = strlen(title) + 1;	 	if (len > env_end - arg_start) {		arg_end = env_end;		len = env_end - arg_start;	} else {		 		if (len >= arg_end - arg_start) {			env_start = env_end;		}		arg_end = arg_start + len;		 		if (arg_end < len || arg_end < arg_start) {			return -1;		}	}	strcpy((char*)arg_start, title);	ret |= prctl(PR_SET_MM, PR_SET_MM_ARG_START,   arg_start, 0, 0);	ret |= prctl(PR_SET_MM, PR_SET_MM_ARG_END,     arg_end, 0, 0);	ret |= prctl(PR_SET_MM, PR_SET_MM_ENV_START,   env_start, 0, 0);	ret |= prctl(PR_SET_MM, PR_SET_MM_ENV_END,     env_end, 0, 0); 	return ret; }",14026
19,255,CVE-2015-3315,11,"static int get_fsuid(void){    int real, euid, saved;         int fs_uid = 0;    char *line = proc_pid_status;      for (;;)    {        if (strncmp(line, ""Uid"", 3) == 0)        {            int n = sscanf(line, ""Uid:\t%d\t%d\t%d\t%d\n"", &real, &euid, &saved, &fs_uid);            if (n != 4)            {                perror_msg_and_die(""Can't parse Uid: line"");            }            break;        }        line = strchr(line, '\n');        if (!line)            break;        line++;    }    return fs_uid;}",22977
76,63,CVE-2014-5045,11,"static inline int lookup_last(struct nameidata *nd, struct path *path){	if (nd->last_type == LAST_NORM && nd->last.name[nd->last.len])		nd->flags |= LOOKUP_FOLLOW | LOOKUP_DIRECTORY;	nd->flags &= ~LOOKUP_PARENT;	return walk_component(nd, path, nd->flags & LOOKUP_FOLLOW);}",10745
49,142,CVE-2015-1335,11,"static void cgm_destroy(void *hdata){	struct cgm_data *d = hdata;	char **slist = subsystems;	int i;	if (!d || !d->cgroup_path)		return;	if (!cgm_dbus_connect()) {		ERROR(""Error connecting to cgroup manager"");		return;	}	if (cgm_supports_multiple_controllers)		slist = subsystems_inone;	for (i = 0; slist[i]; i++)		cgm_remove_cgroup(slist[i], d->cgroup_path);	free(d->name);	free(d->cgroup_path);	free(d);	cgm_dbus_disconnect();}",13932
78,270,CVE-2018-19044,11,flush_log_file(void){	if (log_file)		fflush(log_file);},23382
38,310,CVE-2018-6198,11,"gotoLabel(char *label){    Buffer *buf;    Anchor *al;    int i;    al = searchURLLabel(Currentbuf, label);    if (al == NULL) {	 	disp_message(Sprintf(""%s is not found"", label)->ptr, TRUE);	return;    }    buf = newBuffer(Currentbuf->width);    copyBuffer(buf, Currentbuf);    for (i = 0; i < MAX_LB; i++)	buf->linkBuffer[i] = NULL;    buf->currentURL.label = allocStr(label, -1);    pushHashHist(URLHist, parsedURL2Str(&buf->currentURL)->ptr);    (*buf->clone)++;    pushBuffer(buf);    gotoLine(Currentbuf, al->start.line);    if (label_topline)	Currentbuf->topLine = lineSkip(Currentbuf, Currentbuf->topLine,				       Currentbuf->currentLine->linenumber				       - Currentbuf->topLine->linenumber,				       FALSE);    Currentbuf->pos = al->start.pos;    arrangeCursor(Currentbuf);    displayBuffer(Currentbuf, B_FORCE_REDRAW);    return;}",25425
75,46,CVE-2014-5045,11,"unsigned int full_name_hash(const unsigned char *name, unsigned int len){	unsigned long hash = init_name_hash();	while (len--)		hash = partial_name_hash(*name++, hash);	return end_name_hash(hash);}",10728
27,88,CVE-2014-5045,11,"static inline void path_to_nameidata(const struct path *path,					struct nameidata *nd){	if (!(nd->flags & LOOKUP_RCU)) {		dput(nd->path.dentry);		if (nd->path.mnt != path->mnt)			mntput(nd->path.mnt);	}	nd->path.mnt = path->mnt;	nd->path.dentry = path->dentry;}",10770
57,282,CVE-2018-19044,11,"register_notify_addresses(void){	register_thread_address(""child_killed_thread"", child_killed_thread);}",23394
77,225,CVE-2015-1335,11,"extern int get_u16(unsigned short *val, const char *arg, int base){	unsigned long res;	char *ptr;	if (!arg || !*arg)		return -1;	errno = 0;	res = strtoul(arg, &ptr, base);	if (!ptr || ptr == arg || *ptr || res > 0xFFFF || errno != 0)		return -1;	*val = res;	return 0;}",14015
0,197,CVE-2015-1335,11,"static int send_fd(int sock, int fd){	int ret = lxc_abstract_unix_send_fd(sock, fd, NULL, 0);	if (ret < 0) {		SYSERROR(""Error sending tty fd to parent"");		return -1;	}	return 0;}",13987
33,9,CVE-2019-13636,11,"copy_attr_quote (struct error_context *ctx, char const *str){  return quotearg (str);}",587
86,318,CVE-2018-6198,11,"posTab(int x, int y){    TabBuffer *tab;    if (mouse_action.menu_str && x < mouse_action.menu_width && y == 0)	return NO_TABBUFFER;    if (y > LastTab->y)	return NULL;    for (tab = FirstTab; tab; tab = tab->nextTab) {	if (tab->x1 <= x && x <= tab->x2 && tab->y == y)	    return tab;    }    return NULL;}",25433
71,204,CVE-2015-1335,11,"static int setup_mount_entries(const struct lxc_rootfs *rootfs, struct lxc_list *mount,	const char *lxc_name){	FILE *file;	int ret;	file = write_mount_file(mount);	if (!file)		return -1;	ret = mount_file_entries(rootfs, file, lxc_name);	fclose(file);	return ret;}",13994
42,290,CVE-2018-19044,11,"get_cwd(void){	char *dir = MALLOC(PATH_MAX);	 	return getcwd(dir, PATH_MAX);}",23402
5,202,CVE-2015-1335,11,"static int setup_lodev(const char *rootfs, int fd, struct loop_info64 *loinfo){	int rfd;	int ret = -1;	rfd = open(rootfs, O_RDWR);	if (rfd < 0) {		SYSERROR(""failed to open '%s'"", rootfs);		return -1;	}	memset(loinfo, 0, sizeof(*loinfo));	loinfo->lo_flags = LO_FLAGS_AUTOCLEAR;	if (ioctl(fd, LOOP_SET_FD, rfd)) {		SYSERROR(""failed to LOOP_SET_FD"");		goto out;	}	if (ioctl(fd, LOOP_SET_STATUS64, loinfo)) {		SYSERROR(""failed to LOOP_SET_STATUS64"");		goto out;	}	ret = 0;out:	close(rfd);	return ret;}",13992
26,339,CVE-2017-7418,11,"static int auth_init(void) {      pr_help_add(C_USER, _(""<sp> username""), TRUE);  pr_help_add(C_PASS, _(""<sp> password""), TRUE);  pr_help_add(C_ACCT, _(""is not implemented""), FALSE);  pr_help_add(C_REIN, _(""is not implemented""), FALSE);     set_auth_check(auth_cmd_chk_cb);  return 0;}",28572
79,156,CVE-2015-1335,11,"static int lxc_cgmanager_create(const char *controller, const char *cgroup_path, int *existed){	int ret = true;	if ( cgmanager_create_sync(NULL, cgroup_manager, controller,				       cgroup_path, existed) != 0) {		NihError *nerr;		nerr = nih_error_get();		ERROR(""call to cgmanager_create_sync failed: %s"", nerr->message);		nih_free(nerr);		ERROR(""Failed to create %s:%s"", controller, cgroup_path);		ret = false;	}	return ret;}",13946
83,222,CVE-2015-1335,11,"int file_exists(const char *f){	struct stat statbuf;	return stat(f, &statbuf) == 0;}",14012
82,51,CVE-2014-5045,11,"static inline unsigned long hash_name(const char *name, unsigned int *hashp){	unsigned long a, b, adata, bdata, mask, hash, len;	const struct word_at_a_time constants = WORD_AT_A_TIME_CONSTANTS;	hash = a = 0;	len = -sizeof(unsigned long);	do {		hash = (hash + a) * 9;		len += sizeof(unsigned long);		a = load_unaligned_zeropad(name+len);		b = a ^ REPEAT_BYTE('/');	} while (!(has_zero(a, &adata, &constants) | has_zero(b, &bdata, &constants)));	adata = prep_zero_mask(a, adata, &constants);	bdata = prep_zero_mask(b, bdata, &constants);	mask = create_zero_mask(adata | bdata);	hash += a & zero_bytemask(mask);	*hashp = fold_hash(hash);	return len + find_zero(mask);}",10733
47,294,CVE-2018-19044,11,"install_sublevel_end_handler(void (*handler) (void)){	int i = 0;	keyword_t *keyword;	 	keyword = vector_slot(keywords, vector_size(keywords) - 1);	if (!keyword->active)		return;	 	for (i = 0; i < sublevel; i++)		keyword = vector_slot(keyword->sub, vector_size(keyword->sub) - 1);	keyword->sub_close_handler = handler;}",23406
58,16,CVE-2010-0787,11,static char * getusername(void) {	char *username = NULL;	struct passwd *password = getpwuid(getuid());	if (password) {		username = password->pw_name;	}	return username;},2059
72,210,CVE-2015-1335,11,"static int setup_utsname(struct utsname *utsname){	if (!utsname)		return 0;	if (sethostname(utsname->nodename, strlen(utsname->nodename))) {		SYSERROR(""failed to set the hostname to '%s'"", utsname->nodename);		return -1;	}	INFO(""'%s' hostname has been setup"", utsname->nodename);	return 0;}",14000
81,60,CVE-2014-5045,11,"static struct dentry *lookup_dcache(struct qstr *name, struct dentry *dir,				    unsigned int flags, int *need_lookup){	struct dentry *dentry;	int error;	*need_lookup = false;	dentry = d_lookup(dir, name);	if (dentry) {		if (dentry->d_flags & DCACHE_OP_REVALIDATE) {			error = d_revalidate(dentry, flags);			if (unlikely(error <= 0)) {				if (error < 0) {					dput(dentry);					return ERR_PTR(error);				} else if (!d_invalidate(dentry)) {					dput(dentry);					dentry = NULL;				}			}		}	}	if (!dentry) {		dentry = d_alloc(dir, name);		if (unlikely(!dentry))			return ERR_PTR(-ENOMEM);		*need_lookup = true;	}	return dentry;}",10742
64,292,CVE-2018-19044,11,install_sublevel(void){	sublevel++;},23404
74,295,CVE-2018-6198,11,"_goLine(char *l){    if (l == NULL || *l == '\0' || Currentbuf->currentLine == NULL) {	displayBuffer(Currentbuf, B_FORCE_REDRAW);	return;    }    Currentbuf->pos = 0;    if (((*l == '^') || (*l == '$')) && prec_num) {	gotoRealLine(Currentbuf, prec_num);    }    else if (*l == '^') {	Currentbuf->topLine = Currentbuf->currentLine = Currentbuf->firstLine;    }    else if (*l == '$') {	Currentbuf->topLine =	    lineSkip(Currentbuf, Currentbuf->lastLine,		     -(Currentbuf->LINES + 1) / 2, TRUE);	Currentbuf->currentLine = Currentbuf->lastLine;    }    else	gotoRealLine(Currentbuf, atoi(l));    arrangeCursor(Currentbuf);    displayBuffer(Currentbuf, B_FORCE_REDRAW);}",25410
48,102,CVE-2015-5287,11,"static int create_or_die(const char *filename, int user_core_fd){    int fd = open(filename, O_WRONLY | O_CREAT | O_TRUNC | O_EXCL, DEFAULT_DUMP_DIR_MODE);    if (fd >= 0)    {        IGNORE_RESULT(fchown(fd, dd->dd_uid, dd->dd_gid));        return fd;    }    int sv_errno = errno;    if (dd)        dd_delete(dd);    if (user_core_fd >= 0)        close(user_core_fd);    errno = sv_errno;    perror_msg_and_die(""Can't open '%s'"", filename);}",13422
80,223,CVE-2015-1335,11,"char *get_rundir(){	char *rundir;	const char *homedir;	if (geteuid() == 0) {		rundir = strdup(RUNTIME_PATH);		return rundir;	}	rundir = getenv(""XDG_RUNTIME_DIR"");	if (rundir) {		rundir = strdup(rundir);		return rundir;	}	INFO(""XDG_RUNTIME_DIR isn't set in the environment."");	homedir = getenv(""HOME"");	if (!homedir) {		ERROR(""HOME isn't set in the environment."");		return NULL;	}	rundir = malloc(sizeof(char) * (17 + strlen(homedir)));	sprintf(rundir, ""%s/.cache/lxc/run/"", homedir);	return rundir;}",14013
68,276,CVE-2018-19044,11,"keepalived_free(void *buffer, const char *file, const char *function, int line){	keepalived_free_realloc_common(buffer, 0, file, function, line, false);}",23388
24,107,CVE-2015-1335,11,"static const char *cgfs_get_cgroup(void *hdata, const char *subsystem){	struct cgfs_data *d = hdata;	if (!d)		return NULL;	return lxc_cgroup_get_hierarchy_path_data(subsystem, d);}",13897
11,52,CVE-2014-5045,11,"static inline unsigned long hash_name(const char *name, unsigned int *hashp){	unsigned long hash = init_name_hash();	unsigned long len = 0, c;	c = (unsigned char)*name;	do {		len++;		hash = partial_name_hash(c, hash);		c = (unsigned char)name[len];	} while (c && c != '/');	*hashp = end_name_hash(hash);	return len;}",10734
20,322,CVE-2018-6198,11,"saveBufferInfo(){    FILE *fp;    if (w3m_dump)	return;    if ((fp = fopen(rcFile(""bufinfo""), ""w"")) == NULL) {	return;    }    fprintf(fp, ""%s\n"", currentURL()->ptr);    fclose(fp);}",25437
13,245,CVE-2015-1331,11,"int lxclock(struct lxc_lock *l, int timeout){	int ret = -1, saved_errno = errno;	struct flock lk;	switch(l->type) {	case LXC_LOCK_ANON_SEM:		if (!timeout) {			ret = sem_wait(l->u.sem);			if (ret == -1)				saved_errno = errno;		} else {			struct timespec ts;			if (clock_gettime(CLOCK_REALTIME, &ts) == -1) {				ret = -2;				goto out;			}			ts.tv_sec += timeout;			ret = sem_timedwait(l->u.sem, &ts);			if (ret == -1)				saved_errno = errno;		}		break;	case LXC_LOCK_FLOCK:		ret = -2;		if (timeout) {			ERROR(""Error: timeout not supported with flock"");			ret = -2;			goto out;		}		if (!l->u.f.fname) {			ERROR(""Error: filename not set for flock"");			ret = -2;			goto out;		}		if (l->u.f.fd == -1) {			l->u.f.fd = open(l->u.f.fname, O_RDWR|O_CREAT,					S_IWUSR | S_IRUSR);			if (l->u.f.fd == -1) {				ERROR(""Error opening %s"", l->u.f.fname);				goto out;			}		}		lk.l_type = F_WRLCK;		lk.l_whence = SEEK_SET;		lk.l_start = 0;		lk.l_len = 0;		ret = fcntl(l->u.f.fd, F_SETLKW, &lk);		if (ret == -1)			saved_errno = errno;		break;	}out:	errno = saved_errno;	return ret;}",14063
69,325,CVE-2018-6198,11,"sysm_process_mouse(int x, int y, int nbs, int obs){    int btn;    int bits;    if (obs & ~nbs)	btn = MOUSE_BTN_UP;    else if (nbs & ~obs) {	bits = nbs & ~obs;	btn = bits & 0x1 ? MOUSE_BTN1_DOWN :	    (bits & 0x2 ? MOUSE_BTN2_DOWN :	     (bits & 0x4 ? MOUSE_BTN3_DOWN : 0));    }    else			 	return 0;    process_mouse(btn, x, y);    return 0;}",25440
39,326,CVE-2018-6198,11,"auxbinFile(char *base){    return expandPath(Strnew_m_charp(w3m_auxbin_dir(), ""/"", base, NULL)->ptr);}",25441
46,126,CVE-2015-1335,11,"static void lxc_cgroup_hierarchy_free(struct cgroup_hierarchy *h){	if (!h)		return;	lxc_free_array((void **)h->subsystems, free);	free(h->all_mount_points);	free(h);}",13916
16,83,CVE-2014-5045,11,"static int path_lookupat(int dfd, const char *name,				unsigned int flags, struct nameidata *nd){	struct file *base = NULL;	struct path path;	int err;	 	err = path_init(dfd, name, flags | LOOKUP_PARENT, nd, &base);	if (unlikely(err))		return err;	current->total_link_count = 0;	err = link_path_walk(name, nd);	if (!err && !(flags & LOOKUP_PARENT)) {		err = lookup_last(nd, &path);		while (err > 0) {			void *cookie;			struct path link = path;			err = may_follow_link(&link, nd);			if (unlikely(err))				break;			nd->flags |= LOOKUP_PARENT;			err = follow_link(&link, nd, &cookie);			if (err)				break;			err = lookup_last(nd, &path);			put_link(nd, &link, cookie);		}	}	if (!err)		err = complete_walk(nd);	if (!err && nd->flags & LOOKUP_DIRECTORY) {		if (!d_can_lookup(nd->path.dentry)) {			path_put(&nd->path);			err = -ENOTDIR;		}	}	if (base)		fput(base);	if (nd->root.mnt && !(nd->flags & LOOKUP_ROOT)) {		path_put(&nd->root);		nd->root.mnt = NULL;	}	return err;}",10765
63,112,CVE-2015-1335,11,"static int cgroupfs_setup_limits(void *hdata, struct lxc_list *cgroup_conf,				  int with_devices){	struct cgfs_data *d = hdata;	if (!d)		return false;	return do_setup_cgroup_limits(d, cgroup_conf, with_devices) == 0;}",13902
14,217,CVE-2015-1335,11,"void tmp_proc_unmount(struct lxc_conf *lxc_conf){	if (lxc_conf->tmp_umount_proc == 1) {		umount(""/proc"");		lxc_conf->tmp_umount_proc = 0;	}}",14007
28,100,CVE-2014-5045,11,"int vfs_unlink(struct inode *dir, struct dentry *dentry, struct inode **delegated_inode){	struct inode *target = dentry->d_inode;	int error = may_delete(dir, dentry, 0);	if (error)		return error;	if (!dir->i_op->unlink)		return -EPERM;	mutex_lock(&target->i_mutex);	if (d_mountpoint(dentry))		error = -EBUSY;	else {		error = security_inode_unlink(dir, dentry);		if (!error) {			error = try_break_deleg(target, delegated_inode);			if (error)				goto out;			error = dir->i_op->unlink(dir, dentry);			if (!error)				dont_mount(dentry);		}	}out:	mutex_unlock(&target->i_mutex);	 	if (!error && !(dentry->d_flags & DCACHE_NFSFS_RENAMED)) {		fsnotify_link_count(target);		d_delete(dentry);	}	return error;}",10782
60,122,CVE-2015-1335,11,"static char *lxc_cgroup_get_hierarchy_abs_path(const char *subsystem, const char *name, const char *lxcpath){	struct cgroup_meta_data *meta;	struct cgroup_process_info *base_info, *info;	struct cgroup_mount_point *mp;	char *result = NULL;	meta = lxc_cgroup_load_meta();	if (!meta)		return NULL;	base_info = lxc_cgroup_get_container_info(name, lxcpath, meta);	if (!base_info)		goto out1;	info = find_info_for_subsystem(base_info, subsystem);	if (!info)		goto out2;	if (info->designated_mount_point) {		mp = info->designated_mount_point;	} else {		mp = lxc_cgroup_find_mount_point(info->hierarchy, info->cgroup_path, true);		if (!mp)			goto out3;	}	result = cgroup_to_absolute_path(mp, info->cgroup_path, NULL);out3:out2:	lxc_cgroup_process_info_free(base_info);out1:	lxc_cgroup_put_meta(meta);	return result;}",13912
51,192,CVE-2015-1335,11,"int pin_rootfs(const char *rootfs){	char absrootfs[MAXPATHLEN];	char absrootfspin[MAXPATHLEN];	struct stat s;	int ret, fd;	if (rootfs == NULL || strlen(rootfs) == 0)		return -2;	if (!realpath(rootfs, absrootfs))		return -2;	if (access(absrootfs, F_OK))		return -1;	if (stat(absrootfs, &s))		return -1;	if (!S_ISDIR(s.st_mode))		return -2;	ret = snprintf(absrootfspin, MAXPATHLEN, ""%s/lxc.hold"", absrootfs);	if (ret >= MAXPATHLEN)		return -1;	fd = open(absrootfspin, O_CREAT | O_RDWR, S_IWUSR|S_IRUSR);	if (fd < 0)		return fd;	(void)unlink(absrootfspin);	return fd;}",13982
61,174,CVE-2015-1335,11,"static int instantiate_vlan(struct lxc_handler *handler, struct lxc_netdev *netdev){	char peer[IFNAMSIZ];	int err;	static int vlan_cntr = 0;	if (!netdev->link) {		ERROR(""no link specified for vlan netdev"");		return -1;	}	err = snprintf(peer, sizeof(peer), ""vlan%d-%d"", netdev->priv.vlan_attr.vid, vlan_cntr++);	if (err >= sizeof(peer)) {		ERROR(""peer name too long"");		return -1;	}	err = lxc_vlan_create(netdev->link, peer, netdev->priv.vlan_attr.vid);	if (err) {		ERROR(""failed to create vlan interface '%s' on '%s' : %s"",		      peer, netdev->link, strerror(-err));		return -1;	}	netdev->ifindex = if_nametoindex(peer);	if (!netdev->ifindex) {		ERROR(""failed to retrieve the ifindex for %s"", peer);		lxc_netdev_delete_by_name(peer);		return -1;	}	DEBUG(""instantiated vlan '%s', ifindex is '%d'"", "" vlan1000"",	      netdev->ifindex);	return 0;}",13964
36,80,CVE-2014-5045,11,"int page_symlink(struct inode *inode, const char *symname, int len){	return __page_symlink(inode, symname, len,			!(mapping_gfp_mask(inode->i_mapping) & __GFP_FS));}",10762
85,70,CVE-2014-5045,11,"static inline int may_follow_link(struct path *link, struct nameidata *nd){	const struct inode *inode;	const struct inode *parent;	if (!sysctl_protected_symlinks)		return 0;	 	inode = link->dentry->d_inode;	if (uid_eq(current_cred()->fsuid, inode->i_uid))		return 0;	 	parent = nd->path.dentry->d_inode;	if ((parent->i_mode & (S_ISVTX|S_IWOTH)) != (S_ISVTX|S_IWOTH))		return 0;	 	if (uid_eq(parent->i_uid, inode->i_uid))		return 0;	audit_log_link_denied(""follow_link"", link);	path_put_conditional(link, nd);	path_put(&nd->path);	return -EACCES;}",10752
73,69,CVE-2014-5045,11,"static int may_delete(struct inode *dir, struct dentry *victim, int isdir){	struct inode *inode = victim->d_inode;	int error;	if (d_is_negative(victim))		return -ENOENT;	BUG_ON(!inode);	BUG_ON(victim->d_parent->d_inode != dir);	audit_inode_child(dir, victim, AUDIT_TYPE_CHILD_DELETE);	error = inode_permission(dir, MAY_WRITE | MAY_EXEC);	if (error)		return error;	if (IS_APPEND(dir))		return -EPERM;	if (check_sticky(dir, inode) || IS_APPEND(inode) ||	    IS_IMMUTABLE(inode) || IS_SWAPFILE(inode))		return -EPERM;	if (isdir) {		if (!d_is_dir(victim))			return -ENOTDIR;		if (IS_ROOT(victim))			return -EBUSY;	} else if (d_is_dir(victim))		return -EISDIR;	if (IS_DEADDIR(dir))		return -ENOENT;	if (victim->d_flags & DCACHE_NFSFS_RENAMED)		return -EBUSY;	return 0;}",10751
70,141,CVE-2015-1335,11,static void cgm_dbus_disconnect(void){	if (cgroup_manager) {		dbus_connection_flush(cgroup_manager->connection);		dbus_connection_close(cgroup_manager->connection);		nih_free(cgroup_manager);	}	cgroup_manager = NULL;	cgm_unlock();},13931
62,164,CVE-2015-1335,11,"int do_rootfs_setup(struct lxc_conf *conf, const char *name, const char *lxcpath){	if (conf->rootfs_setup) {		 		const char *path = conf->rootfs.mount;		if (mount(path, path, ""rootfs"", MS_BIND, NULL) < 0) {			ERROR(""Failed to bind-mount container / onto itself"");			return -1;		}		return 0;	}	remount_all_slave();	if (run_lxc_hooks(name, ""pre-mount"", conf, lxcpath, NULL)) {		ERROR(""failed to run pre-mount hooks for container '%s'."", name);		return -1;	}	if (setup_rootfs(conf)) {		ERROR(""failed to setup rootfs for '%s'"", name);		return -1;	}	conf->rootfs_setup = true;	return 0;}",13954
30,45,CVE-2014-5045,11,"unsigned int full_name_hash(const unsigned char *name, unsigned int len){	unsigned long a, mask;	unsigned long hash = 0;	for (;;) {		a = load_unaligned_zeropad(name);		if (len < sizeof(unsigned long))			break;		hash += a;		hash *= 9;		name += sizeof(unsigned long);		len -= sizeof(unsigned long);		if (!len)			goto done;	}	mask = bytemask_from_count(len);	hash += mask & a;done:	return fold_hash(hash);}",10727
45,314,CVE-2018-6198,11,mouse_scroll_line(void){    if (relative_wheel_scroll)	return (relative_wheel_scroll_ratio * LASTLINE + 99) / 100;    else	return fixed_wheel_scroll_count;},25429
2,327,CVE-2018-6198,11,"compare_table(struct rc_search_table *a, struct rc_search_table *b){    return strcmp(a->param->name, b->param->name);}",25442
6,37,CVE-2016-8645,12,"static void tcp_v6_reqsk_send_ack(const struct sock *sk, struct sk_buff *skb,				  struct request_sock *req){	 	 	tcp_v6_send_ack(sk, skb, (sk->sk_state == TCP_LISTEN) ?			tcp_rsk(req)->snt_isn + 1 : tcp_sk(sk)->snd_nxt,			tcp_rsk(req)->rcv_nxt,			req->rsk_rcv_wnd >> inet_rsk(req)->rcv_wscale,			tcp_time_stamp, req->ts_recent, sk->sk_bound_dev_if,			tcp_v6_md5_do_lookup(sk, &ipv6_hdr(skb)->daddr),			0, 0);}",15563
58,301,CVE-2016-3839,12,"void    btif_dm_load_ble_local_keys(void){    memset(&ble_local_key_cb, 0, sizeof(btif_dm_local_key_cb_t)); if (btif_storage_get_ble_local_key(BTIF_DM_LE_LOCAL_KEY_ER,(char*)&ble_local_key_cb.er[0],                                       BT_OCTET16_LEN)== BT_STATUS_SUCCESS) {        ble_local_key_cb.is_er_rcvd = TRUE;        BTIF_TRACE_DEBUG(""%s BLE ER key loaded"",__FUNCTION__ ); } if ((btif_storage_get_ble_local_key(BTIF_DM_LE_LOCAL_KEY_IR,(char*)&ble_local_key_cb.id_keys.ir[0],                                        BT_OCTET16_LEN)== BT_STATUS_SUCCESS )&& (btif_storage_get_ble_local_key(BTIF_DM_LE_LOCAL_KEY_IRK, (char*)&ble_local_key_cb.id_keys.irk[0],                                        BT_OCTET16_LEN)== BT_STATUS_SUCCESS)&& (btif_storage_get_ble_local_key(BTIF_DM_LE_LOCAL_KEY_DHK,(char*)&ble_local_key_cb.id_keys.dhk[0],                                        BT_OCTET16_LEN)== BT_STATUS_SUCCESS)) {        ble_local_key_cb.is_id_keys_rcvd = TRUE;        BTIF_TRACE_DEBUG(""%s BLE ID keys loaded"",__FUNCTION__ ); }}",30429
43,331,CVE-2016-3839,12,"int uinput_driver_check(){ int i; for (i=0; i < MAX_UINPUT_PATHS; i++) { if (access(uinput_dev_path[i], O_RDWR) == 0) { return 0; } }    BTIF_TRACE_ERROR(""%s ERROR: uinput device is not in the system"", __FUNCTION__); return -1;}",30459
85,156,CVE-2016-3698,12,"void ndp_msgra_reachable_time_set(struct ndp_msgra *msgra,				  int reachable_time){	msgra->ra->nd_ra_reachable = htonl(reachable_time);}",17272
68,164,CVE-2016-3698,12,"void ndp_set_log_priority(struct ndp *ndp, int priority){	ndp->log_priority = priority;}",17280
65,175,CVE-2016-1237,12,"static int nfs4_acl_nfsv4_to_posix(struct nfs4_acl *acl,		struct posix_acl **pacl, struct posix_acl **dpacl,		unsigned int flags){	struct posix_acl_state effective_acl_state, default_acl_state;	struct nfs4_ace *ace;	int ret;	ret = init_state(&effective_acl_state, acl->naces);	if (ret)		return ret;	ret = init_state(&default_acl_state, acl->naces);	if (ret)		goto out_estate;	ret = -EINVAL;	for (ace = acl->aces; ace < acl->aces + acl->naces; ace++) {		if (ace->type != NFS4_ACE_ACCESS_ALLOWED_ACE_TYPE &&		    ace->type != NFS4_ACE_ACCESS_DENIED_ACE_TYPE)			goto out_dstate;		if (ace->flag & ~NFS4_SUPPORTED_FLAGS)			goto out_dstate;		if ((ace->flag & NFS4_INHERITANCE_FLAGS) == 0) {			process_one_v4_ace(&effective_acl_state, ace);			continue;		}		if (!(flags & NFS4_ACL_DIR))			goto out_dstate;		 		process_one_v4_ace(&default_acl_state, ace);		if (!(ace->flag & NFS4_ACE_INHERIT_ONLY_ACE))			process_one_v4_ace(&effective_acl_state, ace);	}	*pacl = posix_state_to_acl(&effective_acl_state, flags);	if (IS_ERR(*pacl)) {		ret = PTR_ERR(*pacl);		*pacl = NULL;		goto out_dstate;	}	*dpacl = posix_state_to_acl(&default_acl_state,						flags | NFS4_ACL_TYPE_DEFAULT);	if (IS_ERR(*dpacl)) {		ret = PTR_ERR(*dpacl);		*dpacl = NULL;		posix_acl_release(*pacl);		*pacl = NULL;		goto out_dstate;	}	sort_pacl(*pacl);	sort_pacl(*dpacl);	ret = 0;out_dstate:	free_state(&default_acl_state);out_estate:	free_state(&effective_acl_state);	return ret;}",18187
25,344,CVE-2016-3839,12,static void init_poll(int h){ int i;    ts[h].poll_count = 0;    ts[h].thread_id = -1;    ts[h].callback = NULL;    ts[h].cmd_callback = NULL; for(i = 0; i < MAX_POLL; i++) {        ts[h].ps[i].pfd.fd = -1;        ts[h].psi[i] = -1; }    init_cmd_fd(h);},30472
1,299,CVE-2016-3839,12,"static void btif_dm_ble_test_end_cback(void *p){    btif_transfer_context(btif_dm_generic_evt, BTIF_DM_CB_LE_TEST_END, (char *)p, 3, NULL);}",30427
35,45,CVE-2016-6198,12,"struct file *do_file_open_root(struct dentry *dentry, struct vfsmount *mnt,		const char *name, const struct open_flags *op){	struct nameidata nd;	struct file *file;	struct filename *filename;	int flags = op->lookup_flags | LOOKUP_ROOT;	nd.root.mnt = mnt;	nd.root.dentry = dentry;	if (d_is_symlink(dentry) && op->intent & LOOKUP_OPEN)		return ERR_PTR(-ELOOP);	filename = getname_kernel(name);	if (IS_ERR(filename))		return ERR_CAST(filename);	set_nameidata(&nd, -1, filename);	file = path_openat(&nd, op, flags | LOOKUP_RCU);	if (unlikely(file == ERR_PTR(-ECHILD)))		file = path_openat(&nd, op, flags);	if (unlikely(file == ERR_PTR(-ESTALE)))		file = path_openat(&nd, op, flags | LOOKUP_REVAL);	restore_nameidata();	putname(filename);	return file;}",16203
37,367,CVE-2016-3839,12,static void uipc_check_task_flags_locked(void){ int i; for (i=0; i<UIPC_CH_NUM; i++) { if (uipc_main.ch[i].task_evt_flags & UIPC_TASK_FLAG_DISCONNECT_CHAN) {            uipc_main.ch[i].task_evt_flags &= ~UIPC_TASK_FLAG_DISCONNECT_CHAN;            uipc_close_ch_locked(i); }   }},30495
84,270,CVE-2016-3839,12,"static int adev_set_master_volume(struct audio_hw_device *dev, float volume){    UNUSED(dev);    UNUSED(volume);    FNLOG(); return -ENOSYS;}",30398
56,192,CVE-2016-10030,12,"static void _fb_wrlock(void){	slurm_mutex_lock(&file_bcast_mutex);	fb_write_wait_lock++;	while (1) {		if ((fb_read_lock == 0) && (fb_write_lock == 0)) {			fb_write_lock++;			fb_write_wait_lock--;			break;		} else {	 			pthread_cond_wait(&file_bcast_cond, &file_bcast_mutex);		}	}	slurm_mutex_unlock(&file_bcast_mutex);}",22578
17,245,CVE-2016-1638,12,int IsUsingWindowService() {  return IsSingleProcessMash() || IsMultiProcessMash();},29764
10,343,CVE-2016-3839,12,"static inline void init_cmd_fd(int h){    asrt(ts[h].cmd_fdr == -1 && ts[h].cmd_fdw == -1); if(socketpair(AF_UNIX, SOCK_STREAM, 0, &ts[h].cmd_fdr) < 0) {        APPL_TRACE_ERROR(""socketpair failed: %s"", strerror(errno)); return; }    APPL_TRACE_DEBUG(""h:%d, cmd_fdr:%d, cmd_fdw:%d"", h, ts[h].cmd_fdr, ts[h].cmd_fdw);    add_poll(h, ts[h].cmd_fdr, 0, SOCK_THREAD_FD_RD, 0);}",30471
21,83,CVE-2016-5104,12,void socket_set_verbose(int level){	verbose = level;},16520
12,191,CVE-2016-10030,12,static void _fb_rdunlock(void){	slurm_mutex_lock(&file_bcast_mutex);	fb_read_lock--;	pthread_cond_broadcast(&file_bcast_cond);	slurm_mutex_unlock(&file_bcast_mutex);},22577
4,313,CVE-2016-3839,12,"static inline int bta_role_to_btpan(int bta_pan_role){ int btpan_role = 0;    BTIF_TRACE_DEBUG(""bta_pan_role:0x%x"", bta_pan_role); if (bta_pan_role & PAN_ROLE_NAP_SERVER)        btpan_role |= BTPAN_ROLE_PANNAP; if (bta_pan_role & PAN_ROLE_CLIENT)        btpan_role |= BTPAN_ROLE_PANU; return btpan_role;}",30441
18,217,CVE-2016-6255,12,static void ToUpperCase(	 	char *s){	while (*s) {		*s = (char)toupper(*s);		++s;	}},22819
83,225,CVE-2019-12589,12,"void fslib_install_list(const char *lib_list) {	assert(lib_list);	if (arg_debug || arg_debug_private_lib)		printf(""    fslib_install_list  %s\n"", lib_list);	char *dlist = strdup(lib_list);	if (!dlist)		errExit(""strdup"");	char *ptr = strtok(dlist, "","");	if (!ptr) {		fprintf(stderr, ""Error: invalid private-lib argument\n"");		exit(1);	}	install_list_entry(ptr);	while ((ptr = strtok(NULL, "","")) != NULL)		install_list_entry(ptr);	free(dlist);	fs_logger_print();}",26858
54,142,CVE-2016-3698,12,"void ndp_msgna_flag_router_set(struct ndp_msgna *msgna, int flag_router){	if (flag_router)		msgna->na->nd_na_flags_reserved |= ND_NA_FLAG_ROUTER;	else		msgna->na->nd_na_flags_reserved &= ~ND_NA_FLAG_ROUTER;}",17258
3,364,CVE-2016-3839,12,"static int set_discoverable(int argc, char **argv) { if (argc != 1) {    printf(""Discoverable mode not specified.\n""); return 1; } if (strcmp(argv[0], ""true"") && strcmp(argv[0], ""false"")) {    printf(""Invalid discoverable mode '%s'.\n"", argv[0]); return 2; } int packet[] = { 0x1A, 0x0C, 0x01, 0x00 }; if (argv[0][0] == 't')    packet[ARRAY_SIZE(packet) - 1] = 0x03; return !write_hci_command(HCI_PACKET_COMMAND, packet, ARRAY_SIZE(packet));}",30492
32,88,CVE-2016-3713,12,void kvm_vcpu_mtrr_init(struct kvm_vcpu *vcpu){	INIT_LIST_HEAD(&vcpu->arch.mtrr_state.head);},17192
8,145,CVE-2016-3698,12,struct ndp_msgns *ndp_msgns(struct ndp_msg *msg){	if (ndp_msg_type(msg) != NDP_MSG_NS)		return NULL;	return &msg->nd_msg.ns;},17261
90,91,CVE-2016-3713,12,"static int mtrr_lookup_fixed_start(struct mtrr_iter *iter){	int seg, index;	if (!fixed_mtrr_is_enabled(iter->mtrr_state))		return false;	seg = fixed_mtrr_addr_to_seg(iter->start);	if (seg < 0)		return false;	iter->fixed = true;	index = fixed_mtrr_addr_seg_to_range_index(iter->start, seg);	iter->index = index;	iter->seg = seg;	return true;}",17195
40,57,CVE-2016-6198,12,"struct dentry *lock_rename(struct dentry *p1, struct dentry *p2){	struct dentry *p;	if (p1 == p2) {		inode_lock_nested(p1->d_inode, I_MUTEX_PARENT);		return NULL;	}	mutex_lock(&p1->d_inode->i_sb->s_vfs_rename_mutex);	p = d_ancestor(p2, p1);	if (p) {		inode_lock_nested(p2->d_inode, I_MUTEX_PARENT);		inode_lock_nested(p1->d_inode, I_MUTEX_CHILD);		return p;	}	p = d_ancestor(p1, p2);	if (p) {		inode_lock_nested(p1->d_inode, I_MUTEX_PARENT);		inode_lock_nested(p2->d_inode, I_MUTEX_CHILD);		return p;	}	inode_lock_nested(p1->d_inode, I_MUTEX_PARENT);	inode_lock_nested(p2->d_inode, I_MUTEX_PARENT2);	return NULL;}",16215
89,222,CVE-2016-6255,12,"int web_server_init(){	int ret = 0;	if (bWebServerState == WEB_SERVER_DISABLED) {		 		media_list_init();		membuffer_init(&gDocumentRootDir);		glob_alias_init();		pVirtualDirList = NULL;		 		virtualDirCallback.get_info = NULL;		virtualDirCallback.open = NULL;		virtualDirCallback.read = NULL;		virtualDirCallback.write = NULL;		virtualDirCallback.seek = NULL;		virtualDirCallback.close = NULL;		if (ithread_mutex_init(&gWebMutex, NULL) == -1)			ret = UPNP_E_OUTOF_MEMORY;		else			bWebServerState = WEB_SERVER_ENABLED;	}	return ret;}",22824
59,103,CVE-2016-3698,12,struct in6_addr *ndp_msg_addrto(struct ndp_msg *msg){	return &msg->addrto;},17219
7,202,CVE-2016-10030,12,"static int _match_jobid(void *listentry, void *key){	int *job0 = (int *)listentry;	int *job1 = (int *)key;	return (*job0 == *job1);}",22588
29,107,CVE-2016-3698,12,void ndp_msg_destroy(struct ndp_msg *msg){	free(msg);},17223
72,24,CVE-2016-8645,12,"static int tcp6_seq_show(struct seq_file *seq, void *v){	struct tcp_iter_state *st;	struct sock *sk = v;	if (v == SEQ_START_TOKEN) {		seq_puts(seq,			 ""  sl  ""			 ""local_address                         ""			 ""remote_address                        ""			 ""st tx_queue rx_queue tr tm->when retrnsmt""			 ""   uid  timeout inode\n"");		goto out;	}	st = seq->private;	if (sk->sk_state == TCP_TIME_WAIT)		get_timewait6_sock(seq, v, st->num);	else if (sk->sk_state == TCP_NEW_SYN_RECV)		get_openreq6(seq, v, st->num);	else		get_tcp6_sock(seq, v, st->num);out:	return 0;}",15550
23,277,CVE-2016-3839,12,"static int in_dump(const struct audio_stream *stream, int fd){    UNUSED(stream);    UNUSED(fd);    FNLOG(); return 0;}",30405
31,361,CVE-2016-3839,12,"static void init_layer_interface() { if (!interface_created) {    interface.send_low_power_command = low_power_manager->post_command;    interface.do_postload = do_postload;    interface.event_dispatcher = data_dispatcher_new(""hci_layer""); if (!interface.event_dispatcher) {      LOG_ERROR(""%s could not create upward dispatcher."", __func__); return; }    interface.set_data_queue = set_data_queue;    interface.transmit_command = transmit_command;    interface.transmit_command_futured = transmit_command_futured;    interface.transmit_downward = transmit_downward;    interface_created = true; }}",30489
71,148,CVE-2016-3698,12,int ndp_msgra_curhoplimit(struct ndp_msgra *msgra){	return msgra->ra->nd_ra_curhoplimit;},17264
57,161,CVE-2016-3698,12,int ndp_msgra_router_lifetime(struct ndp_msgra *msgra){	return ntohs(msgra->ra->nd_ra_router_lifetime);},17277
80,295,CVE-2016-3839,12,"void uhid_set_non_blocking(int fd){ int opts = fcntl(fd, F_GETFL); if (opts < 0)        APPL_TRACE_ERROR(""%s() Getting flags failed (%s)"", __func__, strerror(errno));    opts |= O_NONBLOCK; if (fcntl(fd, F_SETFL, opts) < 0)        APPL_TRACE_EVENT(""%s() Setting non-blocking flag failed (%s)"", __func__, strerror(errno));}",30423
9,13,CVE-2016-8645,12,"int tcp_v4_conn_request(struct sock *sk, struct sk_buff *skb){	 	if (skb_rtable(skb)->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))		goto drop;	return tcp_conn_request(&tcp_request_sock_ops,				&tcp_request_sock_ipv4_ops, sk, skb);drop:	tcp_listendrop(sk);	return 0;}",15539
66,122,CVE-2016-3698,12,"int ndp_msg_opt_route_lifetime(struct ndp_msg *msg, int offset){	struct __nd_opt_route_info *ri =			ndp_msg_payload_opts_offset(msg, offset);	return ntohl(ri->nd_opt_ri_lifetime);}",17238
64,16,CVE-2016-8645,12,"static void tcp_v4_init_req(struct request_sock *req,			    const struct sock *sk_listener,			    struct sk_buff *skb){	struct inet_request_sock *ireq = inet_rsk(req);	sk_rcv_saddr_set(req_to_sk(req), ip_hdr(skb)->daddr);	sk_daddr_set(req_to_sk(req), ip_hdr(skb)->saddr);	ireq->opt = tcp_v4_save_options(skb);}",15542
41,80,CVE-2016-6198,12,"int vfs_link(struct dentry *old_dentry, struct inode *dir, struct dentry *new_dentry, struct inode **delegated_inode){	struct inode *inode = old_dentry->d_inode;	unsigned max_links = dir->i_sb->s_max_links;	int error;	if (!inode)		return -ENOENT;	error = may_create(dir, new_dentry);	if (error)		return error;	if (dir->i_sb != inode->i_sb)		return -EXDEV;	 	if (IS_APPEND(inode) || IS_IMMUTABLE(inode))		return -EPERM;	if (!dir->i_op->link)		return -EPERM;	if (S_ISDIR(inode->i_mode))		return -EPERM;	error = security_inode_link(old_dentry, dir, new_dentry);	if (error)		return error;	inode_lock(inode);	 	if (inode->i_nlink == 0 && !(inode->i_state & I_LINKABLE))		error =  -ENOENT;	else if (max_links && inode->i_nlink >= max_links)		error = -EMLINK;	else {		error = try_break_deleg(inode, delegated_inode);		if (!error)			error = dir->i_op->link(old_dentry, dir, new_dentry);	}	if (!error && (inode->i_state & I_LINKABLE)) {		spin_lock(&inode->i_lock);		inode->i_state &= ~I_LINKABLE;		spin_unlock(&inode->i_lock);	}	inode_unlock(inode);	if (!error)		fsnotify_link(dir, inode, new_dentry);	return error;}",16238
49,2,CVE-2016-8645,12,"static void get_openreq4(const struct request_sock *req,			 struct seq_file *f, int i){	const struct inet_request_sock *ireq = inet_rsk(req);	long delta = req->rsk_timer.expires - jiffies;	seq_printf(f, ""%4d: %08X:%04X %08X:%04X""		"" %02X %08X:%08X %02X:%08lX %08X %5u %8d %u %d %pK"",		i,		ireq->ir_loc_addr,		ireq->ir_num,		ireq->ir_rmt_addr,		ntohs(ireq->ir_rmt_port),		TCP_SYN_RECV,		0, 0,  		1,     		jiffies_delta_to_clock_t(delta),		req->num_timeout,		from_kuid_munged(seq_user_ns(f),				 sock_i_uid(req->rsk_listener)),		0,   		0,  		0,		req);}",15528
15,353,CVE-2016-3839,12,static void set_api_wants_to_log(int value) {  logging_enabled_via_api = value;  update_logging();},30481
44,348,CVE-2016-3839,12,"void dump_bin(const char* title, const char* data, int size){ char line_buff[256]; char *line; int i, j, addr; const int width = 16;    LOG_DEBUG(""%s, size:%d, dump started {"", title, size); if(size <= 0) return;    line = line_buff; *line++ = ' '; *line++ = ' '; *line++ = ' '; *line++ = ' '; *line++ = ' '; *line++ = ' '; for(j = 0; j < width; j++) {        byte2hex((const char*)&j, &line); *line++ = ' '; } *line = 0;    PRINT(line_buff); for(i = 0; i < size / width; i++) {        line = line_buff;        addr = i*width;        word2hex((const char*)&addr, &line); *line++ = ':'; *line++ = ' '; for(j = 0; j < width; j++) {            byte2hex(&data[j], &line); *line++ = ' '; } for(j = 0; j < width; j++)            byte2char(data++, &line); *line = 0;        PRINT(line_buff); } int leftover = size % width; if(leftover > 0) {        line = line_buff;        addr = i*width;        word2hex((const char*)&addr, &line); *line++ = ':'; *line++ = ' '; for(j = 0; j < leftover; j++) {            byte2hex(&data[j], &line); *line++ = ' '; } for(; j < width; j++) { *line++ = ' '; *line++ = ' '; *line++ = ' '; } for(j = 0; j < leftover; j++)            byte2char(data++, &line); *line = 0;        PRINT(line_buff); }    LOG_DEBUG(""%s, size:%d, dump ended }"", title, size);}",30476
22,99,CVE-2016-3698,12,int ndp_call_eventfd_handler(struct ndp *ndp){	return ndp_sock_recv(ndp);},17215
34,328,CVE-2016-3839,12,static void initialize_transaction(int lbl){    pthread_mutex_lock(&device.lbllock); if(lbl < MAX_TRANSACTIONS_PER_SESSION) {       device.transaction[lbl].lbl = lbl;       device.transaction[lbl].in_use=FALSE;       device.transaction[lbl].handle=0; }    pthread_mutex_unlock(&device.lbllock);},30456
52,294,CVE-2016-3839,12,"void bta_hh_co_destroy(int fd){ struct uhid_event ev;    memset(&ev, 0, sizeof(ev));    ev.type = UHID_DESTROY;    uhid_write(fd, &ev);    APPL_TRACE_DEBUG(""%s: Closing fd=%d"", __func__, fd);    close(fd);}",30422
93,236,CVE-2016-6198,12,"char *file_path(struct file *filp, char *buf, int buflen){	return d_path(&filp->f_path, buf, buflen);}",28389
19,281,CVE-2016-3839,12,"static int in_set_gain(struct audio_stream_in *stream, float gain){    UNUSED(stream);    UNUSED(gain);    FNLOG(); return 0;}",30409
82,63,CVE-2016-6198,12,"static inline int may_follow_link(struct nameidata *nd){	const struct inode *inode;	const struct inode *parent;	if (!sysctl_protected_symlinks)		return 0;	 	inode = nd->link_inode;	if (uid_eq(current_cred()->fsuid, inode->i_uid))		return 0;	 	parent = nd->inode;	if ((parent->i_mode & (S_ISVTX|S_IWOTH)) != (S_ISVTX|S_IWOTH))		return 0;	 	if (uid_eq(parent->i_uid, inode->i_uid))		return 0;	if (nd->flags & LOOKUP_RCU)		return -ECHILD;	audit_log_link_denied(""follow_link"", &nd->stack[0].link);	return -EACCES;}",16221
53,102,CVE-2016-3698,12,int ndp_get_log_priority(struct ndp *ndp){	return ndp->log_priority;},17218
50,335,CVE-2016-3839,12,static int is_init_done(void) { return pth != -1;},30463
38,9,CVE-2016-8645,12,"static void *tcp_seek_last_pos(struct seq_file *seq){	struct tcp_iter_state *st = seq->private;	int offset = st->offset;	int orig_num = st->num;	void *rc = NULL;	switch (st->state) {	case TCP_SEQ_STATE_LISTENING:		if (st->bucket >= INET_LHTABLE_SIZE)			break;		st->state = TCP_SEQ_STATE_LISTENING;		rc = listening_get_next(seq, NULL);		while (offset-- && rc)			rc = listening_get_next(seq, rc);		if (rc)			break;		st->bucket = 0;		st->state = TCP_SEQ_STATE_ESTABLISHED;		 	case TCP_SEQ_STATE_ESTABLISHED:		if (st->bucket > tcp_hashinfo.ehash_mask)			break;		rc = established_get_first(seq);		while (offset-- && rc)			rc = established_get_next(seq, rc);	}	st->num = orig_num;	return rc;}",15535
81,46,CVE-2016-6198,12,"static int do_last(struct nameidata *nd,		   struct file *file, const struct open_flags *op,		   int *opened){	struct dentry *dir = nd->path.dentry;	int open_flag = op->open_flag;	int will_truncate = (open_flag & O_TRUNC) != 0;	int got_write = false;	int acc_mode = op->acc_mode;	unsigned seq;	struct inode *inode;	struct path save_parent = { .dentry = NULL, .mnt = NULL };	struct path path;	int retried = false;	int error;	nd->flags &= ~LOOKUP_PARENT;	nd->flags |= op->intent;	if (nd->last_type != LAST_NORM) {		error = handle_dots(nd, nd->last_type);		if (unlikely(error))			return error;		goto finish_open;	}	if (!(open_flag & O_CREAT)) {		if (nd->last.name[nd->last.len])			nd->flags |= LOOKUP_FOLLOW | LOOKUP_DIRECTORY;		 		error = lookup_fast(nd, &path, &inode, &seq);		if (likely(error > 0))			goto finish_lookup;		if (error < 0)			return error;		BUG_ON(nd->inode != dir->d_inode);		BUG_ON(nd->flags & LOOKUP_RCU);	} else {		 		 		error = complete_walk(nd);		if (error)			return error;		audit_inode(nd->name, dir, LOOKUP_PARENT);		 		if (unlikely(nd->last.name[nd->last.len]))			return -EISDIR;	}retry_lookup:	if (op->open_flag & (O_CREAT | O_TRUNC | O_WRONLY | O_RDWR)) {		error = mnt_want_write(nd->path.mnt);		if (!error)			got_write = true;		 	}	inode_lock(dir->d_inode);	error = lookup_open(nd, &path, file, op, got_write, opened);	inode_unlock(dir->d_inode);	if (error <= 0) {		if (error)			goto out;		if ((*opened & FILE_CREATED) ||		    !S_ISREG(file_inode(file)->i_mode))			will_truncate = false;		audit_inode(nd->name, file->f_path.dentry, 0);		goto opened;	}	if (*opened & FILE_CREATED) {		 		open_flag &= ~O_TRUNC;		will_truncate = false;		acc_mode = 0;		path_to_nameidata(&path, nd);		goto finish_open_created;	}	 	if (got_write) {		mnt_drop_write(nd->path.mnt);		got_write = false;	}	if (unlikely(d_is_negative(path.dentry))) {		path_to_nameidata(&path, nd);		return -ENOENT;	}	 	audit_inode(nd->name, path.dentry, 0);	if (unlikely((open_flag & (O_EXCL | O_CREAT)) == (O_EXCL | O_CREAT))) {		path_to_nameidata(&path, nd);		return -EEXIST;	}	error = follow_managed(&path, nd);	if (unlikely(error < 0))		return error;	seq = 0;	 	inode = d_backing_inode(path.dentry);finish_lookup:	if (nd->depth)		put_link(nd);	error = should_follow_link(nd, &path, nd->flags & LOOKUP_FOLLOW,				   inode, seq);	if (unlikely(error))		return error;	if ((nd->flags & LOOKUP_RCU) || nd->path.mnt != path.mnt) {		path_to_nameidata(&path, nd);	} else {		save_parent.dentry = nd->path.dentry;		save_parent.mnt = mntget(path.mnt);		nd->path.dentry = path.dentry;	}	nd->inode = inode;	nd->seq = seq;	 finish_open:	error = complete_walk(nd);	if (error) {		path_put(&save_parent);		return error;	}	audit_inode(nd->name, nd->path.dentry, 0);	if (unlikely(d_is_symlink(nd->path.dentry)) && !(open_flag & O_PATH)) {		error = -ELOOP;		goto out;	}	error = -EISDIR;	if ((open_flag & O_CREAT) && d_is_dir(nd->path.dentry))		goto out;	error = -ENOTDIR;	if ((nd->flags & LOOKUP_DIRECTORY) && !d_can_lookup(nd->path.dentry))		goto out;	if (!d_is_reg(nd->path.dentry))		will_truncate = false;	if (will_truncate) {		error = mnt_want_write(nd->path.mnt);		if (error)			goto out;		got_write = true;	}finish_open_created:	if (likely(!(open_flag & O_PATH))) {		error = may_open(&nd->path, acc_mode, open_flag);		if (error)			goto out;	}	BUG_ON(*opened & FILE_OPENED);  	error = vfs_open(&nd->path, file, current_cred());	if (!error) {		*opened |= FILE_OPENED;	} else {		if (error == -EOPENSTALE)			goto stale_open;		goto out;	}opened:	error = open_check_o_direct(file);	if (error)		goto exit_fput;	error = ima_file_check(file, op->acc_mode, *opened);	if (error)		goto exit_fput;	if (will_truncate) {		error = handle_truncate(file);		if (error)			goto exit_fput;	}out:	if (unlikely(error > 0)) {		WARN_ON(1);		error = -EINVAL;	}	if (got_write)		mnt_drop_write(nd->path.mnt);	path_put(&save_parent);	return error;exit_fput:	fput(file);	goto out;stale_open:	 	if (!save_parent.dentry || retried)		goto out;	BUG_ON(save_parent.dentry != dir);	path_put(&nd->path);	nd->path = save_parent;	nd->inode = dir->d_inode;	save_parent.mnt = NULL;	save_parent.dentry = NULL;	if (got_write) {		mnt_drop_write(nd->path.mnt);		got_write = false;	}	retried = true;	goto retry_lookup;}",16204
27,147,CVE-2016-3698,12,struct ndp_msgra *ndp_msgra(struct ndp_msg *msg){	if (ndp_msg_type(msg) != NDP_MSG_RA)		return NULL;	return &msg->nd_msg.ra;},17263
55,283,CVE-2016-3839,12,"static int in_set_sample_rate(struct audio_stream *stream, int rate){ struct a2dp_stream_in *in = (struct a2dp_stream_in *)stream;    FNLOG(); if (in->common.cfg.rate > 0 && in->common.cfg.rate == rate) return 0; else return -1;}",30411
87,60,CVE-2016-6198,12,"struct dentry *lookup_one_len(const char *name, struct dentry *base, int len){	struct qstr this;	unsigned int c;	int err;	WARN_ON_ONCE(!inode_is_locked(base->d_inode));	this.name = name;	this.len = len;	this.hash = full_name_hash(name, len);	if (!len)		return ERR_PTR(-EACCES);	if (unlikely(name[0] == '.')) {		if (len < 2 || (len == 2 && name[1] == '.'))			return ERR_PTR(-EACCES);	}	while (len--) {		c = *(const unsigned char *)name++;		if (c == '/' || c == '\0')			return ERR_PTR(-EACCES);	}	 	if (base->d_flags & DCACHE_OP_HASH) {		int err = base->d_op->d_hash(base, &this);		if (err < 0)			return ERR_PTR(err);	}	err = inode_permission(base->d_inode, MAY_EXEC);	if (err)		return ERR_PTR(err);	return __lookup_hash(&this, base, 0);}",16218
0,113,CVE-2016-3698,12,"struct in6_addr *ndp_msg_opt_prefix(struct ndp_msg *msg, int offset){	struct nd_opt_prefix_info *pi =			ndp_msg_payload_opts_offset(msg, offset);	return &pi->nd_opt_pi_prefix;}",17229
33,100,CVE-2016-3698,12,void ndp_close(struct ndp *ndp){	ndp_sock_close(ndp);	free(ndp);},17216
92,318,CVE-2016-3839,12,static void btpan_jni_cleanup(){    pan_disable();    jni_initialized = false;},30446
77,204,CVE-2016-10030,12,"_pause_for_job_completion (int job_id, char *nodes, int max_time){	int sec = 0;	int pause = 1;	int rc = false;	while ((sec < max_time) || (max_time == 0)) {		rc = _job_still_running (job_id);		if (!rc)			break;		if ((max_time == 0) && (sec > 1)) {			_terminate_all_steps(job_id, true);		}		if (sec > 10) {			 			if (max_time)				pause = MIN((max_time - sec), 10);			else				pause = 10;		}		sleep(pause);		sec += pause;	}	 	return (!rc);}",22590
42,155,CVE-2016-3698,12,int ndp_msgra_reachable_time(struct ndp_msgra *msgra){	return ntohl(msgra->ra->nd_ra_reachable);},17271
5,221,CVE-2016-6255,12,"void web_server_destroy(void){	if (bWebServerState == WEB_SERVER_ENABLED) {		membuffer_destroy(&gDocumentRootDir);		alias_release(&gAliasDoc);		ithread_mutex_lock(&gWebMutex);		memset(&gAliasDoc, 0, sizeof(struct xml_alias_t));		ithread_mutex_unlock(&gWebMutex);		ithread_mutex_destroy(&gWebMutex);		bWebServerState = WEB_SERVER_DISABLED;	}}",22823
26,168,CVE-2016-1237,12,"nfsd3_proc_null(struct svc_rqst *rqstp, void *argp, void *resp){	return nfs_ok;}",18180
67,174,CVE-2016-1237,12,int nfs4_acl_bytes(int entries){	return sizeof(struct nfs4_acl) + entries * sizeof(struct nfs4_ace);},18186
75,325,CVE-2016-3839,12,"static void cleanup(){    BTIF_TRACE_EVENT(""## %s ##"", __FUNCTION__);    close_uinput(); if (bt_rc_callbacks) {        bt_rc_callbacks = NULL; }    memset(&btif_rc_cb, 0, sizeof(btif_rc_cb_t));    lbl_destroy();    BTIF_TRACE_EVENT(""## %s ## completed"", __FUNCTION__);}",30453
79,69,CVE-2016-6198,12,"const char *page_get_link(struct dentry *dentry, struct inode *inode,			  struct delayed_call *callback){	char *kaddr;	struct page *page;	struct address_space *mapping = inode->i_mapping;	if (!dentry) {		page = find_get_page(mapping, 0);		if (!page)			return ERR_PTR(-ECHILD);		if (!PageUptodate(page)) {			put_page(page);			return ERR_PTR(-ECHILD);		}	} else {		page = read_mapping_page(mapping, 0, NULL);		if (IS_ERR(page))			return (char*)page;	}	set_delayed_call(callback, page_put_link, page);	BUG_ON(mapping_gfp_mask(mapping) & __GFP_HIGHMEM);	kaddr = page_address(page);	nd_terminate_link(kaddr, inode->i_size, PAGE_SIZE - 1);	return kaddr;}",16227
47,290,CVE-2016-3839,12,"static int start_audio_datapath(struct a2dp_stream_common *common){    INFO(""state %d"", common->state); if (common->ctrl_fd == AUDIO_SKT_DISCONNECTED) {        INFO(""%s AUDIO_SKT_DISCONNECTED"", __func__); return -1; } int oldstate = common->state;    common->state = AUDIO_A2DP_STATE_STARTING; int a2dp_status = a2dp_command(common, A2DP_CTRL_CMD_START); if (a2dp_status < 0) {        ERROR(""%s Audiopath start failed (status %d)"", __func__, a2dp_status);        common->state = oldstate; return -1; } else if (a2dp_status == A2DP_CTRL_ACK_INCALL_FAILURE) {        ERROR(""%s Audiopath start failed - in call, move to suspended"", __func__);        common->state = oldstate; return -1; }   if (common->audio_fd == AUDIO_SKT_DISCONNECTED) {        common->audio_fd = skt_connect(A2DP_DATA_PATH, common->buffer_sz); if (common->audio_fd < 0) {            common->state = oldstate; return -1; }        common->state = AUDIO_A2DP_STATE_STARTED; } return 0;}",30418
78,210,CVE-2016-10030,12,_waiter_create(int jobid){	struct waiter *wp = xmalloc(sizeof(struct waiter));	wp->jobid = jobid;	wp->thd   = pthread_self();	return wp;},22596
74,276,CVE-2016-3839,12,"static int check_a2dp_ready(struct a2dp_stream_common *common){ if (a2dp_command(common, A2DP_CTRL_CMD_CHECK_READY) < 0) {        ERROR(""check a2dp ready failed""); return -1; } return 0;}",30404
48,219,CVE-2016-6255,12,static void alias_release(	 	struct xml_alias_t *alias){	ithread_mutex_lock(&gWebMutex);	 	if (!is_valid_alias(alias)) {		ithread_mutex_unlock(&gWebMutex);		return;	}	assert(*alias->ct > 0);	*alias->ct -= 1;	if (*alias->ct <= 0) {		membuffer_destroy(&alias->doc);		membuffer_destroy(&alias->name);		free(alias->ct);	}	ithread_mutex_unlock(&gWebMutex);},22821
86,223,CVE-2019-12589,12,"void fslib_copy_dir(const char *full_path) {	assert(full_path);	if (arg_debug || arg_debug_private_lib)		printf(""    fslib_copy_dir %s\n"", full_path);	struct stat s;	if (stat(full_path, &s) != 0 || s.st_uid != 0 || !S_ISDIR(s.st_mode) || access(full_path, R_OK))		return;	char *dir_name = strrchr(full_path, '/');	assert(dir_name);	dir_name++;	assert(*dir_name != '\0');	char *dest;	if (asprintf(&dest, ""%s/%s"", build_dest_dir(full_path), dir_name) == -1)		errExit(""asprintf"");	if (stat(dest, &s) == 0) {		free(dest);		return;	}	mkdir_attr(dest, 0755, 0, 0);	if (mount(full_path, dest, NULL, MS_BIND|MS_REC, NULL) < 0 ||		mount(NULL, dest, NULL, MS_BIND|MS_REMOUNT|MS_NOSUID|MS_NODEV|MS_REC, NULL) < 0)		errExit(""mount bind"");	fs_logger2(""clone"", full_path);	fs_logger2(""mount"", full_path);	dir_cnt++;	free(dest);}",26856
88,51,CVE-2016-6198,12,static int follow_dotdot(struct nameidata *nd){	while(1) {		struct dentry *old = nd->path.dentry;		if (nd->path.dentry == nd->root.dentry &&		    nd->path.mnt == nd->root.mnt) {			break;		}		if (nd->path.dentry != nd->path.mnt->mnt_root) {			 			nd->path.dentry = dget_parent(nd->path.dentry);			dput(old);			if (unlikely(!path_connected(&nd->path)))				return -ENOENT;			break;		}		if (!follow_up(&nd->path))			break;	}	follow_mount(&nd->path);	nd->inode = nd->path.dentry->d_inode;	return 0;},16209
24,255,CVE-2016-1667,12,  P2PQuicTransportTest() {},29804
11,26,CVE-2016-8645,12,static void tcp_v6_destroy_sock(struct sock *sk){	tcp_v4_destroy_sock(sk);	inet6_destroy_sock(sk);},15552
20,133,CVE-2016-3698,12,"int ndp_msg_send(struct ndp *ndp, struct ndp_msg *msg){	return ndp_msg_send_with_flags(ndp, msg, ND_OPT_NORMAL);}",17249
76,141,CVE-2016-3698,12,int ndp_msgna_flag_router(struct ndp_msgna *msgna){	return msgna->na->nd_na_flags_reserved & ND_NA_FLAG_ROUTER;},17257
13,298,CVE-2016-3839,12,"static void btif_dm_ble_rx_test_cback(void *p){    btif_transfer_context(btif_dm_generic_evt, BTIF_DM_CB_LE_RX_TEST, (char *)p, 1, NULL);}",30426
69,112,CVE-2016-3698,12,"int ndp_msg_opt_mtu(struct ndp_msg *msg, int offset){	struct nd_opt_mtu *mtu = ndp_msg_payload_opts_offset(msg, offset);	return ntohl(mtu->nd_opt_mtu_mtu);}",17228
39,166,CVE-2016-3698,12,"static const char *str_in6_addr(struct in6_addr *addr){	static char buf[INET6_ADDRSTRLEN];	return inet_ntop(AF_INET6, addr, buf, sizeof(buf));}",17282
46,86,CVE-2016-3713,12,static int fixed_mtrr_seg_end_range_index(int seg){	struct fixed_mtrr_segment *mtrr_seg = &fixed_seg_table[seg];	int n;	n = (mtrr_seg->end - mtrr_seg->start) >> mtrr_seg->range_shift;	return mtrr_seg->range_start + n - 1;},17190
16,274,CVE-2016-3839,12,"static int adev_set_voice_volume(struct audio_hw_device *dev, float volume){    UNUSED(dev);    UNUSED(volume);    FNLOG(); return -ENOSYS;}",30402
63,333,CVE-2016-3839,12,"void on_l2cap_psm_assigned(int id, int psm) {    l2cap_socket *sock;      pthread_mutex_lock(&state_lock);    sock = btsock_l2cap_find_by_id_l(id);    sock->channel = psm; if(btSock_start_l2cap_server_l(sock) != BT_STATUS_SUCCESS) {        btsock_l2cap_free_l(sock); }    pthread_mutex_unlock(&state_lock);}",30461
14,52,CVE-2016-6198,12,"static int follow_dotdot_rcu(struct nameidata *nd){	struct inode *inode = nd->inode;	while (1) {		if (path_equal(&nd->path, &nd->root))			break;		if (nd->path.dentry != nd->path.mnt->mnt_root) {			struct dentry *old = nd->path.dentry;			struct dentry *parent = old->d_parent;			unsigned seq;			inode = parent->d_inode;			seq = read_seqcount_begin(&parent->d_seq);			if (unlikely(read_seqcount_retry(&old->d_seq, nd->seq)))				return -ECHILD;			nd->path.dentry = parent;			nd->seq = seq;			if (unlikely(!path_connected(&nd->path)))				return -ENOENT;			break;		} else {			struct mount *mnt = real_mount(nd->path.mnt);			struct mount *mparent = mnt->mnt_parent;			struct dentry *mountpoint = mnt->mnt_mountpoint;			struct inode *inode2 = mountpoint->d_inode;			unsigned seq = read_seqcount_begin(&mountpoint->d_seq);			if (unlikely(read_seqretry(&mount_lock, nd->m_seq)))				return -ECHILD;			if (&mparent->mnt == nd->path.mnt)				break;			 			nd->path.dentry = mountpoint;			nd->path.mnt = &mparent->mnt;			inode = inode2;			nd->seq = seq;		}	}	while (unlikely(d_mountpoint(nd->path.dentry))) {		struct mount *mounted;		mounted = __lookup_mnt(nd->path.mnt, nd->path.dentry);		if (unlikely(read_seqretry(&mount_lock, nd->m_seq)))			return -ECHILD;		if (!mounted)			break;		nd->path.mnt = &mounted->mnt;		nd->path.dentry = mounted->mnt.mnt_root;		inode = nd->path.dentry->d_inode;		nd->seq = read_seqcount_begin(&nd->path.dentry->d_seq);	}	nd->inode = inode;	return 0;}",16210
28,212,CVE-2016-10030,12,destroy_starting_step(void *x){	xfree(x);},22598
60,42,CVE-2016-6198,12,"static struct dentry *__lookup_hash(const struct qstr *name,		struct dentry *base, unsigned int flags){	struct dentry *dentry = lookup_dcache(name, base, flags);	if (dentry)		return dentry;	dentry = d_alloc(base, name);	if (unlikely(!dentry))		return ERR_PTR(-ENOMEM);	return lookup_real(base->d_inode, dentry, flags);}",16200
51,126,CVE-2016-3698,12,"unsigned char *ndp_msg_opt_slladdr(struct ndp_msg *msg, int offset){	unsigned char *opt_data = ndp_msg_payload_opts_offset(msg, offset);	return &opt_data[2];}",17242
61,261,CVE-2019-5822,12,  DownloadTest() {},30210
36,77,CVE-2016-6198,12,"static void set_root(struct nameidata *nd){	struct fs_struct *fs = current->fs;	if (nd->flags & LOOKUP_RCU) {		unsigned seq;		do {			seq = read_seqcount_begin(&fs->seq);			nd->root = fs->root;			nd->root_seq = __read_seqcount_begin(&nd->root.dentry->d_seq);		} while (read_seqcount_retry(&fs->seq, seq));	} else {		get_fs_root(fs, &nd->root);	}}",16235
91,70,CVE-2016-6198,12,void page_put_link(void *arg){	put_page(arg);},16228
73,139,CVE-2016-3698,12,int ndp_msgna_flag_override(struct ndp_msgna *msgna){	return msgna->na->nd_na_flags_reserved & ND_NA_FLAG_OVERRIDE;},17255
70,292,CVE-2016-3839,12,"static int suspend_audio_datapath(struct a2dp_stream_common *common, int standby){    INFO(""state %d"", common->state); if (common->ctrl_fd == AUDIO_SKT_DISCONNECTED) return -1; if (common->state == AUDIO_A2DP_STATE_STOPPING) return -1; if (a2dp_command(common, A2DP_CTRL_CMD_SUSPEND) < 0) return -1; if (standby)        common->state = AUDIO_A2DP_STATE_STANDBY; else        common->state = AUDIO_A2DP_STATE_SUSPENDED;      skt_disconnect(common->audio_fd);    common->audio_fd = AUDIO_SKT_DISCONNECTED; return 0;}",30420
62,282,CVE-2016-3839,12,"static int in_set_parameters(struct audio_stream *stream, const char *kvpairs){    UNUSED(stream);    UNUSED(kvpairs);    FNLOG(); return 0;}",30410
30,151,CVE-2016-3698,12,int ndp_msgra_flag_managed(struct ndp_msgra *msgra){	return msgra->ra->nd_ra_flags_reserved & ND_RA_FLAG_MANAGED;},17267
45,334,CVE-2016-3839,12,"static struct packet *packet_alloc(const int *data, int len){ struct packet *p = osi_calloc(sizeof(*p)); int *buf = osi_malloc(len); if (p && buf) {        p->data = buf;        p->len = len;        memcpy(p->data, data, len); return p; } else if (p)       osi_free(p); else if (buf)       osi_free(buf); return NULL;}",30462
2,197,CVE-2016-10030,12,static int _is_batch_job_finished(int job_id){	int found_job = false;	int i;	slurm_mutex_lock(&fini_mutex);	for (i = 0; i < FINI_JOB_CNT; i++) {		if (fini_job_id[i] == job_id) {			found_job = true;			break;		}	}	slurm_mutex_unlock(&fini_mutex);	return found_job;},22583
55,4021,CVE-2016-1621,26,"void reference_dct_2d(int input[64], double output[64]) { for (int i = 0; i < 8; ++i) { double temp_in[8], temp_out[8]; for (int j = 0; j < 8; ++j)      temp_in[j] = input[j*8 + i];    reference_dct_1d(temp_in, temp_out); for (int j = 0; j < 8; ++j)      output[j*8 + i] = temp_out[j]; } for (int i = 0; i < 8; ++i) { double temp_in[8], temp_out[8]; for (int j = 0; j < 8; ++j)      temp_in[j] = output[j + i*8];    reference_dct_1d(temp_in, temp_out); for (int j = 0; j < 8; ++j)      output[j + i*8] = temp_out[j]; } for (int i = 0; i < 64; ++i)    output[i] *= 2;}",30852
635,2753,CVE-2017-11328,26,"define_function(match){  return_integer(yr_re_match(regexp_argument(1), string_argument(2)));}",20535
788,1526,CVE-2014-3158,26,"setdomain(argv)    char **argv;{    gethostname(hostname, MAXNAMELEN);    if (**argv != 0) {	if (**argv != '.')	    strncat(hostname, ""."", MAXNAMELEN - strlen(hostname));	domain = hostname + strlen(hostname);	strncat(hostname, *argv, MAXNAMELEN - strlen(hostname));    }    hostname[MAXNAMELEN-1] = 0;    return (1);}",11521
281,362,CVE-2016-5126,26,"iscsi_co_generic_cb(struct iscsi_context *iscsi, int status,                        void *command_data, void *opaque){    struct IscsiTask *iTask = opaque;    struct scsi_task *task = command_data;    iTask->status = status;    iTask->do_retry = 0;    iTask->task = task;    if (status != SCSI_STATUS_GOOD) {        if (iTask->retries++ < ISCSI_CMD_RETRIES) {            if (status == SCSI_STATUS_CHECK_CONDITION                && task->sense.key == SCSI_SENSE_UNIT_ATTENTION) {                error_report(""iSCSI CheckCondition: %s"",                             iscsi_get_error(iscsi));                iTask->do_retry = 1;                goto out;            }            if (status == SCSI_STATUS_BUSY ||                status == SCSI_STATUS_TIMEOUT ||                status == SCSI_STATUS_TASK_SET_FULL) {                unsigned retry_time =                    exp_random(iscsi_retry_times[iTask->retries - 1]);                if (status == SCSI_STATUS_TIMEOUT) {                                         retry_time = EVENT_INTERVAL * 2;                    iTask->iscsilun->request_timed_out = true;                }                error_report(""iSCSI Busy/TaskSetFull/TimeOut""                             "" (retry #%u in %u ms): %s"",                             iTask->retries, retry_time,                             iscsi_get_error(iscsi));                aio_timer_init(iTask->iscsilun->aio_context,                               &iTask->retry_timer, QEMU_CLOCK_REALTIME,                               SCALE_MS, iscsi_retry_timer_expired, iTask);                timer_mod(&iTask->retry_timer,                          qemu_clock_get_ms(QEMU_CLOCK_REALTIME) + retry_time);                iTask->do_retry = 1;                return;            }        }        iTask->err_code = iscsi_translate_sense(&task->sense);        error_report(""iSCSI Failure: %s"", iscsi_get_error(iscsi));    }out:    if (iTask->co) {        iTask->bh = aio_bh_new(iTask->iscsilun->aio_context,                               iscsi_co_generic_bh_cb, iTask);        qemu_bh_schedule(iTask->bh);    } else {        iTask->complete = 1;    }}",1850
218,823,CVE-2013-6381,26,"int qeth_core_hardsetup_card(struct qeth_card *card){	int retries = 3;	int rc;	QETH_DBF_TEXT(SETUP, 2, ""hrdsetup"");	atomic_set(&card->force_alloc_skb, 0);	qeth_update_from_chp_desc(card);retry:	if (retries < 3)		QETH_DBF_MESSAGE(2, ""%s Retrying to do IDX activates.\n"",			dev_name(&card->gdev->dev));	ccw_device_set_offline(CARD_DDEV(card));	ccw_device_set_offline(CARD_WDEV(card));	ccw_device_set_offline(CARD_RDEV(card));	rc = ccw_device_set_online(CARD_RDEV(card));	if (rc)		goto retriable;	rc = ccw_device_set_online(CARD_WDEV(card));	if (rc)		goto retriable;	rc = ccw_device_set_online(CARD_DDEV(card));	if (rc)		goto retriable;	rc = qeth_qdio_clear_card(card, card->info.type != QETH_CARD_TYPE_IQD);retriable:	if (rc == -ERESTARTSYS) {		QETH_DBF_TEXT(SETUP, 2, ""break1"");		return rc;	} else if (rc) {		QETH_DBF_TEXT_(SETUP, 2, ""1err%d"", rc);		if (--retries < 0)			goto out;		else			goto retry;	}	qeth_determine_capabilities(card);	qeth_init_tokens(card);	qeth_init_func_level(card);	rc = qeth_idx_activate_channel(&card->read, qeth_idx_read_cb);	if (rc == -ERESTARTSYS) {		QETH_DBF_TEXT(SETUP, 2, ""break2"");		return rc;	} else if (rc) {		QETH_DBF_TEXT_(SETUP, 2, ""3err%d"", rc);		if (--retries < 0)			goto out;		else			goto retry;	}	rc = qeth_idx_activate_channel(&card->write, qeth_idx_write_cb);	if (rc == -ERESTARTSYS) {		QETH_DBF_TEXT(SETUP, 2, ""break3"");		return rc;	} else if (rc) {		QETH_DBF_TEXT_(SETUP, 2, ""4err%d"", rc);		if (--retries < 0)			goto out;		else			goto retry;	}	card->read_or_write_problem = 0;	rc = qeth_mpc_initialize(card);	if (rc) {		QETH_DBF_TEXT_(SETUP, 2, ""5err%d"", rc);		goto out;	}	card->options.ipa4.supported_funcs = 0;	card->options.adp.supported_funcs = 0;	card->info.diagass_support = 0;	qeth_query_ipassists(card, QETH_PROT_IPV4);	if (qeth_is_supported(card, IPA_SETADAPTERPARMS))		qeth_query_setadapterparms(card);	if (qeth_adp_supported(card, IPA_SETADP_SET_DIAG_ASSIST))		qeth_query_setdiagass(card);	return 0;out:	dev_warn(&card->gdev->dev, ""The qeth device driver failed to recover ""		""an error on the device\n"");	QETH_DBF_MESSAGE(2, ""%s Initialization in hardsetup failed! rc=%d\n"",		dev_name(&card->gdev->dev), rc);	return rc;}",7252
1003,2830,CVE-2017-8069,26,"static void intr_callback(struct urb *urb){	rtl8150_t *dev;	__u8 *d;	int status = urb->status;	int res;	dev = urb->context;	if (!dev)		return;	switch (status) {	case 0:			 		break;	case -ECONNRESET:	 	case -ENOENT:	case -ESHUTDOWN:		return;	 	default:		dev_info(&urb->dev->dev, ""%s: intr status %d\n"",			 dev->netdev->name, status);		goto resubmit;	}	d = urb->transfer_buffer;	if (d[0] & TSR_ERRORS) {		dev->netdev->stats.tx_errors++;		if (d[INT_TSR] & (TSR_ECOL | TSR_JBR))			dev->netdev->stats.tx_aborted_errors++;		if (d[INT_TSR] & TSR_LCOL)			dev->netdev->stats.tx_window_errors++;		if (d[INT_TSR] & TSR_LOSS_CRS)			dev->netdev->stats.tx_carrier_errors++;	}	 	if ((d[INT_MSR] & MSR_LINK) == 0) {		if (netif_carrier_ok(dev->netdev)) {			netif_carrier_off(dev->netdev);			netdev_dbg(dev->netdev, ""%s: LINK LOST\n"", __func__);		}	} else {		if (!netif_carrier_ok(dev->netdev)) {			netif_carrier_on(dev->netdev);			netdev_dbg(dev->netdev, ""%s: LINK CAME BACK\n"", __func__);		}	}resubmit:	res = usb_submit_urb (urb, GFP_ATOMIC);	if (res == -ENODEV)		netif_device_detach(dev->netdev);	else if (res)		dev_err(&dev->udev->dev,			""can't resubmit intr, %s-%s/input0, status %d\n"",			dev->udev->bus->bus_name, dev->udev->devpath, res);}",21307
121,2636,CVE-2017-1000251,26,"static void l2cap_conn_start(struct l2cap_conn *conn){	struct l2cap_chan_list *l = &conn->chan_list;	struct sock *sk;	BT_DBG(""conn %p"", conn);	read_lock(&l->lock);	for (sk = l->head; sk; sk = l2cap_pi(sk)->next_c) {		bh_lock_sock(sk);		if (sk->sk_type != SOCK_SEQPACKET) {			bh_unlock_sock(sk);			continue;		}		if (sk->sk_state == BT_CONNECT) {			if (l2cap_check_security(sk)) {				struct l2cap_conn_req req;				req.scid = cpu_to_le16(l2cap_pi(sk)->scid);				req.psm  = l2cap_pi(sk)->psm;				l2cap_pi(sk)->ident = l2cap_get_ident(conn);				l2cap_send_cmd(conn, l2cap_pi(sk)->ident,					L2CAP_CONN_REQ, sizeof(req), &req);			}		} else if (sk->sk_state == BT_CONNECT2) {			struct l2cap_conn_rsp rsp;			rsp.scid = cpu_to_le16(l2cap_pi(sk)->dcid);			rsp.dcid = cpu_to_le16(l2cap_pi(sk)->scid);			if (l2cap_check_security(sk)) {				if (bt_sk(sk)->defer_setup) {					struct sock *parent = bt_sk(sk)->parent;					rsp.result = cpu_to_le16(L2CAP_CR_PEND);					rsp.status = cpu_to_le16(L2CAP_CS_AUTHOR_PEND);					parent->sk_data_ready(parent, 0);				} else {					sk->sk_state = BT_CONFIG;					rsp.result = cpu_to_le16(L2CAP_CR_SUCCESS);					rsp.status = cpu_to_le16(L2CAP_CS_NO_INFO);				}			} else {				rsp.result = cpu_to_le16(L2CAP_CR_PEND);				rsp.status = cpu_to_le16(L2CAP_CS_AUTHEN_PEND);			}			l2cap_send_cmd(conn, l2cap_pi(sk)->ident,					L2CAP_CONN_RSP, sizeof(rsp), &rsp);		}		bh_unlock_sock(sk);	}	read_unlock(&l->lock);}",19474
1001,575,CVE-2011-3359,26,"static int alloc_initial_descbuffers(struct b43_dmaring *ring){	int i, err = -ENOMEM;	struct b43_dmadesc_generic *desc;	struct b43_dmadesc_meta *meta;	for (i = 0; i < ring->nr_slots; i++) {		desc = ring->ops->idx2desc(ring, i, &meta);		err = setup_rx_descbuffer(ring, desc, meta, GFP_KERNEL);		if (err) {			b43err(ring->dev->wl,			       ""Failed to allocate initial descbuffers\n"");			goto err_unwind;		}	}	mb();	ring->used_slots = ring->nr_slots;	err = 0;      out:	return err;      err_unwind:	for (i--; i >= 0; i--) {		desc = ring->ops->idx2desc(ring, i, &meta);		unmap_descbuffer(ring, meta->dmaaddr, ring->rx_buffersize, 0);		dev_kfree_skb(meta->skb);	}	goto out;}",5548
225,1479,CVE-2014-3185,26,"static int whiteheat_firmware_download(struct usb_serial *serial,					const struct usb_device_id *id){	int response;	response = ezusb_fx1_ihex_firmware_download(serial->dev, ""whiteheat_loader.fw"");	if (response >= 0) {		response = ezusb_fx1_ihex_firmware_download(serial->dev, ""whiteheat.fw"");		if (response >= 0)			return 0;	}	return -ENOENT;}",11474
629,219,CVE-2017-7476,26,"equal_tm (const struct tm *a, const struct tm *b){  return ! ((a->tm_sec ^ b->tm_sec)            | (a->tm_min ^ b->tm_min)            | (a->tm_hour ^ b->tm_hour)            | (a->tm_mday ^ b->tm_mday)            | (a->tm_mon ^ b->tm_mon)            | (a->tm_year ^ b->tm_year)            | isdst_differ (a->tm_isdst, b->tm_isdst));}",1233
332,2509,CVE-2016-1583,26,static void cpu_cgroup_css_released(struct cgroup_subsys_state *css){	struct task_group *tg = css_tg(css);	sched_offline_group(tg);},18058
66,860,CVE-2013-6381,26,"static int qeth_halt_channel(struct qeth_channel *channel){	unsigned long flags;	struct qeth_card *card;	int rc;	card = CARD_FROM_CDEV(channel->ccwdev);	QETH_CARD_TEXT(card, 3, ""haltch"");	spin_lock_irqsave(get_ccwdev_lock(channel->ccwdev), flags);	rc = ccw_device_halt(channel->ccwdev, QETH_HALT_CHANNEL_PARM);	spin_unlock_irqrestore(get_ccwdev_lock(channel->ccwdev), flags);	if (rc)		return rc;	rc = wait_event_interruptible_timeout(card->wait_q,			channel->state == CH_STATE_HALTED, QETH_TIMEOUT);	if (rc == -ERESTARTSYS)		return rc;	if (channel->state != CH_STATE_HALTED)		return -ETIME;	return 0;}",7289
621,3953,CVE-2016-3822,26,"int TagNameToValue(const char* tagName){ unsigned int i; for (i = 0; i < TAG_TABLE_SIZE; i++) { if (strcmp(TagTable[i].Desc, tagName) == 0) {            printf(""found tag %s val %d"", TagTable[i].Desc, TagTable[i].Tag); return TagTable[i].Tag; } }    printf(""tag %s NOT FOUND"", tagName); return -1;}",30506
11,2121,CVE-2016-4303,26,"iperf_set_test_burst(struct iperf_test *ipt, int burst){    ipt->settings->burst = burst;}",17029
716,2405,CVE-2016-2315,26,static void load_branch(struct branch *b){	load_tree(&b->branch_tree);	if (!b->active) {		b->active = 1;		b->active_next_branch = active_branches;		active_branches = b;		cur_active_branches++;		branch_load_count++;	}},17825
903,1371,CVE-2013-1772,26,void console_stop(struct console *console){	console_lock();	console->flags &= ~CON_ENABLED;	console_unlock();},9608
287,1776,CVE-2016-9793,26,"static void sk_prot_free(struct proto *prot, struct sock *sk){	struct kmem_cache *slab;	struct module *owner;	owner = prot->owner;	slab = prot->slab;	cgroup_sk_free(&sk->sk_cgrp_data);	mem_cgroup_sk_free(sk);	security_sk_free(sk);	if (slab != NULL)		kmem_cache_free(slab, sk);	else		kfree(sk);	module_put(owner);}",15060
251,2429,CVE-2016-2315,26,"static void parse_new_blob(void){	read_next_command();	parse_mark();	parse_and_store_blob(&last_blob, NULL, next_mark);}",17849
44,1308,CVE-2013-1929,26,"static void tg3_tx_recover(struct tg3 *tp){	BUG_ON(tg3_flag(tp, MBOX_WRITE_REORDER) ||	       tp->write32_tx_mbox == tg3_write_indirect_mbox);	netdev_warn(tp->dev,		    ""The system may be re-ordering memory-mapped I/O ""		    ""cycles to the network device, attempting to recover. ""		    ""Please report the problem to the driver maintainer ""		    ""and include system chipset information.\n"");	spin_lock(&tp->lock);	tg3_flag_set(tp, TX_RECOVERY_PENDING);	spin_unlock(&tp->lock);}",9314
273,2585,CVE-2016-1583,26,static const struct cpumask *sd_numa_mask(int cpu){	return sched_domains_numa_masks[sched_domains_curr_level][cpu_to_node(cpu)];},18134
848,377,CVE-2016-4539,26,inline static unsigned short xml_encode_us_ascii(unsigned char c){	return (unsigned short)c;},1887
987,24,CVE-2015-6806,26,"BackSpace(){  if (curr->w_x > 0)    {      curr->w_x--;    }  else if (curr->w_wrap && curr->w_y > 0)    {      curr->w_x = cols - 1;      curr->w_y--;    }  LGotoPos(&curr->w_layer, curr->w_x, curr->w_y);}",245
298,167,CVE-2013-2236,26,msg_get_seq (struct msg *msg){  assert (msg);  return ntohl (msg->hdr.msgseq);},722
1014,70,CVE-2019-15937,26,"static int rpc_check_reply(unsigned char *pkt, int isnfs){	int *data;	int nfserr;	struct rpc_reply rpc;	memcpy(&rpc, pkt, sizeof(rpc));	if (ntohl(rpc.id) != rpc_id)		return -EINVAL;	if (rpc.rstatus  ||	    rpc.verifier ||	    rpc.astatus ) {		return -EINVAL;	}	if (!isnfs)		return 0;	data = (int *)(pkt + sizeof(struct rpc_reply));	nfserr = ntohl(net_read_uint32(data));	debug(""%s: state: %d, err %d\n"", __func__, nfs_state, -nfserr);	if (nfserr <= 30)		 		return -nfserr;	if (nfserr == NFSERR_STALE)		return -ESTALE;	return -EINVAL;}",301
994,204,CVE-2015-0292,26,"int EVP_EncodeBlock(unsigned char *t, const unsigned char *f, int dlen)	{	int i,ret=0;	unsigned long l;	for (i=dlen; i > 0; i-=3)		{		if (i >= 3)			{			l=	(((unsigned long)f[0])<<16L)|				(((unsigned long)f[1])<< 8L)|f[2];			*(t++)=conv_bin2ascii(l>>18L);			*(t++)=conv_bin2ascii(l>>12L);			*(t++)=conv_bin2ascii(l>> 6L);			*(t++)=conv_bin2ascii(l     );			}		else			{			l=((unsigned long)f[0])<<16L;			if (i == 2) l|=((unsigned long)f[1]<<8L);			*(t++)=conv_bin2ascii(l>>18L);			*(t++)=conv_bin2ascii(l>>12L);			*(t++)=(i == 1)?'=':conv_bin2ascii(l>> 6L);			*(t++)='=';			}		ret+=4;		f+=3;		}	*t='\0';	return(ret);	}",992
288,600,CVE-2011-3359,26,"static void op64_tx_suspend(struct b43_dmaring *ring){	b43_dma_write(ring, B43_DMA64_TXCTL, b43_dma_read(ring, B43_DMA64_TXCTL)		      | B43_DMA64_TXSUSPEND);}",5573
892,1498,CVE-2014-3183,26,"static int logi_dj_ll_open(struct hid_device *hid){	dbg_hid(""%s:%s\n"", __func__, hid->phys);	return 0;}",11493
187,3417,CVE-2017-15128,26,"void hugetlb_report_meminfo(struct seq_file *m){	struct hstate *h = &default_hstate;	if (!hugepages_supported())		return;	seq_printf(m,			""HugePages_Total:   %5lu\n""			""HugePages_Free:    %5lu\n""			""HugePages_Rsvd:    %5lu\n""			""HugePages_Surp:    %5lu\n""			""Hugepagesize:   %8lu kB\n"",			h->nr_huge_pages,			h->free_huge_pages,			h->resv_huge_pages,			h->surplus_huge_pages,			1UL << (huge_page_order(h) + PAGE_SHIFT - 10));}",26177
405,2538,CVE-2016-1583,26,"int migrate_swap(struct task_struct *cur, struct task_struct *p){	struct migration_swap_arg arg;	int ret = -EINVAL;	arg = (struct migration_swap_arg){		.src_task = cur,		.src_cpu = task_cpu(cur),		.dst_task = p,		.dst_cpu = task_cpu(p),	};	if (arg.src_cpu == arg.dst_cpu)		goto out;	 	if (!cpu_active(arg.src_cpu) || !cpu_active(arg.dst_cpu))		goto out;	if (!cpumask_test_cpu(arg.dst_cpu, tsk_cpus_allowed(arg.src_task)))		goto out;	if (!cpumask_test_cpu(arg.src_cpu, tsk_cpus_allowed(arg.dst_task)))		goto out;	trace_sched_swap_numa(cur, arg.src_cpu, p, arg.dst_cpu);	ret = stop_two_cpus(arg.dst_cpu, arg.src_cpu, migrate_swap_stop, &arg);out:	return ret;}",18087
512,3636,CVE-2017-18379,26,nvmet_fc_tgt_a_get(struct nvmet_fc_tgt_assoc *assoc){	return kref_get_unless_zero(&assoc->ref);},28092
85,1455,CVE-2014-3535,26,"int dev_forward_skb(struct net_device *dev, struct sk_buff *skb){	skb_orphan(skb);	if (!(dev->flags & IFF_UP) ||	    (skb->len > (dev->mtu + dev->hard_header_len))) {		kfree_skb(skb);		return NET_RX_DROP;	}	skb_set_dev(skb, dev);	skb->tstamp.tv64 = 0;	skb->pkt_type = PACKET_HOST;	skb->protocol = eth_type_trans(skb, dev);	return netif_rx(skb);}",11441
158,438,CVE-2018-20815,26,"int qemu_fdt_get_phandle(void *fdt, const char *path){    int r;    r = fdt_get_phandle(fdt, findnode_nofail(fdt, path));    if (r == 0) {        error_report(""%s: Couldn't get phandle for %s: %s"", __func__,                     path, fdt_strerror(r));        exit(1);    }    return r;}",2163
37,2310,CVE-2016-2324,26,"static void add_message_grep(struct rev_info *revs, const char *pattern){	add_grep(revs, pattern, GREP_PATTERN_BODY);}",17730
553,1544,CVE-2014-0069,26,"int cifs_file_mmap(struct file *file, struct vm_area_struct *vma){	int rc, xid;	xid = get_xid();	rc = cifs_revalidate_file(file);	if (rc) {		cifs_dbg(FYI, ""Validation prior to mmap failed, error=%d\n"",			 rc);		free_xid(xid);		return rc;	}	rc = generic_file_mmap(file, vma);	if (rc == 0)		vma->vm_ops = &cifs_file_vm_ops;	free_xid(xid);	return rc;}",12290
824,2173,CVE-2016-4302,26,"new_node(struct huffman_code *code){  void *new_tree;  if (code->numallocatedentries == code->numentries) {    int new_num_entries = 256;    if (code->numentries > 0) {        new_num_entries = code->numentries * 2;    }    new_tree = realloc(code->tree, new_num_entries * sizeof(*code->tree));    if (new_tree == NULL)        return (-1);    code->tree = (struct huffman_tree_node *)new_tree;    code->numallocatedentries = new_num_entries;  }  code->tree[code->numentries].branches[0] = -1;  code->tree[code->numentries].branches[1] = -2;  return 1;}",17081
878,1016,CVE-2013-4588,26,static int ip_vs_del_service(struct ip_vs_service *svc){	if (svc == NULL)		return -EEXIST;	 	write_lock_bh(&__ip_vs_svc_lock);	ip_vs_svc_unhash(svc);	 	IP_VS_WAIT_WHILE(atomic_read(&svc->usecnt) > 1);	__ip_vs_del_service(svc);	write_unlock_bh(&__ip_vs_svc_lock);	return 0;},7613
351,3892,CVE-2017-5014,26,  int progress() { return progress_; },29924
506,77,CVE-2017-15650,26,"static int name_from_dns(struct address buf[static MAXADDRS], char canon[static 256], const char *name, int family, const struct resolvconf *conf){	unsigned char qbuf[2][280], abuf[2][512];	const unsigned char *qp[2] = { qbuf[0], qbuf[1] };	unsigned char *ap[2] = { abuf[0], abuf[1] };	int qlens[2], alens[2];	int i, nq = 0;	struct dpc_ctx ctx = { .addrs = buf, .canon = canon };	static const struct { int af; int rr; } afrr[2] = {		{ .af = AF_INET6, .rr = RR_A },		{ .af = AF_INET, .rr = RR_AAAA },	};	for (i=0; i<2; i++) {		if (family != afrr[i].af) {			qlens[nq] = __res_mkquery(0, name, 1, afrr[i].rr,				0, 0, 0, qbuf[nq], sizeof *qbuf);			if (qlens[nq] == -1)				return EAI_NONAME;			nq++;		}	}	if (__res_msend_rc(nq, qp, qlens, ap, alens, sizeof *abuf, conf) < 0)		return EAI_SYSTEM;	for (i=0; i<nq; i++)		__dns_parse(abuf[i], alens[i], dns_parse_callback, &ctx);	if (ctx.cnt) return ctx.cnt;	if (alens[0] < 4 || (abuf[0][3] & 15) == 2) return EAI_AGAIN;	if ((abuf[0][3] & 15) == 0) return EAI_NONAME;	if ((abuf[0][3] & 15) == 3) return 0;	return EAI_FAIL;}",385
223,808,CVE-2013-6381,26,"static int qeth_cm_enable_cb(struct qeth_card *card, struct qeth_reply *reply,		unsigned long data){	struct qeth_cmd_buffer *iob;	QETH_DBF_TEXT(SETUP, 2, ""cmenblcb"");	iob = (struct qeth_cmd_buffer *) data;	memcpy(&card->token.cm_filter_r,	       QETH_CM_ENABLE_RESP_FILTER_TOKEN(iob->data),	       QETH_MPC_TOKEN_LENGTH);	QETH_DBF_TEXT_(SETUP, 2, ""  rc%d"", iob->rc);	return 0;}",7237
67,246,CVE-2018-10184,26,"static int h2c_ack_settings(struct h2c *h2c){	struct buffer *res;	char str[9];	int ret = -1;	if (h2c_mux_busy(h2c, NULL)) {		h2c->flags |= H2_CF_DEM_MBUSY;		return 0;	}	res = h2_get_buf(h2c, &h2c->mbuf);	if (!res) {		h2c->flags |= H2_CF_MUX_MALLOC;		h2c->flags |= H2_CF_DEM_MROOM;		return 0;	}	memcpy(str,	       ""\x00\x00\x00""      	       ""\x04"" ""\x01""       	       ""\x00\x00\x00\x00""  , 9);	ret = bo_istput(res, ist2(str, 9));	if (unlikely(ret <= 0)) {		if (!ret) {			h2c->flags |= H2_CF_MUX_MFULL;			h2c->flags |= H2_CF_DEM_MROOM;			return 0;		}		else {			h2c_error(h2c, H2_ERR_INTERNAL_ERROR);			return 0;		}	}	return ret;}",1267
330,2248,CVE-2016-2324,26,"static int pack_offset_sort(const void *_a, const void *_b){	const struct object_entry *a = *(struct object_entry **)_a;	const struct object_entry *b = *(struct object_entry **)_b;	 	if (!a->in_pack && !b->in_pack)		return hashcmp(a->idx.sha1, b->idx.sha1);	if (a->in_pack < b->in_pack)		return -1;	if (a->in_pack > b->in_pack)		return 1;	return a->in_pack_offset < b->in_pack_offset ? -1 :			(a->in_pack_offset > b->in_pack_offset);}",17668
838,592,CVE-2011-3359,26,"static void op32_poke_tx(struct b43_dmaring *ring, int slot){	b43_dma_write(ring, B43_DMA32_TXINDEX,		      (u32) (slot * sizeof(struct b43_dmadesc32)));}",5565
423,3222,CVE-2018-17407,26,void t1_free(void){    xfree(t1_line_array);    xfree(t1_buf_array);},23656
757,183,CVE-2019-11360,26,"inline int xs_has_arg(int argc, char *argv[]){	return optind < argc &&	       argv[optind][0] != '-' &&	       argv[optind][0] != '!';}",775
104,211,CVE-2014-9665,26,  Render_Gray_Glyph( RAS_ARG )  {    FT_UNUSED_RASTER;    return FT_THROW( Unsupported );  },1165
808,1193,CVE-2013-2220,26,"rad_server_secret(struct rad_handle *h){	if (h->srv >= h->num_servers) {		generr(h, ""No RADIUS servers specified"");		return NULL;	}	return (h->servers[h->srv].secret);}",8783
872,2058,CVE-2016-4478,26,"char *xmlrpc_intean(char *buf, int value){	*buf = '\0';	snprintf(buf, XMLRPC_BUFSIZE, ""<intean>%d</intean>"", (value ? 1 : 0));	return buf;}",16957
745,478,CVE-2013-4534,26,"static int inttgt_to_output(int inttgt){    int i;    for (i = 0; i < ARRAY_SIZE(inttgt_output); i++) {        if (inttgt_output[i][0] == inttgt) {            return inttgt_output[i][1];        }    }    fprintf(stderr, ""%s: unsupported inttgt %d\n"", __func__, inttgt);    return OPENPIC_OUTPUT_INT;}",2407
120,2218,CVE-2016-2324,26,"static void add_pbase_object(struct tree_desc *tree,			     const char *name,			     int cmplen,			     const char *fullname){	struct name_entry entry;	int cmp;	while (tree_entry(tree,&entry)) {		if (S_ISGITLINK(entry.mode))			continue;		cmp = tree_entry_len(&entry) != cmplen ? 1 :		      memcmp(name, entry.path, cmplen);		if (cmp > 0)			continue;		if (cmp < 0)			return;		if (name[cmplen] != '/') {			add_object_entry(entry.sha1,					 object_type(entry.mode),					 fullname, 1);			return;		}		if (S_ISDIR(entry.mode)) {			struct tree_desc sub;			struct pbase_tree_cache *tree;			const char *down = name+cmplen+1;			int downlen = name_cmp_len(down);			tree = pbase_tree_get(entry.sha1);			if (!tree)				return;			init_tree_desc(&sub, tree->tree_data, tree->tree_size);			add_pbase_object(&sub, down, downlen, fullname);			pbase_tree_put(tree);		}	}}",17638
439,2778,CVE-2017-9994,26,"int check_intra_pred8x8_mode_emuedge(int mode, int mb_x, int mb_y, int vp7){    switch (mode) {    case DC_PRED8x8:        return check_dc_pred8x8_mode(mode, mb_x, mb_y);    case VERT_PRED8x8:        return !mb_y ? (vp7 ? DC_128_PRED8x8 : DC_127_PRED8x8) : mode;    case HOR_PRED8x8:        return !mb_x ? (vp7 ? DC_128_PRED8x8 : DC_129_PRED8x8) : mode;    case PLANE_PRED8x8:          return check_tm_pred8x8_mode(mode, mb_x, mb_y, vp7);    }    return mode;}",20663
923,3327,CVE-2018-1091,26,"static int set_user_dscr(struct task_struct *task, unsigned long dscr){	task->thread.dscr = dscr;	task->thread.dscr_inherit = 1;	return 0;}",25543
431,2953,CVE-2017-8062,26,"static int dw2104_frontend_attach(struct dvb_usb_adapter *d){	struct dvb_tuner_ops *tuner_ops = NULL;	if (demod_probe & 4) {		d->fe_adap[0].fe = dvb_attach(stv0900_attach, &dw2104a_stv0900_config,				&d->dev->i2c_adap, 0);		if (d->fe_adap[0].fe != NULL) {			if (dvb_attach(stb6100_attach, d->fe_adap[0].fe,					&dw2104a_stb6100_config,					&d->dev->i2c_adap)) {				tuner_ops = &d->fe_adap[0].fe->ops.tuner_ops;				tuner_ops->set_frequency = stb6100_set_freq;				tuner_ops->get_frequency = stb6100_get_freq;				tuner_ops->set_bandwidth = stb6100_set_bandw;				tuner_ops->get_bandwidth = stb6100_get_bandw;				d->fe_adap[0].fe->ops.set_voltage = dw210x_set_voltage;				info(""Attached STV0900+STB6100!"");				return 0;			}		}	}	if (demod_probe & 2) {		d->fe_adap[0].fe = dvb_attach(stv0900_attach, &dw2104_stv0900_config,				&d->dev->i2c_adap, 0);		if (d->fe_adap[0].fe != NULL) {			if (dvb_attach(stv6110_attach, d->fe_adap[0].fe,					&dw2104_stv6110_config,					&d->dev->i2c_adap)) {				d->fe_adap[0].fe->ops.set_voltage = dw210x_set_voltage;				info(""Attached STV0900+STV6110A!"");				return 0;			}		}	}	if (demod_probe & 1) {		d->fe_adap[0].fe = dvb_attach(cx24116_attach, &dw2104_config,				&d->dev->i2c_adap);		if (d->fe_adap[0].fe != NULL) {			d->fe_adap[0].fe->ops.set_voltage = dw210x_set_voltage;			info(""Attached cx24116!"");			return 0;		}	}	d->fe_adap[0].fe = dvb_attach(ds3000_attach, &dw2104_ds3000_config,			&d->dev->i2c_adap);	if (d->fe_adap[0].fe != NULL) {		dvb_attach(ts2020_attach, d->fe_adap[0].fe,			&dw2104_ts2020_config, &d->dev->i2c_adap);		d->fe_adap[0].fe->ops.set_voltage = dw210x_set_voltage;		info(""Attached DS3000!"");		return 0;	}	return -EIO;}",21430
1015,2878,CVE-2017-8066,26,"static void gs_usb_xmit_callback(struct urb *urb){	struct gs_tx_context *txc = urb->context;	struct gs_can *dev = txc->dev;	struct net_device *netdev = dev->netdev;	if (urb->status)		netdev_info(netdev, ""usb xmit fail %d\n"", txc->echo_id);	usb_free_coherent(urb->dev,			  urb->transfer_buffer_length,			  urb->transfer_buffer,			  urb->transfer_dma);	atomic_dec(&dev->active_tx_urbs);	if (!netif_device_present(netdev))		return;	if (netif_queue_stopped(netdev))		netif_wake_queue(netdev);}",21355
865,1397,CVE-2012-2119,26,"static struct net_device *dev_get_by_macvtap_minor(int minor){	struct net_device *dev = NULL;	struct macvlan_dev *vlan;	mutex_lock(&minor_lock);	vlan = idr_find(&minor_idr, minor);	if (vlan) {		dev = vlan->dev;		dev_hold(dev);	}	mutex_unlock(&minor_lock);	return dev;}",10003
171,3332,CVE-2018-1091,26,"static int tm_dscr_active(struct task_struct *target,			 const struct user_regset *regset){	if (!cpu_has_feature(CPU_FTR_TM))		return -ENODEV;	if (MSR_TM_ACTIVE(target->thread.regs->msr))		return regset->n;	return 0;}",25548
623,3893,CVE-2016-5199,26,    IsWebAuthenticationTouchIdAuthenticatorSupported() {  return true;},29951
664,2408,CVE-2016-2315,26,"static char* make_fast_import_path(const char *path){	if (!relative_marks_paths || is_absolute_path(path))		return xstrdup(path);	return xstrdup(git_path(""info/fast-import/%s"", path));}",17828
1009,1115,CVE-2013-2237,26,"static int key_notify_sa(struct xfrm_state *x, const struct km_event *c){	struct sk_buff *skb;	struct sadb_msg *hdr;	skb = pfkey_xfrm_state2msg(x);	if (IS_ERR(skb))		return PTR_ERR(skb);	hdr = (struct sadb_msg *) skb->data;	hdr->sadb_msg_version = PF_KEY_V2;	hdr->sadb_msg_type = event2keytype(c->event);	hdr->sadb_msg_satype = pfkey_proto2satype(x->id.proto);	hdr->sadb_msg_errno = 0;	hdr->sadb_msg_reserved = 0;	hdr->sadb_msg_seq = c->seq;	hdr->sadb_msg_pid = c->portid;	pfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, xs_net(x));	return 0;}",8704
667,2903,CVE-2017-8064,26,"static int dvb_usbv2_adapter_frontend_init(struct dvb_usb_adapter *adap){	int ret, i, count_registered = 0;	struct dvb_usb_device *d = adap_to_d(adap);	dev_dbg(&d->udev->dev, ""%s: adap=%d\n"", __func__, adap->id);	memset(adap->fe, 0, sizeof(adap->fe));	adap->active_fe = -1;	if (d->props->frontend_attach) {		ret = d->props->frontend_attach(adap);		if (ret < 0) {			dev_dbg(&d->udev->dev,					""%s: frontend_attach() failed=%d\n"",					__func__, ret);			goto err_dvb_frontend_detach;		}	} else {		dev_dbg(&d->udev->dev, ""%s: frontend_attach() do not exists\n"",				__func__);		ret = 0;		goto err;	}	for (i = 0; i < MAX_NO_OF_FE_PER_ADAP && adap->fe[i]; i++) {		adap->fe[i]->id = i;		 		adap->fe_init[i] = adap->fe[i]->ops.init;		adap->fe[i]->ops.init = dvb_usb_fe_init;		adap->fe_sleep[i] = adap->fe[i]->ops.sleep;		adap->fe[i]->ops.sleep = dvb_usb_fe_sleep;		ret = dvb_register_frontend(&adap->dvb_adap, adap->fe[i]);		if (ret < 0) {			dev_err(&d->udev->dev,					""%s: frontend%d registration failed\n"",					KBUILD_MODNAME, i);			goto err_dvb_unregister_frontend;		}		count_registered++;	}	if (d->props->tuner_attach) {		ret = d->props->tuner_attach(adap);		if (ret < 0) {			dev_dbg(&d->udev->dev, ""%s: tuner_attach() failed=%d\n"",					__func__, ret);			goto err_dvb_unregister_frontend;		}	}	ret = dvb_create_media_graph(&adap->dvb_adap, true);	if (ret < 0)		goto err_dvb_unregister_frontend;	ret = dvb_usbv2_media_device_register(adap);	return ret;err_dvb_unregister_frontend:	for (i = count_registered - 1; i >= 0; i--)		dvb_unregister_frontend(adap->fe[i]);err_dvb_frontend_detach:	for (i = MAX_NO_OF_FE_PER_ADAP - 1; i >= 0; i--) {		if (adap->fe[i]) {			dvb_frontend_detach(adap->fe[i]);			adap->fe[i] = NULL;		}	}err:	dev_dbg(&d->udev->dev, ""%s: failed=%d\n"", __func__, ret);	return ret;}",21380
924,4038,CVE-2017-13723,26, tbGetBuffer(unsigned size) {    char *rtrn;     if (size >= BUFFER_SIZE)        return NULL;    if ((BUFFER_SIZE - tbNext) <= size)        tbNext = 0;    rtrn = &textBuffer[tbNext];    tbNext += size;    return rtrn; },30888
454,76,CVE-2017-15650,26,static int labelof(const struct in6_addr *a){	return policyof(a)->label;},384
589,2280,CVE-2016-2324,26,"static inline void push_bitmapped_commit(struct commit *commit, struct ewah_bitmap *reused){	if (writer.selected_nr >= writer.selected_alloc) {		writer.selected_alloc = (writer.selected_alloc + 32) * 2;		REALLOC_ARRAY(writer.selected, writer.selected_alloc);	}	writer.selected[writer.selected_nr].commit = commit;	writer.selected[writer.selected_nr].bitmap = reused;	writer.selected[writer.selected_nr].flags = 0;	writer.selected_nr++;}",17700
175,3305,CVE-2018-10124,26,"void task_clear_jobctl_pending(struct task_struct *task, unsigned long mask){	BUG_ON(mask & ~JOBCTL_PENDING_MASK);	if (mask & JOBCTL_STOP_PENDING)		mask |= JOBCTL_STOP_CONSUME | JOBCTL_STOP_DEQUEUED;	task->jobctl &= ~mask;	if (!(task->jobctl & JOBCTL_PENDING_MASK))		task_clear_jobctl_trapping(task);}",25232
911,1850,CVE-2016-8633,26,"static void fwnet_remove(struct fw_unit *unit){	struct fwnet_peer *peer = dev_get_drvdata(&unit->device);	struct fwnet_device *dev = peer->dev;	struct net_device *net;	int i;	mutex_lock(&fwnet_device_mutex);	net = dev->netdev;	fwnet_remove_peer(peer, dev);	if (list_empty(&dev->peer_list)) {		unregister_netdev(net);		fwnet_fifo_stop(dev);		for (i = 0; dev->queued_datagrams && i < 5; i++)			ssleep(1);		WARN_ON(dev->queued_datagrams);		list_del(&dev->dev_link);		free_netdev(net);	}	mutex_unlock(&fwnet_device_mutex);}",15584
533,1965,CVE-2016-5400,26,"static void airspy_urb_complete(struct urb *urb){	struct airspy *s = urb->context;	struct airspy_frame_buf *fbuf;	dev_dbg_ratelimited(s->dev, ""status=%d length=%d/%d errors=%d\n"",			urb->status, urb->actual_length,			urb->transfer_buffer_length, urb->error_count);	switch (urb->status) {	case 0:              	case -ETIMEDOUT:     		break;	case -ECONNRESET:    	case -ENOENT:	case -ESHUTDOWN:		return;	default:             		dev_err_ratelimited(s->dev, ""URB failed %d\n"", urb->status);		break;	}	if (likely(urb->actual_length > 0)) {		void *ptr;		unsigned int len;		 		fbuf = airspy_get_next_fill_buf(s);		if (unlikely(fbuf == NULL)) {			s->vb_full++;			dev_notice_ratelimited(s->dev,					""videobuf is full, %d packets dropped\n"",					s->vb_full);			goto skip;		}		 		ptr = vb2_plane_vaddr(&fbuf->vb.vb2_buf, 0);		len = airspy_convert_stream(s, ptr, urb->transfer_buffer,				urb->actual_length);		vb2_set_plane_payload(&fbuf->vb.vb2_buf, 0, len);		fbuf->vb.vb2_buf.timestamp = ktime_get_ns();		fbuf->vb.sequence = s->sequence++;		vb2_buffer_done(&fbuf->vb.vb2_buf, VB2_BUF_STATE_DONE);	}skip:	usb_submit_urb(urb, GFP_ATOMIC);}",16469
809,3151,CVE-2016-1245,26,"rtadv_prefix_reset (struct zebra_if *zif, struct rtadv_prefix *rp){  struct rtadv_prefix *rprefix;    rprefix = rtadv_prefix_lookup (zif->rtadv.AdvPrefixList, &rp->prefix);  if (rprefix != NULL)    {      listnode_delete (zif->rtadv.AdvPrefixList, (void *) rprefix);      rtadv_prefix_free (rprefix);      return 1;    }  else    return 0;}",22855
890,3407,CVE-2017-15128,26,"static void enqueue_huge_page(struct hstate *h, struct page *page){	int nid = page_to_nid(page);	list_move(&page->lru, &h->hugepage_freelists[nid]);	h->free_huge_pages++;	h->free_huge_pages_node[nid]++;}",26167
479,2418,CVE-2016-2315,26,"static void option_export_pack_edges(const char *edges){	if (pack_edges)		fclose(pack_edges);	pack_edges = fopen(edges, ""a"");	if (!pack_edges)		die_errno(""Cannot open '%s'"", edges);}",17838
950,3696,CVE-2011-5327,26,static int tcm_loop_sess_logged_in(struct se_session *se_sess){	 	return 1;},28182
686,510,CVE-2012-6711,26,"init_seconds_var (){  SHELL_VAR *v;  v = find_variable (""SECONDS"");  if (v)    {      if (legal_number (value_cell(v), &seconds_value_assigned) == 0)	seconds_value_assigned = 0;    }  INIT_DYNAMIC_VAR (""SECONDS"", (v ? value_cell (v) : (char *)NULL), get_seconds, assign_seconds);  return v;      }",2550
576,3313,CVE-2018-1091,26,static int do_seccomp(struct pt_regs *regs){	if (!test_thread_flag(TIF_SECCOMP))		return 0;	 	regs->gpr[3] = -ENOSYS;	 	if (__secure_computing(NULL))		return -1;	 	regs->gpr[3] = regs->orig_gpr3;	return 0;},25529
344,3384,CVE-2017-18193,26,"static void __detach_extent_node(struct f2fs_sb_info *sbi,				struct extent_tree *et, struct extent_node *en){	rb_erase(&en->rb_node, &et->root);	atomic_dec(&et->node_cnt);	atomic_dec(&sbi->total_ext_node);	if (et->cached_en == en)		et->cached_en = NULL;	kmem_cache_free(extent_node_slab, en);}",26062
499,1794,CVE-2016-9793,26,"int sock_recv_errqueue(struct sock *sk, struct msghdr *msg, int len,		       int level, int type){	struct sock_exterr_skb *serr;	struct sk_buff *skb;	int copied, err;	err = -EAGAIN;	skb = sock_dequeue_err_skb(sk);	if (skb == NULL)		goto out;	copied = skb->len;	if (copied > len) {		msg->msg_flags |= MSG_TRUNC;		copied = len;	}	err = skb_copy_datagram_msg(skb, 0, msg, copied);	if (err)		goto out_free_skb;	sock_recv_timestamp(msg, sk, skb);	serr = SKB_EXT_ERR(skb);	put_cmsg(msg, level, type, sizeof(serr->ee), &serr->ee);	msg->msg_flags |= MSG_ERRQUEUE;	err = copied;out_free_skb:	kfree_skb(skb);out:	return err;}",15078
316,2590,CVE-2016-1583,26,static void set_load_weight(struct task_struct *p){	int prio = p->static_prio - MAX_RT_PRIO;	struct load_weight *load = &p->se.load;	 	if (idle_policy(p->policy)) {		load->weight = scale_load(WEIGHT_IDLEPRIO);		load->inv_weight = WMULT_IDLEPRIO;		return;	}	load->weight = scale_load(sched_prio_to_weight[prio]);	load->inv_weight = sched_prio_to_wmult[prio];},18139
154,553,CVE-2012-2745,26,"int set_create_files_as(struct cred *new, struct inode *inode){	new->fsuid = inode->i_uid;	new->fsgid = inode->i_gid;	return security_kernel_create_files_as(new, inode);}",3155
951,847,CVE-2013-6381,26,"static struct qeth_cmd_buffer *qeth_get_buffer(struct qeth_channel *channel){	struct qeth_cmd_buffer *buffer = NULL;	unsigned long flags;	spin_lock_irqsave(&channel->iob_lock, flags);	buffer = __qeth_get_buffer(channel);	spin_unlock_irqrestore(&channel->iob_lock, flags);	return buffer;}",7276
484,2480,CVE-2016-1583,26,"static struct dentry *proc_root_lookup(struct inode * dir, struct dentry * dentry, unsigned int flags){	if (!proc_pid_lookup(dir, dentry, flags))		return NULL;		return proc_lookup(dir, dentry, flags);}",18029
177,1760,CVE-2016-9793,26,"int __sk_receive_skb(struct sock *sk, struct sk_buff *skb,		     const int nested, unsigned int trim_cap, int refcounted){	int rc = NET_RX_SUCCESS;	if (sk_filter_trim_cap(sk, skb, trim_cap))		goto discard_and_relse;	skb->dev = NULL;	if (sk_rcvqueues_full(sk, sk->sk_rcvbuf)) {		atomic_inc(&sk->sk_drops);		goto discard_and_relse;	}	if (nested)		bh_lock_sock_nested(sk);	else		bh_lock_sock(sk);	if (!sock_owned_by_user(sk)) {		 		mutex_acquire(&sk->sk_lock.dep_map, 0, 1, _RET_IP_);		rc = sk_backlog_rcv(sk, skb);		mutex_release(&sk->sk_lock.dep_map, 1, _RET_IP_);	} else if (sk_add_backlog(sk, skb, sk->sk_rcvbuf)) {		bh_unlock_sock(sk);		atomic_inc(&sk->sk_drops);		goto discard_and_relse;	}	bh_unlock_sock(sk);out:	if (refcounted)		sock_put(sk);	return rc;discard_and_relse:	kfree_skb(skb);	goto out;}",15044
577,2314,CVE-2016-2324,26,"void add_pending_object(struct rev_info *revs,			struct object *obj, const char *name){	add_pending_object_with_mode(revs, obj, name, S_IFINVALID);}",17734
569,1204,CVE-2013-2128,26,"static inline void tcp_mark_urg(struct tcp_sock *tp, int flags){	if (flags & MSG_OOB)		tp->snd_up = tp->write_seq;}",8886
783,341,CVE-2010-2527,26,"  usage( char*  execname )  {    fprintf( stderr,  ""\n"" );    fprintf( stderr,  ""ftstring: string viewer -- part of the FreeType project\n"" );    fprintf( stderr,  ""-------------------------------------------------------\n"" );    fprintf( stderr,  ""\n"" );    fprintf( stderr,  ""Usage: %s [options below] ppem fontname[.ttf|.ttc] ...\n"",             execname );    fprintf( stderr,  ""\n"" );    fprintf( stderr,  ""  -e enc      specify encoding tag (default: unic)\n"" );    fprintf( stderr,  ""  -r R        use resolution R dpi (default: 72 dpi)\n"" );    fprintf( stderr,  ""  -m message  message to display\n"" );    fprintf( stderr,  ""\n"" );    exit( 1 );  }",1820
213,3376,CVE-2017-18222,26,"void hns_rcb_init_hw(struct ring_pair_cb *ring){	hns_rcb_ring_init(ring, RX_RING);	hns_rcb_ring_init(ring, TX_RING);}",25817
205,2707,CVE-2017-16534,26,"static void usb_try_string_workarounds(unsigned char *buf, int *length){	int newlength, oldlength = *length;	for (newlength = 2; newlength + 1 < oldlength; newlength += 2)		if (!isprint(buf[newlength]) || buf[newlength + 1])			break;	if (newlength > 2) {		buf[0] = newlength;		*length = newlength;	}}",19713
258,1316,CVE-2013-1860,26,static void kill_urbs(struct wdm_device *desc){	 	usb_kill_urb(desc->command);	usb_kill_urb(desc->validity);	usb_kill_urb(desc->response);},9323
146,3208,CVE-2018-17407,26,"static float t1_scan_num(char *p, char **r){    float f;    skip(p, ' ');    if (sscanf(p, ""%g"", &f) != 1) {        remove_eol(p, t1_line_array);        pdftex_fail(""a number expected: `%s'"", t1_line_array);    }    if (r != NULL) {        for (; isdigit((unsigned char)*p) || *p == '.' ||             *p == 'e' || *p == 'E' || *p == '+' || *p == '-'; p++);        *r = p;    }    return f;}",23642
250,1331,CVE-2013-1773,26,"kvp_cn_callback(struct cn_msg *msg, struct netlink_skb_parms *nsp){	struct hv_ku_msg *message;	message = (struct hv_ku_msg *)msg->data;	if (msg->seq == KVP_REGISTER) {		pr_info(""KVP: user-mode registering done.\n"");		kvp_register();	}	if (msg->seq == KVP_USER_SET) {		 		if (cancel_delayed_work_sync(&kvp_work))			kvp_respond_to_host(message->kvp_key,						message->kvp_value,						!strlen(message->kvp_key));	}}",9568
814,2409,CVE-2016-2315,26,"static struct branch *new_branch(const char *name){	unsigned int hc = hc_str(name, strlen(name)) % branch_table_sz;	struct branch *b = lookup_branch(name);	if (b)		die(""Invalid attempt to create duplicate branch: %s"", name);	if (check_refname_format(name, REFNAME_ALLOW_ONELEVEL))		die(""Branch name doesn't conform to GIT standards: %s"", name);	b = pool_calloc(1, sizeof(struct branch));	b->name = pool_strdup(name);	b->table_next_branch = branch_table[hc];	b->branch_tree.versions[0].mode = S_IFDIR;	b->branch_tree.versions[1].mode = S_IFDIR;	b->num_notes = 0;	b->active = 0;	b->pack_id = MAX_PACK_ID;	branch_table[hc] = b;	branch_count++;	return b;}",17829
899,3406,CVE-2017-15128,26,"int dissolve_free_huge_pages(unsigned long start_pfn, unsigned long end_pfn){	unsigned long pfn;	struct page *page;	int rc = 0;	if (!hugepages_supported())		return rc;	for (pfn = start_pfn; pfn < end_pfn; pfn += 1 << minimum_order) {		page = pfn_to_page(pfn);		if (PageHuge(page) && !page_count(page)) {			rc = dissolve_free_huge_page(page);			if (rc)				break;		}	}	return rc;}",26166
123,2371,CVE-2016-2324,26,"static void set_children(struct rev_info *revs){	struct commit_list *l;	for (l = revs->commits; l; l = l->next) {		struct commit *commit = l->item;		struct commit_list *p;		for (p = commit->parents; p; p = p->next)			add_child(revs, p->item, commit);	}}",17791
839,1298,CVE-2013-1929,26,"static int tg3_set_phys_id(struct net_device *dev,			    enum ethtool_phys_id_state state){	struct tg3 *tp = netdev_priv(dev);	if (!netif_running(tp->dev))		return -EAGAIN;	switch (state) {	case ETHTOOL_ID_ACTIVE:		return 1;	 	case ETHTOOL_ID_ON:		tw32(MAC_LED_CTRL, LED_CTRL_LNKLED_OVERRIDE |		     LED_CTRL_1000MBPS_ON |		     LED_CTRL_100MBPS_ON |		     LED_CTRL_10MBPS_ON |		     LED_CTRL_TRAFFIC_OVERRIDE |		     LED_CTRL_TRAFFIC_BLINK |		     LED_CTRL_TRAFFIC_LED);		break;	case ETHTOOL_ID_OFF:		tw32(MAC_LED_CTRL, LED_CTRL_LNKLED_OVERRIDE |		     LED_CTRL_TRAFFIC_OVERRIDE);		break;	case ETHTOOL_ID_INACTIVE:		tw32(MAC_LED_CTRL, tp->led_ctrl);		break;	}	return 0;}",9304
291,846,CVE-2013-6381,26,"static void qeth_free_qdio_buffers(struct qeth_card *card){	int i, j;	if (atomic_xchg(&card->qdio.state, QETH_QDIO_UNINITIALIZED) ==		QETH_QDIO_UNINITIALIZED)		return;	qeth_free_cq(card);	cancel_delayed_work_sync(&card->buffer_reclaim_work);	for (j = 0; j < QDIO_MAX_BUFFERS_PER_Q; ++j) {		if (card->qdio.in_q->bufs[j].rx_skb)			dev_kfree_skb_any(card->qdio.in_q->bufs[j].rx_skb);	}	kfree(card->qdio.in_q);	card->qdio.in_q = NULL;	 	qeth_free_buffer_pool(card);	 	if (card->qdio.out_qs) {		for (i = 0; i < card->qdio.no_out_queues; ++i) {			qeth_clear_outq_buffers(card->qdio.out_qs[i], 1);			kfree(card->qdio.out_qs[i]);		}		kfree(card->qdio.out_qs);		card->qdio.out_qs = NULL;	}}",7275
717,2457,CVE-2016-2315,26,"static int update_branch(struct branch *b){	static const char *msg = ""fast-import"";	struct ref_transaction *transaction;	unsigned char old_sha1[20];	struct strbuf err = STRBUF_INIT;	if (is_null_sha1(b->sha1)) {		if (b->delete)			delete_ref(b->name, NULL, 0);		return 0;	}	if (read_ref(b->name, old_sha1))		hashclr(old_sha1);	if (!force_update && !is_null_sha1(old_sha1)) {		struct commit *old_cmit, *new_cmit;		old_cmit = lookup_commit_reference_gently(old_sha1, 0);		new_cmit = lookup_commit_reference_gently(b->sha1, 0);		if (!old_cmit || !new_cmit)			return error(""Branch %s is missing commits."", b->name);		if (!in_merge_bases(old_cmit, new_cmit)) {			warning(""Not updating %s""				"" (new tip %s does not contain %s)"",				b->name, sha1_to_hex(b->sha1), sha1_to_hex(old_sha1));			return -1;		}	}	transaction = ref_transaction_begin(&err);	if (!transaction ||	    ref_transaction_update(transaction, b->name, b->sha1, old_sha1,				   0, msg, &err) ||	    ref_transaction_commit(transaction, &err)) {		ref_transaction_free(transaction);		error(""%s"", err.buf);		strbuf_release(&err);		return -1;	}	ref_transaction_free(transaction);	strbuf_release(&err);	return 0;}",17877
132,1241,CVE-2013-1929,26,"static int tg3_get_settings(struct net_device *dev, struct ethtool_cmd *cmd){	struct tg3 *tp = netdev_priv(dev);	if (tg3_flag(tp, USE_PHYLIB)) {		struct phy_device *phydev;		if (!(tp->phy_flags & TG3_PHYFLG_IS_CONNECTED))			return -EAGAIN;		phydev = tp->mdio_bus->phy_map[TG3_PHY_MII_ADDR];		return phy_ethtool_gset(phydev, cmd);	}	cmd->supported = (SUPPORTED_Autoneg);	if (!(tp->phy_flags & TG3_PHYFLG_10_100_ONLY))		cmd->supported |= (SUPPORTED_1000baseT_Half |				   SUPPORTED_1000baseT_Full);	if (!(tp->phy_flags & TG3_PHYFLG_ANY_SERDES)) {		cmd->supported |= (SUPPORTED_100baseT_Half |				  SUPPORTED_100baseT_Full |				  SUPPORTED_10baseT_Half |				  SUPPORTED_10baseT_Full |				  SUPPORTED_TP);		cmd->port = PORT_TP;	} else {		cmd->supported |= SUPPORTED_FIBRE;		cmd->port = PORT_FIBRE;	}	cmd->advertising = tp->link_config.advertising;	if (tg3_flag(tp, PAUSE_AUTONEG)) {		if (tp->link_config.flowctrl & FLOW_CTRL_RX) {			if (tp->link_config.flowctrl & FLOW_CTRL_TX) {				cmd->advertising |= ADVERTISED_Pause;			} else {				cmd->advertising |= ADVERTISED_Pause |						    ADVERTISED_Asym_Pause;			}		} else if (tp->link_config.flowctrl & FLOW_CTRL_TX) {			cmd->advertising |= ADVERTISED_Asym_Pause;		}	}	if (netif_running(dev) && tp->link_up) {		ethtool_cmd_speed_set(cmd, tp->link_config.active_speed);		cmd->duplex = tp->link_config.active_duplex;		cmd->lp_advertising = tp->link_config.rmt_adv;		if (!(tp->phy_flags & TG3_PHYFLG_ANY_SERDES)) {			if (tp->phy_flags & TG3_PHYFLG_MDIX_STATE)				cmd->eth_tp_mdix = ETH_TP_MDI_X;			else				cmd->eth_tp_mdix = ETH_TP_MDI;		}	} else {		ethtool_cmd_speed_set(cmd, SPEED_UNKNOWN);		cmd->duplex = DUPLEX_UNKNOWN;		cmd->eth_tp_mdix = ETH_TP_MDI_INVALID;	}	cmd->phy_address = tp->phy_addr;	cmd->transceiver = XCVR_INTERNAL;	cmd->autoneg = tp->link_config.autoneg;	cmd->maxtxpkt = 0;	cmd->maxrxpkt = 0;	return 0;}",9247
738,1391,CVE-2012-3364,26,"static void nci_add_new_target(struct nci_dev *ndev,			       struct nci_rf_discover_ntf *ntf){	struct nfc_target *target;	int i, rc;	for (i = 0; i < ndev->n_targets; i++) {		target = &ndev->targets[i];		if (target->logical_idx == ntf->rf_discovery_id) {			 			nci_add_new_protocol(ndev, target, ntf->rf_protocol,					     ntf->rf_tech_and_mode,					     &ntf->rf_tech_specific_params);			return;		}	}	 	if (ndev->n_targets == NCI_MAX_DISCOVERED_TARGETS) {		pr_debug(""not enough room, ignoring new target...\n"");		return;	}	target = &ndev->targets[ndev->n_targets];	rc = nci_add_new_protocol(ndev, target, ntf->rf_protocol,				  ntf->rf_tech_and_mode,				  &ntf->rf_tech_specific_params);	if (!rc) {		target->logical_idx = ntf->rf_discovery_id;		ndev->n_targets++;		pr_debug(""logical idx %d, n_targets %d\n"", target->logical_idx,			 ndev->n_targets);	}}",9997
317,1482,CVE-2014-3185,26,static int whiteheat_port_remove(struct usb_serial_port *port){	struct whiteheat_private *info;	info = usb_get_serial_port_data(port);	kfree(info);	return 0;},11477
580,2087,CVE-2016-4303,26,iperf_get_test_burst(struct iperf_test *ipt){    return ipt->settings->burst;},16995
750,3837,CVE-2017-5122,26,  void EndSplitView() { split_view_controller()->EndSplitView(); },29815
587,550,CVE-2012-2745,26,const struct cred *get_task_cred(struct task_struct *task){	const struct cred *cred;	rcu_read_lock();	do {		cred = __task_cred((task));		BUG_ON(!cred);	} while (!atomic_inc_not_zero(&((struct cred *)cred)->usage));	rcu_read_unlock();	return cred;},3152
763,324,CVE-2010-2527,26,"  event_grid_zoom( double  zoom )  {    status.scale *= zoom;    sprintf( status.header_buffer, ""zoom level %.2f %%\n"",             status.scale / status.scale_0 );    status.header = (const char *)status.header_buffer;  }",1803
874,2181,CVE-2016-4301,26,"cleanup(struct archive_read *a){	struct mtree *mtree;	struct mtree_entry *p, *q;	mtree = (struct mtree *)(a->format->data);	p = mtree->entries;	while (p != NULL) {		q = p->next;		free(p->name);		free_options(p->options);		free(p);		p = q;	}	archive_string_free(&mtree->line);	archive_string_free(&mtree->current_dir);	archive_string_free(&mtree->contents_name);	archive_entry_linkresolver_free(mtree->resolver);	free(mtree->buff);	free(mtree);	(a->format->data) = NULL;	return (ARCHIVE_OK);}",17089
350,2980,CVE-2017-7541,26,"struct wireless_dev *brcmf_ap_add_vif(struct wiphy *wiphy, const char *name,				      struct vif_params *params){	struct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);	struct brcmf_if *ifp = netdev_priv(cfg_to_ndev(cfg));	struct brcmf_cfg80211_vif *vif;	int err;	if (brcmf_cfg80211_vif_event_armed(cfg))		return ERR_PTR(-EBUSY);	brcmf_dbg(INFO, ""Adding vif \""%s\""\n"", name);	vif = brcmf_alloc_vif(cfg, NL80211_IFTYPE_AP);	if (IS_ERR(vif))		return (struct wireless_dev *)vif;	brcmf_cfg80211_arm_vif_event(cfg, vif);	err = brcmf_cfg80211_request_ap_if(ifp);	if (err) {		brcmf_cfg80211_arm_vif_event(cfg, NULL);		goto fail;	}	 	err = brcmf_cfg80211_wait_vif_event(cfg, BRCMF_E_IF_ADD,					    BRCMF_VIF_EVENT_TIMEOUT);	brcmf_cfg80211_arm_vif_event(cfg, NULL);	if (!err) {		brcmf_err(""timeout occurred\n"");		err = -EIO;		goto fail;	}	 	ifp = vif->ifp;	if (!ifp) {		brcmf_err(""no if pointer provided\n"");		err = -ENOENT;		goto fail;	}	strncpy(ifp->ndev->name, name, sizeof(ifp->ndev->name) - 1);	err = brcmf_net_attach(ifp, true);	if (err) {		brcmf_err(""Registering netdevice failed\n"");		free_netdev(ifp->ndev);		goto fail;	}	return &ifp->vif->wdev;fail:	brcmf_free_vif(vif);	return ERR_PTR(err);}",21545
939,1026,CVE-2013-4588,26,"static int ip_vs_genl_new_daemon(struct nlattr **attrs){	if (!(attrs[IPVS_DAEMON_ATTR_STATE] &&	      attrs[IPVS_DAEMON_ATTR_MCAST_IFN] &&	      attrs[IPVS_DAEMON_ATTR_SYNC_ID]))		return -EINVAL;	return start_sync_thread(nla_get_u32(attrs[IPVS_DAEMON_ATTR_STATE]),				 nla_data(attrs[IPVS_DAEMON_ATTR_MCAST_IFN]),				 nla_get_u32(attrs[IPVS_DAEMON_ATTR_SYNC_ID]));}",7623
33,2449,CVE-2016-2315,26,"static struct atom_str *to_atom(const char *s, unsigned short len){	unsigned int hc = hc_str(s, len) % atom_table_sz;	struct atom_str *c;	for (c = atom_table[hc]; c; c = c->next_atom)		if (c->str_len == len && !strncmp(s, c->str_dat, len))			return c;	c = pool_alloc(sizeof(struct atom_str) + len + 1);	c->str_len = len;	strncpy(c->str_dat, s, len);	c->str_dat[len] = 0;	c->next_atom = atom_table[hc];	atom_table[hc] = c;	atom_cnt++;	return c;}",17869
662,3919,CVE-2016-1683,26,"xsltUnregisterAllExtModuleTopLevel(void){    xmlMutexLock(xsltExtMutex);    xmlHashFree(xsltTopLevelsHash, NULL);    xsltTopLevelsHash = NULL;    xmlMutexUnlock(xsltExtMutex);}",30353
96,2321,CVE-2016-2324,26,"static void add_rev_cmdline_list(struct rev_info *revs,				 struct commit_list *commit_list,				 int whence,				 unsigned flags){	while (commit_list) {		struct object *object = &commit_list->item->object;		add_rev_cmdline(revs, object, oid_to_hex(&object->oid),				whence, flags);		commit_list = commit_list->next;	}}",17741
881,3042,CVE-2016-10196,26,evutil_global_setup_locks_(const int enable_locks){	return 0;},22440
8,3825,CVE-2015-1213,26,"const char* intString(int val) {  return val ? ""true"" : ""false"";}",29692
912,2876,CVE-2017-8066,26,"static int gs_usb_set_identify(struct net_device *netdev, int do_identify){	struct gs_can *dev = netdev_priv(netdev);	struct gs_identify_mode imode;	int rc;	if (do_identify)		imode.mode = GS_CAN_IDENTIFY_ON;	else		imode.mode = GS_CAN_IDENTIFY_OFF;	rc = usb_control_msg(interface_to_usbdev(dev->iface),			     usb_sndctrlpipe(interface_to_usbdev(dev->iface),					     0),			     GS_USB_BREQ_IDENTIFY,			     USB_DIR_OUT | USB_TYPE_VENDOR |			     USB_RECIP_INTERFACE,			     dev->channel,			     0,			     &imode,			     sizeof(imode),			     100);	return (rc > 0) ? 0 : rc;}",21353
526,236,CVE-2018-10184,26,"static void h2_recv(struct connection *conn){	struct h2c *h2c = conn->mux_ctx;	struct buffer *buf;	int max;	if (!h2_recv_allowed(h2c))		return;	buf = h2_get_buf(h2c, &h2c->dbuf);	if (!buf) {		h2c->flags |= H2_CF_DEM_DALLOC;		return;	}	 	max = buf->size - buf->i;	if (max)		conn->xprt->rcv_buf(conn, buf, max);	if (!buf->i) {		h2_release_buf(h2c, &h2c->dbuf);		return;	}	if (buf->i == buf->size)		h2c->flags |= H2_CF_DEM_DFULL;	return;}",1257
603,1816,CVE-2016-8658,26,static void brcmf_init_conf(struct brcmf_cfg80211_conf *conf){	conf->frag_threshold = (u32)-1;	conf->rts_threshold = (u32)-1;	conf->retry_short = (u32)-1;	conf->retry_long = (u32)-1;},15464
93,3960,CVE-2016-3745,26,"static int session_release_effect(struct session_s *session, struct effect_s *fx){    ALOGW_IF(effect_release(fx) != 0, "" session_release_effect() failed for id %d"", fx->id);    session->created_msk &= ~(1<<fx->id); if (session->created_msk == 0) {        ALOGV(""session_release_effect() last effect: removing session"");        list_remove(&session->node);        free(session); } return 0;}",30644
971,3687,CVE-2011-5327,26,static int tcm_loop_driver_remove(struct device *dev){	struct tcm_loop_hba *tl_hba;	struct Scsi_Host *sh;	tl_hba = to_tcm_loop_hba(dev);	sh = tl_hba->sh;	scsi_remove_host(sh);	scsi_host_put(sh);	return 0;},28173
651,1187,CVE-2013-2220,26,"rad_cvt_addr(const void *data){	struct in_addr value;	memcpy(&value.s_addr, data, sizeof value.s_addr);	return value;}",8777
636,3579,CVE-2018-20182,26,"handle_child_line(const char *line, void *data){	UNUSED(data);	const char *val;	char buf[1024];	if (str_startswith(line, ""Class:""))	{		val = line + sizeof(""Class:"");		 		val += strspn(val, "" \t"") + sizeof(""Class"");		current_device.klass = strtol(val, NULL, 16);	}	else if (str_startswith(line, ""Vendor:""))	{		val = line + sizeof(""Vendor:"");		current_device.vendor = strtol(val, NULL, 16);	}	else if (str_startswith(line, ""Device:""))	{		val = line + sizeof(""Device:"");		 		if (!strchr(val, ':'))			current_device.device = strtol(val, NULL, 16);	}	else if (str_startswith(line, ""SVendor:""))	{		val = line + sizeof(""SVendor:"");		current_device.subvendor = strtol(val, NULL, 16);	}	else if (str_startswith(line, ""SDevice:""))	{		val = line + sizeof(""SDevice:"");		current_device.subdevice = strtol(val, NULL, 16);	}	else if (str_startswith(line, ""Rev:""))	{		val = line + sizeof(""Rev:"");		current_device.revision = strtol(val, NULL, 16);	}	else if (str_startswith(line, ""ProgIf:""))	{		val = line + sizeof(""ProgIf:"");		current_device.progif = strtol(val, NULL, 16);	}	else if (strspn(line, "" \t"") == strlen(line))	{		 		snprintf(buf, sizeof(buf), ""%04x,%04x,%04x,%04x,%04x,%02x,%02x\n"",			 current_device.klass, current_device.vendor,			 current_device.device, current_device.subvendor,			 current_device.subdevice, current_device.revision, current_device.progif);		lspci_send(buf);		memset(&current_device, 0, sizeof(current_device));	}	else	{		logger(Core, Warning, ""handle_child_line(), Unrecognized lspci line '%s'"", line);	}	return True;}",27877
858,2295,CVE-2016-2324,26,int prepare_bitmap_git(void){	if (bitmap_git.loaded)		return 0;	if (!open_pack_bitmap())		return load_pack_bitmap();	return -1;},17715
622,2762,CVE-2017-10671,26,atoll( const char* str )    {    long long value;    long long sign;    while ( isspace( *str ) )	++str;    switch ( *str )	{	case '-': sign = -1; ++str; break;	case '+': sign = 1; ++str; break;	default: sign = 1; break;	}    value = 0;    while ( isdigit( *str ) )	{	value = value * 10 + ( *str - '0' );	++str;	}    return sign * value;    },20610
235,619,CVE-2011-3353,26,void fuse_dev_cleanup(void){	misc_deregister(&fuse_miscdevice);	kmem_cache_destroy(fuse_req_cachep);},5592
342,2708,CVE-2017-16526,26,"static void uwbd_event_handle(struct uwb_event *evt){	struct uwb_rc *rc;	int should_keep;	rc = evt->rc;	if (rc->ready) {		switch (evt->type) {		case UWB_EVT_TYPE_NOTIF:			should_keep = uwbd_event_handle_urc(evt);			if (should_keep <= 0)				kfree(evt->notif.rceb);			break;		case UWB_EVT_TYPE_MSG:			uwbd_event_handle_message(evt);			break;		default:			dev_err(&rc->uwb_dev.dev, ""UWBD: invalid event type %d\n"", evt->type);			break;		}	}	__uwb_rc_put(rc);	 }",19881
109,2473,CVE-2016-2315,26,"static void track_linear(struct rev_info *revs, struct commit *commit){	if (revs->track_first_time) {		revs->linear = 1;		revs->track_first_time = 0;	} else {		struct commit_list *p;		for (p = revs->previous_parents; p; p = p->next)			if (p->item == NULL ||  			    !hashcmp(p->item->object.sha1, commit->object.sha1))				break;		revs->linear = p != NULL;	}	if (revs->reverse) {		if (revs->linear)			commit->object.flags |= TRACK_LINEAR;	}	free_commit_list(revs->previous_parents);	revs->previous_parents = copy_commit_list(commit->parents);}",17893
760,3965,CVE-2016-2463,26,"void H264SwDecTrace(char *string){ FILE *fp;    fp = fopen(""dec_api.trc"", ""at""); if (!fp) return;    fwrite(string, 1, strlen(string), fp);    fwrite(""\n"", 1,1, fp);    fclose(fp);}",30671
389,633,CVE-2011-3353,26,"static void fuse_request_init(struct fuse_req *req){	memset(req, 0, sizeof(*req));	INIT_LIST_HEAD(&req->list);	INIT_LIST_HEAD(&req->intr_entry);	init_waitqueue_head(&req->waitq);	atomic_set(&req->count, 1);}",5606
492,3983,CVE-2017-7376,26,static int is_hex(char c) { if (((c >= '0') && (c <= '9')) || ((c >= 'a') && (c <= 'f')) || ((c >= 'A') && (c <= 'F'))) return(1); return(0);},30803
628,2138,CVE-2016-4303,26,"iperf_set_test_zerocopy(struct iperf_test *ipt, int zerocopy){    ipt->zerocopy = (zerocopy && has_sendfile());}",17046
982,676,CVE-2011-2517,26,"static int nl80211_parse_key(struct genl_info *info, struct key_parse *k){	int err;	memset(k, 0, sizeof(*k));	k->idx = -1;	k->type = -1;	if (info->attrs[NL80211_ATTR_KEY])		err = nl80211_parse_key_new(info->attrs[NL80211_ATTR_KEY], k);	else		err = nl80211_parse_key_old(info, k);	if (err)		return err;	if (k->def && k->defmgmt)		return -EINVAL;	if (k->defmgmt) {		if (k->def_uni || !k->def_multi)			return -EINVAL;	}	if (k->idx != -1) {		if (k->defmgmt) {			if (k->idx < 4 || k->idx > 5)				return -EINVAL;		} else if (k->def) {			if (k->idx < 0 || k->idx > 3)				return -EINVAL;		} else {			if (k->idx < 0 || k->idx > 5)				return -EINVAL;		}	}	return 0;}",6575
769,2201,CVE-2016-3955,26,"void usbip_dump_header(struct usbip_header *pdu){	pr_debug(""BASE: cmd %u seq %u devid %u dir %u ep %u\n"",		 pdu->base.command,		 pdu->base.seqnum,		 pdu->base.devid,		 pdu->base.direction,		 pdu->base.ep);	switch (pdu->base.command) {	case USBIP_CMD_SUBMIT:		pr_debug(""USBIP_CMD_SUBMIT: x_flags %u x_len %u sf %u #p %d iv %d\n"",			 pdu->u.cmd_submit.transfer_flags,			 pdu->u.cmd_submit.transfer_buffer_length,			 pdu->u.cmd_submit.start_frame,			 pdu->u.cmd_submit.number_of_packets,			 pdu->u.cmd_submit.interval);		break;	case USBIP_CMD_UNLINK:		pr_debug(""USBIP_CMD_UNLINK: seq %u\n"",			 pdu->u.cmd_unlink.seqnum);		break;	case USBIP_RET_SUBMIT:		pr_debug(""USBIP_RET_SUBMIT: st %d al %u sf %d #p %d ec %d\n"",			 pdu->u.ret_submit.status,			 pdu->u.ret_submit.actual_length,			 pdu->u.ret_submit.start_frame,			 pdu->u.ret_submit.number_of_packets,			 pdu->u.ret_submit.error_count);		break;	case USBIP_RET_UNLINK:		pr_debug(""USBIP_RET_UNLINK: status %d\n"",			 pdu->u.ret_unlink.status);		break;	default:		 		pr_err(""unknown command\n"");		break;	}}",17128
710,148,CVE-2017-13090,26,"set_local_file (const char **file, const char *default_file){  if (opt.output_document)    {      if (output_stream_regular)        *file = opt.output_document;    }  else    *file = default_file;}",602
279,932,CVE-2013-4591,26,"static int _nfs4_proc_destroy_clientid(struct nfs_client *clp,		struct rpc_cred *cred){	struct rpc_message msg = {		.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_DESTROY_CLIENTID],		.rpc_argp = clp,		.rpc_cred = cred,	};	int status;	status = rpc_call_sync(clp->cl_rpcclient, &msg, RPC_TASK_TIMEOUT);	if (status)		dprintk(""NFS: Got error %d from the server %s on ""			""DESTROY_CLIENTID."", status, clp->cl_hostname);	return status;}",7529
964,142,CVE-2017-13090,26,"fd_read_line (int fd){  return fd_read_hunk (fd, line_terminator, 128, FD_READ_LINE_MAX);}",596
751,3761,CVE-2011-2347,26,"  void Append(int pos, int size) {    target_.Append(data_, data_->data() + pos, size);  }",29144
537,1376,CVE-2013-1772,26,void kdb_syslog_data(char *syslog_data[4]){	syslog_data[0] = log_buf;	syslog_data[1] = log_buf + log_buf_len;	syslog_data[2] = log_buf + log_end -		(logged_chars < log_buf_len ? logged_chars : log_buf_len);	syslog_data[3] = log_buf + log_end;},9613
408,2974,CVE-2017-7742,26,"i2flac24_array (const int *src, int *dest, int count){	while (--count >= 0)		dest [count] = src [count] >> 8 ;}  ",21495
242,2977,CVE-2017-7742,26,"s2flac24_array (const short *src, int *dest, int count){	while (--count >= 0)		dest [count] = src [count] << 8 ;}  ",21498
706,1521,CVE-2014-3158,26,"options_from_list(w, priv)    struct wordlist *w;    int priv;{    char *argv[MAXARGS];    option_t *opt;    int i, n, ret = 0;    struct wordlist *w0;    privileged_option = priv;    option_source = ""secrets file"";    option_priority = OPRIO_SECFILE;    while (w != NULL) {	opt = find_option(w->word);	if (opt == NULL) {	    option_error(""In secrets file: unrecognized option '%s'"",			 w->word);	    goto err;	}	n = n_arguments(opt);	w0 = w;	for (i = 0; i < n; ++i) {	    w = w->next;	    if (w == NULL) {		option_error(			""In secrets file: too few parameters for option '%s'"",			w0->word);		goto err;	    }	    argv[i] = w->word;	}	if (!process_option(opt, w0->word, argv))	    goto err;	w = w->next;    }    ret = 1;err:    return ret;}",11516
190,2440,CVE-2016-2315,26,static void release_tree_content_recursive(struct tree_content *t){	unsigned int i;	for (i = 0; i < t->entry_count; i++)		release_tree_entry(t->entries[i]);	release_tree_content(t);},17860
993,4047,CVE-2015-9262,26,"_XcursorThemeInherits (const char *full){    char    line[8192];    char    *result = NULL;    FILE    *f;    if (!full)        return NULL;    f = fopen (full, ""r"");    if (f)    {	while (fgets (line, sizeof (line), f))	{	    if (!strncmp (line, ""Inherits"", 8))	    {		char    *l = line + 8;		char    *r;		while (*l == ' ') l++; 		if (*l != '=') continue; 		l++; 		while (*l == ' ') l++;		result = malloc (strlen (l)); 		if (result) 		{ 		    r = result;		    while (*l)		    {			while (XcursorSep(*l) || XcursorWhite (*l)) l++;			if (!*l)			    break;			if (r != result)			    *r++ = ':';			while (*l && !XcursorWhite(*l) &&			       !XcursorSep(*l))			    *r++ = *l++;		    }		    *r++ = '\0';		}		break;	    }	}	fclose (f);    }    return result;}",30919
421,3708,CVE-2010-5331,26,"void radeon_atom_output_lock(struct drm_encoder *encoder, int lock){	struct drm_device *dev = encoder->dev;	struct radeon_device *rdev = dev->dev_private;	int bios_6_scratch;	if (rdev->family >= CHIP_R600)		bios_6_scratch = RREG32(R600_BIOS_6_SCRATCH);	else		bios_6_scratch = RREG32(RADEON_BIOS_6_SCRATCH);	if (lock)		bios_6_scratch |= ATOM_S6_CRITICAL_STATE;	else		bios_6_scratch &= ~ATOM_S6_CRITICAL_STATE;	if (rdev->family >= CHIP_R600)		WREG32(R600_BIOS_6_SCRATCH, bios_6_scratch);	else		WREG32(RADEON_BIOS_6_SCRATCH, bios_6_scratch);}",28194
867,1907,CVE-2016-6516,26,static int ioctl_fsfreeze(struct file *filp){	struct super_block *sb = file_inode(filp)->i_sb;	if (!capable(CAP_SYS_ADMIN))		return -EPERM;	 	if (sb->s_op->freeze_fs == NULL && sb->s_op->freeze_super == NULL)		return -EOPNOTSUPP;	 	if (sb->s_op->freeze_super)		return sb->s_op->freeze_super(sb);	return freeze_super(sb);},16004
601,1300,CVE-2013-1929,26,"static int tg3_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol){	struct tg3 *tp = netdev_priv(dev);	struct device *dp = &tp->pdev->dev;	if (wol->wolopts & ~WAKE_MAGIC)		return -EINVAL;	if ((wol->wolopts & WAKE_MAGIC) &&	    !(tg3_flag(tp, WOL_CAP) && device_can_wakeup(dp)))		return -EINVAL;	device_set_wakeup_enable(dp, wol->wolopts & WAKE_MAGIC);	spin_lock_bh(&tp->lock);	if (device_may_wakeup(dp))		tg3_flag_set(tp, WOL_ENABLE);	else		tg3_flag_clear(tp, WOL_ENABLE);	spin_unlock_bh(&tp->lock);	return 0;}",9306
375,3001,CVE-2017-5548,26,static int atusb_get_and_clear_error(struct atusb *atusb){	int err = atusb->err;	atusb->err = 0;	return err;},22040
1,2854,CVE-2017-8067,26,"static int port_fops_release(struct inode *inode, struct file *filp){	struct port *port;	port = filp->private_data;	 	send_control_msg(port, VIRTIO_CONSOLE_PORT_OPEN, 0);	spin_lock_irq(&port->inbuf_lock);	port->guest_connected = false;	discard_port_data(port);	spin_unlock_irq(&port->inbuf_lock);	spin_lock_irq(&port->outvq_lock);	reclaim_consumed_buffers(port);	spin_unlock_irq(&port->outvq_lock);	reclaim_dma_bufs();	 	kref_put(&port->kref, remove_port);	return 0;}",21331
84,2641,CVE-2017-1000251,26,void l2cap_load(void){	 	return;},19479
453,1135,CVE-2013-2237,26,static inline int pfkey_init_proc(struct net *net){	return 0;},8724
922,789,CVE-2013-6381,26,"static int qeth_alloc_qdio_buffers(struct qeth_card *card){	int i, j;	QETH_DBF_TEXT(SETUP, 2, ""allcqdbf"");	if (atomic_cmpxchg(&card->qdio.state, QETH_QDIO_UNINITIALIZED,		QETH_QDIO_ALLOCATED) != QETH_QDIO_UNINITIALIZED)		return 0;	card->qdio.in_q = kzalloc(sizeof(struct qeth_qdio_q),				   GFP_KERNEL);	if (!card->qdio.in_q)		goto out_nomem;	QETH_DBF_TEXT(SETUP, 2, ""inq"");	QETH_DBF_HEX(SETUP, 2, &card->qdio.in_q, sizeof(void *));	memset(card->qdio.in_q, 0, sizeof(struct qeth_qdio_q));	 	for (i = 0; i < QDIO_MAX_BUFFERS_PER_Q; ++i) {		card->qdio.in_q->bufs[i].buffer =			&card->qdio.in_q->qdio_bufs[i];		card->qdio.in_q->bufs[i].rx_skb = NULL;	}	 	if (qeth_alloc_buffer_pool(card))		goto out_freeinq;	 	card->qdio.out_qs =		kzalloc(card->qdio.no_out_queues *			sizeof(struct qeth_qdio_out_q *), GFP_KERNEL);	if (!card->qdio.out_qs)		goto out_freepool;	for (i = 0; i < card->qdio.no_out_queues; ++i) {		card->qdio.out_qs[i] = kzalloc(sizeof(struct qeth_qdio_out_q),					       GFP_KERNEL);		if (!card->qdio.out_qs[i])			goto out_freeoutq;		QETH_DBF_TEXT_(SETUP, 2, ""outq %i"", i);		QETH_DBF_HEX(SETUP, 2, &card->qdio.out_qs[i], sizeof(void *));		card->qdio.out_qs[i]->queue_no = i;		 		for (j = 0; j < QDIO_MAX_BUFFERS_PER_Q; ++j) {			WARN_ON(card->qdio.out_qs[i]->bufs[j] != NULL);			if (qeth_init_qdio_out_buf(card->qdio.out_qs[i], j))				goto out_freeoutqbufs;		}	}	 	if (qeth_alloc_cq(card))		goto out_freeoutq;	return 0;out_freeoutqbufs:	while (j > 0) {		--j;		kmem_cache_free(qeth_qdio_outbuf_cache,				card->qdio.out_qs[i]->bufs[j]);		card->qdio.out_qs[i]->bufs[j] = NULL;	}out_freeoutq:	while (i > 0) {		kfree(card->qdio.out_qs[--i]);		qeth_clear_outq_buffers(card->qdio.out_qs[i], 1);	}	kfree(card->qdio.out_qs);	card->qdio.out_qs = NULL;out_freepool:	qeth_free_buffer_pool(card);out_freeinq:	kfree(card->qdio.in_q);	card->qdio.in_q = NULL;out_nomem:	atomic_set(&card->qdio.state, QETH_QDIO_UNINITIALIZED);	return -ENOMEM;}",7218
804,3266,CVE-2018-12326,26,"static void latencyDistMode(void) {    redisReply *reply;    long long start, latency, count = 0;    long long history_interval =        config.interval ? config.interval/1000 :                          LATENCY_DIST_DEFAULT_INTERVAL;    long long history_start = ustime();    int j, outputs = 0;    struct distsamples samples[] = {                 {10,0,'.'},                  {125,0,'-'},                 {250,0,'*'},                 {500,0,'#'},                 {1000,0,'1'},                {2000,0,'2'},                {3000,0,'3'},                {4000,0,'4'},                {5000,0,'5'},                {6000,0,'6'},                {7000,0,'7'},                {8000,0,'8'},                {9000,0,'9'},                {10000,0,'A'},               {20000,0,'B'},               {30000,0,'C'},               {40000,0,'D'},               {50000,0,'E'},               {100000,0,'F'},              {200000,0,'G'},              {300000,0,'H'},              {400000,0,'I'},              {500000,0,'J'},              {1000000,0,'K'},             {2000000,0,'L'},             {4000000,0,'M'},             {8000000,0,'N'},             {16000000,0,'O'},            {30000000,0,'P'},            {60000000,0,'Q'},            {0,0,'?'},               };    if (!context) exit(1);    while(1) {        start = ustime();        reply = reconnectingRedisCommand(context,""PING"");        if (reply == NULL) {            fprintf(stderr,""\nI/O error\n"");            exit(1);        }        latency = ustime()-start;        freeReplyObject(reply);        count++;                 for (j = 0; ; j++) {            if (samples[j].max == 0 || latency <= samples[j].max) {                samples[j].count++;                break;            }        }                 if (count && (ustime()-history_start)/1000 > history_interval) {            if ((outputs++ % 20) == 0)                showLatencyDistLegend();            showLatencyDistSamples(samples,count);            history_start = ustime();            count = 0;        }        usleep(LATENCY_SAMPLE_RATE * 1000);    }}",25093
588,275,CVE-2017-6542,26,static int ssh_comp_none_disable(void *handle){    return 0;},1339
694,612,CVE-2011-3353,26,"static int fuse_copy_do(struct fuse_copy_state *cs, void **val, unsigned *size){	unsigned ncpy = min(*size, cs->len);	if (val) {		if (cs->write)			memcpy(cs->buf, *val, ncpy);		else			memcpy(*val, cs->buf, ncpy);		*val += ncpy;	}	*size -= ncpy;	cs->len -= ncpy;	cs->buf += ncpy;	return ncpy;}",5585
402,2415,CVE-2016-2315,26,"static void option_date_format(const char *fmt){	if (!strcmp(fmt, ""raw""))		whenspec = WHENSPEC_RAW;	else if (!strcmp(fmt, ""rfc2822""))		whenspec = WHENSPEC_RFC2822;	else if (!strcmp(fmt, ""now""))		whenspec = WHENSPEC_NOW;	else		die(""unknown --date-format argument %s"", fmt);}",17835
633,3581,CVE-2018-20182,26,"lspci_process_line(const char *line, void *data){	UNUSED(data);	char *lspci_command[5] = { ""lspci"", ""-m"", ""-n"", ""-v"", NULL };	if (!strcmp(line, ""LSPCI""))	{		memset(&current_device, 0, sizeof(current_device));		subprocess(lspci_command, handle_child_line, NULL);		 		lspci_send("".\n"");	}	else	{		logger(Core, Error, ""lspci_process_line(), invalid line '%s'"", line);	}	return True;}",27879
412,911,CVE-2013-6381,26,"int qeth_setadpparms_change_macaddr(struct qeth_card *card){	int rc;	struct qeth_cmd_buffer *iob;	struct qeth_ipa_cmd *cmd;	QETH_CARD_TEXT(card, 4, ""chgmac"");	iob = qeth_get_adapter_cmd(card, IPA_SETADP_ALTER_MAC_ADDRESS,				   sizeof(struct qeth_ipacmd_setadpparms));	cmd = (struct qeth_ipa_cmd *)(iob->data+IPA_PDU_HEADER_SIZE);	cmd->data.setadapterparms.data.change_addr.cmd = CHANGE_ADDR_READ_MAC;	cmd->data.setadapterparms.data.change_addr.addr_size = OSA_ADDR_LEN;	memcpy(&cmd->data.setadapterparms.data.change_addr.addr,	       card->dev->dev_addr, OSA_ADDR_LEN);	rc = qeth_send_ipa_cmd(card, iob, qeth_setadpparms_change_macaddr_cb,			       NULL);	return rc;}",7340
571,1958,CVE-2016-5400,26,"static int airspy_querycap(struct file *file, void *fh,		struct v4l2_capability *cap){	struct airspy *s = video_drvdata(file);	strlcpy(cap->driver, KBUILD_MODNAME, sizeof(cap->driver));	strlcpy(cap->card, s->vdev.name, sizeof(cap->card));	usb_make_path(s->udev, cap->bus_info, sizeof(cap->bus_info));	cap->device_caps = V4L2_CAP_SDR_CAPTURE | V4L2_CAP_STREAMING |			V4L2_CAP_READWRITE | V4L2_CAP_TUNER;	cap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;	return 0;}",16462
835,381,CVE-2010-1642,26,"static void delete_partial_auth(struct smbd_server_connection *sconn,				struct pending_auth_data *pad){	if (!pad) {		return;	}	DLIST_REMOVE(sconn->smb1.pd_list, pad);	data_blob_free(&pad->partial_data);	SAFE_FREE(pad);}",1894
61,2054,CVE-2016-4568,26,"int vb2_streamoff(struct vb2_queue *q, enum v4l2_buf_type type){	if (vb2_fileio_is_active(q)) {		dprintk(1, ""file io in progress\n"");		return -EBUSY;	}	return vb2_core_streamoff(q, type);}",16756
436,3838,CVE-2017-5122,26,  int IsSelecting() { return window_selector_controller()->IsSelecting(); },29816
306,2920,CVE-2017-8063,26,"static int cxusb_aver_lgdt3303_frontend_attach(struct dvb_usb_adapter *adap){	adap->fe_adap[0].fe = dvb_attach(lgdt330x_attach, &cxusb_aver_lgdt3303_config,			      &adap->dev->i2c_adap);	if (adap->fe_adap[0].fe != NULL)		return 0;	return -EIO;}",21397
82,814,CVE-2013-6381,26,"static void qeth_configure_unitaddr(struct qeth_card *card, char *prcd){	QETH_DBF_TEXT(SETUP, 2, ""cfgunit"");	card->info.chpid = prcd[30];	card->info.unit_addr2 = prcd[31];	card->info.cula = prcd[63];	card->info.guestlan = ((prcd[0x10] == _ascebc['V']) &&			       (prcd[0x11] == _ascebc['M']));}",7243
303,2595,CVE-2016-1583,26,void set_sched_topology(struct sched_domain_topology_level *tl){	sched_domain_topology = tl;},18144
38,2299,CVE-2016-2324,26,"static void show_commit(struct commit *commit, void *data){}",17719
595,2411,CVE-2016-2315,26,"static struct tree_content *new_tree_content(unsigned int cnt){	struct avail_tree_content *f, *l = NULL;	struct tree_content *t;	unsigned int hc = hc_entries(cnt);	for (f = avail_tree_table[hc]; f; l = f, f = f->next_avail)		if (f->entry_capacity >= cnt)			break;	if (f) {		if (l)			l->next_avail = f->next_avail;		else			avail_tree_table[hc] = f->next_avail;	} else {		cnt = cnt & 7 ? ((cnt / 8) + 1) * 8 : cnt;		f = pool_alloc(sizeof(*t) + sizeof(t->entries[0]) * cnt);		f->entry_capacity = cnt;	}	t = (struct tree_content*)f;	t->entry_count = 0;	t->delta_depth = 0;	return t;}",17831
522,2297,CVE-2016-2324,26,"static struct ewah_bitmap *read_bitmap_1(struct bitmap_index *index){	struct ewah_bitmap *b = ewah_pool_new();	int bitmap_size = ewah_read_mmap(b,		index->map + index->map_pos,		index->map_size - index->map_pos);	if (bitmap_size < 0) {		error(""Failed to load bitmap index (corrupted?)"");		ewah_pool_free(b);		return NULL;	}	index->map_pos += bitmap_size;	return b;}",17717
849,2630,CVE-2017-1000251,26,"static inline void l2cap_chan_add(struct l2cap_conn *conn, struct sock *sk, struct sock *parent){	struct l2cap_chan_list *l = &conn->chan_list;	write_lock_bh(&l->lock);	__l2cap_chan_add(conn, sk, parent);	write_unlock_bh(&l->lock);}",19468
914,1924,CVE-2016-6187,26,"static int apparmor_path_symlink(const struct path *dir, struct dentry *dentry,				 const char *old_name){	return common_perm_create(OP_SYMLINK, dir, dentry, AA_MAY_CREATE,				  S_IFLNK);}",16269
818,1928,CVE-2016-6187,26," static int apparmor_task_setrlimit(struct task_struct *task,		unsigned int resource, struct rlimit *new_rlim){	struct aa_profile *profile = __aa_current_profile();	int error = 0;	if (!unconfined(profile))		error = aa_task_setrlimit(profile, task, resource, new_rlim);	return error;}",16273
701,2990,CVE-2017-7541,26,"brcmf_wowl_nd_results(struct brcmf_if *ifp, const struct brcmf_event_msg *e,		      void *data){	struct brcmf_cfg80211_info *cfg = ifp->drvr->config;	struct brcmf_pno_scanresults_le *pfn_result;	struct brcmf_pno_net_info_le *netinfo;	brcmf_dbg(SCAN, ""Enter\n"");	if (e->datalen < (sizeof(*pfn_result) + sizeof(*netinfo))) {		brcmf_dbg(SCAN, ""Event data to small. Ignore\n"");		return 0;	}	pfn_result = (struct brcmf_pno_scanresults_le *)data;	if (e->event_code == BRCMF_E_PFN_NET_LOST) {		brcmf_dbg(SCAN, ""PFN NET LOST event. Ignore\n"");		return 0;	}	if (le32_to_cpu(pfn_result->count) < 1) {		brcmf_err(""Invalid result count, expected 1 (%d)\n"",			  le32_to_cpu(pfn_result->count));		return -EINVAL;	}	netinfo = brcmf_get_netinfo_array(pfn_result);	memcpy(cfg->wowl.nd->ssid.ssid, netinfo->SSID, netinfo->SSID_len);	cfg->wowl.nd->ssid.ssid_len = netinfo->SSID_len;	cfg->wowl.nd->n_channels = 1;	cfg->wowl.nd->channels[0] =		ieee80211_channel_to_frequency(netinfo->channel,			netinfo->channel <= CH_MAX_2G_CHANNEL ?					NL80211_BAND_2GHZ : NL80211_BAND_5GHZ);	cfg->wowl.nd_info->n_matches = 1;	cfg->wowl.nd_info->matches[0] = cfg->wowl.nd;	 	cfg->wowl.nd_data_completed = true;	wake_up(&cfg->wowl.nd_data_wait);	return 0;}",21555
89,2603,CVE-2016-1583,26,"static int ttwu_remote(struct task_struct *p, int wake_flags){	struct rq_flags rf;	struct rq *rq;	int ret = 0;	rq = __task_rq_lock(p, &rf);	if (task_on_rq_queued(p)) {		 		update_rq_clock(rq);		ttwu_do_wakeup(rq, p, wake_flags, rf.cookie);		ret = 1;	}	__task_rq_unlock(rq, &rf);	return ret;}",18152
354,2797,CVE-2017-9994,26,"static void inv_predict_9(int *p, const int *p_l, const int *p_tl,                          const int *p_t, const int *p_tr){    p[0] = p_t[0] + p_tr[0] >> 1;    p[1] = p_t[1] + p_tr[1] >> 1;    p[2] = p_t[2] + p_tr[2] >> 1;    p[3] = p_t[3] + p_tr[3] >> 1;}",20682
131,1803,CVE-2016-8658,26,"brcmf_cfg80211_leave_ibss(struct wiphy *wiphy, struct net_device *ndev){	struct brcmf_if *ifp = netdev_priv(ndev);	brcmf_dbg(TRACE, ""Enter\n"");	if (!check_vif_up(ifp->vif)) {		 		return 0;	}	brcmf_link_down(ifp->vif, WLAN_REASON_DEAUTH_LEAVING);	brcmf_net_setcarrier(ifp, false);	brcmf_dbg(TRACE, ""Exit\n"");	return 0;}",15451
866,3530,CVE-2018-20855,26,static int is_qp0(enum ib_qp_type qp_type){	return qp_type == IB_QPT_SMI;},27558
938,2148,CVE-2016-4303,26,"timeval_equals(struct timeval * tv0, struct timeval * tv1){    if ( tv0->tv_sec == tv1->tv_sec && tv0->tv_usec == tv1->tv_usec )	return 1;    else	return 0;}",17056
228,3351,CVE-2017-1000418,26,static inline int wm_isupper(int c) {    return (c >= 'A' && c <= 'Z');},25631
58,444,CVE-2014-2013,26,"static int count_commas(char *s){	int n = 0;	while (*s)	{		if (*s == ',')			n ++;		s ++;	}	return n;}",2181
23,770,CVE-2013-6763,26,"int au1100fb_drv_resume(struct platform_device *dev){	struct au1100fb_device *fbdev = platform_get_drvdata(dev);	if (!fbdev)		return 0;	memcpy(fbdev->regs, &fbregs, sizeof(struct au1100fb_regs));	 	au_writel(sys_clksrc, SYS_CLKSRC);	 	au1100fb_fb_blank(VESA_NO_BLANKING, &fbdev->info);	return 0;}",7164
815,2650,CVE-2017-1000251,26,"static void l2cap_sock_kill(struct sock *sk){	if (!sock_flag(sk, SOCK_ZAPPED) || sk->sk_socket)		return;	BT_DBG(""sk %p state %d"", sk, sk->sk_state);	 	bt_sock_unlink(&l2cap_sk_list, sk);	sock_set_flag(sk, SOCK_DEAD);	sock_put(sk);}",19488
957,3074,CVE-2016-10066,26,"static inline double MagickMax(const double x,const double y){  if (x > y)    return(x);  return(y);}",22552
198,3552,CVE-2018-20855,26,"static int query_qp_attr(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp,			 struct ib_qp_attr *qp_attr){	int outlen = MLX5_ST_SZ_BYTES(query_qp_out);	struct mlx5_qp_context *context;	int mlx5_state;	u32 *outb;	int err = 0;	outb = kzalloc(outlen, GFP_KERNEL);	if (!outb)		return -ENOMEM;	err = mlx5_core_qp_query(dev->mdev, &qp->trans_qp.base.mqp, outb,				 outlen);	if (err)		goto out;	 	context = (struct mlx5_qp_context *)MLX5_ADDR_OF(query_qp_out, outb, qpc);	mlx5_state = be32_to_cpu(context->flags) >> 28;	qp->state		     = to_ib_qp_state(mlx5_state);	qp_attr->path_mtu	     = context->mtu_msgmax >> 5;	qp_attr->path_mig_state	     =		to_ib_mig_state((be32_to_cpu(context->flags) >> 11) & 0x3);	qp_attr->qkey		     = be32_to_cpu(context->qkey);	qp_attr->rq_psn		     = be32_to_cpu(context->rnr_nextrecvpsn) & 0xffffff;	qp_attr->sq_psn		     = be32_to_cpu(context->next_send_psn) & 0xffffff;	qp_attr->dest_qp_num	     = be32_to_cpu(context->log_pg_sz_remote_qpn) & 0xffffff;	qp_attr->qp_access_flags     =		to_ib_qp_access_flags(be32_to_cpu(context->params2));	if (qp->ibqp.qp_type == IB_QPT_RC || qp->ibqp.qp_type == IB_QPT_UC) {		to_rdma_ah_attr(dev, &qp_attr->ah_attr, &context->pri_path);		to_rdma_ah_attr(dev, &qp_attr->alt_ah_attr, &context->alt_path);		qp_attr->alt_pkey_index =			be16_to_cpu(context->alt_path.pkey_index);		qp_attr->alt_port_num	=			rdma_ah_get_port_num(&qp_attr->alt_ah_attr);	}	qp_attr->pkey_index = be16_to_cpu(context->pri_path.pkey_index);	qp_attr->port_num = context->pri_path.port;	 	qp_attr->sq_draining = mlx5_state == MLX5_QP_STATE_SQ_DRAINING;	qp_attr->max_rd_atomic = 1 << ((be32_to_cpu(context->params1) >> 21) & 0x7);	qp_attr->max_dest_rd_atomic =		1 << ((be32_to_cpu(context->params2) >> 21) & 0x7);	qp_attr->min_rnr_timer	    =		(be32_to_cpu(context->rnr_nextrecvpsn) >> 24) & 0x1f;	qp_attr->timeout	    = context->pri_path.ackto_lt >> 3;	qp_attr->retry_cnt	    = (be32_to_cpu(context->params1) >> 16) & 0x7;	qp_attr->rnr_retry	    = (be32_to_cpu(context->params1) >> 13) & 0x7;	qp_attr->alt_timeout	    = context->alt_path.ackto_lt >> 3;out:	kfree(outb);	return err;}",27580
608,1288,CVE-2013-1929,26,"static void tg3_ptp_resume(struct tg3 *tp){	if (!tg3_flag(tp, PTP_CAPABLE))		return;	tg3_refclk_write(tp, ktime_to_ns(ktime_get_real()) + tp->ptp_adjust);	tp->ptp_adjust = 0;}",9294
765,3800,CVE-2012-5157,26,"    void kick()    {        kick(1, 8, WebTextDecorationTypeSpelling);    }",29475
796,945,CVE-2013-4591,26,"static int nfs4_commit_done(struct rpc_task *task, struct nfs_commit_data *data){	if (!nfs4_sequence_done(task, &data->res.seq_res))		return -EAGAIN;	return data->commit_done_cb(task, data);}",7542
598,1665,CVE-2015-4036,26,static int vhost_scsi_get_cmd_state(struct se_cmd *se_cmd){	return 0;},13531
831,2044,CVE-2016-4568,26,void vb2_ops_wait_finish(struct vb2_queue *vq){	mutex_lock(vq->lock);},16746
940,1069,CVE-2013-4263,26,"static void hblur(int *dst, int dst_linesize, const int *src, int src_linesize,                  int w, int h, int radius, int power, int *temp[2]){    int y;    if (radius == 0 && dst == src)        return;    for (y = 0; y < h; y++)        blur_power(dst + y*dst_linesize, 1, src + y*src_linesize, 1,                   w, radius, power, temp);}",7876
290,2422,CVE-2016-2315,26,static void parse_checkpoint(void){	checkpoint_requested = 1;	skip_optional_lf();},17842
833,1265,CVE-2013-1929,26,"static int tg3_mem_tx_acquire(struct tg3 *tp){	int i;	struct tg3_napi *tnapi = &tp->napi[0];	 	if (tg3_flag(tp, ENABLE_TSS))		tnapi++;	for (i = 0; i < tp->txq_cnt; i++, tnapi++) {		tnapi->tx_buffers = kzalloc(sizeof(struct tg3_tx_ring_info) *					    TG3_TX_RING_SIZE, GFP_KERNEL);		if (!tnapi->tx_buffers)			goto err_out;		tnapi->tx_ring = dma_alloc_coherent(&tp->pdev->dev,						    TG3_TX_RING_BYTES,						    &tnapi->tx_desc_mapping,						    GFP_KERNEL);		if (!tnapi->tx_ring)			goto err_out;	}	return 0;err_out:	tg3_mem_tx_release(tp);	return -ENOMEM;}",9271
318,1435,CVE-2011-1180,26,"static inline void iriap_start_watchdog_timer(struct iriap_cb *self,					      int timeout){	irda_start_timer(&self->watchdog_timer, timeout, self,			 iriap_watchdog_timer_expired);}",10293
565,4050,CVE-2011-3353,26,"static int fuse_notify_inval_entry(struct fuse_conn *fc, unsigned int size,				   struct fuse_copy_state *cs){	struct fuse_notify_inval_entry_out outarg;	int err = -ENOMEM;	char *buf;	struct qstr name;	buf = kzalloc(FUSE_NAME_MAX + 1, GFP_KERNEL);	if (!buf)		goto err;	err = -EINVAL;	if (size < sizeof(outarg))		goto err;	err = fuse_copy_one(cs, &outarg, sizeof(outarg));	if (err)		goto err;	err = -ENAMETOOLONG; 	if (outarg.namelen > FUSE_NAME_MAX) 		goto err;  	name.name = buf; 	name.len = outarg.namelen; 	err = fuse_copy_one(cs, buf, outarg.namelen + 1);	if (err)		goto err;	fuse_copy_finish(cs);	buf[outarg.namelen] = 0;	name.hash = full_name_hash(name.name, name.len);	down_read(&fc->killsb);	err = -ENOENT;	if (fc->sb)		err = fuse_reverse_inval_entry(fc->sb, outarg.parent, &name);	up_read(&fc->killsb);	kfree(buf);	return err;err:	kfree(buf);	fuse_copy_finish(cs);	return err;}",30991
220,1425,CVE-2011-4098,26,"static int trunc_end(struct gfs2_inode *ip){	struct gfs2_sbd *sdp = GFS2_SB(&ip->i_inode);	struct buffer_head *dibh;	int error;	error = gfs2_trans_begin(sdp, RES_DINODE, 0);	if (error)		return error;	down_write(&ip->i_rw_mutex);	error = gfs2_meta_inode_buffer(ip, &dibh);	if (error)		goto out;	if (!i_size_read(&ip->i_inode)) {		ip->i_height = 0;		ip->i_goal = ip->i_no_addr;		gfs2_buffer_clear_tail(dibh, sizeof(struct gfs2_dinode));	}	ip->i_inode.i_mtime = ip->i_inode.i_ctime = CURRENT_TIME;	ip->i_diskflags &= ~GFS2_DIF_TRUNC_IN_PROG;	gfs2_trans_add_bh(ip->i_gl, dibh, 1);	gfs2_dinode_out(ip, dibh->b_data);	brelse(dibh);out:	up_write(&ip->i_rw_mutex);	gfs2_trans_end(sdp);	return error;}",10060
693,2970,CVE-2017-7742,26,"f2flac24_clip_array (const float *src, int *dest, int count, int normalize){	float normfact, scaled_value ;	normfact = normalize ? (8.0 * 0x100000) : 1.0 ;	while (--count >= 0)	{	scaled_value = src [count] * normfact ;		if (CPU_CLIPS_POSITIVE == 0 && scaled_value >= (1.0 * 0x7FFFFF))		{	dest [count] = 0x7FFFFF ;			continue ;			} ;		if (CPU_CLIPS_NEGATIVE == 0 && scaled_value <= (-8.0 * 0x100000))		{	dest [count] = 0x800000 ;			continue ;			}		dest [count] = lrintf (scaled_value) ;		} ;	return ;}  ",21491
973,261,CVE-2017-6542,26,"static void c_write_stderr(int trusted, const char *buf, int len){    int i;    for (i = 0; i < len; i++)	if (buf[i] != '\r' && (trusted || buf[i] == '\n' || (buf[i] & 0x60)))	    fputc(buf[i], stderr);}",1325
876,1352,CVE-2013-1773,26,static int vfat_revalidate_shortname(struct dentry *dentry){	int ret = 1;	spin_lock(&dentry->d_lock);	if (dentry->d_time != dentry->d_parent->d_inode->i_version)		ret = 0;	spin_unlock(&dentry->d_lock);	return ret;},9589
599,1430,CVE-2011-4098,26,"static int gfs2_lock(struct file *file, int cmd, struct file_lock *fl){	struct gfs2_inode *ip = GFS2_I(file->f_mapping->host);	struct gfs2_sbd *sdp = GFS2_SB(file->f_mapping->host);	struct lm_lockstruct *ls = &sdp->sd_lockstruct;	if (!(fl->fl_flags & FL_POSIX))		return -ENOLCK;	if (__mandatory_lock(&ip->i_inode) && fl->fl_type != F_UNLCK)		return -ENOLCK;	if (cmd == F_CANCELLK) {		 		cmd = F_SETLK;		fl->fl_type = F_UNLCK;	}	if (unlikely(test_bit(SDF_SHUTDOWN, &sdp->sd_flags)))		return -EIO;	if (IS_GETLK(cmd))		return dlm_posix_get(ls->ls_dlm, ip->i_no_addr, file, fl);	else if (fl->fl_type == F_UNLCK)		return dlm_posix_unlock(ls->ls_dlm, ip->i_no_addr, file, fl);	else		return dlm_posix_lock(ls->ls_dlm, ip->i_no_addr, file, cmd, fl);}",10065
741,1987,CVE-2016-4998,26,"check_match(struct xt_entry_match *m, struct xt_mtchk_param *par){	const struct ipt_ip *ip = par->entryinfo;	int ret;	par->match     = m->u.kernel.match;	par->matchinfo = m->data;	ret = xt_check_match(par, m->u.match_size - sizeof(*m),	      ip->proto, ip->invflags & IPT_INV_PROTO);	if (ret < 0) {		duprintf(""check failed for `%s'.\n"", par->match->name);		return ret;	}	return 0;}",16553
604,1650,CVE-2015-4036,26,static int vhost_scsi_check_true(struct se_portal_group *se_tpg){	return 1;},13516
455,1565,CVE-2014-0063,26,"EncodeDateOnly(struct tm * tm, int style, char *str, int EuroDates){	if (tm->tm_mon < 1 || tm->tm_mon > MONTHS_PER_YEAR)		return -1;	switch (style)	{		case USE_ISO_DATES:			 			if (tm->tm_year > 0)				sprintf(str, ""%04d-%02d-%02d"",						tm->tm_year, tm->tm_mon, tm->tm_mday);			else				sprintf(str, ""%04d-%02d-%02d %s"",						-(tm->tm_year - 1), tm->tm_mon, tm->tm_mday, ""BC"");			break;		case USE_SQL_DATES:			 			if (EuroDates)				sprintf(str, ""%02d/%02d"", tm->tm_mday, tm->tm_mon);			else				sprintf(str, ""%02d/%02d"", tm->tm_mon, tm->tm_mday);			if (tm->tm_year > 0)				sprintf(str + 5, ""/%04d"", tm->tm_year);			else				sprintf(str + 5, ""/%04d %s"", -(tm->tm_year - 1), ""BC"");			break;		case USE_GERMAN_DATES:			 			sprintf(str, ""%02d.%02d"", tm->tm_mday, tm->tm_mon);			if (tm->tm_year > 0)				sprintf(str + 5, "".%04d"", tm->tm_year);			else				sprintf(str + 5, "".%04d %s"", -(tm->tm_year - 1), ""BC"");			break;		case USE_POSTGRES_DATES:		default:			 			if (EuroDates)				sprintf(str, ""%02d-%02d"", tm->tm_mday, tm->tm_mon);			else				sprintf(str, ""%02d-%02d"", tm->tm_mon, tm->tm_mday);			if (tm->tm_year > 0)				sprintf(str + 5, ""-%04d"", tm->tm_year);			else				sprintf(str + 5, ""-%04d %s"", -(tm->tm_year - 1), ""BC"");			break;	}	return TRUE;}	 ",12311
378,2001,CVE-2016-4998,26,struct ipt_entry *ipt_next_entry(const struct ipt_entry *entry){	return (void *)entry + entry->next_offset;},16567
917,1817,CVE-2016-8658,26,"static void brcmf_init_escan(struct brcmf_cfg80211_info *cfg){	brcmf_fweh_register(cfg->pub, BRCMF_E_ESCAN_RESULT,			    brcmf_cfg80211_escan_handler);	cfg->escan_info.escan_state = WL_ESCAN_STATE_IDLE;	 	init_timer(&cfg->escan_timeout);	cfg->escan_timeout.data = (unsigned long) cfg;	cfg->escan_timeout.function = brcmf_escan_timeout;	INIT_WORK(&cfg->escan_timeout_work,		  brcmf_cfg80211_escan_timeout_worker);}",15465
674,504,CVE-2012-6711,26,all_exported_variables (){  return (vapply (visible_and_exported));},2544
966,3008,CVE-2017-5548,26,"static int atusb_submit_rx_urb(struct atusb *atusb, struct urb *urb){	struct usb_device *usb_dev = atusb->usb_dev;	struct sk_buff *skb = urb->context;	int ret;	if (!skb) {		skb = alloc_skb(MAX_RX_XFER, GFP_KERNEL);		if (!skb) {			dev_warn_ratelimited(&usb_dev->dev,					     ""atusb_in: can't allocate skb\n"");			return -ENOMEM;		}		skb_put(skb, MAX_RX_XFER);		SKB_ATUSB(skb) = atusb;	}	usb_fill_bulk_urb(urb, usb_dev, usb_rcvbulkpipe(usb_dev, 1),			  skb->data, MAX_RX_XFER, atusb_in, skb);	usb_anchor_urb(urb, &atusb->rx_urbs);	ret = usb_submit_urb(urb, GFP_KERNEL);	if (ret) {		usb_unanchor_urb(urb);		kfree_skb(skb);		urb->context = NULL;	}	return ret;}",22047
616,711,CVE-2011-1477,26,"static void opl3_hw_control(int dev, unsigned char *event){}",6858
313,2428,CVE-2016-2315,26,"static void parse_mark(void){	const char *v;	if (skip_prefix(command_buf.buf, ""mark :"", &v)) {		next_mark = strtoumax(v, NULL, 10);		read_next_command();	}	else		next_mark = 0;}",17848
609,3766,CVE-2012-2876,26,"  void ExpectFilledTestForm() {    ExpectFieldValue(L""firstname"", ""Milton"");    ExpectFieldValue(L""lastname"", ""Waddams"");    ExpectFieldValue(L""address1"", ""4120 Freidrich Lane"");    ExpectFieldValue(L""address2"", ""Basement"");    ExpectFieldValue(L""city"", ""Austin"");    ExpectFieldValue(L""state"", ""TX"");    ExpectFieldValue(L""zip"", ""78744"");    ExpectFieldValue(L""country"", ""US"");     ExpectFieldValue(L""phone"", ""5125551234"");   }",29177
967,4041,CVE-2014-8106,26,"static int blit_is_unsafe(struct CirrusVGAState *s){          assert(s->cirrus_blt_width > 0);     assert(s->cirrus_blt_height > 0);      if (blit_region_is_unsafe(s, s->cirrus_blt_dstpitch,                               s->cirrus_blt_dstaddr & s->cirrus_addr_mask)) {         return true;    }    return false;}",30897
395,3207,CVE-2018-17407,26,"static void t1_puts(const char *s){    if (s != t1_line_array)        strcpy(t1_line_array, s);    t1_line_ptr = strend(t1_line_array);    t1_putline();}",23641
277,2744,CVE-2017-12876,26,"static inline void ModulateLCHuv(const double percent_luma,  const double percent_chroma,const double percent_hue,double *red,  double *green,double *blue){  double    hue,    luma,    chroma;     ConvertRGBToLCHuv(*red,*green,*blue,&luma,&chroma,&hue);  luma*=0.01*percent_luma;  chroma*=0.01*percent_chroma;  hue+=fmod((percent_hue-100.0),200.0)/200.0;  ConvertLCHuvToRGB(luma,chroma,hue,red,green,blue);}",20293
172,515,CVE-2012-6711,26,"n_shell_variables (){  VAR_CONTEXT *vc;  int n;  for (n = 0, vc = shell_variables; vc; vc = vc->down)    n += HASH_ENTRIES (vc->table);  return n;}",2555
943,3081,CVE-2016-10066,26,static inline int ReadWebPLSBWord(const unsigned char *restrict data){  register const unsigned char    *p;  register int    value;  p=data;  value=(int) (*p++);  value|=((int) (*p++)) << 8;  value|=((int) (*p++)) << 16;  value|=((int) (*p++)) << 24;  return(value);},22559
977,2064,CVE-2016-4478,26,"char *xmlrpc_normalizeBuffer(const char *buf){	char *newbuf;	int i, len, j = 0;	len = strlen(buf);	newbuf = (char *)smalloc(sizeof(char) * len + 1);	for (i = 0; i < len; i++)	{		switch (buf[i])		{			   		  case 1:			  break;			   		  case 2:			  break;			   		  case 3:			   			  if (isdigit((unsigned char)buf[i + 1]))			  {				  i++;				   				  if (isdigit((unsigned char)buf[i + 1]))				  {					  i++;				  }				   				  if (buf[i + 1] == ',')				  {					  i++;					  if (isdigit((unsigned char)buf[i + 1]))					  {						  i++;					  }					   					  if (isdigit((unsigned char)buf[i + 1]))					  {						  i++;					  }				  }			  }			  break;			   		  case 9:			  break;			   		  case 10:			  break;			   		  case 13:			  break;			   		  case 22:			  break;			   		  case 31:			  break;			   		  default:			   			  if (buf[i] > 31)			  {				newbuf[j] = buf[i];				j++;			  }		}	}	 	newbuf[j] = 0;	return (newbuf);}",16963
1013,1993,CVE-2016-4998,26,"get_chainname_rulenum(const struct ipt_entry *s, const struct ipt_entry *e,		      const char *hookname, const char **chainname,		      const char **comment, unsigned int *rulenum){	const struct xt_standard_target *t = (void *)ipt_get_target_c(s);	if (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {		 		*chainname = t->target.data;		(*rulenum) = 0;	} else if (s == e) {		(*rulenum)++;		if (s->target_offset == sizeof(struct ipt_entry) &&		    strcmp(t->target.u.kernel.target->name,			   XT_STANDARD_TARGET) == 0 &&		   t->verdict < 0 &&		   unconditional(&s->ip)) {			 			*comment = *chainname == hookname				? comments[NF_IP_TRACE_COMMENT_POLICY]				: comments[NF_IP_TRACE_COMMENT_RETURN];		}		return 1;	} else		(*rulenum)++;	return 0;}",16559
970,1325,CVE-2013-1860,26,"static int wdm_pre_reset(struct usb_interface *intf){	struct wdm_device *desc = wdm_find_device(intf);	 	spin_lock_irq(&desc->iuspin);	set_bit(WDM_RESETTING, &desc->flags);	 	set_bit(WDM_READ, &desc->flags);	 	clear_bit(WDM_IN_USE, &desc->flags);	 	desc->rerr = -EINTR;	spin_unlock_irq(&desc->iuspin);	wake_up_all(&desc->wait);	mutex_lock(&desc->rlock);	mutex_lock(&desc->wlock);	kill_urbs(desc);	cancel_work_sync(&desc->rxwork);	return 0;}",9332
108,2798,CVE-2017-9990,26,"static int ascii2index(const int *cpixel, int cpp){    const int *p = cpixel;    int n = 0, m = 1, i;    for (i = 0; i < cpp; i++) {        if (*p < ' ' || *p > '~')            return AVERROR_INVALIDDATA;        n += (*p++ - ' ') * m;        m *= 95;    }    return n;}",20683
1005,3807,CVE-2014-3173,26,  int ShouldDeferDraws() {    return !offscreen_target_frame_buffer_.get() &&           framebuffer_state_.bound_draw_framebuffer.get() == NULL &&           surface_->DeferDraws();  },29545
634,248,CVE-2018-10184,26,"static int h2c_frt_recv_preface(struct h2c *h2c){	int ret1;	int ret2;	ret1 = b_isteq(h2c->dbuf, 0, h2c->dbuf->i, ist(H2_CONN_PREFACE));	if (unlikely(ret1 <= 0)) {		if (ret1 < 0 || conn_xprt_read0_pending(h2c->conn))			h2c_error(h2c, H2_ERR_PROTOCOL_ERROR);		return 0;	}	ret2 = h2c_snd_settings(h2c);	if (ret2 > 0)		bi_del(h2c->dbuf, ret1);	return ret2;}",1269
331,2799,CVE-2017-9990,26,static unsigned hex_char_to_number(int x){    if (x >= 'a' && x <= 'f')        x -= 'a' - 10;    else if (x >= 'A' && x <= 'F')        x -= 'A' - 10;    else if (x >= '0' && x <= '9')        x -= '0';    else        x = 0;    return x;},20684
181,2688,CVE-2017-16534,26,"void usb_disable_endpoint(struct usb_device *dev, unsigned int epaddr,		int reset_hardware){	unsigned int epnum = epaddr & USB_ENDPOINT_NUMBER_MASK;	struct usb_host_endpoint *ep;	if (!dev)		return;	if (usb_endpoint_out(epaddr)) {		ep = dev->ep_out[epnum];		if (reset_hardware)			dev->ep_out[epnum] = NULL;	} else {		ep = dev->ep_in[epnum];		if (reset_hardware)			dev->ep_in[epnum] = NULL;	}	if (ep) {		ep->enabled = 0;		usb_hcd_flush_endpoint(dev, ep);		if (reset_hardware)			usb_hcd_disable_endpoint(dev, ep);	}}",19694
371,1691,CVE-2015-3331,26,"static int ctr_crypt(struct blkcipher_desc *desc,		     struct scatterlist *dst, struct scatterlist *src,		     unsigned int nbytes){	struct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));	struct blkcipher_walk walk;	int err;	blkcipher_walk_init(&walk, dst, src, nbytes);	err = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);	desc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;	kernel_fpu_begin();	while ((nbytes = walk.nbytes) >= AES_BLOCK_SIZE) {		aesni_ctr_enc_tfm(ctx, walk.dst.virt.addr, walk.src.virt.addr,			              nbytes & AES_BLOCK_MASK, walk.iv);		nbytes &= AES_BLOCK_SIZE - 1;		err = blkcipher_walk_done(desc, &walk, nbytes);	}	if (walk.nbytes) {		ctr_crypt_final(ctx, &walk);		err = blkcipher_walk_done(desc, &walk, 0);	}	kernel_fpu_end();	return err;}",13602
417,3077,CVE-2016-10066,26,"static void RelinquishLZMAMemory(void *context,void *memory){  (void) context;  memory=RelinquishMagickMemory(memory);}",22555
126,656,CVE-2011-2517,26,"static int nl80211_connect(struct sk_buff *skb, struct genl_info *info){	struct cfg80211_registered_device *rdev = info->user_ptr[0];	struct net_device *dev = info->user_ptr[1];	struct cfg80211_connect_params connect;	struct wiphy *wiphy;	struct cfg80211_cached_keys *connkeys = NULL;	int err;	memset(&connect, 0, sizeof(connect));	if (!is_valid_ie_attr(info->attrs[NL80211_ATTR_IE]))		return -EINVAL;	if (!info->attrs[NL80211_ATTR_SSID] ||	    !nla_len(info->attrs[NL80211_ATTR_SSID]))		return -EINVAL;	if (info->attrs[NL80211_ATTR_AUTH_TYPE]) {		connect.auth_type =			nla_get_u32(info->attrs[NL80211_ATTR_AUTH_TYPE]);		if (!nl80211_valid_auth_type(connect.auth_type))			return -EINVAL;	} else		connect.auth_type = NL80211_AUTHTYPE_AUTOMATIC;	connect.privacy = info->attrs[NL80211_ATTR_PRIVACY];	err = nl80211_crypto_settings(rdev, info, &connect.crypto,				      NL80211_MAX_NR_CIPHER_SUITES);	if (err)		return err;	if (dev->ieee80211_ptr->iftype != NL80211_IFTYPE_STATION &&	    dev->ieee80211_ptr->iftype != NL80211_IFTYPE_P2P_CLIENT)		return -EOPNOTSUPP;	wiphy = &rdev->wiphy;	if (info->attrs[NL80211_ATTR_MAC])		connect.bssid = nla_data(info->attrs[NL80211_ATTR_MAC]);	connect.ssid = nla_data(info->attrs[NL80211_ATTR_SSID]);	connect.ssid_len = nla_len(info->attrs[NL80211_ATTR_SSID]);	if (info->attrs[NL80211_ATTR_IE]) {		connect.ie = nla_data(info->attrs[NL80211_ATTR_IE]);		connect.ie_len = nla_len(info->attrs[NL80211_ATTR_IE]);	}	if (info->attrs[NL80211_ATTR_WIPHY_FREQ]) {		connect.channel =			ieee80211_get_channel(wiphy,			    nla_get_u32(info->attrs[NL80211_ATTR_WIPHY_FREQ]));		if (!connect.channel ||		    connect.channel->flags & IEEE80211_CHAN_DISABLED)			return -EINVAL;	}	if (connect.privacy && info->attrs[NL80211_ATTR_KEYS]) {		connkeys = nl80211_parse_connkeys(rdev,					info->attrs[NL80211_ATTR_KEYS]);		if (IS_ERR(connkeys))			return PTR_ERR(connkeys);	}	err = cfg80211_connect(rdev, dev, &connect, connkeys);	if (err)		kfree(connkeys);	return err;}",6555
262,2860,CVE-2017-8067,26,"static void resize_console(struct port *port){	struct virtio_device *vdev;	 	if (!port || !is_console_port(port))		return;	vdev = port->portdev->vdev;	 	if (!is_rproc_serial(vdev) &&	    virtio_has_feature(vdev, VIRTIO_CONSOLE_F_SIZE))		hvc_resize(port->cons.hvc, port->cons.ws);}",21337
415,2343,CVE-2016-2324,26,"static int handle_one_reflog_ent(unsigned char *osha1, unsigned char *nsha1,		const char *email, unsigned long timestamp, int tz,		const char *message, void *cb_data){	handle_one_reflog_commit(osha1, cb_data);	handle_one_reflog_commit(nsha1, cb_data);	return 0;}",17763
954,802,CVE-2013-6381,26,"void qeth_clear_qdio_buffers(struct qeth_card *card){	int i;	QETH_CARD_TEXT(card, 2, ""clearqdbf"");	 	for (i = 0; i < card->qdio.no_out_queues; ++i) {		if (card->qdio.out_qs[i]) {			qeth_clear_outq_buffers(card->qdio.out_qs[i], 0);		}	}}",7231
935,3135,CVE-2016-7480,26,"SPL_METHOD(MultipleIterator, rewind){	spl_SplObjectStorage        *intern;	spl_SplObjectStorageElement *element;	zval                        *it;	intern = Z_SPLOBJSTORAGE_P(getThis());	if (zend_parse_parameters_none() == FAILURE) {		return;	}	zend_hash_internal_pointer_reset_ex(&intern->storage, &intern->pos);	while ((element = zend_hash_get_current_data_ptr_ex(&intern->storage, &intern->pos)) != NULL && !EG(exception)) {		it = &element->obj;		zend_call_method_with_0_params(it, Z_OBJCE_P(it), &Z_OBJCE_P(it)->iterator_funcs.zf_rewind, ""rewind"", NULL);		zend_hash_move_forward_ex(&intern->storage, &intern->pos);	}}",22802
106,2846,CVE-2017-8067,26,static int is_console_port(struct port *port){	if (port->cons.hvc)		return true;	return false;},21323
773,2122,CVE-2016-4303,26,"iperf_set_test_duration(struct iperf_test *ipt, int duration){    ipt->duration = duration;}",17030
138,511,CVE-2012-6711,26,initialize_shell_level (){  adjust_shell_level (1);},2551
160,2902,CVE-2017-8064,26,"static int dvb_usbv2_adapter_frontend_exit(struct dvb_usb_adapter *adap){	int ret, i;	struct dvb_usb_device *d = adap_to_d(adap);	dev_dbg(&d->udev->dev, ""%s: adap=%d\n"", __func__, adap->id);	for (i = MAX_NO_OF_FE_PER_ADAP - 1; i >= 0; i--) {		if (adap->fe[i]) {			dvb_unregister_frontend(adap->fe[i]);			dvb_frontend_detach(adap->fe[i]);		}	}	if (d->props->tuner_detach) {		ret = d->props->tuner_detach(adap);		if (ret < 0) {			dev_dbg(&d->udev->dev, ""%s: tuner_detach() failed=%d\n"",					__func__, ret);		}	}	if (d->props->frontend_detach) {		ret = d->props->frontend_detach(adap);		if (ret < 0) {			dev_dbg(&d->udev->dev,					""%s: frontend_detach() failed=%d\n"",					__func__, ret);		}	}	return 0;}",21379
764,3912,CVE-2016-1683,26,exsltCryptoGcryptInit (void) {    static int gcrypt_init;    xmlLockLibrary ();    if (!gcrypt_init) { 	gcry_check_version (GCRYPT_VERSION);	gcrypt_init = 1;    }    xmlUnlockLibrary ();},30346
666,3005,CVE-2017-5548,26,"atusb_set_promiscuous_mode(struct ieee802154_hw *hw, const int on){	struct atusb *atusb = hw->priv;	int ret;	if (on) {		ret = atusb_write_subreg(atusb, SR_AACK_DIS_ACK, 1);		if (ret < 0)			return ret;		ret = atusb_write_subreg(atusb, SR_AACK_PROM_MODE, 1);		if (ret < 0)			return ret;	} else {		ret = atusb_write_subreg(atusb, SR_AACK_PROM_MODE, 0);		if (ret < 0)			return ret;		ret = atusb_write_subreg(atusb, SR_AACK_DIS_ACK, 0);		if (ret < 0)			return ret;	}	return 0;}",22044
449,693,CVE-2011-2517,26,"static int nl80211_set_channel(struct sk_buff *skb, struct genl_info *info){	struct cfg80211_registered_device *rdev = info->user_ptr[0];	struct net_device *netdev = info->user_ptr[1];	return __nl80211_set_channel(rdev, netdev->ieee80211_ptr, info);}",6592
327,4072,CVE-2014-0749,26,"int disrsi_(  int       stream,  int      *negate,  unsigned *value,  unsigned  count)  {  int  c;  unsigned locval;  unsigned ndigs;  char  *cp;  char  scratch[DIS_BUFSIZ+1];  assert(negate != NULL);  assert(value != NULL);  assert(count);  assert(stream >= 0);  assert(dis_getc != NULL);  assert(dis_gets != NULL);  memset(scratch, 0, DIS_BUFSIZ+1);   if (dis_umaxd == 0)     disiui_();    switch (c = (*dis_getc)(stream))     {     case '-':    case '+':      *negate = c == '-';      if ((*dis_gets)(stream, scratch, count) != (int)count)        {        return(DIS_EOD);        }      if (count >= dis_umaxd)        {        if (count > dis_umaxd)          goto overflow;        if (memcmp(scratch, dis_umax, dis_umaxd) > 0)          goto overflow;        }      cp = scratch;      locval = 0;      do        {        if (((c = *cp++) < '0') || (c > '9'))          {          return(DIS_NONDIGIT);          }        locval = 10 * locval + c - '0';        }      while (--count);      *value = locval;      return (DIS_SUCCESS);      break;    case '0':      return (DIS_LEADZRO);      break;    case '1':    case '2':    case '3':    case '4':    case '5':    case '6':    case '7':    case '8':    case '9':      ndigs = c - '0';      if (count > 1)        {        if ((*dis_gets)(stream, scratch + 1, count - 1) != (int)count - 1)          {          return(DIS_EOD);          }        cp = scratch;        if (count >= dis_umaxd)          {          if (count > dis_umaxd)            break;          *cp = c;          if (memcmp(scratch, dis_umax, dis_umaxd) > 0)            break;          }        while (--count)          {          if (((c = *++cp) < '0') || (c > '9'))            {            return(DIS_NONDIGIT);            }          ndigs = 10 * ndigs + c - '0';          }        }           return(disrsi_(stream, negate, value, ndigs));             break;    case - 1:      return(DIS_EOD);             break;    case -2:      return(DIS_EOF);             break;    default:      return(DIS_NONDIGIT);             break;    }  *negate = FALSE;overflow:  *value = UINT_MAX;  return(DIS_OVERFLOW);  }   ",31166
398,872,CVE-2013-6381,26,"static void qeth_issue_ipa_msg(struct qeth_ipa_cmd *cmd, int rc,		struct qeth_card *card){	char *ipa_name;	int com = cmd->hdr.command;	ipa_name = qeth_get_ipa_cmd_name(com);	if (rc)		QETH_DBF_MESSAGE(2, ""IPA: %s(x%X) for %s/%s returned ""				""x%X \""%s\""\n"",				ipa_name, com, dev_name(&card->gdev->dev),				QETH_CARD_IFNAME(card), rc,				qeth_get_ipa_msg(rc));	else		QETH_DBF_MESSAGE(5, ""IPA: %s(x%X) for %s/%s succeeded\n"",				ipa_name, com, dev_name(&card->gdev->dev),				QETH_CARD_IFNAME(card));}",7301
118,3605,CVE-2018-20182,26,"seamless_send_focus(unsigned long id, unsigned long flags){	if (!g_seamless_rdp)		return (unsigned int) -1;	return seamless_send(""FOCUS"", ""0x%08lx,0x%lx"", id, flags);}",27903
675,4066,CVE-2013-1772,26,"static void call_console_drivers(unsigned start, unsigned end){	unsigned cur_index, start_print;	static int msg_level = -1;	BUG_ON(((int)(start - end)) > 0);	cur_index = start; 	start_print = start; 	while (cur_index != end) { 		if (msg_level < 0 && ((end - cur_index) > 2)) { 			 			cur_index += log_prefix(&LOG_BUF(cur_index), &msg_level, NULL); 			start_print = cur_index; 		} 		while (cur_index != end) {			char c = LOG_BUF(cur_index);			cur_index++;			if (c == '\n') {				if (msg_level < 0) {					 					msg_level = default_message_loglevel;				}				_call_console_drivers(start_print, cur_index, msg_level);				msg_level = -1;				start_print = cur_index;				break;			}		}	}	_call_console_drivers(start_print, end, msg_level);}",31090
483,1889,CVE-2016-7425,26,"arcmsr_request_irq(struct pci_dev *pdev, struct AdapterControlBlock *acb){	int	i, j, r;	struct msix_entry entries[ARCMST_NUM_MSIX_VECTORS];	for (i = 0; i < ARCMST_NUM_MSIX_VECTORS; i++)		entries[i].entry = i;	r = pci_enable_msix_range(pdev, entries, 1, ARCMST_NUM_MSIX_VECTORS);	if (r < 0)		goto msi_int;	acb->msix_vector_count = r;	for (i = 0; i < r; i++) {		if (request_irq(entries[i].vector,			arcmsr_do_interrupt, 0, ""arcmsr"", acb)) {			pr_warn(""arcmsr%d: request_irq =%d failed!\n"",				acb->host->host_no, entries[i].vector);			for (j = 0 ; j < i ; j++)				free_irq(entries[j].vector, acb);			pci_disable_msix(pdev);			goto msi_int;		}		acb->entries[i] = entries[i];	}	acb->acb_flags |= ACB_F_MSIX_ENABLED;	pr_info(""arcmsr%d: msi-x enabled\n"", acb->host->host_no);	return SUCCESS;msi_int:	if (pci_enable_msi_exact(pdev, 1) < 0)		goto legacy_int;	if (request_irq(pdev->irq, arcmsr_do_interrupt,		IRQF_SHARED, ""arcmsr"", acb)) {		pr_warn(""arcmsr%d: request_irq =%d failed!\n"",			acb->host->host_no, pdev->irq);		pci_disable_msi(pdev);		goto legacy_int;	}	acb->acb_flags |= ACB_F_MSI_ENABLED;	pr_info(""arcmsr%d: msi enabled\n"", acb->host->host_no);	return SUCCESS;legacy_int:	if (request_irq(pdev->irq, arcmsr_do_interrupt,		IRQF_SHARED, ""arcmsr"", acb)) {		pr_warn(""arcmsr%d: request_irq = %d failed!\n"",			acb->host->host_no, pdev->irq);		return FAILED;	}	return SUCCESS;}",15808
740,643,CVE-2011-3353,26,"static void put_reserved_req(struct fuse_conn *fc, struct fuse_req *req){	struct file *file = req->stolen_file;	struct fuse_file *ff = file->private_data;	spin_lock(&fc->lock);	fuse_request_init(req);	BUG_ON(ff->reserved_req);	ff->reserved_req = req;	wake_up_all(&fc->reserved_req_waitq);	spin_unlock(&fc->lock);	fput(file);}",5616
284,2835,CVE-2017-8068,26,"pegasus_get_settings(struct net_device *dev, struct ethtool_cmd *ecmd){	pegasus_t *pegasus;	pegasus = netdev_priv(dev);	mii_ethtool_gset(&pegasus->mii, ecmd);	return 0;}",21312
315,3015,CVE-2017-5547,26,static void corsair_remove(struct hid_device *dev){	k90_cleanup_macro_functions(dev);	k90_cleanup_backlight(dev);	hid_hw_stop(dev);},22054
113,342,CVE-2010-2527,26,  Fatal( const char*  message )  {    FTDemo_Display_Done( display );    FTDemo_Done( handle );    PanicZ( message );  },1821
586,137,CVE-2015-5289,26,"jsonb_populate_record(PG_FUNCTION_ARGS){	return populate_record_worker(fcinfo, ""jsonb_populate_record"", true);}",544
206,1898,CVE-2016-7115,26,"static void sig_winch(int sig) {	unsigned short width,height;	struct mt_packet data;	int plen;	 	if (get_terminal_size(&width, &height) != -1) {		init_packet(&data, MT_PTYPE_DATA, srcmac, dstmac, sessionkey, outcounter);		width = htole16(width);		height = htole16(height);		plen = add_control_packet(&data, MT_CPTYPE_TERM_WIDTH, &width, 2);		plen += add_control_packet(&data, MT_CPTYPE_TERM_HEIGHT, &height, 2);		outcounter += plen;		send_udp(&data, 1);	}	 	signal(SIGWINCH, sig_winch);}",15874
199,746,CVE-2010-4650,26,"static int fuse_writepage(struct page *page, struct writeback_control *wbc){	int err;	err = fuse_writepage_locked(page);	unlock_page(page);	return err;}",7030
705,876,CVE-2013-6381,26,"static void qeth_notify_skbs(struct qeth_qdio_out_q *q,		struct qeth_qdio_out_buffer *buf,		enum iucv_tx_notify notification){	struct sk_buff *skb;	if (skb_queue_empty(&buf->skb_list))		goto out;	skb = skb_peek(&buf->skb_list);	while (skb) {		QETH_CARD_TEXT_(q->card, 5, ""skbn%d"", notification);		QETH_CARD_TEXT_(q->card, 5, ""%lx"", (long) skb);		if (skb->protocol == ETH_P_AF_IUCV) {			if (skb->sk) {				struct iucv_sock *iucv = iucv_sk(skb->sk);				iucv->sk_txnotify(skb, notification);			}		}		if (skb_queue_is_last(&buf->skb_list, skb))			skb = NULL;		else			skb = skb_queue_next(&buf->skb_list, skb);	}out:	return;}",7305
433,629,CVE-2011-3353,26,"static int fuse_ref_page(struct fuse_copy_state *cs, struct page *page,			 unsigned offset, unsigned count){	struct pipe_buffer *buf;	if (cs->nr_segs == cs->pipe->buffers)		return -EIO;	unlock_request(cs->fc, cs->req);	fuse_copy_finish(cs);	buf = cs->pipebufs;	page_cache_get(page);	buf->page = page;	buf->offset = offset;	buf->len = count;	cs->pipebufs++;	cs->nr_segs++;	cs->len = 0;	return 0;}",5602
781,528,CVE-2012-3400,26,static void destroy_inodecache(void){	kmem_cache_destroy(udf_inode_cachep);},3113
272,2397,CVE-2016-2315,26,"static void file_change_m(const char *p, struct branch *b){	static struct strbuf uq = STRBUF_INIT;	const char *endp;	struct object_entry *oe;	unsigned char sha1[20];	int mode, inline_data = 0;	p = get_mode(p, &mode);	if (!p)		die(""Corrupt mode: %s"", command_buf.buf);	switch (mode) {	case 0644:	case 0755:		mode |= S_IFREG;	case S_IFREG | 0644:	case S_IFREG | 0755:	case S_IFLNK:	case S_IFDIR:	case S_IFGITLINK:		 		break;	default:		die(""Corrupt mode: %s"", command_buf.buf);	}	if (*p == ':') {		oe = find_mark(parse_mark_ref_space(&p));		hashcpy(sha1, oe->idx.sha1);	} else if (skip_prefix(p, ""inline "", &p)) {		inline_data = 1;		oe = NULL;  	} else {		if (get_sha1_hex(p, sha1))			die(""Invalid dataref: %s"", command_buf.buf);		oe = find_object(sha1);		p += 40;		if (*p++ != ' ')			die(""Missing space after SHA1: %s"", command_buf.buf);	}	strbuf_reset(&uq);	if (!unquote_c_style(&uq, p, &endp)) {		if (*endp)			die(""Garbage after path in: %s"", command_buf.buf);		p = uq.buf;	}	 	if (S_ISDIR(mode) && !hashcmp(sha1, EMPTY_TREE_SHA1_BIN) && *p) {		tree_content_remove(&b->branch_tree, p, NULL, 0);		return;	}	if (S_ISGITLINK(mode)) {		if (inline_data)			die(""Git links cannot be specified 'inline': %s"",				command_buf.buf);		else if (oe) {			if (oe->type != OBJ_COMMIT)				die(""Not a commit (actually a %s): %s"",					typename(oe->type), command_buf.buf);		}		 	} else if (inline_data) {		if (S_ISDIR(mode))			die(""Directories cannot be specified 'inline': %s"",				command_buf.buf);		if (p != uq.buf) {			strbuf_addstr(&uq, p);			p = uq.buf;		}		read_next_command();		parse_and_store_blob(&last_blob, sha1, 0);	} else {		enum object_type expected = S_ISDIR(mode) ?						OBJ_TREE: OBJ_BLOB;		enum object_type type = oe ? oe->type :					sha1_object_info(sha1, NULL);		if (type < 0)			die(""%s not found: %s"",					S_ISDIR(mode) ?  ""Tree"" : ""Blob"",					command_buf.buf);		if (type != expected)			die(""Not a %s (actually a %s): %s"",				typename(expected), typename(type),				command_buf.buf);	}	if (!*p) {		tree_content_replace(&b->branch_tree, sha1, mode, NULL);		return;	}	tree_content_set(&b->branch_tree, p, sha1, mode, NULL);}",17817
893,2476,CVE-2016-1583,26,void pid_ns_release_proc(struct pid_namespace *ns){	kern_unmount(ns->proc_mnt);},18025
134,3072,CVE-2016-10066,26,"static inline float MaxF(float one, float two){  if (one > two)    return one;  return two;}",22550
434,3017,CVE-2017-5547,26,static void k90_cleanup_backlight(struct hid_device *dev){	struct corsair_drvdata *drvdata = hid_get_drvdata(dev);	if (drvdata->backlight) {		drvdata->backlight->removed = true;		led_classdev_unregister(&drvdata->backlight->cdev);		cancel_work_sync(&drvdata->backlight->work);		kfree(drvdata->backlight->cdev.name);		kfree(drvdata->backlight);	}},22056
17,3378,CVE-2017-18222,26,"void *hns_xgmac_config(struct hns_mac_cb *mac_cb, struct mac_params *mac_param){	struct mac_driver *mac_drv;	mac_drv = devm_kzalloc(mac_cb->dev, sizeof(*mac_drv), GFP_KERNEL);	if (!mac_drv)		return NULL;	mac_drv->mac_init = hns_xgmac_init;	mac_drv->mac_enable = hns_xgmac_enable;	mac_drv->mac_disable = hns_xgmac_disable;	mac_drv->mac_id = mac_param->mac_id;	mac_drv->mac_mode = mac_param->mac_mode;	mac_drv->io_base = mac_param->vaddr;	mac_drv->dev = mac_param->dev;	mac_drv->mac_cb = mac_cb;	mac_drv->set_mac_addr = hns_xgmac_set_pausefrm_mac_addr;	mac_drv->set_an_mode = NULL;	mac_drv->config_loopback = NULL;	mac_drv->config_pad_and_crc = hns_xgmac_config_pad_and_crc;	mac_drv->config_half_duplex = NULL;	mac_drv->set_rx_ignore_pause_frames =		hns_xgmac_set_rx_ignore_pause_frames;	mac_drv->mac_free = hns_xgmac_free;	mac_drv->adjust_link = NULL;	mac_drv->set_tx_auto_pause_frames = hns_xgmac_set_tx_auto_pause_frames;	mac_drv->config_max_frame_length = hns_xgmac_config_max_frame_length;	mac_drv->mac_pausefrm_cfg = hns_xgmac_pausefrm_cfg;	mac_drv->autoneg_stat = NULL;	mac_drv->get_info = hns_xgmac_get_info;	mac_drv->get_pause_enable = hns_xgmac_get_pausefrm_cfg;	mac_drv->get_link_status = hns_xgmac_get_link_status;	mac_drv->get_regs = hns_xgmac_get_regs;	mac_drv->get_ethtool_stats = hns_xgmac_get_stats;	mac_drv->get_sset_count = hns_xgmac_get_sset_count;	mac_drv->get_regs_count = hns_xgmac_get_regs_count;	mac_drv->get_strings = hns_xgmac_get_strings;	mac_drv->update_stats = hns_xgmac_update_stats;	return (void *)mac_drv;}",25819
593,1519,CVE-2014-3158,26,check_options(){	if (logfile_fd >= 0 && logfile_fd != log_to_fd)		close(logfile_fd);},11514
482,1942,CVE-2016-5728,26,"static int vop_mmap(struct file *f, struct vm_area_struct *vma){	struct vop_vdev *vdev = f->private_data;	unsigned long offset = vma->vm_pgoff << PAGE_SHIFT;	unsigned long pa, size = vma->vm_end - vma->vm_start, size_rem = size;	int i, err;	err = vop_vdev_inited(vdev);	if (err)		goto ret;	if (vma->vm_flags & VM_WRITE) {		err = -EACCES;		goto ret;	}	while (size_rem) {		i = vop_query_offset(vdev, offset, &size, &pa);		if (i < 0) {			err = -EINVAL;			goto ret;		}		err = remap_pfn_range(vma, vma->vm_start + offset,				      pa >> PAGE_SHIFT, size,				      vma->vm_page_prot);		if (err)			goto ret;		size_rem -= size;		offset += size;	}ret:	return err;}",16376
325,1510,CVE-2014-3183,26,"static int logi_djdevice_probe(struct hid_device *hdev,			 const struct hid_device_id *id){	int ret;	struct dj_device *dj_dev = hdev->driver_data;	if (!is_dj_device(dj_dev))		return -ENODEV;	ret = hid_parse(hdev);	if (!ret)		ret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);	return ret;}",11505
591,241,CVE-2018-10184,26,"static int h2_send_empty_data_es(struct h2s *h2s){	struct h2c *h2c = h2s->h2c;	struct buffer *res;	char str[9];	int ret;	if (h2s->st == H2_SS_HLOC || h2s->st == H2_SS_ERROR || h2s->st == H2_SS_CLOSED)		return 1;	if (h2c_mux_busy(h2c, h2s)) {		h2s->flags |= H2_SF_BLK_MBUSY;		return 0;	}	res = h2_get_buf(h2c, &h2c->mbuf);	if (!res) {		h2c->flags |= H2_CF_MUX_MALLOC;		h2s->flags |= H2_SF_BLK_MROOM;		return 0;	}	 	memcpy(str, ""\x00\x00\x00\x00\x01"", 5);	write_n32(str + 5, h2s->id);	ret = bo_istput(res, ist2(str, 9));	if (likely(ret > 0)) {		h2s->flags |= H2_SF_ES_SENT;	}	else if (!ret) {		h2c->flags |= H2_CF_MUX_MFULL;		h2s->flags |= H2_SF_BLK_MROOM;		return 0;	}	else {		h2c_error(h2c, H2_ERR_INTERNAL_ERROR);		return 0;	}	return ret;}",1262
50,609,CVE-2011-3353,26,static int forget_pending(struct fuse_conn *fc){	return fc->forget_list_head.next != NULL;},5582
559,2420,CVE-2016-2315,26,"static void parse_argv(void){	unsigned int i;	for (i = 1; i < global_argc; i++) {		const char *a = global_argv[i];		if (*a != '-' || !strcmp(a, ""--""))			break;		if (!skip_prefix(a, ""--"", &a))			die(""unknown option %s"", a);		if (parse_one_option(a))			continue;		if (parse_one_feature(a, 0))			continue;		if (skip_prefix(a, ""cat-blob-fd="", &a)) {			option_cat_blob_fd(a);			continue;		}		die(""unknown option --%s"", a);	}	if (i != global_argc)		usage(fast_import_usage);	seen_data_command = 1;	if (import_marks_file)		read_marks();}",17840
825,1702,CVE-2015-3214,26,"static void destroy_pit_timer(struct kvm_timer *pt){	pr_debug(""execute del timer!\n"");	hrtimer_cancel(&pt->timer);}",13613
13,3026,CVE-2017-5522,26,"int FLTIsLogicalFilterType(const char *pszValue){  if (pszValue) {    if (strcasecmp(pszValue, ""AND"") == 0 ||        strcasecmp(pszValue, ""OR"") == 0 ||        strcasecmp(pszValue, ""NOT"") == 0)      return MS_TRUE;  }  return MS_FALSE;}",22126
486,3329,CVE-2018-1091,26,"static int tm_cfpr_active(struct task_struct *target,				const struct user_regset *regset){	if (!cpu_has_feature(CPU_FTR_TM))		return -ENODEV;	if (!MSR_TM_ACTIVE(target->thread.regs->msr))		return 0;	return regset->n;}",25545
81,2259,CVE-2016-2324,26, static void show_edge(struct commit *commit){	add_preferred_base(commit->object.oid.hash);},17679
529,366,CVE-2016-5126,26,"static int parse_timeout(const char *target){    QemuOptsList *list;    QemuOpts *opts;    const char *timeout;    list = qemu_find_opts(""iscsi"");    if (list) {        opts = qemu_opts_find(list, target);        if (!opts) {            opts = QTAILQ_FIRST(&list->head);        }        if (opts) {            timeout = qemu_opt_get(opts, ""timeout"");            if (timeout) {                return atoi(timeout);            }        }    }    return 0;}",1854
787,3306,CVE-2018-10124,26,"void task_clear_jobctl_trapping(struct task_struct *task){	if (unlikely(task->jobctl & JOBCTL_TRAPPING)) {		task->jobctl &= ~JOBCTL_TRAPPING;		smp_mb();	 		wake_up_bit(&task->jobctl, JOBCTL_TRAPPING_BIT);	}}",25233
72,1475,CVE-2014-3185,26,"static int whiteheat_attach(struct usb_serial *serial){	struct usb_serial_port *command_port;	struct whiteheat_command_private *command_info;	struct whiteheat_hw_info *hw_info;	int pipe;	int ret;	int alen;	__u8 *command;	__u8 *result;	command_port = serial->port[COMMAND_PORT];	pipe = usb_sndbulkpipe(serial->dev,			command_port->bulk_out_endpointAddress);	command = kmalloc(2, GFP_KERNEL);	if (!command)		goto no_command_buffer;	command[0] = WHITEHEAT_GET_HW_INFO;	command[1] = 0;	result = kmalloc(sizeof(*hw_info) + 1, GFP_KERNEL);	if (!result)		goto no_result_buffer;	 	usb_clear_halt(serial->dev, pipe);	ret = usb_bulk_msg(serial->dev, pipe, command, 2,						&alen, COMMAND_TIMEOUT_MS);	if (ret) {		dev_err(&serial->dev->dev, ""%s: Couldn't send command [%d]\n"",			serial->type->description, ret);		goto no_firmware;	} else if (alen != 2) {		dev_err(&serial->dev->dev, ""%s: Send command incomplete [%d]\n"",			serial->type->description, alen);		goto no_firmware;	}	pipe = usb_rcvbulkpipe(serial->dev,				command_port->bulk_in_endpointAddress);	 	usb_clear_halt(serial->dev, pipe);	ret = usb_bulk_msg(serial->dev, pipe, result,			sizeof(*hw_info) + 1, &alen, COMMAND_TIMEOUT_MS);	if (ret) {		dev_err(&serial->dev->dev, ""%s: Couldn't get results [%d]\n"",			serial->type->description, ret);		goto no_firmware;	} else if (alen != sizeof(*hw_info) + 1) {		dev_err(&serial->dev->dev, ""%s: Get results incomplete [%d]\n"",			serial->type->description, alen);		goto no_firmware;	} else if (result[0] != command[0]) {		dev_err(&serial->dev->dev, ""%s: Command failed [%d]\n"",			serial->type->description, result[0]);		goto no_firmware;	}	hw_info = (struct whiteheat_hw_info *)&result[1];	dev_info(&serial->dev->dev, ""%s: Firmware v%d.%02d\n"",		 serial->type->description,		 hw_info->sw_major_rev, hw_info->sw_minor_rev);	command_info = kmalloc(sizeof(struct whiteheat_command_private),								GFP_KERNEL);	if (!command_info)		goto no_command_private;	mutex_init(&command_info->mutex);	command_info->port_running = 0;	init_waitqueue_head(&command_info->wait_command);	usb_set_serial_port_data(command_port, command_info);	command_port->write_urb->complete = command_port_write_callback;	command_port->read_urb->complete = command_port_read_callback;	kfree(result);	kfree(command);	return 0;no_firmware:	 	dev_err(&serial->dev->dev,		""%s: Unable to retrieve firmware version, try replugging\n"",		serial->type->description);	dev_err(&serial->dev->dev,		""%s: If the firmware is not running (status led not blinking)\n"",		serial->type->description);	dev_err(&serial->dev->dev,		""%s: please contact support@connecttech.com\n"",		serial->type->description);	kfree(result);	kfree(command);	return -ENODEV;no_command_private:	kfree(result);no_result_buffer:	kfree(command);no_command_buffer:	return -ENOMEM;}",11470
207,2555,CVE-2016-1583,26,void resched_curr(struct rq *rq){	struct task_struct *curr = rq->curr;	int cpu;	lockdep_assert_held(&rq->lock);	if (test_tsk_need_resched(curr))		return;	cpu = cpu_of(rq);	if (cpu == smp_processor_id()) {		set_tsk_need_resched(curr);		set_preempt_need_resched();		return;	}	if (set_nr_and_not_polling(curr))		smp_send_reschedule(cpu);	else		trace_sched_wake_idle_without_ipi(cpu);},18104
681,3522,CVE-2018-20855,26,static struct mlx5_ib_pd *get_pd(struct mlx5_ib_qp *qp){	return to_mpd(qp->ibqp.pd);},27550
597,3713,CVE-2010-5331,26,"radeon_atombios_get_primary_dac_info(struct radeon_encoder *encoder){	struct drm_device *dev = encoder->base.dev;	struct radeon_device *rdev = dev->dev_private;	struct radeon_mode_info *mode_info = &rdev->mode_info;	int index = GetIndexIntoMasterTable(DATA, CompassionateData);	int data_offset;	struct _COMPASSIONATE_DATA *dac_info;	int frev, crev;	int bg, dac;	struct radeon_encoder_primary_dac *p_dac = NULL;	if (atom_parse_data_header(mode_info->atom_context, index, NULL,				   &frev, &crev, &data_offset)) {		dac_info = (struct _COMPASSIONATE_DATA *)			(mode_info->atom_context->bios + data_offset);		p_dac = kzalloc(sizeof(struct radeon_encoder_primary_dac), GFP_KERNEL);		if (!p_dac)			return NULL;		bg = dac_info->ucDAC1_BG_Adjustment;		dac = dac_info->ucDAC1_DAC_Adjustment;		p_dac->ps2_pdac_adj = (bg << 8) | (dac);	}	return p_dac;}",28199
775,1043,CVE-2013-4514,26,"int cfg_driver_identity(struct uilreq *urq, struct wl_private *lp){	int result = 0;	 	DBG_FUNC(""wvlan_driver_identity"");	DBG_ENTER(DbgInfo);	 	if (urq->len < sizeof(lp->driverIdentity)) {		urq->len = sizeof(lp->driverIdentity);		urq->result = UIL_ERR_LEN;		DBG_LEAVE(DbgInfo);		return result;	}	 	result = verify_area(VERIFY_WRITE, urq->data, sizeof(lp->driverIdentity));	if (result != 0) {		urq->result = UIL_FAILURE;		DBG_LEAVE(DbgInfo);		return result;	}	 	urq->result = UIL_SUCCESS;	copy_to_user(urq->data, &(lp->driverIdentity), sizeof(lp->driverIdentity));	DBG_LEAVE(DbgInfo);	return result;}  ",7744
71,3676,CVE-2012-6712,26,"int iwl_set_default_wep_key(struct iwl_priv *priv,			    struct iwl_rxon_context *ctx,			    struct ieee80211_key_conf *keyconf){	int ret;	lockdep_assert_held(&priv->shrd->mutex);	if (keyconf->keylen != WEP_KEY_LEN_128 &&	    keyconf->keylen != WEP_KEY_LEN_64) {		IWL_DEBUG_WEP(priv,			      ""Bad WEP key length %d\n"", keyconf->keylen);		return -EINVAL;	}	keyconf->hw_key_idx = IWLAGN_HW_KEY_DEFAULT;	ctx->wep_keys[keyconf->keyidx].key_size = keyconf->keylen;	memcpy(&ctx->wep_keys[keyconf->keyidx].key, &keyconf->key,							keyconf->keylen);	ret = iwl_send_static_wepkey_cmd(priv, ctx, false);	IWL_DEBUG_WEP(priv, ""Set default WEP key: len=%d idx=%d ret=%d\n"",		keyconf->keylen, keyconf->keyidx, ret);	return ret;}",28162
645,1357,CVE-2013-1773,26,"struct nls_table *load_nls(char *charset){	return try_then_request_module(find_nls(charset), ""nls_%s"", charset);}",9594
648,3408,CVE-2017-15128,26,"follow_huge_addr(struct mm_struct *mm, unsigned long address,			      int write){	return ERR_PTR(-EINVAL);}",26168
101,4045,CVE-2018-20815,26,"void *load_device_tree(const char *filename_path, int *sizep){    int dt_size;    int dt_file_load_size;    int ret;    void *fdt = NULL;    *sizep = 0;    dt_size = get_image_size(filename_path);    if (dt_size < 0) {        error_report(""Unable to get size of device tree file '%s'"",                     filename_path);        goto fail;    }         dt_size += 10000;    dt_size *= 2;           fdt = g_malloc0(dt_size);     dt_file_load_size = load_image(filename_path, fdt);     if (dt_file_load_size < 0) {         error_report(""Unable to open device tree file '%s'"",                      filename_path);        goto fail;    }    ret = fdt_open_into(fdt, fdt, dt_size);    if (ret) {        error_report(""Unable to copy device tree in memory"");        goto fail;    }         if (fdt_check_header(fdt)) {        error_report(""Device tree file loaded into memory is invalid: %s"",                     filename_path);        goto fail;    }    *sizep = dt_size;    return fdt;fail:    g_free(fdt);    return NULL;}",30911
159,667,CVE-2011-2517,26,"static int nl80211_get_reg(struct sk_buff *skb, struct genl_info *info){	struct sk_buff *msg;	void *hdr = NULL;	struct nlattr *nl_reg_rules;	unsigned int i;	int err = -EINVAL;	mutex_lock(&cfg80211_mutex);	if (!cfg80211_regdomain)		goto out;	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);	if (!msg) {		err = -ENOBUFS;		goto out;	}	hdr = nl80211hdr_put(msg, info->snd_pid, info->snd_seq, 0,			     NL80211_CMD_GET_REG);	if (!hdr)		goto put_failure;	NLA_PUT_STRING(msg, NL80211_ATTR_REG_ALPHA2,		cfg80211_regdomain->alpha2);	nl_reg_rules = nla_nest_start(msg, NL80211_ATTR_REG_RULES);	if (!nl_reg_rules)		goto nla_put_failure;	for (i = 0; i < cfg80211_regdomain->n_reg_rules; i++) {		struct nlattr *nl_reg_rule;		const struct ieee80211_reg_rule *reg_rule;		const struct ieee80211_freq_range *freq_range;		const struct ieee80211_power_rule *power_rule;		reg_rule = &cfg80211_regdomain->reg_rules[i];		freq_range = &reg_rule->freq_range;		power_rule = &reg_rule->power_rule;		nl_reg_rule = nla_nest_start(msg, i);		if (!nl_reg_rule)			goto nla_put_failure;		NLA_PUT_U32(msg, NL80211_ATTR_REG_RULE_FLAGS,			reg_rule->flags);		NLA_PUT_U32(msg, NL80211_ATTR_FREQ_RANGE_START,			freq_range->start_freq_khz);		NLA_PUT_U32(msg, NL80211_ATTR_FREQ_RANGE_END,			freq_range->end_freq_khz);		NLA_PUT_U32(msg, NL80211_ATTR_FREQ_RANGE_MAX_BW,			freq_range->max_bandwidth_khz);		NLA_PUT_U32(msg, NL80211_ATTR_POWER_RULE_MAX_ANT_GAIN,			power_rule->max_antenna_gain);		NLA_PUT_U32(msg, NL80211_ATTR_POWER_RULE_MAX_EIRP,			power_rule->max_eirp);		nla_nest_end(msg, nl_reg_rule);	}	nla_nest_end(msg, nl_reg_rules);	genlmsg_end(msg, hdr);	err = genlmsg_reply(msg, info);	goto out;nla_put_failure:	genlmsg_cancel(msg, hdr);put_failure:	nlmsg_free(msg);	err = -EMSGSIZE;out:	mutex_unlock(&cfg80211_mutex);	return err;}",6566
26,3084,CVE-2016-10012,26,"mm_destroy(struct mm_master *mm){	mm_freelist(mm->mmalloc, &mm->rb_free);	mm_freelist(mm->mmalloc, &mm->rb_allocated);	if (munmap(mm->address, mm->size) == -1)		fatal(""munmap(%p, %zu): %s"", mm->address, mm->size,		    strerror(errno));	if (mm->mmalloc == NULL)		free(mm);	else		mm_free(mm->mmalloc, mm);}",22602
211,2069,CVE-2016-4478,26,"char *xmlrpc_string(char *buf, const char *value){	char encoded[XMLRPC_BUFSIZE];	*buf = '\0';	xmlrpc_char_encode(encoded, value);	snprintf(buf, XMLRPC_BUFSIZE, ""<string>%s</string>"", encoded);	return buf;}",16968
518,1762,CVE-2016-9793,26,"int __sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb){	unsigned long flags;	struct sk_buff_head *list = &sk->sk_receive_queue;	if (atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf) {		atomic_inc(&sk->sk_drops);		trace_sock_rcvqueue_full(sk, skb);		return -ENOMEM;	}	if (!sk_rmem_schedule(sk, skb, skb->truesize)) {		atomic_inc(&sk->sk_drops);		return -ENOBUFS;	}	skb->dev = NULL;	skb_set_owner_r(skb, sk);	 	skb_dst_force(skb);	spin_lock_irqsave(&list->lock, flags);	sock_skb_set_dropcount(sk, skb);	__skb_queue_tail(list, skb);	spin_unlock_irqrestore(&list->lock, flags);	if (!sock_flag(sk, SOCK_DEAD))		sk->sk_data_ready(sk);	return 0;}",15046
535,1579,CVE-2015-5283,26,"static int sctp_v4_addr_to_user(struct sctp_sock *sp, union sctp_addr *addr){	 	return sizeof(struct sockaddr_in);}",13434
941,1101,CVE-2013-2237,26,"	__acquires(rcu){	struct net *net = seq_file_net(f);	struct netns_pfkey *net_pfkey = net_generic(net, pfkey_net_id);	rcu_read_lock();	return seq_hlist_start_head_rcu(&net_pfkey->table, *ppos);}",8690
491,3903,CVE-2017-15415,26,"static void InitLibcLocaltimeFunctions() {  g_libc_localtime = reinterpret_cast<LocaltimeFunction>(      dlsym(RTLD_NEXT, ""localtime""));  g_libc_localtime64 = reinterpret_cast<LocaltimeFunction>(      dlsym(RTLD_NEXT, ""localtime64""));  g_libc_localtime_r = reinterpret_cast<LocaltimeRFunction>(      dlsym(RTLD_NEXT, ""localtime_r""));  g_libc_localtime64_r = reinterpret_cast<LocaltimeRFunction>(      dlsym(RTLD_NEXT, ""localtime64_r""));  if (!g_libc_localtime || !g_libc_localtime_r) {    LOG(ERROR) << ""Your system is broken: dlsym doesn't work! This has been ""                  ""reported to be caused by Nvidia's libGL. You should expect""                  "" time related functions to misbehave. ""                  ""http://code.google.com/p/chromium/issues/detail?id=16800"";  }  if (!g_libc_localtime)    g_libc_localtime = gmtime;  if (!g_libc_localtime64)    g_libc_localtime64 = g_libc_localtime;  if (!g_libc_localtime_r)    g_libc_localtime_r = gmtime_r;  if (!g_libc_localtime64_r)    g_libc_localtime64_r = g_libc_localtime_r;}",30137
119,1825,CVE-2016-8658,26,"static int brcmf_setup_ifmodes(struct wiphy *wiphy, struct brcmf_if *ifp){	struct ieee80211_iface_combination *combo = NULL;	struct ieee80211_iface_limit *c0_limits = NULL;	struct ieee80211_iface_limit *p2p_limits = NULL;	struct ieee80211_iface_limit *mbss_limits = NULL;	int mbss, p2p;	int i, c, n_combos;	mbss = brcmf_feat_is_enabled(ifp, BRCMF_FEAT_MBSS);	p2p = brcmf_feat_is_enabled(ifp, BRCMF_FEAT_P2P);	n_combos = 1 + !!p2p + !!mbss;	combo = kcalloc(n_combos, sizeof(*combo), GFP_KERNEL);	if (!combo)		goto err;	wiphy->interface_modes = BIT(NL80211_IFTYPE_STATION) |				 BIT(NL80211_IFTYPE_ADHOC) |				 BIT(NL80211_IFTYPE_AP);	c = 0;	i = 0;	c0_limits = kcalloc(p2p ? 3 : 2, sizeof(*c0_limits), GFP_KERNEL);	if (!c0_limits)		goto err;	c0_limits[i].max = 1;	c0_limits[i++].types = BIT(NL80211_IFTYPE_STATION);	if (p2p) {		if (brcmf_feat_is_enabled(ifp, BRCMF_FEAT_MCHAN))			combo[c].num_different_channels = 2;		wiphy->interface_modes |= BIT(NL80211_IFTYPE_P2P_CLIENT) |					  BIT(NL80211_IFTYPE_P2P_GO) |					  BIT(NL80211_IFTYPE_P2P_DEVICE);		c0_limits[i].max = 1;		c0_limits[i++].types = BIT(NL80211_IFTYPE_P2P_DEVICE);		c0_limits[i].max = 1;		c0_limits[i++].types = BIT(NL80211_IFTYPE_P2P_CLIENT) |				       BIT(NL80211_IFTYPE_P2P_GO);	} else {		c0_limits[i].max = 1;		c0_limits[i++].types = BIT(NL80211_IFTYPE_AP);	}	combo[c].num_different_channels = 1;	combo[c].max_interfaces = i;	combo[c].n_limits = i;	combo[c].limits = c0_limits;	if (p2p) {		c++;		i = 0;		p2p_limits = kcalloc(4, sizeof(*p2p_limits), GFP_KERNEL);		if (!p2p_limits)			goto err;		p2p_limits[i].max = 1;		p2p_limits[i++].types = BIT(NL80211_IFTYPE_STATION);		p2p_limits[i].max = 1;		p2p_limits[i++].types = BIT(NL80211_IFTYPE_AP);		p2p_limits[i].max = 1;		p2p_limits[i++].types = BIT(NL80211_IFTYPE_P2P_CLIENT);		p2p_limits[i].max = 1;		p2p_limits[i++].types = BIT(NL80211_IFTYPE_P2P_DEVICE);		combo[c].num_different_channels = 1;		combo[c].max_interfaces = i;		combo[c].n_limits = i;		combo[c].limits = p2p_limits;	}	if (mbss) {		c++;		i = 0;		mbss_limits = kcalloc(1, sizeof(*mbss_limits), GFP_KERNEL);		if (!mbss_limits)			goto err;		mbss_limits[i].max = 4;		mbss_limits[i++].types = BIT(NL80211_IFTYPE_AP);		combo[c].beacon_int_infra_match = true;		combo[c].num_different_channels = 1;		combo[c].max_interfaces = 4;		combo[c].n_limits = i;		combo[c].limits = mbss_limits;	}	wiphy->n_iface_combinations = n_combos;	wiphy->iface_combinations = combo;	return 0;err:	kfree(c0_limits);	kfree(p2p_limits);	kfree(mbss_limits);	kfree(combo);	return -ENOMEM;}",15473
725,1607,CVE-2015-5156,26,static int init_vqs(struct virtnet_info *vi){	int ret;	 	ret = virtnet_alloc_queues(vi);	if (ret)		goto err;	ret = virtnet_find_vqs(vi);	if (ret)		goto err_free;	get_online_cpus();	virtnet_set_affinity(vi);	put_online_cpus();	return 0;err_free:	virtnet_free_queues(vi);err:	return ret;},13464
747,644,CVE-2011-3353,26,"static void queue_interrupt(struct fuse_conn *fc, struct fuse_req *req){	list_add_tail(&req->intr_entry, &fc->interrupts);	wake_up(&fc->waitq);	kill_fasync(&fc->fasync, SIGIO, POLL_IN);}",5617
561,2467,CVE-2016-2315,26,"void mark_parents_uninteresting(struct commit *commit){	struct commit_list *parents = NULL, *l;	for (l = commit->parents; l; l = l->next)		commit_list_insert(l->item, &parents);	while (parents) {		struct commit *commit = parents->item;		l = parents;		parents = parents->next;		free(l);		while (commit) {			 			if (!has_sha1_file(commit->object.sha1))				commit->object.parsed = 1;			if (commit->object.flags & UNINTERESTING)				break;			commit->object.flags |= UNINTERESTING;			 			if (!commit->parents)				break;			for (l = commit->parents->next; l; l = l->next)				commit_list_insert(l->item, &parents);			commit = commit->parents->item;		}	}}",17887
422,3159,CVE-2015-8026,26,"static void finalize_super_block(struct exfat* ef){	if (ef->ro)		return;	ef->sb->volume_state = cpu_to_le16(			le16_to_cpu(ef->sb->volume_state) & ~EXFAT_STATE_MOUNTED);	 	if (ef->sb->allocated_percent != 0xff)	{		int free, total;		free = exfat_count_free_clusters(ef);		total = le32_to_cpu(ef->sb->cluster_count);		ef->sb->allocated_percent = ((total - free) * 100 + total / 2) / total;	}	commit_super_block(ef);	 }",22887
263,1022,CVE-2013-4588,26,"static int ip_vs_genl_fill_dest(struct sk_buff *skb, struct ip_vs_dest *dest){	struct nlattr *nl_dest;	nl_dest = nla_nest_start(skb, IPVS_CMD_ATTR_DEST);	if (!nl_dest)		return -EMSGSIZE;	NLA_PUT(skb, IPVS_DEST_ATTR_ADDR, sizeof(dest->addr), &dest->addr);	NLA_PUT_U16(skb, IPVS_DEST_ATTR_PORT, dest->port);	NLA_PUT_U32(skb, IPVS_DEST_ATTR_FWD_METHOD,		    atomic_read(&dest->conn_flags) & IP_VS_CONN_F_FWD_MASK);	NLA_PUT_U32(skb, IPVS_DEST_ATTR_WEIGHT, atomic_read(&dest->weight));	NLA_PUT_U32(skb, IPVS_DEST_ATTR_U_THRESH, dest->u_threshold);	NLA_PUT_U32(skb, IPVS_DEST_ATTR_L_THRESH, dest->l_threshold);	NLA_PUT_U32(skb, IPVS_DEST_ATTR_ACTIVE_CONNS,		    atomic_read(&dest->activeconns));	NLA_PUT_U32(skb, IPVS_DEST_ATTR_INACT_CONNS,		    atomic_read(&dest->inactconns));	NLA_PUT_U32(skb, IPVS_DEST_ATTR_PERSIST_CONNS,		    atomic_read(&dest->persistconns));	if (ip_vs_genl_fill_stats(skb, IPVS_DEST_ATTR_STATS, &dest->stats))		goto nla_put_failure;	nla_nest_end(skb, nl_dest);	return 0;nla_put_failure:	nla_nest_cancel(skb, nl_dest);	return -EMSGSIZE;}",7619
253,3104,CVE-2016-10012,26,get_hostkey_by_index(int ind){	if (ind < 0 || ind >= options.num_host_key_files)		return (NULL);	return (sensitive_data.host_keys[ind]);},22622
672,345,CVE-2010-2527,26,  event_index_change( int  delta )  {    int  num_indices = handle->current_font->num_indices;    status.Num += delta;    if ( status.Num < 0 )      status.Num = 0;    else if ( status.Num >= num_indices )      status.Num = num_indices - 1;  },1824
410,3137,CVE-2016-7480,26,"SPL_METHOD(MultipleIterator, current){	spl_SplObjectStorage        *intern;	intern = Z_SPLOBJSTORAGE_P(getThis());	if (zend_parse_parameters_none() == FAILURE) {		return;	}	spl_multiple_iterator_get_all(intern, SPL_MULTIPLE_ITERATOR_GET_ALL_CURRENT, return_value);}",22804
267,982,CVE-2013-4591,26,"int nfs4_proc_get_rootfh(struct nfs_server *server, struct nfs_fh *fhandle,			 struct nfs_fsinfo *info){	int minor_version = server->nfs_client->cl_minorversion;	int status = nfs4_lookup_root(server, fhandle, info);	if ((status == -NFS4ERR_WRONGSEC) && !(server->flags & NFS_MOUNT_SECFLAVOUR))		 		status = nfs_v4_minor_ops[minor_version]->find_root_sec(server, fhandle, info);	if (status == 0)		status = nfs4_server_capabilities(server, fhandle);	if (status == 0)		status = nfs4_do_fsinfo(server, fhandle, info);	return nfs4_map_errors(status);}",7579
919,3155,CVE-2016-1245,26,"rtadv_terminate (struct zebra_vrf *zvrf){  rtadv_event (zvrf, RTADV_STOP, 0);  if (zvrf->rtadv.sock >= 0)    {      close (zvrf->rtadv.sock);      zvrf->rtadv.sock = -1;    }  zvrf->rtadv.adv_if_count = 0;  zvrf->rtadv.adv_msec_if_count = 0;}",22859
390,2574,CVE-2016-1583,26,static void sched_rq_cpu_starting(unsigned int cpu){	struct rq *rq = cpu_rq(cpu);	rq->calc_load_update = calc_load_update;	account_reset_rq(rq);	update_max_interval();},18123
708,2146,CVE-2016-4303,26,"make_cookie(char *cookie){    static int randomized = 0;    char hostname[500];    struct timeval tv;    char temp[1000];    if ( ! randomized )        srandom((int) time(0) ^ getpid());         (void) gethostname(hostname, sizeof(hostname));    (void) gettimeofday(&tv, 0);    (void) snprintf(temp, sizeof(temp), ""%s.%ld.%06ld.%08lx%08lx.%s"", hostname, (unsigned long int) tv.tv_sec, (unsigned long int) tv.tv_usec, (unsigned long int) random(), (unsigned long int) random(), ""1234567890123456789012345678901234567890"");         memcpy(cookie, temp, 36);    cookie[36] = '\0';}",17054
179,3201,CVE-2018-17407,26,static void t1_check_pfa(void){    const int c = t1_getchar();    t1_pfa = (c != 128) ? true : false;    t1_ungetchar(c);},23635
466,2113,CVE-2016-4303,26,iperf_on_test_finish(struct iperf_test *test){},17021
844,334,CVE-2010-2527,26,  make_tag( char  *s )  {    int            i;    unsigned long  l = 0;    for ( i = 0; i < 4; i++ )    {      if ( !s[i] )        break;      l <<= 8;      l  += (unsigned long)s[i];    }    return l;  },1813
161,2638,CVE-2017-1000251,26,"static int l2cap_disconn_ind(struct hci_conn *hcon){	struct l2cap_conn *conn = hcon->l2cap_data;	BT_DBG(""hcon %p"", hcon);	if (hcon->type != ACL_LINK || !conn)		return 0x13;	return conn->disc_reason;}",19476
233,114,CVE-2013-4282,26,"static void reds_update_mouse_mode(void){    int allowed = 0;    int qxl_count = red_dispatcher_qxl_count();    if ((agent_mouse && vdagent) || (inputs_has_tablet() && qxl_count == 1)) {        allowed = reds->dispatcher_allows_client_mouse;    }    if (allowed == reds->is_client_mouse_allowed) {        return;    }    reds->is_client_mouse_allowed = allowed;    if (reds->mouse_mode == SPICE_MOUSE_MODE_CLIENT && !allowed) {        reds_set_mouse_mode(SPICE_MOUSE_MODE_SERVER);        return;    }    if (reds->main_channel) {        main_channel_push_mouse_mode(reds->main_channel, reds->mouse_mode,                                     reds->is_client_mouse_allowed);    }}",424
481,1273,CVE-2013-1929,26,"static int tg3_nvram_lock(struct tg3 *tp){	if (tg3_flag(tp, NVRAM)) {		int i;		if (tp->nvram_lock_cnt == 0) {			tw32(NVRAM_SWARB, SWARB_REQ_SET1);			for (i = 0; i < 8000; i++) {				if (tr32(NVRAM_SWARB) & SWARB_GNT1)					break;				udelay(20);			}			if (i == 8000) {				tw32(NVRAM_SWARB, SWARB_REQ_CLR1);				return -ENODEV;			}		}		tp->nvram_lock_cnt++;	}	return 0;}",9279
655,2150,CVE-2016-4302,26,"add_value(struct archive_read *a, struct huffman_code *code, int value,          int codebits, int length){  int repeatpos, lastnode, bitpos, bit, repeatnode, nextnode;  free(code->table);  code->table = NULL;  if(length > code->maxlength)    code->maxlength = length;  if(length < code->minlength)    code->minlength = length;  repeatpos = -1;  if (repeatpos == 0 || (repeatpos >= 0    && (((codebits >> (repeatpos - 1)) & 3) == 0    || ((codebits >> (repeatpos - 1)) & 3) == 3)))  {    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                      ""Invalid repeat position"");    return (ARCHIVE_FATAL);  }  lastnode = 0;  for (bitpos = length - 1; bitpos >= 0; bitpos--)  {    bit = (codebits >> bitpos) & 1;         if (code->tree[lastnode].branches[0] ==      code->tree[lastnode].branches[1])    {      archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                        ""Prefix found"");      return (ARCHIVE_FATAL);    }    if (bitpos == repeatpos)    {             if (!(code->tree[lastnode].branches[bit] < 0))      {        archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                          ""Invalid repeating code"");        return (ARCHIVE_FATAL);      }      if ((repeatnode = new_node(code)) < 0) {        archive_set_error(&a->archive, ENOMEM,                          ""Unable to allocate memory for node data."");        return (ARCHIVE_FATAL);      }      if ((nextnode = new_node(code)) < 0) {        archive_set_error(&a->archive, ENOMEM,                          ""Unable to allocate memory for node data."");        return (ARCHIVE_FATAL);      }             code->tree[lastnode].branches[bit] = repeatnode;      code->tree[repeatnode].branches[bit] = repeatnode;      code->tree[repeatnode].branches[bit^1] = nextnode;      lastnode = nextnode;      bitpos++;      }    else    {             if (code->tree[lastnode].branches[bit] < 0)      {        if (new_node(code) < 0) {          archive_set_error(&a->archive, ENOMEM,                            ""Unable to allocate memory for node data."");          return (ARCHIVE_FATAL);        }        code->tree[lastnode].branches[bit] = code->numentries++;      }             lastnode = code->tree[lastnode].branches[bit];    }  }  if (!(code->tree[lastnode].branches[0] == -1    && code->tree[lastnode].branches[1] == -2))  {    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                      ""Prefix found"");    return (ARCHIVE_FATAL);  }     code->tree[lastnode].branches[0] = value;  code->tree[lastnode].branches[1] = value;  return (ARCHIVE_OK);}",17058
1018,1922,CVE-2016-6187,26,"static int apparmor_path_rename(const struct path *old_dir, struct dentry *old_dentry,				const struct path *new_dir, struct dentry *new_dentry){	struct aa_profile *profile;	int error = 0;	if (!mediated_filesystem(old_dentry))		return 0;	profile = aa_current_profile();	if (!unconfined(profile)) {		struct path old_path = { old_dir->mnt, old_dentry };		struct path new_path = { new_dir->mnt, new_dentry };		struct path_cond cond = { d_backing_inode(old_dentry)->i_uid,					  d_backing_inode(old_dentry)->i_mode		};		error = aa_path_perm(OP_RENAME_SRC, profile, &old_path, 0,				     MAY_READ | AA_MAY_META_READ | MAY_WRITE |				     AA_MAY_META_WRITE | AA_MAY_DELETE,				     &cond);		if (!error)			error = aa_path_perm(OP_RENAME_DEST, profile, &new_path,					     0, MAY_WRITE | AA_MAY_META_WRITE |					     AA_MAY_CREATE, &cond);	}	return error;}",16267
607,891,CVE-2013-6381,26,"static int qeth_query_ipassists_cb(struct qeth_card *card,		struct qeth_reply *reply, unsigned long data){	struct qeth_ipa_cmd *cmd;	QETH_DBF_TEXT(SETUP, 2, ""qipasscb"");	cmd = (struct qeth_ipa_cmd *) data;	switch (cmd->hdr.return_code) {	case IPA_RC_NOTSUPP:	case IPA_RC_L2_UNSUPPORTED_CMD:		QETH_DBF_TEXT(SETUP, 2, ""ipaunsup"");		card->options.ipa4.supported_funcs |= IPA_SETADAPTERPARMS;		card->options.ipa6.supported_funcs |= IPA_SETADAPTERPARMS;		return -0;	default:		if (cmd->hdr.return_code) {			QETH_DBF_MESSAGE(1, ""%s IPA_CMD_QIPASSIST: Unhandled ""						""rc=%d\n"",						dev_name(&card->gdev->dev),						cmd->hdr.return_code);			return 0;		}	}	if (cmd->hdr.prot_version == QETH_PROT_IPV4) {		card->options.ipa4.supported_funcs = cmd->hdr.ipa_supported;		card->options.ipa4.enabled_funcs = cmd->hdr.ipa_enabled;	} else if (cmd->hdr.prot_version == QETH_PROT_IPV6) {		card->options.ipa6.supported_funcs = cmd->hdr.ipa_supported;		card->options.ipa6.enabled_funcs = cmd->hdr.ipa_enabled;	} else		QETH_DBF_MESSAGE(1, ""%s IPA_CMD_QIPASSIST: Flawed LIC detected""					""\n"", dev_name(&card->gdev->dev));	return 0;}",7320
972,554,CVE-2012-2745,26,"void validate_creds_for_do_exit(struct task_struct *tsk){	kdebug(""validate_creds_for_do_exit(%p,%p{%d,%d})"",	       tsk->real_cred, tsk->cred,	       atomic_read(&tsk->cred->usage),	       read_cred_subscribers(tsk->cred));	__validate_process_creds(tsk, __FILE__, __LINE__);}",3156
384,2256,CVE-2016-2324,26,"static void record_recent_commit(struct commit *commit, void *data){	sha1_array_append(&recent_objects, commit->object.oid.hash);}",17676
965,1819,CVE-2016-8658,26,static int brcmf_is_apmode(struct brcmf_cfg80211_vif *vif){	enum nl80211_iftype iftype;	iftype = vif->wdev.iftype;	return iftype == NL80211_IFTYPE_AP || iftype == NL80211_IFTYPE_P2P_GO;},15467
819,47,CVE-2019-15938,26,"static int nfs_mount_req(struct nfs_priv *npriv){	int data[1024];	int *p;	int len;	int pathlen;	struct packet *nfs_packet;	pathlen = strlen(npriv->path);	debug(""%s: %s\n"", __func__, npriv->path);	p = &(data[0]);	p = rpc_add_credentials(p);	*p++ = hton32(pathlen);	if (pathlen & 3)		*(p + pathlen / 4) = 0;	memcpy (p, npriv->path, pathlen);	p += (pathlen + 3) / 4;	len = p - &(data[0]);	nfs_packet = rpc_req(npriv, PROG_MOUNT, MOUNT_ADDENTRY, data, len);	if (IS_ERR(nfs_packet))		return PTR_ERR(nfs_packet);	p = (void *)nfs_packet->data + sizeof(struct rpc_reply) + 4;	npriv->rootfh.size = ntoh32(net_read_uint32(p++));	if (npriv->rootfh.size > NFS3_FHSIZE) {		printf(""%s: file handle too big: %lu\n"",		       __func__, (unsigned long)npriv->rootfh.size);		free(nfs_packet);		return -EIO;	}	memcpy(npriv->rootfh.data, p, npriv->rootfh.size);	free(nfs_packet);	return 0;}",278
501,2407,CVE-2016-2315,26,"static struct branch *lookup_branch(const char *name){	unsigned int hc = hc_str(name, strlen(name)) % branch_table_sz;	struct branch *b;	for (b = branch_table[hc]; b; b = b->table_next_branch)		if (!strcmp(name, b->name))			return b;	return NULL;}",17827
178,3997,CVE-2016-1621,26,int arg_parse_enum_or_int(const struct arg *arg) { if (arg->def->enums) return arg_parse_enum(arg); return arg_parse_int(arg);},30828
498,900,CVE-2013-6381,26,"int qeth_send_ipa_cmd(struct qeth_card *card, struct qeth_cmd_buffer *iob,		int (*reply_cb)(struct qeth_card *, struct qeth_reply*,			unsigned long),		void *reply_param){	int rc;	char prot_type;	QETH_CARD_TEXT(card, 4, ""sendipa"");	if (card->options.layer2)		if (card->info.type == QETH_CARD_TYPE_OSN)			prot_type = QETH_PROT_OSN2;		else			prot_type = QETH_PROT_LAYER2;	else		prot_type = QETH_PROT_TCPIP;	qeth_prepare_ipa_cmd(card, iob, prot_type);	rc = qeth_send_control_data(card, IPA_CMD_LENGTH,						iob, reply_cb, reply_param);	if (rc == -ETIME) {		qeth_clear_ipacmd_list(card);		qeth_schedule_recovery(card);	}	return rc;}",7329
906,1076,CVE-2013-4244,26,"checksignature(void){    char buf[6];    fread(buf,1,6,infile);    if (strncmp(buf,""GIF"",3)) {        fprintf(stderr, ""file is not a GIF file\n"");        return 0;    }    if (strncmp(&buf[3],""87a"",3)) {        fprintf(stderr, ""unknown GIF version number\n"");        return 0;    }    return 1;}",7929
952,3355,CVE-2017-18222,26,"static void hns_gmac_disable(void *mac_drv, enum mac_commom_mode mode){	struct mac_driver *drv = (struct mac_driver *)mac_drv;	 	if ((mode == MAC_COMM_MODE_TX) || (mode == MAC_COMM_MODE_RX_AND_TX))		dsaf_set_dev_bit(drv, GMAC_PORT_EN_REG, GMAC_PORT_TX_EN_B, 0);	if ((mode == MAC_COMM_MODE_RX) || (mode == MAC_COMM_MODE_RX_AND_TX))		dsaf_set_dev_bit(drv, GMAC_PORT_EN_REG, GMAC_PORT_RX_EN_B, 0);}",25796
841,463,CVE-2016-2148,26,"static char *allocate_tempopt_if_needed(		const struct dhcp_optflag *optflag,		char *buffer,		int *length_p){	char *allocated = NULL;	if ((optflag->flags & OPTION_TYPE_MASK) == OPTION_BIN) {		const char *end;		allocated = xstrdup(buffer);  		end = hex2bin(allocated, buffer, 255);		if (errno)			bb_error_msg_and_die(""malformed hex string '%s'"", buffer);		*length_p = end - allocated;	}	return allocated;}",2376
697,637,CVE-2011-3353,26,"static void fuse_request_send_nowait(struct fuse_conn *fc, struct fuse_req *req){	spin_lock(&fc->lock);	if (fc->connected) {		fuse_request_send_nowait_locked(fc, req);		spin_unlock(&fc->lock);	} else {		req->out.h.error = -ENOTCONN;		request_end(fc, req);	}}",5610
901,1552,CVE-2014-0069,26,"cifs_posix_lock_test(struct file *file, struct file_lock *flock){	int rc = 0;	struct cifsInodeInfo *cinode = CIFS_I(file_inode(file));	unsigned char saved_type = flock->fl_type;	if ((flock->fl_flags & FL_POSIX) == 0)		return 1;	down_read(&cinode->lock_sem);	posix_test_lock(file, flock);	if (flock->fl_type == F_UNLCK && !cinode->can_cache_brlcks) {		flock->fl_type = saved_type;		rc = 1;	}	up_read(&cinode->lock_sem);	return rc;}",12298
319,1309,CVE-2013-1929,26,"static void tg3_tx_timeout(struct net_device *dev){	struct tg3 *tp = netdev_priv(dev);	if (netif_msg_tx_err(tp)) {		netdev_err(dev, ""transmit timed out, resetting\n"");		tg3_dump_state(tp);	}	tg3_reset_task_schedule(tp);}",9315
42,2790,CVE-2017-9994,26,"static void inv_predict_2(int *p, const int *p_l, const int *p_tl,                          const int *p_t, const int *p_tr){    AV_COPY32(p, p_t);}",20675
606,798,CVE-2013-6381,26,"static int qeth_clear_channels(struct qeth_card *card){	int rc1 = 0, rc2 = 0, rc3 = 0;	QETH_CARD_TEXT(card, 3, ""clearchs"");	rc1 = qeth_clear_channel(&card->read);	rc2 = qeth_clear_channel(&card->write);	rc3 = qeth_clear_channel(&card->data);	if (rc1)		return rc1;	if (rc2)		return rc2;	return rc3;}",7227
399,2609,CVE-2016-1583,26,void wake_up_nohz_cpu(int cpu){	if (!wake_up_full_nohz_cpu(cpu))		wake_up_idle_cpu(cpu);},18158
534,425,CVE-2016-1907,26,"ssh_remote_ipaddr(struct ssh *ssh){	 	if (ssh->remote_ipaddr == NULL)		ssh->remote_ipaddr = ssh_packet_connection_is_on_socket(ssh) ?		    get_peer_ipaddr(ssh->state->connection_in) :		    strdup(""UNKNOWN"");	if (ssh->remote_ipaddr == NULL)		return ""UNKNOWN"";	return ssh->remote_ipaddr;}",2149
224,1471,CVE-2014-3186,26,"int picolcd_reset(struct hid_device *hdev){	struct picolcd_data *data = hid_get_drvdata(hdev);	struct hid_report *report = picolcd_out_report(REPORT_RESET, hdev);	unsigned long flags;	int error;	if (!data || !report || report->maxfield != 1)		return -ENODEV;	spin_lock_irqsave(&data->lock, flags);	if (hdev->product == USB_DEVICE_ID_PICOLCD_BOOTLOADER)		data->status |= PICOLCD_BOOTLOADER;	 	hid_set_field(report->field[0], 0, 1);	if (data->status & PICOLCD_FAILED) {		spin_unlock_irqrestore(&data->lock, flags);		return -ENODEV;	}	hid_hw_request(hdev, report, HID_REQ_SET_REPORT);	spin_unlock_irqrestore(&data->lock, flags);	error = picolcd_check_version(hdev);	if (error)		return error;	picolcd_resume_lcd(data);	picolcd_resume_backlight(data);	picolcd_fb_refresh(data);	picolcd_leds_set(data);	return 0;}",11466
129,3967,CVE-2016-2463,26,void H264SwDecTrace(char *string) {     UNUSED(string); },30673
185,285,CVE-2017-6542,26,"static void ssh_pkt_adduint32(struct Packet *pkt, unsigned long value){    unsigned char x[4];    PUT_32BIT(x, value);    ssh_pkt_adddata(pkt, x, 4);}",1349
128,3442,CVE-2017-15128,26,"static inline void unlock_or_release_subpool(struct hugepage_subpool *spool){	int free = (spool->count == 0) && (spool->used_hpages == 0);	spin_unlock(&spool->lock);	 	if (free) {		if (spool->min_hpages != -1)			hugetlb_acct_memory(spool->hstate,						-spool->min_hpages);		kfree(spool);	}}",26202
270,1206,CVE-2013-2128,26,static inline int tcp_need_reset(int state){	return (1 << state) &	       (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT | TCPF_FIN_WAIT1 |		TCPF_FIN_WAIT2 | TCPF_SYN_RECV);},8888
259,704,CVE-2011-1477,26,"static void calc_vol(unsigned char *regbyte, int volume, int main_vol){	int level = (~*regbyte & 0x3f);	if (main_vol > 127)		main_vol = 127;	volume = (volume * main_vol) / 127;	if (level)		level += fm_volume_table[volume];	if (level > 0x3f)		level = 0x3f;	if (level < 0)		level = 0;	*regbyte = (*regbyte & 0xc0) | (~level & 0x3f);}",6851
661,2758,CVE-2017-11328,26,"static void test_count(){  assert_true_rule(      ""rule test { strings: $a = \""ssi\"" condition: #a == 2 }"",      ""mississippi"");}",20540
688,4046,CVE-2012-6711,26," stub_charset () {  locale = get_locale_var (""LC_CTYPE"");    locale = get_locale_var (""LC_CTYPE"");   if (locale == 0 || *locale == 0)    return ""ASCII"";   s = strrchr (locale, '.');   if (s)     {      t = strchr (s, '@');       if (t) 	*t = 0;      return ++s;     }  else if (STREQ (locale, ""UTF-8""))    return ""UTF-8"";  else    return ""ASCII""; }",30918
356,1097,CVE-2013-2850,26,"int iscsi_extract_key_value(char *textbuf, char **key, char **value){	*value = strchr(textbuf, '=');	if (!*value) {		pr_err(""Unable to locate \""=\"" separator for key,""				"" ignoring request.\n"");		return -1;	}	*key = textbuf;	**value = '\0';	*value = *value + 1;	return 0;}",8499
165,2076,CVE-2016-4303,26,"get_parameters(struct iperf_test *test){    int r = 0;    cJSON *j;    cJSON *j_p;    j = JSON_read(test->ctrl_sck);    if (j == NULL) {	i_errno = IERECVPARAMS;        r = -1;    } else {	if (test->debug) {	    printf(""get_parameters:\n%s\n"", cJSON_Print(j));	}	if ((j_p = cJSON_GetObjectItem(j, ""tcp"")) != NULL)	    set_protocol(test, Ptcp);	if ((j_p = cJSON_GetObjectItem(j, ""udp"")) != NULL)	    set_protocol(test, Pudp);	if ((j_p = cJSON_GetObjectItem(j, ""omit"")) != NULL)	    test->omit = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""server_affinity"")) != NULL)	    test->server_affinity = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""time"")) != NULL)	    test->duration = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""num"")) != NULL)	    test->settings->bytes = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""blockcount"")) != NULL)	    test->settings->blocks = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""MSS"")) != NULL)	    test->settings->mss = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""nodelay"")) != NULL)	    test->no_delay = 1;	if ((j_p = cJSON_GetObjectItem(j, ""parallel"")) != NULL)	    test->num_streams = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""reverse"")) != NULL)	    iperf_set_test_reverse(test, 1);	if ((j_p = cJSON_GetObjectItem(j, ""window"")) != NULL)	    test->settings->socket_bufsize = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""len"")) != NULL)	    test->settings->blksize = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""bandwidth"")) != NULL)	    test->settings->rate = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""burst"")) != NULL)	    test->settings->burst = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""TOS"")) != NULL)	    test->settings->tos = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""flowlabel"")) != NULL)	    test->settings->flowlabel = j_p->valueint;	if ((j_p = cJSON_GetObjectItem(j, ""title"")) != NULL)	    test->title = strdup(j_p->valuestring);	if ((j_p = cJSON_GetObjectItem(j, ""congestion"")) != NULL)	    test->congestion = strdup(j_p->valuestring);	if ((j_p = cJSON_GetObjectItem(j, ""get_server_output"")) != NULL)	    iperf_set_test_get_server_output(test, 1);	if (test->sender && test->protocol->id == Ptcp && has_tcpinfo_retransmits())	    test->sender_has_retransmits = 1;	cJSON_Delete(j);    }    return r;}",16984
472,1619,CVE-2015-5156,26,"static void skb_xmit_done(struct virtqueue *vq){	struct virtnet_info *vi = vq->vdev->priv;	 	virtqueue_disable_cb(vq);	 	netif_wake_subqueue(vi->dev, vq2txq(vq));}",13476
346,2003,CVE-2016-4998,26,"void ipt_unregister_table(struct net *net, struct xt_table *table,			  const struct nf_hook_ops *ops){	nf_unregister_net_hooks(net, ops, hweight32(table->valid_hooks));	__ipt_unregister_table(net, table);}",16569
562,391,CVE-2016-2857,26,"int net_checksum_add_cont(int len, int *buf, int seq){    int sum = 0;    int i;    for (i = seq; i < seq + len; i++) {        if (i & 1) {            sum += (int)buf[i - seq];        } else {            sum += (int)buf[i - seq] << 8;        }    }    return sum;}",2070
127,3677,CVE-2012-6712,26,"void iwl_sta_modify_sleep_tx_count(struct iwl_priv *priv, int sta_id, int cnt){	unsigned long flags;	spin_lock_irqsave(&priv->shrd->sta_lock, flags);	priv->stations[sta_id].sta.station_flags |= STA_FLG_PWR_SAVE_MSK;	priv->stations[sta_id].sta.station_flags_msk = STA_FLG_PWR_SAVE_MSK;	priv->stations[sta_id].sta.sta.modify_mask =					STA_MODIFY_SLEEP_TX_COUNT_MSK;	priv->stations[sta_id].sta.sleep_tx_count = cpu_to_le16(cnt);	priv->stations[sta_id].sta.mode = STA_CONTROL_MODIFY_MSK;	iwl_send_add_sta(priv, &priv->stations[sta_id].sta, CMD_ASYNC);	spin_unlock_irqrestore(&priv->shrd->sta_lock, flags);}",28163
684,2461,CVE-2016-2315,26,"static void add_rev_cmdline_list(struct rev_info *revs,				 struct commit_list *commit_list,				 int whence,				 unsigned flags){	while (commit_list) {		struct object *object = &commit_list->item->object;		add_rev_cmdline(revs, object, sha1_to_hex(object->sha1),				whence, flags);		commit_list = commit_list->next;	}}",17881
186,707,CVE-2011-1477,26,"static int opl3_alloc_voice(int dev, int chn, int note, struct voice_alloc_info *alloc){	int i, p, best, first, avail, best_time = 0x7fffffff;	struct sbi_instrument *instr;	int is4op;	int instr_no;	if (chn < 0 || chn > 15)		instr_no = 0;	else		instr_no = devc->chn_info[chn].pgm_num;	instr = &devc->i_map[instr_no];	if (instr->channel < 0 ||	 		devc->nr_voice != 12)	 		is4op = 0;	else if (devc->nr_voice == 12)	 		is4op = (instr->key == OPL3_PATCH);	else		is4op = 0;	if (is4op)	{		first = p = 0;		avail = 6;	}	else	{		if (devc->nr_voice == 12)	 			first = p = 6;		else			first = p = 0;		avail = devc->nr_voice;	}	 	best = first;	for (i = 0; i < avail; i++)	{		if (alloc->map[p] == 0)		{			return p;		}		if (alloc->alloc_times[p] < best_time)		 		{			best_time = alloc->alloc_times[p];			best = p;		}		p = (p + 1) % avail;	}	 	if (best < 0)		best = 0;	if (best > devc->nr_voice)		best -= devc->nr_voice;	return best;	 }",6854
62,2234,CVE-2016-2324,26,"static int has_sha1_pack_kept_or_nonlocal(const unsigned char *sha1){	static struct packed_git *last_found = (void *)1;	struct packed_git *p;	p = (last_found != (void *)1) ? last_found : packed_git;	while (p) {		if ((!p->pack_local || p->pack_keep) &&			find_pack_entry_one(sha1, p)) {			last_found = p;			return 1;		}		if (p == last_found)			p = packed_git;		else			p = p->next;		if (p == last_found)			p = p->next;	}	return 0;}",17654
49,1848,CVE-2016-8633,26,"static int fwnet_pd_update(struct fwnet_peer *peer,		struct fwnet_partial_datagram *pd, void *frag_buf,		unsigned frag_off, unsigned frag_len){	if (fwnet_frag_new(pd, frag_off, frag_len) == NULL)		return false;	memcpy(pd->pbuf + frag_off, frag_buf, frag_len);	 	list_move_tail(&pd->pd_link, &peer->pd_list);	return true;}",15582
742,308,CVE-2017-5994,26,"vrend_surface_reference(struct vrend_surface **ptr, struct vrend_surface *surf){   struct vrend_surface *old_surf = *ptr;   if (pipe_reference(&(*ptr)->reference, &surf->reference))      vrend_destroy_surface(old_surf);   *ptr = surf;}",1606
320,2488,CVE-2016-1583,26,static void __hrtick_start(void *arg){	struct rq *rq = arg;	raw_spin_lock(&rq->lock);	__hrtick_restart(rq);	rq->hrtick_csd_pending = 0;	raw_spin_unlock(&rq->lock);},18037
18,411,CVE-2016-1907,26,ssh_packet_is_interactive(struct ssh *ssh){	return ssh->state->interactive_mode;},2135
195,3268,CVE-2018-12326,26,"static void latencyModePrint(long long min, long long max, double avg, long long count) {    if (config.output == OUTPUT_STANDARD) {        printf(""min: %lld, max: %lld, avg: %.2f (%lld samples)"",                min, max, avg, count);        fflush(stdout);    } else if (config.output == OUTPUT_CSV) {        printf(""%lld,%lld,%.2f,%lld\n"", min, max, avg, count);    } else if (config.output == OUTPUT_RAW) {        printf(""%lld %lld %.2f %lld\n"", min, max, avg, count);    }}",25095
660,652,CVE-2011-2517,26,"static int get_vlan(struct genl_info *info,		    struct cfg80211_registered_device *rdev,		    struct net_device **vlan){	struct nlattr *vlanattr = info->attrs[NL80211_ATTR_STA_VLAN];	*vlan = NULL;	if (vlanattr) {		*vlan = dev_get_by_index(genl_info_net(info),					 nla_get_u32(vlanattr));		if (!*vlan)			return -ENODEV;		if (!(*vlan)->ieee80211_ptr)			return -EINVAL;		if ((*vlan)->ieee80211_ptr->wiphy != &rdev->wiphy)			return -EINVAL;		if (!netif_running(*vlan))			return -ENETDOWN;	}	return 0;}",6551
282,2722,CVE-2017-14727,26,"logger_get_level_for_buffer (struct t_gui_buffer *buffer){    const char *no_log;    char *name, *option_name, *ptr_end;    struct t_config_option *ptr_option;         no_log = weechat_buffer_get_string (buffer, ""localvar_no_log"");    if (no_log && no_log[0])        return 0;    name = logger_build_option_name (buffer);    if (!name)        return LOGGER_LEVEL_DEFAULT;    option_name = strdup (name);    if (option_name)    {        ptr_end = option_name + strlen (option_name);        while (ptr_end >= option_name)        {            ptr_option = logger_config_get_level (option_name);            if (ptr_option)            {                free (option_name);                free (name);                return weechat_config_integer (ptr_option);            }            ptr_end--;            while ((ptr_end >= option_name) && (ptr_end[0] != '.'))            {                ptr_end--;            }            if ((ptr_end >= option_name) && (ptr_end[0] == '.'))                ptr_end[0] = '\0';        }        ptr_option = logger_config_get_level (option_name);        free (option_name);        free (name);        if (ptr_option)            return weechat_config_integer (ptr_option);    }    else        free (name);         return LOGGER_LEVEL_DEFAULT;}",20124
767,1668,CVE-2015-4036,26,"static void vhost_scsi_hotunplug(struct vhost_scsi_tpg *tpg, struct se_lun *lun){	vhost_scsi_do_plug(tpg, lun, false);}",13534
665,2344,CVE-2016-2324,26,"int handle_revision_arg(const char *arg_, struct rev_info *revs, int flags, unsigned revarg_opt){	struct object_context oc;	char *dotdot;	struct object *object;	unsigned char sha1[20];	int local_flags;	const char *arg = arg_;	int cant_be_filename = revarg_opt & REVARG_CANNOT_BE_FILENAME;	unsigned get_sha1_flags = 0;	flags = flags & UNINTERESTING ? flags | BOTTOM : flags & ~BOTTOM;	dotdot = strstr(arg, "".."");	if (dotdot) {		unsigned char from_sha1[20];		const char *next = dotdot + 2;		const char *this = arg;		int symmetric = *next == '.';		unsigned int flags_exclude = flags ^ (UNINTERESTING | BOTTOM);		static const char head_by_default[] = ""HEAD"";		unsigned int a_flags;		*dotdot = 0;		next += symmetric;		if (!*next)			next = head_by_default;		if (dotdot == arg)			this = head_by_default;		if (this == head_by_default && next == head_by_default &&		    !symmetric) {			 			if (!cant_be_filename) {				*dotdot = '.';				return -1;			}		}		if (!get_sha1_committish(this, from_sha1) &&		    !get_sha1_committish(next, sha1)) {			struct object *a_obj, *b_obj;			if (!cant_be_filename) {				*dotdot = '.';				verify_non_filename(revs->prefix, arg);			}			a_obj = parse_object(from_sha1);			b_obj = parse_object(sha1);			if (!a_obj || !b_obj) {			missing:				if (revs->ignore_missing)					return 0;				die(symmetric				    ? ""Invalid symmetric difference expression %s""				    : ""Invalid revision range %s"", arg);			}			if (!symmetric) {				 				a_flags = flags_exclude;			} else {				 				struct commit *a, *b;				struct commit_list *exclude;				a = (a_obj->type == OBJ_COMMIT				     ? (struct commit *)a_obj				     : lookup_commit_reference(a_obj->oid.hash));				b = (b_obj->type == OBJ_COMMIT				     ? (struct commit *)b_obj				     : lookup_commit_reference(b_obj->oid.hash));				if (!a || !b)					goto missing;				exclude = get_merge_bases(a, b);				add_rev_cmdline_list(revs, exclude,						     REV_CMD_MERGE_BASE,						     flags_exclude);				add_pending_commit_list(revs, exclude,							flags_exclude);				free_commit_list(exclude);				a_flags = flags | SYMMETRIC_LEFT;			}			a_obj->flags |= a_flags;			b_obj->flags |= flags;			add_rev_cmdline(revs, a_obj, this,					REV_CMD_LEFT, a_flags);			add_rev_cmdline(revs, b_obj, next,					REV_CMD_RIGHT, flags);			add_pending_object(revs, a_obj, this);			add_pending_object(revs, b_obj, next);			return 0;		}		*dotdot = '.';	}	dotdot = strstr(arg, ""^@"");	if (dotdot && !dotdot[2]) {		*dotdot = 0;		if (add_parents_only(revs, arg, flags))			return 0;		*dotdot = '^';	}	dotdot = strstr(arg, ""^!"");	if (dotdot && !dotdot[2]) {		*dotdot = 0;		if (!add_parents_only(revs, arg, flags ^ (UNINTERESTING | BOTTOM)))			*dotdot = '^';	}	local_flags = 0;	if (*arg == '^') {		local_flags = UNINTERESTING | BOTTOM;		arg++;	}	if (revarg_opt & REVARG_COMMITTISH)		get_sha1_flags = GET_SHA1_COMMITTISH;	if (get_sha1_with_context(arg, get_sha1_flags, sha1, &oc))		return revs->ignore_missing ? 0 : -1;	if (!cant_be_filename)		verify_non_filename(revs->prefix, arg);	object = get_reference(revs, arg, sha1, flags ^ local_flags);	add_rev_cmdline(revs, object, arg_, REV_CMD_REV, flags ^ local_flags);	add_pending_object_with_mode(revs, object, arg, oc.mode);	return 0;}",17764
92,435,CVE-2018-20815,26,"int qemu_fdt_add_subnode(void *fdt, const char *name){    char *dupname = g_strdup(name);    char *basename = strrchr(dupname, '/');    int retval;    int parent = 0;    if (!basename) {        g_free(dupname);        return -1;    }    basename[0] = '\0';    basename++;    if (dupname[0]) {        parent = findnode_nofail(fdt, dupname);    }    retval = fdt_add_subnode(fdt, parent, basename);    if (retval < 0) {        error_report(""FDT: Failed to create subnode %s: %s"", name,                     fdt_strerror(retval));        exit(1);    }    g_free(dupname);    return retval;}",2160
164,3897,CVE-2016-5199,26,"  void CheckMaybeActivateDataReductionProxy(int initially_enabled,                                            int request_succeeded,                                            int expected_enabled,                                            int expected_restricted,                                            int expected_fallback_restricted) {    test_context_->SetDataReductionProxyEnabled(initially_enabled);    test_context_->config()->UpdateConfigForTesting(initially_enabled,                                                    request_succeeded, true);    ExpectSetProxyPrefs(expected_enabled, false);     settings_->MaybeActivateDataReductionProxy(false);     test_context_->RunUntilIdle();   }",29955
196,3134,CVE-2016-7480,26,"SPL_METHOD(MultipleIterator, setFlags){	spl_SplObjectStorage *intern;	intern = Z_SPLOBJSTORAGE_P(getThis());	if (zend_parse_parameters(ZEND_NUM_ARGS(), ""l"", &intern->flags) == FAILURE) {		return;	}}",22801
640,1191,CVE-2013-2220,26,"rad_put_vendor_addr(struct rad_handle *h, int vendor, int type,    struct in_addr addr){	return (rad_put_vendor_attr(h, vendor, type, &addr.s_addr,	    sizeof addr.s_addr));}",8781
230,1495,CVE-2014-3184,26,"static int pl_input_mapping(struct hid_device *hdev, struct hid_input *hi,		struct hid_field *field, struct hid_usage *usage,		unsigned long **bit, int *max){	if ((usage->hid & HID_USAGE_PAGE) == HID_UP_LOGIVENDOR) {		switch (usage->hid & HID_USAGE) {		case 0x05a: pl_map_key_clear(KEY_TEXT);		break;		case 0x05b: pl_map_key_clear(KEY_RED);		break;		case 0x05c: pl_map_key_clear(KEY_GREEN);	break;		case 0x05d: pl_map_key_clear(KEY_YELLOW);	break;		case 0x05e: pl_map_key_clear(KEY_BLUE);		break;		default:			return 0;		}		return 1;	}	if ((usage->hid & HID_USAGE_PAGE) == HID_UP_CONSUMER) {		switch (usage->hid & HID_USAGE) {		case 0x0f6: pl_map_key_clear(KEY_NEXT);		break;		case 0x0fa: pl_map_key_clear(KEY_BACK);		break;		default:			return 0;		}		return 1;	}	return 0;}",11490
1000,2448,CVE-2016-2315,26,"static int tecmp1 (const void *_a, const void *_b){	struct tree_entry *a = *((struct tree_entry**)_a);	struct tree_entry *b = *((struct tree_entry**)_b);	return base_name_compare(		a->name->str_dat, a->name->str_len, a->versions[1].mode,		b->name->str_dat, b->name->str_len, b->versions[1].mode);}",17868
438,939,CVE-2013-4591,26,"static int nfs41_lock_expired(struct nfs4_state *state, struct file_lock *request){	int status = NFS_OK;	if (test_bit(LK_STATE_IN_USE, &state->flags))		status = nfs41_check_expired_locks(state);	if (status != NFS_OK)		status = nfs4_lock_expired(state, request);	return status;}",7536
64,374,CVE-2016-4539,26,inline static char xml_decode_iso_8859_1(unsigned short c){	return (char)(c > 0xff ? '?' : c);},1884
574,3971,CVE-2016-1503,26,"get_option_addr(struct in_addr *a, const struct dhcp_message *dhcp, int option){ const int *p = get_option_raw(dhcp, option); if (!p) return -1;	memcpy(&a->s_addr, p, sizeof(a->s_addr)); return 0;}",30679
40,977,CVE-2013-4591,26,"int nfs4_proc_create_session(struct nfs_client *clp, struct rpc_cred *cred){	int status;	unsigned *ptr;	struct nfs4_session *session = clp->cl_session;	dprintk(""--> %s clp=%p session=%p\n"", __func__, clp, session);	status = _nfs4_proc_create_session(clp, cred);	if (status)		goto out;	 	status = nfs4_setup_session_slot_tables(session);	dprintk(""slot table setup returned %d\n"", status);	if (status)		goto out;	ptr = (unsigned *)&session->sess_id.data[0];	dprintk(""%s client>seqid %d sessionid %u:%u:%u:%u\n"", __func__,		clp->cl_seqid, ptr[0], ptr[1], ptr[2], ptr[3]);out:	dprintk(""<-- %s\n"", __func__);	return status;}",7574
309,2881,CVE-2017-8065,26,static int cbcmac_init_tfm(struct crypto_tfm *tfm){	struct crypto_cipher *cipher;	struct crypto_instance *inst = (void *)tfm->__crt_alg;	struct crypto_spawn *spawn = crypto_instance_ctx(inst);	struct cbcmac_tfm_ctx *ctx = crypto_tfm_ctx(tfm);	cipher = crypto_spawn_cipher(spawn);	if (IS_ERR(cipher))		return PTR_ERR(cipher);	ctx->child = cipher;	return 0;};,21358
311,2614,CVE-2015-8863,26,int jv_parser_remaining(struct jv_parser* p) {  if (p->curr_buf == 0)    return 0;  return (p->curr_buf_length - p->curr_buf_pos);},18467
197,3459,CVE-2019-1010305,26,"static struct mschmd_header *chmd_real_open(struct mschm_decompressor *base,                                            const char *filename, int entire){  struct mschm_decompressor_p *self = (struct mschm_decompressor_p *) base;  struct mschmd_header *chm = NULL;  struct mspack_system *sys;  struct mspack_file *fh;  int error;  if (!base) return NULL;  sys = self->system;  if ((fh = sys->open(sys, filename, MSPACK_SYS_OPEN_READ))) {    if ((chm = (struct mschmd_header *) sys->alloc(sys, sizeof(struct mschmd_header)))) {      chm->filename = filename;      error = chmd_read_headers(sys, fh, chm, entire);      if (error) {                 if (error == MSPACK_ERR_DATAFORMAT && (chm->files || chm->sysfiles)) {          sys->message(fh, ""WARNING; contents are corrupt"");          error = MSPACK_ERR_OK;        }        else {          chmd_close(base, chm);          chm = NULL;        }      }      self->error = error;    }    else {      self->error = MSPACK_ERR_NOMEMORY;    }    sys->close(fh);  }  else {    self->error = MSPACK_ERR_OPEN;  }  return chm;}",26361
56,1081,CVE-2013-4244,26,"processCompressOptions(char* opt){	if (streq(opt, ""none""))		compression = COMPRESSION_NONE;	else if (streq(opt, ""packbits""))		compression = COMPRESSION_PACKBITS;	else if (strneq(opt, ""lzw"", 3)) {		char* cp = strchr(opt, ':');		if (cp)			predictor = atoi(cp+1);		compression = COMPRESSION_LZW;	} else if (strneq(opt, ""zip"", 3)) {		char* cp = strchr(opt, ':');		if (cp)			predictor = atoi(cp+1);		compression = COMPRESSION_DEFLATE;	} else		return (0);	return (1);}",7934
883,3922,CVE-2016-1683,26,xsltSetXIncludeDefault(int xinclude) {    xsltDoXIncludeDefault = (xinclude != 0);},30356
784,996,CVE-2013-4591,26,"static void nfs4_proc_write_rpc_prepare(struct rpc_task *task, struct nfs_write_data *data){	if (nfs4_setup_sequence(NFS_SERVER(data->header->inode),				&data->args.seq_args,				&data->res.seq_res,				task))		return;	rpc_call_start(task);}",7593
594,3318,CVE-2018-1091,26,static unsigned long get_user_ckpt_msr(struct task_struct *task){	return task->thread.ckpt_regs.msr | task->thread.fpexc_mode;},25534
451,239,CVE-2018-10184,26,"static inline void h2_release_buf(struct h2c *h2c, struct buffer **bptr){	if ((*bptr)->size) {		b_free(bptr);		offer_buffers(h2c->buf_wait.target,			      tasks_run_queue + applets_active_queue);	}}",1260
887,3361,CVE-2017-18222,26,"int hns_ppe_common_get_cfg(struct dsaf_device *dsaf_dev, int comm_index){	struct ppe_common_cb *ppe_common;	int ppe_num;	if (!HNS_DSAF_IS_DEBUG(dsaf_dev))		ppe_num = HNS_PPE_SERVICE_NW_ENGINE_NUM;	else		ppe_num = HNS_PPE_DEBUG_NW_ENGINE_NUM;	ppe_common = devm_kzalloc(dsaf_dev->dev, sizeof(*ppe_common) +		ppe_num * sizeof(struct hns_ppe_cb), GFP_KERNEL);	if (!ppe_common)		return -ENOMEM;	ppe_common->ppe_num = ppe_num;	ppe_common->dsaf_dev = dsaf_dev;	ppe_common->comm_index = comm_index;	if (!HNS_DSAF_IS_DEBUG(dsaf_dev))		ppe_common->ppe_mode = PPE_COMMON_MODE_SERVICE;	else		ppe_common->ppe_mode = PPE_COMMON_MODE_DEBUG;	ppe_common->dev = dsaf_dev->dev;	ppe_common->io_base = hns_ppe_common_get_ioaddr(ppe_common);	dsaf_dev->ppe_common[comm_index] = ppe_common;	return 0;}",25802
913,1420,CVE-2011-4098,26,"static inline void bmap_lock(struct gfs2_inode *ip, int create){	if (create)		down_write(&ip->i_rw_mutex);	else		down_read(&ip->i_rw_mutex);}",10055
176,3441,CVE-2017-15128,26,static inline struct hugepage_subpool *subpool_vma(struct vm_area_struct *vma){	return subpool_inode(file_inode(vma->vm_file));},26201
114,45,CVE-2019-15938,26,"static int nfs_iterate(struct file *file, struct dir_context *ctx){	struct dentry *dentry = file->f_path.dentry;	struct inode *dir = d_inode(dentry);	struct nfs_priv *npriv = nfsi(dir)->npriv;	void *buf = NULL;	struct nfs_dir *ndir;	struct xdr_stream *xdr;	int ret;	int *p, len;	ndir = xzalloc(sizeof(*ndir));	ndir->fh = nfsi(dir)->fh;	while (1) {		 		buf = nfs_readdirattr_req(npriv, ndir);		if (!buf) {			pr_err(""%s: nfs_readdirattr_req failed\n"", __func__);			ret = -EINVAL;			goto out;		}		xdr = &ndir->stream;		while (1) {			char name[256];			p = xdr_inline_decode(xdr, 4);			if (!p)				goto err_eop;			if (!net_read_uint32(p)) {				 				p = xdr_inline_decode(xdr, 4);				if (!p)					goto err_eop;				if (net_read_uint32(p)) {					ret = 0;					goto out;				}				break;			}			 			p = xdr_inline_decode(xdr, 8);			if (!p)				goto err_eop;			ret = decode_filename(xdr, name, &len);			if (ret)				goto out;			dir_emit(ctx, name, len, 0, DT_UNKNOWN);			p = xdr_inline_decode(xdr, 8);			if (!p)				goto err_eop;			ndir->cookie = ntoh64(net_read_uint64(p));		}		free(buf);	}	ret = 0;out:	free(ndir->stream.buf);	free(ndir);	return ret;err_eop:	pr_err(""Unexpected end of packet\n"");	return -EIO;}",276
630,2472,CVE-2016-2315,26,"static void simplify_merges(struct rev_info *revs){	struct commit_list *list, *next;	struct commit_list *yet_to_do, **tail;	struct commit *commit;	if (!revs->prune)		return;	 	yet_to_do = NULL;	for (list = revs->commits; list; list = next) {		commit = list->item;		next = list->next;		 		commit_list_insert(commit, &yet_to_do);	}	while (yet_to_do) {		list = yet_to_do;		yet_to_do = NULL;		tail = &yet_to_do;		while (list) {			commit = list->item;			next = list->next;			free(list);			list = next;			tail = simplify_one(revs, commit, tail);		}	}	 	list = revs->commits;	revs->commits = NULL;	tail = &revs->commits;	while (list) {		struct merge_simplify_state *st;		commit = list->item;		next = list->next;		free(list);		list = next;		st = locate_simplify_state(revs, commit);		if (st->simplified == commit)			tail = &commit_list_insert(commit, tail)->next;	}}",17892
107,3982,CVE-2017-0809,26,static char encode6Bit(unsigned x) { if (x <= 25) { return 'A' + x; } else if (x <= 51) { return 'a' + x - 26; } else if (x <= 61) { return '0' + x - 52; } else if (x == 62) { return '+'; } else { return '/'; }},30779
734,957,CVE-2013-4591,26,"nfs4_layoutcommit_done(struct rpc_task *task, void *calldata){	struct nfs4_layoutcommit_data *data = calldata;	struct nfs_server *server = NFS_SERVER(data->args.inode);	if (!nfs4_sequence_done(task, &data->res.seq_res))		return;	switch (task->tk_status) {  	case -NFS4ERR_DELEG_REVOKED:  	case -NFS4ERR_BADIOMODE:      	case -NFS4ERR_BADLAYOUT:      	case -NFS4ERR_GRACE:	     		task->tk_status = 0;		break;	case 0:		nfs_post_op_update_inode_force_wcc(data->args.inode,						   data->res.fattr);		break;	default:		if (nfs4_async_handle_error(task, server, NULL) == -EAGAIN) {			rpc_restart_call_prepare(task);			return;		}	}}",7554
170,1065,CVE-2013-4387,26,"int ip6_push_pending_frames(struct sock *sk){	struct sk_buff *skb, *tmp_skb;	struct sk_buff **tail_skb;	struct in6_addr final_dst_buf, *final_dst = &final_dst_buf;	struct inet_sock *inet = inet_sk(sk);	struct ipv6_pinfo *np = inet6_sk(sk);	struct net *net = sock_net(sk);	struct ipv6hdr *hdr;	struct ipv6_txoptions *opt = np->cork.opt;	struct rt6_info *rt = (struct rt6_info *)inet->cork.base.dst;	struct flowi6 *fl6 = &inet->cork.fl.u.ip6;	unsigned char proto = fl6->flowi6_proto;	int err = 0;	if ((skb = __skb_dequeue(&sk->sk_write_queue)) == NULL)		goto out;	tail_skb = &(skb_shinfo(skb)->frag_list);	 	if (skb->data < skb_network_header(skb))		__skb_pull(skb, skb_network_offset(skb));	while ((tmp_skb = __skb_dequeue(&sk->sk_write_queue)) != NULL) {		__skb_pull(tmp_skb, skb_network_header_len(skb));		*tail_skb = tmp_skb;		tail_skb = &(tmp_skb->next);		skb->len += tmp_skb->len;		skb->data_len += tmp_skb->len;		skb->truesize += tmp_skb->truesize;		tmp_skb->destructor = NULL;		tmp_skb->sk = NULL;	}	 	if (np->pmtudisc < IPV6_PMTUDISC_DO)		skb->local_df = 1;	*final_dst = fl6->daddr;	__skb_pull(skb, skb_network_header_len(skb));	if (opt && opt->opt_flen)		ipv6_push_frag_opts(skb, opt, &proto);	if (opt && opt->opt_nflen)		ipv6_push_nfrag_opts(skb, opt, &proto, &final_dst);	skb_push(skb, sizeof(struct ipv6hdr));	skb_reset_network_header(skb);	hdr = ipv6_hdr(skb);	ip6_flow_hdr(hdr, np->cork.tclass, fl6->flowlabel);	hdr->hop_limit = np->cork.hop_limit;	hdr->nexthdr = proto;	hdr->saddr = fl6->saddr;	hdr->daddr = *final_dst;	skb->priority = sk->sk_priority;	skb->mark = sk->sk_mark;	skb_dst_set(skb, dst_clone(&rt->dst));	IP6_UPD_PO_STATS(net, rt->rt6i_idev, IPSTATS_MIB_OUT, skb->len);	if (proto == IPPROTO_ICMPV6) {		struct inet6_dev *idev = ip6_dst_idev(skb_dst(skb));		ICMP6MSGOUT_INC_STATS_BH(net, idev, icmp6_hdr(skb)->icmp6_type);		ICMP6_INC_STATS_BH(net, idev, ICMP6_MIB_OUTMSGS);	}	err = ip6_local_out(skb);	if (err) {		if (err > 0)			err = net_xmit_errno(err);		if (err)			goto error;	}out:	ip6_cork_release(inet, np);	return err;error:	IP6_INC_STATS(net, rt->rt6i_idev, IPSTATS_MIB_OUTDISCARDS);	goto out;}",7817
564,764,CVE-2013-6763,26,"static int uio_mmap(struct file *filep, struct vm_area_struct *vma){	struct uio_listener *listener = filep->private_data;	struct uio_device *idev = listener->dev;	int mi;	unsigned long requested_pages, actual_pages;	int ret = 0;	if (vma->vm_end < vma->vm_start)		return -EINVAL;	vma->vm_private_data = idev;	mi = uio_find_mem_index(vma);	if (mi < 0)		return -EINVAL;	requested_pages = vma_pages(vma);	actual_pages = ((idev->info->mem[mi].addr & ~PAGE_MASK)			+ idev->info->mem[mi].size + PAGE_SIZE -1) >> PAGE_SHIFT;	if (requested_pages > actual_pages)		return -EINVAL;	if (idev->info->mmap) {		ret = idev->info->mmap(idev->info, vma);		return ret;	}	switch (idev->info->mem[mi].memtype) {		case UIO_MEM_PHYS:			return uio_mmap_physical(vma);		case UIO_MEM_LOGICAL:		case UIO_MEM_VIRTUAL:			return uio_mmap_logical(vma);		default:			return -EINVAL;	}}",7158
934,3223,CVE-2018-17407,26,"static int t1_getbyte(void){    int c = t1_getchar();    if (t1_pfa)        return c;    if (t1_block_length == 0) {        if (c != 128)            normal_error(""type 1"",""invalid marker"");        c = t1_getchar();        if (c == 3) {            while (!t1_eof())                (void) t1_getchar();            return EOF;        }        t1_block_length = t1_getchar() & 0xff;        t1_block_length |= (t1_getchar() & 0xff) << 8;        t1_block_length |= (t1_getchar() & 0xff) << 16;        t1_block_length |= (t1_getchar() & 0xff) << 24;        c = t1_getchar();    }    t1_block_length--;    return c;}",23657
610,1238,CVE-2013-1929,26,"static void tg3_get_nstats(struct tg3 *tp, struct rtnl_link_stats64 *stats){	struct rtnl_link_stats64 *old_stats = &tp->net_stats_prev;	struct tg3_hw_stats *hw_stats = tp->hw_stats;	stats->rx_packets = old_stats->rx_packets +		get_stat64(&hw_stats->rx_ucast_packets) +		get_stat64(&hw_stats->rx_mcast_packets) +		get_stat64(&hw_stats->rx_bcast_packets);	stats->tx_packets = old_stats->tx_packets +		get_stat64(&hw_stats->tx_ucast_packets) +		get_stat64(&hw_stats->tx_mcast_packets) +		get_stat64(&hw_stats->tx_bcast_packets);	stats->rx_bytes = old_stats->rx_bytes +		get_stat64(&hw_stats->rx_octets);	stats->tx_bytes = old_stats->tx_bytes +		get_stat64(&hw_stats->tx_octets);	stats->rx_errors = old_stats->rx_errors +		get_stat64(&hw_stats->rx_errors);	stats->tx_errors = old_stats->tx_errors +		get_stat64(&hw_stats->tx_errors) +		get_stat64(&hw_stats->tx_mac_errors) +		get_stat64(&hw_stats->tx_carrier_sense_errors) +		get_stat64(&hw_stats->tx_discards);	stats->multicast = old_stats->multicast +		get_stat64(&hw_stats->rx_mcast_packets);	stats->collisions = old_stats->collisions +		get_stat64(&hw_stats->tx_collisions);	stats->rx_length_errors = old_stats->rx_length_errors +		get_stat64(&hw_stats->rx_frame_too_long_errors) +		get_stat64(&hw_stats->rx_undersize_packets);	stats->rx_over_errors = old_stats->rx_over_errors +		get_stat64(&hw_stats->rxbds_empty);	stats->rx_frame_errors = old_stats->rx_frame_errors +		get_stat64(&hw_stats->rx_align_errors);	stats->tx_aborted_errors = old_stats->tx_aborted_errors +		get_stat64(&hw_stats->tx_discards);	stats->tx_carrier_errors = old_stats->tx_carrier_errors +		get_stat64(&hw_stats->tx_carrier_sense_errors);	stats->rx_crc_errors = old_stats->rx_crc_errors +		tg3_calc_crc_errors(tp);	stats->rx_missed_errors = old_stats->rx_missed_errors +		get_stat64(&hw_stats->rx_discards);	stats->rx_dropped = tp->rx_dropped;	stats->tx_dropped = tp->tx_dropped;}",9244
755,2239,CVE-2016-2324,26,"static void loosen_unused_packed_objects(struct rev_info *revs){	struct packed_git *p;	int i;	const unsigned char *sha1;	for (p = packed_git; p; p = p->next) {		if (!p->pack_local || p->pack_keep)			continue;		if (open_pack_index(p))			die(""cannot open pack index"");		for (i = 0; i < p->num_objects; i++) {			sha1 = nth_packed_object_sha1(p, i);			if (!packlist_find(&to_pack, sha1, NULL) &&			    !has_sha1_pack_kept_or_nonlocal(sha1) &&			    !loosened_object_can_be_discarded(sha1, p->mtime))				if (force_object_loose(sha1, p->mtime))					die(""unable to force loose object"");		}	}}",17659
149,4043,CVE-2016-4539,26," PHP_FUNCTION(xml_parser_create) {       php_xml_parser_create_impl(INTERNAL_FUNCTION_PARAM_PASSTHRU, 0);         }",30906
209,3637,CVE-2017-18379,26,"nvmet_fc_tgt_a_put(struct nvmet_fc_tgt_assoc *assoc){	kref_put(&assoc->ref, nvmet_fc_target_assoc_free);}",28093
297,1215,CVE-2013-1929,26,"static inline void _tg3_flag_clear(enum TG3_FLAGS flag, unsigned long *bits){	clear_bit(flag, bits);}",9221
278,3372,CVE-2017-18222,26,static int hns_rcb_get_base_irq_idx(struct rcb_common_cb *rcb_common){	int is_ver1 = AE_IS_VER1(rcb_common->dsaf_dev->dsaf_ver);	if (!HNS_DSAF_IS_DEBUG(rcb_common->dsaf_dev))		return SERVICE_RING_IRQ_IDX(is_ver1);	else		return  HNS_DEBUG_RING_IRQ_IDX;},25813
307,1053,CVE-2013-4513,26,"int oz_cdev_init(void){	oz_app_enable(OZ_APPID_SERIAL, 1);	return 0;}",7754
812,715,CVE-2011-1477,26,"static int opl3_set_instr  (int dev, int voice, int instr_no){	if (voice < 0 || voice >= devc->nr_voice)		return 0;	if (instr_no < 0 || instr_no >= SBFM_MAXINSTR)		instr_no = 0;	 	devc->act_i[voice] = &devc->i_map[instr_no];	return 0;}",6862
173,1403,CVE-2012-2119,26,"static int macvtap_forward(struct net_device *dev, struct sk_buff *skb){	struct macvtap_queue *q = macvtap_get_queue(dev, skb);	if (!q)		goto drop;	if (skb_queue_len(&q->sk.sk_receive_queue) >= dev->tx_queue_len)		goto drop;	skb_queue_tail(&q->sk.sk_receive_queue, skb);	wake_up_interruptible_poll(sk_sleep(&q->sk), POLLIN | POLLRDNORM | POLLRDBAND);	return NET_RX_SUCCESS;drop:	kfree_skb(skb);	return NET_RX_DROP;}",10009
730,810,CVE-2013-6381,26,"static int qeth_cm_setup_cb(struct qeth_card *card, struct qeth_reply *reply,		unsigned long data){	struct qeth_cmd_buffer *iob;	QETH_DBF_TEXT(SETUP, 2, ""cmsetpcb"");	iob = (struct qeth_cmd_buffer *) data;	memcpy(&card->token.cm_connection_r,	       QETH_CM_SETUP_RESP_DEST_ADDR(iob->data),	       QETH_MPC_TOKEN_LENGTH);	QETH_DBF_TEXT_(SETUP, 2, ""  rc%d"", iob->rc);	return 0;}",7239
531,3284,CVE-2018-11595,26,int jslMatch(int expected_tk) {  if (lex->tk != expected_tk) {    jslMatchError(expected_tk);    return false;  }  jslGetNextToken();  return true;},25131
682,2477,CVE-2016-1583,26,static void proc_kill_sb(struct super_block *sb){	struct pid_namespace *ns;	ns = (struct pid_namespace *)sb->s_fs_info;	if (ns->proc_self)		dput(ns->proc_self);	if (ns->proc_thread_self)		dput(ns->proc_thread_self);	kill_anon_super(sb);	put_pid_ns(ns);},18026
286,150,CVE-2017-13090,26,url_uses_proxy (struct url * u){  int ret;  char *proxy;  if (!u)    return false;  proxy = getproxy (u);  ret = proxy != NULL;  xfree (proxy);  return ret;},604
243,1899,CVE-2016-7115,26,"static void abort_connection(struct mt_connection *curconn, struct mt_mactelnet_hdr *pkthdr, char *message) {	struct mt_packet pdata;	init_packet(&pdata, MT_PTYPE_DATA, pkthdr->dstaddr, pkthdr->srcaddr, pkthdr->seskey, curconn->outcounter);	add_control_packet(&pdata, MT_CPTYPE_PLAINDATA, message, strlen(message));	send_udp(curconn, &pdata);	 	curconn->state = STATE_CLOSED;	init_packet(&pdata, MT_PTYPE_END, pkthdr->dstaddr, pkthdr->srcaddr, pkthdr->seskey, curconn->outcounter);	send_udp(curconn, &pdata);}",15875
388,1468,CVE-2014-3186,26,"static int picolcd_init_keys(struct picolcd_data *data,		struct hid_report *report){	struct hid_device *hdev = data->hdev;	struct input_dev *idev;	int error, i;	if (!report)		return -ENODEV;	if (report->maxfield != 1 || report->field[0]->report_count != 2 ||			report->field[0]->report_size != 8) {		hid_err(hdev, ""unsupported KEY_STATE report\n"");		return -EINVAL;	}	idev = input_allocate_device();	if (idev == NULL) {		hid_err(hdev, ""failed to allocate input device\n"");		return -ENOMEM;	}	input_set_drvdata(idev, hdev);	memcpy(data->keycode, def_keymap, sizeof(def_keymap));	idev->name = hdev->name;	idev->phys = hdev->phys;	idev->uniq = hdev->uniq;	idev->id.bustype = hdev->bus;	idev->id.vendor  = hdev->vendor;	idev->id.product = hdev->product;	idev->id.version = hdev->version;	idev->dev.parent = &hdev->dev;	idev->keycode     = &data->keycode;	idev->keycodemax  = PICOLCD_KEYS;	idev->keycodesize = sizeof(data->keycode[0]);	input_set_capability(idev, EV_MSC, MSC_SCAN);	set_bit(EV_REP, idev->evbit);	for (i = 0; i < PICOLCD_KEYS; i++)		input_set_capability(idev, EV_KEY, data->keycode[i]);	error = input_register_device(idev);	if (error) {		hid_err(hdev, ""error registering the input device\n"");		input_free_device(idev);		return error;	}	data->input_keys = idev;	return 0;}",11463
192,3783,CVE-2013-0904,26,    void advance()    {        ASSERT(hasMore());        m_colIndex--;        update();    },29443
94,856,CVE-2013-6381,26,static inline int qeth_get_qdio_q_format(struct qeth_card *card){	switch (card->info.type) {	case QETH_CARD_TYPE_IQD:		return 2;	default:		return 0;	}},7285
803,3034,CVE-2016-10196,26,"evutil_addrinfo_append_(struct evutil_addrinfo *first,    struct evutil_addrinfo *append){	struct evutil_addrinfo *ai = first;	if (!ai)		return append;	while (ai->ai_next)		ai = ai->ai_next;	ai->ai_next = append;	return first;}",22432
536,3021,CVE-2017-5522,26,"int FLTIsComparisonFilterType(const char *pszValue){  if (pszValue) {    if (FLTIsBinaryComparisonFilterType(pszValue) ||        strcasecmp(pszValue, ""PropertyIsLike"") == 0 ||        strcasecmp(pszValue, ""PropertyIsBetween"") == 0 ||        strcasecmp(pszValue, ""PropertyIsNull"") == 0 ||        strcasecmp(pszValue, ""PropertyIsNil"") == 0)      return MS_TRUE;  }  return MS_FALSE;}",22121
21,756,CVE-2013-6763,26,static void release_uio_class(void){	class_unregister(&uio_class);	uio_major_cleanup();},7150
759,1431,CVE-2011-4098,26,"static int gfs2_mmap(struct file *file, struct vm_area_struct *vma){	struct gfs2_inode *ip = GFS2_I(file->f_mapping->host);	if (!(file->f_flags & O_NOATIME) &&	    !IS_NOATIME(&ip->i_inode)) {		struct gfs2_holder i_gh;		int error;		gfs2_holder_init(ip->i_gl, LM_ST_SHARED, LM_FLAG_ANY, &i_gh);		error = gfs2_glock_nq(&i_gh);		if (error == 0) {			file_accessed(file);			gfs2_glock_dq(&i_gh);		}		gfs2_holder_uninit(&i_gh);		if (error)			return error;	}	vma->vm_ops = &gfs2_vm_ops;	vma->vm_flags |= VM_CAN_NONLINEAR;	return 0;}",10066
985,3364,CVE-2017-18222,26,int hns_ppe_get_regs_count(void){	return ETH_PPE_DUMP_NUM;},25805
523,998,CVE-2013-4591,26,"static int nfs4_read_done_cb(struct rpc_task *task, struct nfs_read_data *data){	struct nfs_server *server = NFS_SERVER(data->header->inode);	if (nfs4_async_handle_error(task, server, data->args.context->state) == -EAGAIN) {		rpc_restart_call_prepare(task);		return -EAGAIN;	}	__nfs4_read_done_cb(data);	if (task->tk_status > 0)		renew_lease(server, data->timestamp);	return 0;}",7595
0,477,CVE-2013-4534,26,static int get_current_cpu(void){    if (!current_cpu) {        return -1;    }    return current_cpu->cpu_index;},2406
182,782,CVE-2013-6381,26,"static long __qeth_check_irb_error(struct ccw_device *cdev,		unsigned long intparm, struct irb *irb){	struct qeth_card *card;	card = CARD_FROM_CDEV(cdev);	if (!IS_ERR(irb))		return 0;	switch (PTR_ERR(irb)) {	case -EIO:		QETH_DBF_MESSAGE(2, ""%s i/o-error on device\n"",			dev_name(&cdev->dev));		QETH_CARD_TEXT(card, 2, ""ckirberr"");		QETH_CARD_TEXT_(card, 2, ""  rc%d"", -EIO);		break;	case -ETIMEDOUT:		dev_warn(&cdev->dev, ""A hardware operation timed out""			"" on the device\n"");		QETH_CARD_TEXT(card, 2, ""ckirberr"");		QETH_CARD_TEXT_(card, 2, ""  rc%d"", -ETIMEDOUT);		if (intparm == QETH_RCD_PARM) {			if (card && (card->data.ccwdev == cdev)) {				card->data.state = CH_STATE_DOWN;				wake_up(&card->wait_q);			}		}		break;	default:		QETH_DBF_MESSAGE(2, ""%s unknown error %ld on device\n"",			dev_name(&cdev->dev), PTR_ERR(irb));		QETH_CARD_TEXT(card, 2, ""ckirberr"");		QETH_CARD_TEXT(card, 2, ""  rc???"");	}	return PTR_ERR(irb);}",7211
349,1232,CVE-2013-1929,26,"static int tg3_get_coalesce(struct net_device *dev, struct ethtool_coalesce *ec){	struct tg3 *tp = netdev_priv(dev);	memcpy(ec, &tp->coal, sizeof(*ec));	return 0;}",9238
254,2057,CVE-2016-4478,26,"int xmlrpc_about(void *userdata, int ac, char **av){	char buf[XMLRPC_BUFSIZE];	char buf2[XMLRPC_BUFSIZE];	char buf3[XMLRPC_BUFSIZE];	char buf4[XMLRPC_BUFSIZE];	char *arraydata;	(void)userdata;	xmlrpc_integer(buf3, ac);	xmlrpc_string(buf4, av[0]);	xmlrpc_string(buf, (char *)XMLLIB_VERSION);	xmlrpc_string(buf2, (char *)XMLLIB_AUTHOR);	arraydata = xmlrpc_array(4, buf, buf2, buf3, buf4);	xmlrpc_send(1, arraydata);	free(arraydata);	return XMLRPC_CONT;}",16956
508,3215,CVE-2018-17407,26,"static void copy_glyph_names(char **glyph_names, int a, int b){    if (glyph_names[b] != notdef) {        xfree(glyph_names[b]);        glyph_names[b] = (char *) notdef;    }    if (glyph_names[a] != notdef) {        glyph_names[b] = xstrdup(glyph_names[a]);    }}",23649
779,2474,CVE-2016-2315,26,"static void try_to_simplify_commit(struct rev_info *revs, struct commit *commit){	struct commit_list **pp, *parent;	struct treesame_state *ts = NULL;	int relevant_change = 0, irrelevant_change = 0;	int relevant_parents, nth_parent;	 	if (!revs->prune)		return;	if (!commit->tree)		return;	if (!commit->parents) {		if (rev_same_tree_as_empty(revs, commit))			commit->object.flags |= TREESAME;		return;	}	 	if (!revs->dense && !commit->parents->next)		return;	for (pp = &commit->parents, nth_parent = 0, relevant_parents = 0;	     (parent = *pp) != NULL;	     pp = &parent->next, nth_parent++) {		struct commit *p = parent->item;		if (relevant_commit(p))			relevant_parents++;		if (nth_parent == 1) {			 			if (revs->first_parent_only)				break;			 			if (revs->treesame.name &&			    !revs->simplify_history &&			    !(commit->object.flags & UNINTERESTING)) {				ts = initialise_treesame(revs, commit);				if (!(irrelevant_change || relevant_change))					ts->treesame[0] = 1;			}		}		if (parse_commit(p) < 0)			die(""cannot simplify commit %s (because of %s)"",			    sha1_to_hex(commit->object.sha1),			    sha1_to_hex(p->object.sha1));		switch (rev_compare_tree(revs, p, commit)) {		case REV_TREE_SAME:			if (!revs->simplify_history || !relevant_commit(p)) {				 				if (ts)					ts->treesame[nth_parent] = 1;				continue;			}			parent->next = NULL;			commit->parents = parent;			commit->object.flags |= TREESAME;			return;		case REV_TREE_NEW:			if (revs->remove_empty_trees &&			    rev_same_tree_as_empty(revs, p)) {				 				if (parse_commit(p) < 0)					die(""cannot simplify commit %s (invalid %s)"",					    sha1_to_hex(commit->object.sha1),					    sha1_to_hex(p->object.sha1));				p->parents = NULL;			}		 		case REV_TREE_OLD:		case REV_TREE_DIFFERENT:			if (relevant_commit(p))				relevant_change = 1;			else				irrelevant_change = 1;			continue;		}		die(""bad tree compare for commit %s"", sha1_to_hex(commit->object.sha1));	}	 	if (relevant_parents ? !relevant_change : !irrelevant_change)		commit->object.flags |= TREESAME;}",17894
460,1007,CVE-2013-4588,26,__ip_vs_unbind_svc(struct ip_vs_dest *dest){	struct ip_vs_service *svc = dest->svc;	dest->svc = NULL;	if (atomic_dec_and_test(&svc->refcnt))		kfree(svc);},7604
97,2661,CVE-2017-17857,26,"static void sanitize_dead_code(struct bpf_verifier_env *env){	struct bpf_insn_aux_data *aux_data = env->insn_aux_data;	struct bpf_insn nop = BPF_MOV64_REG(BPF_REG_0, BPF_REG_0);	struct bpf_insn *insn = env->prog->insnsi;	const int insn_cnt = env->prog->len;	int i;	for (i = 0; i < insn_cnt; i++) {		if (aux_data[i].seen)			continue;		memcpy(insn + i, &nop, sizeof(nop));	}}",19566
184,3660,CVE-2015-9289,26,"static int cx24116_diseqc_init(struct dvb_frontend *fe){	struct cx24116_state *state = fe->demodulator_priv;	struct cx24116_cmd cmd;	int ret;	 	cmd.args[0x00] = CMD_LNBCONFIG;	cmd.args[0x01] = 0x00;	cmd.args[0x02] = 0x10;	cmd.args[0x03] = 0x00;	cmd.args[0x04] = 0x8f;	cmd.args[0x05] = 0x28;	cmd.args[0x06] = (toneburst == CX24116_DISEQC_TONEOFF) ? 0x00 : 0x01;	cmd.args[0x07] = 0x01;	cmd.len = 0x08;	ret = cx24116_cmd_execute(fe, &cmd);	if (ret != 0)		return ret;	 	state->dsec_cmd.args[0x00] = CMD_LNBSEND;	 	state->dsec_cmd.args[CX24116_DISEQC_BURST]  = CX24116_DISEQC_MINI_A;	 	state->dsec_cmd.args[CX24116_DISEQC_ARG2_2] = 0x02;	state->dsec_cmd.args[CX24116_DISEQC_ARG3_0] = 0x00;	 	state->dsec_cmd.args[CX24116_DISEQC_ARG4_0] = 0x00;	 	state->dsec_cmd.args[CX24116_DISEQC_MSGLEN] = 0x00;	 	state->dsec_cmd.len = CX24116_DISEQC_MSGOFS;	return 0;}",28146
435,9,CVE-2015-6806,26,"ClearToEOS(){  register int y = curr->w_y, x = curr->w_x;  if (x == 0 && y == 0)    {      ClearScreen();      RestorePosRendition();      return;    }  LClearArea(&curr->w_layer, x, y, cols - 1, rows - 1, CURR_BCE, 1);  MClearArea(curr, x, y, cols - 1, rows - 1, CURR_BCE);  RestorePosRendition();}",118
386,1767,CVE-2016-9793,26,void release_sock(struct sock *sk){	spin_lock_bh(&sk->sk_lock.slock);	if (sk->sk_backlog.tail)		__release_sock(sk);	 	if (sk->sk_prot->release_cb)		sk->sk_prot->release_cb(sk);	sock_release_ownership(sk);	if (waitqueue_active(&sk->sk_lock.wq))		wake_up(&sk->sk_lock.wq);	spin_unlock_bh(&sk->sk_lock.slock);},15051
368,1542,CVE-2014-0069,26,"int cifs_closedir(struct inode *inode, struct file *file){	int rc = 0;	unsigned int xid;	struct cifsFileInfo *cfile = file->private_data;	struct cifs_tcon *tcon;	struct TCP_Server_Info *server;	char *buf;	cifs_dbg(FYI, ""Closedir inode = 0x%p\n"", inode);	if (cfile == NULL)		return rc;	xid = get_xid();	tcon = tlink_tcon(cfile->tlink);	server = tcon->ses->server;	cifs_dbg(FYI, ""Freeing private data in close dir\n"");	spin_lock(&cifs_file_list_lock);	if (!cfile->srch_inf.endOfSearch && !cfile->invalidHandle) {		cfile->invalidHandle = true;		spin_unlock(&cifs_file_list_lock);		if (server->ops->close_dir)			rc = server->ops->close_dir(xid, tcon, &cfile->fid);		else			rc = -ENOSYS;		cifs_dbg(FYI, ""Closing uncompleted readdir with rc %d\n"", rc);		 		rc = 0;	} else		spin_unlock(&cifs_file_list_lock);	buf = cfile->srch_inf.ntwrk_buf_start;	if (buf) {		cifs_dbg(FYI, ""closedir free smb buf in srch struct\n"");		cfile->srch_inf.ntwrk_buf_start = NULL;		if (cfile->srch_inf.smallBuf)			cifs_small_buf_release(buf);		else			cifs_buf_release(buf);	}	cifs_put_tlink(cfile->tlink);	kfree(file->private_data);	file->private_data = NULL;	 	free_xid(xid);	return rc;}",12288
362,1900,CVE-2016-7115,26,"static void display_motd() {	FILE *fp;	int c;	if ((fp = fopen(""/etc/motd"", ""r""))) {		while ((c = getc(fp)) != EOF) {			putchar(c);		}		fclose(fp);	}}",15876
468,1961,CVE-2016-5400,26,"static int airspy_s_tuner(struct file *file, void *priv,		const struct v4l2_tuner *v){	int ret;	if (v->index == 0)		ret = 0;	else if (v->index == 1)		ret = 0;	else		ret = -EINVAL;	return ret;}",16465
929,1407,CVE-2012-2119,26,"static int macvtap_open(struct inode *inode, struct file *file){	struct net *net = current->nsproxy->net_ns;	struct net_device *dev = dev_get_by_macvtap_minor(iminor(inode));	struct macvtap_queue *q;	int err;	err = -ENODEV;	if (!dev)		goto out;	err = -ENOMEM;	q = (struct macvtap_queue *)sk_alloc(net, AF_UNSPEC, GFP_KERNEL,					     &macvtap_proto);	if (!q)		goto out;	q->sock.wq = &q->wq;	init_waitqueue_head(&q->wq.wait);	q->sock.type = SOCK_RAW;	q->sock.state = SS_CONNECTED;	q->sock.file = file;	q->sock.ops = &macvtap_socket_ops;	sock_init_data(&q->sock, &q->sk);	q->sk.sk_write_space = macvtap_sock_write_space;	q->sk.sk_destruct = macvtap_sock_destruct;	q->flags = IFF_VNET_HDR | IFF_NO_PI | IFF_TAP;	q->vnet_hdr_sz = sizeof(struct virtio_net_hdr);	 	if ((dev->features & NETIF_F_HIGHDMA) && (dev->features & NETIF_F_SG))		sock_set_flag(&q->sk, SOCK_ZEROCOPY);	err = macvtap_set_queue(dev, file, q);	if (err)		sock_put(&q->sk);out:	if (dev)		dev_put(dev);	return err;}",10013
4,2340,CVE-2016-2324,26,"static struct commit *handle_commit(struct rev_info *revs,				    struct object_array_entry *entry){	struct object *object = entry->item;	const char *name = entry->name;	const char *path = entry->path;	unsigned int mode = entry->mode;	unsigned long flags = object->flags;	 	while (object->type == OBJ_TAG) {		struct tag *tag = (struct tag *) object;		if (revs->tag_objects && !(flags & UNINTERESTING))			add_pending_object(revs, object, tag->tag);		if (!tag->tagged)			die(""bad tag"");		object = parse_object(tag->tagged->oid.hash);		if (!object) {			if (flags & UNINTERESTING)				return NULL;			die(""bad object %s"", oid_to_hex(&tag->tagged->oid));		}		object->flags |= flags;		 		path = NULL;		mode = 0;	}	 	if (object->type == OBJ_COMMIT) {		struct commit *commit = (struct commit *)object;		if (parse_commit(commit) < 0)			die(""unable to parse commit %s"", name);		if (flags & UNINTERESTING) {			mark_parents_uninteresting(commit);			revs->limited = 1;		}		if (revs->show_source && !commit->util)			commit->util = xstrdup(name);		return commit;	}	 	if (object->type == OBJ_TREE) {		struct tree *tree = (struct tree *)object;		if (!revs->tree_objects)			return NULL;		if (flags & UNINTERESTING) {			mark_tree_contents_uninteresting(tree);			return NULL;		}		add_pending_object_with_path(revs, object, name, mode, path);		return NULL;	}	 	if (object->type == OBJ_BLOB) {		if (!revs->blob_objects)			return NULL;		if (flags & UNINTERESTING)			return NULL;		add_pending_object_with_path(revs, object, name, mode, path);		return NULL;	}	die(""%s is unknown object"", name);}",17760
753,2211,CVE-2016-3955,26,"void usbip_pad_iso(struct usbip_device *ud, struct urb *urb){	int np = urb->number_of_packets;	int i;	int actualoffset = urb->actual_length;	if (!usb_pipeisoc(urb->pipe))		return;	 	if (np == 0 || urb->actual_length == 0)		return;	 	if (urb->actual_length == urb->transfer_buffer_length)		return;	 	for (i = np-1; i > 0; i--) {		actualoffset -= urb->iso_frame_desc[i].actual_length;		memmove(urb->transfer_buffer + urb->iso_frame_desc[i].offset,			urb->transfer_buffer + actualoffset,			urb->iso_frame_desc[i].actual_length);	}}",17138
712,2028,CVE-2016-4568,26,"int _vb2_fop_release(struct file *file, struct mutex *lock){	struct video_device *vdev = video_devdata(file);	if (lock)		mutex_lock(lock);	if (file->private_data == vdev->queue->owner) {		vb2_queue_release(vdev->queue);		vdev->queue->owner = NULL;	}	if (lock)		mutex_unlock(lock);	return v4l2_fh_release(file);}",16730
545,1576,CVE-2015-5283,26,"static void sctp_inet_skb_msgname(struct sk_buff *skb, char *msgname, int *len){	if (msgname) {		struct sctphdr *sh = sctp_hdr(skb);		struct sockaddr_in *sin = (struct sockaddr_in *)msgname;		sctp_inet_msgname(msgname, len);		sin->sin_port = sh->source;		sin->sin_addr.s_addr = ip_hdr(skb)->saddr;	}}",13431
240,2089,CVE-2016-4303,26,iperf_get_test_get_server_output(struct iperf_test *ipt){    return ipt->get_server_output;},16997
937,1535,CVE-2014-0205,26,static void get_futex_key_refs(union futex_key *key){	if (!key->both.ptr)		return;	switch (key->both.offset & (FUT_OFF_INODE|FUT_OFF_MMSHARED)) {	case FUT_OFF_INODE:		atomic_inc(&key->shared.inode->i_count);		break;	case FUT_OFF_MMSHARED:		atomic_inc(&key->private.mm->mm_count);		break;	}},12082
771,296,CVE-2016-7161,26,static void xilinx_ethlite_register_types(void){    type_register_static(&xilinx_ethlite_info);},1373
244,3037,CVE-2016-10196,26,evutil_free_globals_(void){	evutil_free_secure_rng_globals_();	evutil_free_sock_err_globals();},22435
374,3845,CVE-2017-5122,26,"  void DragMove(int dx, int dy) {    resizer_->Drag(CalculateDragPoint(*resizer_, dx, dy), 0);  }",29823
627,1673,CVE-2015-4036,26,static void vhost_scsi_queue_tm_rsp(struct se_cmd *se_cmd){	return;},13539
857,136,CVE-2015-5289,26,"jsonb_extract_path_text(PG_FUNCTION_ARGS){	return get_jsonb_path_all(fcinfo, true);}",543
669,2620,CVE-2015-8863,26,static void parser_reset(struct jv_parser* p) {  if ((p->flags & JV_PARSE_STREAMING)) {    jv_free(p->path);    p->path = jv_array();    p->stacklen = 0;  }  p->last_seen = JV_LAST_NONE;  jv_free(p->output);  p->output = jv_invalid();  jv_free(p->next);  p->next = jv_invalid();  for (int i=0; i<p->stackpos; i++)    jv_free(p->stack[i]);  p->stackpos = 0;  p->tokenpos = 0;  p->st = JV_PARSER_NORMAL;},18473
992,2189,CVE-2016-4301,26,"parse_escapes(char *src, struct mtree_entry *mentry){	char *dest = src;	char c;	if (mentry != NULL && strcmp(src, ""."") == 0)		mentry->full = 1;	while (*src != '\0') {		c = *src++;		if (c == '/' && mentry != NULL)			mentry->full = 1;		if (c == '\\') {			switch (src[0]) {			case '0':				if (src[1] < '0' || src[1] > '7') {					c = 0;					++src;					break;				}				 			case '1':			case '2':			case '3':				if (src[1] >= '0' && src[1] <= '7' &&				    src[2] >= '0' && src[2] <= '7') {					c = (src[0] - '0') << 6;					c |= (src[1] - '0') << 3;					c |= (src[2] - '0');					src += 3;				}				break;			case 'a':				c = '\a';				++src;				break;			case 'b':				c = '\b';				++src;				break;			case 'f':				c = '\f';				++src;				break;			case 'n':				c = '\n';				++src;				break;			case 'r':				c = '\r';				++src;				break;			case 's':				c = ' ';				++src;				break;			case 't':				c = '\t';				++src;				break;			case 'v':				c = '\v';				++src;				break;			case '\\':				c = '\\';				++src;				break;			}		}		*dest++ = c;	}	*dest = '\0';}",17097
927,943,CVE-2013-4591,26,"nfs4_atomic_open(struct inode *dir, struct nfs_open_context *ctx, int open_flags, struct iattr *attr){	struct nfs4_state *state;	 	state = nfs4_do_open(dir, ctx->dentry, ctx->mode, open_flags, attr,			     ctx->cred, &ctx->mdsthreshold);	if (IS_ERR(state))		return ERR_CAST(state);	ctx->state = state;	return igrab(state->inode);}",7540
718,3212,CVE-2018-17407,26,"static void t1_subset_end(void){    if (t1_synthetic) {                  while (!strstr(t1_line_array, ""definefont"")) {            t1_getline();            t1_putline();        }        while (!t1_end_eexec())            t1_getline();                t1_putline();                } else        while (!t1_end_eexec()) {                    t1_getline();            t1_putline();        }    t1_stop_eexec();    if (fixedcontent) {                  while (!t1_cleartomark()) {            t1_getline();            t1_putline();        }        if (!t1_synthetic)                   t1_check_end();          }    get_length3();}",23646
780,1139,CVE-2013-2237,26,static inline int pfkey_mode_to_xfrm(int mode){	switch(mode) {	case IPSEC_MODE_ANY:	 	case IPSEC_MODE_TRANSPORT:		return XFRM_MODE_TRANSPORT;	case IPSEC_MODE_TUNNEL:		return XFRM_MODE_TUNNEL;	case IPSEC_MODE_BEET:		return XFRM_MODE_BEET;	default:		return -1;	}},8728
590,3549,CVE-2018-20855,26,"static int modify_raw_packet_qp_rq(struct mlx5_ib_dev *dev,				   struct mlx5_ib_rq *rq, int new_state,				   const struct mlx5_modify_raw_qp_param *raw_qp_param){	void *in;	void *rqc;	int inlen;	int err;	inlen = MLX5_ST_SZ_BYTES(modify_rq_in);	in = kvzalloc(inlen, GFP_KERNEL);	if (!in)		return -ENOMEM;	MLX5_SET(modify_rq_in, in, rq_state, rq->state);	rqc = MLX5_ADDR_OF(modify_rq_in, in, ctx);	MLX5_SET(rqc, rqc, state, new_state);	if (raw_qp_param->set_mask & MLX5_RAW_QP_MOD_SET_RQ_Q_CTR_ID) {		if (MLX5_CAP_GEN(dev->mdev, modify_rq_counter_set_id)) {			MLX5_SET64(modify_rq_in, in, modify_bitmask,				   MLX5_MODIFY_RQ_IN_MODIFY_BITMASK_RQ_COUNTER_SET_ID);			MLX5_SET(rqc, rqc, counter_set_id, raw_qp_param->rq_q_ctr_id);		} else			pr_info_once(""%s: RAW PACKET QP counters are not supported on current FW\n"",				     dev->ib_dev.name);	}	err = mlx5_core_modify_rq(dev->mdev, rq->base.mqp.qpn, in, inlen);	if (err)		goto out;	rq->state = new_state;out:	kvfree(in);	return err;}",27577
294,455,CVE-2014-2013,26,"static inline float point_inside_circle(float px, float py, float x, float y, float r){	float dx = px - x;	float dy = py - y;	return dx * dx + dy * dy <= r * r;}",2192
487,3632,CVE-2017-18379,26,"nvmet_fc_queue_to_cpu(struct nvmet_fc_tgtport *tgtport, int qid){	int cpu, idx, cnt;	if (tgtport->ops->max_hw_queues == 1)		return WORK_CPU_UNBOUND;	 	idx = !qid ? 0 : (qid - 1) % num_active_cpus();	 	for (cpu = 0, cnt = 0; ; ) {		if (cpu_active(cpu)) {			if (cnt == idx)				break;			cnt++;		}		cpu = (cpu + 1) % num_possible_cpus();	}	return cpu;}",28088
340,2619,CVE-2015-8863,26,"static void parser_init(struct jv_parser* p, int flags) {  p->flags = flags;  if ((p->flags & JV_PARSE_STREAMING)) {    p->path = jv_array();  } else {    p->path = jv_invalid();    p->flags &= ~(JV_PARSE_STREAM_ERRORS);  }  p->stack = 0;  p->stacklen = p->stackpos = 0;  p->last_seen = JV_LAST_NONE;  p->output = jv_invalid();  p->next = jv_invalid();  p->tokenbuf = 0;  p->tokenlen = p->tokenpos = 0;  if ((p->flags & JV_PARSE_SEQ))    p->st = JV_PARSER_WAITING_FOR_RS;  else    p->st = JV_PARSER_NORMAL;  p->eof = 0;  p->curr_buf = 0;  p->curr_buf_length = p->curr_buf_pos = p->curr_buf_is_partial = 0;  p->bom_strip_position = 0;  p->last_ch_was_ws = 0;  p->line = 1;  p->column = 0;  jvp_dtoa_context_init(&p->dtoa);}",18472
657,3224,CVE-2018-17407,26,"static void t1_init_params(int open_name_prefix){    report_start_file(open_name_prefix,cur_file_name);    t1_lenIV = 4;    t1_dr = 55665;    t1_er = 55665;    t1_in_eexec = 0;    t1_cs = false;    t1_scan = true;    t1_synthetic = false;    t1_eexec_encrypt = false;    t1_block_length = 0;    t1_check_pfa();}",23658
727,4058,CVE-2013-4244,26,"process(register int code, unsigned char** fill){    int incode;    static unsigned char firstchar;    if (code == clear) {	codesize = datasize + 1;	codemask = (1 << codesize) - 1;	avail = clear + 2;	oldcode = -1;	return 1;     }      if (oldcode == -1) { 	*(*fill)++ = suffix[code]; 	firstchar = oldcode = code; 	return 1;    }    if (code > avail) {	fprintf(stderr, ""code %d too large for %d\n"", code, avail);	return 0;     }    incode = code;    if (code == avail) {       	*stackp++ = firstchar;	code = oldcode;    }    while (code > clear) {	*stackp++ = suffix[code];	code = prefix[code];    }    *stackp++ = firstchar = suffix[code];    prefix[avail] = oldcode;    suffix[avail] = firstchar;    avail++;    if (((avail & codemask) == 0) && (avail < 4096)) {	codesize++;	codemask += avail;    }    oldcode = incode;    do {	*(*fill)++ = *--stackp;    } while (stackp > stack);    return 1;}",31057
35,1111,CVE-2013-2237,26,"static inline int ealg_tmpl_set(const struct xfrm_tmpl *t,				const struct xfrm_algo_desc *d){	unsigned int id = d->desc.sadb_alg_id;	if (id >= sizeof(t->ealgos) * 8)		return 0;	return (t->ealgos >> id) & 1;}",8700
379,2100,CVE-2016-4303,26,iperf_get_test_server_port(struct iperf_test *ipt){    return ipt->server_port;},17008
256,956,CVE-2013-4591,26,"int nfs4_init_session(struct nfs_server *server){	struct nfs_client *clp = server->nfs_client;	struct nfs4_session *session;	unsigned int rsize, wsize;	if (!nfs4_has_session(clp))		return 0;	session = clp->cl_session;	spin_lock(&clp->cl_lock);	if (test_and_clear_bit(NFS4_SESSION_INITING, &session->session_state)) {		rsize = server->rsize;		if (rsize == 0)			rsize = NFS_MAX_FILE_IO_SIZE;		wsize = server->wsize;		if (wsize == 0)			wsize = NFS_MAX_FILE_IO_SIZE;		session->fc_attrs.max_rqst_sz = wsize + nfs41_maxwrite_overhead;		session->fc_attrs.max_resp_sz = rsize + nfs41_maxread_overhead;	}	spin_unlock(&clp->cl_lock);	return nfs41_check_session_ready(clp);}",7553
711,3560,CVE-2018-20855,26,"static void set_linv_wr(struct mlx5_ib_qp *qp, void **seg, int *size){	set_linv_umr_seg(*seg);	*seg += sizeof(struct mlx5_wqe_umr_ctrl_seg);	*size += sizeof(struct mlx5_wqe_umr_ctrl_seg) / 16;	if (unlikely((*seg == qp->sq.qend)))		*seg = mlx5_get_send_wqe(qp, 0);	set_linv_mkey_seg(*seg);	*seg += sizeof(struct mlx5_mkey_seg);	*size += sizeof(struct mlx5_mkey_seg) / 16;	if (unlikely((*seg == qp->sq.qend)))		*seg = mlx5_get_send_wqe(qp, 0);}",27588
29,242,CVE-2018-10184,26,"static void h2_shutr(struct conn_stream *cs, enum cs_shr_mode mode){	struct h2s *h2s = cs->ctx;	if (!mode)		return;	if (h2s->st == H2_SS_HLOC || h2s->st == H2_SS_ERROR || h2s->st == H2_SS_CLOSED)		return;	 	if (!(h2s->flags & H2_SF_RST_SENT) &&	    h2s_send_rst_stream(h2s->h2c, h2s) <= 0)		goto add_to_list;	if (!(h2s->flags & H2_SF_OUTGOING_DATA) &&	    !(h2s->h2c->flags & (H2_CF_GOAWAY_SENT|H2_CF_GOAWAY_FAILED)) &&	    h2c_send_goaway_error(h2s->h2c, h2s) <= 0)		goto add_to_list;	if (h2s->h2c->mbuf->o && !(cs->conn->flags & CO_FL_XPRT_WR_ENA))		conn_xprt_want_send(cs->conn);	h2s_close(h2s); add_to_list:	if (LIST_ISEMPTY(&h2s->list)) {		if (h2s->flags & H2_SF_BLK_MFCTL)			LIST_ADDQ(&h2s->h2c->fctl_list, &h2s->list);		else if (h2s->flags & (H2_SF_BLK_MBUSY|H2_SF_BLK_MROOM))			LIST_ADDQ(&h2s->h2c->send_list, &h2s->list);	}}",1263
188,1189,CVE-2013-2220,26,"rad_put_addr(struct rad_handle *h, int type, struct in_addr addr){	return rad_put_attr(h, type, &addr.s_addr, sizeof addr.s_addr);}",8779
879,668,CVE-2011-2517,26,"static int nl80211_get_wiphy(struct sk_buff *skb, struct genl_info *info){	struct sk_buff *msg;	struct cfg80211_registered_device *dev = info->user_ptr[0];	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);	if (!msg)		return -ENOMEM;	if (nl80211_send_wiphy(msg, info->snd_pid, info->snd_seq, 0, dev) < 0) {		nlmsg_free(msg);		return -ENOBUFS;	}	return genlmsg_reply(msg, info);}",6567
54,3353,CVE-2017-1000418,26,static inline int wm_tolower(int c) {    return ((wm_isupper(c)) ? (c | ('a' - 'A')) : c);},25633
3,193,CVE-2017-10971,26,"SetCriticalEvent(int event){    if (event >= MAXEVENTS)        FatalError(""SetCriticalEvent: bogus event number"");    criticalEvents[event >> 3] |= 1 << (event & 7);}",844
380,3554,CVE-2018-20855,26,"static int set_data_inl_seg(struct mlx5_ib_qp *qp, const struct ib_send_wr *wr,			    void *wqe, int *sz){	struct mlx5_wqe_inline_seg *seg;	void *qend = qp->sq.qend;	void *addr;	int inl = 0;	int copy;	int len;	int i;	seg = wqe;	wqe += sizeof(*seg);	for (i = 0; i < wr->num_sge; i++) {		addr = (void *)(unsigned long)(wr->sg_list[i].addr);		len  = wr->sg_list[i].length;		inl += len;		if (unlikely(inl > qp->max_inline_data))			return -ENOMEM;		if (unlikely(wqe + len > qend)) {			copy = qend - wqe;			memcpy(wqe, addr, copy);			addr += copy;			len -= copy;			wqe = mlx5_get_send_wqe(qp, 0);		}		memcpy(wqe, addr, len);		wqe += len;	}	seg->byte_count = cpu_to_be32(inl | MLX5_INLINE_SEG);	*sz = ALIGN(inl + sizeof(seg->byte_count), 16) / 16;	return 0;}",27582
397,34,CVE-2015-6806,26,"Return(){  if (curr->w_x == 0)    return;  curr->w_x = 0;  LGotoPos(&curr->w_layer, curr->w_x, curr->w_y);}",255
485,3291,CVE-2018-11506,26,"static int sr_read_tocentry(struct cdrom_device_info *cdi,		struct cdrom_tocentry *tocentry){	struct scsi_cd *cd = cdi->handle;	struct packet_command cgc;	int result;	unsigned char *buffer;	buffer = kmalloc(32, GFP_KERNEL | SR_GFP_DMA(cd));	if (!buffer)		return -ENOMEM;	memset(&cgc, 0, sizeof(struct packet_command));	cgc.timeout = IOCTL_TIMEOUT;	cgc.cmd[0] = GPCMD_READ_TOC_PMA_ATIP;	cgc.cmd[1] |= (tocentry->cdte_format == CDROM_MSF) ? 0x02 : 0;	cgc.cmd[6] = tocentry->cdte_track;	cgc.cmd[8] = 12;		 	cgc.buffer = buffer;	cgc.buflen = 12;	cgc.data_direction = DMA_FROM_DEVICE;	result = sr_do_ioctl(cd, &cgc);	tocentry->cdte_ctrl = buffer[5] & 0xf;	tocentry->cdte_adr = buffer[5] >> 4;	tocentry->cdte_datamode = (tocentry->cdte_ctrl & 0x04) ? 1 : 0;	if (tocentry->cdte_format == CDROM_MSF) {		tocentry->cdte_addr.msf.minute = buffer[9];		tocentry->cdte_addr.msf.second = buffer[10];		tocentry->cdte_addr.msf.frame = buffer[11];	} else		tocentry->cdte_addr.lba = (((((buffer[8] << 8) + buffer[9]) << 8)			+ buffer[10]) << 8) + buffer[11];	kfree(buffer);	return result;}",25150
532,3734,CVE-2017-7586,26,"psf_d2i_array (const double *src, int *dest, int count, int normalize){	double 			normfact ;	normfact = normalize ? (1.0 * 0x7FFFFFFF) : 1.0 ;	while (--count >= 0)		dest [count] = lrint (src [count] * normfact) ;	return ;}  ",28555
285,3831,CVE-2016-1646,26,"void RecordInterventionUserDecision(int accepted) {  UMA_HISTOGRAM_BOOLEAN(""Memory.Experimental.OomIntervention.UserDecision"",                        accepted);}",29747
663,3885,CVE-2017-5012,26,  PaymentsRequestVisualTest() {},29915
908,2885,CVE-2017-8065,26,"static void crypto_ccm_decrypt_done(struct crypto_async_request *areq,				   int err){	struct aead_request *req = areq->data;	struct crypto_ccm_req_priv_ctx *pctx = crypto_ccm_reqctx(req);	struct crypto_aead *aead = crypto_aead_reqtfm(req);	unsigned int authsize = crypto_aead_authsize(aead);	unsigned int cryptlen = req->cryptlen - authsize;	struct scatterlist *dst;	pctx->flags = 0;	dst = sg_next(req->src == req->dst ? pctx->src : pctx->dst);	if (!err) {		err = crypto_ccm_auth(req, dst, cryptlen);		if (!err && crypto_memneq(pctx->auth_tag, pctx->odata, authsize))			err = -EBADMSG;	}	aead_request_complete(req, err);}",21362
827,304,CVE-2017-6209,26,static char uprcase( char c ){   if (c >= 'a' && c <= 'z')      return c + 'A' - 'a';   return c;},1602
873,2673,CVE-2017-16931,26,uripClose(void * context) {    if (context == NULL) return(-1);    urip_cur = NULL;    urip_rlen = 0;    return(0);},19662
840,500,CVE-2012-6711,26,"open_files (){  register int i;  int f, fd_table_size;  fd_table_size = getdtablesize ();  fprintf (stderr, ""pid %ld open files:"", (long)getpid ());  for (i = 3; i < fd_table_size; i++)    {      if ((f = fcntl (i, F_GETFD, 0)) != -1)	fprintf (stderr, "" %d (%s)"", i, f ? ""close"" : ""open"");    }  fprintf (stderr, ""\n"");}",2540
440,3010,CVE-2017-5548,26,"static int atusb_write_reg(struct atusb *atusb, int reg, int value){	struct usb_device *usb_dev = atusb->usb_dev;	dev_dbg(&usb_dev->dev, ""atusb_write_reg: 0x%02x <- 0x%02x\n"",		reg, value);	return atusb_control_msg(atusb, usb_sndctrlpipe(usb_dev, 0),				 ATUSB_REG_WRITE, ATUSB_REQ_TO_DEV,				 value, reg, NULL, 0, 1000);}",22049
557,3904,CVE-2017-15416,26,  BlobStorageContextTest() {},30138
979,122,CVE-2015-5289,26,"json_array_elements_text(PG_FUNCTION_ARGS){	return elements_worker(fcinfo, ""json_array_elements_text"", true);}",529
882,3586,CVE-2018-20182,26,"rdp_reset_state(void){	logger(Protocol, Debug, ""%s()"", __func__);	g_next_packet = NULL;	 	g_rdp_shareid = 0;	g_exit_mainloop = False;	g_first_bitmap_caps = True;	sec_reset_state();}",27884
124,2823,CVE-2017-8070,26,"static int catc_open(struct net_device *netdev){	struct catc *catc = netdev_priv(netdev);	int status;	catc->irq_urb->dev = catc->usbdev;	if ((status = usb_submit_urb(catc->irq_urb, GFP_KERNEL)) < 0) {		dev_err(&catc->usbdev->dev, ""submit(irq_urb) status %d\n"",			status);		return -1;	}	netif_start_queue(netdev);	if (!catc->is_f5u011)		mod_timer(&catc->timer, jiffies + STATS_UPDATE);	return 0;}",21300
473,1154,CVE-2013-2237,26,"static int pfkey_send_notify(struct xfrm_state *x, const struct km_event *c){	struct net *net = x ? xs_net(x) : c->net;	struct netns_pfkey *net_pfkey = net_generic(net, pfkey_net_id);	if (atomic_read(&net_pfkey->socks_nr) == 0)		return 0;	switch (c->event) {	case XFRM_MSG_EXPIRE:		return key_notify_sa_expire(x, c);	case XFRM_MSG_DELSA:	case XFRM_MSG_NEWSA:	case XFRM_MSG_UPDSA:		return key_notify_sa(x, c);	case XFRM_MSG_FLUSHSA:		return key_notify_sa_flush(c);	case XFRM_MSG_NEWAE:  		break;	default:		pr_err(""pfkey: Unknown SA event %d\n"", c->event);		break;	}	return 0;}",8743
955,1243,CVE-2013-1929,26,"static struct rtnl_link_stats64 *tg3_get_stats64(struct net_device *dev,						struct rtnl_link_stats64 *stats){	struct tg3 *tp = netdev_priv(dev);	spin_lock_bh(&tp->lock);	if (!tp->hw_stats) {		spin_unlock_bh(&tp->lock);		return &tp->net_stats_prev;	}	tg3_get_nstats(tp, stats);	spin_unlock_bh(&tp->lock);	return stats;}",9249
252,2221,CVE-2016-2324,26,"static int add_ref_tag(const char *path, const struct object_id *oid, int flag, void *cb_data){	struct object_id peeled;	if (starts_with(path, ""refs/tags/"") &&  	    !peel_ref(path, peeled.hash)    &&  	    packlist_find(&to_pack, peeled.hash, NULL))       		add_object_entry(oid->hash, OBJ_TAG, NULL, 0);	return 0;}",17641
877,1733,CVE-2015-1333,26,"static int keyring_compare_object(const void *object, const void *data){	const struct keyring_index_key *index_key = data;	const struct key *key = keyring_ptr_to_key(object);	return key->index_key.type == index_key->type &&		key->index_key.desc_len == index_key->desc_len &&		memcmp(key->index_key.description, index_key->description,		       index_key->desc_len) == 0;}",14038
558,850,CVE-2013-6381,26,"int qeth_get_elements_for_frags(struct sk_buff *skb){	int cnt, length, e, elements = 0;	struct skb_frag_struct *frag;	char *data;	for (cnt = 0; cnt < skb_shinfo(skb)->nr_frags; cnt++) {		frag = &skb_shinfo(skb)->frags[cnt];		data = (char *)page_to_phys(skb_frag_page(frag)) +			frag->page_offset;		length = frag->size;		e = PFN_UP((unsigned long)data + length - 1) -			PFN_DOWN((unsigned long)data);		elements += e;	}	return elements;}",7279
996,3141,CVE-2016-1245,26,"if_join_all_router (int sock, struct interface *ifp){  int ret;  struct ipv6_mreq mreq;  memset (&mreq, 0, sizeof (struct ipv6_mreq));  inet_pton (AF_INET6, ALLROUTER, &mreq.ipv6mr_multiaddr);  mreq.ipv6mr_interface = ifp->ifindex;  ret = setsockopt (sock, IPPROTO_IPV6, IPV6_JOIN_GROUP, 		    (char *) &mreq, sizeof mreq);  if (ret < 0)    zlog_warn (""can't setsockopt IPV6_JOIN_GROUP: %s"", safe_strerror (errno));  zlog_info (""rtadv: %s join to all-routers multicast group"", ifp->name);  return 0;}",22845
202,3765,CVE-2012-2876,26,  AutofillTest() {    EnableDOMAutomation();  },29176
1008,222,CVE-2017-7476,26,"tm_diff (struct tm const *a, struct tm const *b){     int a4 = SHR (a->tm_year, 2) + SHR (TM_YEAR_BASE, 2) - ! (a->tm_year & 3);  int b4 = SHR (b->tm_year, 2) + SHR (TM_YEAR_BASE, 2) - ! (b->tm_year & 3);  int a100 = a4 / 25 - (a4 % 25 < 0);  int b100 = b4 / 25 - (b4 % 25 < 0);  int a400 = SHR (a100, 2);  int b400 = SHR (b100, 2);  int intervening_leap_days = (a4 - b4) - (a100 - b100) + (a400 - b400);  long int ayear = a->tm_year;  long int years = ayear - b->tm_year;  long int days = (365 * years + intervening_leap_days                   + (a->tm_yday - b->tm_yday));  return (60 * (60 * (24 * days + (a->tm_hour - b->tm_hour))                + (a->tm_min - b->tm_min))          + (a->tm_sec - b->tm_sec));}",1236
605,2381,CVE-2016-2315,26,"static void cat_blob(struct object_entry *oe, unsigned char sha1[20]){	struct strbuf line = STRBUF_INIT;	unsigned long size;	enum object_type type = 0;	char *buf;	if (!oe || oe->pack_id == MAX_PACK_ID) {		buf = read_sha1_file(sha1, &type, &size);	} else {		type = oe->type;		buf = gfi_unpack_entry(oe, &size);	}	 	if (type <= 0) {		strbuf_reset(&line);		strbuf_addf(&line, ""%s missing\n"", sha1_to_hex(sha1));		cat_blob_write(line.buf, line.len);		strbuf_release(&line);		free(buf);		return;	}	if (!buf)		die(""Can't read object %s"", sha1_to_hex(sha1));	if (type != OBJ_BLOB)		die(""Object %s is a %s but a blob was expected."",		    sha1_to_hex(sha1), typename(type));	strbuf_reset(&line);	strbuf_addf(&line, ""%s %s %lu\n"", sha1_to_hex(sha1),						typename(type), size);	cat_blob_write(line.buf, line.len);	strbuf_release(&line);	cat_blob_write(buf, size);	cat_blob_write(""\n"", 1);	if (oe && oe->pack_id == pack_id) {		last_blob.offset = oe->idx.offset;		strbuf_attach(&last_blob.data, buf, size, size);		last_blob.depth = oe->depth;	} else		free(buf);}",17801
25,3088,CVE-2016-10012,26,"ssh_packet_set_tos(struct ssh *ssh, int tos){	if (!ssh_packet_connection_is_on_socket(ssh))		return;	switch (ssh_packet_connection_af(ssh)) {	case AF_INET:		debug3(""%s: set IP_TOS 0x%02x"", __func__, tos);		if (setsockopt(ssh->state->connection_in,		    IPPROTO_IP, IP_TOS, &tos, sizeof(tos)) < 0)			error(""setsockopt IP_TOS %d: %.100s:"",			    tos, strerror(errno));		break;	case AF_INET6:		debug3(""%s: set IPV6_TCLASS 0x%02x"", __func__, tos);		if (setsockopt(ssh->state->connection_in,		    IPPROTO_IPV6, IPV6_TCLASS, &tos, sizeof(tos)) < 0)			error(""setsockopt IPV6_TCLASS %d: %.100s:"",			    tos, strerror(errno));		break;	}}",22606
442,2934,CVE-2017-8063,26,"static int cxusb_lgh064f_tuner_attach(struct dvb_usb_adapter *adap){	dvb_attach(simple_tuner_attach, adap->fe_adap[0].fe,		   &adap->dev->i2c_adap, 0x61, TUNER_LG_TDVS_H06XF);	return 0;}",21411
744,1713,CVE-2015-2697,26,krb5_anonymous_principal(){    return &anon_princ;},13714
20,2815,CVE-2017-8073,26,"irc_ctcp_get_default_reply (const char *ctcp){    int i;    for (i = 0; irc_ctcp_default_reply[i].name; i++)    {        if (weechat_strcasecmp (irc_ctcp_default_reply[i].name, ctcp) == 0)            return irc_ctcp_default_reply[i].reply;    }         return NULL;}",21286
961,1662,CVE-2015-4036,26,"static void vhost_scsi_free_cmd(struct vhost_scsi_cmd *cmd){	struct se_cmd *se_cmd = &cmd->tvc_se_cmd;	 	transport_generic_free_cmd(se_cmd, 0);}",13528
59,2954,CVE-2017-8062,26,"static int dw3101_frontend_attach(struct dvb_usb_adapter *d){	d->fe_adap[0].fe = dvb_attach(tda10023_attach, &dw3101_tda10023_config,				&d->dev->i2c_adap, 0x48);	if (d->fe_adap[0].fe != NULL) {		info(""Attached tda10023!"");		return 0;	}	return -EIO;}",21431
736,3683,CVE-2011-5327,26,static int tcm_loop_check_demo_mode_write_protect(struct se_portal_group *se_tpg){	return 0;},28169
731,732,CVE-2010-4650,26,void fuse_init_file_inode(struct inode *inode){	inode->i_fop = &fuse_file_operations;	inode->i_data.a_ops = &fuse_file_aops;},7016
162,3184,CVE-2018-17942,26,"floorlog10l (long double x){  int exp;  long double y;  double z;  double l;     y = frexpl (x, &exp);  if (!(y >= 0.0L && y < 1.0L))    abort ();  if (y == 0.0L)    return INT_MIN;  if (y < 0.5L)    {      while (y < (1.0L / (1 << (GMP_LIMB_BITS / 2)) / (1 << (GMP_LIMB_BITS / 2))))        {          y *= 1.0L * (1 << (GMP_LIMB_BITS / 2)) * (1 << (GMP_LIMB_BITS / 2));          exp -= GMP_LIMB_BITS;        }      if (y < (1.0L / (1 << 16)))        {          y *= 1.0L * (1 << 16);          exp -= 16;        }      if (y < (1.0L / (1 << 8)))        {          y *= 1.0L * (1 << 8);          exp -= 8;        }      if (y < (1.0L / (1 << 4)))        {          y *= 1.0L * (1 << 4);          exp -= 4;        }      if (y < (1.0L / (1 << 2)))        {          y *= 1.0L * (1 << 2);          exp -= 2;        }      if (y < (1.0L / (1 << 1)))        {          y *= 1.0L * (1 << 1);          exp -= 1;        }    }  if (!(y >= 0.5L && y < 1.0L))    abort ();     l = exp;  z = y;  if (z < 0.70710678118654752444)    {      z *= 1.4142135623730950488;      l -= 0.5;    }  if (z < 0.8408964152537145431)    {      z *= 1.1892071150027210667;      l -= 0.25;    }  if (z < 0.91700404320467123175)    {      z *= 1.0905077326652576592;      l -= 0.125;    }  if (z < 0.9576032806985736469)    {      z *= 1.0442737824274138403;      l -= 0.0625;    }     z = 1 - z;     l -= 1.4426950408889634074 * z * (1.0 + z * (0.5 + z * ((1.0 / 3) + z * 0.25)));     l *= 0.30102999566398119523;     return (int) l + (l < 0 ? -1 : 0);}",23591
312,3584,CVE-2018-20182,26,"reset_order_state(void){	memset(&g_order_state, 0, sizeof(g_order_state));	g_order_state.order_type = RDP_ORDER_PATBLT;}",27882
337,25,CVE-2015-6806,26,"BackwardTab(){  register int x = curr->w_x;  if (curr->w_tabs[x] && x > 0)    x--;  while (x > 0 && !curr->w_tabs[x])    x--;  curr->w_x = x;  LGotoPos(&curr->w_layer, curr->w_x, curr->w_y);}",246
959,2012,CVE-2016-4998,26,"get_entry(const void *base, unsigned int offset){	return (struct ip6t_entry *)(base + offset);}",16578
226,404,CVE-2016-1907,26,ssh_packet_get_input(struct ssh *ssh){	return (void *)ssh->state->input;},2128
1012,2462,CVE-2016-2315,26,"static int commit_match(struct commit *commit, struct rev_info *opt){	int retval;	const char *encoding;	const char *message;	struct strbuf buf = STRBUF_INIT;	if (!opt->grep_filter.pattern_list && !opt->grep_filter.header_list)		return 1;	 	if (opt->grep_filter.use_reflog_filter) {		strbuf_addstr(&buf, ""reflog "");		get_reflog_message(&buf, opt->reflog_info);		strbuf_addch(&buf, '\n');	}	 	encoding = get_log_output_encoding();	message = logmsg_reencode(commit, NULL, encoding);	 	if (buf.len)		strbuf_addstr(&buf, message);	if (opt->grep_filter.header_list && opt->mailmap) {		if (!buf.len)			strbuf_addstr(&buf, message);		commit_rewrite_person(&buf, ""\nauthor "", opt->mailmap);		commit_rewrite_person(&buf, ""\ncommitter "", opt->mailmap);	}	 	if (opt->show_notes) {		if (!buf.len)			strbuf_addstr(&buf, message);		format_display_notes(commit->object.sha1, &buf, encoding, 1);	}	 	if (buf.len)		retval = grep_buffer(&opt->grep_filter, buf.buf, buf.len);	else		retval = grep_buffer(&opt->grep_filter,				     (char *)message, strlen(message));	strbuf_release(&buf);	unuse_commit_buffer(commit, message);	return opt->invert_grep ? !retval : retval;}",17882
915,4051,CVE-2011-1477,26," static void opl3_panning(int dev, int voice, int value) { 	devc->voc[voice].panning = value; }",31032
816,3280,CVE-2018-11596,26,unsigned int jsvGetMemoryTotal() {  return jsVarsSize;},25127
842,1362,CVE-2013-1772,26,"int __printk_ratelimit(const char *func){	return ___ratelimit(&printk_ratelimit_state, func);}",9599
326,2172,CVE-2016-4302,26,"make_table_recurse(struct archive_read *a, struct huffman_code *code, int node,                   struct huffman_table_entry *table, int depth,                   int maxdepth){  int currtablesize, i, ret = (ARCHIVE_OK);  if (!code->tree)  {    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                      ""Huffman tree was not created."");    return (ARCHIVE_FATAL);  }  if (node < 0 || node >= code->numentries)  {    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                      ""Invalid location to Huffman tree specified."");    return (ARCHIVE_FATAL);  }  currtablesize = 1 << (maxdepth - depth);  if (code->tree[node].branches[0] ==    code->tree[node].branches[1])  {    for(i = 0; i < currtablesize; i++)    {      table[i].length = depth;      table[i].value = code->tree[node].branches[0];    }  }  else if (node < 0)  {    for(i = 0; i < currtablesize; i++)      table[i].length = -1;  }  else  {    if(depth == maxdepth)    {      table[0].length = maxdepth + 1;      table[0].value = node;    }    else    {      ret |= make_table_recurse(a, code, code->tree[node].branches[0], table,                                depth + 1, maxdepth);      ret |= make_table_recurse(a, code, code->tree[node].branches[1],                         table + currtablesize / 2, depth + 1, maxdepth);    }  }  return ret;}",17080
579,135,CVE-2015-5289,26,"jsonb_extract_path(PG_FUNCTION_ARGS){	return get_jsonb_path_all(fcinfo, false);}",542
471,665,CVE-2011-2517,26,"static int nl80211_get_mesh_config(struct sk_buff *skb,				   struct genl_info *info){	struct cfg80211_registered_device *rdev = info->user_ptr[0];	struct net_device *dev = info->user_ptr[1];	struct wireless_dev *wdev = dev->ieee80211_ptr;	struct mesh_config cur_params;	int err = 0;	void *hdr;	struct nlattr *pinfoattr;	struct sk_buff *msg;	if (wdev->iftype != NL80211_IFTYPE_MESH_POINT)		return -EOPNOTSUPP;	if (!rdev->ops->get_mesh_config)		return -EOPNOTSUPP;	wdev_lock(wdev);	 	if (!wdev->mesh_id_len)		memcpy(&cur_params, &default_mesh_config, sizeof(cur_params));	else		err = rdev->ops->get_mesh_config(&rdev->wiphy, dev,						 &cur_params);	wdev_unlock(wdev);	if (err)		return err;	 	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);	if (!msg)		return -ENOMEM;	hdr = nl80211hdr_put(msg, info->snd_pid, info->snd_seq, 0,			     NL80211_CMD_GET_MESH_CONFIG);	if (!hdr)		goto out;	pinfoattr = nla_nest_start(msg, NL80211_ATTR_MESH_CONFIG);	if (!pinfoattr)		goto nla_put_failure;	NLA_PUT_U32(msg, NL80211_ATTR_IFINDEX, dev->ifindex);	NLA_PUT_U16(msg, NL80211_MESHCONF_RETRY_TIMEOUT,			cur_params.dot11MeshRetryTimeout);	NLA_PUT_U16(msg, NL80211_MESHCONF_CONFIRM_TIMEOUT,			cur_params.dot11MeshConfirmTimeout);	NLA_PUT_U16(msg, NL80211_MESHCONF_HOLDING_TIMEOUT,			cur_params.dot11MeshHoldingTimeout);	NLA_PUT_U16(msg, NL80211_MESHCONF_MAX_PEER_LINKS,			cur_params.dot11MeshMaxPeerLinks);	NLA_PUT_U8(msg, NL80211_MESHCONF_MAX_RETRIES,			cur_params.dot11MeshMaxRetries);	NLA_PUT_U8(msg, NL80211_MESHCONF_TTL,			cur_params.dot11MeshTTL);	NLA_PUT_U8(msg, NL80211_MESHCONF_ELEMENT_TTL,			cur_params.element_ttl);	NLA_PUT_U8(msg, NL80211_MESHCONF_AUTO_OPEN_PLINKS,			cur_params.auto_open_plinks);	NLA_PUT_U8(msg, NL80211_MESHCONF_HWMP_MAX_PREQ_RETRIES,			cur_params.dot11MeshHWMPmaxPREQretries);	NLA_PUT_U32(msg, NL80211_MESHCONF_PATH_REFRESH_TIME,			cur_params.path_refresh_time);	NLA_PUT_U16(msg, NL80211_MESHCONF_MIN_DISCOVERY_TIMEOUT,			cur_params.min_discovery_timeout);	NLA_PUT_U32(msg, NL80211_MESHCONF_HWMP_ACTIVE_PATH_TIMEOUT,			cur_params.dot11MeshHWMPactivePathTimeout);	NLA_PUT_U16(msg, NL80211_MESHCONF_HWMP_PREQ_MIN_INTERVAL,			cur_params.dot11MeshHWMPpreqMinInterval);	NLA_PUT_U16(msg, NL80211_MESHCONF_HWMP_NET_DIAM_TRVS_TIME,			cur_params.dot11MeshHWMPnetDiameterTraversalTime);	NLA_PUT_U8(msg, NL80211_MESHCONF_HWMP_ROOTMODE,			cur_params.dot11MeshHWMPRootMode);	nla_nest_end(msg, pinfoattr);	genlmsg_end(msg, hdr);	return genlmsg_reply(msg, info); nla_put_failure:	genlmsg_cancel(msg, hdr); out:	nlmsg_free(msg);	return -ENOBUFS;}",6564
859,2822,CVE-2017-8070,26,"static int catc_get_settings(struct net_device *dev, struct ethtool_cmd *cmd){	struct catc *catc = netdev_priv(dev);	if (!catc->is_f5u011)		return -EOPNOTSUPP;	cmd->supported = SUPPORTED_10baseT_Half | SUPPORTED_TP;	cmd->advertising = ADVERTISED_10baseT_Half | ADVERTISED_TP;	ethtool_cmd_speed_set(cmd, SPEED_10);	cmd->duplex = DUPLEX_HALF;	cmd->port = PORT_TP; 	cmd->phy_address = 0;	cmd->transceiver = XCVR_INTERNAL;	cmd->autoneg = AUTONEG_DISABLE;	cmd->maxtxpkt = 1;	cmd->maxrxpkt = 1;	return 0;}",21299
394,3698,CVE-2011-5327,26,static int tcm_loop_shutdown_session(struct se_session *se_sess){	return 0;},28184
855,3848,CVE-2017-5122,26,int AllRootWindowsHaveLockedModalBackgrounds() {  return AllRootWindowsHaveModalBackgroundsForContainer(      kShellWindowId_LockSystemModalContainer);},29826
355,394,CVE-2016-2108,26,"static int asn1_check_eoc(const unsigned char **in, long len){    const unsigned char *p;    if (len < 2)        return 0;    p = *in;    if (!p[0] && !p[1]) {        *in += 2;        return 1;    }    return 0;}",2081
503,741,CVE-2010-4650,26,"static int fuse_release(struct inode *inode, struct file *file){	fuse_release_common(file, FUSE_RELEASE);	 	return 0;}",7025
30,2635,CVE-2017-1000251,26,"static void l2cap_conn_ready(struct l2cap_conn *conn){	struct l2cap_chan_list *l = &conn->chan_list;	struct sock *sk;	BT_DBG(""conn %p"", conn);	read_lock(&l->lock);	for (sk = l->head; sk; sk = l2cap_pi(sk)->next_c) {		bh_lock_sock(sk);		if (sk->sk_type != SOCK_SEQPACKET) {			l2cap_sock_clear_timer(sk);			sk->sk_state = BT_CONNECTED;			sk->sk_state_change(sk);		} else if (sk->sk_state == BT_CONNECT)			l2cap_do_start(sk);		bh_unlock_sock(sk);	}	read_unlock(&l->lock);}",19473
749,2924,CVE-2017-8063,26,"static int cxusb_d680_dmb_frontend_attach(struct dvb_usb_adapter *adap){	struct dvb_usb_device *d = adap->dev;	int n;	 	if (usb_set_interface(d->udev, 0, 0) < 0)		err(""set interface failed"");	 	usb_clear_halt(d->udev,		usb_sndbulkpipe(d->udev, d->props.generic_bulk_ctrl_endpoint));	usb_clear_halt(d->udev,		usb_rcvbulkpipe(d->udev, d->props.generic_bulk_ctrl_endpoint));	usb_clear_halt(d->udev,		usb_rcvbulkpipe(d->udev, d->props.adapter[0].fe[0].stream.endpoint));	 	for (n = 0;  n < 5;  n++) {		cxusb_d680_dmb_drain_message(d);		cxusb_d680_dmb_drain_video(d);		msleep(200);	}	 	if (cxusb_d680_dmb_gpio_tuner(d, 0x07, 0) < 0) {		err(""clear tuner gpio failed"");		return -EIO;	}	msleep(100);	if (cxusb_d680_dmb_gpio_tuner(d, 0x07, 1) < 0) {		err(""set tuner gpio failed"");		return -EIO;	}	msleep(100);	 	adap->fe_adap[0].fe = dvb_attach(lgs8gxx_attach, &d680_lgs8gl5_cfg, &d->i2c_adap);	if (adap->fe_adap[0].fe == NULL)		return -EIO;	return 0;}",21401
95,1077,CVE-2013-4244,26,"convert(void){    int ch;    char* mode = ""w"";    if (!checksignature())        return (-1);    readscreen();    while ((ch = getc(infile)) != ';' && ch != EOF) {        switch (ch) {            case '\0':  break;               case ',':   if (!readgifimage(mode))                           return (-1);			mode = ""a"";		                         break;            case '!':   readextension();                        break;            default:    fprintf(stderr, ""illegal GIF block type\n"");                        return (-1);        }    }    return (0);}",7930
364,2431,CVE-2016-2315,26,"static int parse_one_feature(const char *feature, int from_stream){	const char *arg;	if (skip_prefix(feature, ""date-format="", &arg)) {		option_date_format(arg);	} else if (skip_prefix(feature, ""import-marks="", &arg)) {		option_import_marks(arg, from_stream, 0);	} else if (skip_prefix(feature, ""import-marks-if-exists="", &arg)) {		option_import_marks(arg, from_stream, 1);	} else if (skip_prefix(feature, ""export-marks="", &arg)) {		option_export_marks(arg);	} else if (!strcmp(feature, ""get-mark"")) {		;  	} else if (!strcmp(feature, ""cat-blob"")) {		;  	} else if (!strcmp(feature, ""relative-marks"")) {		relative_marks_paths = 1;	} else if (!strcmp(feature, ""no-relative-marks"")) {		relative_marks_paths = 0;	} else if (!strcmp(feature, ""done"")) {		require_explicit_termination = 1;	} else if (!strcmp(feature, ""force"")) {		force_update = 1;	} else if (!strcmp(feature, ""notes"") || !strcmp(feature, ""ls"")) {		;  	} else {		return 0;	}	return 1;}",17851
420,2812,CVE-2017-8807,26,"vbf_stp_fetchend(struct worker *wrk, struct busyobj *bo){	AZ(bo->vfc->failed);	VFP_Close(bo->vfc);	AZ(ObjSetU64(wrk, bo->fetch_objcore, OA_LEN,	    bo->fetch_objcore->boc->len_so_far));	if (bo->do_stream)		assert(bo->fetch_objcore->boc->state == BOS_STREAM);	else {		assert(bo->fetch_objcore->boc->state == BOS_REQ_DONE);		HSH_Unbusy(wrk, bo->fetch_objcore);	}	 	VDI_Finish(bo->wrk, bo);	ObjSetState(wrk, bo->fetch_objcore, BOS_FINISHED);	VSLb_ts_busyobj(bo, ""BerespBody"", W_TIM_real(wrk));	if (bo->stale_oc != NULL)		HSH_Kill(bo->stale_oc);	return (F_STP_DONE);}",21267
411,628,CVE-2011-3353,26,"void fuse_put_request(struct fuse_conn *fc, struct fuse_req *req){	if (atomic_dec_and_test(&req->count)) {		if (req->waiting)			atomic_dec(&fc->num_waiting);		if (req->stolen_file)			put_reserved_req(fc, req);		else			fuse_request_free(req);	}}",5601
931,1991,CVE-2016-4998,26,"compat_find_calc_match(struct xt_entry_match *m,		       const char *name,		       const struct ipt_ip *ip,		       int *size){	struct xt_match *match;	match = xt_request_find_match(NFPROTO_IPV4, m->u.user.name,				      m->u.user.revision);	if (IS_ERR(match)) {		duprintf(""compat_check_calc_match: `%s' not found\n"",			 m->u.user.name);		return PTR_ERR(match);	}	m->u.kernel.match = match;	*size += xt_compat_match_offset(match);	return 0;}",16557
268,3455,CVE-2016-9586,26,"static int test_string_formatting(void){  int errors = 0;  char buf[256];  curl_msnprintf(buf, sizeof(buf), ""%0*d%s"", 2, 9, ""foo"");  errors += string_check(buf, ""09foo"");  curl_msnprintf(buf, sizeof(buf), ""%*.*s"", 5, 2, ""foo"");  errors += string_check(buf, ""   fo"");  curl_msnprintf(buf, sizeof(buf), ""%*.*s"", 2, 5, ""foo"");  errors += string_check(buf, ""foo"");  curl_msnprintf(buf, sizeof(buf), ""%*.*s"", 0, 10, ""foo"");  errors += string_check(buf, ""foo"");  curl_msnprintf(buf, sizeof(buf), ""%-10s"", ""foo"");  errors += string_check(buf, ""foo       "");  curl_msnprintf(buf, sizeof(buf), ""%10s"", ""foo"");  errors += string_check(buf, ""       foo"");  curl_msnprintf(buf, sizeof(buf), ""%*.*s"", -10, -10, ""foo"");  errors += string_check(buf, ""foo       "");  if(!errors)    printf(""All curl_mprintf() strings tests OK!\n"");  else    printf(""Some curl_mprintf() string tests Failed!\n"");  return errors;}",26240
343,674,CVE-2011-2517,26,"static int nl80211_msg_put_channel(struct sk_buff *msg,				   struct ieee80211_channel *chan){	NLA_PUT_U32(msg, NL80211_FREQUENCY_ATTR_FREQ,		    chan->center_freq);	if (chan->flags & IEEE80211_CHAN_DISABLED)		NLA_PUT_FLAG(msg, NL80211_FREQUENCY_ATTR_DISABLED);	if (chan->flags & IEEE80211_CHAN_PASSIVE_SCAN)		NLA_PUT_FLAG(msg, NL80211_FREQUENCY_ATTR_PASSIVE_SCAN);	if (chan->flags & IEEE80211_CHAN_NO_IBSS)		NLA_PUT_FLAG(msg, NL80211_FREQUENCY_ATTR_NO_IBSS);	if (chan->flags & IEEE80211_CHAN_RADAR)		NLA_PUT_FLAG(msg, NL80211_FREQUENCY_ATTR_RADAR);	NLA_PUT_U32(msg, NL80211_FREQUENCY_ATTR_MAX_TX_POWER,		    DBM_TO_MBM(chan->max_power));	return 0; nla_put_failure:	return -ENOBUFS;}",6573
566,682,CVE-2011-2517,26,"static int nl80211_pre_doit(struct genl_ops *ops, struct sk_buff *skb,			    struct genl_info *info){	struct cfg80211_registered_device *rdev;	struct net_device *dev;	int err;	int rtnl = ops->internal_flags & NL80211_FLAG_NEED_RTNL;	if (rtnl)		rtnl_lock();	if (ops->internal_flags & NL80211_FLAG_NEED_WIPHY) {		rdev = cfg80211_get_dev_from_info(info);		if (IS_ERR(rdev)) {			if (rtnl)				rtnl_unlock();			return PTR_ERR(rdev);		}		info->user_ptr[0] = rdev;	} else if (ops->internal_flags & NL80211_FLAG_NEED_NETDEV) {		err = get_rdev_dev_by_info_ifindex(info, &rdev, &dev);		if (err) {			if (rtnl)				rtnl_unlock();			return err;		}		if (ops->internal_flags & NL80211_FLAG_CHECK_NETDEV_UP &&		    !netif_running(dev)) {			cfg80211_unlock_rdev(rdev);			dev_put(dev);			if (rtnl)				rtnl_unlock();			return -ENETDOWN;		}		info->user_ptr[0] = rdev;		info->user_ptr[1] = dev;	}	return 0;}",6581
792,2950,CVE-2017-8062,26,"static int dw2102_frontend_attach(struct dvb_usb_adapter *d){	if (dw2102_properties.i2c_algo == &dw2102_serit_i2c_algo) {		 		d->fe_adap[0].fe = dvb_attach(si21xx_attach, &serit_sp1511lhb_config,					&d->dev->i2c_adap);		if (d->fe_adap[0].fe != NULL) {			d->fe_adap[0].fe->ops.set_voltage = dw210x_set_voltage;			info(""Attached si21xx!"");			return 0;		}	}	if (dw2102_properties.i2c_algo == &dw2102_earda_i2c_algo) {		d->fe_adap[0].fe = dvb_attach(stv0288_attach, &earda_config,					&d->dev->i2c_adap);		if (d->fe_adap[0].fe != NULL) {			if (dvb_attach(stb6000_attach, d->fe_adap[0].fe, 0x61,					&d->dev->i2c_adap)) {				d->fe_adap[0].fe->ops.set_voltage = dw210x_set_voltage;				info(""Attached stv0288!"");				return 0;			}		}	}	if (dw2102_properties.i2c_algo == &dw2102_i2c_algo) {		 		d->fe_adap[0].fe = dvb_attach(stv0299_attach, &sharp_z0194a_config,					&d->dev->i2c_adap);		if (d->fe_adap[0].fe != NULL) {			d->fe_adap[0].fe->ops.set_voltage = dw210x_set_voltage;			info(""Attached stv0299!"");			return 0;		}	}	return -EIO;}",21427
556,620,CVE-2011-3353,26,"static int fuse_dev_fasync(int fd, struct file *file, int on){	struct fuse_conn *fc = fuse_get_conn(file);	if (!fc)		return -EPERM;	 	return fasync_helper(fd, file, on, &fc->fasync);}",5593
6,3732,CVE-2016-1583,26,"ecryptfs_unlocked_ioctl(struct file *file, unsigned int cmd, unsigned long arg){	struct file *lower_file = ecryptfs_file_to_lower(file);	long rc = -ENOTTY;	if (!lower_file->f_op->unlocked_ioctl)		return rc;	switch (cmd) {	case FITRIM:	case FS_IOC_GETFLAGS:	case FS_IOC_SETFLAGS:	case FS_IOC_GETVERSION:	case FS_IOC_SETVERSION:		rc = lower_file->f_op->unlocked_ioctl(lower_file, cmd, arg);		fsstack_copy_attr_all(file_inode(file), file_inode(lower_file));		return rc;	default:		return rc;	}}",28437
761,1092,CVE-2013-2850,26,"static int iscsi_check_value(struct iscsi_param *param, char *value){	char *comma_ptr = NULL;	if (!strcmp(value, REJECT)) {		if (!strcmp(param->name, IFMARKINT) ||		    !strcmp(param->name, OFMARKINT)) {			 			SET_PSTATE_REJECT(param);			return 0;		}		pr_err(""Received %s=%s\n"", param->name, value);		return -1;	}	if (!strcmp(value, IRRELEVANT)) {		pr_debug(""Received %s=%s\n"", param->name, value);		SET_PSTATE_IRRELEVANT(param);		return 0;	}	if (!strcmp(value, NOTUNDERSTOOD)) {		if (!IS_PSTATE_PROPOSER(param)) {			pr_err(""Received illegal offer %s=%s\n"",				param->name, value);			return -1;		} 		pr_err(""Standard iSCSI key \""%s\"" cannot be answered""			"" with \""%s\"", protocol error.\n"", param->name, value);		return -1;	}	do {		comma_ptr = NULL;		comma_ptr = strchr(value, ',');		if (comma_ptr && !IS_TYPE_VALUE_LIST(param)) {			pr_err(""Detected value separator \"",\"", but""				"" key \""%s\"" does not allow a value list,""				"" protocol error.\n"", param->name);			return -1;		}		if (comma_ptr)			*comma_ptr = '\0';		if (strlen(value) > VALUE_MAXLEN) {			pr_err(""Value for key \""%s\"" exceeds %d,""				"" protocol error.\n"", param->name,				VALUE_MAXLEN);			return -1;		}		if (IS_TYPE_BOOL_AND(param) || IS_TYPE_BOOL_OR(param)) {			if (iscsi_check_intean_value(param, value) < 0)				return -1;		} else if (IS_TYPE_NUMBER(param)) {			if (iscsi_check_numerical_value(param, value) < 0)				return -1;		} else if (IS_TYPE_NUMBER_RANGE(param)) {			if (iscsi_check_numerical_range_value(param, value) < 0)				return -1;		} else if (IS_TYPE_STRING(param) || IS_TYPE_VALUE_LIST(param)) {			if (iscsi_check_string_or_list_value(param, value) < 0)				return -1;		} else {			pr_err(""Huh? 0x%02x\n"", param->type);			return -1;		}		if (comma_ptr)			*comma_ptr++ = ',';		value = comma_ptr;	} while (value);	return 0;}",8494
229,2781,CVE-2017-9994,26,"const int *get_submv_prob(int left, int top, int is_vp7){    if (is_vp7)        return vp7_submv_prob;    if (left == top)        return vp8_submv_prob[4 - !!left];    if (!top)        return vp8_submv_prob[2];    return vp8_submv_prob[1 - !!left];}",20666
461,2772,CVE-2017-10671,26,"init_mime( void )    {    int i;         qsort( enc_tab, n_enc_tab, sizeof(*enc_tab), ext_compare );    qsort( typ_tab, n_typ_tab, sizeof(*typ_tab), ext_compare );         for ( i = 0; i < n_enc_tab; ++i )	{	enc_tab[i].ext_len = strlen( enc_tab[i].ext );	enc_tab[i].val_len = strlen( enc_tab[i].val );	}    for ( i = 0; i < n_typ_tab; ++i )	{	typ_tab[i].ext_len = strlen( typ_tab[i].ext );	typ_tab[i].val_len = strlen( typ_tab[i].val );	}    }",20620
949,1830,CVE-2016-8658,26,static void init_vif_event(struct brcmf_cfg80211_vif_event *event){	init_waitqueue_head(&event->vif_wq);	spin_lock_init(&event->vif_event_lock);},15478
547,3518,CVE-2018-20855,26,"static void destroy_user_rq(struct mlx5_ib_dev *dev, struct ib_pd *pd,			    struct mlx5_ib_rwq *rwq){	struct mlx5_ib_ucontext *context;	if (rwq->create_flags & MLX5_IB_WQ_FLAGS_DELAY_DROP)		atomic_dec(&dev->delay_drop.rqs_cnt);	context = to_mucontext(pd->uobject->context);	mlx5_ib_db_unmap_user(context, &rwq->db);	if (rwq->umem)		ib_umem_release(rwq->umem);}",27546
323,3000,CVE-2017-5548,26,static void atusb_free_urbs(struct atusb *atusb){	struct urb *urb;	while (1) {		urb = usb_get_from_anchor(&atusb->idle_urbs);		if (!urb)			break;		kfree_skb(urb->context);		usb_free_urb(urb);	}},22039
980,2222,CVE-2016-2324,26,"static inline void add_to_write_order(struct object_entry **wo,			       unsigned int *endp,			       struct object_entry *e){	if (e->filled)		return;	wo[(*endp)++] = e;	e->filled = 1;}",17642
617,1995,CVE-2016-4998,26,static int icmp_checkentry(const struct xt_mtchk_param *par){	const struct ipt_icmp *icmpinfo = par->matchinfo;	 	return (icmpinfo->invflags & ~IPT_ICMP_INV) ? -EINVAL : 0;},16561
578,543,CVE-2012-3400,26,"static struct dentry *udf_mount(struct file_system_type *fs_type,		      int flags, const char *dev_name, void *data){	return mount_bdev(fs_type, flags, dev_name, data, udf_fill_super);}",3128
441,2358,CVE-2016-2324,26,void mark_tree_uninteresting(struct tree *tree){	struct object *obj;	if (!tree)		return;	obj = &tree->object;	if (obj->flags & UNINTERESTING)		return;	obj->flags |= UNINTERESTING;	mark_tree_contents_uninteresting(tree);},17778
916,217,CVE-2014-9427,26,static void sapi_cgi_flush(void *server_context){	if (fflush(stdout) == EOF) {		php_handle_aborted_connection();	}},1175
869,3499,CVE-2018-21010,26,"static void sycc_to_rgb(int offset, int upb, int y, int cb, int cr,                        int *out_r, int *out_g, int *out_b){    int r, g, b;    cb -= offset;    cr -= offset;    r = y + (int)(1.402 * (float)cr);    if (r < 0) {        r = 0;    } else if (r > upb) {        r = upb;    }    *out_r = r;    g = y - (int)(0.344 * (float)cb + 0.714 * (float)cr);    if (g < 0) {        g = 0;    } else if (g > upb) {        g = upb;    }    *out_g = g;    b = y + (int)(1.772 * (float)cb);    if (b < 0) {        b = 0;    } else if (b > upb) {        b = upb;    }    *out_b = b;}",27440
305,3328,CVE-2018-1091,26,"static int set_user_dscr(struct task_struct *task, unsigned long dscr){	return -EIO;}",25544
465,3124,CVE-2016-7970,26,"static inline int blur_func(int p4, int p3, int p2, int p1, int z0,                                int n1, int n2, int n3, int n4, const int c[]){    p1 -= z0;    p2 -= z0;    p3 -= z0;    p4 -= z0;    n1 -= z0;    n2 -= z0;    n3 -= z0;    n4 -= z0;    return (((p1 + n1) * c[0] +             (p2 + n2) * c[1] +             (p3 + n3) * c[2] +             (p4 + n4) * c[3] +             0x8000) >> 16) + z0;}",22782
567,1405,CVE-2012-2119,26,"static int macvtap_init(void){	int err;	err = alloc_chrdev_region(&macvtap_major, 0,				MACVTAP_NUM_DEVS, ""macvtap"");	if (err)		goto out1;	cdev_init(&macvtap_cdev, &macvtap_fops);	err = cdev_add(&macvtap_cdev, macvtap_major, MACVTAP_NUM_DEVS);	if (err)		goto out2;	macvtap_class = class_create(THIS_MODULE, ""macvtap"");	if (IS_ERR(macvtap_class)) {		err = PTR_ERR(macvtap_class);		goto out3;	}	err = register_netdevice_notifier(&macvtap_notifier_block);	if (err)		goto out4;	err = macvlan_link_register(&macvtap_link_ops);	if (err)		goto out5;	return 0;out5:	unregister_netdevice_notifier(&macvtap_notifier_block);out4:	class_unregister(macvtap_class);out3:	cdev_del(&macvtap_cdev);out2:	unregister_chrdev_region(macvtap_major, MACVTAP_NUM_DEVS);out1:	return err;}",10011
513,3272,CVE-2018-12326,26,"static void parseRedisUri(const char *uri) {    const char *scheme = ""redis://"";    const char *curr = uri;    const char *end = uri + strlen(uri);    const char *userinfo, *username, *port, *host, *path;         if (strncasecmp(scheme, curr, strlen(scheme))) {        fprintf(stderr,""Invalid URI scheme\n"");        exit(1);    }    curr += strlen(scheme);    if (curr == end) return;         if ((userinfo = strchr(curr,'@'))) {        if ((username = strchr(curr, ':')) && username < userinfo) {                         curr = username + 1;        }        config.auth = percentDecode(curr, userinfo - curr);        curr = userinfo + 1;    }    if (curr == end) return;         path = strchr(curr, '/');    if (*curr != '/') {        host = path ? path - 1 : end;        if ((port = strchr(curr, ':'))) {            config.hostport = atoi(port + 1);            host = port - 1;        }        config.hostip = sdsnewlen(curr, host - curr + 1);    }    curr = path ? path + 1 : end;    if (curr == end) return;         config.dbnum = atoi(curr);}",25099
868,2036,CVE-2016-4568,26,"int vb2_ioctl_create_bufs(struct file *file, void *priv,			  struct v4l2_create_buffers *p){	struct video_device *vdev = video_devdata(file);	int res = vb2_verify_memory_type(vdev->queue, p->memory,			p->format.type);	p->index = vdev->queue->num_buffers;	 	if (p->count == 0)		return res != -EBUSY ? res : 0;	if (res)		return res;	if (vb2_queue_is_busy(vdev, file))		return -EBUSY;	res = vb2_create_bufs(vdev->queue, p);	if (res == 0)		vdev->queue->owner = file->private_data;	return res;}",16738
585,283,CVE-2017-6542,26,"static void ssh_pkt_addstring_start(struct Packet *pkt){    ssh_pkt_adduint32(pkt, 0);    pkt->savedpos = pkt->length;}",1347
817,3656,CVE-2016-10764,26,"static int cqspi_suspend(struct device *dev){	struct cqspi_st *cqspi = dev_get_drvdata(dev);	cqspi_controller_enable(cqspi, 0);	return 0;}",28115
387,238,CVE-2018-10184,26,"static void h2_release(struct connection *conn){	struct h2c *h2c = conn->mux_ctx;	LIST_DEL(&conn->list);	if (h2c) {		hpack_dht_free(h2c->ddht);		HA_SPIN_LOCK(BUF_WQ_LOCK, &buffer_wq_lock);		LIST_DEL(&h2c->buf_wait.list);		HA_SPIN_UNLOCK(BUF_WQ_LOCK, &buffer_wq_lock);		h2_release_buf(h2c, &h2c->dbuf);		h2_release_buf(h2c, &h2c->mbuf);		if (h2c->task) {			h2c->task->context = NULL;			task_wakeup(h2c->task, TASK_WOKEN_OTHER);			h2c->task = NULL;		}		pool_free(pool_head_h2c, h2c);	}	conn->mux = NULL;	conn->mux_ctx = NULL;	conn_stop_tracking(conn);	conn_full_close(conn);	if (conn->destroy_cb)		conn->destroy_cb(conn);	conn_free(conn);}",1259
238,795,CVE-2013-6381,26,"static void qeth_clean_channel(struct qeth_channel *channel){	int cnt;	QETH_DBF_TEXT(SETUP, 2, ""freech"");	for (cnt = 0; cnt < QETH_CMD_BUFFER_NO; cnt++)		kfree(channel->iob[cnt].data);}",7224
444,2710,CVE-2017-16526,26,"void uwbd_event_queue(struct uwb_event *evt){	struct uwb_rc *rc = evt->rc;	unsigned long flags;	spin_lock_irqsave(&rc->uwbd.event_list_lock, flags);	if (rc->uwbd.pid != 0) {		list_add(&evt->list_node, &rc->uwbd.event_list);		wake_up_all(&rc->uwbd.wq);	} else {		__uwb_rc_put(evt->rc);		if (evt->type == UWB_EVT_TYPE_NOTIF)			kfree(evt->notif.rceb);		kfree(evt);	}	spin_unlock_irqrestore(&rc->uwbd.event_list_lock, flags);	return;}",19883
726,3430,CVE-2017-15128,26,"static void prep_compound_gigantic_page(struct page *page, unsigned int order){	int i;	int nr_pages = 1 << order;	struct page *p = page + 1;	 	set_compound_order(page, order);	__ClearPageReserved(page);	__SetPageHead(page);	for (i = 1; i < nr_pages; i++, p = mem_map_next(p, page, i)) {		 		__ClearPageReserved(p);		set_page_count(p, 0);		set_compound_head(p, page);	}	atomic_set(compound_mapcount_ptr(page), -1);}",26190
447,951,CVE-2013-4591,26,static void nfs4_free_closedata(void *data){	struct nfs4_closedata *calldata = data;	struct nfs4_state_owner *sp = calldata->state->owner;	struct super_block *sb = calldata->state->inode->i_sb;	if (calldata->roc)		pnfs_roc_release(calldata->state->inode);	nfs4_put_open_state(calldata->state);	nfs_free_seqid(calldata->arg.seqid);	nfs4_put_state_owner(sp);	nfs_sb_deactive_async(sb);	kfree(calldata);},7548
690,3792,CVE-2013-0904,26,    void setHasMarginBeforeQuirk(int b) { m_hasMarginBeforeQuirk = b; },29452
777,985,CVE-2013-4591,26,"static int nfs4_proc_lookup_common(struct rpc_clnt **clnt, struct inode *dir,				   struct qstr *name, struct nfs_fh *fhandle,				   struct nfs_fattr *fattr){	struct nfs4_exception exception = { };	struct rpc_clnt *client = *clnt;	int err;	do {		err = _nfs4_proc_lookup(client, dir, name, fhandle, fattr);		switch (err) {		case -NFS4ERR_BADNAME:			err = -ENOENT;			goto out;		case -NFS4ERR_MOVED:			err = nfs4_get_referral(client, dir, name, fattr, fhandle);			goto out;		case -NFS4ERR_WRONGSEC:			err = -EPERM;			if (client != *clnt)				goto out;			client = nfs4_create_sec_client(client, dir, name);			if (IS_ERR(client))				return PTR_ERR(client);			exception.retry = 1;			break;		default:			err = nfs4_handle_exception(NFS_SERVER(dir), err, &exception);		}	} while (exception.retry);out:	if (err == 0)		*clnt = client;	else if (client != *clnt)		rpc_shutdown_client(client);	return err;}",7582
216,3112,CVE-2016-10012,26,"server_accept_inetd(int *sock_in, int *sock_out){	int fd;	startup_pipe = -1;	if (rexeced_flag) {		close(REEXEC_CONFIG_PASS_FD);		*sock_in = *sock_out = dup(STDIN_FILENO);		if (!debug_flag) {			startup_pipe = dup(REEXEC_STARTUP_PIPE_FD);			close(REEXEC_STARTUP_PIPE_FD);		}	} else {		*sock_in = dup(STDIN_FILENO);		*sock_out = dup(STDOUT_FILENO);	}	 	if ((fd = open(_PATH_DEVNULL, O_RDWR, 0)) != -1) {		dup2(fd, STDIN_FILENO);		dup2(fd, STDOUT_FILENO);		if (!log_stderr)			dup2(fd, STDERR_FILENO);		if (fd > (log_stderr ? STDERR_FILENO : STDOUT_FILENO))			close(fd);	}	debug(""inetd sockets after dupping: %d, %d"", *sock_in, *sock_out);}",22630
437,2837,CVE-2017-8068,26,"static inline void pegasus_reset_wol(struct net_device *dev){	struct ethtool_wolinfo wol;	memset(&wol, 0, sizeof wol);	(void) pegasus_set_wol(dev, &wol);}",21314
34,2187,CVE-2016-4301,26,"mtree_atol8(char **p){	int	l, limit, last_digit_limit;	int digit, base;	base = 8;	limit = INT64_MAX / base;	last_digit_limit = INT64_MAX % base;	l = 0;	digit = **p - '0';	while (digit >= 0 && digit < base) {		if (l>limit || (l == limit && digit > last_digit_limit)) {			l = INT64_MAX;  			break;		}		l = (l * base) + digit;		digit = *++(*p) - '0';	}	return (l);}",17095
53,1759,CVE-2016-9793,26,"int __sk_mem_schedule(struct sock *sk, int size, int kind){	struct proto *prot = sk->sk_prot;	int amt = sk_mem_pages(size);	long allocated;	sk->sk_forward_alloc += amt * SK_MEM_QUANTUM;	allocated = sk_memory_allocated_add(sk, amt);	if (mem_cgroup_sockets_enabled && sk->sk_memcg &&	    !mem_cgroup_charge_skmem(sk->sk_memcg, amt))		goto suppress_allocation;	 	if (allocated <= sk_prot_mem_limits(sk, 0)) {		sk_leave_memory_pressure(sk);		return 1;	}	 	if (allocated > sk_prot_mem_limits(sk, 1))		sk_enter_memory_pressure(sk);	 	if (allocated > sk_prot_mem_limits(sk, 2))		goto suppress_allocation;	 	if (kind == SK_MEM_RECV) {		if (atomic_read(&sk->sk_rmem_alloc) < prot->sysctl_rmem[0])			return 1;	} else {  		if (sk->sk_type == SOCK_STREAM) {			if (sk->sk_wmem_queued < prot->sysctl_wmem[0])				return 1;		} else if (atomic_read(&sk->sk_wmem_alloc) <			   prot->sysctl_wmem[0])				return 1;	}	if (sk_has_memory_pressure(sk)) {		int alloc;		if (!sk_under_memory_pressure(sk))			return 1;		alloc = sk_sockets_allocated_read_positive(sk);		if (sk_prot_mem_limits(sk, 2) > alloc *		    sk_mem_pages(sk->sk_wmem_queued +				 atomic_read(&sk->sk_rmem_alloc) +				 sk->sk_forward_alloc))			return 1;	}suppress_allocation:	if (kind == SK_MEM_SEND && sk->sk_type == SOCK_STREAM) {		sk_stream_moderate_sndbuf(sk);		 		if (sk->sk_wmem_queued + size >= sk->sk_sndbuf)			return 1;	}	trace_sock_exceed_buf_limit(sk, prot, allocated);	 	sk->sk_forward_alloc -= amt * SK_MEM_QUANTUM;	sk_memory_allocated_sub(sk, amt);	if (mem_cgroup_sockets_enabled && sk->sk_memcg)		mem_cgroup_uncharge_skmem(sk->sk_memcg, amt);	return 0;}",15043
797,1400,CVE-2012-2119,26,"static void macvtap_del_queues(struct net_device *dev){	struct macvlan_dev *vlan = netdev_priv(dev);	struct macvtap_queue *q, *qlist[MAX_MACVTAP_QUEUES];	int i, j = 0;	 	spin_lock(&macvtap_lock);	for (i = 0; i < MAX_MACVTAP_QUEUES && vlan->numvtaps; i++) {		q = rcu_dereference_protected(vlan->taps[i],					      lockdep_is_held(&macvtap_lock));		if (q) {			qlist[j++] = q;			RCU_INIT_POINTER(vlan->taps[i], NULL);			RCU_INIT_POINTER(q->vlan, NULL);			vlan->numvtaps--;		}	}	BUG_ON(vlan->numvtaps != 0);	 	vlan->numvtaps = MAX_MACVTAP_QUEUES;	spin_unlock(&macvtap_lock);	synchronize_rcu();	for (--j; j >= 0; j--)		sock_put(&qlist[j]->sk);}",10006
766,2249,CVE-2016-2324,26,static int pack_options_allow_reuse(void){	return allow_ofs_delta;},17669
546,3113,CVE-2016-10012,26,"server_listen(void){	int ret, listen_sock, on = 1;	struct addrinfo *ai;	char ntop[NI_MAXHOST], strport[NI_MAXSERV];	for (ai = options.listen_addrs; ai; ai = ai->ai_next) {		if (ai->ai_family != AF_INET && ai->ai_family != AF_INET6)			continue;		if (num_listen_socks >= MAX_LISTEN_SOCKS)			fatal(""Too many listen sockets. ""			    ""Enlarge MAX_LISTEN_SOCKS"");		if ((ret = getnameinfo(ai->ai_addr, ai->ai_addrlen,		    ntop, sizeof(ntop), strport, sizeof(strport),		    NI_NUMERICHOST|NI_NUMERICSERV)) != 0) {			error(""getnameinfo failed: %.100s"",			    ssh_gai_strerror(ret));			continue;		}		 		listen_sock = socket(ai->ai_family, ai->ai_socktype,		    ai->ai_protocol);		if (listen_sock < 0) {			 			verbose(""socket: %.100s"", strerror(errno));			continue;		}		if (set_nonblock(listen_sock) == -1) {			close(listen_sock);			continue;		}		 		if (setsockopt(listen_sock, SOL_SOCKET, SO_REUSEADDR,		    &on, sizeof(on)) == -1)			error(""setsockopt SO_REUSEADDR: %s"", strerror(errno));		debug(""Bind to port %s on %s."", strport, ntop);		 		if (bind(listen_sock, ai->ai_addr, ai->ai_addrlen) < 0) {			error(""Bind to port %s on %s failed: %.200s."",			    strport, ntop, strerror(errno));			close(listen_sock);			continue;		}		listen_socks[num_listen_socks] = listen_sock;		num_listen_socks++;		 		if (listen(listen_sock, SSH_LISTEN_BACKLOG) < 0)			fatal(""listen on [%s]:%s: %.100s"",			    ntop, strport, strerror(errno));		logit(""Server listening on %s port %s."", ntop, strport);	}	freeaddrinfo(options.listen_addrs);	if (!num_listen_socks)		fatal(""Cannot bind any address."");}",22631
551,1785,CVE-2016-9793,26,static void sock_def_wakeup(struct sock *sk){	struct socket_wq *wq;	rcu_read_lock();	wq = rcu_dereference(sk->sk_wq);	if (skwq_has_sleeper(wq))		wake_up_interruptible_all(&wq->wait);	rcu_read_unlock();},15069
613,3187,CVE-2018-17942,26,"main (int argc, char *argv[]){  test_vasnprintf ();  test_asnprintf ();  return 0;}",23594
470,1031,CVE-2013-4588,26,int ip_vs_get_debug_level(void){	return sysctl_ip_vs_debug_level;},7628
401,3094,CVE-2016-10012,26,"option_clear_or_none(const char *o){	return o == NULL || strcasecmp(o, ""none"") == 0;}",22612
494,2996,CVE-2017-6435,26,"static int *plist_utf8_to_utf16(char *unistr, long size, long *items_read, long *items_written){	int *outbuf = (int*)malloc(((size*2)+1)*sizeof(int));	int p = 0;	long i = 0;	unsigned char c0;	unsigned char c1;	unsigned char c2;	unsigned char c3;	int w;	while (i < size) {		c0 = unistr[i];		c1 = (i < size-1) ? unistr[i+1] : 0;		c2 = (i < size-2) ? unistr[i+2] : 0;		c3 = (i < size-3) ? unistr[i+3] : 0;		if ((c0 >= 0xF0) && (i < size-3) && (c1 >= 0x80) && (c2 >= 0x80) && (c3 >= 0x80)) {			w = ((((c0 & 7) << 18) + ((c1 & 0x3F) << 12) + ((c2 & 0x3F) << 6) + (c3 & 0x3F)) & 0x1FFFFF) - 0x010000;			outbuf[p++] = 0xD800 + (w >> 10);			outbuf[p++] = 0xDC00 + (w & 0x3FF);			i+=4;		} else if ((c0 >= 0xE0) && (i < size-2) && (c1 >= 0x80) && (c2 >= 0x80)) {			outbuf[p++] = ((c2 & 0x3F) + ((c1 & 3) << 6)) + (((c1 >> 2) & 15) << 8) + ((c0 & 15) << 12);			i+=3;		} else if ((c0 >= 0xC0) && (i < size-1) && (c1 >= 0x80)) {			outbuf[p++] = ((c1 & 0x3F) + ((c0 & 3) << 6)) + (((c0 >> 2) & 7) << 8);			i+=2;		} else if (c0 < 0x80) {			outbuf[p++] = c0;			i+=1;		} else {			PLIST_BIN_ERR(""%s: invalid utf8 sequence in string at index %lu\n"", __func__, i);			break;		}	}	if (items_read) {		*items_read = i;	}	if (items_written) {		*items_written = p;	}	outbuf[p] = 0;	return outbuf;}",21798
568,519,CVE-2012-6711,26,"set_ppid (){  char namebuf[INT_STRLEN_BOUND(pid_t) + 1], *name;  SHELL_VAR *temp_var;  name = inttostr (getppid (), namebuf, sizeof(namebuf));  temp_var = find_variable (""PPID"");  if (temp_var)    VUNSETATTR (temp_var, (att_readonly | att_exported));  temp_var = bind_variable (""PPID"", name, 0);  VSETATTR (temp_var, (att_readonly | att_integer));}",2559
464,1504,CVE-2014-3183,26,"static void logi_dj_recv_destroy_djhid_device(struct dj_receiver_dev *djrcv_dev,						struct dj_report *dj_report){	 	struct dj_device *dj_dev;	unsigned long flags;	spin_lock_irqsave(&djrcv_dev->lock, flags);	dj_dev = djrcv_dev->paired_dj_devices[dj_report->device_index];	djrcv_dev->paired_dj_devices[dj_report->device_index] = NULL;	spin_unlock_irqrestore(&djrcv_dev->lock, flags);	if (dj_dev != NULL) {		hid_destroy_device(dj_dev->hdev);		kfree(dj_dev);	} else {		dev_err(&djrcv_dev->hdev->dev, ""%s: can't destroy a NULL device\n"",			__func__);	}}",11499
302,3365,CVE-2017-18222,26,"int hns_ppe_init(struct dsaf_device *dsaf_dev){	int ret;	int i;	for (i = 0; i < HNS_PPE_COM_NUM; i++) {		ret = hns_ppe_common_get_cfg(dsaf_dev, i);		if (ret)			goto get_cfg_fail;		ret = hns_rcb_common_get_cfg(dsaf_dev, i);		if (ret)			goto get_cfg_fail;		hns_ppe_get_cfg(dsaf_dev->ppe_common[i]);		ret = hns_rcb_get_cfg(dsaf_dev->rcb_common[i]);		if (ret)			goto get_cfg_fail;	}	for (i = 0; i < HNS_PPE_COM_NUM; i++)		hns_ppe_reset_common(dsaf_dev, i);	return 0;get_cfg_fail:	for (i = 0; i < HNS_PPE_COM_NUM; i++) {		hns_rcb_common_free_cfg(dsaf_dev, i);		hns_ppe_common_free_cfg(dsaf_dev, i);	}	return ret;}",25806
271,2988,CVE-2017-7541,26,brcmf_get_netinfo_array(struct brcmf_pno_scanresults_le *pfn_v1){	struct brcmf_pno_scanresults_v2_le *pfn_v2;	struct brcmf_pno_net_info_le *netinfo;	switch (pfn_v1->version) {	default:		WARN_ON(1);		 	case cpu_to_le32(1):		netinfo = (struct brcmf_pno_net_info_le *)(pfn_v1 + 1);		break;	case cpu_to_le32(2):		pfn_v2 = (struct brcmf_pno_scanresults_v2_le *)pfn_v1;		netinfo = (struct brcmf_pno_net_info_le *)(pfn_v2 + 1);		break;	}	return netinfo;},21553
889,1834,CVE-2016-8633,26,"static void __fwnet_broadcast_stop(struct fwnet_device *dev){	unsigned u;	if (dev->broadcast_state != FWNET_BROADCAST_ERROR) {		for (u = 0; u < FWNET_ISO_PAGE_COUNT; u++)			kunmap(dev->broadcast_rcv_buffer.pages[u]);		fw_iso_buffer_destroy(&dev->broadcast_rcv_buffer, dev->card);	}	if (dev->broadcast_rcv_context) {		fw_iso_context_destroy(dev->broadcast_rcv_context);		dev->broadcast_rcv_context = NULL;	}	kfree(dev->broadcast_rcv_buffer_ptrs);	dev->broadcast_rcv_buffer_ptrs = NULL;	dev->broadcast_state = FWNET_BROADCAST_ERROR;}",15568
791,105,CVE-2013-4282,26,"static void reds_mig_started(void){    spice_info(NULL);    spice_assert(reds->mig_spice);    reds->mig_inprogress = TRUE;    reds->mig_wait_connect = TRUE;    core->timer_start(reds->mig_timer, MIGRATE_TIMEOUT);}",415
51,2997,CVE-2017-5548,26,"static int atusb_alloc_urbs(struct atusb *atusb, int n){	struct urb *urb;	while (n) {		urb = usb_alloc_urb(0, GFP_KERNEL);		if (!urb) {			atusb_free_urbs(atusb);			return -ENOMEM;		}		usb_anchor_urb(urb, &atusb->idle_urbs);		n--;	}	return 0;}",22036
1002,2785,CVE-2017-9994,26,"static void inv_predict_1(int *p, const int *p_l, const int *p_tl,                          const int *p_t, const int *p_tr){    AV_COPY32(p, p_l);}",20670
87,72,CVE-2019-15937,26,"static void rpc_lookup_req(int prog, int ver){	int data[16];	data[0] = 0; data[1] = 0;	 	data[2] = 0; data[3] = 0;	 	data[4] = htonl(prog);	data[5] = htonl(ver);	data[6] = htonl(17);	 	data[7] = 0;	rpc_req(PROG_PORTMAP, PORTMAP_GETPORT, data, 8);}",303
150,1486,CVE-2014-3185,26,"static int whiteheat_tiocmset(struct tty_struct *tty,			       unsigned int set, unsigned int clear){	struct usb_serial_port *port = tty->driver_data;	struct whiteheat_private *info = usb_get_serial_port_data(port);	if (set & TIOCM_RTS)		info->mcr |= UART_MCR_RTS;	if (set & TIOCM_DTR)		info->mcr |= UART_MCR_DTR;	if (clear & TIOCM_RTS)		info->mcr &= ~UART_MCR_RTS;	if (clear & TIOCM_DTR)		info->mcr &= ~UART_MCR_DTR;	firm_set_dtr(port, info->mcr & UART_MCR_DTR);	firm_set_rts(port, info->mcr & UART_MCR_RTS);	return 0;}",11481
834,3900,CVE-2018-18339,26,"const char* HiddenStateToString(int is_hidden) {  if (is_hidden) {    return ""hidden"";  } else {    return ""visible"";  }}",29969
416,617,CVE-2011-3353,26,"static int fuse_copy_page(struct fuse_copy_state *cs, struct page **pagep,			  unsigned offset, unsigned count, int zeroing){	int err;	struct page *page = *pagep;	if (page && zeroing && count < PAGE_SIZE)		clear_highpage(page);	while (count) {		if (cs->write && cs->pipebufs && page) {			return fuse_ref_page(cs, page, offset, count);		} else if (!cs->len) {			if (cs->move_pages && page &&			    offset == 0 && count == PAGE_SIZE) {				err = fuse_try_move_page(cs, pagep);				if (err <= 0)					return err;			} else {				err = fuse_copy_fill(cs);				if (err)					return err;			}		}		if (page) {			void *mapaddr = kmap_atomic(page, KM_USER0);			void *buf = mapaddr + offset;			offset += fuse_copy_do(cs, &buf, &count);			kunmap_atomic(mapaddr, KM_USER0);		} else			offset += fuse_copy_do(cs, NULL, &count);	}	if (page && !cs->write)		flush_dcache_page(page);	return 0;}",5590
385,3486,CVE-2019-12982,26,"dcchkstr(int size){	while( (strsize+size) > strmaxsize ) {		dcstr=realloc(dcstr,strmaxsize+DCSTRSIZE);		strmaxsize+=DCSTRSIZE;		dcptr=dcstr+strsize;	}}",26808
227,1727,CVE-2015-1333,26,"void __key_link(struct key *key, struct assoc_array_edit **_edit){	__key_get(key);	assoc_array_insert_set_object(*_edit, keyring_key_to_ptr(key));	assoc_array_apply_edit(*_edit);	*_edit = NULL;}",14032
43,684,CVE-2011-2517,26,"static int nl80211_put_iface_combinations(struct wiphy *wiphy,					  struct sk_buff *msg){	struct nlattr *nl_combis;	int i, j;	nl_combis = nla_nest_start(msg,				NL80211_ATTR_INTERFACE_COMBINATIONS);	if (!nl_combis)		goto nla_put_failure;	for (i = 0; i < wiphy->n_iface_combinations; i++) {		const struct ieee80211_iface_combination *c;		struct nlattr *nl_combi, *nl_limits;		c = &wiphy->iface_combinations[i];		nl_combi = nla_nest_start(msg, i + 1);		if (!nl_combi)			goto nla_put_failure;		nl_limits = nla_nest_start(msg, NL80211_IFACE_COMB_LIMITS);		if (!nl_limits)			goto nla_put_failure;		for (j = 0; j < c->n_limits; j++) {			struct nlattr *nl_limit;			nl_limit = nla_nest_start(msg, j + 1);			if (!nl_limit)				goto nla_put_failure;			NLA_PUT_U32(msg, NL80211_IFACE_LIMIT_MAX,				    c->limits[j].max);			if (nl80211_put_iftypes(msg, NL80211_IFACE_LIMIT_TYPES,						c->limits[j].types))				goto nla_put_failure;			nla_nest_end(msg, nl_limit);		}		nla_nest_end(msg, nl_limits);		if (c->beacon_int_infra_match)			NLA_PUT_FLAG(msg,				NL80211_IFACE_COMB_STA_AP_BI_MATCH);		NLA_PUT_U32(msg, NL80211_IFACE_COMB_NUM_CHANNELS,			    c->num_different_channels);		NLA_PUT_U32(msg, NL80211_IFACE_COMB_MAXNUM,			    c->max_interfaces);		nla_nest_end(msg, nl_combi);	}	nla_nest_end(msg, nl_combis);	return 0;nla_put_failure:	return -ENOBUFS;}",6583
754,3793,CVE-2012-5152,26,"   int ComputeConsumedBytes(int initial_bytes_enqueued,                           int initial_bytes_buffered) {    int byte_delta = bytes_enqueued_ - initial_bytes_enqueued;    int buffered_delta = algorithm_.bytes_buffered() - initial_bytes_buffered;    int consumed = byte_delta - buffered_delta;    CHECK_GE(consumed, 0);    return consumed;   }",29465
799,1873,CVE-2016-7425,26,"static void arcmsr_hbaD_request_device_map(struct AdapterControlBlock *acb){	struct MessageUnit_D *reg = acb->pmuD;	if (unlikely(atomic_read(&acb->rq_map_token) == 0) ||		((acb->acb_flags & ACB_F_BUS_RESET) != 0) ||		((acb->acb_flags & ACB_F_ABORT) != 0)) {		mod_timer(&acb->eternal_timer,			jiffies + msecs_to_jiffies(6 * HZ));	} else {		acb->fw_flag = FW_NORMAL;		if (atomic_read(&acb->ante_token_value) ==			atomic_read(&acb->rq_map_token)) {			atomic_set(&acb->rq_map_token, 16);		}		atomic_set(&acb->ante_token_value,			atomic_read(&acb->rq_map_token));		if (atomic_dec_and_test(&acb->rq_map_token)) {			mod_timer(&acb->eternal_timer, jiffies +				msecs_to_jiffies(6 * HZ));			return;		}		writel(ARCMSR_INBOUND_MESG0_GET_CONFIG,			reg->inbound_msgaddr0);		mod_timer(&acb->eternal_timer, jiffies +			msecs_to_jiffies(6 * HZ));	}}",15792
430,1813,CVE-2016-8658,26,void brcmf_free_vif(struct brcmf_cfg80211_vif *vif){	list_del(&vif->list);	kfree(vif);},15461
310,2047,CVE-2016-4568,26,"int vb2_qbuf(struct vb2_queue *q, struct v4l2_buffer *b){	if (vb2_fileio_is_active(q)) {		dprintk(1, ""file io in progress\n"");		return -EBUSY;	}	return vb2_internal_qbuf(q, b);}",16749
813,1060,CVE-2013-4512,26,"static int exitcode_proc_open(struct inode *inode, struct file *file){	return single_open(file, exitcode_proc_show, NULL);}",7761
524,2563,CVE-2016-1583,26,static inline int sched_debug(void){	return sched_debug_enabled;},18112
103,859,CVE-2013-6381,26,"static void qeth_get_trap_id(struct qeth_card *card, struct qeth_trap_id *tid){	unsigned long info = get_zeroed_page(GFP_KERNEL);	struct sysinfo_2_2_2 *info222 = (struct sysinfo_2_2_2 *)info;	struct sysinfo_3_2_2 *info322 = (struct sysinfo_3_2_2 *)info;	struct ccw_dev_id ccwid;	int level;	tid->chpid = card->info.chpid;	ccw_device_get_id(CARD_RDEV(card), &ccwid);	tid->ssid = ccwid.ssid;	tid->devno = ccwid.devno;	if (!info)		return;	level = stsi(NULL, 0, 0, 0);	if ((level >= 2) && (stsi(info222, 2, 2, 2) == 0))		tid->lparnr = info222->lpar_number;	if ((level >= 3) && (stsi(info322, 3, 2, 2) == 0)) {		EBCASC(info322->vm[0].name, sizeof(info322->vm[0].name));		memcpy(tid->vmname, info322->vm[0].name, sizeof(tid->vmname));	}	free_page(info);	return;}",7288
239,1976,CVE-2016-4998,26,"static int check_underflow(const struct arpt_entry *e){	const struct xt_entry_target *t;	unsigned int verdict;	if (!unconditional(&e->arp))		return false;	t = arpt_get_target_c(e);	if (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)		return false;	verdict = ((struct xt_standard_target *)t)->verdict;	verdict = -verdict - 1;	return verdict == NF_DROP || verdict == NF_ACCEPT;}",16542
269,1024,CVE-2013-4588,26,"static int ip_vs_genl_fill_stats(struct sk_buff *skb, int container_type,				 struct ip_vs_stats *stats){	struct nlattr *nl_stats = nla_nest_start(skb, container_type);	if (!nl_stats)		return -EMSGSIZE;	spin_lock_bh(&stats->lock);	NLA_PUT_U32(skb, IPVS_STATS_ATTR_CONNS, stats->ustats.conns);	NLA_PUT_U32(skb, IPVS_STATS_ATTR_INPKTS, stats->ustats.inpkts);	NLA_PUT_U32(skb, IPVS_STATS_ATTR_OUTPKTS, stats->ustats.outpkts);	NLA_PUT_U64(skb, IPVS_STATS_ATTR_INBYTES, stats->ustats.inbytes);	NLA_PUT_U64(skb, IPVS_STATS_ATTR_OUTBYTES, stats->ustats.outbytes);	NLA_PUT_U32(skb, IPVS_STATS_ATTR_CPS, stats->ustats.cps);	NLA_PUT_U32(skb, IPVS_STATS_ATTR_INPPS, stats->ustats.inpps);	NLA_PUT_U32(skb, IPVS_STATS_ATTR_OUTPPS, stats->ustats.outpps);	NLA_PUT_U32(skb, IPVS_STATS_ATTR_INBPS, stats->ustats.inbps);	NLA_PUT_U32(skb, IPVS_STATS_ATTR_OUTBPS, stats->ustats.outbps);	spin_unlock_bh(&stats->lock);	nla_nest_end(skb, nl_stats);	return 0;nla_put_failure:	spin_unlock_bh(&stats->lock);	nla_nest_cancel(skb, nl_stats);	return -EMSGSIZE;}",7621
111,3805,CVE-2014-7903,26,"  int GetScrollTop() {    return ExecuteScriptAndExtractInt(""document.scrollingElement.scrollTop"");  }",29492
76,17,CVE-2015-6806,26,"ReverseLineFeed(){  if (curr->w_y == curr->w_top)    {      MScrollV(curr, -1, curr->w_top, curr->w_bot, CURR_BCE);      LScrollV(&curr->w_layer, -1, curr->w_top, curr->w_bot, CURR_BCE);      LGotoPos(&curr->w_layer, curr->w_x, curr->w_y);    }  else if (curr->w_y > 0)    CursorUp(1);}",126
573,329,CVE-2010-2527,26,"  Clear_Display( void )  {    long  bitmap_size = (long)bit.pitch * bit.rows;    if ( bitmap_size < 0 )      bitmap_size = -bitmap_size;    memset( bit.buffer, 0, bitmap_size );  }",1808
729,1134,CVE-2013-2237,26,"static inline void pfkey_hdr_dup(struct sadb_msg *new,				 const struct sadb_msg *orig){	*new = *orig;}",8723
647,1764,CVE-2016-9793,26,"static void cred_to_ucred(struct pid *pid, const struct cred *cred,			  struct ucred *ucred){	ucred->pid = pid_vnr(pid);	ucred->uid = ucred->gid = -1;	if (cred) {		struct user_namespace *current_ns = current_user_ns();		ucred->uid = from_kuid_munged(current_ns, cred->euid);		ucred->gid = from_kgid_munged(current_ns, cred->egid);	}}",15048
382,3772,CVE-2012-2895,26,  void RunAllPendingInMessageLoops() {    loop_.RunAllPending();  },29208
480,1688,CVE-2015-3331,26,"static inline struct crypto_aes_ctx *aes_ctx(void *raw_ctx){	unsigned long addr = (unsigned long)raw_ctx;	unsigned long align = AESNI_ALIGN;	if (align <= crypto_tfm_ctx_alignment())		align = 1;	return (struct crypto_aes_ctx *)ALIGN(addr, align);}",13599
909,3858,CVE-2017-5122,26,  int GetMouseEventCountAndReset() {    int count = mouse_events_;    mouse_events_ = 0;    return count;  },29836
65,3453,CVE-2017-15128,26,"static int zone_spans_last_pfn(const struct zone *zone,			unsigned long start_pfn, unsigned long nr_pages){	unsigned long last_pfn = start_pfn + nr_pages - 1;	return zone_spans_pfn(zone, last_pfn);}",26213
15,216,CVE-2014-9427,26,"static void php_cgi_usage(char *argv0){	char *prog;	prog = strrchr(argv0, '/');	if (prog) {		prog++;	} else {		prog = ""php"";	}	php_printf(	""Usage: %s [-q] [-h] [-s] [-v] [-i] [-f <file>]\n""				""       %s <file> [args...]\n""				""  -a               Run interactively\n""				""  -b <address:port>|<port> Bind Path for external FASTCGI Server mode\n""				""  -C               Do not chdir to the script's directory\n""				""  -c <path>|<file> Look for php.ini file in this directory\n""				""  -n               No php.ini file will be used\n""				""  -d foo[=bar]     Define INI entry foo with value 'bar'\n""				""  -e               Generate extended information for debugger/profiler\n""				""  -f <file>        Parse <file>.  Implies `-q'\n""				""  -h               This help\n""				""  -i               PHP information\n""				""  -l               Syntax check only (lint)\n""				""  -m               Show compiled in modules\n""				""  -q               Quiet-mode.  Suppress HTTP Header output.\n""				""  -s               Display colour syntax highlighted source.\n""				""  -v               Version number\n""				""  -w               Display source with stripped comments and whitespace.\n""				""  -z <file>        Load Zend extension <file>.\n""				""  -T <count>       Measure execution time of script repeated <count> times.\n"",				prog, prog);}",1174
560,2544,CVE-2016-1583,26,static inline int normal_prio(struct task_struct *p){	int prio;	if (task_has_dl_policy(p))		prio = MAX_DL_PRIO-1;	else if (task_has_rt_policy(p))		prio = MAX_RT_PRIO-1 - p->rt_priority;	else		prio = __normal_prio(p);	return prio;},18093
7,1113,CVE-2013-2237,26,"static int key_notify_policy(struct xfrm_policy *xp, int dir, const struct km_event *c){	struct sk_buff *out_skb;	struct sadb_msg *out_hdr;	int err;	out_skb = pfkey_xfrm_policy2msg_prep(xp);	if (IS_ERR(out_skb))		return PTR_ERR(out_skb);	err = pfkey_xfrm_policy2msg(out_skb, xp, dir);	if (err < 0)		return err;	out_hdr = (struct sadb_msg *) out_skb->data;	out_hdr->sadb_msg_version = PF_KEY_V2;	if (c->data.byid && c->event == XFRM_MSG_DELPOLICY)		out_hdr->sadb_msg_type = SADB_X_SPDDELETE2;	else		out_hdr->sadb_msg_type = event2poltype(c->event);	out_hdr->sadb_msg_errno = 0;	out_hdr->sadb_msg_seq = c->seq;	out_hdr->sadb_msg_pid = c->portid;	pfkey_broadcast(out_skb, GFP_ATOMIC, BROADCAST_ALL, NULL, xp_net(xp));	return 0;}",8702
864,2308,CVE-2016-2324,26,"void add_head_to_pending(struct rev_info *revs){	unsigned char sha1[20];	struct object *obj;	if (get_sha1(""HEAD"", sha1))		return;	obj = parse_object(sha1);	if (!obj)		return;	add_pending_object(revs, obj, ""HEAD"");}",17728
541,426,CVE-2016-1907,26,sshpkt_get_end(struct ssh *ssh){	if (sshbuf_len(ssh->state->incoming_packet) > 0)		return SSH_ERR_UNEXPECTED_TRAILING_DATA;	return 0;},2150
112,1967,CVE-2016-4998,26,"static inline int arp_devaddr_compare(const struct arpt_devaddr_info *ap,				      const char *hdr_addr, int len){	int i, ret;	if (len > ARPT_DEV_ADDR_LEN_MAX)		len = ARPT_DEV_ADDR_LEN_MAX;	ret = 0;	for (i = 0; i < len; i++)		ret |= (hdr_addr[i] ^ ap->addr[i]) & ap->mask[i];	return ret != 0;}",16533
798,456,CVE-2014-2013,26,"xps_parse_float_array(char *s, int num, float *x){	int k = 0;	if (s == NULL || *s == 0)		return NULL;	while (*s)	{		while (*s == 0x0d || *s == '\t' || *s == ' ' || *s == 0x0a)			s++;		x[k] = (float)strtod(s, &s);		while (*s == 0x0d || *s == '\t' || *s == ' ' || *s == 0x0a)			s++;		if (*s == ',')			s++;		if (++k == num)			break;	}	return s;}",2193
530,117,CVE-2013-4282,26,"static void vdi_port_on_free_self_token(void *opaque){    if (inputs_inited() && reds->pending_mouse_event) {        spice_debug(""pending mouse event"");        reds_handle_agent_mouse_event(inputs_get_mouse_state());    }}",427
370,2277,CVE-2016-2324,26,"static int find_object_pos(const unsigned char *sha1){	struct object_entry *entry = packlist_find(writer.to_pack, sha1, NULL);	if (!entry) {		die(""Failed to write bitmap index. Packfile doesn't have full closure ""			""(object %s is missing)"", sha1_to_hex(sha1));	} 	return entry->in_pack_pos; }",17697
600,476,CVE-2013-4538,26,static void ssd03232_register_types(void){    type_register_static(&ssd0323_info);},2404
983,1456,CVE-2014-3535,26,"const struct rtnl_link_stats64 *dev_get_stats(struct net_device *dev){	const struct net_device_ops *ops = dev->netdev_ops;	if (ops->ndo_get_stats64)		return ops->ndo_get_stats64(dev);	if (ops->ndo_get_stats)		return (struct rtnl_link_stats64 *)ops->ndo_get_stats(dev);	dev_txq_stats_fold(dev, &dev->stats);	return &dev->stats64;}",11442
683,3056,CVE-2016-10192,26,"static int http_server(void){    int server_fd = 0, rtsp_server_fd = 0;    int ret, delay;    struct pollfd *poll_table, *poll_entry;    HTTPContext *c, *c_next;    poll_table = av_mallocz_array(config.nb_max_http_connections + 2,                                  sizeof(*poll_table));    if(!poll_table) {        http_log(""Impossible to allocate a poll table handling %d ""                 ""connections.\n"", config.nb_max_http_connections);        return -1;    }    if (config.http_addr.sin_port) {        server_fd = socket_open_listen(&config.http_addr);        if (server_fd < 0)            goto quit;    }    if (config.rtsp_addr.sin_port) {        rtsp_server_fd = socket_open_listen(&config.rtsp_addr);        if (rtsp_server_fd < 0) {            closesocket(server_fd);            goto quit;        }    }    if (!rtsp_server_fd && !server_fd) {        http_log(""HTTP and RTSP disabled.\n"");        goto quit;    }    http_log(""FFserver started.\n"");    start_children(config.first_feed);    start_multicast();    for(;;) {        poll_entry = poll_table;        if (server_fd) {            poll_entry->fd = server_fd;            poll_entry->events = POLLIN;            poll_entry++;        }        if (rtsp_server_fd) {            poll_entry->fd = rtsp_server_fd;            poll_entry->events = POLLIN;            poll_entry++;        }                 c = first_http_ctx;        delay = 1000;        while (c) {            int fd;            fd = c->fd;            switch(c->state) {            case HTTPSTATE_SEND_HEADER:            case RTSPSTATE_SEND_REPLY:            case RTSPSTATE_SEND_PACKET:                c->poll_entry = poll_entry;                poll_entry->fd = fd;                poll_entry->events = POLLOUT;                poll_entry++;                break;            case HTTPSTATE_SEND_DATA_HEADER:            case HTTPSTATE_SEND_DATA:            case HTTPSTATE_SEND_DATA_TRAILER:                if (!c->is_packetized) {                                         c->poll_entry = poll_entry;                    poll_entry->fd = fd;                    poll_entry->events = POLLOUT;                    poll_entry++;                } else {                                         if (delay > 10)                        delay = 10;                }                break;            case HTTPSTATE_WAIT_REQUEST:            case HTTPSTATE_RECEIVE_DATA:            case HTTPSTATE_WAIT_FEED:            case RTSPSTATE_WAIT_REQUEST:                                 c->poll_entry = poll_entry;                poll_entry->fd = fd;                poll_entry->events = POLLIN;                 poll_entry++;                break;            default:                c->poll_entry = NULL;                break;            }            c = c->next;        }                 do {            ret = poll(poll_table, poll_entry - poll_table, delay);            if (ret < 0 && ff_neterrno() != AVERROR(EAGAIN) &&                ff_neterrno() != AVERROR(EINTR)) {                goto quit;            }        } while (ret < 0);        cur_time = av_gettime() / 1000;        if (need_to_start_children) {            need_to_start_children = 0;            start_children(config.first_feed);        }                 for(c = first_http_ctx; c; c = c_next) {            c_next = c->next;            if (handle_connection(c) < 0) {                log_connection(c);                                 close_connection(c);            }        }        poll_entry = poll_table;        if (server_fd) {                         if (poll_entry->revents & POLLIN)                new_connection(server_fd, 0);            poll_entry++;        }        if (rtsp_server_fd) {                         if (poll_entry->revents & POLLIN)                new_connection(rtsp_server_fd, 1);        }    }quit:    av_free(poll_table);    return -1;}",22456
691,3567,CVE-2018-20855,26,"static int set_user_buf_size(struct mlx5_ib_dev *dev,			    struct mlx5_ib_qp *qp,			    struct mlx5_ib_create_qp *ucmd,			    struct mlx5_ib_qp_base *base,			    struct ib_qp_init_attr *attr){	int desc_sz = 1 << qp->sq.wqe_shift;	if (desc_sz > MLX5_CAP_GEN(dev->mdev, max_wqe_sz_sq)) {		mlx5_ib_warn(dev, ""desc_sz %d, max_sq_desc_sz %d\n"",			     desc_sz, MLX5_CAP_GEN(dev->mdev, max_wqe_sz_sq));		return -EINVAL;	}	if (ucmd->sq_wqe_count && ((1 << ilog2(ucmd->sq_wqe_count)) != ucmd->sq_wqe_count)) {		mlx5_ib_warn(dev, ""sq_wqe_count %d, sq_wqe_count %d\n"",			     ucmd->sq_wqe_count, ucmd->sq_wqe_count);		return -EINVAL;	}	qp->sq.wqe_cnt = ucmd->sq_wqe_count;	if (qp->sq.wqe_cnt > (1 << MLX5_CAP_GEN(dev->mdev, log_max_qp_sz))) {		mlx5_ib_warn(dev, ""wqe_cnt %d, max_wqes %d\n"",			     qp->sq.wqe_cnt,			     1 << MLX5_CAP_GEN(dev->mdev, log_max_qp_sz));		return -EINVAL;	}	if (attr->qp_type == IB_QPT_RAW_PACKET ||	    qp->flags & MLX5_IB_QP_UNDERLAY) {		base->ubuffer.buf_size = qp->rq.wqe_cnt << qp->rq.wqe_shift;		qp->raw_packet_qp.sq.ubuffer.buf_size = qp->sq.wqe_cnt << 6;	} else {		base->ubuffer.buf_size = (qp->rq.wqe_cnt << qp->rq.wqe_shift) +					 (qp->sq.wqe_cnt << 6);	}	return 0;}",27595
888,1428,CVE-2011-4098,26,"static int gfs2_close(struct inode *inode, struct file *file){	struct gfs2_sbd *sdp = inode->i_sb->s_fs_info;	struct gfs2_file *fp;	fp = file->private_data;	file->private_data = NULL;	if (gfs2_assert_warn(sdp, fp))		return -EIO;	kfree(fp);	return 0;}",10063
517,2664,CVE-2017-16931,26,static const char *baseFilename(const char *filename) {    const char *cur;    if (filename == NULL)        return(NULL);    cur = &filename[strlen(filename)];    while ((cur > filename) && (*cur != '/'))        cur--;    if (*cur == '/')        return(cur + 1);    return(cur);},19653
215,112,CVE-2013-4282,26,"static void reds_set_mouse_mode(int mode){    if (reds->mouse_mode == mode) {        return;    }    reds->mouse_mode = mode;    red_dispatcher_set_mouse_mode(reds->mouse_mode);    main_channel_push_mouse_mode(reds->main_channel, reds->mouse_mode, reds->is_client_mouse_allowed);}",422
768,2053,CVE-2016-4568,26,"int vb2_reqbufs(struct vb2_queue *q, struct v4l2_requestbuffers *req){	int ret = vb2_verify_memory_type(q, req->memory, req->type);	return ret ? ret : vb2_core_reqbufs(q, req->memory, &req->count);}",16755
1016,1950,CVE-2016-5400,26,"static int airspy_enum_fmt_sdr_cap(struct file *file, void *priv,		struct v4l2_fmtdesc *f){	if (f->index >= NUM_FORMATS)		return -EINVAL;	strlcpy(f->description, formats[f->index].name, sizeof(f->description));	f->pixelformat = formats[f->index].pixelformat;	return 0;}",16454
393,2495,CVE-2016-1583,26,"static void __setscheduler_params(struct task_struct *p,		const struct sched_attr *attr){	int policy = attr->sched_policy;	if (policy == SETPARAM_POLICY)		policy = p->policy;	p->policy = policy;	if (dl_policy(policy))		__setparam_dl(p, attr);	else if (fair_policy(policy))		p->static_prio = NICE_TO_PRIO(attr->sched_nice);	 	p->rt_priority = attr->sched_priority;	p->normal_prio = normal_prio(p);	set_load_weight(p);}",18044
359,3485,CVE-2019-12982,26,"countAllSwitchActions (union SWF_ACTION *actions, union SWF_ACTION *pre){	int i,j=1;	if (actions->SWF_ACTIONRECORD.ActionCode==SWFACTION_IF && pre->SWF_ACTIONRECORD.ActionCode==SWFACTION_STRICTEQUALS )	{		for(i=0; i < ((struct SWF_ACTIONIF*)actions)->numActions; i++)		{			j+=countAllSwitchActions(&((struct SWF_ACTIONIF*)actions)->Actions[i],pre);			pre=&((struct SWF_ACTIONIF*)actions)->Actions[i];		}	}                  	return j;}",26807
203,1731,CVE-2015-1333,26,"int key_unlink(struct key *keyring, struct key *key){	struct assoc_array_edit *edit;	int ret;	key_check(keyring);	key_check(key);	if (keyring->type != &key_type_keyring)		return -ENOTDIR;	down_write(&keyring->sem);	edit = assoc_array_delete(&keyring->keys, &keyring_assoc_array_ops,				  &key->index_key);	if (IS_ERR(edit)) {		ret = PTR_ERR(edit);		goto error;	}	ret = -ENOENT;	if (edit == NULL)		goto error;	assoc_array_apply_edit(edit);	key_payload_reserve(keyring, keyring->datalen - KEYQUOTA_LINK_BYTES);	ret = 0;error:	up_write(&keyring->sem);	return ret;}",14036
692,2755,CVE-2017-11328,26,"static void test_arithmetic_operators(){  assert_true_rule(      ""rule test { condition: (1 + 1) * 2 == (9 - 1) \\ 2 }"", NULL);  assert_true_rule(      ""rule test { condition: 5 % 2 == 1 }"", NULL);  assert_true_rule(      ""rule test { condition: 1.5 + 1.5 == 3}"", NULL);  assert_true_rule(      ""rule test { condition: 3 \\ 2 == 1}"", NULL);  assert_true_rule(      ""rule test { condition: 3.0 \\ 2 == 1.5}"", NULL);  assert_true_rule(      ""rule test { condition: 1 + -1 == 0}"", NULL);  assert_true_rule(      ""rule test { condition: -1 + -1 == -2}"", NULL);  assert_true_rule(      ""rule test { condition: 4 --2 * 2 == 8}"", NULL);  assert_true_rule(      ""rule test { condition: -1.0 * 1 == -1.0}"", NULL);  assert_true_rule(      ""rule test { condition: 1-1 == 0}"", NULL);  assert_true_rule(      ""rule test { condition: -2.0-3.0 == -5}"", NULL);  assert_true_rule(      ""rule test { condition: --1 == 1}"", NULL);  assert_true_rule(      ""rule test { condition: 1--1 == 2}"", NULL);  assert_true_rule(      ""rule test { condition: -0x01 == -1}"", NULL);  assert_true_rule(      ""rule test { condition: 0o10 == 8 }"", NULL);  assert_true_rule(      ""rule test { condition: 0o100 == 64 }"", NULL);  assert_true_rule(      ""rule test { condition: 0o755 == 493 }"", NULL);}",20537
748,685,CVE-2011-2517,26,"static int nl80211_req_set_reg(struct sk_buff *skb, struct genl_info *info){	int r;	char *data = NULL;	 	mutex_lock(&cfg80211_mutex);	if (unlikely(!cfg80211_regdomain)) {		mutex_unlock(&cfg80211_mutex);		return -EINPROGRESS;	}	mutex_unlock(&cfg80211_mutex);	if (!info->attrs[NL80211_ATTR_REG_ALPHA2])		return -EINVAL;	data = nla_data(info->attrs[NL80211_ATTR_REG_ALPHA2]);	r = regulatory_hint_user(data);	return r;}",6584
894,3786,CVE-2013-0904,26,    void setAtBeforeSideOfBlock(int b) { m_atBeforeSideOfBlock = b; },29446
143,3397,CVE-2017-15128,26,int PageHuge(struct page *page){	if (!PageCompound(page))		return 0;	page = compound_head(page);	return page[1].compound_dtor == HUGETLB_PAGE_DTOR;},26157
475,1693,CVE-2015-3331,26,"static int ecb_encrypt(struct blkcipher_desc *desc,		       struct scatterlist *dst, struct scatterlist *src,		       unsigned int nbytes){	struct crypto_aes_ctx *ctx = aes_ctx(crypto_blkcipher_ctx(desc->tfm));	struct blkcipher_walk walk;	int err;	blkcipher_walk_init(&walk, dst, src, nbytes);	err = blkcipher_walk_virt(desc, &walk);	desc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;	kernel_fpu_begin();	while ((nbytes = walk.nbytes)) {		aesni_ecb_enc(ctx, walk.dst.virt.addr, walk.src.virt.addr,			      nbytes & AES_BLOCK_MASK);		nbytes &= AES_BLOCK_SIZE - 1;		err = blkcipher_walk_done(desc, &walk, nbytes);	}	kernel_fpu_end();	return err;}",13604
639,257,CVE-2018-10184,26,"static int h2c_send_window_update(struct h2c *h2c, int sid, int increment){	struct buffer *res;	char str[13];	int ret = -1;	if (h2c_mux_busy(h2c, NULL)) {		h2c->flags |= H2_CF_DEM_MBUSY;		return 0;	}	res = h2_get_buf(h2c, &h2c->mbuf);	if (!res) {		h2c->flags |= H2_CF_MUX_MALLOC;		h2c->flags |= H2_CF_DEM_MROOM;		return 0;	}	 	memcpy(str, ""\x00\x00\x04\x08\x00"", 5);	write_n32(str + 5, sid);	write_n32(str + 9, increment);	ret = bo_istput(res, ist2(str, 13));	if (unlikely(ret <= 0)) {		if (!ret) {			h2c->flags |= H2_CF_MUX_MFULL;			h2c->flags |= H2_CF_DEM_MROOM;			return 0;		}		else {			h2c_error(h2c, H2_ERR_INTERNAL_ERROR);			return 0;		}	}	return ret;}",1278
200,1856,CVE-2016-7425,26,"static int arcmsr_abort_one_cmd(struct AdapterControlBlock *acb,		struct CommandControlBlock *ccb){	int rtn;	rtn = arcmsr_polling_ccbdone(acb, ccb);	return rtn;}",15775
280,880,CVE-2013-6381,26,static void qeth_put_reply(struct qeth_reply *reply){	WARN_ON(atomic_read(&reply->refcnt) <= 0);	if (atomic_dec_and_test(&reply->refcnt))		kfree(reply);},7309
539,2079,CVE-2016-4303,26,"iperf_defaults(struct iperf_test *testp){    struct protocol *tcp, *udp;    testp->omit = OMIT;    testp->duration = DURATION;    testp->diskfile_name = (char*) 0;    testp->affinity = -1;    testp->server_affinity = -1;    testp->title = NULL;    testp->congestion = NULL;    testp->server_port = PORT;    testp->ctrl_sck = -1;    testp->prot_listener = -1;    testp->stats_callback = iperf_stats_callback;    testp->reporter_callback = iperf_reporter_callback;    testp->stats_interval = testp->reporter_interval = 1;    testp->num_streams = 1;    testp->settings->domain = AF_UNSPEC;    testp->settings->unit_format = 'a';    testp->settings->socket_bufsize = 0;         testp->settings->blksize = DEFAULT_TCP_BLKSIZE;    testp->settings->rate = 0;    testp->settings->burst = 0;    testp->settings->mss = 0;    testp->settings->bytes = 0;    testp->settings->blocks = 0;    memset(testp->cookie, 0, COOKIE_SIZE);    testp->multisend = 10;	          SLIST_INIT(&testp->streams);    SLIST_INIT(&testp->protocols);    tcp = (struct protocol *) malloc(sizeof(struct protocol));    if (!tcp)        return -1;    memset(tcp, 0, sizeof(struct protocol));    udp = (struct protocol *) malloc(sizeof(struct protocol));    if (!udp) {        free(tcp);        return -1;    }    memset(udp, 0, sizeof(struct protocol));    tcp->id = Ptcp;    tcp->name = ""TCP"";    tcp->accept = iperf_tcp_accept;    tcp->listen = iperf_tcp_listen;    tcp->connect = iperf_tcp_connect;    tcp->send = iperf_tcp_send;    tcp->recv = iperf_tcp_recv;    tcp->init = NULL;    SLIST_INSERT_HEAD(&testp->protocols, tcp, protocols);    udp->id = Pudp;    udp->name = ""UDP"";    udp->accept = iperf_udp_accept;    udp->listen = iperf_udp_listen;    udp->connect = iperf_udp_connect;    udp->send = iperf_udp_send;    udp->recv = iperf_udp_recv;    udp->init = iperf_udp_init;    SLIST_INSERT_AFTER(tcp, udp, protocols);    set_protocol(testp, Ptcp);    testp->on_new_stream = iperf_on_new_stream;    testp->on_test_start = iperf_on_test_start;    testp->on_connect = iperf_on_connect;    testp->on_test_finish = iperf_on_test_finish;    TAILQ_INIT(&testp->server_output_list);    return 0;}",16987
671,156,CVE-2015-3281,26,"int buffer_insert_line2(struct buffer *b, char *pos, const char *str, int len){	int delta;	delta = len + 2;	if (bi_end(b) + delta >= b->data + b->size)		return 0;   	if (buffer_not_empty(b) &&	    bi_end(b) + delta > bo_ptr(b) &&	    bo_ptr(b) >= bi_end(b))		return 0;   	 	memmove(pos + delta, pos, bi_end(b) - pos);	 	if (len && str) {		memcpy(pos, str, len);		pos[len] = '\r';		pos[len + 1] = '\n';	}	b->i += delta;        return delta; }",707
832,2128,CVE-2016-4303,26,"iperf_set_test_rate(struct iperf_test *ipt, int rate){    ipt->settings->rate = rate;}",17036
515,2328,CVE-2016-2324,26,"static int compact_treesame(struct rev_info *revs, struct commit *commit, unsigned nth_parent){	struct treesame_state *st;	int old_same;	if (!commit->parents) {		 		if (nth_parent != 0)			die(""compact_treesame %u"", nth_parent);		old_same = !!(commit->object.flags & TREESAME);		if (rev_same_tree_as_empty(revs, commit))			commit->object.flags |= TREESAME;		else			commit->object.flags &= ~TREESAME;		return old_same;	}	st = lookup_decoration(&revs->treesame, &commit->object);	if (!st || nth_parent >= st->nparents)		die(""compact_treesame %u"", nth_parent);	old_same = st->treesame[nth_parent];	memmove(st->treesame + nth_parent,		st->treesame + nth_parent + 1,		st->nparents - nth_parent - 1);	 	if (--st->nparents == 1) {		if (commit->parents->next)			die(""compact_treesame parents mismatch"");		if (st->treesame[0] && revs->dense)			commit->object.flags |= TREESAME;		else			commit->object.flags &= ~TREESAME;		free(add_decoration(&revs->treesame, &commit->object, NULL));	}	return old_same;}",17748
516,1754,CVE-2014-9496,26,"write_str (unsigned char * data, int offset, const char * buffer, int buffer_len){	memcpy (data + offset, buffer, buffer_len) ;}  ",14473
702,4005,CVE-2016-1621,26,"static int merge_hist_buckets(struct hist_bucket *bucket, int max_buckets, int *num_buckets) { int small_bucket = 0, merge_bucket = INT_MAX, big_bucket = 0; int buckets = *num_buckets; int i;    big_bucket = small_bucket = 0; for (i = 0; i < buckets; i++) { if (bucket[i].count < bucket[small_bucket].count)      small_bucket = i; if (bucket[i].count > bucket[big_bucket].count)      big_bucket = i; }   while (buckets > max_buckets) { int last_bucket = buckets - 1;   if (small_bucket == 0)      merge_bucket = 1; else if (small_bucket == last_bucket)      merge_bucket = last_bucket - 1; else if (bucket[small_bucket - 1].count < bucket[small_bucket + 1].count)      merge_bucket = small_bucket - 1; else      merge_bucket = small_bucket + 1;    assert(abs(merge_bucket - small_bucket) <= 1);    assert(small_bucket < buckets);    assert(big_bucket < buckets);    assert(merge_bucket < buckets); if (merge_bucket < small_bucket) {      bucket[merge_bucket].high = bucket[small_bucket].high;      bucket[merge_bucket].count += bucket[small_bucket].count; } else {      bucket[small_bucket].high = bucket[merge_bucket].high;      bucket[small_bucket].count += bucket[merge_bucket].count;      merge_bucket = small_bucket; }    assert(bucket[merge_bucket].low != bucket[merge_bucket].high);    buckets--;      big_bucket = small_bucket = 0; for (i = 0; i < buckets; i++) { if (i > merge_bucket)        bucket[i] = bucket[i + 1]; if (bucket[i].count < bucket[small_bucket].count)        small_bucket = i; if (bucket[i].count > bucket[big_bucket].count)        big_bucket = i; } } *num_buckets = buckets; return bucket[big_bucket].count;}",30836
75,3178,CVE-2018-1000050,26,"static void *make_block_array(void *mem, int count, int size){   int i;   void ** p = (void **) mem;   char *q = (char *) (p + count);   for (i=0; i < count; ++i) {      p[i] = q;      q += size;   }   return p;}",23256
48,3422,CVE-2017-15128,26,"static void hugetlb_vm_op_close(struct vm_area_struct *vma){	struct hstate *h = hstate_vma(vma);	struct resv_map *resv = vma_resv_map(vma);	struct hugepage_subpool *spool = subpool_vma(vma);	unsigned long reserve, start, end;	long gbl_reserve;	if (!resv || !is_vma_resv_set(vma, HPAGE_RESV_OWNER))		return;	start = vma_hugecache_offset(h, vma, vma->vm_start);	end = vma_hugecache_offset(h, vma, vma->vm_end);	reserve = (end - start) - region_count(resv, start, end);	kref_put(&resv->refs, resv_map_release);	if (reserve) {		 		gbl_reserve = hugepage_subpool_put_pages(spool, reserve);		hugetlb_acct_memory(h, -gbl_reserve);	}}",26182
366,2713,CVE-2017-14727,26,"logger_backlog_signal_cb (const void *pointer, void *data,                          const char *signal,                          const char *type_data, void *signal_data){    struct t_logger_buffer *ptr_logger_buffer;         (void) pointer;    (void) data;    (void) signal;    (void) type_data;    if (weechat_config_integer (logger_config_look_backlog) >= 0)    {        ptr_logger_buffer = logger_buffer_search_buffer (signal_data);        if (ptr_logger_buffer && ptr_logger_buffer->log_enabled)        {            if (!ptr_logger_buffer->log_filename)                logger_set_log_filename (ptr_logger_buffer);            if (ptr_logger_buffer->log_filename)            {                ptr_logger_buffer->log_enabled = 0;                logger_backlog (signal_data,                                ptr_logger_buffer->log_filename,                                weechat_config_integer (logger_config_look_backlog));                ptr_logger_buffer->log_enabled = 1;            }        }    }    return WEECHAT_RC_OK;}",20115
117,1017,CVE-2013-4588,26,"static inline const char *ip_vs_fwd_name(unsigned flags){	switch (flags & IP_VS_CONN_F_FWD_MASK) {	case IP_VS_CONN_F_LOCALNODE:		return ""Local"";	case IP_VS_CONN_F_TUNNEL:		return ""Tunnel"";	case IP_VS_CONN_F_DROUTE:		return ""Route"";	default:		return ""Masq"";	}}",7614
679,1738,CVE-2015-1333,26,"static int keyring_diff_objects(const void *object, const void *data){	const struct key *key_a = keyring_ptr_to_key(object);	const struct keyring_index_key *a = &key_a->index_key;	const struct keyring_index_key *b = data;	unsigned long seg_a, seg_b;	int level, i;	level = 0;	seg_a = hash_key_type_and_desc(a);	seg_b = hash_key_type_and_desc(b);	if ((seg_a ^ seg_b) != 0)		goto differ;	 	level += ASSOC_ARRAY_KEY_CHUNK_SIZE / 8;	seg_a = a->desc_len;	seg_b = b->desc_len;	if ((seg_a ^ seg_b) != 0)		goto differ;	 	level++;	seg_a = (unsigned long)a->type;	seg_b = (unsigned long)b->type;	if ((seg_a ^ seg_b) != 0)		goto differ;	level += sizeof(unsigned long);	if (a->desc_len == 0)		goto same;	i = 0;	if (((unsigned long)a->description | (unsigned long)b->description) &	    (sizeof(unsigned long) - 1)) {		do {			seg_a = *(unsigned long *)(a->description + i);			seg_b = *(unsigned long *)(b->description + i);			if ((seg_a ^ seg_b) != 0)				goto differ_plus_i;			i += sizeof(unsigned long);		} while (i < (a->desc_len & (sizeof(unsigned long) - 1)));	}	for (; i < a->desc_len; i++) {		seg_a = *(unsigned char *)(a->description + i);		seg_b = *(unsigned char *)(b->description + i);		if ((seg_a ^ seg_b) != 0)			goto differ_plus_i;	}same:	return -1;differ_plus_i:	level += i;differ:	i = level * 8 + __ffs(seg_a ^ seg_b);	return i;}",14043
719,3534,CVE-2018-20855,26,"static void mlx5_fill_inl_bsf(struct ib_sig_domain *domain,			      struct mlx5_bsf_inl *inl){	 	inl->vld_refresh = cpu_to_be16(MLX5_BSF_INL_VALID |				       MLX5_BSF_REFRESH_DIF);	inl->dif_apptag = cpu_to_be16(domain->sig.dif.app_tag);	inl->dif_reftag = cpu_to_be32(domain->sig.dif.ref_tag);	 	inl->rp_inv_seed = MLX5_BSF_REPEAT_BLOCK;	inl->sig_type = domain->sig.dif.bg_type == IB_T10DIF_CRC ?			MLX5_DIF_CRC : MLX5_DIF_IPCS;	if (domain->sig.dif.ref_remap)		inl->dif_inc_ref_guard_check |= MLX5_BSF_INC_REFTAG;	if (domain->sig.dif.app_escape) {		if (domain->sig.dif.ref_escape)			inl->dif_inc_ref_guard_check |= MLX5_BSF_APPREF_ESCAPE;		else			inl->dif_inc_ref_guard_check |= MLX5_BSF_APPTAG_ESCAPE;	}	inl->dif_app_bitmask_check =		cpu_to_be16(domain->sig.dif.apptag_check_mask);}",27562
425,3883,CVE-2017-5009,26,DEFINE_TRACE(FetchContext) {  visitor->Trace(platform_probe_sink_);},29913
555,3949,CVE-2016-3822,26,"static void ConvertDoubleToURational(double value, unsigned int *numerator, unsigned int *denominator) {    float2urat(value, 0xFFFFFFFFU, numerator, denominator);}",30502
352,326,CVE-2010-2527,26,"  event_size_change( int delta )  {    status.ptsize += delta;    if ( status.ptsize < 1*64 )      status.ptsize = 1*64;    else if ( status.ptsize > MAXPTSIZE*64 )      status.ptsize = MAXPTSIZE*64;    FTDemo_Set_Current_Charsize( handle, status.ptsize, status.res );  }",1805
490,3287,CVE-2018-11506,26,"int sr_audio_ioctl(struct cdrom_device_info *cdi, unsigned int cmd, void *arg){	switch (cmd) {	case CDROMREADTOCHDR:		return sr_read_tochdr(cdi, arg);	case CDROMREADTOCENTRY:		return sr_read_tocentry(cdi, arg);	case CDROMPLAYTRKIND:		return sr_play_trkind(cdi, arg);	default:		return -EINVAL;	}}",25146
31,2019,CVE-2016-4998,26,ip6t_next_entry(const struct ip6t_entry *entry){	return (void *)entry + entry->next_offset;},16585
800,2961,CVE-2017-7742,26,"d2flac16_array (const double *src, int *dest, int count, int normalize){	double normfact = normalize ? (1.0 * 0x7FFF) : 1.0 ;	while (--count >= 0)		dest [count] = lrint (src [count] * normfact) ;}  ",21482
459,4012,CVE-2016-1621,26," int SetLayerId(int frame_num, int num_temp_layers) { int layer_id = 0; if (num_temp_layers == 2) { if (frame_num % 2 == 0) {        layer_id = 0; } else {        layer_id = 1; } } else if (num_temp_layers == 3) { if (frame_num % 4 == 0) {        layer_id = 0; } else if ((frame_num - 2) % 4 == 0) {        layer_id = 1; } else if ((frame_num - 1) % 2 == 0) {        layer_id = 2; } } return layer_id; }",30843
699,884,CVE-2013-6381,26,"static int qeth_qdio_establish(struct qeth_card *card){	struct qdio_initialize init_data;	char *qib_param_field;	struct qdio_buffer **in_sbal_ptrs;	void (**queue_start_poll) (struct ccw_device *, int, unsigned long);	struct qdio_buffer **out_sbal_ptrs;	int i, j, k;	int rc = 0;	QETH_DBF_TEXT(SETUP, 2, ""qdioest"");	qib_param_field = kzalloc(QDIO_MAX_BUFFERS_PER_Q * sizeof(char),			      GFP_KERNEL);	if (!qib_param_field) {		rc =  -ENOMEM;		goto out_free_nothing;	}	qeth_create_qib_param_field(card, qib_param_field);	qeth_create_qib_param_field_blkt(card, qib_param_field);	in_sbal_ptrs = kzalloc(card->qdio.no_in_queues *			       QDIO_MAX_BUFFERS_PER_Q * sizeof(void *),			       GFP_KERNEL);	if (!in_sbal_ptrs) {		rc = -ENOMEM;		goto out_free_qib_param;	}	for (i = 0; i < QDIO_MAX_BUFFERS_PER_Q; ++i) {		in_sbal_ptrs[i] = (struct qdio_buffer *)			virt_to_phys(card->qdio.in_q->bufs[i].buffer);	}	queue_start_poll = kzalloc(sizeof(void *) * card->qdio.no_in_queues,				   GFP_KERNEL);	if (!queue_start_poll) {		rc = -ENOMEM;		goto out_free_in_sbals;	}	for (i = 0; i < card->qdio.no_in_queues; ++i)		queue_start_poll[i] = card->discipline->start_poll;	qeth_qdio_establish_cq(card, in_sbal_ptrs, queue_start_poll);	out_sbal_ptrs =		kzalloc(card->qdio.no_out_queues * QDIO_MAX_BUFFERS_PER_Q *			sizeof(void *), GFP_KERNEL);	if (!out_sbal_ptrs) {		rc = -ENOMEM;		goto out_free_queue_start_poll;	}	for (i = 0, k = 0; i < card->qdio.no_out_queues; ++i)		for (j = 0; j < QDIO_MAX_BUFFERS_PER_Q; ++j, ++k) {			out_sbal_ptrs[k] = (struct qdio_buffer *)virt_to_phys(				card->qdio.out_qs[i]->bufs[j]->buffer);		}	memset(&init_data, 0, sizeof(struct qdio_initialize));	init_data.cdev                   = CARD_DDEV(card);	init_data.q_format               = qeth_get_qdio_q_format(card);	init_data.qib_param_field_format = 0;	init_data.qib_param_field        = qib_param_field;	init_data.no_input_qs            = card->qdio.no_in_queues;	init_data.no_output_qs           = card->qdio.no_out_queues;	init_data.input_handler 	 = card->discipline->input_handler;	init_data.output_handler	 = card->discipline->output_handler;	init_data.queue_start_poll_array = queue_start_poll;	init_data.int_parm               = (unsigned long) card;	init_data.input_sbal_addr_array  = (void **) in_sbal_ptrs;	init_data.output_sbal_addr_array = (void **) out_sbal_ptrs;	init_data.output_sbal_state_array = card->qdio.out_bufstates;	init_data.scan_threshold =		(card->info.type == QETH_CARD_TYPE_IQD) ? 1 : 32;	if (atomic_cmpxchg(&card->qdio.state, QETH_QDIO_ALLOCATED,		QETH_QDIO_ESTABLISHED) == QETH_QDIO_ALLOCATED) {		rc = qdio_allocate(&init_data);		if (rc) {			atomic_set(&card->qdio.state, QETH_QDIO_ALLOCATED);			goto out;		}		rc = qdio_establish(&init_data);		if (rc) {			atomic_set(&card->qdio.state, QETH_QDIO_ALLOCATED);			qdio_free(CARD_DDEV(card));		}	}	switch (card->options.cq) {	case QETH_CQ_ENABLED:		dev_info(&card->gdev->dev, ""Completion Queue support enabled"");		break;	case QETH_CQ_DISABLED:		dev_info(&card->gdev->dev, ""Completion Queue support disabled"");		break;	default:		break;	}out:	kfree(out_sbal_ptrs);out_free_queue_start_poll:	kfree(queue_start_poll);out_free_in_sbals:	kfree(in_sbal_ptrs);out_free_qib_param:	kfree(qib_param_field);out_free_nothing:	return rc;}",7313
552,3303,CVE-2018-10124,26,"int kill_pid_info(int sig, struct siginfo *info, struct pid *pid){	int error = -ESRCH;	struct task_struct *p;	for (;;) {		rcu_read_lock();		p = pid_task(pid, PIDTYPE_PID);		if (p)			error = group_send_sig_info(sig, info, p);		rcu_read_unlock();		if (likely(!p || error != -ESRCH))			return error;		 	}}",25230
41,1852,CVE-2016-8633,26,"static void fwnet_transmit_packet_failed(struct fwnet_packet_task *ptask){	struct fwnet_device *dev = ptask->dev;	unsigned long flags;	int free;	spin_lock_irqsave(&dev->lock, flags);	 	ptask->outstanding_pkts = 0;	 	free = ptask->enqueued;	if (free)		dec_queued_datagrams(dev);	dev->netdev->stats.tx_dropped++;	dev->netdev->stats.tx_errors++;	spin_unlock_irqrestore(&dev->lock, flags);	if (free)		fwnet_free_ptask(ptask);}",15586
823,542,CVE-2012-3400,26,"static int udf_load_sequence(struct super_block *sb, struct buffer_head *bh,			     struct kernel_lb_addr *fileset){	struct anchorVolDescPtr *anchor;	long main_s, main_e, reserve_s, reserve_e;	anchor = (struct anchorVolDescPtr *)bh->b_data;	 	main_s = le32_to_cpu(anchor->mainVolDescSeqExt.extLocation);	main_e = le32_to_cpu(anchor->mainVolDescSeqExt.extLength);	main_e = main_e >> sb->s_blocksize_bits;	main_e += main_s;	 	reserve_s = le32_to_cpu(anchor->reserveVolDescSeqExt.extLocation);	reserve_e = le32_to_cpu(anchor->reserveVolDescSeqExt.extLength);	reserve_e = reserve_e >> sb->s_blocksize_bits;	reserve_e += reserve_s;	 	 	if (!udf_process_sequence(sb, main_s, main_e, fileset))		return 1;	return !udf_process_sequence(sb, reserve_s, reserve_e, fileset);}",3127
116,2167,CVE-2016-4302,26,lzss_mask(struct lzss *lzss){  return lzss->mask;},17075
891,1908,CVE-2016-6516,26,static int ioctl_fsthaw(struct file *filp){	struct super_block *sb = file_inode(filp)->i_sb;	if (!capable(CAP_SYS_ADMIN))		return -EPERM;	 	if (sb->s_op->thaw_super)		return sb->s_op->thaw_super(sb);	return thaw_super(sb);},16005
231,245,CVE-2018-10184,26,"static struct task *h2_timeout_task(struct task *t){	struct h2c *h2c = t->context;	int expired = tick_is_expired(t->expire, now_ms);	if (!expired && h2c)		return t;	task_delete(t);	task_free(t);	if (!h2c) {		 		return NULL;	}	h2c->task = NULL;	h2c_error(h2c, H2_ERR_NO_ERROR);	h2_wake_some_streams(h2c, 0, 0);	if (h2c->mbuf->o) {		 		h2c->flags |= H2_CF_GOAWAY_FAILED;	}	 	h2c->last_sid = h2c->max_id;	if (h2c_send_goaway_error(h2c, NULL) <= 0)		h2c->flags |= H2_CF_GOAWAY_FAILED;	if (h2c->mbuf->o && !(h2c->flags & H2_CF_GOAWAY_FAILED) && conn_xprt_ready(h2c->conn))		h2c->conn->xprt->snd_buf(h2c->conn, h2c->mbuf, 0);	 	if (eb_is_empty(&h2c->streams_by_id))		h2_release(h2c->conn);	return NULL;}",1266
520,3972,CVE-2016-1503,26,"get_option_routes(const struct dhcp_message *dhcp, const char *ifname, unsigned long long *opts){ const int *p; const int *e; struct rt *routes = NULL; struct rt *route = NULL; int len;  	p = get_option(dhcp, DHO_CSR, &len, NULL);   if (!p)		p = get_option(dhcp, DHO_MSCSR, &len, NULL); if (p) {		routes = decode_rfc3442_rt(len, p); if (routes) { if (!(*opts & DHCPCD_CSR_WARNED)) {				syslog(LOG_DEBUG, ""%s: using Classless Static Routes"",				    ifname); *opts |= DHCPCD_CSR_WARNED; } return routes; } }  	p = get_option(dhcp, DHO_STATICROUTE, &len, NULL); if (p) {		e = p + len; while (p < e) { if (route) {				route->next = xmalloc(sizeof(*route));				route = route->next; } else				routes = route = xmalloc(sizeof(*routes));			route->next = NULL;			memcpy(&route->dest.s_addr, p, 4);			p += 4;			memcpy(&route->gate.s_addr, p, 4);			p += 4;			route->net.s_addr = route_netmask(route->dest.s_addr); } }  	p = get_option(dhcp, DHO_ROUTER, &len, NULL); if (p) {		e = p + len; while (p < e) { if (route) {				route->next = xzalloc(sizeof(*route));				route = route->next; } else				routes = route = xzalloc(sizeof(*route));			memcpy(&route->gate.s_addr, p, 4);			p += 4; } } return routes;}",30680
646,1493,CVE-2014-3184,26,"static int lg_wireless_mapping(struct hid_input *hi, struct hid_usage *usage,		unsigned long **bit, int *max){	if ((usage->hid & HID_USAGE_PAGE) != HID_UP_CONSUMER)		return 0;	switch (usage->hid & HID_USAGE) {	case 0x1001: lg_map_key_clear(KEY_MESSENGER);		break;	case 0x1003: lg_map_key_clear(KEY_SOUND);		break;	case 0x1004: lg_map_key_clear(KEY_VIDEO);		break;	case 0x1005: lg_map_key_clear(KEY_AUDIO);		break;	case 0x100a: lg_map_key_clear(KEY_DOCUMENTS);		break;	 	case 0x100f: lg_map_key_clear(KEY_FN_1);		break;	case 0x1010: lg_map_key_clear(KEY_FN_2);		break;	case 0x1011: lg_map_key_clear(KEY_PREVIOUSSONG);	break;	case 0x1012: lg_map_key_clear(KEY_NEXTSONG);		break;	case 0x1013: lg_map_key_clear(KEY_CAMERA);		break;	case 0x1014: lg_map_key_clear(KEY_MESSENGER);		break;	case 0x1015: lg_map_key_clear(KEY_RECORD);		break;	case 0x1016: lg_map_key_clear(KEY_PLAYER);		break;	case 0x1017: lg_map_key_clear(KEY_EJECTCD);		break;	case 0x1018: lg_map_key_clear(KEY_MEDIA);		break;	case 0x1019: lg_map_key_clear(KEY_PROG1);		break;	case 0x101a: lg_map_key_clear(KEY_PROG2);		break;	case 0x101b: lg_map_key_clear(KEY_PROG3);		break;	case 0x101c: lg_map_key_clear(KEY_CYCLEWINDOWS);	break;	case 0x101f: lg_map_key_clear(KEY_ZOOMIN);		break;	case 0x1020: lg_map_key_clear(KEY_ZOOMOUT);		break;	case 0x1021: lg_map_key_clear(KEY_ZOOMRESET);		break;	case 0x1023: lg_map_key_clear(KEY_CLOSE);		break;	case 0x1027: lg_map_key_clear(KEY_MENU);		break;	 	case 0x1028: lg_map_key_clear(KEY_ANGLE);		break;	case 0x1029: lg_map_key_clear(KEY_SHUFFLE);		break;	case 0x102a: lg_map_key_clear(KEY_BACK);		break;	case 0x102b: lg_map_key_clear(KEY_CYCLEWINDOWS);	break;	case 0x102d: lg_map_key_clear(KEY_WWW);			break;	 	case 0x1031: lg_map_key_clear(KEY_OK);			break;	case 0x1032: lg_map_key_clear(KEY_CANCEL);		break;	case 0x1041: lg_map_key_clear(KEY_BATTERY);		break;	case 0x1042: lg_map_key_clear(KEY_WORDPROCESSOR);	break;	case 0x1043: lg_map_key_clear(KEY_SPREADSHEET);		break;	case 0x1044: lg_map_key_clear(KEY_PRESENTATION);	break;	case 0x1045: lg_map_key_clear(KEY_UNDO);		break;	case 0x1046: lg_map_key_clear(KEY_REDO);		break;	case 0x1047: lg_map_key_clear(KEY_PRINT);		break;	case 0x1048: lg_map_key_clear(KEY_SAVE);		break;	case 0x1049: lg_map_key_clear(KEY_PROG1);		break;	case 0x104a: lg_map_key_clear(KEY_PROG2);		break;	case 0x104b: lg_map_key_clear(KEY_PROG3);		break;	case 0x104c: lg_map_key_clear(KEY_PROG4);		break;	default:		return 0;	}	return 1;}",11488
620,3653,CVE-2016-10764,26,"static int cqspi_probe(struct platform_device *pdev){	struct device_node *np = pdev->dev.of_node;	struct device *dev = &pdev->dev;	struct cqspi_st *cqspi;	struct resource *res;	struct resource *res_ahb;	int ret;	int irq;	cqspi = devm_kzalloc(dev, sizeof(*cqspi), GFP_KERNEL);	if (!cqspi)		return -ENOMEM;	mutex_init(&cqspi->bus_mutex);	cqspi->pdev = pdev;	platform_set_drvdata(pdev, cqspi);	 	ret = cqspi_of_get_pdata(pdev);	if (ret) {		dev_err(dev, ""Cannot get mandatory OF data.\n"");		return -ENODEV;	}	 	cqspi->clk = devm_clk_get(dev, NULL);	if (IS_ERR(cqspi->clk)) {		dev_err(dev, ""Cannot claim QSPI clock.\n"");		return PTR_ERR(cqspi->clk);	}	 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);	cqspi->iobase = devm_ioremap_resource(dev, res);	if (IS_ERR(cqspi->iobase)) {		dev_err(dev, ""Cannot remap controller address.\n"");		return PTR_ERR(cqspi->iobase);	}	 	res_ahb = platform_get_resource(pdev, IORESOURCE_MEM, 1);	cqspi->ahb_base = devm_ioremap_resource(dev, res_ahb);	if (IS_ERR(cqspi->ahb_base)) {		dev_err(dev, ""Cannot remap AHB address.\n"");		return PTR_ERR(cqspi->ahb_base);	}	init_completion(&cqspi->transfer_complete);	 	irq = platform_get_irq(pdev, 0);	if (irq < 0) {		dev_err(dev, ""Cannot obtain IRQ.\n"");		return -ENXIO;	}	ret = clk_prepare_enable(cqspi->clk);	if (ret) {		dev_err(dev, ""Cannot enable QSPI clock.\n"");		return ret;	}	cqspi->master_ref_clk_hz = clk_get_rate(cqspi->clk);	ret = devm_request_irq(dev, irq, cqspi_irq_handler, 0,			       pdev->name, cqspi);	if (ret) {		dev_err(dev, ""Cannot request IRQ.\n"");		goto probe_irq_failed;	}	cqspi_wait_idle(cqspi);	cqspi_controller_init(cqspi);	cqspi->current_cs = -1;	cqspi->sclk = 0;	ret = cqspi_setup_flash(cqspi, np);	if (ret) {		dev_err(dev, ""Cadence QSPI NOR probe failed %d\n"", ret);		goto probe_setup_failed;	}	return ret;probe_irq_failed:	cqspi_controller_enable(cqspi, 0);probe_setup_failed:	clk_disable_unprepare(cqspi->clk);	return ret;}",28112
846,3911,CVE-2016-1683,26,"exsltCryptoBin2Hex (const unsigned char *bin, int binlen,		    unsigned char *hex, int hexlen) {    static const char bin2hex[] = { '0', '1', '2', '3',	'4', '5', '6', '7',	'8', '9', 'a', 'b',	'c', 'd', 'e', 'f'    };    unsigned char lo, hi;    int i, pos;    for (i = 0, pos = 0; (i < binlen && pos < hexlen); i++) {	lo = bin[i] & 0xf;	hi = bin[i] >> 4;	hex[pos++] = bin2hex[hi];	hex[pos++] = bin2hex[lo];    }    hex[pos] = '\0';}",30345
372,1347,CVE-2013-1773,26,"static struct dentry *vfat_lookup(struct inode *dir, struct dentry *dentry,				  struct nameidata *nd){	struct super_block *sb = dir->i_sb;	struct fat_slot_info sinfo;	struct inode *inode;	struct dentry *alias;	int err;	lock_super(sb);	err = vfat_find(dir, &dentry->d_name, &sinfo);	if (err) {		if (err == -ENOENT) {			inode = NULL;			goto out;		}		goto error;	}	inode = fat_build_inode(sb, sinfo.de, sinfo.i_pos);	brelse(sinfo.bh);	if (IS_ERR(inode)) {		err = PTR_ERR(inode);		goto error;	}	alias = d_find_alias(inode);	if (alias && !vfat_d_anon_disconn(alias)) {		 		BUG_ON(d_unhashed(alias));		if (!S_ISDIR(inode->i_mode))			d_move(alias, dentry);		iput(inode);		unlock_super(sb);		return alias;	} else		dput(alias);out:	unlock_super(sb);	dentry->d_time = dentry->d_parent->d_inode->i_version;	dentry = d_splice_alias(inode, dentry);	if (dentry)		dentry->d_time = dentry->d_parent->d_inode->i_version;	return dentry;error:	unlock_super(sb);	return ERR_PTR(err);}",9584
496,2441,CVE-2016-2315,26,static void release_tree_entry(struct tree_entry *e){	if (e->tree)		release_tree_content_recursive(e->tree);	*((void**)e) = avail_tree_entry;	avail_tree_entry = e;},17861
419,2099,CVE-2016-4303,26,iperf_get_test_server_hostname(struct iperf_test *ipt){    return ipt->server_hostname;},17007
391,658,CVE-2011-2517,26,"static int nl80211_del_interface(struct sk_buff *skb, struct genl_info *info){	struct cfg80211_registered_device *rdev = info->user_ptr[0];	struct net_device *dev = info->user_ptr[1];	if (!rdev->ops->del_virtual_intf)		return -EOPNOTSUPP;	return rdev->ops->del_virtual_intf(&rdev->wiphy, dev);}",6557
999,3118,CVE-2016-8860,26,buf_get_total_allocation(void){  return total_bytes_allocated_in_chunks;},22773
845,2010,CVE-2016-4998,26,"find_check_match(struct xt_entry_match *m, struct xt_mtchk_param *par){	struct xt_match *match;	int ret;	match = xt_request_find_match(NFPROTO_IPV6, m->u.user.name,				      m->u.user.revision);	if (IS_ERR(match)) {		duprintf(""find_check_match: `%s' not found\n"", m->u.user.name);		return PTR_ERR(match);	}	m->u.kernel.match = match;	ret = check_match(m, par);	if (ret)		goto err;	return 0;err:	module_put(m->u.kernel.match->me);	return ret;}",16576
519,1563,CVE-2014-0063,26,"DecodeTimezone(char *str, int *tzp){	int			tz;	int			hr,				min;	char	   *cp;	int			len;	 	hr = strtol(str + 1, &cp, 10);	 	if (*cp == ':')		min = strtol(cp + 1, &cp, 10);	 	else if (*cp == '\0' && (len = strlen(str)) > 3)	{		min = strtol(str + len - 2, &cp, 10);		if (min < 0 || min >= 60)			return -1;		*(str + len - 2) = '\0';		hr = strtol(str + 1, &cp, 10);		if (hr < 0 || hr > 13)			return -1;	}	else		min = 0;	tz = (hr * MINS_PER_HOUR + min) * SECS_PER_MINUTE;	if (*str == '-')		tz = -tz;	*tzp = -tz;	return *cp != '\0';}	 ",12309
770,2241,CVE-2016-2324,26,"static void mark_in_pack_object(struct object *object, struct packed_git *p, struct in_pack *in_pack){	in_pack->array[in_pack->nr].offset = find_pack_entry_one(object->oid.hash, p);	in_pack->array[in_pack->nr].object = object;	in_pack->nr++;}",17661
752,2690,CVE-2017-16534,26,"int usb_driver_set_configuration(struct usb_device *udev, int config){	struct set_config_request *req;	req = kmalloc(sizeof(*req), GFP_KERNEL);	if (!req)		return -ENOMEM;	req->udev = udev;	req->config = config;	INIT_WORK(&req->work, driver_set_config_work);	spin_lock(&set_config_lock);	list_add(&req->node, &set_config_list);	spin_unlock(&set_config_lock);	usb_get_dev(udev);	schedule_work(&req->work);	return 0;}",19696
329,3324,CVE-2018-1091,26,"void ptrace_triggered(struct perf_event *bp,		      struct perf_sample_data *data, struct pt_regs *regs){	struct perf_event_attr attr;	 	attr = bp->attr;	attr.disabled = true;	modify_user_hw_breakpoint(bp, &attr);}",25540
785,2591,CVE-2016-1583,26,"static int set_nr_and_not_polling(struct task_struct *p){	struct thread_info *ti = task_thread_info(p);	return !(fetch_or(&ti->flags, _TIF_NEED_RESCHED) & _TIF_POLLING_NRFLAG);}",18140
653,2631,CVE-2017-1000251,26,"static void l2cap_chan_del(struct sock *sk, int err){	struct l2cap_conn *conn = l2cap_pi(sk)->conn;	struct sock *parent = bt_sk(sk)->parent;	l2cap_sock_clear_timer(sk);	BT_DBG(""sk %p, conn %p, err %d"", sk, conn, err);	if (conn) {		 		l2cap_chan_unlink(&conn->chan_list, sk);		l2cap_pi(sk)->conn = NULL;		hci_conn_put(conn->hcon);	}	sk->sk_state = BT_CLOSED;	sock_set_flag(sk, SOCK_ZAPPED);	if (err)		sk->sk_err = err;	if (parent) {		bt_accept_unlink(sk);		parent->sk_data_ready(parent, 0);	} else		sk->sk_state_change(sk);}",19469
266,804,CVE-2013-6381,26,"void qeth_clear_thread_running_bit(struct qeth_card *card, unsigned long thread){	unsigned long flags;	spin_lock_irqsave(&card->thread_mask_lock, flags);	card->thread_running_mask &= ~thread;	spin_unlock_irqrestore(&card->thread_mask_lock, flags);	wake_up(&card->wait_q);}",7233
805,3905,CVE-2017-15398,26,  void set_authorized(int authorized) { authorized_ = authorized; },30148
135,1550,CVE-2014-0069,26,"cifs_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf){	struct page *page = vmf->page;	lock_page(page);	return VM_FAULT_LOCKED;}",12296
853,2496,CVE-2016-1583,26,"static int _sched_setscheduler(struct task_struct *p, int policy,			       const struct sched_param *param, int check){	struct sched_attr attr = {		.sched_policy   = policy,		.sched_priority = param->sched_priority,		.sched_nice	= PRIO_TO_NICE(p->static_prio),	};	 	if ((policy != SETPARAM_POLICY) && (policy & SCHED_RESET_ON_FORK)) {		attr.sched_flags |= SCHED_FLAG_RESET_ON_FORK;		policy &= ~SCHED_RESET_ON_FORK;		attr.sched_policy = policy;	}	return __sched_setscheduler(p, &attr, check, true);}",18045
895,1338,CVE-2013-1773,26,"static int vfat_cmp(const struct dentry *parent, const struct inode *pinode,		const struct dentry *dentry, const struct inode *inode,		unsigned int len, const char *str, const struct qstr *name){	unsigned int alen, blen;	 	alen = vfat_striptail_len(name);	blen = __vfat_striptail_len(len, str);	if (alen == blen) {		if (strncmp(name->name, str, alen) == 0)			return 0;	}	return 1;}",9575
527,1099,CVE-2013-2850,26,"int iscsi_login_tx_data(	struct iscsi_conn *conn,	char *pdu_buf,	char *text_buf,	int text_length){	int length, tx_sent, iov_cnt = 1;	struct kvec iov[2];	length = (ISCSI_HDR_LEN + text_length);	memset(&iov[0], 0, 2 * sizeof(struct kvec));	iov[0].iov_len		= ISCSI_HDR_LEN;	iov[0].iov_base		= pdu_buf;	if (text_buf && text_length) {		iov[1].iov_len	= text_length;		iov[1].iov_base	= text_buf;		iov_cnt++;	}	 	conn->if_marker += length;	tx_sent = tx_data(conn, &iov[0], iov_cnt, length);	if (tx_sent != length) {		pr_err(""tx_data returned %d, expecting %d.\n"",				tx_sent, length);		return -1;	}	return 0;}",8501
321,1217,CVE-2013-1929,26,"static int tg3_abort_hw(struct tg3 *tp, int silent){	int i, err;	tg3_disable_ints(tp);	tp->rx_mode &= ~RX_MODE_ENABLE;	tw32_f(MAC_RX_MODE, tp->rx_mode);	udelay(10);	err  = tg3_stop_block(tp, RCVBDI_MODE, RCVBDI_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, RCVLPC_MODE, RCVLPC_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, RCVLSC_MODE, RCVLSC_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, RCVDBDI_MODE, RCVDBDI_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, RCVDCC_MODE, RCVDCC_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, RCVCC_MODE, RCVCC_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, SNDBDS_MODE, SNDBDS_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, SNDBDI_MODE, SNDBDI_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, SNDDATAI_MODE, SNDDATAI_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, RDMAC_MODE, RDMAC_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, SNDDATAC_MODE, SNDDATAC_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, DMAC_MODE, DMAC_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, SNDBDC_MODE, SNDBDC_MODE_ENABLE, silent);	tp->mac_mode &= ~MAC_MODE_TDE_ENABLE;	tw32_f(MAC_MODE, tp->mac_mode);	udelay(40);	tp->tx_mode &= ~TX_MODE_ENABLE;	tw32_f(MAC_TX_MODE, tp->tx_mode);	for (i = 0; i < MAX_WAIT_CNT; i++) {		udelay(100);		if (!(tr32(MAC_TX_MODE) & TX_MODE_ENABLE))			break;	}	if (i >= MAX_WAIT_CNT) {		dev_err(&tp->pdev->dev,			""%s timed out, TX_MODE_ENABLE will not clear ""			""MAC_TX_MODE=%08x\n"", __func__, tr32(MAC_TX_MODE));		err |= -ENODEV;	}	err |= tg3_stop_block(tp, HOSTCC_MODE, HOSTCC_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, WDMAC_MODE, WDMAC_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, MBFREE_MODE, MBFREE_MODE_ENABLE, silent);	tw32(FTQ_RESET, 0xffffffff);	tw32(FTQ_RESET, 0x00000000);	err |= tg3_stop_block(tp, BUFMGR_MODE, BUFMGR_MODE_ENABLE, silent);	err |= tg3_stop_block(tp, MEMARB_MODE, MEMARB_MODE_ENABLE, silent);	for (i = 0; i < tp->irq_cnt; i++) {		struct tg3_napi *tnapi = &tp->napi[i];		if (tnapi->hw_status)			memset(tnapi->hw_status, 0, TG3_HW_STATUS_SIZE);	}	return err;}",9223
953,1110,CVE-2013-2237,26,"static int dump_sp(struct xfrm_policy *xp, int dir, int count, void *ptr){	struct pfkey_sock *pfk = ptr;	struct sk_buff *out_skb;	struct sadb_msg *out_hdr;	int err;	if (!pfkey_can_dump(&pfk->sk))		return -ENOBUFS;	out_skb = pfkey_xfrm_policy2msg_prep(xp);	if (IS_ERR(out_skb))		return PTR_ERR(out_skb);	err = pfkey_xfrm_policy2msg(out_skb, xp, dir);	if (err < 0)		return err;	out_hdr = (struct sadb_msg *) out_skb->data;	out_hdr->sadb_msg_version = pfk->dump.msg_version;	out_hdr->sadb_msg_type = SADB_X_SPDDUMP;	out_hdr->sadb_msg_satype = SADB_SATYPE_UNSPEC;	out_hdr->sadb_msg_errno = 0;	out_hdr->sadb_msg_seq = count + 1;	out_hdr->sadb_msg_pid = pfk->dump.msg_portid;	if (pfk->dump.skb)		pfkey_broadcast(pfk->dump.skb, GFP_ATOMIC, BROADCAST_ONE,				&pfk->sk, sock_net(&pfk->sk));	pfk->dump.skb = out_skb;	return 0;}",8699
137,2364,CVE-2016-2324,26,"static void read_pathspec_from_stdin(struct rev_info *revs, struct strbuf *sb,				     struct cmdline_pathspec *prune){	while (strbuf_getline(sb, stdin) != EOF) {		ALLOC_GROW(prune->path, prune->nr + 1, prune->alloc);		prune->path[prune->nr++] = xstrdup(sb->buf);	}}",17784
550,3948,CVE-2016-3822,26,"static void ConvertDoubleToSRational(double value, int *numerator, int *denominator) { int negative = 0; if (value < 0) {        value = -value;        negative = 1; } unsigned int n, d;    float2urat(value, 0x7FFFFFFFU, &n, &d); *numerator = (int)n; *denominator = (int)d; if (negative) { *numerator = -*numerator; }}",30501
275,537,CVE-2012-3400,26,"static int udf_find_fileset(struct super_block *sb,			    struct kernel_lb_addr *fileset,			    struct kernel_lb_addr *root){	struct buffer_head *bh = NULL;	long lastblock;	int ident;	struct udf_sb_info *sbi;	if (fileset->logicalBlockNum != 0xFFFFFFFF ||	    fileset->partitionReferenceNum != 0xFFFF) {		bh = udf_read_ptagged(sb, fileset, 0, &ident);		if (!bh) {			return 1;		} else if (ident != TAG_IDENT_FSD) {			brelse(bh);			return 1;		}	}	sbi = UDF_SB(sb);	if (!bh) {		 		struct kernel_lb_addr newfileset; 		return 1;		for (newfileset.partitionReferenceNum = sbi->s_partitions - 1;		     (newfileset.partitionReferenceNum != 0xFFFF &&		      fileset->logicalBlockNum == 0xFFFFFFFF &&		      fileset->partitionReferenceNum == 0xFFFF);		     newfileset.partitionReferenceNum--) {			lastblock = sbi->s_partmaps					[newfileset.partitionReferenceNum]						.s_partition_len;			newfileset.logicalBlockNum = 0;			do {				bh = udf_read_ptagged(sb, &newfileset, 0,						      &ident);				if (!bh) {					newfileset.logicalBlockNum++;					continue;				}				switch (ident) {				case TAG_IDENT_SBD:				{					struct spaceBitmapDesc *sp;					sp = (struct spaceBitmapDesc *)								bh->b_data;					newfileset.logicalBlockNum += 1 +						((le32_to_cpu(sp->numOfBytes) +						  sizeof(struct spaceBitmapDesc)						  - 1) >> sb->s_blocksize_bits);					brelse(bh);					break;				}				case TAG_IDENT_FSD:					*fileset = newfileset;					break;				default:					newfileset.logicalBlockNum++;					brelse(bh);					bh = NULL;					break;				}			} while (newfileset.logicalBlockNum < lastblock &&				 fileset->logicalBlockNum == 0xFFFFFFFF &&				 fileset->partitionReferenceNum == 0xFFFF);		}	}	if ((fileset->logicalBlockNum != 0xFFFFFFFF ||	     fileset->partitionReferenceNum != 0xFFFF) && bh) {		udf_debug(""Fileset at block=%d, partition=%d\n"",			  fileset->logicalBlockNum,			  fileset->partitionReferenceNum);		sbi->s_partition = fileset->partitionReferenceNum;		udf_load_fileset(sb, bh, root);		brelse(bh);		return 0;	}	return 1;}",3122
232,688,CVE-2011-2517,26,"void nl80211_send_scan_aborted(struct cfg80211_registered_device *rdev,			       struct net_device *netdev){	struct sk_buff *msg;	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);	if (!msg)		return;	if (nl80211_send_scan_msg(msg, rdev, netdev, 0, 0, 0,				  NL80211_CMD_SCAN_ABORTED) < 0) {		nlmsg_free(msg);		return;	}	genlmsg_multicast_netns(wiphy_net(&rdev->wiphy), msg, 0,				nl80211_scan_mcgrp.id, GFP_KERNEL);}",6587
477,3835,CVE-2017-5122,26,  ConsumeEventHandler() {},29813
677,1261,CVE-2013-1929,26,static int tg3_mdio_reset(struct mii_bus *bp){	return 0;},9267
32,1370,CVE-2013-1772,26,void console_start(struct console *console){	console_lock();	console->flags |= CON_ENABLED;	console_unlock();},9607
733,4015,CVE-2016-1621,26,"void reference_16x16_dct_2d(int input[256], double output[256]) { for (int i = 0; i < 16; ++i) { double temp_in[16], temp_out[16]; for (int j = 0; j < 16; ++j)      temp_in[j] = input[j * 16 + i];    butterfly_16x16_dct_1d(temp_in, temp_out); for (int j = 0; j < 16; ++j)      output[j * 16 + i] = temp_out[j]; } for (int i = 0; i < 16; ++i) { double temp_in[16], temp_out[16]; for (int j = 0; j < 16; ++j)      temp_in[j] = output[j + i * 16];    butterfly_16x16_dct_1d(temp_in, temp_out); for (int j = 0; j < 16; ++j)      output[j + i * 16] = temp_out[j]/2;   } }",30846
246,721,CVE-2010-4650,26,"static long fuse_file_compat_ioctl(struct file *file, unsigned int cmd,				   unsigned long arg){	return fuse_file_ioctl_common(file, cmd, arg, FUSE_IOCTL_COMPAT);}",7005
820,249,CVE-2018-10184,26,"static int h2c_handle_goaway(struct h2c *h2c){	int error;	int last;	if (h2c->dsi != 0) {		error = H2_ERR_PROTOCOL_ERROR;		goto conn_err;	}	if (h2c->dfl < 8) {		error = H2_ERR_FRAME_SIZE_ERROR;		goto conn_err;	}	 	if (h2c->dbuf->i < h2c->dfl)		return 0;	last = h2_get_n32(h2c->dbuf, 0);	h2c->errcode = h2_get_n32(h2c->dbuf, 4);	h2_wake_some_streams(h2c, last, CS_FL_ERROR);	if (h2c->last_sid < 0)		h2c->last_sid = last;	return 1; conn_err:	h2c_error(h2c, error);	return 0;}",1270
703,1564,CVE-2014-0063,26,"DecodeUnits(int field, char *lowtoken, int *val){	int			type;	datetkn    *tp;	if (deltacache[field] != NULL &&		strncmp(lowtoken, deltacache[field]->token, TOKMAXLEN) == 0)		tp = deltacache[field];	else		tp = datebsearch(lowtoken, deltatktbl, szdeltatktbl);	deltacache[field] = tp;	if (tp == NULL)	{		type = UNKNOWN_FIELD;		*val = 0;	}	else	{		type = tp->type;		if (type == TZ || type == DTZ)			*val = FROMVAL(tp);		else			*val = tp->value;	}	return type;}	 ",12310
641,12,CVE-2015-6806,26,"ForwardTab(){  register int x = curr->w_x;  if (x == cols)    {      LineFeed(1);      x = 0;    }  if (curr->w_tabs[x] && x < cols - 1)    x++;  while (x < cols - 1 && !curr->w_tabs[x])    x++;  curr->w_x = x;  LGotoPos(&curr->w_layer, curr->w_x, curr->w_y);}",121
406,2518,CVE-2016-1583,26,inline struct dl_bw *dl_bw_of(int i){	return &cpu_rq(i)->dl.dl_bw;},18067
476,2160,CVE-2016-4302,26,"expand(struct archive_read *a, int end){  static const unsigned char lengthbases[] =    {   0,   1,   2,   3,   4,   5,   6,        7,   8,  10,  12,  14,  16,  20,       24,  28,  32,  40,  48,  56,  64,       80,  96, 112, 128, 160, 192, 224 };  static const unsigned char lengthbits[] =    { 0, 0, 0, 0, 0, 0, 0,      0, 1, 1, 1, 1, 2, 2,      2, 2, 3, 3, 3, 3, 4,      4, 4, 4, 5, 5, 5, 5 };  static const unsigned int offsetbases[] =    {       0,       1,       2,       3,       4,       6,            8,      12,      16,      24,      32,      48,           64,      96,     128,     192,     256,     384,          512,     768,    1024,    1536,    2048,    3072,         4096,    6144,    8192,   12288,   16384,   24576,        32768,   49152,   65536,   98304,  131072,  196608,       262144,  327680,  393216,  458752,  524288,  589824,       655360,  720896,  786432,  851968,  917504,  983040,      1048576, 1310720, 1572864, 1835008, 2097152, 2359296,      2621440, 2883584, 3145728, 3407872, 3670016, 3932160 };  static const unsigned char offsetbits[] =    {  0,  0,  0,  0,  1,  1,  2,  2,  3,  3,  4,  4,       5,  5,  6,  6,  7,  7,  8,  8,  9,  9, 10, 10,      11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,      16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,      18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18 };  static const unsigned char shortbases[] =    { 0, 4, 8, 16, 32, 64, 128, 192 };  static const unsigned char shortbits[] =    { 2, 2, 3, 4, 5, 6, 6, 6 };  int symbol, offs, len, offsindex, lensymbol, i, offssymbol, lowoffsetsymbol;  unsigned char newfile;  struct rar *rar = (struct rar *)(a->format->data);  struct rar_br *br = &(rar->br);  if (rar->filterstart < end)    end = rar->filterstart;  while (1)  {    if (rar->output_last_match &&      lzss_position(&rar->lzss) + rar->lastlength <= end)    {      lzss_emit_match(rar, rar->lastoffset, rar->lastlength);      rar->output_last_match = 0;    }    if(rar->is_ppmd_block || rar->output_last_match ||      lzss_position(&rar->lzss) >= end)      return lzss_position(&rar->lzss);    if ((symbol = read_next_symbol(a, &rar->maincode)) < 0)      return (ARCHIVE_FATAL);    rar->output_last_match = 0;    if (symbol < 256)    {      lzss_emit_literal(rar, symbol);      continue;    }    else if (symbol == 256)    {      if (!rar_br_read_ahead(a, br, 1))        goto truncated_data;      newfile = !rar_br_bits(br, 1);      rar_br_consume(br, 1);      if(newfile)      {        rar->start_new_block = 1;        if (!rar_br_read_ahead(a, br, 1))          goto truncated_data;        rar->start_new_table = rar_br_bits(br, 1);        rar_br_consume(br, 1);        return lzss_position(&rar->lzss);      }      else      {        if (parse_codes(a) != ARCHIVE_OK)          return (ARCHIVE_FATAL);        continue;      }    }    else if(symbol==257)    {      archive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,                        ""Parsing filters is unsupported."");      return (ARCHIVE_FAILED);    }    else if(symbol==258)    {      if(rar->lastlength == 0)        continue;      offs = rar->lastoffset;      len = rar->lastlength;    }    else if (symbol <= 262)    {      offsindex = symbol - 259;      offs = rar->oldoffset[offsindex];      if ((lensymbol = read_next_symbol(a, &rar->lengthcode)) < 0)        goto bad_data;      if (lensymbol > (int)(sizeof(lengthbases)/sizeof(lengthbases[0])))        goto bad_data;      if (lensymbol > (int)(sizeof(lengthbits)/sizeof(lengthbits[0])))        goto bad_data;      len = lengthbases[lensymbol] + 2;      if (lengthbits[lensymbol] > 0) {        if (!rar_br_read_ahead(a, br, lengthbits[lensymbol]))          goto truncated_data;        len += rar_br_bits(br, lengthbits[lensymbol]);        rar_br_consume(br, lengthbits[lensymbol]);      }      for (i = offsindex; i > 0; i--)        rar->oldoffset[i] = rar->oldoffset[i-1];      rar->oldoffset[0] = offs;    }    else if(symbol<=270)    {      offs = shortbases[symbol-263] + 1;      if(shortbits[symbol-263] > 0) {        if (!rar_br_read_ahead(a, br, shortbits[symbol-263]))          goto truncated_data;        offs += rar_br_bits(br, shortbits[symbol-263]);        rar_br_consume(br, shortbits[symbol-263]);      }      len = 2;      for(i = 3; i > 0; i--)        rar->oldoffset[i] = rar->oldoffset[i-1];      rar->oldoffset[0] = offs;    }    else    {      if (symbol-271 > (int)(sizeof(lengthbases)/sizeof(lengthbases[0])))        goto bad_data;      if (symbol-271 > (int)(sizeof(lengthbits)/sizeof(lengthbits[0])))        goto bad_data;      len = lengthbases[symbol-271]+3;      if(lengthbits[symbol-271] > 0) {        if (!rar_br_read_ahead(a, br, lengthbits[symbol-271]))          goto truncated_data;        len += rar_br_bits(br, lengthbits[symbol-271]);        rar_br_consume(br, lengthbits[symbol-271]);      }      if ((offssymbol = read_next_symbol(a, &rar->offsetcode)) < 0)        goto bad_data;      if (offssymbol > (int)(sizeof(offsetbases)/sizeof(offsetbases[0])))        goto bad_data;      if (offssymbol > (int)(sizeof(offsetbits)/sizeof(offsetbits[0])))        goto bad_data;      offs = offsetbases[offssymbol]+1;      if(offsetbits[offssymbol] > 0)      {        if(offssymbol > 9)        {          if(offsetbits[offssymbol] > 4) {            if (!rar_br_read_ahead(a, br, offsetbits[offssymbol] - 4))              goto truncated_data;            offs += rar_br_bits(br, offsetbits[offssymbol] - 4) << 4;            rar_br_consume(br, offsetbits[offssymbol] - 4);	  }          if(rar->numlowoffsetrepeats > 0)          {            rar->numlowoffsetrepeats--;            offs += rar->lastlowoffset;          }          else          {            if ((lowoffsetsymbol =              read_next_symbol(a, &rar->lowoffsetcode)) < 0)              return (ARCHIVE_FATAL);            if(lowoffsetsymbol == 16)            {              rar->numlowoffsetrepeats = 15;              offs += rar->lastlowoffset;            }            else            {              offs += lowoffsetsymbol;              rar->lastlowoffset = lowoffsetsymbol;            }          }        }        else {          if (!rar_br_read_ahead(a, br, offsetbits[offssymbol]))            goto truncated_data;          offs += rar_br_bits(br, offsetbits[offssymbol]);          rar_br_consume(br, offsetbits[offssymbol]);        }      }      if (offs >= 0x40000)        len++;      if (offs >= 0x2000)        len++;      for(i = 3; i > 0; i--)        rar->oldoffset[i] = rar->oldoffset[i-1];      rar->oldoffset[0] = offs;    }    rar->lastoffset = offs;    rar->lastlength = len;    rar->output_last_match = 1;  }truncated_data:  archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                    ""Truncated RAR file data"");  rar->valid = 0;  return (ARCHIVE_FATAL);bad_data:  archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,                    ""Bad RAR file data"");  return (ARCHIVE_FATAL);}",17068
910,2293,CVE-2016-2324,26,static int open_pack_bitmap(void){	struct packed_git *p;	int ret = -1;	assert(!bitmap_git.map && !bitmap_git.loaded);	prepare_packed_git();	for (p = packed_git; p; p = p->next) {		if (open_pack_bitmap_1(p) == 0)			ret = 0;	}	return ret;},17713
626,915,CVE-2013-6381,26,"static int qeth_setadpparms_set_access_ctrl_cb(struct qeth_card *card,		struct qeth_reply *reply, unsigned long data){	struct qeth_ipa_cmd *cmd;	struct qeth_set_access_ctrl *access_ctrl_req;	int fallback = *(int *)reply->param;	QETH_CARD_TEXT(card, 4, ""setaccb"");	cmd = (struct qeth_ipa_cmd *) data;	access_ctrl_req = &cmd->data.setadapterparms.data.set_access_ctrl;	QETH_DBF_TEXT_(SETUP, 2, ""setaccb"");	QETH_DBF_TEXT_(SETUP, 2, ""%s"", card->gdev->dev.kobj.name);	QETH_DBF_TEXT_(SETUP, 2, ""rc=%d"",		cmd->data.setadapterparms.hdr.return_code);	if (cmd->data.setadapterparms.hdr.return_code !=						SET_ACCESS_CTRL_RC_SUCCESS)		QETH_DBF_MESSAGE(3, ""ERR:SET_ACCESS_CTRL(%s,%d)==%d\n"",				card->gdev->dev.kobj.name,				access_ctrl_req->subcmd_code,				cmd->data.setadapterparms.hdr.return_code);	switch (cmd->data.setadapterparms.hdr.return_code) {	case SET_ACCESS_CTRL_RC_SUCCESS:		if (card->options.isolation == ISOLATION_MODE_NONE) {			dev_info(&card->gdev->dev,			    ""QDIO data connection isolation is deactivated\n"");		} else {			dev_info(&card->gdev->dev,			    ""QDIO data connection isolation is activated\n"");		}		break;	case SET_ACCESS_CTRL_RC_ALREADY_NOT_ISOLATED:		QETH_DBF_MESSAGE(2, ""%s QDIO data connection isolation already ""				""deactivated\n"", dev_name(&card->gdev->dev));		if (fallback)			card->options.isolation = card->options.prev_isolation;		break;	case SET_ACCESS_CTRL_RC_ALREADY_ISOLATED:		QETH_DBF_MESSAGE(2, ""%s QDIO data connection isolation already""				"" activated\n"", dev_name(&card->gdev->dev));		if (fallback)			card->options.isolation = card->options.prev_isolation;		break;	case SET_ACCESS_CTRL_RC_NOT_SUPPORTED:		dev_err(&card->gdev->dev, ""Adapter does not ""			""support QDIO data connection isolation\n"");		break;	case SET_ACCESS_CTRL_RC_NONE_SHARED_ADAPTER:		dev_err(&card->gdev->dev,			""Adapter is dedicated. ""			""QDIO data connection isolation not supported\n"");		if (fallback)			card->options.isolation = card->options.prev_isolation;		break;	case SET_ACCESS_CTRL_RC_ACTIVE_CHECKSUM_OFF:		dev_err(&card->gdev->dev,			""TSO does not permit QDIO data connection isolation\n"");		if (fallback)			card->options.isolation = card->options.prev_isolation;		break;	case SET_ACCESS_CTRL_RC_REFLREL_UNSUPPORTED:		dev_err(&card->gdev->dev, ""The adjacent switch port does not ""			""support reflective relay mode\n"");		if (fallback)			card->options.isolation = card->options.prev_isolation;		break;	case SET_ACCESS_CTRL_RC_REFLREL_FAILED:		dev_err(&card->gdev->dev, ""The reflective relay mode cannot be ""					""enabled at the adjacent switch port"");		if (fallback)			card->options.isolation = card->options.prev_isolation;		break;	case SET_ACCESS_CTRL_RC_REFLREL_DEACT_FAILED:		dev_warn(&card->gdev->dev, ""Turning off reflective relay mode ""					""at the adjacent switch failed\n"");		break;	default:		 		if (fallback)			card->options.isolation = card->options.prev_isolation;		break;	}	qeth_default_setadapterparms_cb(card, reply, (unsigned long) cmd);	return 0;}",7344
696,698,CVE-2011-2517,26,"static int parse_station_flags(struct genl_info *info,			       struct station_parameters *params){	struct nlattr *flags[NL80211_STA_FLAG_MAX + 1];	struct nlattr *nla;	int flag;	 	nla = info->attrs[NL80211_ATTR_STA_FLAGS2];	if (nla) {		struct nl80211_sta_flag_update *sta_flags;		sta_flags = nla_data(nla);		params->sta_flags_mask = sta_flags->mask;		params->sta_flags_set = sta_flags->set;		if ((params->sta_flags_mask |		     params->sta_flags_set) & BIT(__NL80211_STA_FLAG_INVALID))			return -EINVAL;		return 0;	}	 	nla = info->attrs[NL80211_ATTR_STA_FLAGS];	if (!nla)		return 0;	if (nla_parse_nested(flags, NL80211_STA_FLAG_MAX,			     nla, sta_flags_policy))		return -EINVAL;	params->sta_flags_mask = (1 << __NL80211_STA_FLAG_AFTER_LAST) - 1;	params->sta_flags_mask &= ~1;	for (flag = 1; flag <= NL80211_STA_FLAG_MAX; flag++)		if (flags[flag])			params->sta_flags_set |= (1<<flag);	return 0;}",6597
264,65,CVE-2019-15937,26,"static void nfs_readlink_req(void){	int data[1024];	int *p;	int len;	p = &(data[0]);	p = rpc_add_credentials(p);	memcpy (p, filefh, NFS_FHSIZE);	p += (NFS_FHSIZE / 4);	len = p - &(data[0]);	rpc_req(PROG_NFS, NFS_READLINK, data, len);}",296
743,700,CVE-2011-2182,26,"static int ldm_compare_privheads (const struct privhead *ph1,				   const struct privhead *ph2){	BUG_ON (!ph1 || !ph2);	return ((ph1->ver_major          == ph2->ver_major)		&&		(ph1->ver_minor          == ph2->ver_minor)		&&		(ph1->logical_disk_start == ph2->logical_disk_start)	&&		(ph1->logical_disk_size  == ph2->logical_disk_size)	&&		(ph1->config_start       == ph2->config_start)		&&		(ph1->config_size        == ph2->config_size)		&&		!memcmp (ph1->disk_id, ph2->disk_id, GUID_SIZE));}",6756
214,1600,CVE-2015-5283,26,"static void sctp_v4_to_sk_saddr(union sctp_addr *addr, struct sock *sk){	inet_sk(sk)->inet_rcv_saddr = addr->v4.sin_addr.s_addr;}",13455
168,3898,CVE-2018-18339,26,"const char* AudioPlayingStateToString(int is_audio_playing) {  if (is_audio_playing) {    return ""playing"";  } else {    return ""muted"";  }}",29967
925,1704,CVE-2015-3214,26,void kvm_inject_pit_timer_irqs(struct kvm_vcpu *vcpu){	struct kvm_pit *pit = vcpu->kvm->arch.vpit;	struct kvm *kvm = vcpu->kvm;	struct kvm_kpit_state *ps;	if (pit) {		int inject = 0;		ps = &pit->pit_state;		 		spin_lock(&ps->inject_lock);		if (atomic_read(&ps->pit_timer.pending) && ps->irq_ack) {			ps->irq_ack = 0;			inject = 1;		}		spin_unlock(&ps->inject_lock);		if (inject)			__inject_pit_timer_intr(kvm);	}},13615
801,1513,CVE-2014-3181,26,static int magicmouse_firm_touch(struct magicmouse_sc *msc){	int touch = -1;	int ii;	 	for (ii = 0; ii < msc->ntouches; ii++) {		int idx = msc->tracking_ids[ii];		if (msc->touches[idx].size < 8) {			 		} else if (touch >= 0) {			touch = -1;			break;		} else {			touch = idx;		}	}	return touch;},11508
670,2728,CVE-2017-14727,26,"logger_start_signal_cb (const void *pointer, void *data,                        const char *signal, const char *type_data,                        void *signal_data){         (void) pointer;    (void) data;    (void) signal;    (void) type_data;    logger_start_buffer (signal_data, 1);    return WEECHAT_RC_OK;}",20130
618,2511,CVE-2016-1583,26,"int cpus_share_cache(int this_cpu, int that_cpu){	return per_cpu(sd_llc_id, this_cpu) == per_cpu(sd_llc_id, that_cpu);}",18060
851,3145,CVE-2016-1245,26,"rtadv_event (struct zebra_vrf *zvrf, enum rtadv_event event, int val){  struct rtadv *rtadv = &zvrf->rtadv;  switch (event)    {    case RTADV_START:      if (! rtadv->ra_read)	rtadv->ra_read = thread_add_read (zebrad.master, rtadv_read, zvrf, val);      if (! rtadv->ra_timer)	rtadv->ra_timer = thread_add_event (zebrad.master, rtadv_timer,	                                    zvrf, 0);      break;    case RTADV_STOP:      if (rtadv->ra_timer)	{	  thread_cancel (rtadv->ra_timer);	  rtadv->ra_timer = NULL;	}      if (rtadv->ra_read)	{	  thread_cancel (rtadv->ra_read);	  rtadv->ra_read = NULL;	}      break;    case RTADV_TIMER:      if (! rtadv->ra_timer)	rtadv->ra_timer = thread_add_timer (zebrad.master, rtadv_timer, zvrf,	                                    val);      break;    case RTADV_TIMER_MSEC:      if (! rtadv->ra_timer)	rtadv->ra_timer = thread_add_timer_msec (zebrad.master, rtadv_timer, 					    zvrf, val);      break;    case RTADV_READ:      if (! rtadv->ra_read)	rtadv->ra_read = thread_add_read (zebrad.master, rtadv_read, zvrf, val);      break;    default:      break;    }  return;}",22849
988,1163,CVE-2013-2237,26,"static int pfkey_spdflush(struct sock *sk, struct sk_buff *skb, const struct sadb_msg *hdr, void * const *ext_hdrs){	struct net *net = sock_net(sk);	struct km_event c;	struct xfrm_audit audit_info;	int err, err2;	audit_info.loginuid = audit_get_loginuid(current);	audit_info.sessionid = audit_get_sessionid(current);	audit_info.secid = 0;	err = xfrm_policy_flush(net, XFRM_POLICY_TYPE_MAIN, &audit_info);	err2 = unicast_flush_resp(sk, hdr);	if (err || err2) {		if (err == -ESRCH)  			return 0;		return err;	}	c.data.type = XFRM_POLICY_TYPE_MAIN;	c.event = XFRM_MSG_FLUSHPOLICY;	c.portid = hdr->sadb_msg_pid;	c.seq = hdr->sadb_msg_seq;	c.net = net;	km_policy_notify(NULL, 0, &c);	return 0;}",8752
723,3012,CVE-2017-5548,26,"static int atusb_xmit(struct ieee802154_hw *hw, struct sk_buff *skb){	struct atusb *atusb = hw->priv;	struct usb_device *usb_dev = atusb->usb_dev;	int ret;	dev_dbg(&usb_dev->dev, ""atusb_xmit (%d)\n"", skb->len);	atusb->tx_skb = skb;	atusb->tx_ack_seq++;	atusb->tx_dr.wIndex = cpu_to_le16(atusb->tx_ack_seq);	atusb->tx_dr.wLength = cpu_to_le16(skb->len);	usb_fill_control_urb(atusb->tx_urb, usb_dev,			     usb_sndctrlpipe(usb_dev, 0),			     (unsigned char *)&atusb->tx_dr, skb->data,			     skb->len, atusb_xmit_complete, NULL);	ret = usb_submit_urb(atusb->tx_urb, GFP_ATOMIC);	dev_dbg(&usb_dev->dev, ""atusb_xmit done (%d)\n"", ret);	return ret;}",22051
896,3943,CVE-2016-3916,26,"const char *get_camera_metadata_section_name(int tag) { int tag_section = tag >> 16; if (tag_section >= VENDOR_SECTION && vendor_tag_ops != NULL) { return vendor_tag_ops->get_section_name(            vendor_tag_ops,            tag); } if (tag_section >= ANDROID_SECTION_COUNT) { return NULL; } return camera_metadata_section_names[tag_section];}",30382
843,39,CVE-2019-15938,26,"static int *nfs_add_uint64(int *p, int val){	int nval = hton64(val);	memcpy(p, &nval, 8);	return p + 2;}",270
418,1606,CVE-2015-5156,26,"static void give_pages(struct receive_queue *rq, struct page *page){	struct page *end;	 	for (end = page; end->private; end = (struct page *)end->private);	end->private = (unsigned long)rq->pages;	rq->pages = page;}",13463
212,487,CVE-2013-4527,26,"static void update_irq(struct HPETTimer *timer, int set){    int mask;    HPETState *s;    int route;    if (timer->tn <= 1 && hpet_in_legacy_mode(timer->state)) {                 route = (timer->tn == 0) ? 0 : RTC_ISA_IRQ;    } else {        route = timer_int_route(timer);    }    s = timer->state;    mask = 1 << timer->tn;    if (!set || !timer_enabled(timer) || !hpet_enabled(timer->state)) {        s->isr &= ~mask;        if (!timer_fsb_route(timer)) {                         if (route >= ISA_NUM_IRQS) {                qemu_irq_raise(s->irqs[route]);            } else {                qemu_irq_lower(s->irqs[route]);            }        }    } else if (timer_fsb_route(timer)) {        stl_le_phys(&address_space_memory,                    timer->fsb >> 32, timer->fsb & 0xffffffff);    } else if (timer->config & HPET_TN_TYPE_LEVEL) {        s->isr |= mask;                 if (route >= ISA_NUM_IRQS) {            qemu_irq_lower(s->irqs[route]);        } else {            qemu_irq_raise(s->irqs[route]);        }    } else {        s->isr &= ~mask;        qemu_irq_pulse(s->irqs[route]);    }}",2416
632,907,CVE-2013-6381,26,"static void qeth_set_single_write_queues(struct qeth_card *card){	if ((atomic_read(&card->qdio.state) != QETH_QDIO_UNINITIALIZED) &&	    (card->qdio.no_out_queues == 4))		qeth_free_qdio_buffers(card);	card->qdio.no_out_queues = 1;	if (card->qdio.default_out_queue != 0)		dev_info(&card->gdev->dev, ""Priority Queueing not supported\n"");	card->qdio.default_out_queue = 0;}",7336
649,1638,CVE-2015-5156,26,"static int virtnet_receive(struct receive_queue *rq, int budget){	struct virtnet_info *vi = rq->vq->vdev->priv;	unsigned int len, received = 0;	void *buf;	while (received < budget &&	       (buf = virtqueue_get_buf(rq->vq, &len)) != NULL) {		receive_buf(vi, rq, buf, len);		received++;	}	if (rq->vq->num_free > virtqueue_get_vring_size(rq->vq) / 2) {		if (!try_fill_recv(vi, rq, GFP_ATOMIC))			schedule_delayed_work(&vi->refill, 0);	}	return received;}",13495
90,1277,CVE-2013-1929,26,"static int tg3_phy_reset_chanpat(struct tg3 *tp){	int chan;	for (chan = 0; chan < 4; chan++) {		int i;		tg3_writephy(tp, MII_TG3_DSP_ADDRESS,			     (chan * 0x2000) | 0x0200);		tg3_writephy(tp, MII_TG3_DSP_CONTROL, 0x0002);		for (i = 0; i < 6; i++)			tg3_writephy(tp, MII_TG3_DSP_RW_PORT, 0x000);		tg3_writephy(tp, MII_TG3_DSP_CONTROL, 0x0202);		if (tg3_wait_macro_done(tp))			return -EBUSY;	}	return 0;}",9283
762,3205,CVE-2018-17407,26,"static void t1_mark_glyphs(void){    int i;    char *charset = extra_charset();    char *g, *s, *r;    cs_entry *ptr;    if (t1_synthetic || embed_all_glyphs(tex_font)) {          if (cs_tab != NULL)            for (ptr = cs_tab; ptr < cs_ptr; ptr++)                if (ptr->valid)                    ptr->used = true;        if (subr_tab != NULL) {            for (ptr = subr_tab; ptr - subr_tab < subr_size; ptr++)                if (ptr->valid)                    ptr->used = true;            subr_max = subr_size - 1;        }        return;    }    mark_cs(notdef);    for (i = 0; i < 256; i++)        if (is_used_char(i)) {            if (t1_glyph_names[i] == notdef)                pdftex_warn(""character %i is mapped to %s"", i, notdef);            else                mark_cs(t1_glyph_names[i]);        }    if (charset == NULL)        goto set_subr_max;    g = s = charset + 1;      r = strend(g);    while (g < r) {        while (*s != '/' && s < r)            s++;        *s = 0;          mark_cs(g);        g = s + 1;    }  set_subr_max:    if (subr_tab != NULL)        for (subr_max = -1, ptr = subr_tab; ptr - subr_tab < subr_size; ptr++)            if (ptr->used && ptr - subr_tab > subr_max)                subr_max = ptr - subr_tab;}",23639
424,2752,CVE-2017-11328,26,define_function(isum_3){  int a = integer_argument(1);  int b = integer_argument(2);  int c = integer_argument(3);  return_integer(a + b + c);},20534
947,3664,CVE-2015-9289,26,"static int cx24116_wait_for_lnb(struct dvb_frontend *fe){	struct cx24116_state *state = fe->demodulator_priv;	int i;	dprintk(""%s() qstatus = 0x%02x\n"", __func__,		cx24116_readreg(state, CX24116_REG_QSTATUS));	 	for (i = 0; i < 30 ; i++) {		if (cx24116_readreg(state, CX24116_REG_QSTATUS) & 0x20)			return 0;		msleep(10);	}	dprintk(""%s(): LNB not ready\n"", __func__);	return -ETIMEDOUT;  }",28150
509,3009,CVE-2017-5548,26,"static void atusb_tx_done(struct atusb *atusb, int seq){	struct usb_device *usb_dev = atusb->usb_dev;	int expect = atusb->tx_ack_seq;	dev_dbg(&usb_dev->dev, ""atusb_tx_done (0x%02x/0x%02x)\n"", seq, expect);	if (seq == expect) {		 		ieee802154_xmit_complete(atusb->hw, atusb->tx_skb, false);	} else {		 		ieee802154_wake_queue(atusb->hw);		if (atusb->tx_skb)			dev_kfree_skb_irq(atusb->tx_skb);	}}",22048
248,1833,CVE-2016-8658,26,static void wl_deinit_priv(struct brcmf_cfg80211_info *cfg){	cfg->dongle_up = false;	 	brcmf_abort_scanning(cfg);	brcmf_deinit_priv_mem(cfg);},15481
507,2216,CVE-2016-2324,26,"static void add_descendants_to_write_order(struct object_entry **wo,					   unsigned int *endp,					   struct object_entry *e){	int add_to_order = 1;	while (e) {		if (add_to_order) {			struct object_entry *s;			 			add_to_write_order(wo, endp, e);			 			for (s = e->delta_sibling; s; s = s->delta_sibling) {				add_to_write_order(wo, endp, s);			}		}		 		if (e->delta_child) {			add_to_order = 1;			e = e->delta_child;		} else {			add_to_order = 0;			 			if (e->delta_sibling) {				e = e->delta_sibling;				continue;			}			 			e = e->delta;			while (e && !e->delta_sibling) {				 				e = e->delta;			}			if (!e) {				 				return;			}			 			e = e->delta_sibling;		}	};}",17636
713,2125,CVE-2016-4303,26,"iperf_set_test_num_streams(struct iperf_test *ipt, int num_streams){    ipt->num_streams = num_streams;}",17033
322,3925,CVE-2016-1691,26,  FailedJobInterceptor() {},30359
257,243,CVE-2018-10184,26,"static void h2_shutw(struct conn_stream *cs, enum cs_shw_mode mode){	struct h2s *h2s = cs->ctx;	if (h2s->st == H2_SS_HLOC || h2s->st == H2_SS_ERROR || h2s->st == H2_SS_CLOSED)		return;	if (h2s->flags & H2_SF_HEADERS_SENT) {		 		if (!(h2s->flags & (H2_SF_ES_SENT|H2_SF_RST_SENT)) &&		    h2_send_empty_data_es(h2s) <= 0)			goto add_to_list;		if (h2s->st == H2_SS_HREM)			h2s_close(h2s);		else			h2s->st = H2_SS_HLOC;	} else {		 		if (!(h2s->flags & H2_SF_RST_SENT) &&		    h2s_send_rst_stream(h2s->h2c, h2s) <= 0)			goto add_to_list;		if (!(h2s->flags & H2_SF_OUTGOING_DATA) &&		    !(h2s->h2c->flags & (H2_CF_GOAWAY_SENT|H2_CF_GOAWAY_FAILED)) &&		    h2c_send_goaway_error(h2s->h2c, h2s) <= 0)			goto add_to_list;		h2s_close(h2s);	}	if (h2s->h2c->mbuf->o && !(cs->conn->flags & CO_FL_XPRT_WR_ENA))		conn_xprt_want_send(cs->conn); add_to_list:	if (LIST_ISEMPTY(&h2s->list)) {		if (h2s->flags & H2_SF_BLK_MFCTL)			LIST_ADDQ(&h2s->h2c->fctl_list, &h2s->list);		else if (h2s->flags & (H2_SF_BLK_MBUSY|H2_SF_BLK_MROOM))			LIST_ADDQ(&h2s->h2c->send_list, &h2s->list);	}}",1264
167,1633,CVE-2015-5156,26,"static void virtnet_get_drvinfo(struct net_device *dev,				struct ethtool_drvinfo *info){	struct virtnet_info *vi = netdev_priv(dev);	struct virtio_device *vdev = vi->vdev;	strlcpy(info->driver, KBUILD_MODNAME, sizeof(info->driver));	strlcpy(info->version, VIRTNET_DRIVER_VERSION, sizeof(info->version));	strlcpy(info->bus_info, virtio_bus_name(vdev), sizeof(info->bus_info));}",13490
12,1851,CVE-2016-8633,26,static int fwnet_stop(struct net_device *net){	struct fwnet_device *dev = netdev_priv(net);	netif_stop_queue(net);	fwnet_broadcast_stop(dev);	return 0;},15585
293,2701,CVE-2017-16534,26,"int usb_set_configuration(struct usb_device *dev, int configuration){	int i, ret;	struct usb_host_config *cp = NULL;	struct usb_interface **new_interfaces = NULL;	struct usb_hcd *hcd = bus_to_hcd(dev->bus);	int n, nintf;	if (dev->authorized == 0 || configuration == -1)		configuration = 0;	else {		for (i = 0; i < dev->descriptor.bNumConfigurations; i++) {			if (dev->config[i].desc.bConfigurationValue ==					configuration) {				cp = &dev->config[i];				break;			}		}	}	if ((!cp && configuration != 0))		return -EINVAL;	 	if (cp && configuration == 0)		dev_warn(&dev->dev, ""config 0 descriptor??\n"");	 	n = nintf = 0;	if (cp) {		nintf = cp->desc.bNumInterfaces;		new_interfaces = kmalloc(nintf * sizeof(*new_interfaces),				GFP_NOIO);		if (!new_interfaces)			return -ENOMEM;		for (; n < nintf; ++n) {			new_interfaces[n] = kzalloc(					sizeof(struct usb_interface),					GFP_NOIO);			if (!new_interfaces[n]) {				ret = -ENOMEM;free_interfaces:				while (--n >= 0)					kfree(new_interfaces[n]);				kfree(new_interfaces);				return ret;			}		}		i = dev->bus_mA - usb_get_max_power(dev, cp);		if (i < 0)			dev_warn(&dev->dev, ""new config #%d exceeds power ""					""limit by %dmA\n"",					configuration, -i);	}	 	ret = usb_autoresume_device(dev);	if (ret)		goto free_interfaces;	 	if (dev->state != USB_STATE_ADDRESS)		usb_disable_device(dev, 1);	 	 	cancel_async_set_config(dev);	 	mutex_lock(hcd->bandwidth_mutex);	 	if (dev->actconfig && usb_disable_lpm(dev)) {		dev_err(&dev->dev, ""%s Failed to disable LPM\n."", __func__);		mutex_unlock(hcd->bandwidth_mutex);		ret = -ENOMEM;		goto free_interfaces;	}	ret = usb_hcd_alloc_bandwidth(dev, cp, NULL, NULL);	if (ret < 0) {		if (dev->actconfig)			usb_enable_lpm(dev);		mutex_unlock(hcd->bandwidth_mutex);		usb_autosuspend_device(dev);		goto free_interfaces;	}	 	for (i = 0; i < nintf; ++i) {		struct usb_interface_cache *intfc;		struct usb_interface *intf;		struct usb_host_interface *alt;		cp->interface[i] = intf = new_interfaces[i];		intfc = cp->intf_cache[i];		intf->altsetting = intfc->altsetting;		intf->num_altsetting = intfc->num_altsetting;		intf->authorized = !!HCD_INTF_AUTHORIZED(hcd);		kref_get(&intfc->ref);		alt = usb_altnum_to_altsetting(intf, 0);		 		if (!alt)			alt = &intf->altsetting[0];		intf->intf_assoc =			find_iad(dev, cp, alt->desc.bInterfaceNumber);		intf->cur_altsetting = alt;		usb_enable_interface(dev, intf, true);		intf->dev.parent = &dev->dev;		intf->dev.driver = NULL;		intf->dev.bus = &usb_bus_type;		intf->dev.type = &usb_if_device_type;		intf->dev.groups = usb_interface_groups;		 		intf->dev.dma_mask = dev->dev.dma_mask;		intf->dev.dma_pfn_offset = dev->dev.dma_pfn_offset;		INIT_WORK(&intf->reset_ws, __usb_queue_reset_device);		intf->minor = -1;		device_initialize(&intf->dev);		pm_runtime_no_callbacks(&intf->dev);		dev_set_name(&intf->dev, ""%d-%s:%d.%d"",			dev->bus->busnum, dev->devpath,			configuration, alt->desc.bInterfaceNumber);		usb_get_dev(dev);	}	kfree(new_interfaces);	ret = usb_control_msg(dev, usb_sndctrlpipe(dev, 0),			      USB_REQ_SET_CONFIGURATION, 0, configuration, 0,			      NULL, 0, USB_CTRL_SET_TIMEOUT);	if (ret < 0 && cp) {		 		usb_hcd_alloc_bandwidth(dev, NULL, NULL, NULL);		for (i = 0; i < nintf; ++i) {			usb_disable_interface(dev, cp->interface[i], true);			put_device(&cp->interface[i]->dev);			cp->interface[i] = NULL;		}		cp = NULL;	}	dev->actconfig = cp;	mutex_unlock(hcd->bandwidth_mutex);	if (!cp) {		usb_set_device_state(dev, USB_STATE_ADDRESS);		 		usb_autosuspend_device(dev);		return ret;	}	usb_set_device_state(dev, USB_STATE_CONFIGURED);	if (cp->string == NULL &&			!(dev->quirks & USB_QUIRK_CONFIG_INTF_STRINGS))		cp->string = usb_cache_string(dev, cp->desc.iConfiguration);	 	usb_unlocked_enable_lpm(dev);	 	usb_enable_ltm(dev);	 	for (i = 0; i < nintf; ++i) {		struct usb_interface *intf = cp->interface[i];		dev_dbg(&dev->dev,			""adding %s (config #%d, interface %d)\n"",			dev_name(&intf->dev), configuration,			intf->cur_altsetting->desc.bInterfaceNumber);		device_enable_async_suspend(&intf->dev);		ret = device_add(&intf->dev);		if (ret != 0) {			dev_err(&dev->dev, ""device_add(%s) --> %d\n"",				dev_name(&intf->dev), ret);			continue;		}		create_intf_ep_devs(intf);	}	usb_autosuspend_device(dev);	return 0;}",19707
829,1674,CVE-2015-4036,26,"static int vhost_scsi_release(struct inode *inode, struct file *f){	struct vhost_scsi *vs = f->private_data;	struct vhost_scsi_target t;	mutex_lock(&vs->dev.mutex);	memcpy(t.vhost_wwpn, vs->vs_vhost_wwpn, sizeof(t.vhost_wwpn));	mutex_unlock(&vs->dev.mutex);	vhost_scsi_clear_endpoint(vs, &t);	vhost_dev_stop(&vs->dev);	vhost_dev_cleanup(&vs->dev, false);	 	vhost_scsi_flush(vs);	kfree(vs->dev.vqs);	kvfree(vs);	return 0;}",13540
976,3405,CVE-2017-15128,26,"int dissolve_free_huge_page(struct page *page){	int rc = 0;	spin_lock(&hugetlb_lock);	if (PageHuge(page) && !page_count(page)) {		struct page *head = compound_head(page);		struct hstate *h = page_hstate(head);		int nid = page_to_nid(head);		if (h->free_huge_pages - h->resv_huge_pages == 0) {			rc = -EBUSY;			goto out;		}		 		if (PageHWPoison(head) && page != head) {			SetPageHWPoison(page);			ClearPageHWPoison(head);		}		list_del(&head->lru);		h->free_huge_pages--;		h->free_huge_pages_node[nid]--;		h->max_huge_pages--;		update_and_free_page(h, head);	}out:	spin_unlock(&hugetlb_lock);	return rc;}",26165
469,1709,CVE-2015-2831,26,"static int is_a_member(int val,int *vals,int num_vals){  int lokke;  for(lokke=0;lokke<num_vals;lokke++)    if(val==vals[lokke])      return 1;  return 0;}",13710
336,1072,CVE-2013-4263,26,"static void fill_buf(int *data, int w, int h, int linesize, int v){    int y;    for (y = 0; y < h; y++) {        memset(data, v, w);        data += linesize;    }}",7879
963,3686,CVE-2011-5327,26,static void tcm_loop_close_session(struct se_session *se_sess){	return;};,28172
180,1209,CVE-2013-2128,26,"static int tcp_recv_urg(struct sock *sk, struct msghdr *msg, int len, int flags){	struct tcp_sock *tp = tcp_sk(sk);	 	if (sock_flag(sk, SOCK_URGINLINE) || !tp->urg_data ||	    tp->urg_data == TCP_URG_READ)		return -EINVAL;	 	if (sk->sk_state == TCP_CLOSE && !sock_flag(sk, SOCK_DONE))		return -ENOTCONN;	if (tp->urg_data & TCP_URG_VALID) {		int err = 0;		char c = tp->urg_data;		if (!(flags & MSG_PEEK))			tp->urg_data = TCP_URG_READ;		 		msg->msg_flags |= MSG_OOB;		if (len > 0) {			if (!(flags & MSG_TRUNC))				err = memcpy_toiovec(msg->msg_iov, &c, 1);			len = 1;		} else			msg->msg_flags |= MSG_TRUNC;		return err ? -EFAULT : len;	}	if (sk->sk_state == TCP_CLOSE || (sk->sk_shutdown & RCV_SHUTDOWN))		return 0;	 	return -EAGAIN;}",8891
778,1168,CVE-2013-2237,26,static inline int pfkey_xfrm_policy2sec_ctx_size(const struct xfrm_policy *xp){  struct xfrm_sec_ctx *xfrm_ctx = xp->security;	if (xfrm_ctx) {		int len = sizeof(struct sadb_x_sec_ctx);		len += xfrm_ctx->ctx_len;		return PFKEY_ALIGN8(len);	}	return 0;},8757
1019,2284,CVE-2016-2324,26,"static void write_hash_cache(struct sha1file *f,			     struct pack_idx_entry **index,			     int index_nr){	int i;	for (i = 0; i < index_nr; ++i) {		struct object_entry *entry = (struct object_entry *)index[i];		int hash_value = htonl(entry->hash);		sha1write(f, &hash_value, sizeof(hash_value));	}}",17704
756,1481,CVE-2014-3185,26,"static int whiteheat_port_probe(struct usb_serial_port *port){	struct whiteheat_private *info;	info = kzalloc(sizeof(*info), GFP_KERNEL);	if (!info)		return -ENOMEM;	usb_set_serial_port_data(port, info);	return 0;}",11476
870,392,CVE-2016-2857,26,int net_checksum_finish(int sum){    while (sum>>16)	sum = (sum & 0xFFFF)+(sum >> 16);    return ~sum;},2071
102,2506,CVE-2016-1583,26,"cpu_attach_domain(struct sched_domain *sd, struct root_domain *rd, int cpu){	struct rq *rq = cpu_rq(cpu);	struct sched_domain *tmp;	 	for (tmp = sd; tmp; ) {		struct sched_domain *parent = tmp->parent;		if (!parent)			break;		if (sd_parent_degenerate(tmp, parent)) {			tmp->parent = parent->parent;			if (parent->parent)				parent->parent->child = tmp;			 			if (parent->flags & SD_PREFER_SIBLING)				tmp->flags |= SD_PREFER_SIBLING;			destroy_sched_domain(parent, cpu);		} else			tmp = tmp->parent;	}	if (sd && sd_degenerate(sd)) {		tmp = sd;		sd = sd->parent;		destroy_sched_domain(tmp, cpu);		if (sd)			sd->child = NULL;	}	sched_domain_debug(sd, cpu);	rq_attach_root(rq, rd);	tmp = rq->sd;	rcu_assign_pointer(rq->sd, sd);	destroy_sched_domains(tmp, cpu);	update_top_cache_domain(cpu);}",18055
152,306,CVE-2017-5994,26,"vrend_so_target_reference(struct vrend_so_target **ptr, struct vrend_so_target *target){   struct vrend_so_target *old_target = *ptr;   if (pipe_reference(&(*ptr)->reference, &target->reference))      vrend_destroy_so_target(old_target);   *ptr = target;}",1604
210,742,CVE-2010-4650,26,"void fuse_release_common(struct file *file, int opcode){	struct fuse_file *ff;	struct fuse_req *req;	ff = file->private_data;	if (unlikely(!ff))		return;	req = ff->reserved_req;	fuse_prepare_release(ff, file->f_flags, opcode);	 	path_get(&file->f_path);	req->misc.release.path = file->f_path;	 	fuse_file_put(ff);}",7026
14,1815,CVE-2016-8658,26,static int brcmf_get_first_free_bsscfgidx(struct brcmf_pub *drvr){	int bsscfgidx;	for (bsscfgidx = 0; bsscfgidx < BRCMF_MAX_IFS; bsscfgidx++) {		 		if (bsscfgidx == 1)			continue;		if (!drvr->iflist[bsscfgidx])			return bsscfgidx;	}	return -ENOMEM;},15463
652,3308,CVE-2018-10124,26,"int task_set_jobctl_pending(struct task_struct *task, unsigned long mask){	BUG_ON(mask & ~(JOBCTL_PENDING_MASK | JOBCTL_STOP_CONSUME |			JOBCTL_STOP_SIGMASK | JOBCTL_TRAPPING));	BUG_ON((mask & JOBCTL_TRAPPING) && !(mask & JOBCTL_PENDING_MASK));	if (unlikely(fatal_signal_pending(task) || (task->flags & PF_EXITING)))		return false;	if (mask & JOBCTL_STOP_SIGMASK)		task->jobctl &= ~JOBCTL_STOP_SIGMASK;	task->jobctl |= mask;	return true;}",25235
836,2382,CVE-2016-2315,26,"static void cat_blob_write(const char *buf, unsigned long size){	if (write_in_full(cat_blob_fd, buf, size) != size)		die_errno(""Write to frontend failed"");}",17802
360,701,CVE-2011-2182,26,"static int ldm_compare_tocblocks (const struct tocblock *toc1,				   const struct tocblock *toc2){	BUG_ON (!toc1 || !toc2);	return ((toc1->bitmap1_start == toc2->bitmap1_start)	&&		(toc1->bitmap1_size  == toc2->bitmap1_size)	&&		(toc1->bitmap2_start == toc2->bitmap2_start)	&&		(toc1->bitmap2_size  == toc2->bitmap2_size)	&&		!strncmp (toc1->bitmap1_name, toc2->bitmap1_name,			sizeof (toc1->bitmap1_name))		&&		!strncmp (toc1->bitmap2_name, toc2->bitmap2_name,			sizeof (toc1->bitmap2_name)));}",6757
974,3866,CVE-2017-5112,26,"int ValidateCharacter(unsigned char c) {  if (c >= 32 && c <= 126 && c != '""' && c != '$' && c != '`' && c != '@' &&      c != '\\' && c != '\'')    return true;  if (c >= 9 && c <= 13)    return true;  return false;}",29844
365,3340,CVE-2017-1000494,26,"NameValueParserStartElt(void * d, const char * name, int l){	struct NameValueParserData * data = (struct NameValueParserData *)d;	data->topelt = 1;    if(l>63)        l = 63;    memcpy(data->curelt, name, l);    data->curelt[l] = '\0';	data->cdata = NULL;	data->cdatalen = 0;}",25620
572,2976,CVE-2017-7742,26,"s2flac16_array (const short *src, int *dest, int count){	while (--count >= 0)		dest [count] = src [count] ;}  ",21497
928,1748,CVE-2015-1333,26,"static void keyring_revoke(struct key *keyring){	struct assoc_array_edit *edit;	edit = assoc_array_clear(&keyring->keys, &keyring_assoc_array_ops);	if (!IS_ERR(edit)) {		if (edit)			assoc_array_apply_edit(edit);		key_payload_reserve(keyring, 0);	}}",14053
1004,2204,CVE-2016-3955,26,"static void usbip_dump_usb_ctrlrequest(struct usb_ctrlrequest *cmd){	if (!cmd) {		pr_debug(""       : null pointer\n"");		return;	}	pr_debug(""       "");	pr_debug(""bRequestType(%02X) bRequest(%02X) wValue(%04X) wIndex(%04X) wLength(%04X) "",		 cmd->bRequestType, cmd->bRequest,		 cmd->wValue, cmd->wIndex, cmd->wLength);	pr_debug(""\n       "");	if ((cmd->bRequestType & USB_TYPE_MASK) == USB_TYPE_STANDARD) {		pr_debug(""STANDARD "");		switch (cmd->bRequest) {		case USB_REQ_GET_STATUS:			pr_debug(""GET_STATUS\n"");			break;		case USB_REQ_CLEAR_FEATURE:			pr_debug(""CLEAR_FEAT\n"");			break;		case USB_REQ_SET_FEATURE:			pr_debug(""SET_FEAT\n"");			break;		case USB_REQ_SET_ADDRESS:			pr_debug(""SET_ADDRRS\n"");			break;		case USB_REQ_GET_DESCRIPTOR:			pr_debug(""GET_DESCRI\n"");			break;		case USB_REQ_SET_DESCRIPTOR:			pr_debug(""SET_DESCRI\n"");			break;		case USB_REQ_GET_CONFIGURATION:			pr_debug(""GET_CONFIG\n"");			break;		case USB_REQ_SET_CONFIGURATION:			pr_debug(""SET_CONFIG\n"");			break;		case USB_REQ_GET_INTERFACE:			pr_debug(""GET_INTERF\n"");			break;		case USB_REQ_SET_INTERFACE:			pr_debug(""SET_INTERF\n"");			break;		case USB_REQ_SYNCH_FRAME:			pr_debug(""SYNC_FRAME\n"");			break;		default:			pr_debug(""REQ(%02X)\n"", cmd->bRequest);			break;		}		usbip_dump_request_type(cmd->bRequestType);	} else if ((cmd->bRequestType & USB_TYPE_MASK) == USB_TYPE_CLASS) {		pr_debug(""CLASS\n"");	} else if ((cmd->bRequestType & USB_TYPE_MASK) == USB_TYPE_VENDOR) {		pr_debug(""VENDOR\n"");	} else if ((cmd->bRequestType & USB_TYPE_MASK) == USB_TYPE_RESERVED) {		pr_debug(""RESERVED\n"");	}}",17131
345,2385,CVE-2016-2315,26,"static void construct_path_with_fanout(const char *hex_sha1,		unsigned char fanout, char *path){	unsigned int i = 0, j = 0;	if (fanout >= 20)		die(""Too large fanout (%u)"", fanout);	while (fanout) {		path[i++] = hex_sha1[j++];		path[i++] = hex_sha1[j++];		path[i++] = '/';		fanout--;	}	memcpy(path + i, hex_sha1 + j, 40 - j);	path[i + 40 - j] = '\0';}",17805
493,797,CVE-2013-6381,26,"static int qeth_clear_channel(struct qeth_channel *channel){	unsigned long flags;	struct qeth_card *card;	int rc;	card = CARD_FROM_CDEV(channel->ccwdev);	QETH_CARD_TEXT(card, 3, ""clearch"");	spin_lock_irqsave(get_ccwdev_lock(channel->ccwdev), flags);	rc = ccw_device_clear(channel->ccwdev, QETH_CLEAR_CHANNEL_PARM);	spin_unlock_irqrestore(get_ccwdev_lock(channel->ccwdev), flags);	if (rc)		return rc;	rc = wait_event_interruptible_timeout(card->wait_q,			channel->state == CH_STATE_STOPPED, QETH_TIMEOUT);	if (rc == -ERESTARTSYS)		return rc;	if (channel->state != CH_STATE_STOPPED)		return -ETIME;	channel->state = CH_STATE_DOWN;	return 0;}",7226
504,1227,CVE-2013-1929,26,"static void tg3_free_consistent(struct tg3 *tp){	int i;	for (i = 0; i < tp->irq_cnt; i++) {		struct tg3_napi *tnapi = &tp->napi[i];		if (tnapi->hw_status) {			dma_free_coherent(&tp->pdev->dev, TG3_HW_STATUS_SIZE,					  tnapi->hw_status,					  tnapi->status_mapping);			tnapi->hw_status = NULL;		}	}	tg3_mem_rx_release(tp);	tg3_mem_tx_release(tp);	if (tp->hw_stats) {		dma_free_coherent(&tp->pdev->dev, sizeof(struct tg3_hw_stats),				  tp->hw_stats, tp->stats_mapping);		tp->hw_stats = NULL;	}}",9233
1006,1084,CVE-2013-4244,26,"usage(void){	char buf[BUFSIZ];	int i;	setbuf(stderr, buf);        fprintf(stderr, ""%s\n\n"", TIFFGetVersion());	for (i = 0; stuff[i] != NULL; i++)		fprintf(stderr, ""%s\n"", stuff[i]);	exit(-1);}",7937
720,1845,CVE-2016-8633,26,"static inline void fwnet_make_uf_hdr(struct rfc2734_header *hdr,		unsigned ether_type){	hdr->w0 = fwnet_set_hdr_lf(RFC2374_HDR_UNFRAG)		  | fwnet_set_hdr_ether_type(ether_type);}",15579
237,1706,CVE-2015-3214,26,int pit_has_pending_timer(struct kvm_vcpu *vcpu){	struct kvm_pit *pit = vcpu->kvm->arch.vpit;	if (pit && kvm_vcpu_is_bsp(vcpu) && pit->pit_state.irq_ack)		return atomic_read(&pit->pit_state.pit_timer.pending);	return 0;},13617
581,3546,CVE-2018-20855,26,"static void mlx5_ib_wq_event(struct mlx5_core_qp *core_qp, int type){	struct mlx5_ib_rwq *rwq = to_mibrwq(core_qp);	struct mlx5_ib_dev *dev = to_mdev(rwq->ibwq.device);	struct ib_event event;	if (rwq->ibwq.event_handler) {		event.device     = rwq->ibwq.device;		event.element.wq = &rwq->ibwq;		switch (type) {		case MLX5_EVENT_TYPE_WQ_CATAS_ERROR:			event.event = IB_EVENT_WQ_FATAL;			break;		default:			mlx5_ib_warn(dev, ""Unexpected event type %d on WQ %06x\n"", type, core_qp->qpn);			return;		}		rwq->ibwq.event_handler(&event, rwq->ibwq.wq_context);	}}",27574
739,3219,CVE-2018-17407,26,"static void destroy_t1_glyph_tree(struct avl_table *gl_tree){    avl_destroy(gl_tree, NULL);}",23653
348,4076,CVE-2014-0049,26,"static int complete_emulated_mmio(struct kvm_vcpu *vcpu){	struct kvm_run *run = vcpu->run;	struct kvm_mmio_fragment *frag;	unsigned len;	BUG_ON(!vcpu->mmio_needed);	 	frag = &vcpu->mmio_fragments[vcpu->mmio_cur_fragment];	len = min(8u, frag->len);	if (!vcpu->mmio_is_write)		memcpy(frag->data, run->mmio.data, len);	if (frag->len <= 8) {		 		frag++;		vcpu->mmio_cur_fragment++;	} else {		 		frag->data += len;		frag->gpa += len; 		frag->len -= len; 	} 	if (vcpu->mmio_cur_fragment == vcpu->mmio_nr_fragments) { 		vcpu->mmio_needed = 0;  		 		if (vcpu->mmio_is_write)			return 1;		vcpu->mmio_read_completed = 1;		return complete_emulated_io(vcpu);	}	run->exit_reason = KVM_EXIT_MMIO;	run->mmio.phys_addr = frag->gpa;	if (vcpu->mmio_is_write)		memcpy(run->mmio.data, frag->data, min(8u, frag->len));	run->mmio.len = min(8u, frag->len);	run->mmio.is_write = vcpu->mmio_is_write;	vcpu->arch.complete_userspace_io = complete_emulated_mmio;	return 0;}",31173
450,103,CVE-2013-4282,26,"static void reds_mig_finished(int completed){    spice_info(NULL);    reds->mig_inprogress = TRUE;    if (reds->src_do_seamless_migrate && completed) {        reds_migrate_channels_seamless();    } else {        main_channel_migrate_src_complete(reds->main_channel, completed);    }    if (completed) {        reds_mig_fill_wait_disconnect();    } else {        reds_mig_cleanup();    }    reds_mig_release();}",413
1017,3501,CVE-2018-20855,26,"static int _mlx5_ib_post_recv(struct ib_qp *ibqp, const struct ib_recv_wr *wr,		      const struct ib_recv_wr **bad_wr, int drain){	struct mlx5_ib_qp *qp = to_mqp(ibqp);	struct mlx5_wqe_data_seg *scat;	struct mlx5_rwqe_sig *sig;	struct mlx5_ib_dev *dev = to_mdev(ibqp->device);	struct mlx5_core_dev *mdev = dev->mdev;	unsigned long flags;	int err = 0;	int nreq;	int ind;	int i;	if (unlikely(ibqp->qp_type == IB_QPT_GSI))		return mlx5_ib_gsi_post_recv(ibqp, wr, bad_wr);	spin_lock_irqsave(&qp->rq.lock, flags);	if (mdev->state == MLX5_DEVICE_STATE_INTERNAL_ERROR && !drain) {		err = -EIO;		*bad_wr = wr;		nreq = 0;		goto out;	}	ind = qp->rq.head & (qp->rq.wqe_cnt - 1);	for (nreq = 0; wr; nreq++, wr = wr->next) {		if (mlx5_wq_overflow(&qp->rq, nreq, qp->ibqp.recv_cq)) {			err = -ENOMEM;			*bad_wr = wr;			goto out;		}		if (unlikely(wr->num_sge > qp->rq.max_gs)) {			err = -EINVAL;			*bad_wr = wr;			goto out;		}		scat = get_recv_wqe(qp, ind);		if (qp->wq_sig)			scat++;		for (i = 0; i < wr->num_sge; i++)			set_data_ptr_seg(scat + i, wr->sg_list + i);		if (i < qp->rq.max_gs) {			scat[i].byte_count = 0;			scat[i].lkey       = cpu_to_be32(MLX5_INVALID_LKEY);			scat[i].addr       = 0;		}		if (qp->wq_sig) {			sig = (struct mlx5_rwqe_sig *)scat;			set_sig_seg(sig, (qp->rq.max_gs + 1) << 2);		}		qp->rq.wrid[ind] = wr->wr_id;		ind = (ind + 1) & (qp->rq.wqe_cnt - 1);	}out:	if (likely(nreq)) {		qp->rq.head += nreq;		 		wmb();		*qp->db.db = cpu_to_be32(qp->rq.head & 0xffff);	}	spin_unlock_irqrestore(&qp->rq.lock, flags);	return err;}",27529
413,2350,CVE-2016-2324,26,"static void limit_left_right(struct commit_list *list, struct rev_info *revs){	struct commit_list *p;	for (p = list; p; p = p->next) {		struct commit *commit = p->item;		if (revs->right_only) {			if (commit->object.flags & SYMMETRIC_LEFT)				commit->object.flags |= SHOWN;		} else	 			if (!(commit->object.flags & SYMMETRIC_LEFT))				commit->object.flags |= SHOWN;	}}",17770
510,2523,CVE-2016-1583,26,"int find_numa_distance(int distance){	int i;	if (distance == node_distance(0, 0))		return true;	for (i = 0; i < sched_domains_numa_levels; i++) {		if (sched_domains_numa_distance[i] == distance)			return true;	}	return false;}",18072
811,3475,CVE-2019-14323,26,static int filter_addr(struct sockaddr *sa){	struct ifsock *ifs;	struct sockaddr_in *sin = (struct sockaddr_in *)sa;	if (!sa)		return 1;	if (sa->sa_family != AF_INET)		return 1;	if (sin->sin_addr.s_addr == htonl(INADDR_ANY))		return 1;	if (sin->sin_addr.s_addr == htonl(INADDR_LOOPBACK))		return 1;	ifs = find_outbound(sa);	if (ifs) {		if (ifs->addr.sin_addr.s_addr != htonl(INADDR_ANY))			return 1;	}	return 0;},26699
746,1796,CVE-2016-8658,26,"void brcmf_abort_scanning(struct brcmf_cfg80211_info *cfg){	struct escan_info *escan = &cfg->escan_info;	set_bit(BRCMF_SCAN_STATUS_ABORT, &cfg->scan_status);	if (cfg->scan_request) {		escan->escan_state = WL_ESCAN_STATE_IDLE;		brcmf_notify_escan_complete(cfg, escan->ifp, true, true);	}	clear_bit(BRCMF_SCAN_STATUS_BUSY, &cfg->scan_status);	clear_bit(BRCMF_SCAN_STATUS_ABORT, &cfg->scan_status);}",15444
78,2309,CVE-2016-2324,26,"static void add_header_grep(struct rev_info *revs, enum grep_header_field field, const char *pattern){	append_header_grep_pattern(&revs->grep_filter, field, pattern);}",17729
495,2857,CVE-2017-8067,26,"static void remove_controlq_data(struct ports_device *portdev){	struct port_buffer *buf;	unsigned int len;	if (!use_multiport(portdev))		return;	while ((buf = virtqueue_get_buf(portdev->c_ivq, &len)))		free_buf(buf, true);	while ((buf = virtqueue_detach_unused_buf(portdev->c_ivq)))		free_buf(buf, true);}",21334
707,4070,CVE-2014-3185,26,"static void command_port_read_callback(struct urb *urb){	struct usb_serial_port *command_port = urb->context;	struct whiteheat_command_private *command_info;	int status = urb->status;	unsigned char *data = urb->transfer_buffer;	int result;	command_info = usb_get_serial_port_data(command_port);	if (!command_info) { 		dev_dbg(&urb->dev->dev, ""%s - command_info is NULL, exiting.\n"", __func__); 		return; 	} 	if (status) { 		dev_dbg(&urb->dev->dev, ""%s - nonzero urb status: %d\n"", __func__, status); 		if (status != -ENOENT)			command_info->command_finished = WHITEHEAT_CMD_FAILURE;		wake_up(&command_info->wait_command);		return;	}	usb_serial_debug_data(&command_port->dev, __func__, urb->actual_length, data);	if (data[0] == WHITEHEAT_CMD_COMPLETE) {		command_info->command_finished = WHITEHEAT_CMD_COMPLETE;		wake_up(&command_info->wait_command);	} else if (data[0] == WHITEHEAT_CMD_FAILURE) {		command_info->command_finished = WHITEHEAT_CMD_FAILURE;		wake_up(&command_info->wait_command);	} else if (data[0] == WHITEHEAT_EVENT) { 		  		dev_dbg(&urb->dev->dev, ""%s - event received\n"", __func__);	} else if (data[0] == WHITEHEAT_GET_DTR_RTS) { 		memcpy(command_info->result_buffer, &data[1], 						urb->actual_length - 1); 		command_info->command_finished = WHITEHEAT_CMD_COMPLETE;		wake_up(&command_info->wait_command);	} else		dev_dbg(&urb->dev->dev, ""%s - bad reply from firmware\n"", __func__);	 	result = usb_submit_urb(command_port->read_urb, GFP_ATOMIC);	if (result)		dev_dbg(&urb->dev->dev, ""%s - failed resubmitting read urb, error %d\n"",			__func__, result);}",31156
612,201,CVE-2015-1345,26,"treedelta (struct tree const *tree,           unsigned int depth,           unsigned char delta[]){  if (!tree)    return;  treedelta(tree->llink, depth, delta);  treedelta(tree->rlink, depth, delta);  if (depth < delta[tree->label])    delta[tree->label] = depth;}",889
821,443,CVE-2018-20815,26,"int qemu_fdt_setprop_u64(void *fdt, const char *node_path,                         const char *property, int val){    val = cpu_to_be64(val);    return qemu_fdt_setprop(fdt, node_path, property, &val, sizeof(val));}",2168
698,2832,CVE-2017-8069,26,"static void write_bulk_callback(struct urb *urb){	rtl8150_t *dev;	int status = urb->status;	dev = urb->context;	if (!dev)		return;	dev_kfree_skb_irq(dev->tx_skb);	if (!netif_device_present(dev->netdev))		return;	if (status)		dev_info(&urb->dev->dev, ""%s: Tx status %d\n"",			 dev->netdev->name, status);	netif_trans_update(dev->netdev);	netif_wake_queue(dev->netdev);}",21309
637,2413,CVE-2016-2315,26,"static void option_active_branches(const char *branches){	max_active_branches = ulong_arg(""--active-branches"", branches);}",17833
897,145,CVE-2017-13090,26,limit_bandwidth_reset (void){  xzero (limit_data);},599
946,57,CVE-2019-15938,26,"static int rpc_lookup_req(struct nfs_priv *npriv, int prog, int ver){	int data[16];	struct packet *nfs_packet;	int port;	data[0] = 0; data[1] = 0;	 	data[2] = 0; data[3] = 0;	 	data[4] = hton32(prog);	data[5] = hton32(ver);	data[6] = hton32(17);	 	data[7] = 0;	nfs_packet = rpc_req(npriv, PROG_PORTMAP, PORTMAP_GETPORT, data, 8);	if (IS_ERR(nfs_packet))		return PTR_ERR(nfs_packet);	port = ntoh32(net_read_uint32(nfs_packet->data + sizeof(struct rpc_reply)));	free(nfs_packet);	return port;}",288
540,925,CVE-2013-6381,26,"int qeth_wait_for_threads(struct qeth_card *card, unsigned long threads){	if (qeth_is_recovery_task(card))		return 0;	return wait_event_interruptible(card->wait_q,			qeth_threads_running(card, threads) == 0);}",7354
997,807,CVE-2013-6381,26,"static int qeth_cm_enable(struct qeth_card *card){	int rc;	struct qeth_cmd_buffer *iob;	QETH_DBF_TEXT(SETUP, 2, ""cmenable"");	iob = qeth_wait_for_buffer(&card->write);	memcpy(iob->data, CM_ENABLE, CM_ENABLE_SIZE);	memcpy(QETH_CM_ENABLE_ISSUER_RM_TOKEN(iob->data),	       &card->token.issuer_rm_r, QETH_MPC_TOKEN_LENGTH);	memcpy(QETH_CM_ENABLE_FILTER_TOKEN(iob->data),	       &card->token.cm_filter_w, QETH_MPC_TOKEN_LENGTH);	rc = qeth_send_control_data(card, CM_ENABLE_SIZE, iob,				    qeth_cm_enable_cb, NULL);	return rc;}",7236
497,2849,CVE-2017-8067,26,"static void notifier_del_vio(struct hvc_struct *hp, int data){	hp->irq_requested = 0;}",21326
1010,1469,CVE-2014-3186,26,"static int picolcd_probe_bootloader(struct hid_device *hdev, struct picolcd_data *data){	picolcd_init_devfs(data, NULL, NULL,			picolcd_out_report(REPORT_BL_READ_MEMORY, hdev),			picolcd_out_report(REPORT_BL_WRITE_MEMORY, hdev), NULL);	return 0;}",11464
98,1183,CVE-2013-2220,26,"rad_add_server(struct rad_handle *h, const char *host, int port,    const char *secret, int timeout, int tries){	struct rad_server *srvp;	if (h->num_servers >= MAXSERVERS) {		generr(h, ""Too many RADIUS servers specified"");		return -1;	}	srvp = &h->servers[h->num_servers];	memset(&srvp->addr, 0, sizeof srvp->addr);	srvp->addr.sin_family = AF_INET;	if (!inet_aton(host, &srvp->addr.sin_addr)) {		struct hostent *hent;		if ((hent = gethostbyname(host)) == NULL) {			generr(h, ""%s: host not found"", host);			return -1;		}		memcpy(&srvp->addr.sin_addr, hent->h_addr,		    sizeof srvp->addr.sin_addr);	}	if (port != 0)		srvp->addr.sin_port = htons((short) port);	else {		struct servent *sent;		if (h->type == RADIUS_AUTH)			srvp->addr.sin_port =			    (sent = getservbyname(""radius"", ""udp"")) != NULL ?				sent->s_port : htons(RADIUS_PORT);		else			srvp->addr.sin_port =			    (sent = getservbyname(""radacct"", ""udp"")) != NULL ?				sent->s_port : htons(RADACCT_PORT);	}	if ((srvp->secret = strdup(secret)) == NULL) {		generr(h, ""Out of memory"");		return -1;	}	srvp->timeout = timeout;	srvp->max_tries = tries;	srvp->num_tries = 0;	h->num_servers++;	return 0;}",8773
986,2196,CVE-2016-3955,26,"static void correct_endian_cmd_unlink(struct usbip_header_cmd_unlink *pdu,				      int send){	if (send)		pdu->seqnum = cpu_to_be32(pdu->seqnum);	else		pdu->seqnum = be32_to_cpu(pdu->seqnum);}",17123
758,1682,CVE-2015-3905,26,"static void eexec_start(char *string){  eexec_string(""currentfile eexec\n"");  if (pfb && w.blocktyp != PFB_BINARY) {    pfb_writer_output_block(&w);    w.blocktyp = PFB_BINARY;  }  in_eexec = 1;  er = 55665;  eexec_byte(0);  eexec_byte(0);  eexec_byte(0);  eexec_byte(0);  eexec_string(string);}",13580
942,1587,CVE-2015-5283,26,"static void sctp_v4_from_sk(union sctp_addr *addr, struct sock *sk){	addr->v4.sin_family = AF_INET;	addr->v4.sin_port = 0;	addr->v4.sin_addr.s_addr = inet_sk(sk)->inet_rcv_saddr;}",13442
189,1978,CVE-2016-4998,26,"static int compat_calc_entry(const struct arpt_entry *e,			     const struct xt_table_info *info,			     const void *base, struct xt_table_info *newinfo){	const struct xt_entry_target *t;	unsigned int entry_offset;	int off, i, ret;	off = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);	entry_offset = (void *)e - base;	t = arpt_get_target_c(e);	off += xt_compat_target_offset(t->u.kernel.target);	newinfo->size -= off;	ret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);	if (ret)		return ret;	for (i = 0; i < NF_ARP_NUMHOOKS; i++) {		if (info->hook_entry[i] &&		    (e < (struct arpt_entry *)(base + info->hook_entry[i])))			newinfo->hook_entry[i] -= off;		if (info->underflow[i] &&		    (e < (struct arpt_entry *)(base + info->underflow[i])))			newinfo->underflow[i] -= off;	}	return 0;}",16544
357,355,CVE-2010-2520,26,"  Ins_ENDF( INS_ARG )  {    TT_CallRec*  pRec;    FT_UNUSED_ARG;    if ( CUR.callTop <= 0 )          {      CUR.error = TT_Err_ENDF_In_Exec_Stream;      return;    }    CUR.callTop--;    pRec = &CUR.callStack[CUR.callTop];    pRec->Cur_Count--;    CUR.step_ins = FALSE;    if ( pRec->Cur_Count > 0 )    {      CUR.callTop++;      CUR.IP = pRec->Cur_Restart;    }    else             INS_Goto_CodeRange( pRec->Caller_Range,                          pRec->Caller_IP );                                }",1834
409,2542,CVE-2016-1583,26,"static int migration_cpu_stop(void *data){	struct migration_arg *arg = data;	struct task_struct *p = arg->task;	struct rq *rq = this_rq();	 	local_irq_disable();	 	sched_ttwu_pending();	raw_spin_lock(&p->pi_lock);	raw_spin_lock(&rq->lock);	 	if (task_rq(p) == rq && task_on_rq_queued(p))		rq = __migrate_task(rq, p, arg->dest_cpu);	raw_spin_unlock(&rq->lock);	raw_spin_unlock(&p->pi_lock);	local_irq_enable();	return 0;}",18091
140,2729,CVE-2017-14727,26,"logger_stop_all (int write_info_line){    while (logger_buffers)    {        logger_stop (logger_buffers, write_info_line);    }}",20131
462,986,CVE-2013-4591,26,"nfs4_proc_lookup_mountpoint(struct inode *dir, struct qstr *name,			    struct nfs_fh *fhandle, struct nfs_fattr *fattr){	int status;	struct rpc_clnt *client = rpc_clone_client(NFS_CLIENT(dir));	status = nfs4_proc_lookup_common(&client, dir, name, fhandle, fattr);	if (status < 0) {		rpc_shutdown_client(client);		return ERR_PTR(status);	}	return client;}",7583
944,678,CVE-2011-2517,26,"static int nl80211_parse_key_old(struct genl_info *info, struct key_parse *k){	if (info->attrs[NL80211_ATTR_KEY_DATA]) {		k->p.key = nla_data(info->attrs[NL80211_ATTR_KEY_DATA]);		k->p.key_len = nla_len(info->attrs[NL80211_ATTR_KEY_DATA]);	}	if (info->attrs[NL80211_ATTR_KEY_SEQ]) {		k->p.seq = nla_data(info->attrs[NL80211_ATTR_KEY_SEQ]);		k->p.seq_len = nla_len(info->attrs[NL80211_ATTR_KEY_SEQ]);	}	if (info->attrs[NL80211_ATTR_KEY_IDX])		k->idx = nla_get_u8(info->attrs[NL80211_ATTR_KEY_IDX]);	if (info->attrs[NL80211_ATTR_KEY_CIPHER])		k->p.cipher = nla_get_u32(info->attrs[NL80211_ATTR_KEY_CIPHER]);	k->def = !!info->attrs[NL80211_ATTR_KEY_DEFAULT];	k->defmgmt = !!info->attrs[NL80211_ATTR_KEY_DEFAULT_MGMT];	if (k->def) {		k->def_uni = true;		k->def_multi = true;	}	if (k->defmgmt)		k->def_multi = true;	if (info->attrs[NL80211_ATTR_KEY_TYPE]) {		k->type = nla_get_u32(info->attrs[NL80211_ATTR_KEY_TYPE]);		if (k->type < 0 || k->type >= NUM_NL80211_KEYTYPES)			return -EINVAL;	}	if (info->attrs[NL80211_ATTR_KEY_DEFAULT_TYPES]) {		struct nlattr *kdt[NUM_NL80211_KEY_DEFAULT_TYPES];		int err = nla_parse_nested(				kdt, NUM_NL80211_KEY_DEFAULT_TYPES - 1,				info->attrs[NL80211_ATTR_KEY_DEFAULT_TYPES],				nl80211_key_default_policy);		if (err)			return err;		k->def_uni = kdt[NL80211_KEY_DEFAULT_TYPE_UNICAST];		k->def_multi = kdt[NL80211_KEY_DEFAULT_TYPE_MULTICAST];	}	return 0;}",6577
930,2870,CVE-2017-8066,26,"static struct gs_tx_context *gs_get_tx_context(struct gs_can *dev,					       unsigned int id){	unsigned long flags;	if (id < GS_MAX_TX_URBS) {		spin_lock_irqsave(&dev->tx_ctx_lock, flags);		if (dev->tx_context[id].echo_id == id) {			spin_unlock_irqrestore(&dev->tx_ctx_lock, flags);			return &dev->tx_context[id];		}		spin_unlock_irqrestore(&dev->tx_ctx_lock, flags);	}	return NULL;}",21347
583,3599,CVE-2018-20182,26,"rdpsnd_show_help(void){	struct audio_driver *pos;	rdpsnd_register_drivers(NULL);	pos = drivers;	while (pos != NULL)	{		fprintf(stderr, ""                     %s:\t%s\n"", pos->name, pos->description);		pos = pos->next;	}}",27897
358,3395,CVE-2017-18193,26,"void init_extent_cache_info(struct f2fs_sb_info *sbi){	INIT_RADIX_TREE(&sbi->extent_tree_root, GFP_NOIO);	mutex_init(&sbi->extent_tree_lock);	INIT_LIST_HEAD(&sbi->extent_list);	spin_lock_init(&sbi->extent_lock);	atomic_set(&sbi->total_ext_tree, 0);	INIT_LIST_HEAD(&sbi->zombie_list);	atomic_set(&sbi->total_zombie_tree, 0);	atomic_set(&sbi->total_ext_node, 0);}",26073
998,488,CVE-2013-4526,26,static void sysbus_ahci_register_types(void){    type_register_static(&sysbus_ahci_info);},2417
521,3840,CVE-2017-5122,26,  TestDragWindowDelegate() { set_window_component(HTCAPTION); },29818
110,2536,CVE-2016-1583,26,"static void init_sched_groups_capacity(int cpu, struct sched_domain *sd){	struct sched_group *sg = sd->groups;	WARN_ON(!sg);	do {		sg->group_weight = cpumask_weight(sched_group_cpus(sg));		sg = sg->next;	} while (sg != sd->groups);	if (cpu != group_balance_cpu(sg))		return;	update_group_capacity(sd, cpu);	atomic_set(&sg->sgc->nr_busy_cpus, sg->group_weight);}",18085
732,1974,CVE-2016-4998,26,static inline int check_entry(const struct arpt_entry *e){	const struct xt_entry_target *t;	if (!arp_checkentry(&e->arp))		return -EINVAL;	if (e->target_offset + sizeof(struct xt_entry_target) > e->next_offset)		return -EINVAL;	t = arpt_get_target_c(e);	if (e->target_offset + t->u.target_size > e->next_offset)		return -EINVAL;	return 0;},16540
956,505,CVE-2012-6711,26,all_visible_functions (){  return (fapply (visible_var));},2545
570,2188,CVE-2016-4301,26,"mtree_bid(struct archive_read *a, int best_bid){	const char *signature = ""#mtree"";	const char *p;	(void)best_bid;  	 	p = __archive_read_ahead(a, strlen(signature), NULL);	if (p == NULL)		return (-1);	if (memcmp(p, signature, strlen(signature)) == 0)		return (8 * (int)strlen(signature));	 	return (detect_form(a, NULL));}",17096
611,1192,CVE-2013-2220,26,"rad_put_vendor_string(struct rad_handle *h, int vendor, int type,    const char *str){	return (rad_put_vendor_attr(h, vendor, type, str, strlen(str)));}",8782
936,3160,CVE-2015-8026,26,"static int get_int_option(const char* options, const char* option_name,		int base, int default_value){	const char* p = get_option(options, option_name);	if (p == NULL)		return default_value;	return strtol(p, NULL, base);}",22888
367,2264,CVE-2016-2324,26,"static void print_var_int(const char *var, int val){	printf(""%s=%d\n"", var, val);}",17684
147,3658,CVE-2016-10764,26,"static int cqspi_wait_idle(struct cqspi_st *cqspi){	const unsigned int poll_idle_retry = 3;	unsigned int count = 0;	unsigned long timeout;	timeout = jiffies + msecs_to_jiffies(CQSPI_TIMEOUT_MS);	while (1) {		 		if (cqspi_is_idle(cqspi))			count++;		else			count = 0;		if (count >= poll_idle_retry)			return 0;		if (time_after(jiffies, timeout)) {			 			dev_err(&cqspi->pdev->dev,				""QSPI is still busy after %dms timeout.\n"",				CQSPI_TIMEOUT_MS);			return -ETIMEDOUT;		}		cpu_relax();	}}",28117
643,2341,CVE-2016-2324,26,"static int handle_one_ref(const char *path, const struct object_id *oid,			  int flag, void *cb_data){	struct all_refs_cb *cb = cb_data;	struct object *object;	if (ref_excluded(cb->all_revs->ref_excludes, path))	    return 0;	object = get_reference(cb->all_revs, path, oid->hash, cb->all_flags);	add_rev_cmdline(cb->all_revs, object, path, REV_CMD_REF, cb->all_flags);	add_pending_sha1(cb->all_revs, path, oid->hash, cb->all_flags);	return 0;}",17761
308,2748,CVE-2017-11721,26,"void MSG_ReportChangeVectors_f( void ) {	int i;	for(i=0;i<256;i++) {		if (pcount[i]) {			Com_Printf(""%d used %d\n"", i, pcount[i]);		}	}}",20454
700,2971,CVE-2017-7742,26,"f2flac8_array (const float *src, int *dest, int count, int normalize){	float normfact = normalize ? (1.0 * 0x7F) : 1.0 ;	while (--count >= 0)		dest [count] = lrintf (src [count] * normfact) ;}  ",21492
863,2704,CVE-2017-16534,26,"void usb_sg_wait(struct usb_sg_request *io){	int i;	int entries = io->entries;	 	spin_lock_irq(&io->lock);	i = 0;	while (i < entries && !io->status) {		int retval;		io->urbs[i]->dev = io->dev;		spin_unlock_irq(&io->lock);		retval = usb_submit_urb(io->urbs[i], GFP_NOIO);		switch (retval) {			 		case -ENXIO:	 		case -EAGAIN:		case -ENOMEM:			retval = 0;			yield();			break;			 		case 0:			++i;			cpu_relax();			break;			 		default:			io->urbs[i]->status = retval;			dev_dbg(&io->dev->dev, ""%s, submit --> %d\n"",				__func__, retval);			usb_sg_cancel(io);		}		spin_lock_irq(&io->lock);		if (retval && (io->status == 0 || io->status == -ECONNRESET))			io->status = retval;	}	io->count -= entries - i;	if (io->count == 0)		complete(&io->complete);	spin_unlock_irq(&io->lock);	 	wait_for_completion(&io->complete);	sg_clean(io);}",19710
478,2578,CVE-2016-1583,26,static int sched_rt_global_validate(void){	if (sysctl_sched_rt_period <= 0)		return -EINVAL;	if ((sysctl_sched_rt_runtime != RUNTIME_INF) &&		(sysctl_sched_rt_runtime > sysctl_sched_rt_period))		return -EINVAL;	return 0;},18127
772,2679,CVE-2017-16534,26,static void sg_clean(struct usb_sg_request *io){	if (io->urbs) {		while (io->entries--)			usb_free_urb(io->urbs[io->entries]);		kfree(io->urbs);		io->urbs = NULL;	}	io->dev = NULL;},19685
790,2901,CVE-2017-8064,26,"static int dvb_usbv2_adapter_exit(struct dvb_usb_device *d){	int i;	dev_dbg(&d->udev->dev, ""%s:\n"", __func__);	for (i = MAX_NO_OF_ADAPTER_PER_DEVICE - 1; i >= 0; i--) {		if (d->adapter[i].props) {			dvb_usbv2_adapter_dvb_exit(&d->adapter[i]);			dvb_usbv2_adapter_stream_exit(&d->adapter[i]);			dvb_usbv2_adapter_frontend_exit(&d->adapter[i]);			dvb_usbv2_media_device_unregister(&d->adapter[i]);		}	}	return 0;}",21378
685,1798,CVE-2016-8658,26,"static int brcmf_cfg80211_del_ap_iface(struct wiphy *wiphy,				       struct wireless_dev *wdev){	struct brcmf_cfg80211_info *cfg = wiphy_priv(wiphy);	struct net_device *ndev = wdev->netdev;	struct brcmf_if *ifp = netdev_priv(ndev);	int ret;	int err;	brcmf_cfg80211_arm_vif_event(cfg, ifp->vif);	err = brcmf_fil_bsscfg_data_set(ifp, ""interface_remove"", NULL, 0);	if (err) {		brcmf_err(""interface_remove failed %d\n"", err);		goto err_unarm;	}	 	ret = brcmf_cfg80211_wait_vif_event(cfg, BRCMF_E_IF_DEL,					    BRCMF_VIF_EVENT_TIMEOUT);	if (!ret) {		brcmf_err(""timeout occurred\n"");		err = -EIO;		goto err_unarm;	}	brcmf_remove_interface(ifp, true);err_unarm:	brcmf_cfg80211_arm_vif_event(cfg, NULL);	return err;}",15446
689,1102,CVE-2013-2237,26,"static struct sk_buff *__pfkey_xfrm_state2msg(const struct xfrm_state *x,					      int add_keys, int hsc){	struct sk_buff *skb;	struct sadb_msg *hdr;	struct sadb_sa *sa;	struct sadb_lifetime *lifetime;	struct sadb_address *addr;	struct sadb_key *key;	struct sadb_x_sa2 *sa2;	struct sadb_x_sec_ctx *sec_ctx;	struct xfrm_sec_ctx *xfrm_ctx;	int ctx_size = 0;	int size;	int auth_key_size = 0;	int encrypt_key_size = 0;	int sockaddr_size;	struct xfrm_encap_tmpl *natt = NULL;	int mode;	 	sockaddr_size = pfkey_sockaddr_size(x->props.family);	if (!sockaddr_size)		return ERR_PTR(-EINVAL);	 	size = sizeof(struct sadb_msg) +sizeof(struct sadb_sa) +		sizeof(struct sadb_lifetime) +		((hsc & 1) ? sizeof(struct sadb_lifetime) : 0) +		((hsc & 2) ? sizeof(struct sadb_lifetime) : 0) +			sizeof(struct sadb_address)*2 +				sockaddr_size*2 +					sizeof(struct sadb_x_sa2);	if ((xfrm_ctx = x->security)) {		ctx_size = PFKEY_ALIGN8(xfrm_ctx->ctx_len);		size += sizeof(struct sadb_x_sec_ctx) + ctx_size;	}	 	if (!xfrm_addr_equal(&x->sel.saddr, &x->props.saddr, x->props.family))		size += sizeof(struct sadb_address) + sockaddr_size;	if (add_keys) {		if (x->aalg && x->aalg->alg_key_len) {			auth_key_size =				PFKEY_ALIGN8((x->aalg->alg_key_len + 7) / 8);			size += sizeof(struct sadb_key) + auth_key_size;		}		if (x->ealg && x->ealg->alg_key_len) {			encrypt_key_size =				PFKEY_ALIGN8((x->ealg->alg_key_len+7) / 8);			size += sizeof(struct sadb_key) + encrypt_key_size;		}	}	if (x->encap)		natt = x->encap;	if (natt && natt->encap_type) {		size += sizeof(struct sadb_x_nat_t_type);		size += sizeof(struct sadb_x_nat_t_port);		size += sizeof(struct sadb_x_nat_t_port);	}	skb =  alloc_skb(size + 16, GFP_ATOMIC);	if (skb == NULL)		return ERR_PTR(-ENOBUFS);	 	hdr = (struct sadb_msg *) skb_put(skb, sizeof(struct sadb_msg));	memset(hdr, 0, size);	 	hdr->sadb_msg_len = size / sizeof(int);	 	sa = (struct sadb_sa *)  skb_put(skb, sizeof(struct sadb_sa));	sa->sadb_sa_len = sizeof(struct sadb_sa)/sizeof(int);	sa->sadb_sa_exttype = SADB_EXT_SA;	sa->sadb_sa_spi = x->id.spi;	sa->sadb_sa_replay = x->props.replay_window;	switch (x->km.state) {	case XFRM_STATE_VALID:		sa->sadb_sa_state = x->km.dying ?			SADB_SASTATE_DYING : SADB_SASTATE_MATURE;		break;	case XFRM_STATE_ACQ:		sa->sadb_sa_state = SADB_SASTATE_LARVAL;		break;	default:		sa->sadb_sa_state = SADB_SASTATE_DEAD;		break;	}	sa->sadb_sa_auth = 0;	if (x->aalg) {		struct xfrm_algo_desc *a = xfrm_aalg_get_byname(x->aalg->alg_name, 0);		sa->sadb_sa_auth = (a && a->pfkey_supported) ?					a->desc.sadb_alg_id : 0;	}	sa->sadb_sa_encrypt = 0;	BUG_ON(x->ealg && x->calg);	if (x->ealg) {		struct xfrm_algo_desc *a = xfrm_ealg_get_byname(x->ealg->alg_name, 0);		sa->sadb_sa_encrypt = (a && a->pfkey_supported) ?					a->desc.sadb_alg_id : 0;	}	 	if (x->calg) {		struct xfrm_algo_desc *a = xfrm_calg_get_byname(x->calg->alg_name, 0);		sa->sadb_sa_encrypt = (a && a->pfkey_supported) ?					a->desc.sadb_alg_id : 0;	}	sa->sadb_sa_flags = 0;	if (x->props.flags & XFRM_STATE_NOECN)		sa->sadb_sa_flags |= SADB_SAFLAGS_NOECN;	if (x->props.flags & XFRM_STATE_DECAP_DSCP)		sa->sadb_sa_flags |= SADB_SAFLAGS_DECAP_DSCP;	if (x->props.flags & XFRM_STATE_NOPMTUDISC)		sa->sadb_sa_flags |= SADB_SAFLAGS_NOPMTUDISC;	 	if (hsc & 2) {		lifetime = (struct sadb_lifetime *)  skb_put(skb,							     sizeof(struct sadb_lifetime));		lifetime->sadb_lifetime_len =			sizeof(struct sadb_lifetime)/sizeof(int);		lifetime->sadb_lifetime_exttype = SADB_EXT_LIFETIME_HARD;		lifetime->sadb_lifetime_allocations =  _X2KEY(x->lft.hard_packet_limit);		lifetime->sadb_lifetime_bytes = _X2KEY(x->lft.hard_byte_limit);		lifetime->sadb_lifetime_addtime = x->lft.hard_add_expires_seconds;		lifetime->sadb_lifetime_usetime = x->lft.hard_use_expires_seconds;	}	 	if (hsc & 1) {		lifetime = (struct sadb_lifetime *)  skb_put(skb,							     sizeof(struct sadb_lifetime));		lifetime->sadb_lifetime_len =			sizeof(struct sadb_lifetime)/sizeof(int);		lifetime->sadb_lifetime_exttype = SADB_EXT_LIFETIME_SOFT;		lifetime->sadb_lifetime_allocations =  _X2KEY(x->lft.soft_packet_limit);		lifetime->sadb_lifetime_bytes = _X2KEY(x->lft.soft_byte_limit);		lifetime->sadb_lifetime_addtime = x->lft.soft_add_expires_seconds;		lifetime->sadb_lifetime_usetime = x->lft.soft_use_expires_seconds;	}	 	lifetime = (struct sadb_lifetime *)  skb_put(skb,						     sizeof(struct sadb_lifetime));	lifetime->sadb_lifetime_len =		sizeof(struct sadb_lifetime)/sizeof(int);	lifetime->sadb_lifetime_exttype = SADB_EXT_LIFETIME_CURRENT;	lifetime->sadb_lifetime_allocations = x->curlft.packets;	lifetime->sadb_lifetime_bytes = x->curlft.bytes;	lifetime->sadb_lifetime_addtime = x->curlft.add_time;	lifetime->sadb_lifetime_usetime = x->curlft.use_time;	 	addr = (struct sadb_address*) skb_put(skb,					      sizeof(struct sadb_address)+sockaddr_size);	addr->sadb_address_len =		(sizeof(struct sadb_address)+sockaddr_size)/			sizeof(int);	addr->sadb_address_exttype = SADB_EXT_ADDRESS_SRC;	 	addr->sadb_address_proto = 0;	addr->sadb_address_reserved = 0;	addr->sadb_address_prefixlen =		pfkey_sockaddr_fill(&x->props.saddr, 0,				    (struct sockaddr *) (addr + 1),				    x->props.family);	if (!addr->sadb_address_prefixlen)		BUG();	 	addr = (struct sadb_address*) skb_put(skb,					      sizeof(struct sadb_address)+sockaddr_size);	addr->sadb_address_len =		(sizeof(struct sadb_address)+sockaddr_size)/			sizeof(int);	addr->sadb_address_exttype = SADB_EXT_ADDRESS_DST;	addr->sadb_address_proto = 0;	addr->sadb_address_reserved = 0;	addr->sadb_address_prefixlen =		pfkey_sockaddr_fill(&x->id.daddr, 0,				    (struct sockaddr *) (addr + 1),				    x->props.family);	if (!addr->sadb_address_prefixlen)		BUG();	if (!xfrm_addr_equal(&x->sel.saddr, &x->props.saddr,			     x->props.family)) {		addr = (struct sadb_address*) skb_put(skb,			sizeof(struct sadb_address)+sockaddr_size);		addr->sadb_address_len =			(sizeof(struct sadb_address)+sockaddr_size)/			sizeof(int);		addr->sadb_address_exttype = SADB_EXT_ADDRESS_PROXY;		addr->sadb_address_proto =			pfkey_proto_from_xfrm(x->sel.proto);		addr->sadb_address_prefixlen = x->sel.prefixlen_s;		addr->sadb_address_reserved = 0;		pfkey_sockaddr_fill(&x->sel.saddr, x->sel.sport,				    (struct sockaddr *) (addr + 1),				    x->props.family);	}	 	if (add_keys && auth_key_size) {		key = (struct sadb_key *) skb_put(skb,						  sizeof(struct sadb_key)+auth_key_size);		key->sadb_key_len = (sizeof(struct sadb_key) + auth_key_size) /			sizeof(int);		key->sadb_key_exttype = SADB_EXT_KEY_AUTH;		key->sadb_key_bits = x->aalg->alg_key_len;		key->sadb_key_reserved = 0;		memcpy(key + 1, x->aalg->alg_key, (x->aalg->alg_key_len+7)/8);	}	 	if (add_keys && encrypt_key_size) {		key = (struct sadb_key *) skb_put(skb,						  sizeof(struct sadb_key)+encrypt_key_size);		key->sadb_key_len = (sizeof(struct sadb_key) +				     encrypt_key_size) / sizeof(int);		key->sadb_key_exttype = SADB_EXT_KEY_ENCRYPT;		key->sadb_key_bits = x->ealg->alg_key_len;		key->sadb_key_reserved = 0;		memcpy(key + 1, x->ealg->alg_key,		       (x->ealg->alg_key_len+7)/8);	}	 	sa2 = (struct sadb_x_sa2 *)  skb_put(skb, sizeof(struct sadb_x_sa2));	sa2->sadb_x_sa2_len = sizeof(struct sadb_x_sa2)/sizeof(int);	sa2->sadb_x_sa2_exttype = SADB_X_EXT_SA2;	if ((mode = pfkey_mode_from_xfrm(x->props.mode)) < 0) {		kfree_skb(skb);		return ERR_PTR(-EINVAL);	}	sa2->sadb_x_sa2_mode = mode;	sa2->sadb_x_sa2_reserved1 = 0;	sa2->sadb_x_sa2_reserved2 = 0;	sa2->sadb_x_sa2_sequence = 0;	sa2->sadb_x_sa2_reqid = x->props.reqid;	if (natt && natt->encap_type) {		struct sadb_x_nat_t_type *n_type;		struct sadb_x_nat_t_port *n_port;		 		n_type = (struct sadb_x_nat_t_type*) skb_put(skb, sizeof(*n_type));		n_type->sadb_x_nat_t_type_len = sizeof(*n_type)/sizeof(int);		n_type->sadb_x_nat_t_type_exttype = SADB_X_EXT_NAT_T_TYPE;		n_type->sadb_x_nat_t_type_type = natt->encap_type;		n_type->sadb_x_nat_t_type_reserved[0] = 0;		n_type->sadb_x_nat_t_type_reserved[1] = 0;		n_type->sadb_x_nat_t_type_reserved[2] = 0;		 		n_port = (struct sadb_x_nat_t_port*) skb_put(skb, sizeof (*n_port));		n_port->sadb_x_nat_t_port_len = sizeof(*n_port)/sizeof(int);		n_port->sadb_x_nat_t_port_exttype = SADB_X_EXT_NAT_T_SPORT;		n_port->sadb_x_nat_t_port_port = natt->encap_sport;		n_port->sadb_x_nat_t_port_reserved = 0;		 		n_port = (struct sadb_x_nat_t_port*) skb_put(skb, sizeof (*n_port));		n_port->sadb_x_nat_t_port_len = sizeof(*n_port)/sizeof(int);		n_port->sadb_x_nat_t_port_exttype = SADB_X_EXT_NAT_T_DPORT;		n_port->sadb_x_nat_t_port_port = natt->encap_dport;		n_port->sadb_x_nat_t_port_reserved = 0;	}	 	if (xfrm_ctx) {		sec_ctx = (struct sadb_x_sec_ctx *) skb_put(skb,				sizeof(struct sadb_x_sec_ctx) + ctx_size);		sec_ctx->sadb_x_sec_len =		  (sizeof(struct sadb_x_sec_ctx) + ctx_size) / sizeof(int);		sec_ctx->sadb_x_sec_exttype = SADB_X_EXT_SEC_CTX;		sec_ctx->sadb_x_ctx_doi = xfrm_ctx->ctx_doi;		sec_ctx->sadb_x_ctx_alg = xfrm_ctx->ctx_alg;		sec_ctx->sadb_x_ctx_len = xfrm_ctx->ctx_len;		memcpy(sec_ctx + 1, xfrm_ctx->ctx_str,		       xfrm_ctx->ctx_len);	}	return skb;}",8691
642,1763,CVE-2016-9793,26,"void __sock_wfree(struct sk_buff *skb){	struct sock *sk = skb->sk;	if (atomic_sub_and_test(skb->truesize, &sk->sk_wmem_alloc))		__sk_free(sk);}",15047
163,1438,CVE-2014-8884,26,"struct dvb_frontend* ttusbdecfe_dvbt_attach(const struct ttusbdecfe_config* config){	struct ttusbdecfe_state* state = NULL;	 	state = kmalloc(sizeof(struct ttusbdecfe_state), GFP_KERNEL);	if (state == NULL)		return NULL;	 	state->config = config;	 	memcpy(&state->frontend.ops, &ttusbdecfe_dvbt_ops, sizeof(struct dvb_frontend_ops));	state->frontend.demodulator_priv = state;	return &state->frontend;}",10384
721,1033,CVE-2013-4588,26,"static int ip_vs_rs_hash(struct ip_vs_dest *dest){	unsigned hash;	if (!list_empty(&dest->d_list)) {		return 0;	}	 	hash = ip_vs_rs_hashkey(dest->af, &dest->addr, dest->port);	list_add(&dest->d_list, &ip_vs_rtable[hash]);	return 1;}",7630
933,2667,CVE-2017-16931,26,"static int compareFiles(const char *r1  , const char *r2  ) {    int res1, res2;    int fd1, fd2;    char bytes1[4096];    char bytes2[4096];    if (update_results) {        fd1 = open(r1, RD_FLAGS);        if (fd1 < 0)            return(-1);        fd2 = open(r2, WR_FLAGS, 0644);        if (fd2 < 0) {            close(fd1);            return(-1);        }        do {            res1 = read(fd1, bytes1, 4096);            if (res1 <= 0)                break;            res2 = write(fd2, bytes1, res1);            if (res2 <= 0 || res2 != res1)                break;        } while (1);        close(fd2);        close(fd1);        return(res1 != 0);    }    fd1 = open(r1, RD_FLAGS);    if (fd1 < 0)        return(-1);    fd2 = open(r2, RD_FLAGS);    if (fd2 < 0) {        close(fd1);        return(-1);    }    while (1) {        res1 = read(fd1, bytes1, 4096);        res2 = read(fd2, bytes2, 4096);	if ((res1 != res2) || (res1 < 0)) {	    close(fd1);	    close(fd2);	    return(1);	}	if (res1 == 0)	    break;	if (memcmp(bytes1, bytes2, res1) != 0) {	    close(fd1);	    close(fd2);	    return(1);	}    }    close(fd1);    close(fd2);    return(0);}",19656
457,779,CVE-2013-6763,26,"static int fbinfo2index (struct fb_info *fb_info){	int i;	for (i = 0; i < device_count; ++i) {		if (fb_info == _au1200fb_infos[i])			return i;	}	printk(""au1200fb: ERROR: fbinfo2index failed!\n"");	return -1;}",7173
183,1795,CVE-2016-9793,26,"static long sock_wait_for_wmem(struct sock *sk, long timeo){	DEFINE_WAIT(wait);	sk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);	for (;;) {		if (!timeo)			break;		if (signal_pending(current))			break;		set_bit(SOCK_NOSPACE, &sk->sk_socket->flags);		prepare_to_wait(sk_sleep(sk), &wait, TASK_INTERRUPTIBLE);		if (atomic_read(&sk->sk_wmem_alloc) < sk->sk_sndbuf)			break;		if (sk->sk_shutdown & SEND_SHUTDOWN)			break;		if (sk->sk_err)			break;		timeo = schedule_timeout(timeo);	}	finish_wait(sk_sleep(sk), &wait);	return timeo;}",15079
658,2258,CVE-2016-2324,26,"static void show_commit(struct commit *commit, void *data){	add_object_entry(commit->object.oid.hash, OBJ_COMMIT, NULL, 0);	commit->object.flags |= OBJECT_ADDED;	if (write_bitmap_index) 		index_commit_for_bitmap(commit); }",17678
407,1870,CVE-2016-7425,26,"static void arcmsr_hbaD_doorbell_isr(struct AdapterControlBlock *pACB){	int outbound_doorbell;	struct MessageUnit_D  *pmu = pACB->pmuD;	outbound_doorbell = readl(pmu->outbound_doorbell);	do {		writel(outbound_doorbell, pmu->outbound_doorbell);		if (outbound_doorbell & ARCMSR_ARC1214_IOP2DRV_MESSAGE_CMD_DONE)			arcmsr_hbaD_message_isr(pACB);		if (outbound_doorbell & ARCMSR_ARC1214_IOP2DRV_DATA_WRITE_OK)			arcmsr_iop2drv_data_wrote_handle(pACB);		if (outbound_doorbell & ARCMSR_ARC1214_IOP2DRV_DATA_READ_OK)			arcmsr_iop2drv_data_read_handle(pACB);		outbound_doorbell = readl(pmu->outbound_doorbell);	} while (outbound_doorbell & (ARCMSR_ARC1214_IOP2DRV_DATA_WRITE_OK		| ARCMSR_ARC1214_IOP2DRV_DATA_READ_OK		| ARCMSR_ARC1214_IOP2DRV_MESSAGE_CMD_DONE));}",15789
68,953,CVE-2013-4591,26,"static void nfs4_handle_setlk_error(struct nfs_server *server, struct nfs4_lock_state *lsp, int new_lock_owner, int error){	switch (error) {	case -NFS4ERR_ADMIN_REVOKED:	case -NFS4ERR_BAD_STATEID:		lsp->ls_seqid.flags &= ~NFS_SEQID_CONFIRMED;		if (new_lock_owner != 0 ||		   test_bit(NFS_LOCK_INITIALIZED, &lsp->ls_flags) != 0)			nfs4_schedule_stateid_recovery(server, lsp->ls_state);		break;	case -NFS4ERR_STALE_STATEID:		lsp->ls_seqid.flags &= ~NFS_SEQID_CONFIRMED;	case -NFS4ERR_EXPIRED:		nfs4_schedule_lease_recovery(server->nfs_client);	};}",7550
856,3202,CVE-2018-17407,26,static void t1_close_font_file(const char *close_name_suffix){    t1_log(close_name_suffix);    t1_close();    cur_file_name = NULL;},23636
324,1658,CVE-2015-4036,26,"static char *vhost_scsi_dump_proto_id(struct vhost_scsi_tport *tport){	switch (tport->tport_proto_id) {	case SCSI_PROTOCOL_SAS:		return ""SAS"";	case SCSI_PROTOCOL_FCP:		return ""FCP"";	case SCSI_PROTOCOL_ISCSI:		return ""iSCSI"";	default:		break;	}	return ""Unknown"";}",13524
728,521,CVE-2012-6711,26,sh_get_home_dir (){  if (current_user.home_dir == 0)    get_current_user_info ();  return current_user.home_dir;},2561
201,1042,CVE-2013-4588,26,"static void update_defense_level(void){	struct sysinfo i;	static int old_secure_tcp = 0;	int availmem;	int nomem;	int to_change = -1;	 	si_meminfo(&i);	availmem = i.freeram + i.bufferram;	 	 	 	nomem = (availmem < sysctl_ip_vs_amemthresh);	local_bh_disable();	 	spin_lock(&__ip_vs_dropentry_lock);	switch (sysctl_ip_vs_drop_entry) {	case 0:		atomic_set(&ip_vs_dropentry, 0);		break;	case 1:		if (nomem) {			atomic_set(&ip_vs_dropentry, 1);			sysctl_ip_vs_drop_entry = 2;		} else {			atomic_set(&ip_vs_dropentry, 0);		}		break;	case 2:		if (nomem) {			atomic_set(&ip_vs_dropentry, 1);		} else {			atomic_set(&ip_vs_dropentry, 0);			sysctl_ip_vs_drop_entry = 1;		};		break;	case 3:		atomic_set(&ip_vs_dropentry, 1);		break;	}	spin_unlock(&__ip_vs_dropentry_lock);	 	spin_lock(&__ip_vs_droppacket_lock);	switch (sysctl_ip_vs_drop_packet) {	case 0:		ip_vs_drop_rate = 0;		break;	case 1:		if (nomem) {			ip_vs_drop_rate = ip_vs_drop_counter				= sysctl_ip_vs_amemthresh /				(sysctl_ip_vs_amemthresh-availmem);			sysctl_ip_vs_drop_packet = 2;		} else {			ip_vs_drop_rate = 0;		}		break;	case 2:		if (nomem) {			ip_vs_drop_rate = ip_vs_drop_counter				= sysctl_ip_vs_amemthresh /				(sysctl_ip_vs_amemthresh-availmem);		} else {			ip_vs_drop_rate = 0;			sysctl_ip_vs_drop_packet = 1;		}		break;	case 3:		ip_vs_drop_rate = sysctl_ip_vs_am_droprate;		break;	}	spin_unlock(&__ip_vs_droppacket_lock);	 	write_lock(&__ip_vs_securetcp_lock);	switch (sysctl_ip_vs_secure_tcp) {	case 0:		if (old_secure_tcp >= 2)			to_change = 0;		break;	case 1:		if (nomem) {			if (old_secure_tcp < 2)				to_change = 1;			sysctl_ip_vs_secure_tcp = 2;		} else {			if (old_secure_tcp >= 2)				to_change = 0;		}		break;	case 2:		if (nomem) {			if (old_secure_tcp < 2)				to_change = 1;		} else {			if (old_secure_tcp >= 2)				to_change = 0;			sysctl_ip_vs_secure_tcp = 1;		}		break;	case 3:		if (old_secure_tcp < 2)			to_change = 1;		break;	}	old_secure_tcp = sysctl_ip_vs_secure_tcp;	if (to_change >= 0)		ip_vs_protocol_timeout_change(sysctl_ip_vs_secure_tcp>1);	write_unlock(&__ip_vs_securetcp_lock);	local_bh_enable();}",7639
644,3876,CVE-2017-6991,26,static int debugMutexEnd(void){ return SQLITE_OK; },29863
5,2443,CVE-2016-2315,26,"static void set_checkpoint_signal(void){	struct sigaction sa;	memset(&sa, 0, sizeof(sa));	sa.sa_handler = checkpoint_signal;	sigemptyset(&sa.sa_mask);	sa.sa_flags = SA_RESTART;	sigaction(SIGUSR1, &sa, NULL);}",17863
153,495,CVE-2007-5199,26,"CatalogueRegisterLocalFpeFunctions (void){    RegisterFPEFunctions(CatalogueNameCheck,			 CatalogueInitFPE,			 CatalogueFreeFPE,			 CatalogueResetFPE,			 CatalogueOpenFont,			 CatalogueCloseFont,			 CatalogueListFonts,			 CatalogueStartListFontsWithInfo,			 CatalogueListNextFontWithInfo,			 NULL,			 NULL,			 NULL,			 CatalogueStartListFontsAndAliases,			 CatalogueListNextFontOrAlias,			 FontFileEmptyBitmapSource);}",2524
193,5,CVE-2013-6420,26,int php_openssl_get_x509_list_id(void)  {	return le_x509;} ,30
296,3727,CVE-2016-1583,26,"ecryptfs_compat_ioctl(struct file *file, unsigned int cmd, unsigned long arg){	struct file *lower_file = ecryptfs_file_to_lower(file);	long rc = -ENOIOCTLCMD;	if (!lower_file->f_op->compat_ioctl)		return rc;	switch (cmd) {	case FS_IOC32_GETFLAGS:	case FS_IOC32_SETFLAGS:	case FS_IOC32_GETVERSION:	case FS_IOC32_SETVERSION:		rc = lower_file->f_op->compat_ioctl(lower_file, cmd, arg);		fsstack_copy_attr_all(file_inode(file), file_inode(lower_file));		return rc;	default:		return rc;	}}",28432
631,3129,CVE-2016-7970,26,"static inline int pre_blur1_func(int p1, int z0, int n1){         return (int)(((int)(p1 + n1) >> 1) + z0 + 1) >> 1;}",22787
74,3117,CVE-2016-9933,26,"int gdAlphaBlend (int dst, int src) {    int src_alpha = gdTrueColorGetAlpha(src);    int dst_alpha, alpha, red, green, blue;    int src_weight, dst_weight, tot_weight;       if( src_alpha == gdAlphaOpaque )        return src;    dst_alpha = gdTrueColorGetAlpha(dst);    if( src_alpha == gdAlphaTransparent )        return dst;    if( dst_alpha == gdAlphaTransparent )        return src;         src_weight = gdAlphaTransparent - src_alpha;    dst_weight = (gdAlphaTransparent - dst_alpha) * src_alpha / gdAlphaMax;    tot_weight = src_weight + dst_weight;       alpha = src_alpha * dst_alpha / gdAlphaMax;    red = (gdTrueColorGetRed(src) * src_weight           + gdTrueColorGetRed(dst) * dst_weight) / tot_weight;    green = (gdTrueColorGetGreen(src) * src_weight           + gdTrueColorGetGreen(dst) * dst_weight) / tot_weight;    blue = (gdTrueColorGetBlue(src) * src_weight           + gdTrueColorGetBlue(dst) * dst_weight) / tot_weight;       return ((alpha << 24) + (red << 16) + (green << 8) + blue);}",22655
22,1071,CVE-2013-4263,26,"static void build_abs_diff_mask(const int *prvp, int prv_linesize,                                const int *nxtp, int nxt_linesize,                                int *tbuffer,    int tbuf_linesize,                                int width, int height){    int y, x;    prvp -= prv_linesize;    nxtp -= nxt_linesize;    for (y = 0; y < height; y++) {        for (x = 0; x < width; x++)            tbuffer[x] = FFABS(prvp[x] - nxtp[x]);        prvp += prv_linesize;        nxtp += nxt_linesize;        tbuffer += tbuf_linesize;    }}",7878
19,1599,CVE-2015-5283,26,"static void sctp_v4_to_sk_daddr(union sctp_addr *addr, struct sock *sk){	inet_sk(sk)->inet_daddr = addr->v4.sin_addr.s_addr;}",13454
144,3234,CVE-2018-14358,26,"int imap_cache_del(struct ImapData *idata, struct Header *h){  if (!idata || !h)    return -1;  idata->bcache = msg_cache_open(idata);  char id[64];  snprintf(id, sizeof(id), ""%u-%u"", idata->uid_validity, HEADER_DATA(h)->uid);  return mutt_bcache_del(idata->bcache, id);}",24493
426,1641,CVE-2015-5156,26,"static int virtnet_set_mac_address(struct net_device *dev, void *p){	struct virtnet_info *vi = netdev_priv(dev);	struct virtio_device *vdev = vi->vdev;	int ret;	struct sockaddr *addr = p;	struct scatterlist sg;	ret = eth_prepare_mac_addr_change(dev, p);	if (ret)		return ret;	if (virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_MAC_ADDR)) {		sg_init_one(&sg, addr->sa_data, dev->addr_len);		if (!virtnet_send_command(vi, VIRTIO_NET_CTRL_MAC,					  VIRTIO_NET_CTRL_MAC_ADDR_SET, &sg)) {			dev_warn(&vdev->dev,				 ""Failed to set mac address by vq command.\n"");			return -EINVAL;		}	} else if (virtio_has_feature(vdev, VIRTIO_NET_F_MAC) &&		   !virtio_has_feature(vdev, VIRTIO_F_VERSION_1)) {		unsigned int i;		 		for (i = 0; i < dev->addr_len; i++)			virtio_cwrite8(vdev,				       offsetof(struct virtio_net_config, mac) +				       i, addr->sa_data[i]);	}	eth_commit_mac_addr_change(dev, p);	return 0;}",13498
115,2142,CVE-2016-4303,26,"usage_long(){    fprintf(stderr, usage_longstr, UDP_RATE / (1024*1024), DURATION, DEFAULT_TCP_BLKSIZE / 1024, DEFAULT_UDP_BLKSIZE / 1024);}",17050
904,191,CVE-2017-10971,26,LastEventTime(int deviceid){    return lastDeviceEventTime[deviceid].time;},842
300,95,CVE-2013-4282,26,"int reds_get_mm_time(void){    struct timespec time_space;    clock_gettime(CLOCK_MONOTONIC, &time_space);    return time_space.tv_sec * 1000 + time_space.tv_nsec / 1000 / 1000;}",405
341,3868,CVE-2017-6991,26,"static int allSpaces(const char *z, int n){  while( n>0 && z[n-1]==' ' ){ n--; }  return n==0;}",29855
543,3531,CVE-2018-20855,26,static int is_sqp(enum ib_qp_type qp_type){	return is_qp0(qp_type) || is_qp1(qp_type);},27559
265,2968,CVE-2017-7742,26,"f2flac16_clip_array (const float *src, int *dest, int count, int normalize){	float normfact, scaled_value ;	normfact = normalize ? (8.0 * 0x1000) : 1.0 ;	while (--count >= 0)	{	scaled_value = src [count] * normfact ;		if (CPU_CLIPS_POSITIVE == 0 && scaled_value >= (1.0 * 0x7FFF))		{	dest [count] = 0x7FFF ;			continue ;			} ;		if (CPU_CLIPS_NEGATIVE == 0 && scaled_value <= (-8.0 * 0x1000))		{	dest [count] = 0x8000 ;			continue ;			} ;		dest [count] = lrintf (scaled_value) ;		} ;}  ",21489
234,2391,CVE-2016-2315,26,"static void dump_tags(void){	static const char *msg = ""fast-import"";	struct tag *t;	struct strbuf ref_name = STRBUF_INIT;	struct strbuf err = STRBUF_INIT;	struct ref_transaction *transaction;	transaction = ref_transaction_begin(&err);	if (!transaction) {		failure |= error(""%s"", err.buf);		goto cleanup;	}	for (t = first_tag; t; t = t->next_tag) {		strbuf_reset(&ref_name);		strbuf_addf(&ref_name, ""refs/tags/%s"", t->name);		if (ref_transaction_update(transaction, ref_name.buf,					   t->sha1, NULL, 0, msg, &err)) {			failure |= error(""%s"", err.buf);			goto cleanup;		}	}	if (ref_transaction_commit(transaction, &err))		failure |= error(""%s"", err.buf); cleanup:	ref_transaction_free(transaction);	strbuf_release(&ref_name);	strbuf_release(&err);}",17811
502,663,CVE-2011-2517,26,"static int nl80211_get_ifidx(struct netlink_callback *cb){	int res;	res = nlmsg_parse(cb->nlh, GENL_HDRLEN + nl80211_fam.hdrsize,			  nl80211_fam.attrbuf, nl80211_fam.maxattr,			  nl80211_policy);	if (res)		return res;	if (!nl80211_fam.attrbuf[NL80211_ATTR_IFINDEX])		return -EINVAL;	res = nla_get_u32(nl80211_fam.attrbuf[NL80211_ATTR_IFINDEX]);	if (!res)		return -EINVAL;	return res;}",6562
299,1318,CVE-2013-1860,26,"struct usb_driver *usb_cdc_wdm_register(struct usb_interface *intf,					struct usb_endpoint_descriptor *ep,					int bufsize,					int (*manage_power)(struct usb_interface *, int)){	int rv = -EINVAL;	rv = wdm_create(intf, ep, bufsize, manage_power);	if (rv < 0)		goto err;	return &wdm_driver;err:	return ERR_PTR(rv);}",9325
105,2452,CVE-2016-2315,26,"static void tree_content_replace(	struct tree_entry *root,	const unsigned char *sha1,	const int mode,	struct tree_content *newtree){	if (!S_ISDIR(mode))		die(""Root cannot be a non-directory"");	hashclr(root->versions[0].sha1);	hashcpy(root->versions[1].sha1, sha1);	if (root->tree)		release_tree_content_recursive(root->tree);	root->tree = newtree;}",17872
654,3616,CVE-2017-18379,26,"nvmet_fc_abort_op(struct nvmet_fc_tgtport *tgtport,				struct nvmet_fc_fcp_iod *fod){	struct nvmefc_tgt_fcp_req *fcpreq = fod->fcpreq;	 	nvmet_fc_free_tgt_pgs(fod);	 	 	if (!fod->aborted)		tgtport->ops->fcp_abort(&tgtport->fc_target_port, fcpreq);	nvmet_fc_free_fcp_iod(fod->queue, fod);}",28072
166,1666,CVE-2015-4036,26,"static char *vhost_scsi_get_fabric_name(void){	return ""vhost"";}",13532
905,3977,CVE-2016-1503,26,"print_options(void){ const struct dhcp_opt *opt; const char **p; for (p = if_params; *p; p++)		printf("" -  %s\n"", *p); for (p = dhcp_params; *p; p++)		printf(""    %s\n"", *p); for (opt = dhcp_opts; opt->option; opt++) if (opt->var)			printf(""%03d %s\n"", opt->option, opt->var);}",30685
376,908,CVE-2013-6381,26,"static int qeth_set_thread_start_bit(struct qeth_card *card,		unsigned long thread){	unsigned long flags;	spin_lock_irqsave(&card->thread_mask_lock, flags);	if (!(card->thread_allowed_mask & thread) ||	      (card->thread_start_mask & thread)) {		spin_unlock_irqrestore(&card->thread_mask_lock, flags);		return -EPERM;	}	card->thread_start_mask |= thread;	spin_unlock_irqrestore(&card->thread_mask_lock, flags);	return 0;}",7337
456,3771,CVE-2012-2895,26,  NullDownloadRequestHandle() {},29207
489,1573,CVE-2015-5283,26,"static void sctp_inet_event_msgname(struct sctp_ulpevent *event, char *msgname,				    int *addr_len){	struct sockaddr_in *sin, *sinfrom;	if (msgname) {		struct sctp_association *asoc;		asoc = event->asoc;		sctp_inet_msgname(msgname, addr_len);		sin = (struct sockaddr_in *)msgname;		sinfrom = &asoc->peer.primary_addr.v4;		sin->sin_port = htons(asoc->peer.port);		sin->sin_addr.s_addr = sinfrom->sin_addr.s_addr;	}}",13428
695,169,CVE-2013-2236,26,"ospf_api_typename (int msgtype){  struct nametab NameTab[] = {    { MSG_REGISTER_OPAQUETYPE,   ""Register opaque-type"",   },    { MSG_UNREGISTER_OPAQUETYPE, ""Unregister opaque-type"", },    { MSG_REGISTER_EVENT,        ""Register event"",         },    { MSG_SYNC_LSDB,             ""Sync LSDB"",              },    { MSG_ORIGINATE_REQUEST,     ""Originate request"",      },    { MSG_DELETE_REQUEST,        ""Delete request"",         },    { MSG_REPLY,                 ""Reply"",                  },    { MSG_READY_NOTIFY,          ""Ready notify"",           },    { MSG_LSA_UPDATE_NOTIFY,     ""LSA update notify"",      },    { MSG_LSA_DELETE_NOTIFY,     ""LSA delete notify"",      },    { MSG_NEW_IF,                ""New interface"",          },    { MSG_DEL_IF,                ""Del interface"",          },    { MSG_ISM_CHANGE,            ""ISM change"",             },    { MSG_NSM_CHANGE,            ""NSM change"",             },  };  int i, n = array_size(NameTab);  const char *name = NULL;  for (i = 0; i < n; i++)    {      if (NameTab[i].value == msgtype)        {          name = NameTab[i].name;          break;        }    }  return name ? name : ""?"";}",724
194,3374,CVE-2017-18222,26,"static int hns_rcb_get_port_in_comm(	struct rcb_common_cb *rcb_common, int ring_idx){	return ring_idx / (rcb_common->max_q_per_vf * rcb_common->max_vfn);}",25815
852,3938,CVE-2015-3842,26,int LVC_Convert_VolToDb(int vol){ int  dB;    dB = LVC_ToDB_s32Tos16(vol <<7);    dB = (dB +8)>>4;    dB = (dB <-96) ? -96 : dB ; return dB;},30376
363,2459,CVE-2016-2315,26,"static int add_parents_only(struct rev_info *revs, const char *arg_, int flags){	unsigned char sha1[20];	struct object *it;	struct commit *commit;	struct commit_list *parents;	const char *arg = arg_;	if (*arg == '^') {		flags ^= UNINTERESTING | BOTTOM;		arg++;	}	if (get_sha1_committish(arg, sha1))		return 0;	while (1) {		it = get_reference(revs, arg, sha1, 0);		if (!it && revs->ignore_missing)			return 0;		if (it->type != OBJ_TAG)			break;		if (!((struct tag*)it)->tagged)			return 0;		hashcpy(sha1, ((struct tag*)it)->tagged->sha1);	}	if (it->type != OBJ_COMMIT)		return 0;	commit = (struct commit *)it;	for (parents = commit->parents; parents; parents = parents->next) {		it = &parents->item->object;		it->flags |= flags;		add_rev_cmdline(revs, it, arg_, REV_CMD_PARENTS_ONLY, flags);		add_pending_object(revs, it, arg);	}	return 1;}",17879
169,2602,CVE-2016-1583,26,"static void ttwu_queue_remote(struct task_struct *p, int cpu, int wake_flags){	struct rq *rq = cpu_rq(cpu);	p->sched_remote_wakeup = !!(wake_flags & WF_MIGRATED);	if (llist_add(&p->wake_entry, &cpu_rq(cpu)->wake_list)) {		if (!set_nr_if_polling(rq->idle))			smp_send_reschedule(cpu);		else			trace_sched_wake_idle_without_ipi(cpu);	}}",18151
79,3665,CVE-2012-6712,26,"static int is_lq_table_valid(struct iwl_priv *priv,			      struct iwl_rxon_context *ctx,			      struct iwl_link_quality_cmd *lq){	int i;	if (ctx->ht.enabled)		return true;	IWL_DEBUG_INFO(priv, ""Channel %u is not an HT channel\n"",		       ctx->active.channel);	for (i = 0; i < LINK_QUAL_MAX_RETRY_NUM; i++) {		if (le32_to_cpu(lq->rs_table[i].rate_n_flags) &		    RATE_MCS_HT_MSK) {			IWL_DEBUG_INFO(priv,				       ""index %d of LQ expects HT channel\n"",				       i);			return false;		}	}	return true;}",28151
446,893,CVE-2013-6381,26,"static int qeth_query_setadapterparms_cb(struct qeth_card *card,		struct qeth_reply *reply, unsigned long data){	struct qeth_ipa_cmd *cmd;	QETH_CARD_TEXT(card, 3, ""quyadpcb"");	cmd = (struct qeth_ipa_cmd *) data;	if (cmd->data.setadapterparms.data.query_cmds_supp.lan_type & 0x7f) {		card->info.link_type =		      cmd->data.setadapterparms.data.query_cmds_supp.lan_type;		QETH_DBF_TEXT_(SETUP, 2, ""lnk %d"", card->info.link_type);	}	card->options.adp.supported_funcs =		cmd->data.setadapterparms.data.query_cmds_supp.supported_cmds;	return qeth_default_setadapterparms_cb(card, reply, (unsigned long)cmd);}",7322
403,51,CVE-2019-15938,26,"static void *nfs_readdirattr_req(struct nfs_priv *npriv, struct nfs_dir *dir){	int data[1024];	int *p;	int len;	struct packet *nfs_packet;	void *buf;	 	p = &(data[0]);	p = rpc_add_credentials(p);	p = nfs_add_fh3(p, &dir->fh);	p = nfs_add_uint64(p, dir->cookie);	memcpy(p, dir->cookieverf, NFS3_COOKIEVERFSIZE);	p += NFS3_COOKIEVERFSIZE / 4;	p = nfs_add_uint32(p, 1024);  	nfs_packet = rpc_req(npriv, PROG_NFS, NFSPROC3_READDIR, data, p - data);	if (IS_ERR(nfs_packet))		return NULL;	p = (void *)nfs_packet->data + sizeof(struct rpc_reply) + 4;	p = nfs_read_post_op_attr(p, NULL);	 	memcpy(dir->cookieverf, p, NFS3_COOKIEVERFSIZE);	p += NFS3_COOKIEVERFSIZE / 4;	len = (void *)nfs_packet->data + nfs_packet->len - (void *)p;	if (!len) {		printf(""%s: huh, no payload left\n"", __func__);		free(nfs_packet);		return NULL;	}	buf = xzalloc(len);	memcpy(buf, p, len);	free(nfs_packet);	xdr_init(&dir->stream, buf, len);	 	return buf;}",282
715,1921,CVE-2016-6187,26,"static int apparmor_path_link(struct dentry *old_dentry, const struct path *new_dir,			      struct dentry *new_dentry){	struct aa_profile *profile;	int error = 0;	if (!mediated_filesystem(old_dentry))		return 0;	profile = aa_current_profile();	if (!unconfined(profile))		error = aa_path_link(profile, old_dentry, new_dir, new_dentry);	return error;}",16266
36,3588,CVE-2018-20182,26,"rdpdr_remove_iorequest(struct async_iorequest *prev, struct async_iorequest *iorq){	if (!iorq)		return NULL;	if (iorq->buffer)		xfree(iorq->buffer);	if (prev)	{		prev->next = iorq->next;		xfree(iorq);		iorq = prev->next;	}	else	{		 		g_iorequest = iorq->next;		xfree(iorq);		iorq = NULL;	}	return iorq;}",27886
361,2143,CVE-2016-4303,26,"void warning(char *str){    fprintf(stderr, ""warning: %s\n"", str);}",17051
602,1005,CVE-2013-4588,26,"static int __ip_vs_addr_is_local_v6(const struct in6_addr *addr){	struct rt6_info *rt;	struct flowi fl = {		.oif = 0,		.nl_u = {			.ip6_u = {				.daddr = *addr,				.saddr = { .s6_addr32 = {0, 0, 0, 0} }, } },	};	rt = (struct rt6_info *)ip6_route_output(&init_net, NULL, &fl);	if (rt && rt->rt6i_dev && (rt->rt6i_dev->flags & IFF_LOOPBACK))			return 1;	return 0;}",7602
208,3236,CVE-2018-14358,26,void imap_free_header_data(struct ImapHeaderData **data){  if (!data || !*data)    return;     FREE(&((*data)->flags_system));  FREE(&((*data)->flags_remote));  FREE(data);},24495
584,2369,CVE-2016-2324,26,"static enum rewrite_result rewrite_one(struct rev_info *revs, struct commit **pp){	struct commit_list *cache = NULL;	for (;;) {		struct commit *p = *pp;		if (!revs->limited)			if (add_parents_to_list(revs, p, &revs->commits, &cache) < 0)				return rewrite_one_error;		if (p->object.flags & UNINTERESTING)			return rewrite_one_ok;		if (!(p->object.flags & TREESAME))			return rewrite_one_ok;		if (!p->parents)			return rewrite_one_noparents;		if ((p = one_relevant_parent(revs, p->parents)) == NULL)			return rewrite_one_ok;		*pp = p;	}}",17789
47,1202,CVE-2013-2128,26,"int tcp_gro_complete(struct sk_buff *skb){	struct tcphdr *th = tcp_hdr(skb);	skb->csum_start = skb_transport_header(skb) - skb->head;	skb->csum_offset = offsetof(struct tcphdr, check);	skb->ip_summed = CHECKSUM_PARTIAL;	skb_shinfo(skb)->gso_segs = NAPI_GRO_CB(skb)->count;	if (th->cwr)		skb_shinfo(skb)->gso_type |= SKB_GSO_TCP_ECN;	return 0;}",8884
249,2838,CVE-2017-8068,26,"static int pegasus_resume(struct usb_interface *intf){	struct pegasus *pegasus = usb_get_intfdata(intf);	netif_device_attach(pegasus->net);	if (netif_running(pegasus->net)) {		pegasus->rx_urb->status = 0;		pegasus->rx_urb->actual_length = 0;		read_bulk_callback(pegasus->rx_urb);		pegasus->intr_urb->status = 0;		pegasus->intr_urb->actual_length = 0;		intr_callback(pegasus->intr_urb);	}	queue_delayed_work(pegasus_workqueue, &pegasus->carrier_check,				CARRIER_CHECK_DELAY);	return 0;}",21315
443,3962,CVE-2016-2505,26, void setPID(unsigned pid) { mElementaryPID = pid; },30646
542,1894,CVE-2016-7425,26,static void arcmsr_unmap_pciregion(struct AdapterControlBlock *acb){	switch (acb->adapter_type) {	case ACB_ADAPTER_TYPE_A:{		iounmap(acb->pmuA);	}	break;	case ACB_ADAPTER_TYPE_B:{		iounmap(acb->mem_base0);		iounmap(acb->mem_base1);	}	break;	case ACB_ADAPTER_TYPE_C:{		iounmap(acb->pmuC);	}	break;	case ACB_ADAPTER_TYPE_D:		iounmap(acb->mem_base0);		break;	}},15813
125,2400,CVE-2016-2315,26,"static void *gfi_unpack_entry(	struct object_entry *oe,	unsigned long *sizep){	enum object_type type;	struct packed_git *p = all_packs[oe->pack_id];	if (p == pack_data && p->pack_size < (pack_size + 20)) {		 		close_pack_windows(p);		sha1flush(pack_file);		 		p->pack_size = pack_size + 20;	}	return unpack_entry(p, oe->idx.offset, &type, sizep);}",17820
945,3411,CVE-2017-15128,26,"void free_huge_page(struct page *page){	 	struct hstate *h = page_hstate(page);	int nid = page_to_nid(page);	struct hugepage_subpool *spool =		(struct hugepage_subpool *)page_private(page);	int restore_reserve;	set_page_private(page, 0);	page->mapping = NULL;	VM_BUG_ON_PAGE(page_count(page), page);	VM_BUG_ON_PAGE(page_mapcount(page), page);	restore_reserve = PagePrivate(page);	ClearPagePrivate(page);	 	if (hugepage_subpool_put_pages(spool, 1) == 0)		restore_reserve = true;	spin_lock(&hugetlb_lock);	clear_page_huge_active(page);	hugetlb_cgroup_uncharge_page(hstate_index(h),				     pages_per_huge_page(h), page);	if (restore_reserve)		h->resv_huge_pages++;	if (h->surplus_huge_pages_node[nid]) {		 		list_del(&page->lru);		update_and_free_page(h, page);		h->surplus_huge_pages--;		h->surplus_huge_pages_node[nid]--;	} else {		arch_clear_hugepage_flags(page);		enqueue_huge_page(h, page);	}	spin_unlock(&hugetlb_lock);}",26171
369,78,CVE-2017-15650,26,"static int name_from_null(struct address buf[static 2], const char *name, int family, int flags){	int cnt = 0;	if (name) return 0;	if (flags & AI_PASSIVE) {		if (family != AF_INET6)			buf[cnt++] = (struct address){ .family = AF_INET };		if (family != AF_INET)			buf[cnt++] = (struct address){ .family = AF_INET6 };	} else {		if (family != AF_INET6)			buf[cnt++] = (struct address){ .family = AF_INET, .addr = { 127,0,0,1 } };		if (family != AF_INET)			buf[cnt++] = (struct address){ .family = AF_INET6, .addr = { [15] = 1 } };	}	return cnt;}",386
304,1525,CVE-2014-3158,26,"setactivefilter(argv)    char **argv;{    pcap_t *pc;    int ret = 1;    pc = pcap_open_dead(DLT_PPP_PPPD, 65535);    if (pcap_compile(pc, &active_filter, *argv, 1, netmask) == -1) {	option_error(""error in active-filter expression: %s\n"",		     pcap_geterr(pc));	ret = 0;    }    pcap_close(pc);    return ret;}",11520
990,885,CVE-2013-6381,26,"static inline void qeth_qdio_establish_cq(struct qeth_card *card,	struct qdio_buffer **in_sbal_ptrs,	void (**queue_start_poll) (struct ccw_device *, int, unsigned long)) {	int i;	if (card->options.cq == QETH_CQ_ENABLED) {		int offset = QDIO_MAX_BUFFERS_PER_Q *			     (card->qdio.no_in_queues - 1);		i = QDIO_MAX_BUFFERS_PER_Q * (card->qdio.no_in_queues - 1);		for (i = 0; i < QDIO_MAX_BUFFERS_PER_Q; ++i) {			in_sbal_ptrs[offset + i] = (struct qdio_buffer *)				virt_to_phys(card->qdio.c_q->bufs[i].buffer);		}		queue_start_poll[card->qdio.no_in_queues - 1] = NULL;	}}",7314
650,180,CVE-2019-11360,26,"proto_to_name(int proto, int nolookup){	unsigned int i;	if (proto && !nolookup) {		struct protoent *pent = getprotobynumber(proto);		if (pent)			return pent->p_name;	}	for (i = 0; xtables_chain_protos[i].name != NULL; ++i)		if (xtables_chain_protos[i].num == proto)			return xtables_chain_protos[i].name;	return NULL;}",772
28,1651,CVE-2015-4036,26,static void vhost_scsi_close_session(struct se_session *se_sess){	return;},13517
80,3778,CVE-2013-2862,26,"  int OnNatPolicyUpdate(int nat_traversal_enabled) {    DCHECK(context_->network_task_runner()->BelongsToCurrentThread());    if (allow_nat_traversal_ != nat_traversal_enabled) {      allow_nat_traversal_ = nat_traversal_enabled;      LOG(INFO) << ""Updated NAT policy."";      return true;    }    return false;  }",29419
241,3669,CVE-2012-6712,26,"static void iwl_dump_lq_cmd(struct iwl_priv *priv,			   struct iwl_link_quality_cmd *lq){	int i;	IWL_DEBUG_RATE(priv, ""lq station id 0x%x\n"", lq->sta_id);	IWL_DEBUG_RATE(priv, ""lq ant 0x%X 0x%X\n"",		       lq->general_params.single_stream_ant_msk,		       lq->general_params.dual_stream_ant_msk);	for (i = 0; i < LINK_QUAL_MAX_RETRY_NUM; i++)		IWL_DEBUG_RATE(priv, ""lq index %d 0x%X\n"",			       i, lq->rs_table[i].rate_n_flags);}",28155
886,295,CVE-2016-7161,26,static inline void eth_pulse_irq(struct xlx_ethlite *s){         if (s->regs[R_TX_GIE0] & GIE_GIE) {        qemu_irq_pulse(s->irq);    }},1372
381,3487,CVE-2019-12982,26,dcputchar(char c){	dcchkstr(1);	*dcptr++=c;	*dcptr='\000';	strsize++;},26809
854,1377,CVE-2013-1772,26,"int kmsg_dump_register(struct kmsg_dumper *dumper){	unsigned long flags;	int err = -EBUSY;	 	if (!dumper->dump)		return -EINVAL;	spin_lock_irqsave(&dump_list_lock, flags);	 	if (!dumper->registered) {		dumper->registered = 1;		list_add_tail_rcu(&dumper->list, &dump_list);		err = 0;	}	spin_unlock_irqrestore(&dump_list_lock, flags);	return err;}",9614
157,2230,CVE-2016-2324,26,"static void *get_delta(struct object_entry *entry){	unsigned long size, base_size, delta_size;	void *buf, *base_buf, *delta_buf;	enum object_type type;	buf = read_sha1_file(entry->idx.sha1, &type, &size);	if (!buf)		die(""unable to read %s"", sha1_to_hex(entry->idx.sha1));	base_buf = read_sha1_file(entry->delta->idx.sha1, &type, &base_size);	if (!base_buf)		die(""unable to read %s"", sha1_to_hex(entry->delta->idx.sha1));	delta_buf = diff_delta(base_buf, base_size,			       buf, size, &delta_size, 0);	if (!delta_buf || delta_size != entry->delta_size)		die(""delta size changed"");	free(buf);	free(base_buf);	return delta_buf;}",17650
948,2203,CVE-2016-3955,26,"void usbip_dump_urb(struct urb *urb){	struct device *dev;	if (!urb) {		pr_debug(""urb: null pointer!!\n"");		return;	}	if (!urb->dev) {		pr_debug(""urb->dev: null pointer!!\n"");		return;	}	dev = &urb->dev->dev;	dev_dbg(dev, ""   urb                   :%p\n"", urb);	dev_dbg(dev, ""   dev                   :%p\n"", urb->dev);	usbip_dump_usb_device(urb->dev);	dev_dbg(dev, ""   pipe                  :%08x "", urb->pipe);	usbip_dump_pipe(urb->pipe);	dev_dbg(dev, ""   status                :%d\n"", urb->status);	dev_dbg(dev, ""   transfer_flags        :%08X\n"", urb->transfer_flags);	dev_dbg(dev, ""   transfer_buffer       :%p\n"", urb->transfer_buffer);	dev_dbg(dev, ""   transfer_buffer_length:%d\n"",						urb->transfer_buffer_length);	dev_dbg(dev, ""   actual_length         :%d\n"", urb->actual_length);	dev_dbg(dev, ""   setup_packet          :%p\n"", urb->setup_packet);	if (urb->setup_packet && usb_pipetype(urb->pipe) == PIPE_CONTROL)		usbip_dump_usb_ctrlrequest(			(struct usb_ctrlrequest *)urb->setup_packet);	dev_dbg(dev, ""   start_frame           :%d\n"", urb->start_frame);	dev_dbg(dev, ""   number_of_packets     :%d\n"", urb->number_of_packets);	dev_dbg(dev, ""   interval              :%d\n"", urb->interval);	dev_dbg(dev, ""   error_count           :%d\n"", urb->error_count);	dev_dbg(dev, ""   context               :%p\n"", urb->context);	dev_dbg(dev, ""   complete              :%p\n"", urb->complete);}",17130
274,2108,CVE-2016-4303,26,"iperf_json_finish(struct iperf_test *test){    char *str;         if (test->json_server_output) {	cJSON_AddItemToObject(test->json_top, ""server_output_json"", test->json_server_output);    }    if (test->server_output_text) {	cJSON_AddStringToObject(test->json_top, ""server_output_text"", test->server_output_text);    }    str = cJSON_Print(test->json_top);    if (str == NULL)        return -1;    fputs(str, stdout);    putchar('\n');    fflush(stdout);    free(str);    cJSON_Delete(test->json_top);    test->json_top = test->json_start = test->json_connected = test->json_intervals = test->json_server_output = test->json_end = NULL;    return 0;}",17016
500,2807,CVE-2017-9761,26,"static int getArg(char ch, int def) {	switch (ch) {	case '&':	case '-':		return ch;	}	return def;}",20713
463,1406,CVE-2012-2119,26,"static int macvtap_newlink(struct net *src_net,			   struct net_device *dev,			   struct nlattr *tb[],			   struct nlattr *data[]){	 	return macvlan_common_newlink(src_net, dev, tb, data,				      macvtap_receive, macvtap_forward);}",10012
338,2493,CVE-2016-1583,26,"static inline int __set_cpus_allowed_ptr(struct task_struct *p,					 const struct cpumask *new_mask, int check){	return set_cpus_allowed_ptr(p, new_mask);}",18042
39,1966,CVE-2016-4998,26,"static inline int arp_checkentry(const struct arpt_arp *arp){	if (arp->flags & ~ARPT_F_MASK) {		duprintf(""Unknown flag bits set: %08X\n"",			 arp->flags & ~ARPT_F_MASK);		return 0;	}	if (arp->invflags & ~ARPT_INV_MASK) {		duprintf(""Unknown invflag bits set: %08X\n"",			 arp->invflags & ~ARPT_INV_MASK);		return 0;	}	return 1;}",16532
902,2586,CVE-2016-1583,26,"sd_parent_degenerate(struct sched_domain *sd, struct sched_domain *parent){	unsigned long cflags = sd->flags, pflags = parent->flags;	if (sd_degenerate(parent))		return 1;	if (!cpumask_equal(sched_domain_span(sd), sched_domain_span(parent)))		return 0;	 	if (parent->groups == parent->groups->next) {		pflags &= ~(SD_LOAD_BALANCE |				SD_BALANCE_NEWIDLE |				SD_BALANCE_FORK |				SD_BALANCE_EXEC |				SD_SHARE_CPUCAPACITY |				SD_SHARE_PKG_RESOURCES |				SD_PREFER_SIBLING |				SD_SHARE_POWERDOMAIN);		if (nr_node_ids == 1)			pflags &= ~SD_SERIALIZE;	}	if (~cflags & pflags)		return 0;	return 1;}",18135
860,3620,CVE-2017-18379,26,"nvmet_fc_fcp_nvme_cmd_done(struct nvmet_req *nvme_req){	struct nvmet_fc_fcp_iod *fod = nvmet_req_to_fod(nvme_req);	struct nvmet_fc_tgtport *tgtport = fod->tgtport;	__nvmet_fc_fcp_nvme_cmd_done(tgtport, fod, 0);}",28076
880,1990,CVE-2016-4998,26,"static void cleanup_match(struct xt_entry_match *m, struct net *net){	struct xt_mtdtor_param par;	par.net       = net;	par.match     = m->u.kernel.match;	par.matchinfo = m->data;	par.family    = NFPROTO_IPV4;	if (par.match->destroy != NULL)		par.match->destroy(&par);	module_put(par.match->me);}",16556
377,539,CVE-2012-3400,26,"static void udf_load_fileset(struct super_block *sb, struct buffer_head *bh,			     struct kernel_lb_addr *root){	struct fileSetDesc *fset;	fset = (struct fileSetDesc *)bh->b_data;	*root = lelb_to_cpu(fset->rootDirectoryICB.extLocation);	UDF_SB(sb)->s_serial_number = le16_to_cpu(fset->descTag.tagSerialNum);	udf_debug(""Rootdir at block=%d, partition=%d\n"",		  root->logicalBlockNum, root->partitionReferenceNum);}",3124
582,844,CVE-2013-6381,26,"static int qeth_flush_buffers_on_no_pci(struct qeth_qdio_out_q *queue){	struct qeth_qdio_out_buffer *buffer;	buffer = queue->bufs[queue->next_buf_to_fill];	if ((atomic_read(&buffer->state) == QETH_QDIO_BUF_EMPTY) &&	   (buffer->next_element_to_fill > 0)) {		 		atomic_set(&buffer->state, QETH_QDIO_BUF_PRIMED);		queue->next_buf_to_fill =			(queue->next_buf_to_fill + 1) % QDIO_MAX_BUFFERS_PER_Q;		return 1;	}	return 0;}",7273
995,3794,CVE-2012-5157,26,"    void addResource(const char* url, const char* mime, const char* fileName)    {        addResource(url, mime, readFile(fileName));    }",29469
73,3377,CVE-2017-18222,26,"static void hns_rcb_ring_pair_get_cfg(struct ring_pair_cb *ring_pair_cb){	ring_pair_cb->q.handle = NULL;	hns_rcb_ring_get_cfg(&ring_pair_cb->q, RX_RING);	hns_rcb_ring_get_cfg(&ring_pair_cb->q, TX_RING);}",25818
448,524,CVE-2015-9262,26,"XcursorShapeLoadImages (unsigned int shape, const char *theme, int size){    unsigned int    id = shape >> 1;    if (id < NUM_STANDARD_NAMES)	return XcursorLibraryLoadImages (STANDARD_NAME (id), theme, size);    else	return NULL;}",2620
353,3544,CVE-2018-20855,26,"int mlx5_ib_post_send(struct ib_qp *ibqp, const struct ib_send_wr *wr,		      const struct ib_send_wr **bad_wr){	return _mlx5_ib_post_send(ibqp, wr, bad_wr, false);}",27572
776,2875,CVE-2017-8066,26,"static int gs_usb_set_bittiming(struct net_device *netdev){	struct gs_can *dev = netdev_priv(netdev);	struct can_bittiming *bt = &dev->can.bittiming;	struct usb_interface *intf = dev->iface;	int rc;	struct gs_device_bittiming *dbt;	dbt = kmalloc(sizeof(*dbt), GFP_KERNEL);	if (!dbt)		return -ENOMEM;	dbt->prop_seg = bt->prop_seg;	dbt->phase_seg1 = bt->phase_seg1;	dbt->phase_seg2 = bt->phase_seg2;	dbt->sjw = bt->sjw;	dbt->brp = bt->brp;	 	rc = usb_control_msg(interface_to_usbdev(intf),			     usb_sndctrlpipe(interface_to_usbdev(intf), 0),			     GS_USB_BREQ_BITTIMING,			     USB_DIR_OUT|USB_TYPE_VENDOR|USB_RECIP_INTERFACE,			     dev->channel,			     0,			     dbt,			     sizeof(*dbt),			     1000);	kfree(dbt);	if (rc < 0)		dev_err(netdev->dev.parent, ""Couldn't set bittimings (err=%d)"",			rc);	return rc;}",21352
130,351,CVE-2010-2520,26,"  Current_Ppem( EXEC_OP )  {    return TT_MULFIX( CUR.tt_metrics.ppem, CURRENT_Ratio() );  }",1830
136,1715,CVE-2015-2666,26,"_load_ucode_intel_bsp(struct mc_saved_data *mc_saved_data,		      unsigned long *mc_saved_in_initrd,		      unsigned long initrd_start_early,		      unsigned long initrd_end_early,		      struct ucode_cpu_info *uci){	enum ucode_state ret;	collect_cpu_info_early(uci);	scan_microcode(initrd_start_early, initrd_end_early, mc_saved_data,		       mc_saved_in_initrd, uci);	ret = load_microcode(mc_saved_data, mc_saved_in_initrd,			     initrd_start_early, uci);	if (ret == UCODE_OK)		apply_microcode_early(uci, true);}",13716
247,1461,CVE-2014-3535,26,"static inline struct sk_buff *handle_ing(struct sk_buff *skb,					 struct packet_type **pt_prev,					 int *ret, struct net_device *orig_dev){	if (skb->dev->rx_queue.qdisc == &noop_qdisc)		goto out;	if (*pt_prev) {		*ret = deliver_skb(skb, *pt_prev, orig_dev);		*pt_prev = NULL;	}	switch (ing_filter(skb)) {	case TC_ACT_SHOT:	case TC_ACT_STOLEN:		kfree_skb(skb);		return NULL;	}out:	skb->tc_verd = 0;	return skb;}",11447
774,22,CVE-2013-6420,26,"PHP_FUNCTION(openssl_error_string){	char buf[512];	unsigned long val;	if (zend_parse_parameters_none() == FAILURE) {		return;	}	val = ERR_get_error();	if (val) {		RETURN_STRING(ERR_error_string(val, buf), 1);	} else {		RETURN_FALSE;	}}",159
548,1859,CVE-2016-7425,26,static void arcmsr_flush_adapter_cache(struct AdapterControlBlock *acb){	switch (acb->adapter_type) {	case ACB_ADAPTER_TYPE_A: {		arcmsr_hbaA_flush_cache(acb);		}		break;	case ACB_ADAPTER_TYPE_B: {		arcmsr_hbaB_flush_cache(acb);		}		break;	case ACB_ADAPTER_TYPE_C: {		arcmsr_hbaC_flush_cache(acb);		}		break;	case ACB_ADAPTER_TYPE_D:		arcmsr_hbaD_flush_cache(acb);		break;	}},15778
27,525,CVE-2011-0530,26,"void dousers(void) {	struct passwd *pw;	struct group *gr;	gchar* str;	if(rungroup) {		gr=getgrnam(rungroup);		if(!gr) {			str = g_strdup_printf(""Invalid group name: %s"", rungroup);			err(str);		}		if(setgid(gr->gr_gid)<0) {			err(""Could not set GID: %m""); 		}	}	if(runuser) {		pw=getpwnam(runuser);		if(!pw) {			str = g_strdup_printf(""Invalid user name: %s"", runuser);			err(str);		}		if(setuid(pw->pw_uid)<0) {			err(""Could not set UID: %m"");		}	}}",2668
544,3709,CVE-2010-5331,26,"radeon_atombios_connected_scratch_regs(struct drm_connector *connector,				       struct drm_encoder *encoder,				       int connected){	struct drm_device *dev = connector->dev;	struct radeon_device *rdev = dev->dev_private;	struct radeon_connector *radeon_connector =	    to_radeon_connector(connector);	struct radeon_encoder *radeon_encoder = to_radeon_encoder(encoder);	int bios_0_scratch, bios_3_scratch, bios_6_scratch;	if (rdev->family >= CHIP_R600) {		bios_0_scratch = RREG32(R600_BIOS_0_SCRATCH);		bios_3_scratch = RREG32(R600_BIOS_3_SCRATCH);		bios_6_scratch = RREG32(R600_BIOS_6_SCRATCH);	} else {		bios_0_scratch = RREG32(RADEON_BIOS_0_SCRATCH);		bios_3_scratch = RREG32(RADEON_BIOS_3_SCRATCH);		bios_6_scratch = RREG32(RADEON_BIOS_6_SCRATCH);	}	if ((radeon_encoder->devices & ATOM_DEVICE_TV1_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_TV1_SUPPORT)) {		if (connected) {			DRM_DEBUG(""TV1 connected\n"");			bios_3_scratch |= ATOM_S3_TV1_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_TV1;		} else {			DRM_DEBUG(""TV1 disconnected\n"");			bios_0_scratch &= ~ATOM_S0_TV1_MASK;			bios_3_scratch &= ~ATOM_S3_TV1_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_TV1;		}	}	if ((radeon_encoder->devices & ATOM_DEVICE_CV_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_CV_SUPPORT)) {		if (connected) {			DRM_DEBUG(""CV connected\n"");			bios_3_scratch |= ATOM_S3_CV_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_CV;		} else {			DRM_DEBUG(""CV disconnected\n"");			bios_0_scratch &= ~ATOM_S0_CV_MASK;			bios_3_scratch &= ~ATOM_S3_CV_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_CV;		}	}	if ((radeon_encoder->devices & ATOM_DEVICE_LCD1_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_LCD1_SUPPORT)) {		if (connected) {			DRM_DEBUG(""LCD1 connected\n"");			bios_0_scratch |= ATOM_S0_LCD1;			bios_3_scratch |= ATOM_S3_LCD1_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_LCD1;		} else {			DRM_DEBUG(""LCD1 disconnected\n"");			bios_0_scratch &= ~ATOM_S0_LCD1;			bios_3_scratch &= ~ATOM_S3_LCD1_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_LCD1;		}	}	if ((radeon_encoder->devices & ATOM_DEVICE_CRT1_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_CRT1_SUPPORT)) {		if (connected) {			DRM_DEBUG(""CRT1 connected\n"");			bios_0_scratch |= ATOM_S0_CRT1_COLOR;			bios_3_scratch |= ATOM_S3_CRT1_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_CRT1;		} else {			DRM_DEBUG(""CRT1 disconnected\n"");			bios_0_scratch &= ~ATOM_S0_CRT1_MASK;			bios_3_scratch &= ~ATOM_S3_CRT1_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_CRT1;		}	}	if ((radeon_encoder->devices & ATOM_DEVICE_CRT2_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_CRT2_SUPPORT)) {		if (connected) {			DRM_DEBUG(""CRT2 connected\n"");			bios_0_scratch |= ATOM_S0_CRT2_COLOR;			bios_3_scratch |= ATOM_S3_CRT2_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_CRT2;		} else {			DRM_DEBUG(""CRT2 disconnected\n"");			bios_0_scratch &= ~ATOM_S0_CRT2_MASK;			bios_3_scratch &= ~ATOM_S3_CRT2_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_CRT2;		}	}	if ((radeon_encoder->devices & ATOM_DEVICE_DFP1_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_DFP1_SUPPORT)) {		if (connected) {			DRM_DEBUG(""DFP1 connected\n"");			bios_0_scratch |= ATOM_S0_DFP1;			bios_3_scratch |= ATOM_S3_DFP1_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_DFP1;		} else {			DRM_DEBUG(""DFP1 disconnected\n"");			bios_0_scratch &= ~ATOM_S0_DFP1;			bios_3_scratch &= ~ATOM_S3_DFP1_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_DFP1;		}	}	if ((radeon_encoder->devices & ATOM_DEVICE_DFP2_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_DFP2_SUPPORT)) {		if (connected) {			DRM_DEBUG(""DFP2 connected\n"");			bios_0_scratch |= ATOM_S0_DFP2;			bios_3_scratch |= ATOM_S3_DFP2_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_DFP2;		} else {			DRM_DEBUG(""DFP2 disconnected\n"");			bios_0_scratch &= ~ATOM_S0_DFP2;			bios_3_scratch &= ~ATOM_S3_DFP2_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_DFP2;		}	}	if ((radeon_encoder->devices & ATOM_DEVICE_DFP3_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_DFP3_SUPPORT)) {		if (connected) {			DRM_DEBUG(""DFP3 connected\n"");			bios_0_scratch |= ATOM_S0_DFP3;			bios_3_scratch |= ATOM_S3_DFP3_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_DFP3;		} else {			DRM_DEBUG(""DFP3 disconnected\n"");			bios_0_scratch &= ~ATOM_S0_DFP3;			bios_3_scratch &= ~ATOM_S3_DFP3_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_DFP3;		}	}	if ((radeon_encoder->devices & ATOM_DEVICE_DFP4_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_DFP4_SUPPORT)) {		if (connected) {			DRM_DEBUG(""DFP4 connected\n"");			bios_0_scratch |= ATOM_S0_DFP4;			bios_3_scratch |= ATOM_S3_DFP4_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_DFP4;		} else {			DRM_DEBUG(""DFP4 disconnected\n"");			bios_0_scratch &= ~ATOM_S0_DFP4;			bios_3_scratch &= ~ATOM_S3_DFP4_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_DFP4;		}	}	if ((radeon_encoder->devices & ATOM_DEVICE_DFP5_SUPPORT) &&	    (radeon_connector->devices & ATOM_DEVICE_DFP5_SUPPORT)) {		if (connected) {			DRM_DEBUG(""DFP5 connected\n"");			bios_0_scratch |= ATOM_S0_DFP5;			bios_3_scratch |= ATOM_S3_DFP5_ACTIVE;			bios_6_scratch |= ATOM_S6_ACC_REQ_DFP5;		} else {			DRM_DEBUG(""DFP5 disconnected\n"");			bios_0_scratch &= ~ATOM_S0_DFP5;			bios_3_scratch &= ~ATOM_S3_DFP5_ACTIVE;			bios_6_scratch &= ~ATOM_S6_ACC_REQ_DFP5;		}	}	if (rdev->family >= CHIP_R600) {		WREG32(R600_BIOS_0_SCRATCH, bios_0_scratch);		WREG32(R600_BIOS_3_SCRATCH, bios_3_scratch);		WREG32(R600_BIOS_6_SCRATCH, bios_6_scratch);	} else {		WREG32(RADEON_BIOS_0_SCRATCH, bios_0_scratch);		WREG32(RADEON_BIOS_3_SCRATCH, bios_3_scratch);		WREG32(RADEON_BIOS_6_SCRATCH, bios_6_scratch);	}}",28195
656,736,CVE-2010-4650,26,"static int fuse_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf){	struct page *page = vmf->page;	 	struct inode *inode = vma->vm_file->f_mapping->host;	fuse_wait_on_page_writeback(inode, page->index);	return 0;}",7020
260,2654,CVE-2017-1000251,26,"static void l2cap_sock_timeout(unsigned long arg){	struct sock *sk = (struct sock *) arg;	int reason;	BT_DBG(""sock %p state %d"", sk, sk->sk_state);	bh_lock_sock(sk);	if (sk->sk_state == BT_CONNECTED || sk->sk_state == BT_CONFIG)		reason = ECONNREFUSED;	else if (sk->sk_state == BT_CONNECT &&				l2cap_pi(sk)->sec_level != BT_SECURITY_SDP)		reason = ECONNREFUSED;	else		reason = ETIMEDOUT;	__l2cap_sock_close(sk, reason);	bh_unlock_sock(sk);	l2cap_sock_kill(sk);	sock_put(sk);}",19492
373,4040,CVE-2015-2806,26,"_asn1_ltostr (long v, char *str) {   long d, r;   char temp[LTOSTR_MAX_SIZE];  int count, k, start;  if (v < 0)    {      str[0] = '-';      start = 1;      v = -v;    }  else    start = 0;  count = 0;  do    {      d = v / 10;      r = v - d * 10;      temp[start + count] = '0' + (char) r;       count++;       v = d;     }  while (v);    for (k = 0; k < count; k++)     str[k + start] = temp[start + count - k - 1];  str[count + start] = 0;  return str;}",30892
458,2558,CVE-2016-1583,26,int sched_can_stop_tick(struct rq *rq){	int fifo_nr_running;	 	if (rq->dl.dl_nr_running)		return false;	 	if (rq->rt.rr_nr_running) {		if (rq->rt.rr_nr_running == 1)			return true;		else			return false;	}	 	fifo_nr_running = rq->rt.rt_nr_running - rq->rt.rr_nr_running;	if (fifo_nr_running)		return true;	 	if (rq->nr_running > 1)		return false;	return true;},18107
427,1409,CVE-2012-2119,26,"static int macvtap_receive(struct sk_buff *skb){	skb_push(skb, ETH_HLEN);	return macvtap_forward(skb->dev, skb);}",10015
392,2498,CVE-2016-1583,26,static inline void balance_callback(struct rq *rq){	if (unlikely(rq->balance_callback))		__balance_callback(rq);},18047
596,1784,CVE-2016-9793,26,"static void sock_def_readable(struct sock *sk){	struct socket_wq *wq;	rcu_read_lock();	wq = rcu_dereference(sk->sk_wq);	if (skwq_has_sleeper(wq))		wake_up_interruptible_sync_poll(&wq->wait, POLLIN | POLLPRI |						POLLRDNORM | POLLRDBAND);	sk_wake_async(sk, SOCK_WAKE_WAITD, POLL_IN);	rcu_read_unlock();}",15068
10,2764,CVE-2017-10671,26,"defang( char* str, char* dfstr, int dfsize )    {    char* cp1;    char* cp2;    for ( cp1 = str, cp2 = dfstr;	  *cp1 != '\0' && cp2 - dfstr < dfsize - 5;	  ++cp1, ++cp2 )	{	switch ( *cp1 )	    {	    case '<':	    *cp2++ = '&';	    *cp2++ = 'l';	    *cp2++ = 't';	    *cp2 = ';';	    break;	    case '>':	    *cp2++ = '&';	    *cp2++ = 'g';	    *cp2++ = 't';	    *cp2 = ';';	    break;	    default:	    *cp2 = *cp1;	    break;	    }	}    *cp2 = '\0';    }",20612
625,1236,CVE-2013-1929,26,"static void tg3_get_estats(struct tg3 *tp, struct tg3_ethtool_stats *estats){	struct tg3_ethtool_stats *old_estats = &tp->estats_prev;	struct tg3_hw_stats *hw_stats = tp->hw_stats;	ESTAT_ADD(rx_octets);	ESTAT_ADD(rx_fragments);	ESTAT_ADD(rx_ucast_packets);	ESTAT_ADD(rx_mcast_packets);	ESTAT_ADD(rx_bcast_packets);	ESTAT_ADD(rx_fcs_errors);	ESTAT_ADD(rx_align_errors);	ESTAT_ADD(rx_xon_pause_rcvd);	ESTAT_ADD(rx_xoff_pause_rcvd);	ESTAT_ADD(rx_mac_ctrl_rcvd);	ESTAT_ADD(rx_xoff_entered);	ESTAT_ADD(rx_frame_too_long_errors);	ESTAT_ADD(rx_jabbers);	ESTAT_ADD(rx_undersize_packets);	ESTAT_ADD(rx_in_length_errors);	ESTAT_ADD(rx_out_length_errors);	ESTAT_ADD(rx_64_or_less_octet_packets);	ESTAT_ADD(rx_65_to_127_octet_packets);	ESTAT_ADD(rx_128_to_255_octet_packets);	ESTAT_ADD(rx_256_to_511_octet_packets);	ESTAT_ADD(rx_512_to_1023_octet_packets);	ESTAT_ADD(rx_1024_to_1522_octet_packets);	ESTAT_ADD(rx_1523_to_2047_octet_packets);	ESTAT_ADD(rx_2048_to_4095_octet_packets);	ESTAT_ADD(rx_4096_to_8191_octet_packets);	ESTAT_ADD(rx_8192_to_9022_octet_packets);	ESTAT_ADD(tx_octets);	ESTAT_ADD(tx_collisions);	ESTAT_ADD(tx_xon_sent);	ESTAT_ADD(tx_xoff_sent);	ESTAT_ADD(tx_flow_control);	ESTAT_ADD(tx_mac_errors);	ESTAT_ADD(tx_single_collisions);	ESTAT_ADD(tx_mult_collisions);	ESTAT_ADD(tx_deferred);	ESTAT_ADD(tx_excessive_collisions);	ESTAT_ADD(tx_late_collisions);	ESTAT_ADD(tx_collide_2times);	ESTAT_ADD(tx_collide_3times);	ESTAT_ADD(tx_collide_4times);	ESTAT_ADD(tx_collide_5times);	ESTAT_ADD(tx_collide_6times);	ESTAT_ADD(tx_collide_7times);	ESTAT_ADD(tx_collide_8times);	ESTAT_ADD(tx_collide_9times);	ESTAT_ADD(tx_collide_10times);	ESTAT_ADD(tx_collide_11times);	ESTAT_ADD(tx_collide_12times);	ESTAT_ADD(tx_collide_13times);	ESTAT_ADD(tx_collide_14times);	ESTAT_ADD(tx_collide_15times);	ESTAT_ADD(tx_ucast_packets);	ESTAT_ADD(tx_mcast_packets);	ESTAT_ADD(tx_bcast_packets);	ESTAT_ADD(tx_carrier_sense_errors);	ESTAT_ADD(tx_discards);	ESTAT_ADD(tx_errors);	ESTAT_ADD(dma_writeq_full);	ESTAT_ADD(dma_write_prioq_full);	ESTAT_ADD(rxbds_empty);	ESTAT_ADD(rx_discards);	ESTAT_ADD(rx_errors);	ESTAT_ADD(rx_threshold_hit);	ESTAT_ADD(dma_readq_full);	ESTAT_ADD(dma_read_prioq_full);	ESTAT_ADD(tx_comp_queue_full);	ESTAT_ADD(ring_set_send_prod_index);	ESTAT_ADD(ring_status_update);	ESTAT_ADD(nic_irqs);	ESTAT_ADD(nic_avoided_irqs);	ESTAT_ADD(nic_tx_threshold_hit);	ESTAT_ADD(mbuf_lwm_thresh_hit);}",9242
921,2909,CVE-2017-8064,26,"static int dvb_usbv2_exit(struct dvb_usb_device *d){	dev_dbg(&d->udev->dev, ""%s:\n"", __func__);	dvb_usbv2_remote_exit(d);	dvb_usbv2_adapter_exit(d);	dvb_usbv2_i2c_exit(d);	kfree(d->priv);	kfree(d);	return 0;}",21386
875,875,CVE-2013-6381,26,"static inline int qeth_mtu_is_valid(struct qeth_card *card, int mtu){	switch (card->info.type) {	case QETH_CARD_TYPE_OSD:	case QETH_CARD_TYPE_OSM:	case QETH_CARD_TYPE_OSX:	case QETH_CARD_TYPE_IQD:		return ((mtu >= 576) &&			(mtu <= card->info.max_mtu));	case QETH_CARD_TYPE_OSN:	case QETH_CARD_TYPE_UNKNOWN:	default:		return 1;	}}",7304
328,1046,CVE-2013-4514,26,"int wvlan_uil(struct uilreq *urq, struct wl_private *lp){	int ioctl_ret = 0;	 	DBG_FUNC(""wvlan_uil"");	DBG_ENTER(DbgInfo);	switch (urq->command) {	case UIL_FUN_CONNECT:		DBG_TRACE(DbgInfo, ""IOCTL: WVLAN2_IOCTL_UIL -- WVLAN2_UIL_CONNECT\n"");		ioctl_ret = wvlan_uil_connect(urq, lp);		break;	case UIL_FUN_DISCONNECT:		DBG_TRACE(DbgInfo, ""IOCTL: WVLAN2_IOCTL_UIL -- WVLAN2_UIL_DISCONNECT\n"");		ioctl_ret = wvlan_uil_disconnect(urq, lp);		break;	case UIL_FUN_ACTION:		DBG_TRACE(DbgInfo, ""IOCTL: WVLAN2_IOCTL_UIL -- WVLAN2_UIL_ACTION\n"");		ioctl_ret = wvlan_uil_action(urq, lp);		break;	case UIL_FUN_SEND_DIAG_MSG:		DBG_TRACE(DbgInfo, ""IOCTL: WVLAN2_IOCTL_UIL -- WVLAN2_UIL_SEND_DIAG_MSG\n"");		ioctl_ret = wvlan_uil_send_diag_msg(urq, lp);		break;	case UIL_FUN_GET_INFO:		DBG_TRACE(DbgInfo, ""IOCTL: WVLAN2_IOCTL_UIL -- WVLAN2_UIL_GET_INFO\n"");		ioctl_ret = wvlan_uil_get_info(urq, lp);		break;	case UIL_FUN_PUT_INFO:		DBG_TRACE(DbgInfo, ""IOCTL: WVLAN2_IOCTL_UIL -- WVLAN2_UIL_PUT_INFO\n"");		ioctl_ret = wvlan_uil_put_info(urq, lp);		break;	default:		DBG_TRACE(DbgInfo, ""IOCTL: WVLAN2_IOCTL_UIL -- UNSUPPORTED UIL CODE: 0x%X"", urq->command);		ioctl_ret = -EOPNOTSUPP;		break;	}	DBG_LEAVE(DbgInfo);	return ioctl_ret;}  ",7747
709,2927,CVE-2017-8063,26,"static int cxusb_dee1601_tuner_attach(struct dvb_usb_adapter *adap){	dvb_attach(dvb_pll_attach, adap->fe_adap[0].fe, 0x61,		   NULL, DVB_PLL_THOMSON_DTT7579);	return 0;}",21404
668,365,CVE-2016-5126,26,"static char *parse_initiator_name(const char *target){    QemuOptsList *list;    QemuOpts *opts;    const char *name;    char *iscsi_name;    UuidInfo *uuid_info;    list = qemu_find_opts(""iscsi"");    if (list) {        opts = qemu_opts_find(list, target);        if (!opts) {            opts = QTAILQ_FIRST(&list->head);        }        if (opts) {            name = qemu_opt_get(opts, ""initiator-name"");            if (name) {                return g_strdup(name);            }        }    }    uuid_info = qmp_query_uuid(NULL);    if (strcmp(uuid_info->UUID, UUID_NONE) == 0) {        name = qemu_get_vm_name();    } else {        name = uuid_info->UUID;    }    iscsi_name = g_strdup_printf(""iqn.2008-11.org.linux-kvm%s%s"",                                 name ? "":"" : "", name ? name : "");    qapi_free_UuidInfo(uuid_info);    return iscsi_name;}",1853
514,968,CVE-2013-4591,26,"static int nfs4_map_errors(int err){	if (err >= -1000)		return err;	switch (err) {	case -NFS4ERR_RESOURCE:		return -EREMOTEIO;	case -NFS4ERR_WRONGSEC:		return -EPERM;	case -NFS4ERR_BADOWNER:	case -NFS4ERR_BADNAME:		return -EINVAL;	case -NFS4ERR_SHARE_DENIED:		return -EACCES;	case -NFS4ERR_MINOR_VERS_MISMATCH:		return -EPROTONOSUPPORT;	case -NFS4ERR_ACCESS:		return -EACCES;	default:		dprintk(""%s could not handle NFSv4 error %d\n"",				__func__, -err);		break;	}	return -EIO;}",7565
850,4055,CVE-2013-6763,26," static int au1200fb_fb_mmap(struct fb_info *info, struct vm_area_struct *vma) {	unsigned int len;	unsigned long start=0, off; 	struct au1200fb_device *fbdev = info->par; 	if (vma->vm_pgoff > (~0UL >> PAGE_SHIFT)) {		return -EINVAL;	}	start = fbdev->fb_phys & PAGE_MASK;	len = PAGE_ALIGN((start & ~PAGE_MASK) + fbdev->fb_len);	off = vma->vm_pgoff << PAGE_SHIFT;	if ((vma->vm_end - vma->vm_start + off) > len) {		return -EINVAL;	}	off += start;	vma->vm_pgoff = off >> PAGE_SHIFT; 	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot); 	pgprot_val(vma->vm_page_prot) |= _CACHE_MASK;   	return io_remap_pfn_range(vma, vma->vm_start, off >> PAGE_SHIFT,				  vma->vm_end - vma->vm_start,				  vma->vm_page_prot); }",31040
221,56,CVE-2019-15938,26,"static int rpc_check_reply(struct packet *pkt, int rpc_prog,			   int rpc_id, int *nfserr){	int *data;	struct rpc_reply rpc;	*nfserr = 0;	if (!pkt)		return -EAGAIN;	memcpy(&rpc, pkt->data, sizeof(rpc));	if (ntoh32(rpc.id) != rpc_id) {		if (rpc_id - ntoh32(rpc.id) == 1)			 			return 0;		return -EINVAL;	}	if (rpc.rstatus  ||	    rpc.verifier ||	    rpc.astatus ) {		return -EINVAL;	}	if (rpc_prog != PROG_NFS)		return 0;	data = (int *)(pkt->data + sizeof(struct rpc_reply));	*nfserr = ntoh32(net_read_uint32(data));	*nfserr = -*nfserr;	debug(""%s: state: %d, err %d\n"", __func__, nfs_state, *nfserr);	return 0;}",287
549,1140,CVE-2013-2237,26,"static struct xfrm_state * pfkey_msg2xfrm_state(struct net *net,						const struct sadb_msg *hdr,						void * const *ext_hdrs){	struct xfrm_state *x;	const struct sadb_lifetime *lifetime;	const struct sadb_sa *sa;	const struct sadb_key *key;	const struct sadb_x_sec_ctx *sec_ctx;	int proto;	int err;	sa = ext_hdrs[SADB_EXT_SA - 1];	if (!sa ||	    !present_and_same_family(ext_hdrs[SADB_EXT_ADDRESS_SRC-1],				     ext_hdrs[SADB_EXT_ADDRESS_DST-1]))		return ERR_PTR(-EINVAL);	if (hdr->sadb_msg_satype == SADB_SATYPE_ESP &&	    !ext_hdrs[SADB_EXT_KEY_ENCRYPT-1])		return ERR_PTR(-EINVAL);	if (hdr->sadb_msg_satype == SADB_SATYPE_AH &&	    !ext_hdrs[SADB_EXT_KEY_AUTH-1])		return ERR_PTR(-EINVAL);	if (!!ext_hdrs[SADB_EXT_LIFETIME_HARD-1] !=	    !!ext_hdrs[SADB_EXT_LIFETIME_SOFT-1])		return ERR_PTR(-EINVAL);	proto = pfkey_satype2proto(hdr->sadb_msg_satype);	if (proto == 0)		return ERR_PTR(-EINVAL);	 	err = -ENOBUFS;	 	if (sa->sadb_sa_auth > SADB_AALG_MAX ||	    (hdr->sadb_msg_satype == SADB_X_SATYPE_IPCOMP &&	     sa->sadb_sa_encrypt > SADB_X_CALG_MAX) ||	    sa->sadb_sa_encrypt > SADB_EALG_MAX)		return ERR_PTR(-EINVAL);	key = ext_hdrs[SADB_EXT_KEY_AUTH - 1];	if (key != NULL &&	    sa->sadb_sa_auth != SADB_X_AALG_NULL &&	    ((key->sadb_key_bits+7) / 8 == 0 ||	     (key->sadb_key_bits+7) / 8 > key->sadb_key_len * sizeof(int)))		return ERR_PTR(-EINVAL);	key = ext_hdrs[SADB_EXT_KEY_ENCRYPT-1];	if (key != NULL &&	    sa->sadb_sa_encrypt != SADB_EALG_NULL &&	    ((key->sadb_key_bits+7) / 8 == 0 ||	     (key->sadb_key_bits+7) / 8 > key->sadb_key_len * sizeof(int)))		return ERR_PTR(-EINVAL);	x = xfrm_state_alloc(net);	if (x == NULL)		return ERR_PTR(-ENOBUFS);	x->id.proto = proto;	x->id.spi = sa->sadb_sa_spi;	x->props.replay_window = sa->sadb_sa_replay;	if (sa->sadb_sa_flags & SADB_SAFLAGS_NOECN)		x->props.flags |= XFRM_STATE_NOECN;	if (sa->sadb_sa_flags & SADB_SAFLAGS_DECAP_DSCP)		x->props.flags |= XFRM_STATE_DECAP_DSCP;	if (sa->sadb_sa_flags & SADB_SAFLAGS_NOPMTUDISC)		x->props.flags |= XFRM_STATE_NOPMTUDISC;	lifetime = ext_hdrs[SADB_EXT_LIFETIME_HARD - 1];	if (lifetime != NULL) {		x->lft.hard_packet_limit = _KEY2X(lifetime->sadb_lifetime_allocations);		x->lft.hard_byte_limit = _KEY2X(lifetime->sadb_lifetime_bytes);		x->lft.hard_add_expires_seconds = lifetime->sadb_lifetime_addtime;		x->lft.hard_use_expires_seconds = lifetime->sadb_lifetime_usetime;	}	lifetime = ext_hdrs[SADB_EXT_LIFETIME_SOFT - 1];	if (lifetime != NULL) {		x->lft.soft_packet_limit = _KEY2X(lifetime->sadb_lifetime_allocations);		x->lft.soft_byte_limit = _KEY2X(lifetime->sadb_lifetime_bytes);		x->lft.soft_add_expires_seconds = lifetime->sadb_lifetime_addtime;		x->lft.soft_use_expires_seconds = lifetime->sadb_lifetime_usetime;	}	sec_ctx = ext_hdrs[SADB_X_EXT_SEC_CTX - 1];	if (sec_ctx != NULL) {		struct xfrm_user_sec_ctx *uctx = pfkey_sadb2xfrm_user_sec_ctx(sec_ctx);		if (!uctx)			goto out;		err = security_xfrm_state_alloc(x, uctx);		kfree(uctx);		if (err)			goto out;	}	key = ext_hdrs[SADB_EXT_KEY_AUTH - 1];	if (sa->sadb_sa_auth) {		int keysize = 0;		struct xfrm_algo_desc *a = xfrm_aalg_get_byid(sa->sadb_sa_auth);		if (!a || !a->pfkey_supported) {			err = -ENOSYS;			goto out;		}		if (key)			keysize = (key->sadb_key_bits + 7) / 8;		x->aalg = kmalloc(sizeof(*x->aalg) + keysize, GFP_KERNEL);		if (!x->aalg)			goto out;		strcpy(x->aalg->alg_name, a->name);		x->aalg->alg_key_len = 0;		if (key) {			x->aalg->alg_key_len = key->sadb_key_bits;			memcpy(x->aalg->alg_key, key+1, keysize);		}		x->aalg->alg_trunc_len = a->uinfo.auth.icv_truncbits;		x->props.aalgo = sa->sadb_sa_auth;		 	}	if (sa->sadb_sa_encrypt) {		if (hdr->sadb_msg_satype == SADB_X_SATYPE_IPCOMP) {			struct xfrm_algo_desc *a = xfrm_calg_get_byid(sa->sadb_sa_encrypt);			if (!a || !a->pfkey_supported) {				err = -ENOSYS;				goto out;			}			x->calg = kmalloc(sizeof(*x->calg), GFP_KERNEL);			if (!x->calg)				goto out;			strcpy(x->calg->alg_name, a->name);			x->props.calgo = sa->sadb_sa_encrypt;		} else {			int keysize = 0;			struct xfrm_algo_desc *a = xfrm_ealg_get_byid(sa->sadb_sa_encrypt);			if (!a || !a->pfkey_supported) {				err = -ENOSYS;				goto out;			}			key = (struct sadb_key*) ext_hdrs[SADB_EXT_KEY_ENCRYPT-1];			if (key)				keysize = (key->sadb_key_bits + 7) / 8;			x->ealg = kmalloc(sizeof(*x->ealg) + keysize, GFP_KERNEL);			if (!x->ealg)				goto out;			strcpy(x->ealg->alg_name, a->name);			x->ealg->alg_key_len = 0;			if (key) {				x->ealg->alg_key_len = key->sadb_key_bits;				memcpy(x->ealg->alg_key, key+1, keysize);			}			x->props.ealgo = sa->sadb_sa_encrypt;		}	}	 	x->props.family = pfkey_sadb_addr2xfrm_addr((struct sadb_address *) ext_hdrs[SADB_EXT_ADDRESS_SRC-1],						    &x->props.saddr);	if (!x->props.family) {		err = -EAFNOSUPPORT;		goto out;	}	pfkey_sadb_addr2xfrm_addr((struct sadb_address *) ext_hdrs[SADB_EXT_ADDRESS_DST-1],				  &x->id.daddr);	if (ext_hdrs[SADB_X_EXT_SA2-1]) {		const struct sadb_x_sa2 *sa2 = ext_hdrs[SADB_X_EXT_SA2-1];		int mode = pfkey_mode_to_xfrm(sa2->sadb_x_sa2_mode);		if (mode < 0) {			err = -EINVAL;			goto out;		}		x->props.mode = mode;		x->props.reqid = sa2->sadb_x_sa2_reqid;	}	if (ext_hdrs[SADB_EXT_ADDRESS_PROXY-1]) {		const struct sadb_address *addr = ext_hdrs[SADB_EXT_ADDRESS_PROXY-1];		 		x->sel.family = pfkey_sadb_addr2xfrm_addr(addr, &x->sel.saddr);		x->sel.prefixlen_s = addr->sadb_address_prefixlen;	}	if (!x->sel.family)		x->sel.family = x->props.family;	if (ext_hdrs[SADB_X_EXT_NAT_T_TYPE-1]) {		const struct sadb_x_nat_t_type* n_type;		struct xfrm_encap_tmpl *natt;		x->encap = kmalloc(sizeof(*x->encap), GFP_KERNEL);		if (!x->encap)			goto out;		natt = x->encap;		n_type = ext_hdrs[SADB_X_EXT_NAT_T_TYPE-1];		natt->encap_type = n_type->sadb_x_nat_t_type_type;		if (ext_hdrs[SADB_X_EXT_NAT_T_SPORT-1]) {			const struct sadb_x_nat_t_port *n_port =				ext_hdrs[SADB_X_EXT_NAT_T_SPORT-1];			natt->encap_sport = n_port->sadb_x_nat_t_port_port;		}		if (ext_hdrs[SADB_X_EXT_NAT_T_DPORT-1]) {			const struct sadb_x_nat_t_port *n_port =				ext_hdrs[SADB_X_EXT_NAT_T_DPORT-1];			natt->encap_dport = n_port->sadb_x_nat_t_port_port;		}		memset(&natt->encap_oa, 0, sizeof(natt->encap_oa));	}	err = xfrm_init_state(x);	if (err)		goto out;	x->km.seq = hdr->sadb_msg_seq;	return x;out:	x->km.state = XFRM_STATE_DEAD;	xfrm_state_put(x);	return ERR_PTR(err);}",8729
295,3877,CVE-2017-6991,26,static int debugMutexInit(void){ return SQLITE_OK; },29864
289,877,CVE-2013-6381,26,static int qeth_peer_func_level(int level){	if ((level & 0xff) == 8)		return (level & 0xff) + 0x400;	if (((level >> 8) & 3) == 1)		return (level & 0xff) + 0x200;	return level;},7306
404,3495,CVE-2019-11222,26,char gf_prompt_get_char(){	return getchar();},27151
810,2494,CVE-2016-1583,26,"static void __setscheduler(struct rq *rq, struct task_struct *p,			   const struct sched_attr *attr, int keep_boost){	__setscheduler_params(p, attr);	 	if (keep_boost)		p->prio = rt_mutex_get_effective_prio(p, normal_prio(p));	else		p->prio = normal_prio(p);	if (dl_prio(p->prio))		p->sched_class = &dl_sched_class;	else if (rt_prio(p->prio))		p->sched_class = &rt_sched_class;	else		p->sched_class = &fair_sched_class;}",18043
335,1246,CVE-2013-1929,26,"static int tg3_halt(struct tg3 *tp, int kind, int silent){	int err;	tg3_stop_fw(tp);	tg3_write_sig_pre_reset(tp, kind);	tg3_abort_hw(tp, silent);	err = tg3_chip_reset(tp);	__tg3_set_mac_addr(tp, 0);	tg3_write_sig_legacy(tp, kind);	tg3_write_sig_post_reset(tp, kind);	if (tp->hw_stats) {		 		tg3_get_nstats(tp, &tp->net_stats_prev);		tg3_get_estats(tp, &tp->estats_prev);		 		memset(tp->hw_stats, 0, sizeof(struct tg3_hw_stats));	}	if (err)		return err;	return 0;}",9252
884,2269,CVE-2016-2324,26,"void bitmap_writer_finish(struct pack_idx_entry **index,			  int index_nr,			  const char *filename,			  int options){	static char tmp_file[PATH_MAX];	static int default_version = 1;	static int flags = BITMAP_OPT_FULL_DAG;	struct sha1file *f;	struct bitmap_disk_header header;	int fd = odb_mkstemp(tmp_file, sizeof(tmp_file), ""pack/tmp_bitmap_XXXXXX"");	if (fd < 0)		die_errno(""unable to create '%s'"", tmp_file);	f = sha1fd(fd, tmp_file);	memcpy(header.magic, BITMAP_IDX_SIGNATURE, sizeof(BITMAP_IDX_SIGNATURE));	header.version = htons(default_version);	header.options = htons(flags | options);	header.entry_count = htonl(writer.selected_nr);	hashcpy(header.checksum, writer.pack_checksum);	sha1write(f, &header, sizeof(header));	dump_bitmap(f, writer.commits);	dump_bitmap(f, writer.trees);	dump_bitmap(f, writer.blobs);	dump_bitmap(f, writer.tags);	write_selected_commits_v1(f, index, index_nr);	if (options & BITMAP_OPT_HASH_CACHE)		write_hash_cache(f, index, index_nr);	sha1close(f, NULL, CSUM_FSYNC);	if (adjust_shared_perm(tmp_file))		die_errno(""unable to make temporary bitmap file readable"");	if (rename(tmp_file, filename))		die_errno(""unable to rename temporary bitmap file to '%s'"", filename);}",17689
474,541,CVE-2012-3400,26,"static int udf_load_metadata_files(struct super_block *sb, int partition){	struct udf_sb_info *sbi = UDF_SB(sb);	struct udf_part_map *map;	struct udf_meta_data *mdata;	struct kernel_lb_addr addr;	map = &sbi->s_partmaps[partition];	mdata = &map->s_type_specific.s_metadata;	 	udf_debug(""Metadata file location: block = %d part = %d\n"",		  mdata->s_meta_file_loc, map->s_partition_num);	mdata->s_metadata_fe = udf_find_metadata_inode_efe(sb,		mdata->s_meta_file_loc, map->s_partition_num);	if (mdata->s_metadata_fe == NULL) {		 		udf_debug(""Mirror metadata file location: block = %d part = %d\n"",			  mdata->s_mirror_file_loc, map->s_partition_num);		mdata->s_mirror_fe = udf_find_metadata_inode_efe(sb,			mdata->s_mirror_file_loc, map->s_partition_num);		if (mdata->s_mirror_fe == NULL) {			udf_err(sb, ""Both metadata and mirror metadata inode efe can not found\n"");			goto error_exit;		}	}	 	if (mdata->s_bitmap_file_loc != 0xFFFFFFFF) {		addr.logicalBlockNum = mdata->s_bitmap_file_loc;		addr.partitionReferenceNum = map->s_partition_num;		udf_debug(""Bitmap file location: block = %d part = %d\n"",			  addr.logicalBlockNum, addr.partitionReferenceNum);		mdata->s_bitmap_fe = udf_iget(sb, &addr);		if (mdata->s_bitmap_fe == NULL) {			if (sb->s_flags & MS_RDONLY)				udf_warn(sb, ""bitmap inode efe not found but it's ok since the disc is mounted read-only\n"");			else {				udf_err(sb, ""bitmap inode efe not found and attempted read-write mount\n"");				goto error_exit;			}		}	}	udf_debug(""udf_load_metadata_files Ok\n"");	return 0;error_exit:	return 1;}",3126
428,3299,CVE-2018-10124,26,SYSCALL_DEFINE0(pause){	while (!signal_pending(current)) {		__set_current_state(TASK_INTERRUPTIBLE);		schedule();	}	return -ERESTARTNOHAND;},25226
714,2237,CVE-2016-2324,26,"static void init_threaded_search(void){	init_recursive_mutex(&read_mutex);	pthread_mutex_init(&cache_mutex, NULL);	pthread_mutex_init(&progress_mutex, NULL);	pthread_cond_init(&progress_cond, NULL);	old_try_to_free_routine = set_try_to_free_routine(try_to_free_from_threads);}",17657
314,2957,CVE-2017-8062,26,"static int su3000_identify_state(struct usb_device *udev,				 struct dvb_usb_device_properties *props,				 struct dvb_usb_device_description **desc,				 int *cold){	info(""%s"", __func__);	*cold = 0;	return 0;}",21434
871,3668,CVE-2012-6712,26,"void iwl_dealloc_bcast_stations(struct iwl_priv *priv){	unsigned long flags;	int i;	spin_lock_irqsave(&priv->shrd->sta_lock, flags);	for (i = 0; i < IWLAGN_STATION_COUNT; i++) {		if (!(priv->stations[i].used & IWL_STA_BCAST))			continue;		priv->stations[i].used &= ~IWL_STA_UCODE_ACTIVE;		priv->num_stations--;		if (WARN_ON(priv->num_stations < 0))			priv->num_stations = 0;		kfree(priv->stations[i].lq);		priv->stations[i].lq = NULL;	}	spin_unlock_irqrestore(&priv->shrd->sta_lock, flags);}",28154
145,3426,CVE-2017-15128,26,"static int is_vma_resv_set(struct vm_area_struct *vma, unsigned long flag){	VM_BUG_ON_VMA(!is_vm_hugetlb_page(vma), vma);	return (get_vma_private_data(vma) & flag) != 0;}",26186
525,516,CVE-2012-6711,26,"pop_context (){  pop_dollar_vars ();  variable_context--;  pop_var_context ();  sv_ifs (""IFS"");		 }",2556
334,2250,CVE-2016-2324,26,static int pbase_tree_cache_ix(const unsigned char *sha1){	return sha1[0] % ARRAY_SIZE(pbase_tree_cache);},17670
452,269,CVE-2017-6542,26,static int ssh2_pkt_getint(struct Packet *pkt){    unsigned long value;    if (pkt->length - pkt->savedpos < 1)	return 0;		            value = pkt->body[pkt->savedpos] != 0;    pkt->savedpos++;    return value;},1333
528,48,CVE-2019-15938,26,"static int nfs_probe(struct device_d *dev){	struct fs_device_d *fsdev = dev_to_fs_device(dev);	struct nfs_priv *npriv = xzalloc(sizeof(struct nfs_priv));	struct super_block *sb = &fsdev->sb;	char *tmp = xstrdup(fsdev->backingstore);	char *path;	struct inode *inode;	int ret;	dev->priv = npriv;	debug(""nfs: mount: %s\n"", fsdev->backingstore);	path = strchr(tmp, ':');	if (!path) {		ret = -EINVAL;		goto err;	}	*path = 0;	npriv->path = xstrdup(path + 1);	ret = resolv(tmp, &npriv->server);	if (ret) {		printf(""cannot resolve \""%s\"": %s\n"", tmp, strerror(-ret));		goto err1;	}	debug(""nfs: server: %s path: %s\n"", tmp, npriv->path);	npriv->con = net_udp_new(npriv->server, SUNRPC_PORT, nfs_handler, npriv);	if (IS_ERR(npriv->con)) {		ret = PTR_ERR(npriv->con);		goto err1;	}	 	net_udp_bind(npriv->con, 1000);	parseopt_hu(fsdev->options, ""mountport"", &npriv->mount_port);	if (!npriv->mount_port) {		ret = rpc_lookup_req(npriv, PROG_MOUNT, 3);		if (ret < 0) {			printf(""lookup mount port failed with %d\n"", ret);			goto err2;		}		npriv->mount_port = ret;	} else {		npriv->manual_mount_port = 1;	}	debug(""mount port: %hu\n"", npriv->mount_port);	parseopt_hu(fsdev->options, ""port"", &npriv->nfs_port);	if (!npriv->nfs_port) {		ret = rpc_lookup_req(npriv, PROG_NFS, 3);		if (ret < 0) {			printf(""lookup nfs port failed with %d\n"", ret);			goto err2;		}		npriv->nfs_port = ret;	} else {		npriv->manual_nfs_port = 1;	}	debug(""nfs port: %d\n"", npriv->nfs_port);	ret = nfs_mount_req(npriv);	if (ret) {		printf(""mounting failed with %d\n"", ret);		goto err2;	}	nfs_set_rootarg(npriv, fsdev);	free(tmp);	sb->s_op = &nfs_ops;	inode = new_inode(sb);	nfs_set_fh(inode, &npriv->rootfh);	nfs_init_inode(npriv, inode, S_IFDIR);	sb->s_root = d_make_root(inode);	return 0;err2:	net_unregister(npriv->con);err1:	free(npriv->path);err:	free(tmp);	free(npriv);	return ret;}",279
538,490,CVE-2013-4150,26,static int virtio_net_guest_offloads_by_features(int features){    static const int guest_offloads_mask =        (1ULL << VIRTIO_NET_F_GUEST_CSUM) |        (1ULL << VIRTIO_NET_F_GUEST_TSO4) |        (1ULL << VIRTIO_NET_F_GUEST_TSO6) |        (1ULL << VIRTIO_NET_F_GUEST_ECN)  |        (1ULL << VIRTIO_NET_F_GUEST_UFO);    return guest_offloads_mask & features;},2420
347,2786,CVE-2017-9994,26,"static void inv_predict_10(int *p, const int *p_l, const int *p_tl,                           const int *p_t, const int *p_tr){    p[0] = (p_l[0] + p_tl[0] >> 1) + (p_t[0] + p_tr[0] >> 1) >> 1;    p[1] = (p_l[1] + p_tl[1] >> 1) + (p_t[1] + p_tr[1] >> 1) >> 1;    p[2] = (p_l[2] + p_tl[2] >> 1) + (p_t[2] + p_tr[2] >> 1) >> 1;    p[3] = (p_l[3] + p_tl[3] >> 1) + (p_t[3] + p_tr[3] >> 1) >> 1;}",20671
191,738,CVE-2010-4650,26,"static int fuse_readpages(struct file *file, struct address_space *mapping,			  struct list_head *pages, unsigned nr_pages){	struct inode *inode = mapping->host;	struct fuse_conn *fc = get_fuse_conn(inode);	struct fuse_fill_data data;	int err;	err = -EIO;	if (is_bad_inode(inode))		goto out;	data.file = file;	data.inode = inode;	data.req = fuse_get_req(fc);	err = PTR_ERR(data.req);	if (IS_ERR(data.req))		goto out;	err = read_cache_pages(mapping, pages, fuse_readpages_fill, &data);	if (!err) {		if (data.req->num_pages)			fuse_send_readpages(data.req, file);		else			fuse_put_request(fc, data.req);	}out:	return err;}",7022
920,2147,CVE-2016-4303,26,"timeval_diff(struct timeval * tv0, struct timeval * tv1){    double time1, time2;        time1 = tv0->tv_sec + (tv0->tv_usec / 1000000.0);    time2 = tv1->tv_sec + (tv1->tv_usec / 1000000.0);    time1 = time1 - time2;    if (time1 < 0)        time1 = -time1;    return time1;}",17055
52,155,CVE-2015-3456,26,"static int fdctrl_transfer_handler (void *opaque, int nchan,                                    int dma_pos, int dma_len){    FDCtrl *fdctrl;    FDrive *cur_drv;    int len, start_pos, rel_pos;    int status0 = 0x00, status1 = 0x00, status2 = 0x00;    fdctrl = opaque;    if (fdctrl->msr & FD_MSR_RQM) {        FLOPPY_DPRINTF(""Not in DMA transfer mode !\n"");        return 0;    }    cur_drv = get_cur_drv(fdctrl);    if (fdctrl->data_dir == FD_DIR_SCANE || fdctrl->data_dir == FD_DIR_SCANL ||        fdctrl->data_dir == FD_DIR_SCANH)        status2 = FD_SR2_SNS;    if (dma_len > fdctrl->data_len)        dma_len = fdctrl->data_len;    if (cur_drv->blk == NULL) {        if (fdctrl->data_dir == FD_DIR_WRITE)            fdctrl_stop_transfer(fdctrl, FD_SR0_ABNTERM | FD_SR0_SEEK, 0x00, 0x00);        else            fdctrl_stop_transfer(fdctrl, FD_SR0_ABNTERM, 0x00, 0x00);        len = 0;        goto transfer_error;    }    rel_pos = fdctrl->data_pos % FD_SECTOR_LEN;    for (start_pos = fdctrl->data_pos; fdctrl->data_pos < dma_len;) {        len = dma_len - fdctrl->data_pos;        if (len + rel_pos > FD_SECTOR_LEN)            len = FD_SECTOR_LEN - rel_pos;        FLOPPY_DPRINTF(""copy %d bytes (%d %d %d) %d pos %d %02x ""                       ""(%d-0x%08x 0x%08x)\n"", len, dma_len, fdctrl->data_pos,                       fdctrl->data_len, GET_CUR_DRV(fdctrl), cur_drv->head,                       cur_drv->track, cur_drv->sect, fd_sector(cur_drv),                       fd_sector(cur_drv) * FD_SECTOR_LEN);        if (fdctrl->data_dir != FD_DIR_WRITE ||            len < FD_SECTOR_LEN || rel_pos != 0) {                         if (blk_read(cur_drv->blk, fd_sector(cur_drv),                         fdctrl->fifo, 1) < 0) {                FLOPPY_DPRINTF(""Floppy: error getting sector %d\n"",                               fd_sector(cur_drv));                                 memset(fdctrl->fifo, 0, FD_SECTOR_LEN);            }        }        switch (fdctrl->data_dir) {        case FD_DIR_READ:                         DMA_write_memory (nchan, fdctrl->fifo + rel_pos,                              fdctrl->data_pos, len);            break;        case FD_DIR_WRITE:                         if (cur_drv->ro) {                                 fdctrl_stop_transfer(fdctrl,                                     FD_SR0_ABNTERM | FD_SR0_SEEK, FD_SR1_NW,                                     0x00);                goto transfer_error;            }            DMA_read_memory (nchan, fdctrl->fifo + rel_pos,                             fdctrl->data_pos, len);            if (blk_write(cur_drv->blk, fd_sector(cur_drv),                          fdctrl->fifo, 1) < 0) {                FLOPPY_DPRINTF(""error writing sector %d\n"",                               fd_sector(cur_drv));                fdctrl_stop_transfer(fdctrl, FD_SR0_ABNTERM | FD_SR0_SEEK, 0x00, 0x00);                goto transfer_error;            }            break;        case FD_DIR_VERIFY:                         break;        default:                         {                int tmpbuf[FD_SECTOR_LEN];                int ret;                DMA_read_memory (nchan, tmpbuf, fdctrl->data_pos, len);                ret = memcmp(tmpbuf, fdctrl->fifo + rel_pos, len);                if (ret == 0) {                    status2 = FD_SR2_SEH;                    goto end_transfer;                }                if ((ret < 0 && fdctrl->data_dir == FD_DIR_SCANL) ||                    (ret > 0 && fdctrl->data_dir == FD_DIR_SCANH)) {                    status2 = 0x00;                    goto end_transfer;                }            }            break;        }        fdctrl->data_pos += len;        rel_pos = fdctrl->data_pos % FD_SECTOR_LEN;        if (rel_pos == 0) {                         if (!fdctrl_seek_to_next_sect(fdctrl, cur_drv))                break;        }    } end_transfer:    len = fdctrl->data_pos - start_pos;    FLOPPY_DPRINTF(""end transfer %d %d %d\n"",                   fdctrl->data_pos, len, fdctrl->data_len);    if (fdctrl->data_dir == FD_DIR_SCANE ||        fdctrl->data_dir == FD_DIR_SCANL ||        fdctrl->data_dir == FD_DIR_SCANH)        status2 = FD_SR2_SEH;    fdctrl->data_len -= len;    fdctrl_stop_transfer(fdctrl, status0, status1, status2); transfer_error:    return len;}",609
989,2324,CVE-2016-2324,26,"void clear_ref_exclusion(struct string_list **ref_excludes_p){	if (*ref_excludes_p) {		string_list_clear(*ref_excludes_p, 0);		free(*ref_excludes_p);	}	*ref_excludes_p = NULL;}",17744
918,1157,CVE-2013-2237,26,"static int pfkey_seq_show(struct seq_file *f, void *v){	struct sock *s = sk_entry(v);	if (v == SEQ_START_TOKEN)		seq_printf(f ,""sk       RefCnt Rmem   Wmem   User   Inode\n"");	else		seq_printf(f, ""%pK %-6d %-6u %-6u %-6u %-6lu\n"",			       s,			       atomic_read(&s->sk_refcnt),			       sk_rmem_alloc_get(s),			       sk_wmem_alloc_get(s),			       from_kuid_munged(seq_user_ns(f), sock_i_uid(s)),			       sock_i_ino(s)			       );	return 0;}",8746
786,3337,CVE-2017-1000494,26,ClearNameValueList(struct NameValueParserData * pdata){    struct NameValue * nv;	if(pdata->portListing)	{		free(pdata->portListing);		pdata->portListing = NULL;		pdata->portListingLength = 0;	}    while((nv = pdata->l_head) != NULL)    {		pdata->l_head = nv->l_next;        free(nv);    }},25617
245,3533,CVE-2018-20855,26,"static int max_bfregs(struct mlx5_ib_dev *dev, struct mlx5_bfreg_info *bfregi){	return get_num_static_uars(dev, bfregi) * MLX5_NON_FP_BFREGS_PER_UAR;}",27561
826,2417,CVE-2016-2315,26,static void option_export_marks(const char *marks){	export_marks_file = make_fast_import_path(marks);	safe_create_leading_directories_const(export_marks_file);},17837
828,514,CVE-2012-6711,26,merge_temporary_env (){  if (temporary_env)    dispose_temporary_env (push_temp_var);},2554
396,1240,CVE-2013-1929,26,"static void tg3_get_ringparam(struct net_device *dev, struct ethtool_ringparam *ering){	struct tg3 *tp = netdev_priv(dev);	ering->rx_max_pending = tp->rx_std_ring_mask;	if (tg3_flag(tp, JUMBO_RING_ENABLE))		ering->rx_jumbo_max_pending = tp->rx_jmb_ring_mask;	else		ering->rx_jumbo_max_pending = 0;	ering->tx_max_pending = TG3_TX_RING_SIZE - 1;	ering->rx_pending = tp->rx_pending;	if (tg3_flag(tp, JUMBO_RING_ENABLE))		ering->rx_jumbo_pending = tp->rx_jumbo_pending;	else		ering->rx_jumbo_pending = 0;	ering->tx_pending = tp->napi[0].tx_pending;}",9246
900,3524,CVE-2018-20855,26,"static void *get_wqe(struct mlx5_ib_qp *qp, int offset){	return mlx5_buf_offset(&qp->buf, offset);}",27552
991,3909,CVE-2016-1678,26,  RenderFrameHostManagerUnloadBrowserTest() {},30342
217,309,CVE-2012-3291,26,"static int appendenv(const char *opt, const char *new){	char buf[1024];	char *old = getenv(opt);	buf[1023] = 0;	if (old)		snprintf(buf, 1023, ""%s %s"", old, new);	else		snprintf(buf, 1023, ""%s"", new);	return setenv(opt, buf, 1);}",1637
793,2702,CVE-2017-16534,26,"int usb_set_interface(struct usb_device *dev, int interface, int alternate){	struct usb_interface *iface;	struct usb_host_interface *alt;	struct usb_hcd *hcd = bus_to_hcd(dev->bus);	int i, ret, manual = 0;	unsigned int epaddr;	unsigned int pipe;	if (dev->state == USB_STATE_SUSPENDED)		return -EHOSTUNREACH;	iface = usb_ifnum_to_if(dev, interface);	if (!iface) {		dev_dbg(&dev->dev, ""selecting invalid interface %d\n"",			interface);		return -EINVAL;	}	if (iface->unregistering)		return -ENODEV;	alt = usb_altnum_to_altsetting(iface, alternate);	if (!alt) {		dev_warn(&dev->dev, ""selecting invalid altsetting %d\n"",			 alternate);		return -EINVAL;	}	 	mutex_lock(hcd->bandwidth_mutex);	 	if (usb_disable_lpm(dev)) {		dev_err(&iface->dev, ""%s Failed to disable LPM\n."", __func__);		mutex_unlock(hcd->bandwidth_mutex);		return -ENOMEM;	}	 	for (i = 0; i < iface->cur_altsetting->desc.bNumEndpoints; i++)		iface->cur_altsetting->endpoint[i].streams = 0;	ret = usb_hcd_alloc_bandwidth(dev, NULL, iface->cur_altsetting, alt);	if (ret < 0) {		dev_info(&dev->dev, ""Not enough bandwidth for altsetting %d\n"",				alternate);		usb_enable_lpm(dev);		mutex_unlock(hcd->bandwidth_mutex);		return ret;	}	if (dev->quirks & USB_QUIRK_NO_SET_INTF)		ret = -EPIPE;	else		ret = usb_control_msg(dev, usb_sndctrlpipe(dev, 0),				   USB_REQ_SET_INTERFACE, USB_RECIP_INTERFACE,				   alternate, interface, NULL, 0, 5000);	 	if (ret == -EPIPE && iface->num_altsetting == 1) {		dev_dbg(&dev->dev,			""manual set_interface for iface %d, alt %d\n"",			interface, alternate);		manual = 1;	} else if (ret < 0) {		 		usb_hcd_alloc_bandwidth(dev, NULL, alt, iface->cur_altsetting);		usb_enable_lpm(dev);		mutex_unlock(hcd->bandwidth_mutex);		return ret;	}	mutex_unlock(hcd->bandwidth_mutex);	 	 	if (iface->cur_altsetting != alt) {		remove_intf_ep_devs(iface);		usb_remove_sysfs_intf_files(iface);	}	usb_disable_interface(dev, iface, true);	iface->cur_altsetting = alt;	 	usb_unlocked_enable_lpm(dev);	 	if (manual) {		for (i = 0; i < alt->desc.bNumEndpoints; i++) {			epaddr = alt->endpoint[i].desc.bEndpointAddress;			pipe = __create_pipe(dev,					USB_ENDPOINT_NUMBER_MASK & epaddr) |					(usb_endpoint_out(epaddr) ?					USB_DIR_OUT : USB_DIR_IN);			usb_clear_halt(dev, pipe);		}	}	 	usb_enable_interface(dev, iface, true);	if (device_is_registered(&iface->dev)) {		usb_create_sysfs_intf_files(iface);		create_intf_ep_devs(iface);	}	return 0;}",19708
133,371,CVE-2016-4544,26,"static void php_ifd_set16u(char *data, unsigned int value, int motorola_intel){	if (motorola_intel) {		data[0] = (value & 0xFF00) >> 8;		data[1] = (value & 0x00FF);	} else {		data[1] = (value & 0xFF00) >> 8;		data[0] = (value & 0x00FF);	}}",1880
83,1549,CVE-2014-0069,26,"cifs_lock_add_if(struct cifsFileInfo *cfile, struct cifsLockInfo *lock,		 int wait){	struct cifsLockInfo *conf_lock;	struct cifsInodeInfo *cinode = CIFS_I(cfile->dentry->d_inode);	int exist;	int rc = 0;try_again:	exist = false;	down_write(&cinode->lock_sem);	exist = cifs_find_lock_conflict(cfile, lock->offset, lock->length,					lock->type, &conf_lock, CIFS_LOCK_OP);	if (!exist && cinode->can_cache_brlcks) {		list_add_tail(&lock->llist, &cfile->llist->locks);		up_write(&cinode->lock_sem);		return rc;	}	if (!exist)		rc = 1;	else if (!wait)		rc = -EACCES;	else {		list_add_tail(&lock->blist, &conf_lock->blist);		up_write(&cinode->lock_sem);		rc = wait_event_interruptible(lock->block_q,					(lock->blist.prev == &lock->blist) &&					(lock->blist.next == &lock->blist));		if (!rc)			goto try_again;		down_write(&cinode->lock_sem);		list_del_init(&lock->blist);	}	up_write(&cinode->lock_sem);	return rc;}",12295
99,1953,CVE-2016-5400,26,"static int airspy_free_urbs(struct airspy *s){	int i;	airspy_kill_urbs(s);	for (i = s->urbs_initialized - 1; i >= 0; i--) {		if (s->urb_list[i]) {			dev_dbg(s->dev, ""free urb=%d\n"", i);			 			usb_free_urb(s->urb_list[i]);		}	}	s->urbs_initialized = 0;	return 0;}",16457
861,27,CVE-2015-6806,26,"ClearToEOS(){  register int y = curr->w_y, x = curr->w_x;  if (x == 0 && y == 0)    {      ClearScreen();      RestorePosRendition();      return;    }  LClearArea(&curr->w_layer, x, y, cols - 1, rows - 1, CURR_BCE, 1);  MClearArea(curr, x, y, cols - 1, rows - 1, CURR_BCE);  RestorePosRendition();}",248
789,299,CVE-2016-6835,26,void vmxnet_tx_pkt_uninit(struct VmxnetTxPkt *pkt){    if (pkt) {        g_free(pkt->vec);        g_free(pkt->raw);        g_free(pkt);    }},1597
255,1114,CVE-2013-2237,26,"static int key_notify_policy_expire(struct xfrm_policy *xp, const struct km_event *c){	return 0;}",8703
978,687,CVE-2011-2517,26,"void nl80211_send_reg_change_event(struct regulatory_request *request){	struct sk_buff *msg;	void *hdr;	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);	if (!msg)		return;	hdr = nl80211hdr_put(msg, 0, 0, 0, NL80211_CMD_REG_CHANGE);	if (!hdr) {		nlmsg_free(msg);		return;	}	 	NLA_PUT_U8(msg, NL80211_ATTR_REG_INITIATOR, request->initiator);	if (request->alpha2[0] == '0' && request->alpha2[1] == '0')		NLA_PUT_U8(msg, NL80211_ATTR_REG_TYPE,			   NL80211_REGDOM_TYPE_WORLD);	else if (request->alpha2[0] == '9' && request->alpha2[1] == '9')		NLA_PUT_U8(msg, NL80211_ATTR_REG_TYPE,			   NL80211_REGDOM_TYPE_CUSTOM_WORLD);	else if ((request->alpha2[0] == '9' && request->alpha2[1] == '8') ||		 request->intersect)		NLA_PUT_U8(msg, NL80211_ATTR_REG_TYPE,			   NL80211_REGDOM_TYPE_INTERSECTION);	else {		NLA_PUT_U8(msg, NL80211_ATTR_REG_TYPE,			   NL80211_REGDOM_TYPE_COUNTRY);		NLA_PUT_STRING(msg, NL80211_ATTR_REG_ALPHA2, request->alpha2);	}	if (wiphy_idx_valid(request->wiphy_idx))		NLA_PUT_U32(msg, NL80211_ATTR_WIPHY, request->wiphy_idx);	if (genlmsg_end(msg, hdr) < 0) {		nlmsg_free(msg);		return;	}	rcu_read_lock();	genlmsg_multicast_allns(msg, 0, nl80211_regulatory_mcgrp.id,				GFP_ATOMIC);	rcu_read_unlock();	return;nla_put_failure:	genlmsg_cancel(msg, hdr);	nlmsg_free(msg);}",6586
680,3420,CVE-2017-15128,26,"static int hugetlb_sysfs_add_hstate(struct hstate *h, struct kobject *parent,				    struct kobject **hstate_kobjs,				    const struct attribute_group *hstate_attr_group){	int retval;	int hi = hstate_index(h);	hstate_kobjs[hi] = kobject_create_and_add(h->name, parent);	if (!hstate_kobjs[hi])		return -ENOMEM;	retval = sysfs_create_group(hstate_kobjs[hi], hstate_attr_group);	if (retval)		kobject_put(hstate_kobjs[hi]);	return retval;}",26180
659,1038,CVE-2013-4588,26,"static int ip_vs_svc_unhash(struct ip_vs_service *svc){	if (!(svc->flags & IP_VS_SVC_F_HASHED)) {		pr_err(""%s(): request for unhash flagged, called from %pF\n"",		       __func__, __builtin_return_address(0));		return 0;	}	if (svc->fwmark == 0) {		 		list_del(&svc->s_list);	} else {		 		list_del(&svc->f_list);	}	svc->flags &= ~IP_VS_SVC_F_HASHED;	atomic_dec(&svc->refcnt);	return 1;}",7635
724,3988,CVE-2017-7376,26,"xmlURIUnescapeString(const char *str, int len, char *target) { char *ret, *out; const char *in; if (str == NULL) return(NULL); if (len <= 0) len = strlen(str); if (len < 0) return(NULL); if (target == NULL) {	ret = (char *) xmlMallocAtomic(len + 1); if (ret == NULL) {            xmlURIErrMemory(""unescaping URI value\n""); return(NULL); } } else	ret = target;    in = str;    out = ret; while(len > 0) { if ((len > 2) && (*in == '%') && (is_hex(in[1])) && (is_hex(in[2]))) {	    in++; if ((*in >= '0') && (*in <= '9')) *out = (*in - '0'); else if ((*in >= 'a') && (*in <= 'f')) *out = (*in - 'a') + 10; else if ((*in >= 'A') && (*in <= 'F')) *out = (*in - 'A') + 10;	    in++; if ((*in >= '0') && (*in <= '9')) *out = *out * 16 + (*in - '0'); else if ((*in >= 'a') && (*in <= 'f')) *out = *out * 16 + (*in - 'a') + 10; else if ((*in >= 'A') && (*in <= 'F')) *out = *out * 16 + (*in - 'A') + 10;	    in++;	    len -= 3;	    out++; } else { *out++ = *in++;	    len--; } } *out = 0; return(ret);}",30808
383,3111,CVE-2016-10012,26,"send_rexec_state(int fd, struct sshbuf *conf){	struct sshbuf *m;	int r;	debug3(""%s: entering fd = %d config len %zu"", __func__, fd,	    sshbuf_len(conf));	 	if ((m = sshbuf_new()) == NULL)		fatal(""%s: sshbuf_new failed"", __func__);	if ((r = sshbuf_put_stringb(m, conf)) != 0)		fatal(""%s: buffer error: %s"", __func__, ssh_err(r));	if (ssh_msg_send(fd, 0, m) == -1)		fatal(""%s: ssh_msg_send failed"", __func__);	sshbuf_free(m);	debug3(""%s: done"", __func__);}",22629
822,861,CVE-2013-6381,26,"static int qeth_halt_channels(struct qeth_card *card){	int rc1 = 0, rc2 = 0, rc3 = 0;	QETH_CARD_TEXT(card, 3, ""haltchs"");	rc1 = qeth_halt_channel(&card->read);	rc2 = qeth_halt_channel(&card->write);	rc3 = qeth_halt_channel(&card->data);	if (rc1)		return rc1;	if (rc2)		return rc2;	return rc3;}",7290
907,3348,CVE-2017-1000418,26,static void free_gauss(void) {    _WM_Lock(&gauss_lock);    free(gauss_table);    gauss_table = NULL;    _WM_Unlock(&gauss_lock);},25628
619,4048,CVE-2012-2127,26, void pid_ns_release_proc(struct pid_namespace *ns) {	mntput(ns->proc_mnt); },30947
151,2165,CVE-2016-4302,26,"lzss_emit_literal(struct rar *rar, int literal){  *lzss_current_pointer(&rar->lzss) = literal;  rar->lzss.position++;}",17073
63,3383,CVE-2017-18193,26,"static struct extent_node *__attach_extent_node(struct f2fs_sb_info *sbi,				struct extent_tree *et, struct extent_info *ei,				struct rb_node *parent, struct rb_node **p){	struct extent_node *en;	en = kmem_cache_alloc(extent_node_slab, GFP_ATOMIC);	if (!en)		return NULL;	en->ei = *ei;	INIT_LIST_HEAD(&en->list);	en->et = et;	rb_link_node(&en->rb_node, parent, p);	rb_insert_color(&en->rb_node, &et->root);	atomic_inc(&et->node_cnt);	atomic_inc(&sbi->total_ext_node);	return en;}",26061
88,841,CVE-2013-6381,26,"int qeth_do_send_packet_fast(struct qeth_card *card,		struct qeth_qdio_out_q *queue, struct sk_buff *skb,		struct qeth_hdr *hdr, int elements_needed,		int offset, int hd_len){	struct qeth_qdio_out_buffer *buffer;	int index;	 	while (atomic_cmpxchg(&queue->state, QETH_OUT_Q_UNLOCKED,			      QETH_OUT_Q_LOCKED) != QETH_OUT_Q_UNLOCKED);	 	index = queue->next_buf_to_fill;	buffer = queue->bufs[queue->next_buf_to_fill];	 	if (atomic_read(&buffer->state) != QETH_QDIO_BUF_EMPTY)		goto out;	queue->next_buf_to_fill = (queue->next_buf_to_fill + 1) %					  QDIO_MAX_BUFFERS_PER_Q;	atomic_set(&queue->state, QETH_OUT_Q_UNLOCKED);	qeth_fill_buffer(queue, buffer, skb, hdr, offset, hd_len);	qeth_flush_buffers(queue, index, 1);	return 0;out:	atomic_set(&queue->state, QETH_OUT_Q_UNLOCKED);	return -EBUSY;}",7270
511,2009,CVE-2016-4998,26,"compat_find_calc_match(struct xt_entry_match *m,		       const char *name,		       const struct ip6t_ip6 *ipv6,		       int *size){	struct xt_match *match;	match = xt_request_find_match(NFPROTO_IPV6, m->u.user.name,				      m->u.user.revision);	if (IS_ERR(match)) {		duprintf(""compat_check_calc_match: `%s' not found\n"",			 m->u.user.name);		return PTR_ERR(match);	}	m->u.kernel.match = match;	*size += xt_compat_match_offset(match);	return 0;}",16575
100,538,CVE-2012-3400,26,static void udf_free_partition(struct udf_part_map *map){	int i;	struct udf_meta_data *mdata;	if (map->s_partition_flags & UDF_PART_FLAG_UNALLOC_TABLE)		iput(map->s_uspace.s_table);	if (map->s_partition_flags & UDF_PART_FLAG_FREED_TABLE)		iput(map->s_fspace.s_table);	if (map->s_partition_flags & UDF_PART_FLAG_UNALLOC_BITMAP)		udf_sb_free_bitmap(map->s_uspace.s_bitmap);	if (map->s_partition_flags & UDF_PART_FLAG_FREED_BITMAP)		udf_sb_free_bitmap(map->s_fspace.s_bitmap);	if (map->s_partition_type == UDF_SPARABLE_MAP15)		for (i = 0; i < 4; i++)			brelse(map->s_type_specific.s_sparing.s_spar_map[i]);	else if (map->s_partition_type == UDF_METADATA_MAP25) {		mdata = &map->s_type_specific.s_metadata;		iput(mdata->s_metadata_fe);		mdata->s_metadata_fe = NULL;		iput(mdata->s_mirror_fe);		mdata->s_mirror_fe = NULL;		iput(mdata->s_bitmap_fe);		mdata->s_bitmap_fe = NULL;	}},3123
958,1491,CVE-2014-3184,26,static void lg_remove(struct hid_device *hdev){	struct lg_drv_data *drv_data = hid_get_drvdata(hdev);	if (drv_data->quirks & LG_FF4)		lg4ff_deinit(hdev);	hid_hw_stop(hdev);	kfree(drv_data);},11486
45,1040,CVE-2013-4588,26,ip_vs_use_count_inc(void){	return try_module_get(THIS_MODULE);},7637
77,1609,CVE-2015-5156,26,static void *mergeable_ctx_to_buf_address(unsigned long mrg_ctx){	return (void *)(mrg_ctx & -MERGEABLE_BUFFER_ALIGN);},13466
1007,563,CVE-2012-1571,26,cdf_tole4(int sv){	return CDF_TOLE4(sv);},3849
9,173,CVE-2019-11360,26,"int add_argv(const char *what, int quoted){	DEBUGP(""add_argv: %s\n"", what);	if (what && newargc + 1 < ARRAY_SIZE(newargv)) {		newargv[newargc] = strdup(what);		newargvattr[newargc] = quoted;		newargv[++newargc] = NULL;		return 1;	} else {		xtables_error(PARAMETER_PROBLEM,			      ""Parser cannot handle more arguments\n"");	}}",765
678,1605,CVE-2015-5156,26,"static void free_unused_bufs(struct virtnet_info *vi){	void *buf;	int i;	for (i = 0; i < vi->max_queue_pairs; i++) {		struct virtqueue *vq = vi->sq[i].vq;		while ((buf = virtqueue_detach_unused_buf(vq)) != NULL)			dev_kfree_skb(buf);	}	for (i = 0; i < vi->max_queue_pairs; i++) {		struct virtqueue *vq = vi->rq[i].vq;		while ((buf = virtqueue_detach_unused_buf(vq)) != NULL) {			if (vi->mergeable_rx_bufs) {				unsigned long ctx = (unsigned long)buf;				void *base = mergeable_ctx_to_buf_address(ctx);				put_page(virt_to_head_page(base));			} else if (vi->big_packets) {				give_pages(&vi->rq[i], buf);			} else {				dev_kfree_skb(buf);			}		}	}}",13462
339,1604,CVE-2015-5156,26,static void free_receive_page_frags(struct virtnet_info *vi){	int i;	for (i = 0; i < vi->max_queue_pairs; i++)		if (vi->rq[i].alloc_frag.page)			put_page(vi->rq[i].alloc_frag.page);},13461
57,3562,CVE-2018-20855,26,"static void set_reg_data_seg(struct mlx5_wqe_data_seg *dseg,			     struct mlx5_ib_mr *mr,			     struct mlx5_ib_pd *pd){	int bcount = mr->desc_size * mr->ndescs;	dseg->addr = cpu_to_be64(mr->desc_map);	dseg->byte_count = cpu_to_be32(ALIGN(bcount, 64));	dseg->lkey = cpu_to_be32(pd->ibpd.local_dma_lkey);}",27590
592,32,CVE-2015-6806,26,"PrintStart(){  curr->w_pdisplay = 0;     display = curr->w_lastdisp;  if (!(display && curr == D_fore && (printcmd || D_PO)))    for (display = displays; display; display = display->d_next)      if (curr == D_fore && (printcmd || D_PO))        break;  if (!display)    {      struct canvas *cv;      for (cv = curr->w_layer.l_cvlist; cv; cv = cv->c_lnext)	{	  display = cv->c_display;	  if (printcmd || D_PO)	    break;	}      if (!cv)	{	  display = displays;	  if (!display || display->d_next || !(printcmd || D_PO))	    return;	}    }  curr->w_pdisplay = display;  curr->w_stringp = curr->w_string;  curr->w_state = PRIN;  if (printcmd && curr->w_pdisplay->d_printfd < 0)    curr->w_pdisplay->d_printfd = printpipe(curr, printcmd);}",253
155,975,CVE-2013-4591,26,"static void nfs4_proc_commit_setup(struct nfs_commit_data *data, struct rpc_message *msg){	struct nfs_server *server = NFS_SERVER(data->inode);	if (data->commit_done_cb == NULL)		data->commit_done_cb = nfs4_commit_done_cb;	data->res.server = server;	msg->rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_COMMIT];	nfs41_init_sequence(&data->args.seq_args, &data->res.seq_res, 1);}",7572
962,3878,CVE-2017-5009,26,static int IsErrorStatusCode(int status_code) {  return status_code >= 400;},29908
984,624,CVE-2011-3353,26,"struct fuse_req *fuse_get_req_nofail(struct fuse_conn *fc, struct file *file){	struct fuse_req *req;	atomic_inc(&fc->num_waiting);	wait_event(fc->blocked_waitq, !fc->blocked);	req = fuse_request_alloc();	if (!req)		req = get_reserved_req(fc, file);	fuse_req_init_context(req);	req->waiting = 1;	return req;}",5597
847,3978,CVE-2016-1503,26,route_netmask(int ip_in){   int p = ntohl(ip_in); int t; if (IN_CLASSA(p))		t = ~IN_CLASSA_NET; else { if (IN_CLASSB(p))			t = ~IN_CLASSB_NET; else { if (IN_CLASSC(p))				t = ~IN_CLASSC_NET; else				t = 0; } } while (t & p)		t >>= 1; return (htonl(~t));},30686
283,4,CVE-2013-6420,26,"PHP_FUNCTION(openssl_error_string){	char buf[512];	unsigned long val;	if (zend_parse_parameters_none() == FAILURE) {		return;	}	val = ERR_get_error();	if (val) {		RETURN_STRING(ERR_error_string(val, buf), 1);	} else {		RETURN_FALSE;	}}",29
86,576,CVE-2011-3359,26,"void b43_dma_free(struct b43_wldev *dev){	struct b43_dma *dma;	if (b43_using_pio_transfers(dev))		return;	dma = &dev->dma;	destroy_ring(dma, rx_ring);	destroy_ring(dma, tx_ring_AC_BK);	destroy_ring(dma, tx_ring_AC_BE);	destroy_ring(dma, tx_ring_AC_VI);	destroy_ring(dma, tx_ring_AC_VO);	destroy_ring(dma, tx_ring_mcast);}",5549
802,2743,CVE-2017-12876,26,"static inline void ModulateLCHab(const double percent_luma,  const double percent_chroma,const double percent_hue,double *red,  double *green,double *blue){  double    hue,    luma,    chroma;     ConvertRGBToLCHab(*red,*green,*blue,&luma,&chroma,&hue);  luma*=0.01*percent_luma;  chroma*=0.01*percent_chroma;  hue+=fmod((percent_hue-100.0),200.0)/200.0;  ConvertLCHabToRGB(luma,chroma,hue,red,green,blue);}",20292
219,3269,CVE-2018-12326,26,"int main(int argc, char **argv) {    int firstarg;    config.hostip = sdsnew(""127.0.0.1"");    config.hostport = 6379;    config.hostsocket = NULL;    config.repeat = 1;    config.interval = 0;    config.dbnum = 0;    config.interactive = 0;    config.shutdown = 0;    config.monitor_mode = 0;    config.pubsub_mode = 0;    config.latency_mode = 0;    config.latency_dist_mode = 0;    config.latency_history = 0;    config.lru_test_mode = 0;    config.lru_test_sample_size = 0;    config.cluster_mode = 0;    config.slave_mode = 0;    config.getrdb_mode = 0;    config.stat_mode = 0;    config.scan_mode = 0;    config.intrinsic_latency_mode = 0;    config.pattern = NULL;    config.rdb_filename = NULL;    config.pipe_mode = 0;    config.pipe_timeout = REDIS_CLI_DEFAULT_PIPE_TIMEOUT;    config.bigkeys = 0;    config.hotkeys = 0;    config.stdinarg = 0;    config.auth = NULL;    config.eval = NULL;    config.eval_ldb = 0;    config.eval_ldb_end = 0;    config.eval_ldb_sync = 0;    config.enable_ldb_on_eval = 0;    config.last_cmd_type = -1;    pref.hints = 1;    spectrum_palette = spectrum_palette_color;    spectrum_palette_size = spectrum_palette_color_size;    if (!isatty(fileno(stdout)) && (getenv(""FAKETTY"") == NULL))        config.output = OUTPUT_RAW;    else        config.output = OUTPUT_STANDARD;    config.mb_delim = sdsnew(""\n"");    firstarg = parseOptions(argc,argv);    argc -= firstarg;    argv += firstarg;         if (config.latency_mode) {        if (cliConnect(0) == REDIS_ERR) exit(1);        latencyMode();    }         if (config.latency_dist_mode) {        if (cliConnect(0) == REDIS_ERR) exit(1);        latencyDistMode();    }         if (config.slave_mode) {        if (cliConnect(0) == REDIS_ERR) exit(1);        slaveMode();    }         if (config.getrdb_mode) {        if (cliConnect(0) == REDIS_ERR) exit(1);        getRDB();    }         if (config.pipe_mode) {        if (cliConnect(0) == REDIS_ERR) exit(1);        pipeMode();    }         if (config.bigkeys) {        if (cliConnect(0) == REDIS_ERR) exit(1);        findBigKeys();    }         if (config.hotkeys) {        if (cliConnect(0) == REDIS_ERR) exit(1);        findHotKeys();    }         if (config.stat_mode) {        if (cliConnect(0) == REDIS_ERR) exit(1);        if (config.interval == 0) config.interval = 1000000;        statMode();    }         if (config.scan_mode) {        if (cliConnect(0) == REDIS_ERR) exit(1);        scanMode();    }         if (config.lru_test_mode) {        if (cliConnect(0) == REDIS_ERR) exit(1);        LRUTestMode();    }         if (config.intrinsic_latency_mode) intrinsicLatencyMode();         if (argc == 0 && !config.eval) {                 signal(SIGPIPE, SIG_IGN);                 cliConnect(0);        repl();    }         if (cliConnect(0) != REDIS_OK) exit(1);    if (config.eval) {        return evalMode(argc,argv);    } else {        return noninteractive(argc,convertToSds(argc,argv));    }}",25096
505,2215,CVE-2016-2385,26,char get_header_code(struct hdr_field *hf){   switch(hf->type){      case HDR_CALLID_T:	 return 'i';      case HDR_CONTACT_T:	 return 'm';      case HDR_CONTENTLENGTH_T:	 return 'l';      case HDR_CONTENTTYPE_T:	 return 'c';      case HDR_FROM_T:	 return 'f';      case HDR_SUBJECT_T:	 return 's';      case HDR_SUPPORTED_T:	 return 'k';      case HDR_TO_T:	 return 't';      case HDR_VIA_T:	 return 'v';      case HDR_ROUTE_T:	 return 'r';      case HDR_RECORDROUTE_T:	 return 'R';      case HDR_ALLOW_T:	 return 'a';      case HDR_ACCEPT_T:	 return 'A';      case HDR_CSEQ_T:	 return 'S';      case HDR_REFER_TO_T:	 return 'o';      case HDR_RPID_T:	 return 'p';      case HDR_EXPIRES_T:	 return 'P';      case HDR_AUTHORIZATION_T:	 return 'H';      case HDR_PROXYAUTH_T:	 return 'z';      default:	 return 'x';   }   return 'x';},17574
2,3068,CVE-2016-10154,26,"SMBencrypt(unsigned char *passwd, const unsigned char *c8, unsigned char *p24){	int rc;	unsigned char p14[14], p16[16], p21[21];	memset(p14, '\0', 14);	memset(p16, '\0', 16);	memset(p21, '\0', 21);	memcpy(p14, passwd, 14);	rc = E_P16(p14, p16);	if (rc)		return rc;	memcpy(p21, p16, 16);	rc = E_P24(p21, c8, p24);	return rc;}",22485
467,1039,CVE-2013-4588,26,ip_vs_use_count_dec(void){	module_put(THIS_MODULE);},7636
968,3776,CVE-2013-6640,26,  MockAffiliationFetcherDelegate() {},29349
638,322,CVE-2010-2527,26,"  event_font_change( int  delta )  {    int      num_indices;    if ( status.font_index + delta >= handle->num_fonts ||         status.font_index + delta < 0 )      return;    status.font_index += delta;    FTDemo_Set_Current_Font( handle, handle->fonts[status.font_index] );    FTDemo_Set_Current_Charsize( handle, status.ptsize, status.res );    FTDemo_Update_Current_Flags( handle );    num_indices = handle->current_font->num_indices;    if ( status.Num >= num_indices )      status.Num = num_indices - 1;  }",1801
806,338,CVE-2010-2527,26,"  event_gamma_change( double delta )  {    int i;    double gamma_inv;    status.gamma += delta;    if ( status.gamma > 3.0 )      status.gamma = 3.0;    else if ( status.gamma < 0.1 )      status.gamma = 0.1;    sprintf( status.header_buffer, ""gamma changed to %.1f"", status.gamma );    status.header = status.header_buffer;    gamma_inv = 1.0f / status.gamma;    for ( i = 0; i < 256; i++ )      status.gamma_ramp[i] = (FT_Byte)( pow( (double)i / 255.0f, gamma_inv )                                        * 255.0f );  }",1817
614,1761,CVE-2016-9793,26,"static inline void __sock_kfree_s(struct sock *sk, void *mem, int size,				  const int nullify){	if (WARN_ON_ONCE(!mem))		return;	if (nullify)		kzfree(mem);	else		kfree(mem);	atomic_sub(size, &sk->sk_omem_alloc);}",15045
142,745,CVE-2010-4650,26,static void fuse_vma_close(struct vm_area_struct *vma){	filemap_write_and_wait(vma->vm_file->f_mapping);},7029
795,1562,CVE-2014-0063,26,"DecodeSpecial(int field, char *lowtoken, int *val){	int			type;	datetkn    *tp;	if (datecache[field] != NULL &&		strncmp(lowtoken, datecache[field]->token, TOKMAXLEN) == 0)		tp = datecache[field];	else	{		tp = NULL;		if (!tp)			tp = datebsearch(lowtoken, datetktbl, szdatetktbl);	}	datecache[field] = tp;	if (tp == NULL)	{		type = UNKNOWN_FIELD;		*val = 0;	}	else	{		type = tp->type;		switch (type)		{			case TZ:			case DTZ:			case DTZMOD:				*val = FROMVAL(tp);				break;			default:				*val = tp->value;				break;		}	}	return type;}	 ",12308
960,4028,CVE-2016-1621,26," void SetTopUnavailable() {    mbptr_->up_available = 0; for (int p = 0; p < num_planes_; p++)      memset(&data_ptr_[p][-1 - stride_], 127, block_size_ + 2); }",30859
981,3934,CVE-2016-1691,26,  UsbChooserContextTest() {},30368
704,3847,CVE-2017-5122,26,  PanelWindowResizerTest() {},29825
673,1517,CVE-2014-3181,26,"static int param_set_scroll_speed(const char *val, struct kernel_param *kp) {	unsigned long speed;	if (!val || kstrtoul(val, 0, &speed) || speed > 63)		return -EINVAL;	scroll_speed = speed;	return 0;}",11512
301,852,CVE-2013-6381,26,static inline int qeth_get_initial_mtu_for_card(struct qeth_card *card){	switch (card->info.type) {	case QETH_CARD_TYPE_UNKNOWN:		return 1500;	case QETH_CARD_TYPE_IQD:		return card->info.max_mtu;	case QETH_CARD_TYPE_OSD:		switch (card->info.link_type) {		case QETH_LINK_TYPE_HSTR:		case QETH_LINK_TYPE_LANE_TR:			return 2000;		default:			return card->options.layer2 ? 1500 : 1492;		}	case QETH_CARD_TYPE_OSM:	case QETH_CARD_TYPE_OSX:		return card->options.layer2 ? 1500 : 1492;	default:		return 1500;	}},7281
615,1694,CVE-2015-3331,26,static void lrw_aesni_exit_tfm(struct crypto_tfm *tfm){	struct aesni_lrw_ctx *ctx = crypto_tfm_ctx(tfm);	lrw_free_table(&ctx->lrw_table);},13605
554,3393,CVE-2017-18193,26,"void f2fs_destroy_extent_tree(struct inode *inode){	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);	struct extent_tree *et = F2FS_I(inode)->extent_tree;	unsigned int node_cnt = 0;	if (!et)		return;	if (inode->i_nlink && !is_bad_inode(inode) &&					atomic_read(&et->node_cnt)) {		mutex_lock(&sbi->extent_tree_lock);		list_add_tail(&et->list, &sbi->zombie_list);		atomic_inc(&sbi->total_zombie_tree);		mutex_unlock(&sbi->extent_tree_lock);		return;	}	 	node_cnt = f2fs_destroy_extent_node(inode);	 	mutex_lock(&sbi->extent_tree_lock);	f2fs_bug_on(sbi, atomic_read(&et->node_cnt));	radix_tree_delete(&sbi->extent_tree_root, inode->i_ino);	kmem_cache_free(extent_tree_slab, et);	atomic_dec(&sbi->total_ext_tree);	mutex_unlock(&sbi->extent_tree_lock);	F2FS_I(inode)->extent_tree = NULL;	trace_f2fs_destroy_extent_tree(inode, node_cnt);}",26071
261,926,CVE-2013-4591,26,void __nfs4_read_done_cb(struct nfs_read_data *data){	nfs_invalidate_atime(data->header->inode);},7523
794,166,CVE-2013-2236,26,"msg_free (struct msg *msg){  if (msg->s)    stream_free (msg->s);  XFREE (MTYPE_OSPF_API_MSG, msg);}",721
1011,4004,CVE-2016-1621,26,void destroy_rate_histogram(struct rate_hist *hist) { if (hist) {    free(hist->pts);    free(hist->sz);    free(hist); }},30835
333,69,CVE-2019-15937,26,static int *rpc_add_credentials(int *p){	int hl;	int hostnamelen = 0;	 	hl = (hostnamelen + 3) & ~3;	 	*p++ = htonl(1);		 	*p++ = htonl(hl+20);		 	*p++ = htonl(0);		 	*p++ = htonl(hostnamelen);	 	if (hostnamelen & 3)		*(p + hostnamelen / 4) = 0;  	   	p += hl / 4;	*p++ = 0;			 	*p++ = 0;			 	*p++ = 0;			 	 	*p++ = 0;			 	*p++ = 0;			 	return p;},300
16,2514,CVE-2016-1583,26,"int cpuset_cpumask_can_shrink(const struct cpumask *cur,			      const struct cpumask *trial){	int ret = 1, trial_cpus;	struct dl_bw *cur_dl_b;	unsigned long flags;	if (!cpumask_weight(cur))		return ret;	rcu_read_lock_sched();	cur_dl_b = dl_bw_of(cpumask_any(cur));	trial_cpus = cpumask_weight(trial);	raw_spin_lock_irqsave(&cur_dl_b->lock, flags);	if (cur_dl_b->bw != -1 &&	    cur_dl_b->bw * trial_cpus < cur_dl_b->total_bw)		ret = 0;	raw_spin_unlock_irqrestore(&cur_dl_b->lock, flags);	rcu_read_unlock_sched();	return ret;}",18063
687,1678,CVE-2015-4036,26,static int vhost_scsi_write_pending_status(struct se_cmd *se_cmd){	return 0;},13544
122,2177,CVE-2016-4302,26,rar_fls(unsigned int word){  word |= (word >>  1);  word |= (word >>  2);  word |= (word >>  4);  word |= (word >>  8);  word |= (word >> 16);  return word - (word >> 1);},17085
174,1903,CVE-2016-7115,26,"static void list_add_connection(struct mt_connection *conn) {	DL_APPEND(connections_head, conn);}",15879
862,544,CVE-2012-3400,26,"static void udf_open_lvid(struct super_block *sb){	struct udf_sb_info *sbi = UDF_SB(sb);	struct buffer_head *bh = sbi->s_lvid_bh;	struct logicalVolIntegrityDesc *lvid;	struct logicalVolIntegrityDescImpUse *lvidiu;	if (!bh)		return;	mutex_lock(&sbi->s_alloc_mutex);	lvid = (struct logicalVolIntegrityDesc *)bh->b_data;	lvidiu = udf_sb_lvidiu(sbi);	lvidiu->impIdent.identSuffix[0] = UDF_OS_CLASS_UNIX;	lvidiu->impIdent.identSuffix[1] = UDF_OS_ID_LINUX;	udf_time_to_disk_stamp(&lvid->recordingDateAndTime,				CURRENT_TIME);	lvid->integrityType = cpu_to_le32(LVID_INTEGRITY_TYPE_OPEN);	lvid->descTag.descCRC = cpu_to_le16(		crc_itu_t(0, (char *)lvid + sizeof(struct tag),			le16_to_cpu(lvid->descTag.descCRCLength)));	lvid->descTag.tagChecksum = udf_tag_checksum(&lvid->descTag);	mark_buffer_dirty(bh);	sbi->s_lvid_dirty = 0;	mutex_unlock(&sbi->s_alloc_mutex);}",3129
676,1744,CVE-2015-1333,26,static inline void *keyring_key_to_ptr(struct key *key){	if (key->type == &key_type_keyring)		return (void *)((unsigned long)key | KEYRING_PTR_SUBTYPE);	return key;},14049
432,1067,CVE-2013-4263,26,"static inline void blur(int *dst, int dst_step, const int *src, int src_step,                        int len, int radius){         const int length = radius*2 + 1;    const int inv = ((1<<16) + length/2)/length;    int x, sum = 0;    for (x = 0; x < radius; x++)        sum += src[x*src_step]<<1;    sum += src[radius*src_step];    for (x = 0; x <= radius; x++) {        sum += src[(radius+x)*src_step] - src[(radius-x)*src_step];        dst[x*dst_step] = (sum*inv + (1<<15))>>16;    }    for (; x < len-radius; x++) {        sum += src[(radius+x)*src_step] - src[(x-radius-1)*src_step];        dst[x*dst_step] = (sum*inv + (1<<15))>>16;    }    for (; x < len; x++) {        sum += src[(2*len-radius-x-1)*src_step] - src[(x-radius-1)*src_step];        dst[x*dst_step] = (sum*inv + (1<<15))>>16;    }}",7874
624,1442,CVE-2014-4502,26,"void _cg_memcpy(void *dest, const void *src, unsigned int n, const char *file, const char *func, const int line){	if (unlikely(n < 1 || n > (1ul << 31))) {		applog(LOG_ERR, ""ERR: Asked to memcpy %u bytes from %s %s():%d"",			      n, file, func, line);		return;	}	memcpy(dest, src, n);}",10888
292,1737,CVE-2015-1333,26,"static int keyring_detect_cycle_iterator(const void *object,					 void *iterator_data){	struct keyring_search_context *ctx = iterator_data;	const struct key *key = keyring_ptr_to_key(object);	kenter(""{%d}"", key->serial);	 	if (key != ctx->match_data.raw_data)		return 0;	ctx->result = ERR_PTR(-EDEADLK);	return 1;}",14042
148,3894,CVE-2016-5199,26,  OptimizationHintsComponentInstallerTest() {},29952
24,1697,CVE-2015-3331,26,"static int rfc4106_set_authsize(struct crypto_aead *parent,				unsigned int authsize){	struct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(parent);	struct crypto_aead *cryptd_child = cryptd_aead_child(ctx->cryptd_tfm);	switch (authsize) {	case 8:	case 12:	case 16:		break;	default:		return -EINVAL;	}	crypto_aead_crt(parent)->authsize = authsize;	crypto_aead_crt(cryptd_child)->authsize = authsize;	return 0;}",13608
139,1503,CVE-2014-3183,26,"static void logi_dj_recv_add_djhid_device(struct dj_receiver_dev *djrcv_dev,					  struct dj_report *dj_report){	 	struct hid_device *djrcv_hdev = djrcv_dev->hdev;	struct usb_interface *intf = to_usb_interface(djrcv_hdev->dev.parent);	struct usb_device *usbdev = interface_to_usbdev(intf);	struct hid_device *dj_hiddev;	struct dj_device *dj_dev;	 	unsigned char tmpstr[3];	if (dj_report->report_params[DEVICE_PAIRED_PARAM_SPFUNCTION] &	    SPFUNCTION_DEVICE_LIST_EMPTY) {		dbg_hid(""%s: device list is empty\n"", __func__);		djrcv_dev->querying_devices = false;		return;	}	if ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||	    (dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {		dev_err(&djrcv_hdev->dev, ""%s: invalid device index:%d\n"",			__func__, dj_report->device_index);		return;	}	if (djrcv_dev->paired_dj_devices[dj_report->device_index]) {		 		dbg_hid(""%s: device is already known\n"", __func__);		return;	}	dj_hiddev = hid_allocate_device();	if (IS_ERR(dj_hiddev)) {		dev_err(&djrcv_hdev->dev, ""%s: hid_allocate_device failed\n"",			__func__);		return;	}	dj_hiddev->ll_driver = &logi_dj_ll_driver;	dj_hiddev->dev.parent = &djrcv_hdev->dev;	dj_hiddev->bus = BUS_USB;	dj_hiddev->vendor = le16_to_cpu(usbdev->descriptor.idVendor);	dj_hiddev->product = le16_to_cpu(usbdev->descriptor.idProduct);	snprintf(dj_hiddev->name, sizeof(dj_hiddev->name),		""Logitech Unifying Device. Wireless PID:%02x%02x"",		dj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_MSB],		dj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_LSB]);	usb_make_path(usbdev, dj_hiddev->phys, sizeof(dj_hiddev->phys));	snprintf(tmpstr, sizeof(tmpstr), "":%d"", dj_report->device_index);	strlcat(dj_hiddev->phys, tmpstr, sizeof(dj_hiddev->phys));	dj_dev = kzalloc(sizeof(struct dj_device), GFP_KERNEL);	if (!dj_dev) {		dev_err(&djrcv_hdev->dev, ""%s: failed allocating dj_device\n"",			__func__);		goto dj_device_allocate_fail;	}	dj_dev->reports_supported = get_unaligned_le32(		dj_report->report_params + DEVICE_PAIRED_RF_REPORT_TYPE);	dj_dev->hdev = dj_hiddev;	dj_dev->dj_receiver_dev = djrcv_dev;	dj_dev->device_index = dj_report->device_index;	dj_hiddev->driver_data = dj_dev;	djrcv_dev->paired_dj_devices[dj_report->device_index] = dj_dev;	if (hid_add_device(dj_hiddev)) {		dev_err(&djrcv_hdev->dev, ""%s: failed adding dj_device\n"",			__func__);		goto hid_add_device_fail;	}	return;hid_add_device_fail:	djrcv_dev->paired_dj_devices[dj_report->device_index] = NULL;	kfree(dj_dev);dj_device_allocate_fail:	hid_destroy_device(dj_hiddev);}",11498
276,3057,CVE-2016-10192,26,"int main(int argc, char **argv){    struct sigaction sigact = { { 0 } };    int cfg_parsed;    int ret = EXIT_FAILURE;    init_dynload();    config.filename = av_strdup(""/etc/ffserver.conf"");    parse_loglevel(argc, argv, options);    av_register_all();    avformat_network_init();    show_banner(argc, argv, options);    my_program_name = argv[0];    parse_options(NULL, argc, argv, options, NULL);    unsetenv(""http_proxy"");                  av_lfg_init(&random_state, av_get_random_seed());    sigact.sa_handler = handle_child_exit;    sigact.sa_flags = SA_NOCLDSTOP | SA_RESTART;    sigaction(SIGCHLD, &sigact, 0);    if ((cfg_parsed = ffserver_parse_ffconfig(config.filename, &config)) < 0) {        fprintf(stderr, ""Error reading configuration file '%s': %s\n"",                config.filename, av_err2str(cfg_parsed));        goto bail;    }         if (config.logfilename[0] != '\0') {        if (!strcmp(config.logfilename, ""-""))            logfile = stdout;        else            logfile = fopen(config.logfilename, ""a"");        av_log_set_callback(http_av_log);    }    build_file_streams();    if (build_feed_streams() < 0) {        http_log(""Could not setup feed streams\n"");        goto bail;    }    compute_bandwidth();         signal(SIGPIPE, SIG_IGN);    if (http_server() < 0) {        http_log(""Could not start server\n"");        goto bail;    }    ret=EXIT_SUCCESS;bail:    av_freep (&config.filename);    avformat_network_deinit();    return ret;}",22457
885,3621,CVE-2017-18379,26,"nvmet_fc_fod_op_done(struct nvmet_fc_fcp_iod *fod){	struct nvmefc_tgt_fcp_req *fcpreq = fod->fcpreq;	struct nvmet_fc_tgtport *tgtport = fod->tgtport;	unsigned long flags;	int abort;	spin_lock_irqsave(&fod->flock, flags);	abort = fod->abort;	fod->writedataactive = false;	spin_unlock_irqrestore(&fod->flock, flags);	switch (fcpreq->op) {	case NVMET_FCOP_WRITEDATA:		if (__nvmet_fc_fod_op_abort(fod, abort))			return;		if (fcpreq->fcp_error ||		    fcpreq->transferred_length != fcpreq->transfer_length) {			spin_lock(&fod->flock);			fod->abort = true;			spin_unlock(&fod->flock);			nvmet_req_complete(&fod->req, NVME_SC_INTERNAL);			return;		}		fod->offset += fcpreq->transferred_length;		if (fod->offset != fod->total_length) {			spin_lock_irqsave(&fod->flock, flags);			fod->writedataactive = true;			spin_unlock_irqrestore(&fod->flock, flags);			 			nvmet_fc_transfer_fcp_data(tgtport, fod,						NVMET_FCOP_WRITEDATA);			return;		}		 		fod->req.execute(&fod->req);		break;	case NVMET_FCOP_READDATA:	case NVMET_FCOP_READDATA_RSP:		if (__nvmet_fc_fod_op_abort(fod, abort))			return;		if (fcpreq->fcp_error ||		    fcpreq->transferred_length != fcpreq->transfer_length) {			nvmet_fc_abort_op(tgtport, fod);			return;		}		 		if (fcpreq->op == NVMET_FCOP_READDATA_RSP) {			 			nvmet_fc_free_tgt_pgs(fod);			nvmet_fc_free_fcp_iod(fod->queue, fod);			return;		}		fod->offset += fcpreq->transferred_length;		if (fod->offset != fod->total_length) {			 			nvmet_fc_transfer_fcp_data(tgtport, fod,						NVMET_FCOP_READDATA);			return;		}		 		 		nvmet_fc_free_tgt_pgs(fod);		nvmet_fc_xmt_fcp_rsp(tgtport, fod);		break;	case NVMET_FCOP_RSP:		if (__nvmet_fc_fod_op_abort(fod, abort))			return;		nvmet_fc_free_fcp_iod(fod->queue, fod);		break;	default:		break;	}}",28077
837,2205,CVE-2016-3955,26,"static void usbip_dump_usb_device(struct usb_device *udev){	struct device *dev = &udev->dev;	int i;	dev_dbg(dev, ""       devnum(%d) devpath(%s) usb speed(%s)"",		udev->devnum, udev->devpath, usb_speed_string(udev->speed));	pr_debug(""tt %p, ttport %d\n"", udev->tt, udev->ttport);	dev_dbg(dev, ""                    "");	for (i = 0; i < 16; i++)		pr_debug("" %2u"", i);	pr_debug(""\n"");	dev_dbg(dev, ""       toggle0(IN) :"");	for (i = 0; i < 16; i++)		pr_debug("" %2u"", (udev->toggle[0] & (1 << i)) ? 1 : 0);	pr_debug(""\n"");	dev_dbg(dev, ""       toggle1(OUT):"");	for (i = 0; i < 16; i++)		pr_debug("" %2u"", (udev->toggle[1] & (1 << i)) ? 1 : 0);	pr_debug(""\n"");	dev_dbg(dev, ""       epmaxp_in   :"");	for (i = 0; i < 16; i++) {		if (udev->ep_in[i])			pr_debug("" %2u"",			    le16_to_cpu(udev->ep_in[i]->desc.wMaxPacketSize));	}	pr_debug(""\n"");	dev_dbg(dev, ""       epmaxp_out  :"");	for (i = 0; i < 16; i++) {		if (udev->ep_out[i])			pr_debug("" %2u"",			    le16_to_cpu(udev->ep_out[i]->desc.wMaxPacketSize));	}	pr_debug(""\n"");	dev_dbg(dev, ""parent %p, bus %p\n"", udev->parent, udev->bus);	dev_dbg(dev,		""descriptor %p, config %p, actconfig %p, rawdescriptors %p\n"",		&udev->descriptor, udev->config,		udev->actconfig, udev->rawdescriptors);	dev_dbg(dev, ""have_langid %d, string_langid %d\n"",		udev->have_langid, udev->string_langid);	dev_dbg(dev, ""maxchild %d\n"", udev->maxchild);}",17132
141,2209,CVE-2016-3955,26,"void usbip_pack_pdu(struct usbip_header *pdu, struct urb *urb, int cmd,		    int pack){	switch (cmd) {	case USBIP_CMD_SUBMIT:		usbip_pack_cmd_submit(pdu, urb, pack);		break;	case USBIP_RET_SUBMIT:		usbip_pack_ret_submit(pdu, urb, pack);		break;	default:		 		pr_err(""unknown command\n"");		break;	}}",17136
975,1956,CVE-2016-5400,26,"static int airspy_g_tuner(struct file *file, void *priv, struct v4l2_tuner *v){	int ret;	if (v->index == 0) {		strlcpy(v->name, ""AirSpy ADC"", sizeof(v->name));		v->type = V4L2_TUNER_ADC;		v->capability = V4L2_TUNER_CAP_1HZ | V4L2_TUNER_CAP_FREQ_BANDS;		v->rangelow  = bands[0].rangelow;		v->rangehigh = bands[0].rangehigh;		ret = 0;	} else if (v->index == 1) {		strlcpy(v->name, ""AirSpy RF"", sizeof(v->name));		v->type = V4L2_TUNER_RF;		v->capability = V4L2_TUNER_CAP_1HZ | V4L2_TUNER_CAP_FREQ_BANDS;		v->rangelow  = bands_rf[0].rangelow;		v->rangehigh = bands_rf[0].rangehigh;		ret = 0;	} else {		ret = -EINVAL;	}	return ret;}",16460
204,2323,CVE-2016-2324,26,"static void cherry_pick_list(struct commit_list *list, struct rev_info *revs){	struct commit_list *p;	int left_count = 0, right_count = 0;	int left_first;	struct patch_ids ids;	unsigned cherry_flag;	 	for (p = list; p; p = p->next) {		struct commit *commit = p->item;		unsigned flags = commit->object.flags;		if (flags & BOUNDARY)			;		else if (flags & SYMMETRIC_LEFT)			left_count++;		else			right_count++;	}	if (!left_count || !right_count)		return;	left_first = left_count < right_count;	init_patch_ids(&ids);	ids.diffopts.pathspec = revs->diffopt.pathspec;	 	for (p = list; p; p = p->next) {		struct commit *commit = p->item;		unsigned flags = commit->object.flags;		if (flags & BOUNDARY)			continue;		 		if (left_first != !!(flags & SYMMETRIC_LEFT))			continue;		commit->util = add_commit_patch_id(commit, &ids);	}	 	cherry_flag = revs->cherry_mark ? PATCHSAME : SHOWN;	 	for (p = list; p; p = p->next) {		struct commit *commit = p->item;		struct patch_id *id;		unsigned flags = commit->object.flags;		if (flags & BOUNDARY)			continue;		 		if (left_first == !!(flags & SYMMETRIC_LEFT))			continue;		 		id = has_commit_patch_id(commit, &ids);		if (!id)			continue;		id->seen = 1;		commit->object.flags |= cherry_flag;	}	 	for (p = list; p; p = p->next) {		struct commit *commit = p->item;		struct patch_id *ent;		ent = commit->util;		if (!ent)			continue;		if (ent->seen)			commit->object.flags |= cherry_flag;		commit->util = NULL;	}	free_patch_ids(&ids);}",17743
722,1916,CVE-2016-6187,26,"static void apparmor_cred_transfer(struct cred *new, const struct cred *old){	const struct aa_task_cxt *old_cxt = cred_cxt(old);	struct aa_task_cxt *new_cxt = cred_cxt(new);	aa_dup_task_context(new_cxt, old_cxt);}",16261
69,849,CVE-2013-6381,26,"const char *qeth_get_cardname_short(struct qeth_card *card){	if (card->info.guestlan) {		switch (card->info.type) {		case QETH_CARD_TYPE_OSD:			return ""Virt.NIC QDIO"";		case QETH_CARD_TYPE_IQD:			return ""Virt.NIC Hiper"";		case QETH_CARD_TYPE_OSM:			return ""Virt.NIC OSM"";		case QETH_CARD_TYPE_OSX:			return ""Virt.NIC OSX"";		default:			return ""unknown"";		}	} else {		switch (card->info.type) {		case QETH_CARD_TYPE_OSD:			switch (card->info.link_type) {			case QETH_LINK_TYPE_FAST_ETH:				return ""OSD_100"";			case QETH_LINK_TYPE_HSTR:				return ""HSTR"";			case QETH_LINK_TYPE_GBIT_ETH:				return ""OSD_1000"";			case QETH_LINK_TYPE_10GBIT_ETH:				return ""OSD_10GIG"";			case QETH_LINK_TYPE_LANE_ETH100:				return ""OSD_FE_LANE"";			case QETH_LINK_TYPE_LANE_TR:				return ""OSD_TR_LANE"";			case QETH_LINK_TYPE_LANE_ETH1000:				return ""OSD_GbE_LANE"";			case QETH_LINK_TYPE_LANE:				return ""OSD_ATM_LANE"";			default:				return ""OSD_Express"";			}		case QETH_CARD_TYPE_IQD:			return ""HiperSockets"";		case QETH_CARD_TYPE_OSN:			return ""OSN"";		case QETH_CARD_TYPE_OSM:			return ""OSM_1000"";		case QETH_CARD_TYPE_OSX:			return ""OSX_10GIG"";		default:			return ""unknown"";		}	}	return ""n/a"";}",7278
807,3435,CVE-2017-15128,26,"static void restore_reserve_on_error(struct hstate *h,			struct vm_area_struct *vma, unsigned long address,			struct page *page){	if (unlikely(PagePrivate(page))) {		long rc = vma_needs_reservation(h, vma, address);		if (unlikely(rc < 0)) {			 			ClearPagePrivate(page);		} else if (rc) {			rc = vma_add_reservation(h, vma, address);			if (unlikely(rc < 0))				 				ClearPagePrivate(page);		} else			vma_end_reservation(h, vma, address);	}}",26195
488,1804,CVE-2016-8658,26,"static int brcmf_cfg80211_request_ap_if(struct brcmf_if *ifp){	struct brcmf_mbss_ssid_le mbss_ssid_le;	int bsscfgidx;	int err;	memset(&mbss_ssid_le, 0, sizeof(mbss_ssid_le));	bsscfgidx = brcmf_get_first_free_bsscfgidx(ifp->drvr);	if (bsscfgidx < 0)		return bsscfgidx;	mbss_ssid_le.bsscfgidx = cpu_to_le32(bsscfgidx);	mbss_ssid_le.SSID_len = cpu_to_le32(5);	sprintf(mbss_ssid_le.SSID, ""ssid%d"" , bsscfgidx);	err = brcmf_fil_bsscfg_data_set(ifp, ""bsscfg:ssid"", &mbss_ssid_le,					sizeof(mbss_ssid_le));	if (err < 0)		brcmf_err(""setting ssid failed %d\n"", err);	return err;}",15452
46,20,CVE-2013-6712,26,"static void timelib_eat_until_separator(char **ptr){	while (strchr("" \t.,:;/-0123456789"", **ptr) == NULL) {		++*ptr;	}}",155
400,2101,CVE-2016-4303,26,iperf_get_test_socket_bufsize(struct iperf_test *ipt){    return ipt->settings->socket_bufsize;},17009
575,3140,CVE-2016-4796,26,"static void sycc_to_rgb(int offset, int upb, int y, int cb, int cr,	int *out_r, int *out_g, int *out_b){	int r, g, b;	cb -= offset; cr -= offset;	r = y + (int)(1.402 * (float)cr);	if(r < 0) r = 0; else if(r > upb) r = upb; *out_r = r;	g = y - (int)(0.344 * (float)cb + 0.714 * (float)cr);	if(g < 0) g = 0; else if(g > upb) g = upb; *out_g = g;	b = y + (int)(1.772 * (float)cb);	if(b < 0) b = 0; else if(b > upb) b = upb; *out_b = b;}",22827
737,2111,CVE-2016-4303,26,"iperf_new_test(){    struct iperf_test *test;    test = (struct iperf_test *) malloc(sizeof(struct iperf_test));    if (!test) {        i_errno = IENEWTEST;        return NULL;    }         memset(test, 0, sizeof(struct iperf_test));    test->settings = (struct iperf_settings *) malloc(sizeof(struct iperf_settings));    if (!test->settings) {        free(test);	i_errno = IENEWTEST;	return NULL;    }    memset(test->settings, 0, sizeof(struct iperf_settings));    return test;}",17019
782,300,CVE-2016-6835,26,"void vmxnet_tx_pkt_update_ip_checksums(struct VmxnetTxPkt *pkt){    int csum;    int ph_raw_csum;    assert(pkt);    int gso_type = pkt->virt_hdr.gso_type & ~VIRTIO_NET_HDR_GSO_ECN;    struct ip_header *ip_hdr;    if (VIRTIO_NET_HDR_GSO_TCPV4 != gso_type &&        VIRTIO_NET_HDR_GSO_UDP != gso_type) {        return;    }    ip_hdr = pkt->vec[VMXNET_TX_PKT_L3HDR_FRAG].iov_base;    if (pkt->payload_len + pkt->vec[VMXNET_TX_PKT_L3HDR_FRAG].iov_len >        ETH_MAX_IP_DGRAM_LEN) {        return;    }    ip_hdr->ip_len = cpu_to_be16(pkt->payload_len +        pkt->vec[VMXNET_TX_PKT_L3HDR_FRAG].iov_len);         ip_hdr->ip_sum = 0;    csum = net_raw_checksum((int *)ip_hdr,        pkt->vec[VMXNET_TX_PKT_L3HDR_FRAG].iov_len);    ip_hdr->ip_sum = cpu_to_be16(csum);         ph_raw_csum = eth_calc_pseudo_hdr_csum(ip_hdr, pkt->payload_len);    csum = cpu_to_be16(~net_checksum_finish(ph_raw_csum));    iov_from_buf(&pkt->vec[VMXNET_TX_PKT_PL_START_FRAG], pkt->payload_frags,                 pkt->virt_hdr.csum_offset, &csum, sizeof(csum));}",1598
156,3799,CVE-2012-5157,26,"    WebFrameCSSCallbackTest()    {        m_frame = m_helper.initializeAndLoad(""about:blank"", true, &m_client)->mainFrame();    }",29474
735,570,CVE-2011-4086,26,"void __jbd2_journal_temp_unlink_buffer(struct journal_head *jh){	struct journal_head **list = NULL;	transaction_t *transaction;	struct buffer_head *bh = jh2bh(jh);	J_ASSERT_JH(jh, jbd_is_locked_bh_state(bh));	transaction = jh->b_transaction;	if (transaction)		assert_spin_locked(&transaction->t_journal->j_list_lock);	J_ASSERT_JH(jh, jh->b_jlist < BJ_Types);	if (jh->b_jlist != BJ_None)		J_ASSERT_JH(jh, transaction != NULL);	switch (jh->b_jlist) {	case BJ_None:		return;	case BJ_Metadata:		transaction->t_nr_buffers--;		J_ASSERT_JH(jh, transaction->t_nr_buffers >= 0);		list = &transaction->t_buffers;		break;	case BJ_Forget:		list = &transaction->t_forget;		break;	case BJ_IO:		list = &transaction->t_iobuf_list;		break;	case BJ_Shadow:		list = &transaction->t_shadow_list;		break;	case BJ_LogCtl:		list = &transaction->t_log_list;		break;	case BJ_Reserved:		list = &transaction->t_reserved_list;		break;	}	__blist_del_buffer(list, jh);	jh->b_jlist = BJ_None;	if (test_clear_buffer_jbddirty(bh))		mark_buffer_dirty(bh);	 }",5481
60,1440,CVE-2014-8884,26,static void ttusbdecfe_release(struct dvb_frontend* fe){	struct ttusbdecfe_state* state = (struct ttusbdecfe_state*) fe->demodulator_priv;	kfree(state);},10386
563,2094,CVE-2016-4303,26,iperf_get_test_protocol_id(struct iperf_test *ipt){    return ipt->protocol->id;},17002
222,1862,CVE-2016-7425,26,"static void arcmsr_free_mu(struct AdapterControlBlock *acb){	switch (acb->adapter_type) {	case ACB_ADAPTER_TYPE_B:	case ACB_ADAPTER_TYPE_D: {		dma_free_coherent(&acb->pdev->dev, acb->roundup_ccbsize,			acb->dma_coherent2, acb->dma_coherent_handle2);		break;	}	}}",15781
91,2105,CVE-2016-4303,26,iperf_get_verbose(struct iperf_test *ipt){    return ipt->verbose;},17013
445,1839,CVE-2016-8633,26,static void fwnet_fifo_stop(struct fwnet_device *dev){	if (dev->local_fifo == FWNET_NO_FIFO_ADDR)		return;	fw_core_remove_address_handler(&dev->handler);	dev->local_fifo = FWNET_NO_FIFO_ADDR;},15573
932,2955,CVE-2017-8062,26,"static int dw3101_tuner_attach(struct dvb_usb_adapter *adap){	dvb_attach(dvb_pll_attach, adap->fe_adap[0].fe, 0x60,		&adap->dev->i2c_adap, DVB_PLL_TUA6034);	return 0;}",21432
414,1295,CVE-2013-1929,26,"static void tg3_rx_prodring_fini(struct tg3 *tp,				 struct tg3_rx_prodring_set *tpr){	kfree(tpr->rx_std_buffers);	tpr->rx_std_buffers = NULL;	kfree(tpr->rx_jmb_buffers);	tpr->rx_jmb_buffers = NULL;	if (tpr->rx_std) {		dma_free_coherent(&tp->pdev->dev, TG3_RX_STD_RING_BYTES(tp),				  tpr->rx_std, tpr->rx_std_mapping);		tpr->rx_std = NULL;	}	if (tpr->rx_jmb) {		dma_free_coherent(&tp->pdev->dev, TG3_RX_JMB_RING_BYTES(tp),				  tpr->rx_jmb, tpr->rx_jmb_mapping);		tpr->rx_jmb = NULL;	}}",9301
969,673,CVE-2011-2517,26,"static int nl80211_leave_mesh(struct sk_buff *skb, struct genl_info *info){	struct cfg80211_registered_device *rdev = info->user_ptr[0];	struct net_device *dev = info->user_ptr[1];	return cfg80211_leave_mesh(rdev, dev);}",6572
70,206,CVE-2012-5670,26,"  _bdf_atol( char*   s,             char**  end,             int     base )  {    long                  v, neg;    const unsigned char*  dmap;    if ( s == 0 || *s == 0 )      return 0;         switch ( base )    {    case 8:      dmap = odigits;      break;    case 16:      dmap = hdigits;      break;    default:      base = 10;      dmap = ddigits;      break;    }         neg = 0;    if ( *s == '-' )    {      s++;      neg = 1;    }         if ( *s == '0'                                  &&         ( *( s + 1 ) == 'x' || *( s + 1 ) == 'X' ) )    {      base = 16;      dmap = hdigits;      s   += 2;    }    for ( v = 0; sbitset( dmap, *s ); s++ )      v = v * base + a2i[(int)*s];    if ( end != 0 )      *end = s;    return ( !neg ) ? v : -v;  }",1024
830,3100,CVE-2016-10012,26,close_startup_pipes(void){	int i;	if (startup_pipes)		for (i = 0; i < options.max_startups; i++)			if (startup_pipes[i] != -1)				close(startup_pipes[i]);},22618
926,1683,CVE-2015-3905,26,static void eexec_string(const char *string){  while (*string)    eexec_byte(*string++);},13581
429,1863,CVE-2016-7425,26,static int arcmsr_get_firmware_spec(struct AdapterControlBlock *acb){	int rtn = false;	switch (acb->adapter_type) {	case ACB_ADAPTER_TYPE_A:		rtn = arcmsr_hbaA_get_config(acb);		break;	case ACB_ADAPTER_TYPE_B:		rtn = arcmsr_hbaB_get_config(acb);		break;	case ACB_ADAPTER_TYPE_C:		rtn = arcmsr_hbaC_get_config(acb);		break;	case ACB_ADAPTER_TYPE_D:		rtn = arcmsr_hbaD_get_config(acb);		break;	default:		break;	}	if (acb->firm_numbers_queue > ARCMSR_MAX_OUTSTANDING_CMD)		acb->maxOutstanding = ARCMSR_MAX_OUTSTANDING_CMD;	else		acb->maxOutstanding = acb->firm_numbers_queue - 1;	acb->host->can_queue = acb->maxOutstanding;	return rtn;},15782
898,2573,CVE-2016-1583,26,"void sched_online_group(struct task_group *tg, struct task_group *parent){	unsigned long flags;	spin_lock_irqsave(&task_group_lock, flags);	list_add_rcu(&tg->list, &task_groups);	WARN_ON(!parent);  	tg->parent = parent;	INIT_LIST_HEAD(&tg->children);	list_add_rcu(&tg->siblings, &parent->children);	spin_unlock_irqrestore(&task_group_lock, flags);}",18122
236,3282,CVE-2018-11595,26,int jslGetTokenLength() {  return lex->tokenl;},25129
58,290,CVE-2018-17204,13,"ofputil_decode_flow_stats_request(struct ofputil_flow_stats_request *fsr,                                  const struct ofp_header *oh,                                  const struct tun_table *tun_table,                                  const struct vl_mff_map *vl_mff_map){    struct ofpbuf b = ofpbuf_const_initializer(oh, ntohs(oh->length));    enum ofpraw raw = ofpraw_pull_assert(&b);    switch ((int) raw) {    case OFPRAW_OFPST10_FLOW_REQUEST:        return ofputil_decode_ofpst10_flow_request(fsr, b.data, false);    case OFPRAW_OFPST10_AGGREGATE_REQUEST:        return ofputil_decode_ofpst10_flow_request(fsr, b.data, true);    case OFPRAW_OFPST11_FLOW_REQUEST:        return ofputil_decode_ofpst11_flow_request(fsr, &b, false, tun_table,                                                   vl_mff_map);    case OFPRAW_OFPST11_AGGREGATE_REQUEST:        return ofputil_decode_ofpst11_flow_request(fsr, &b, true, tun_table,                                                   vl_mff_map);    case OFPRAW_NXST_FLOW_REQUEST:        return ofputil_decode_nxst_flow_request(fsr, &b, false, tun_table,                                                vl_mff_map);    case OFPRAW_NXST_AGGREGATE_REQUEST:        return ofputil_decode_nxst_flow_request(fsr, &b, true, tun_table,                                                vl_mff_map);    default:                 OVS_NOT_REACHED();    }}",24025
0,338,CVE-2018-17204,13,"ofputil_encode_group_stats_request(enum ofp_version ofp_version,                                   int group_id){    struct ofpbuf *request;    switch (ofp_version) {    case OFP10_VERSION:        ovs_fatal(0, ""dump-group-stats needs OpenFlow 1.1 or later ""                     ""(\'-O OpenFlow11\')"");    case OFP11_VERSION:    case OFP12_VERSION:    case OFP13_VERSION:    case OFP14_VERSION:    case OFP15_VERSION:    case OFP16_VERSION: {        struct ofp11_group_stats_request *req;        request = ofpraw_alloc(OFPRAW_OFPST11_GROUP_REQUEST, ofp_version, 0);        req = ofpbuf_put_zeros(request, sizeof *req);        req->group_id = htonl(group_id);        break;    }    default:        OVS_NOT_REACHED();    }    return request;}",24073
3,440,CVE-2018-17204,13,"ofputil_version_to_string(enum ofp_version ofp_version){    switch (ofp_version) {    case OFP10_VERSION:        return ""OpenFlow10"";    case OFP11_VERSION:        return ""OpenFlow11"";    case OFP12_VERSION:        return ""OpenFlow12"";    case OFP13_VERSION:        return ""OpenFlow13"";    case OFP14_VERSION:        return ""OpenFlow14"";    case OFP15_VERSION:        return ""OpenFlow15"";    case OFP16_VERSION:        return ""OpenFlow16"";    default:        OVS_NOT_REACHED();    }}",24175
6,442,CVE-2018-17204,13,"ofputil_wildcard_from_ofpfw10(int ofpfw, struct flow_wildcards *wc){    BUILD_ASSERT_DECL(FLOW_WC_SEQ == 36);         flow_wildcards_init_catchall(wc);    if (!(ofpfw & OFPFW10_IN_PORT)) {        wc->masks.in_port.ofp_port = u16_to_ofp(UINT16_MAX);    }    if (!(ofpfw & OFPFW10_NW_TOS)) {        wc->masks.nw_tos |= IP_DSCP_MASK;    }    if (!(ofpfw & OFPFW10_NW_PROTO)) {        wc->masks.nw_proto = UINT8_MAX;    }    wc->masks.nw_src = ofputil_wcbits_to_netmask(ofpfw                                                 >> OFPFW10_NW_SRC_SHIFT);    wc->masks.nw_dst = ofputil_wcbits_to_netmask(ofpfw                                                 >> OFPFW10_NW_DST_SHIFT);    if (!(ofpfw & OFPFW10_TP_SRC)) {        wc->masks.tp_src = OVS_BE16_MAX;    }    if (!(ofpfw & OFPFW10_TP_DST)) {        wc->masks.tp_dst = OVS_BE16_MAX;    }    if (!(ofpfw & OFPFW10_DL_SRC)) {        WC_MASK_FIELD(wc, dl_src);    }    if (!(ofpfw & OFPFW10_DL_DST)) {        WC_MASK_FIELD(wc, dl_dst);    }    if (!(ofpfw & OFPFW10_DL_TYPE)) {        wc->masks.dl_type = OVS_BE16_MAX;    }         if (!(ofpfw & OFPFW10_DL_VLAN_PCP)) {        wc->masks.vlan_tci |= htons(VLAN_PCP_MASK | VLAN_CFI);    }    if (!(ofpfw & OFPFW10_DL_VLAN)) {        wc->masks.vlan_tci |= htons(VLAN_VID_MASK | VLAN_CFI);    }}",24177
103,60,CVE-2018-17205,13,"    OVS_EXCLUDED(ofproto_mutex){    struct ofproto *ofproto = ofconn_get_ofproto(ofconn);    struct ofproto_group_mod ogm;    enum ofperr error;    error = reject_slave_controller(ofconn);    if (error) {        return error;    }    error = ofputil_decode_group_mod(oh, &ogm.gm);    if (error) {        return error;    }    ovs_mutex_lock(&ofproto_mutex);    ogm.version = ofproto->tables_version + 1;    error = ofproto_group_mod_start(ofproto, &ogm);    if (!error) {        struct openflow_mod_requester req = { ofconn, oh };        ofproto_bump_tables_version(ofproto);        ofproto_group_mod_finish(ofproto, &ogm, &req);        ofmonitor_flush(ofproto->connmgr);    }    ovs_mutex_unlock(&ofproto_mutex);    ofputil_uninit_group_mod(&ogm.gm);    return error;}",23795
98,63,CVE-2018-17205,13,"    OVS_EXCLUDED(ofproto_mutex){    enum ofperr error = handle_openflow__(ofconn, ofp_msg);    if (error) {        ofconn_send_error(ofconn, ofp_msg->data, error);    }    COVERAGE_INC(ofproto_recv_openflow);}",23798
44,45,CVE-2018-17205,13,    OVS_EXCLUDED(ofproto_mutex){    ovs_mutex_lock(&ofproto_mutex);    remove_rule_rcu__(rule);    ovs_mutex_unlock(&ofproto_mutex);},23780
8,367,CVE-2018-17204,13,"ofputil_format_version_bitmap__(struct ds *msg, int bitmap,                                void (*format_version)(struct ds *msg,                                                       enum ofp_version)){    while (bitmap) {        format_version(msg, raw_ctz(bitmap));        bitmap = zero_rightmost_1bit(bitmap);        if (bitmap) {            ds_put_cstr(msg, "", "");        }    }}",24102
71,103,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){         delete_flows_finish__(ofproto, &group->rules, OFPRR_GROUP_DELETE, NULL);     }",23838
52,155,CVE-2018-17205,13,"next_visible_table(const struct ofproto *ofproto, int table_id){    struct oftable *table;    for (table = &ofproto->tables[table_id];         table < &ofproto->tables[ofproto->n_tables];         table++) {        if (!(table->flags & OFTABLE_HIDDEN)) {            return table;        }    }    return NULL;}",23890
1,221,CVE-2018-17205,13,ofproto_set_flow_restore_wait(int flow_restore_wait_db){    flow_restore_wait = flow_restore_wait_db;},23956
90,325,CVE-2018-17204,13,"ofputil_encode_bundle_add(enum ofp_version ofp_version,                          struct ofputil_bundle_add_msg *msg){    struct ofpbuf *request;    struct ofp14_bundle_ctrl_msg *m;         request = ofpraw_alloc_xid(ofp_version == OFP13_VERSION                               ? OFPRAW_ONFT13_BUNDLE_ADD_MESSAGE                               : OFPRAW_OFPT14_BUNDLE_ADD_MESSAGE, ofp_version,                               msg->msg->xid, ntohs(msg->msg->length));    m = ofpbuf_put_zeros(request, sizeof *m);    m->bundle_id = htonl(msg->bundle_id);    m->flags = htons(msg->flags);    ofpbuf_put(request, msg->msg, ntohs(msg->msg->length));    ofpmsg_update_length(request);    return request;}",24060
49,339,CVE-2018-17204,13,"ofputil_encode_meter_features_reply(const struct ofputil_meter_features *mf,                                    const struct ofp_header *request){    struct ofpbuf *reply;    struct ofp13_meter_features *omf;    reply = ofpraw_alloc_stats_reply(request, 0);    omf = ofpbuf_put_zeros(reply, sizeof *omf);    omf->max_meter = htonl(mf->max_meters);    omf->band_types = htonl(mf->band_types);    omf->capabilities = htonl(mf->capabilities);    omf->max_bands = mf->max_bands;    omf->max_color = mf->max_color;    return reply;}",24074
55,335,CVE-2018-17204,13,"ofputil_encode_group_features_reply(    const struct ofputil_group_features *features,    const struct ofp_header *request){    struct ofp12_group_features_stats *ogf;    struct ofpbuf *reply;    int i;    reply = ofpraw_alloc_xid(OFPRAW_OFPST12_GROUP_FEATURES_REPLY,                             request->version, request->xid, 0);    ogf = ofpbuf_put_zeros(reply, sizeof *ogf);    ogf->types = htonl(features->types);    ogf->capabilities = htonl(features->capabilities);    for (i = 0; i < OFPGT12_N_TYPES; i++) {        ogf->max_groups[i] = htonl(features->max_groups[i]);        ogf->actions[i] = ofpact_bitmap_to_openflow(features->ofpacts[i],                                                    request->version);    }    return reply;}",24070
102,223,CVE-2018-17205,13,"ofproto_set_in_band_queue(struct ofproto *ofproto, int queue_id){    connmgr_set_in_band_queue(ofproto->connmgr, queue_id);}",23958
115,236,CVE-2018-17205,13,"ofproto_wait(struct ofproto *p){    p->ofproto_class->wait(p);    if (p->ofproto_class->port_poll_wait) {        p->ofproto_class->port_poll_wait(p);    }    seq_wait(connectivity_seq_get(), p->change_seq);    connmgr_wait(p->connmgr);}",23971
10,13,CVE-2017-12168,13,"int kvm_handle_sys_reg(struct kvm_vcpu *vcpu, struct kvm_run *run){	struct sys_reg_params params;	unsigned long esr = kvm_vcpu_get_hsr(vcpu);	int Rt = (esr >> 5) & 0x1f;	int ret;	trace_kvm_handle_sys_reg(esr);	params.is_aarch32 = false;	params.is_32bit = false;	params.Op0 = (esr >> 20) & 3;	params.Op1 = (esr >> 14) & 0x7;	params.CRn = (esr >> 10) & 0xf;	params.CRm = (esr >> 1) & 0xf;	params.Op2 = (esr >> 17) & 0x7;	params.regval = vcpu_get_reg(vcpu, Rt);	params.is_write = !(esr & 1);	ret = emulate_sys_reg(vcpu, &params);	if (!params.is_write)		vcpu_set_reg(vcpu, Rt, params.regval);	return ret;}",20344
109,457,CVE-2018-17204,13,"put_table_action_features(struct ofpbuf *reply,                          const struct ofputil_table_action_features *taf,                          enum ofp13_table_feature_prop_type actions_type,                          enum ofp13_table_feature_prop_type set_fields_type,                          int miss_offset, enum ofp_version version){    ofpprop_put_bitmap(reply, actions_type + miss_offset,                       ntohl(ofpact_bitmap_to_openflow(taf->ofpacts,                                                       version)));    put_fields_property(reply, &taf->set_fields, NULL,                        set_fields_type + miss_offset, version);}",24192
17,52,CVE-2018-17205,13,"    OVS_EXCLUDED(ofproto_mutex){    rule_criteria_init(&ofm->criteria, fm->table_id, &fm->match, fm->priority,                       OVS_VERSION_MAX, fm->cookie, fm->cookie_mask, OFPP_ANY,                       OFPG_ANY);    rule_criteria_require_rw(&ofm->criteria,                             (fm->flags & OFPUTIL_FF_NO_READONLY) != 0);         add_flow_init(ofproto, ofm, fm);    return 0;}",23787
50,57,CVE-2018-17205,13,"    OVS_EXCLUDED(ofproto_mutex){    enum ofperr error;    int id;    id = ofputil_decode_flow_monitor_cancel(oh);    ovs_mutex_lock(&ofproto_mutex);    error = flow_monitor_delete(ofconn, id);    ovs_mutex_unlock(&ofproto_mutex);    return error;}",23792
67,426,CVE-2018-17204,13,"ofputil_put_ofp14_port(const struct ofputil_phy_port *pp,                       struct ofpbuf *b){    struct ofp14_port *op;    struct ofp14_port_desc_prop_ethernet *eth;    ofpbuf_prealloc_tailroom(b, sizeof *op + sizeof *eth);    op = ofpbuf_put_zeros(b, sizeof *op);    op->port_no = ofputil_port_to_ofp11(pp->port_no);    op->length = htons(sizeof *op + sizeof *eth);    op->hw_addr = pp->hw_addr;    ovs_strlcpy(op->name, pp->name, sizeof op->name);    op->config = htonl(pp->config & OFPPC11_ALL);    op->state = htonl(pp->state & OFPPS11_ALL);    eth = ofpprop_put_zeros(b, OFPPDPT14_ETHERNET, sizeof *eth);    eth->curr = netdev_port_features_to_ofp11(pp->curr);    eth->advertised = netdev_port_features_to_ofp11(pp->advertised);    eth->supported = netdev_port_features_to_ofp11(pp->supported);    eth->peer = netdev_port_features_to_ofp11(pp->peer);    eth->curr_speed = htonl(pp->curr_speed);    eth->max_speed = htonl(pp->max_speed);}",24161
31,277,CVE-2018-17204,13,"ofputil_append_queue_stat(struct ovs_list *replies,                          const struct ofputil_queue_stats *oqs){    switch (ofpmp_version(replies)) {    case OFP13_VERSION: {        struct ofp13_queue_stats *reply = ofpmp_append(replies, sizeof *reply);        ofputil_queue_stats_to_ofp13(oqs, reply);        break;    }    case OFP12_VERSION:    case OFP11_VERSION: {        struct ofp11_queue_stats *reply = ofpmp_append(replies, sizeof *reply);        ofputil_queue_stats_to_ofp11(oqs, reply);        break;    }    case OFP10_VERSION: {        struct ofp10_queue_stats *reply = ofpmp_append(replies, sizeof *reply);        ofputil_queue_stats_to_ofp10(oqs, reply);        break;    }    case OFP14_VERSION:    case OFP15_VERSION:    case OFP16_VERSION: {        struct ofp14_queue_stats *reply = ofpmp_append(replies, sizeof *reply);        ofputil_queue_stats_to_ofp14(oqs, reply);        break;    }    default:        OVS_NOT_REACHED();    }}",24012
54,428,CVE-2018-17204,13,"ofputil_put_switch_config(const struct ofputil_switch_config *config,                          struct ofpbuf *b){    const struct ofp_header *oh = b->data;    struct ofp_switch_config *osc = ofpbuf_put_zeros(b, sizeof *osc);    osc->flags = htons(config->frag);    if (config->invalid_ttl_to_controller > 0 && oh->version < OFP13_VERSION) {        osc->flags |= htons(OFPC_INVALID_TTL_TO_CONTROLLER);    }    osc->miss_send_len = htons(config->miss_send_len);    return b;}",24163
80,174,CVE-2018-17205,13,"ofproto_flow_mod_learn_refresh(struct ofproto_flow_mod *ofm){    enum ofperr error = 0;         struct rule *rule = ofm->temp_rule;    if (!rule) {        return OFPERR_OFPFMFC_UNKNOWN;    }         if (rule->state == RULE_REMOVED) {        struct cls_rule cr;        cls_rule_clone(&cr, &rule->cr);        ovs_mutex_lock(&rule->mutex);        error = ofproto_rule_create(rule->ofproto, &cr, rule->table_id,                                    rule->flow_cookie,                                    rule->idle_timeout,                                    rule->hard_timeout, rule->flags,                                    rule->importance,                                    rule->actions->ofpacts,                                    rule->actions->ofpacts_len,                                    rule->match_tlv_bitmap,                                    rule->ofpacts_tlv_bitmap,                                    &ofm->temp_rule);        ovs_mutex_unlock(&rule->mutex);        if (!error) {            ofproto_rule_unref(rule);            }    } else {                 ovs_mutex_lock(&rule->mutex);        rule->modified = time_msec();        ovs_mutex_unlock(&rule->mutex);    }    return error;}",23909
41,88,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    if (rule_collection_n(rules)) {        struct ofproto *ofproto = rule_collection_rules(rules)[0]->ofproto;        delete_flows_start__(ofproto, ofproto->tables_version + 1, rules);        ofproto_bump_tables_version(ofproto);        delete_flows_finish__(ofproto, rules, reason, req);        ofmonitor_flush(ofproto->connmgr);    }}",23823
32,255,CVE-2018-17205,13,"rule_criteria_require_rw(struct rule_criteria *criteria,                         int can_write_readonly){    criteria->include_readonly = can_write_readonly;}",23990
18,433,CVE-2018-17204,13,"ofputil_queue_stats_to_ofp11(const struct ofputil_queue_stats *oqs,                             struct ofp11_queue_stats *qs11){    qs11->port_no = ofputil_port_to_ofp11(oqs->port_no);    qs11->queue_id = htonl(oqs->queue_id);    qs11->tx_bytes = htonll(oqs->tx_bytes);    qs11->tx_packets = htonll(oqs->tx_packets);    qs11->tx_errors = htonll(oqs->tx_errors);}",24168
104,51,CVE-2018-17205,13,"    OVS_EXCLUDED(ofproto_mutex){    enum ofperr error = ofproto_flow_mod_learn_refresh(ofm);    struct rule *rule = ofm->temp_rule;         if (!error && rule->state == RULE_INITIALIZED) {        ovs_mutex_lock(&ofproto_mutex);        ofm->version = rule->ofproto->tables_version + 1;        error = ofproto_flow_mod_learn_start(ofm);        if (!error) {            ofproto_flow_mod_learn_finish(ofm, NULL);        }        ovs_mutex_unlock(&ofproto_mutex);    }    if (!keep_ref) {        ofproto_rule_unref(rule);        ofm->temp_rule = NULL;    }    return error;}",23786
75,453,CVE-2018-17204,13,"parse_table_mod_vacancy_property(struct ofpbuf *property,                                 struct ofputil_table_mod *tm){    struct ofp14_table_mod_prop_vacancy *otv = property->data;    if (property->size != sizeof *otv) {        return OFPERR_OFPBPC_BAD_LEN;    }    tm->table_vacancy.vacancy_down = otv->vacancy_down;    tm->table_vacancy.vacancy_up = otv->vacancy_up;    if (tm->table_vacancy.vacancy_down > tm->table_vacancy.vacancy_up) {        OFPPROP_LOG(&bad_ofmsg_rl, false,                    ""Value of vacancy_down is greater than vacancy_up"");        return OFPERR_OFPBPC_BAD_VALUE;    }    if (tm->table_vacancy.vacancy_down > 100 ||        tm->table_vacancy.vacancy_up > 100) {        OFPPROP_LOG(&bad_ofmsg_rl, false, ""Vacancy threshold percentage ""                    ""should not be greater than 100"");        return OFPERR_OFPBPC_BAD_VALUE;    }    tm->table_vacancy.vacancy = otv->vacancy;    if (tm->table_vacancy.vacancy) {        OFPPROP_LOG(&bad_ofmsg_rl, false,                    ""Vacancy value should be zero for table-mod messages"");        return OFPERR_OFPBPC_BAD_VALUE;    }    return 0;}",24188
100,270,CVE-2018-17204,13,netdev_port_features_to_ofp10(enum netdev_features features){    return htonl((features & 0x7f) | ((features & 0xf800) >> 4));},24005
12,422,CVE-2018-17204,13,"ofputil_put_ofp11_match(struct ofpbuf *b, const struct match *match,                        enum ofputil_protocol protocol){    switch (protocol) {    case OFPUTIL_P_OF10_STD:    case OFPUTIL_P_OF10_STD_TID:    case OFPUTIL_P_OF10_NXM:    case OFPUTIL_P_OF10_NXM_TID:        OVS_NOT_REACHED();    case OFPUTIL_P_OF11_STD: {        struct ofp11_match *om;                 BUILD_ASSERT_DECL(sizeof *om % 8 == 0);        om = ofpbuf_put_uninit(b, sizeof *om);        ofputil_match_to_ofp11_match(match, om);        return sizeof *om;    }    case OFPUTIL_P_OF12_OXM:    case OFPUTIL_P_OF13_OXM:    case OFPUTIL_P_OF14_OXM:    case OFPUTIL_P_OF15_OXM:    case OFPUTIL_P_OF16_OXM:        return oxm_put_match(b, match,                             ofputil_protocol_to_ofp_version(protocol));    }    OVS_NOT_REACHED();}",24157
4,289,CVE-2018-17204,13,"ofputil_decode_flow_removed(struct ofputil_flow_removed *fr,                            const struct ofp_header *oh){    struct ofpbuf b = ofpbuf_const_initializer(oh, ntohs(oh->length));    enum ofpraw raw = ofpraw_pull_assert(&b);    if (raw == OFPRAW_OFPT11_FLOW_REMOVED) {        const struct ofp12_flow_removed *ofr;        enum ofperr error;        ofr = ofpbuf_pull(&b, sizeof *ofr);        error = ofputil_pull_ofp11_match(&b, NULL, NULL, &fr->match, NULL);        if (error) {            return error;        }        fr->priority = ntohs(ofr->priority);        fr->cookie = ofr->cookie;        fr->reason = ofr->reason;        fr->table_id = ofr->table_id;        fr->duration_sec = ntohl(ofr->duration_sec);        fr->duration_nsec = ntohl(ofr->duration_nsec);        fr->idle_timeout = ntohs(ofr->idle_timeout);        fr->hard_timeout = ntohs(ofr->hard_timeout);        fr->packet_count = ntohll(ofr->packet_count);        fr->byte_count = ntohll(ofr->byte_count);    } else if (raw == OFPRAW_OFPT10_FLOW_REMOVED) {        const struct ofp10_flow_removed *ofr;        ofr = ofpbuf_pull(&b, sizeof *ofr);        ofputil_match_from_ofp10_match(&ofr->match, &fr->match);        fr->priority = ntohs(ofr->priority);        fr->cookie = ofr->cookie;        fr->reason = ofr->reason;        fr->table_id = 255;        fr->duration_sec = ntohl(ofr->duration_sec);        fr->duration_nsec = ntohl(ofr->duration_nsec);        fr->idle_timeout = ntohs(ofr->idle_timeout);        fr->hard_timeout = 0;        fr->packet_count = ntohll(ofr->packet_count);        fr->byte_count = ntohll(ofr->byte_count);    } else if (raw == OFPRAW_NXT_FLOW_REMOVED) {        struct nx_flow_removed *nfr;        enum ofperr error;        nfr = ofpbuf_pull(&b, sizeof *nfr);        error = nx_pull_match(&b, ntohs(nfr->match_len), &fr->match, NULL,                              NULL, NULL, NULL);        if (error) {            return error;        }        if (b.size) {            return OFPERR_OFPBRC_BAD_LEN;        }        fr->priority = ntohs(nfr->priority);        fr->cookie = nfr->cookie;        fr->reason = nfr->reason;        fr->table_id = nfr->table_id ? nfr->table_id - 1 : 255;        fr->duration_sec = ntohl(nfr->duration_sec);        fr->duration_nsec = ntohl(nfr->duration_nsec);        fr->idle_timeout = ntohs(nfr->idle_timeout);        fr->hard_timeout = 0;        fr->packet_count = ntohll(nfr->packet_count);        fr->byte_count = ntohll(nfr->byte_count);    } else {        OVS_NOT_REACHED();    }    return 0;}",24024
37,310,CVE-2018-17204,13,"ofputil_decode_port_status(const struct ofp_header *oh,                           struct ofputil_port_status *ps){    struct ofpbuf b = ofpbuf_const_initializer(oh, ntohs(oh->length));    ofpraw_pull_assert(&b);    const struct ofp_port_status *ops = ofpbuf_pull(&b, sizeof *ops);    if (ops->reason != OFPPR_ADD &&        ops->reason != OFPPR_DELETE &&        ops->reason != OFPPR_MODIFY) {        return OFPERR_NXBRC_BAD_REASON;    }    ps->reason = ops->reason;    int retval = ofputil_pull_phy_port(oh->version, &b, &ps->desc);    ovs_assert(retval != EOF);    return retval;}",24045
106,91,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    delete_flows_finish__(ofproto, &ofm->old_rules, OFPRR_DELETE, req);}",23826
25,217,CVE-2018-17205,13,"ofproto_set_dp_desc(struct ofproto *p, const char *dp_desc){    free(p->dp_desc);    p->dp_desc = nullable_xstrdup(dp_desc);}",23952
74,282,CVE-2018-17204,13,"ofputil_bucket_list_back(const struct ovs_list *buckets){    static struct ofputil_bucket *bucket;    ASSIGN_CONTAINER(bucket, ovs_list_back(buckets), list_node);    return bucket;}",24017
40,443,CVE-2018-17204,13,"parse_action_bitmap(struct ofpbuf *payload, enum ofp_version ofp_version,                    int *ofpacts){    int types = 0;    while (payload->size > 0) {        enum ofperr error;        int type;        error = ofpprop_pull__(payload, NULL, 1, 0x10000, &type);        if (error) {            return error;        }        if (type < CHAR_BIT * sizeof types) {            types |= 1u << type;        }    }    *ofpacts = ofpact_bitmap_from_openflow(htonl(types), ofp_version);    return 0;}",24178
35,147,CVE-2018-17205,13,"handle_role_request(struct ofconn *ofconn, const struct ofp_header *oh){    struct ofputil_role_request request;    struct ofputil_role_request reply;    struct ofpbuf *buf;    enum ofperr error;    error = ofputil_decode_role_message(oh, &request);    if (error) {        return error;    }    if (request.role != OFPCR12_ROLE_NOCHANGE) {        if (request.role != OFPCR12_ROLE_EQUAL            && request.have_generation_id            && !ofconn_set_master_election_id(ofconn, request.generation_id)) {                return OFPERR_OFPRRFC_STALE;        }        ofconn_set_role(ofconn, request.role);    }    reply.role = ofconn_get_role(ofconn);    reply.have_generation_id = ofconn_get_master_election_id(        ofconn, &reply.generation_id);    buf = ofputil_encode_role_reply(oh, &reply);    ofconn_send_reply(ofconn, buf);    return 0;}",23882
29,99,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    struct ofputil_group_stats ogs;    const struct ofproto *ofproto = group->ofproto;    long long int now = time_msec();    int error;    ogs.bucket_stats = xmalloc(group->n_buckets * sizeof *ogs.bucket_stats);         ogs.ref_count = rule_collection_n(&group->rules);    ogs.n_buckets = group->n_buckets;    error = (ofproto->ofproto_class->group_get_stats             ? ofproto->ofproto_class->group_get_stats(group, &ogs)             : EOPNOTSUPP);    if (error) {        ogs.packet_count = UINT64_MAX;        ogs.byte_count = UINT64_MAX;        memset(ogs.bucket_stats, 0xff,               ogs.n_buckets * sizeof *ogs.bucket_stats);    }    ogs.group_id = group->group_id;    calc_duration(group->created, now, &ogs.duration_sec, &ogs.duration_nsec);    ofputil_append_group_stats(replies, &ogs);    free(ogs.bucket_stats);}",23834
21,245,CVE-2018-17205,13,"process_port_change(struct ofproto *ofproto, int error, char *devname){    if (error == ENOBUFS) {        reinit_ports(ofproto);    } else if (!error) {        update_port(ofproto, devname);        free(devname);    }}",23980
53,408,CVE-2018-17204,13,ofputil_protocols_from_ofp_version(enum ofp_version version){    switch (version) {    case OFP10_VERSION:        return OFPUTIL_P_OF10_STD_ANY | OFPUTIL_P_OF10_NXM_ANY;    case OFP11_VERSION:        return OFPUTIL_P_OF11_STD;    case OFP12_VERSION:        return OFPUTIL_P_OF12_OXM;    case OFP13_VERSION:        return OFPUTIL_P_OF13_OXM;    case OFP14_VERSION:        return OFPUTIL_P_OF14_OXM;    case OFP15_VERSION:        return OFPUTIL_P_OF15_OXM;    case OFP16_VERSION:        return OFPUTIL_P_OF16_OXM;    default:        return 0;    }},24143
84,292,CVE-2018-17204,13,"ofputil_decode_group_desc_reply(struct ofputil_group_desc *gd,                                struct ofpbuf *msg, enum ofp_version version){    ofputil_init_group_properties(&gd->props);    switch (version)    {    case OFP11_VERSION:    case OFP12_VERSION:    case OFP13_VERSION:    case OFP14_VERSION:        return ofputil_decode_ofp11_group_desc_reply(gd, msg, version);    case OFP15_VERSION:    case OFP16_VERSION:        return ofputil_decode_ofp15_group_desc_reply(gd, msg, version);    case OFP10_VERSION:    default:        OVS_NOT_REACHED();    }}",24027
7,202,CVE-2018-17205,13,ofproto_port_destroy(struct ofproto_port *ofproto_port){    free(ofproto_port->name);    free(ofproto_port->type);},23937
86,24,CVE-2017-12168,13,"static int trap_debug32(struct kvm_vcpu *vcpu,			 struct sys_reg_params *p,			 const struct sys_reg_desc *r){	if (p->is_write) {		vcpu_cp14(vcpu, r->reg) = p->regval;		vcpu->arch.debug_flags |= KVM_ARM64_DEBUG_DIRTY;	} else {		p->regval = vcpu_cp14(vcpu, r->reg);	}	return true;}",20355
43,405,CVE-2018-17204,13,"ofputil_protocol_to_base(enum ofputil_protocol protocol){    return ofputil_protocol_set_tid(protocol, false);}",24140
23,316,CVE-2018-17204,13,"ofputil_decode_set_config(const struct ofp_header *oh,                          struct ofputil_switch_config *config){    return (ofputil_decode_switch_config(oh, config)            ? 0            : OFPERR_OFPSCFC_BAD_FLAGS);}",24051
85,148,CVE-2018-17205,13,"handle_set_config(struct ofconn *ofconn, const struct ofp_header *oh){    struct ofproto *ofproto = ofconn_get_ofproto(ofconn);    struct ofputil_switch_config config;    enum ofperr error;    error = ofputil_decode_set_config(oh, &config);    if (error) {        return error;    }    if (ofconn_get_type(ofconn) != OFCONN_PRIMARY        || ofconn_get_role(ofconn) != OFPCR12_ROLE_SLAVE) {        enum ofputil_frag_handling cur = ofproto->frag_handling;        enum ofputil_frag_handling next = config.frag;        if (cur != next) {            if (ofproto->ofproto_class->set_frag_handling(ofproto, next)) {                ofproto->frag_handling = next;            } else {                VLOG_WARN_RL(&rl, ""%s: unsupported fragment handling mode %s"",                             ofproto->name,                             ofputil_frag_handling_to_string(next));            }        }    }    if (config.invalid_ttl_to_controller >= 0) {        ofconn_set_invalid_ttl_to_controller(ofconn,                                             config.invalid_ttl_to_controller);    }    ofconn_set_miss_send_len(ofconn, config.miss_send_len);    return 0;}",23883
105,222,CVE-2018-17205,13,"ofproto_set_forward_bpdu(struct ofproto *ofproto, int forward_bpdu){    int old_val = ofproto->forward_bpdu;    ofproto->forward_bpdu = forward_bpdu;    if (old_val != ofproto->forward_bpdu) {        if (ofproto->ofproto_class->forward_bpdu_changed) {            ofproto->ofproto_class->forward_bpdu_changed(ofproto);        }    }}",23957
65,142,CVE-2018-17205,13,"handle_nxt_set_flow_format(struct ofconn *ofconn, const struct ofp_header *oh){    const struct nx_set_flow_format *msg = ofpmsg_body(oh);    enum ofputil_protocol cur, next;    enum ofputil_protocol next_base;    next_base = ofputil_nx_flow_format_to_protocol(ntohl(msg->format));    if (!next_base) {        return OFPERR_OFPBRC_EPERM;    }    cur = ofconn_get_protocol(ofconn);    next = ofputil_protocol_set_base(cur, next_base);    ofconn_set_protocol(ofconn, next);    return 0;}",23877
72,42,CVE-2018-17205,13,"    OVS_EXCLUDED(ofproto_mutex){    ovsrcu_postpone(ofproto_destroy__, ofproto);}",23777
89,373,CVE-2018-17204,13,"ofputil_group_properties_copy(struct ofputil_group_props *to,                              const struct ofputil_group_props *from){    *to = *from;    to->fields.values = xmemdup(from->fields.values, from->fields.values_size);}",24108
9,145,CVE-2018-17205,13,"handle_queue_stats_dump_cb(int queue_id,                           struct netdev_queue_stats *stats,                           void *cbdata_){    struct queue_stats_cbdata *cbdata = cbdata_;    put_queue_stats(cbdata, queue_id, stats);}",23880
56,411,CVE-2018-17204,13,ofputil_protocols_to_version_bitmap(enum ofputil_protocol protocols){    int bitmap = 0;    for (; protocols; protocols = zero_rightmost_1bit(protocols)) {        enum ofputil_protocol protocol = rightmost_1bit(protocols);        bitmap |= 1u << ofputil_protocol_to_ofp_version(protocol);    }    return bitmap;},24146
19,369,CVE-2018-17204,13,"ofputil_format_version_name(struct ds *msg, enum ofp_version version){    ds_put_cstr(msg, ofputil_version_to_string(version));}",24104
78,175,CVE-2018-17205,13,ofproto_flow_mod_uninit(struct ofproto_flow_mod *ofm){    if (ofm->temp_rule) {        ofproto_rule_unref(ofm->temp_rule);        ofm->temp_rule = NULL;    }    if (ofm->criteria.version != OVS_VERSION_NOT_REMOVED) {        rule_criteria_destroy(&ofm->criteria);    }    if (ofm->conjs) {        free(ofm->conjs);        ofm->conjs = NULL;        ofm->n_conjs = 0;    }},23910
59,219,CVE-2018-17205,13,"ofproto_set_flood_vlans(struct ofproto *ofproto, unsigned long *flood_vlans){    return (ofproto->ofproto_class->set_flood_vlans            ? ofproto->ofproto_class->set_flood_vlans(ofproto, flood_vlans)            : EOPNOTSUPP);}",23954
66,283,CVE-2018-17204,13,"ofputil_bucket_list_front(const struct ovs_list *buckets){    static struct ofputil_bucket *bucket;    ASSIGN_CONTAINER(bucket, ovs_list_front(buckets), list_node);    return bucket;}",24018
92,204,CVE-2018-17205,13,"ofproto_port_dump_next(struct ofproto_port_dump *dump,                       struct ofproto_port *port){    const struct ofproto *ofproto = dump->ofproto;    if (dump->error) {        return false;    }    dump->error = ofproto->ofproto_class->port_dump_next(ofproto, dump->state,                                                         port);    if (dump->error) {        ofproto->ofproto_class->port_dump_done(ofproto, dump->state);        return false;    }    return true;}",23939
15,191,CVE-2018-17205,13,ofproto_has_snoops(const struct ofproto *ofproto){    return connmgr_has_snoops(ofproto->connmgr);},23926
111,318,CVE-2018-17204,13,"ofputil_decode_table_mod(const struct ofp_header *oh,                         struct ofputil_table_mod *pm){    memset(pm, 0, sizeof *pm);    pm->miss = OFPUTIL_TABLE_MISS_DEFAULT;    pm->eviction = OFPUTIL_TABLE_EVICTION_DEFAULT;    pm->eviction_flags = UINT32_MAX;    pm->vacancy = OFPUTIL_TABLE_VACANCY_DEFAULT;    struct ofpbuf b = ofpbuf_const_initializer(oh, ntohs(oh->length));    enum ofpraw raw = ofpraw_pull_assert(&b);    if (raw == OFPRAW_OFPT11_TABLE_MOD) {        const struct ofp11_table_mod *otm = b.data;        pm->table_id = otm->table_id;        pm->miss = ofputil_decode_table_miss(otm->config, oh->version);    } else if (raw == OFPRAW_OFPT14_TABLE_MOD) {        const struct ofp14_table_mod *otm = ofpbuf_pull(&b, sizeof *otm);        pm->table_id = otm->table_id;        pm->miss = ofputil_decode_table_miss(otm->config, oh->version);        pm->eviction = ofputil_decode_table_eviction(otm->config, oh->version);        pm->vacancy = ofputil_decode_table_vacancy(otm->config, oh->version);        while (b.size > 0) {            struct ofpbuf property;            enum ofperr error;            int type;            error = ofpprop_pull(&b, &property, &type);            if (error) {                return error;            }            switch (type) {            case OFPTMPT14_EVICTION:                error = ofpprop_parse_u32(&property, &pm->eviction);                break;            case OFPTMPT14_VACANCY:                error = parse_table_mod_vacancy_property(&property, pm);                break;            default:                error = OFPERR_OFPBRC_BAD_TYPE;                break;            }            if (error) {                return error;            }        }    } else {        return OFPERR_OFPBRC_BAD_TYPE;    }    return 0;}",24053
22,314,CVE-2018-17204,13,"ofputil_decode_role_status(const struct ofp_header *oh,                           struct ofputil_role_status *rs){    struct ofpbuf b = ofpbuf_const_initializer(oh, ntohs(oh->length));    enum ofpraw raw = ofpraw_pull_assert(&b);    ovs_assert(raw == OFPRAW_OFPT14_ROLE_STATUS);    const struct ofp14_role_status *r = b.msg;    if (r->role != htonl(OFPCR12_ROLE_NOCHANGE) &&        r->role != htonl(OFPCR12_ROLE_EQUAL) &&        r->role != htonl(OFPCR12_ROLE_MASTER) &&        r->role != htonl(OFPCR12_ROLE_SLAVE)) {        return OFPERR_OFPRRFC_BAD_ROLE;    }    rs->role = ntohl(r->role);    rs->generation_id = ntohll(r->generation_id);    rs->reason = r->reason;    return 0;}",24049
34,168,CVE-2018-17205,13,"ofproto_bump_tables_version(struct ofproto *ofproto){    ++ofproto->tables_version;    ofproto->ofproto_class->set_tables_version(ofproto,                                               ofproto->tables_version);}",23903
68,192,CVE-2018-17205,13,"ofproto_init_max_ports(struct ofproto *ofproto, int max_ports){    ovs_assert(max_ports <= ofp_to_u16(OFPP_MAX));    ofproto->max_ports = max_ports;}",23927
57,86,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    struct rule_collection *old_rules = &ofm->old_rules;    enum ofperr error;    error = collect_rules_loose(ofproto, &ofm->criteria, old_rules);    if (!error) {        error = modify_flows_start__(ofproto, ofm);    }    if (error) {        rule_collection_destroy(old_rules);    }    return error;}",23821
114,386,CVE-2018-17204,13,"ofputil_normalize_match_quiet(struct match *match){    ofputil_normalize_match__(match, false);}",24121
88,276,CVE-2018-17204,13,"ofputil_append_port_stat(struct ovs_list *replies,                         const struct ofputil_port_stats *ops){    switch (ofpmp_version(replies)) {    case OFP13_VERSION: {        struct ofp13_port_stats *reply = ofpmp_append(replies, sizeof *reply);        ofputil_port_stats_to_ofp13(ops, reply);        break;    }    case OFP12_VERSION:    case OFP11_VERSION: {        struct ofp11_port_stats *reply = ofpmp_append(replies, sizeof *reply);        ofputil_port_stats_to_ofp11(ops, reply);        break;    }    case OFP10_VERSION: {        struct ofp10_port_stats *reply = ofpmp_append(replies, sizeof *reply);        ofputil_port_stats_to_ofp10(ops, reply);        break;    }    case OFP14_VERSION:    case OFP15_VERSION:    case OFP16_VERSION:        ofputil_append_ofp14_port_stats(ops, replies);        break;    default:        OVS_NOT_REACHED();    }}",24011
38,107,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    switch (ofm->command) {    case OFPFC_ADD:        add_flow_finish(ofproto, ofm, req);        break;    case OFPFC_MODIFY:    case OFPFC_MODIFY_STRICT:        modify_flows_finish(ofproto, ofm, req);        break;    case OFPFC_DELETE:    case OFPFC_DELETE_STRICT:        delete_flows_finish(ofproto, ofm, req);        break;    default:        break;    }    rule_collection_destroy(&ofm->old_rules);    rule_collection_destroy(&ofm->new_rules);    if (req) {        ofconn_report_flow_mod(req->ofconn, ofm->command);    }}",23842
99,225,CVE-2018-17205,13,"ofproto_set_mcast_snooping(struct ofproto *ofproto,                           const struct ofproto_mcast_snooping_settings *s){    return (ofproto->ofproto_class->set_mcast_snooping            ? ofproto->ofproto_class->set_mcast_snooping(ofproto, s)            : EOPNOTSUPP);}",23960
27,133,CVE-2018-17205,13,"handle_meter_mod(struct ofconn *ofconn, const struct ofp_header *oh){    struct ofproto *ofproto = ofconn_get_ofproto(ofconn);    struct ofputil_meter_mod mm;    int bands_stub[256 / 8];    struct ofpbuf bands;    int meter_id;    enum ofperr error;    error = reject_slave_controller(ofconn);    if (error) {        return error;    }    ofpbuf_use_stub(&bands, bands_stub, sizeof bands_stub);    error = ofputil_decode_meter_mod(oh, &mm, &bands);    if (error) {        goto exit_free_bands;    }    meter_id = mm.meter.meter_id;    if (mm.command != OFPMC13_DELETE) {                 if (meter_id == 0 || meter_id > OFPM13_MAX) {            error = OFPERR_OFPMMFC_INVALID_METER;            goto exit_free_bands;        } else if (meter_id > ofproto->meter_features.max_meters) {            error = OFPERR_OFPMMFC_OUT_OF_METERS;            goto exit_free_bands;        }        if (mm.meter.n_bands > ofproto->meter_features.max_bands) {            error = OFPERR_OFPMMFC_OUT_OF_BANDS;            goto exit_free_bands;        }    }    switch (mm.command) {    case OFPMC13_ADD:        error = handle_add_meter(ofproto, &mm);        break;    case OFPMC13_MODIFY:        error = handle_modify_meter(ofproto, &mm);        break;    case OFPMC13_DELETE:        error = handle_delete_meter(ofconn, &mm);        break;    default:        error = OFPERR_OFPMMFC_BAD_COMMAND;        break;    }    if (!error) {        struct ofputil_requestforward rf;        rf.xid = oh->xid;        rf.reason = OFPRFR_METER_MOD;        rf.meter_mod = &mm;        connmgr_send_requestforward(ofproto->connmgr, ofconn, &rf);    }exit_free_bands:    ofpbuf_uninit(&bands);    return error;}",23868
110,70,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    learned_cookies_update__(ofproto, actions, +1, NULL);}",23805
64,102,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){         group->being_deleted = true;         delete_flows_start__(ofproto, version, &group->rules);    group_collection_add(groups, group);    versions_set_remove_version(&group->versions, version);    ofproto->n_groups[group->type]--;}",23837
33,423,CVE-2018-17204,13,"ofputil_put_ofp11_table_stats(const struct ofputil_table_stats *stats,                              const struct ofputil_table_features *features,                              struct ofpbuf *buf){    struct mf_bitmap wc = wild_or_nonmatchable_fields(features);    struct ofp11_table_stats *out;    out = ofpbuf_put_zeros(buf, sizeof *out);    out->table_id = features->table_id;    ovs_strlcpy(out->name, features->name, sizeof out->name);    out->wildcards = mf_bitmap_to_of11(&wc);    out->match = mf_bitmap_to_of11(&features->match);    out->instructions = ovsinst_bitmap_to_openflow(        features->nonmiss.instructions, OFP11_VERSION);    out->write_actions = ofpact_bitmap_to_openflow(        features->nonmiss.write.ofpacts, OFP11_VERSION);    out->apply_actions = ofpact_bitmap_to_openflow(        features->nonmiss.apply.ofpacts, OFP11_VERSION);    out->config = htonl(features->miss_config);    out->max_entries = htonl(features->max_entries);    out->active_count = htonl(stats->active_count);    out->lookup_count = htonll(stats->lookup_count);    out->matched_count = htonll(stats->matched_count);}",24158
113,429,CVE-2018-17204,13,"ofputil_queue_stats_from_ofp10(struct ofputil_queue_stats *oqs,                               const struct ofp10_queue_stats *qs10){    oqs->port_no = u16_to_ofp(ntohs(qs10->port_no));    oqs->queue_id = ntohl(qs10->queue_id);    oqs->tx_bytes = ntohll(get_32aligned_be64(&qs10->tx_bytes));    oqs->tx_packets = ntohll(get_32aligned_be64(&qs10->tx_packets));    oqs->tx_errors = ntohll(get_32aligned_be64(&qs10->tx_errors));    oqs->duration_sec = oqs->duration_nsec = UINT32_MAX;    return 0;}",24164
42,100,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    enum ofperr error;    if (ofproto_group_exists(ofproto, ogm->gm.group_id)) {        return OFPERR_OFPGMFC_GROUP_EXISTS;    }    if (ofproto->n_groups[ogm->gm.type]        >= ofproto->ogf.max_groups[ogm->gm.type]) {        return OFPERR_OFPGMFC_OUT_OF_GROUPS;    }         error = init_group(ofproto, &ogm->gm, ogm->version, &ogm->new_group);    if (!error) {                 cmap_insert(&ofproto->groups, &ogm->new_group->cmap_node,                    hash_int(ogm->new_group->group_id, 0));        ofproto->n_groups[ogm->new_group->type]++;    }    return error;}",23835
5,298,CVE-2018-17204,13,"ofputil_decode_meter_mod(const struct ofp_header *oh,                         struct ofputil_meter_mod *mm,                         struct ofpbuf *bands){    struct ofpbuf b = ofpbuf_const_initializer(oh, ntohs(oh->length));    ofpraw_pull_assert(&b);    const struct ofp13_meter_mod *omm = ofpbuf_pull(&b, sizeof *omm);         mm->command = ntohs(omm->command);    if (mm->command != OFPMC13_ADD &&        mm->command != OFPMC13_MODIFY &&        mm->command != OFPMC13_DELETE) {        return OFPERR_OFPMMFC_BAD_COMMAND;    }    mm->meter.meter_id = ntohl(omm->meter_id);    if (mm->command == OFPMC13_DELETE) {        mm->meter.flags = 0;        mm->meter.n_bands = 0;        mm->meter.bands = NULL;    } else {        enum ofperr error;        mm->meter.flags = ntohs(omm->flags);        if (mm->meter.flags & OFPMF13_KBPS &&            mm->meter.flags & OFPMF13_PKTPS) {            return OFPERR_OFPMMFC_BAD_FLAGS;        }        error = ofputil_pull_bands(&b, b.size, &mm->meter.n_bands, bands);        if (error) {            return error;        }        mm->meter.bands = bands->data;    }    return 0;}",24033
26,281,CVE-2018-17204,13,"ofputil_bucket_clone_data(const struct ofputil_bucket *bucket){    struct ofputil_bucket *new;    new = xmemdup(bucket, sizeof *bucket);    new->ofpacts = xmemdup(bucket->ofpacts, bucket->ofpacts_len);    return new;}",24016
81,350,CVE-2018-17204,13,"ofputil_encode_requestforward(const struct ofputil_requestforward *rf,                              enum ofputil_protocol protocol){    enum ofp_version ofp_version = ofputil_protocol_to_ofp_version(protocol);    struct ofpbuf *inner;    switch (rf->reason) {    case OFPRFR_GROUP_MOD:        inner = ofputil_encode_group_mod(ofp_version, rf->group_mod);        break;    case OFPRFR_METER_MOD:        inner = ofputil_encode_meter_mod(ofp_version, rf->meter_mod);        break;    case OFPRFR_N_REASONS:    default:        OVS_NOT_REACHED();    }    struct ofp_header *inner_oh = inner->data;    inner_oh->xid = rf->xid;    inner_oh->length = htons(inner->size);    struct ofpbuf *outer = ofpraw_alloc_xid(OFPRAW_OFPT14_REQUESTFORWARD,                                            ofp_version, htonl(0),                                            inner->size);    ofpbuf_put(outer, inner->data, inner->size);    ofpbuf_delete(inner);    return outer;}",24085
77,16,CVE-2017-12168,13,"static int match_sys_reg(const void *key, const void *elt){	const unsigned long pval = (unsigned long)key;	const struct sys_reg_desc *r = elt;	return pval - reg_to_match_value(r);}",20347
96,46,CVE-2018-17205,13,    OVS_EXCLUDED(ofproto_mutex){    ovs_mutex_lock(&ofproto_mutex);    remove_group_rcu__(group);    ovs_mutex_unlock(&ofproto_mutex);},23781
47,9,CVE-2017-12168,13,"static const struct sys_reg_desc *find_reg(const struct sys_reg_params *params,					 const struct sys_reg_desc table[],					 unsigned int num){	unsigned long pval = reg_to_match_value(params);	return bsearch((void *)pval, table, num, sizeof(table[0]), match_sys_reg);}",20340
101,156,CVE-2018-17205,13,"ofport_destroy(struct ofport *port, int del){    if (port) {        dealloc_ofp_port(port->ofproto, port->ofp_port);        port->ofproto->ofproto_class->port_destruct(port, del);        ofport_destroy__(port);     }}",23891
83,112,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    struct ofproto *ofproto = rule->ofproto;    struct oftable *table = &ofproto->tables[rule->table_id];    int has_timeout;         has_timeout = rule->hard_timeout || rule->idle_timeout;    if (table->eviction && has_timeout) {        struct eviction_group *evg;        evg = eviction_group_find(table, eviction_group_hash_rule(rule));        rule->eviction_group = evg;        heap_insert(&evg->rules, &rule->evg_node,                    rule_eviction_priority(ofproto, rule));        eviction_group_resized(table, evg);    }}",23847
48,166,CVE-2018-17205,13,ofproto_aa_vlan_get_queue_size(struct ofproto *ofproto){    if (!ofproto->ofproto_class->aa_vlan_get_queue_size) {        return EOPNOTSUPP;    }    return ofproto->ofproto_class->aa_vlan_get_queue_size(ofproto);},23901
107,445,CVE-2018-17204,13,"parse_intel_port_stats_property(const struct ofpbuf *payload,                                int exp_type,                                struct ofputil_port_stats *ops){    enum ofperr error;    switch (exp_type) {    case INTEL_PORT_STATS_RFC2819:        error = parse_intel_port_stats_rfc2819_property(payload, ops);        break;    default:        error = OFPERR_OFPBPC_BAD_EXP_TYPE;        break;    }    return error;}",24180
87,139,CVE-2018-17205,13,"handle_nxt_resume(struct ofconn *ofconn, const struct ofp_header *oh){    struct ofproto *ofproto = ofconn_get_ofproto(ofconn);    struct ofputil_packet_in_private pin;    enum ofperr error;    error = ofputil_decode_packet_in_private(oh, false,                                             ofproto_get_tun_tab(ofproto),                                             &ofproto->vl_mff_map, &pin, NULL,                                             NULL);    if (error) {        return error;    }    error = (ofproto->ofproto_class->nxt_resume             ? ofproto->ofproto_class->nxt_resume(ofproto, &pin)             : OFPERR_NXR_NOT_SUPPORTED);    ofputil_packet_in_private_destroy(&pin);    return error;}",23874
24,435,CVE-2018-17204,13,"ofputil_queue_stats_to_ofp14(const struct ofputil_queue_stats *oqs,                             struct ofp14_queue_stats *qs14){    qs14->length = htons(sizeof *qs14);    memset(qs14->pad, 0, sizeof qs14->pad);    ofputil_queue_stats_to_ofp13(oqs, &qs14->qs);}",24170
11,334,CVE-2018-17204,13,"ofputil_encode_group_desc_request(enum ofp_version ofp_version,                                  int group_id){    struct ofpbuf *request;    switch (ofp_version) {    case OFP10_VERSION:        ovs_fatal(0, ""dump-groups needs OpenFlow 1.1 or later ""                     ""(\'-O OpenFlow11\')"");    case OFP11_VERSION:    case OFP12_VERSION:    case OFP13_VERSION:    case OFP14_VERSION:        request = ofpraw_alloc(OFPRAW_OFPST11_GROUP_DESC_REQUEST,                               ofp_version, 0);        break;    case OFP15_VERSION:    case OFP16_VERSION: {        struct ofp15_group_desc_request *req;        request = ofpraw_alloc(OFPRAW_OFPST15_GROUP_DESC_REQUEST,                               ofp_version, 0);        req = ofpbuf_put_zeros(request, sizeof *req);        req->group_id = htonl(group_id);        break;    }    default:        OVS_NOT_REACHED();    }    return request;}",24069
20,274,CVE-2018-17204,13,"ofputil_append_meter_stats(struct ovs_list *replies,                           const struct ofputil_meter_stats *ms){    struct ofp13_meter_stats *reply;    int n = 0;    int len;    len = sizeof *reply + ms->n_bands * sizeof(struct ofp13_meter_band_stats);    reply = ofpmp_append(replies, len);    reply->meter_id = htonl(ms->meter_id);    reply->len = htons(len);    memset(reply->pad, 0, sizeof reply->pad);    reply->flow_count = htonl(ms->flow_count);    reply->packet_in_count = htonll(ms->packet_in_count);    reply->byte_in_count = htonll(ms->byte_in_count);    reply->duration_sec = htonl(ms->duration_sec);    reply->duration_nsec = htonl(ms->duration_nsec);    for (n = 0; n < ms->n_bands; ++n) {        const struct ofputil_meter_band_stats *src = &ms->bands[n];        struct ofp13_meter_band_stats *dst = &reply->band_stats[n];        dst->packet_band_count = htonll(src->packet_count);        dst->byte_band_count = htonll(src->byte_count);    }}",24009
93,210,CVE-2018-17205,13,"ofproto_port_set_mcast_snooping(struct ofproto *ofproto, void *aux,                           const struct ofproto_mcast_snooping_port_settings *s){    return (ofproto->ofproto_class->set_mcast_snooping_port            ? ofproto->ofproto_class->set_mcast_snooping_port(ofproto, aux, s)            : EOPNOTSUPP);}",23945
13,26,CVE-2017-12168,13,"static int trap_oslsr_el1(struct kvm_vcpu *vcpu,			   struct sys_reg_params *p,			   const struct sys_reg_desc *r){	if (p->is_write) {		return ignore_write(vcpu, p);	} else {		p->regval = (1 << 3);		return true;	}}",20357
79,122,CVE-2018-17205,13,"group_remove_rule(struct ofgroup *group, struct rule *rule){    rule_collection_remove(&group->rules, rule);}",23857
76,333,CVE-2018-17204,13,"ofputil_encode_get_config_reply(const struct ofp_header *request,                                const struct ofputil_switch_config *config){    struct ofpbuf *b = ofpraw_alloc_reply(OFPRAW_OFPT_GET_CONFIG_REPLY,                                          request, 0);    return ofputil_put_switch_config(config, b);}",24068
82,164,CVE-2018-17205,13,"ofport_remove_with_name(struct ofproto *ofproto, const char *name){    struct ofport *port = shash_find_data(&ofproto->port_by_name, name);    if (port) {        ofport_remove(port);    }}",23899
69,161,CVE-2018-17205,13,"ofport_is_mtu_overridden(const struct ofproto *p, const struct ofport *port){    return ofport_is_internal_or_patch(p, port)           && !netdev_mtu_is_user_config(port->netdev);}",23896
39,151,CVE-2018-17205,13,"meter_insert_rule(struct rule *rule){    const struct rule_actions *a = rule_get_actions(rule);    int meter_id = ofpacts_get_meter(a->ofpacts, a->ofpacts_len);    struct meter *meter = rule->ofproto->meters[meter_id];    ovs_list_insert(&meter->rules, &rule->meter_list_node);}",23886
46,449,CVE-2018-17204,13,"parse_ofp14_port_stats_ethernet_property(const struct ofpbuf *payload,                                         struct ofputil_port_stats *ops){    const struct ofp14_port_stats_prop_ethernet *eth = payload->data;    if (payload->size != sizeof *eth) {        return OFPERR_OFPBPC_BAD_LEN;    }    ops->stats.rx_frame_errors = ntohll(eth->rx_frame_err);    ops->stats.rx_over_errors = ntohll(eth->rx_over_err);    ops->stats.rx_crc_errors = ntohll(eth->rx_crc_err);    ops->stats.collisions = ntohll(eth->collisions);    return 0;}",24184
16,371,CVE-2018-17204,13,"ofputil_frag_handling_to_string(enum ofputil_frag_handling frag){    switch (frag) {    case OFPUTIL_FRAG_NORMAL:   return ""normal"";    case OFPUTIL_FRAG_DROP:     return ""drop"";    case OFPUTIL_FRAG_REASM:    return ""reassemble"";    case OFPUTIL_FRAG_NX_MATCH: return ""nx-match"";    }    OVS_NOT_REACHED();}",24106
63,294,CVE-2018-17204,13,"ofputil_decode_group_mod(const struct ofp_header *oh,                         struct ofputil_group_mod *gm){    ofputil_init_group_properties(&gm->props);    enum ofp_version ofp_version = oh->version;    struct ofpbuf msg = ofpbuf_const_initializer(oh, ntohs(oh->length));    ofpraw_pull_assert(&msg);    enum ofperr err;    switch (ofp_version)    {    case OFP11_VERSION:    case OFP12_VERSION:    case OFP13_VERSION:    case OFP14_VERSION:        err = ofputil_pull_ofp11_group_mod(&msg, ofp_version, gm);        break;    case OFP15_VERSION:    case OFP16_VERSION:        err = ofputil_pull_ofp15_group_mod(&msg, ofp_version, gm);        break;    case OFP10_VERSION:    default:        OVS_NOT_REACHED();    }    if (err) {        return err;    }    err = ofputil_check_group_mod(gm);    if (err) {        ofputil_uninit_group_mod(gm);    }    return err;}",24029
97,400,CVE-2018-17204,13,"ofputil_port_stats_to_ofp13(const struct ofputil_port_stats *ops,                            struct ofp13_port_stats *ps13){    ofputil_port_stats_to_ofp11(ops, &ps13->ps);    ps13->duration_sec = htonl(ops->duration_sec);    ps13->duration_nsec = htonl(ops->duration_nsec);}",24135
14,347,CVE-2018-17204,13,"ofputil_encode_port_mod(const struct ofputil_port_mod *pm,                        enum ofputil_protocol protocol){    enum ofp_version ofp_version = ofputil_protocol_to_ofp_version(protocol);    struct ofpbuf *b;    switch (ofp_version) {    case OFP10_VERSION: {        struct ofp10_port_mod *opm;        b = ofpraw_alloc(OFPRAW_OFPT10_PORT_MOD, ofp_version, 0);        opm = ofpbuf_put_zeros(b, sizeof *opm);        opm->port_no = htons(ofp_to_u16(pm->port_no));        opm->hw_addr = pm->hw_addr;        opm->config = htonl(pm->config & OFPPC10_ALL);        opm->mask = htonl(pm->mask & OFPPC10_ALL);        opm->advertise = netdev_port_features_to_ofp10(pm->advertise);        break;    }    case OFP11_VERSION:    case OFP12_VERSION:    case OFP13_VERSION: {        struct ofp11_port_mod *opm;        b = ofpraw_alloc(OFPRAW_OFPT11_PORT_MOD, ofp_version, 0);        opm = ofpbuf_put_zeros(b, sizeof *opm);        opm->port_no = ofputil_port_to_ofp11(pm->port_no);        opm->hw_addr = pm->hw_addr;        opm->config = htonl(pm->config & OFPPC11_ALL);        opm->mask = htonl(pm->mask & OFPPC11_ALL);        opm->advertise = netdev_port_features_to_ofp11(pm->advertise);        break;    }    case OFP14_VERSION:    case OFP15_VERSION:    case OFP16_VERSION: {        struct ofp14_port_mod *opm;        b = ofpraw_alloc(OFPRAW_OFPT14_PORT_MOD, ofp_version, 0);        opm = ofpbuf_put_zeros(b, sizeof *opm);        opm->port_no = ofputil_port_to_ofp11(pm->port_no);        opm->hw_addr = pm->hw_addr;        opm->config = htonl(pm->config & OFPPC11_ALL);        opm->mask = htonl(pm->mask & OFPPC11_ALL);        if (pm->advertise) {            ofpprop_put_be32(b, OFPPMPT14_ETHERNET,                             netdev_port_features_to_ofp11(pm->advertise));        }        break;    }    default:        OVS_NOT_REACHED();    }    return b;}",24082
28,83,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    struct rule *rule = rule_collection_rules(&ofm->new_rules)[0];    ofproto_flow_mod_revert(rule->ofproto, ofm);}",23818
95,295,CVE-2018-17204,13,"ofputil_decode_group_stats_request(const struct ofp_header *request,                                   int *group_id){    const struct ofp11_group_stats_request *gsr11 = ofpmsg_body(request);    *group_id = ntohl(gsr11->group_id);    return 0;}",24030
60,2,CVE-2017-12168,13,"static int access_dcsw(struct kvm_vcpu *vcpu,			struct sys_reg_params *p,			const struct sys_reg_desc *r){	if (!p->is_write)		return read_from_write_only(vcpu, p);	kvm_set_way_flush(vcpu);	return true;}",20333
51,80,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    struct rule *old_rule = NULL;    struct rule *new_rule = ofm->temp_rule;    const struct rule_actions *actions = rule_get_actions(new_rule);    struct oftable *table = &ofproto->tables[new_rule->table_id];    enum ofperr error;         error = ofproto_check_ofpacts(ofproto, actions->ofpacts,                                  actions->ofpacts_len);    if (error) {        return error;    }         old_rule = rule_from_cls_rule(classifier_find_rule_exactly(&table->cls,                                                               &new_rule->cr,                                                               ofm->version));    if (!old_rule) {                 if (new_rule->flags & OFPUTIL_FF_CHECK_OVERLAP            && classifier_rule_overlaps(&table->cls, &new_rule->cr,                                        ofm->version)) {            return OFPERR_OFPFMFC_OVERLAP;        }                 if (table->n_flows >= table->max_flows) {            if (!choose_rule_to_evict(table, &old_rule)) {                return OFPERR_OFPFMFC_TABLE_FULL;            }            eviction_group_remove_rule(old_rule);                         old_rule->removed_reason = OFPRR_EVICTION;        }    } else {        ofm->modify_cookie = true;    }    if (old_rule) {        rule_collection_add(&ofm->old_rules, old_rule);    }         rule_collection_add(&ofm->new_rules, new_rule);    ofm->temp_rule = NULL;    replace_rule_start(ofproto, ofm, old_rule, new_rule);    return 0;}",23815
94,69,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    if (actions->has_learn_with_delete) {        const struct ofpact_learn *learn;        for (learn = next_learn_with_delete(actions, NULL); learn;             learn = next_learn_with_delete(actions, learn)) {            learned_cookies_update_one__(ofproto, learn, delta, dead_cookies);        }    }}",23804
91,141,CVE-2018-17205,13,"handle_nxt_set_controller_id(struct ofconn *ofconn,                             const struct ofp_header *oh){    const struct nx_controller_id *nci = ofpmsg_body(oh);    if (!is_all_zeros(nci->zero, sizeof nci->zero)) {        return OFPERR_NXBRC_MUST_BE_ZERO;    }    ofconn_set_controller_id(ofconn, ntohs(nci->controller_id));    return 0;}",23876
61,413,CVE-2018-17204,13,"ofputil_pull_ofp11_group_mod(struct ofpbuf *msg, enum ofp_version ofp_version,                             struct ofputil_group_mod *gm){    const struct ofp11_group_mod *ogm;    enum ofperr error;    ogm = ofpbuf_pull(msg, sizeof *ogm);    gm->command = ntohs(ogm->command);    gm->type = ogm->type;    gm->group_id = ntohl(ogm->group_id);    gm->command_bucket_id = OFPG15_BUCKET_ALL;    error = ofputil_pull_ofp11_buckets(msg, msg->size, ofp_version,                                       &gm->buckets);         if (!error        && ofp_version >= OFP13_VERSION        && gm->command == OFPGC11_DELETE        && !ovs_list_is_empty(&gm->buckets)) {        error = OFPERR_OFPGMFC_INVALID_GROUP;        ofputil_bucket_list_destroy(&gm->buckets);    }    return error;}",24148
36,212,CVE-2018-17205,13,ofproto_reconnect_controllers(struct ofproto *ofproto){    connmgr_reconnect(ofproto->connmgr);},23947
112,414,CVE-2018-17204,13,"ofputil_pull_ofp11_match(struct ofpbuf *buf, const struct tun_table *tun_table,                         const struct vl_mff_map *vl_mff_map,                         struct match *match, int *padded_match_len){    struct ofp11_match_header *omh = buf->data;    int match_len;    if (buf->size < sizeof *omh) {        return OFPERR_OFPBMC_BAD_LEN;    }    match_len = ntohs(omh->length);    switch (ntohs(omh->type)) {    case OFPMT_STANDARD: {        struct ofp11_match *om;        if (match_len != sizeof *om || buf->size < sizeof *om) {            return OFPERR_OFPBMC_BAD_LEN;        }        om = ofpbuf_pull(buf, sizeof *om);        if (padded_match_len) {            *padded_match_len = match_len;        }        return ofputil_match_from_ofp11_match(om, match);    }    case OFPMT_OXM:        if (padded_match_len) {            *padded_match_len = ROUND_UP(match_len, 8);        }        return oxm_pull_match(buf, tun_table, vl_mff_map, match);    default:        return OFPERR_OFPBMC_BAD_TYPE;    }}",24149
73,261,CVE-2018-17205,13,"update_port_config(struct ofconn *ofconn, struct ofport *port,                   enum ofputil_port_config config,                   enum ofputil_port_config mask){    enum ofputil_port_config toggle = (config ^ port->pp.config) & mask;    if (toggle & OFPUTIL_PC_PORT_DOWN        && (config & OFPUTIL_PC_PORT_DOWN            ? netdev_turn_flags_off(port->netdev, NETDEV_UP, NULL)            : netdev_turn_flags_on(port->netdev, NETDEV_UP, NULL))) {                 toggle &= ~OFPUTIL_PC_PORT_DOWN;    }    if (toggle) {        enum ofputil_port_config old_config = port->pp.config;        port->pp.config ^= toggle;        port->ofproto->ofproto_class->port_reconfigured(port, old_config);        connmgr_send_port_status(port->ofproto->connmgr, ofconn, &port->pp,                                 OFPPR_MODIFY);    }}",23996
70,301,CVE-2018-17204,13,"ofputil_decode_ofp10_phy_port(struct ofputil_phy_port *pp,                              const struct ofp10_phy_port *opp){    pp->port_no = u16_to_ofp(ntohs(opp->port_no));    pp->hw_addr = opp->hw_addr;    ovs_strlcpy(pp->name, opp->name, OFP_MAX_PORT_NAME_LEN);    pp->config = ntohl(opp->config) & OFPPC10_ALL;    pp->state = ntohl(opp->state) & OFPPS10_ALL;    pp->curr = netdev_port_features_from_ofp10(opp->curr);    pp->advertised = netdev_port_features_from_ofp10(opp->advertised);    pp->supported = netdev_port_features_from_ofp10(opp->supported);    pp->peer = netdev_port_features_from_ofp10(opp->peer);    pp->curr_speed = netdev_features_to_bps(pp->curr, 0) / 1000;    pp->max_speed = netdev_features_to_bps(pp->supported, 0) / 1000;    return 0;}",24036
62,126,CVE-2018-17205,13,"handle_get_config_request(struct ofconn *ofconn, const struct ofp_header *oh){    struct ofputil_switch_config config;    config.frag = ofconn_get_ofproto(ofconn)->frag_handling;    config.invalid_ttl_to_controller        = ofconn_get_invalid_ttl_to_controller(ofconn);    config.miss_send_len = ofconn_get_miss_send_len(ofconn);    ofconn_send_reply(ofconn, ofputil_encode_get_config_reply(oh, &config));    return 0;}",23861
30,349,CVE-2018-17204,13,"ofputil_encode_queue_stats_request(enum ofp_version ofp_version,                                   const struct ofputil_queue_stats_request *oqsr){    struct ofpbuf *request;    switch (ofp_version) {    case OFP11_VERSION:    case OFP12_VERSION:    case OFP13_VERSION:    case OFP14_VERSION:    case OFP15_VERSION:    case OFP16_VERSION: {        struct ofp11_queue_stats_request *req;        request = ofpraw_alloc(OFPRAW_OFPST11_QUEUE_REQUEST, ofp_version, 0);        req = ofpbuf_put_zeros(request, sizeof *req);        req->port_no = ofputil_port_to_ofp11(oqsr->port_no);        req->queue_id = htonl(oqsr->queue_id);        break;    }    case OFP10_VERSION: {        struct ofp10_queue_stats_request *req;        request = ofpraw_alloc(OFPRAW_OFPST10_QUEUE_REQUEST, ofp_version, 0);        req = ofpbuf_put_zeros(request, sizeof *req);                 req->port_no = htons(ofp_to_u16(oqsr->port_no == OFPP_ANY                                        ? OFPP_ALL : oqsr->port_no));        req->queue_id = htonl(oqsr->queue_id);        break;    }    default:        OVS_NOT_REACHED();    }    return request;}",24084
45,77,CVE-2018-17205,13,"    OVS_REQUIRES(ofproto_mutex){    if (group_collection_n(groups) > 0) {        if (group_collection_n(groups) == 1) {            ovsrcu_postpone(remove_group_rcu,                            group_collection_groups(groups)[0]);            group_collection_init(groups);        } else {            ovsrcu_postpone(remove_groups_rcu,                            group_collection_detach(groups));        }    }}",23812
2,37,CVE-2017-0376,13,"relay_command_to_string(int command){  switch (command) {    case RELAY_COMMAND_BEGIN: return ""BEGIN"";    case RELAY_COMMAND_DATA: return ""DATA"";    case RELAY_COMMAND_END: return ""END"";    case RELAY_COMMAND_CONNECTED: return ""CONNECTED"";    case RELAY_COMMAND_SENDME: return ""SENDME"";    case RELAY_COMMAND_EXTEND: return ""EXTEND"";    case RELAY_COMMAND_EXTENDED: return ""EXTENDED"";    case RELAY_COMMAND_TRUNCATE: return ""TRUNCATE"";    case RELAY_COMMAND_TRUNCATED: return ""TRUNCATED"";    case RELAY_COMMAND_DROP: return ""DROP"";    case RELAY_COMMAND_RESOLVE: return ""RESOLVE"";    case RELAY_COMMAND_RESOLVED: return ""RESOLVED"";    case RELAY_COMMAND_BEGIN_DIR: return ""BEGIN_DIR"";    case RELAY_COMMAND_ESTABLISH_INTRO: return ""ESTABLISH_INTRO"";    case RELAY_COMMAND_ESTABLISH_RENDEZVOUS: return ""ESTABLISH_RENDEZVOUS"";    case RELAY_COMMAND_INTRODUCE1: return ""INTRODUCE1"";    case RELAY_COMMAND_INTRODUCE2: return ""INTRODUCE2"";    case RELAY_COMMAND_RENDEZVOUS1: return ""RENDEZVOUS1"";    case RELAY_COMMAND_RENDEZVOUS2: return ""RENDEZVOUS2"";    case RELAY_COMMAND_INTRO_ESTABLISHED: return ""INTRO_ESTABLISHED"";    case RELAY_COMMAND_RENDEZVOUS_ESTABLISHED:      return ""RENDEZVOUS_ESTABLISHED"";    case RELAY_COMMAND_INTRODUCE_ACK: return ""INTRODUCE_ACK"";    default: return ""(unrecognized)"";  }}",22268
108,420,CVE-2018-17204,13,"ofputil_pull_switch_features(struct ofpbuf *b,                             struct ofputil_switch_features *features){    const struct ofp_header *oh = b->data;    enum ofpraw raw = ofpraw_pull_assert(b);    const struct ofp_switch_features *osf = ofpbuf_pull(b, sizeof *osf);    features->datapath_id = ntohll(osf->datapath_id);    features->n_buffers = ntohl(osf->n_buffers);    features->n_tables = osf->n_tables;    features->auxiliary_id = 0;    features->capabilities = ntohl(osf->capabilities) &        ofputil_capabilities_mask(oh->version);    if (raw == OFPRAW_OFPT10_FEATURES_REPLY) {        if (osf->capabilities & htonl(OFPC10_STP)) {            features->capabilities |= OFPUTIL_C_STP;        }        features->ofpacts = ofpact_bitmap_from_openflow(osf->actions,                                                        OFP10_VERSION);    } else if (raw == OFPRAW_OFPT11_FEATURES_REPLY               || raw == OFPRAW_OFPT13_FEATURES_REPLY) {        if (osf->capabilities & htonl(OFPC11_GROUP_STATS)) {            features->capabilities |= OFPUTIL_C_GROUP_STATS;        }        features->ofpacts = 0;        if (raw == OFPRAW_OFPT13_FEATURES_REPLY) {            features->auxiliary_id = osf->auxiliary_id;        }    } else {        return OFPERR_OFPBRC_BAD_VERSION;    }    return 0;}",24155
6,202,CVE-2018-12714,14,"static void print_snapshot_help(struct seq_file *m, struct trace_iterator *iter){	if (iter->tr->allocated_snapshot)		seq_puts(m, ""#\n# * Snapshot is allocated *\n#\n"");	else		seq_puts(m, ""#\n# * Snapshot is freed *\n#\n"");	seq_puts(m, ""# Snapshot commands:\n"");	if (iter->cpu_file == RING_BUFFER_ALL_CPUS)		show_snapshot_main_help(m);	else		show_snapshot_percpu_help(m);}",24836
3,289,CVE-2018-12714,14,"static int tracing_eval_map_open(struct inode *inode, struct file *filp){	if (tracing_disabled)		return -ENODEV;	return seq_open(filp, &tracing_eval_map_seq_ops);}",24923
54,431,CVE-2019-13106,14,"int zfs_print(const char *entry, const struct zfs_dirhook_info *data){	printf(""%s %s\n"",		   data->dir ? ""<DIR> "" : ""		 "",		   entry);	return 0;  }",26776
53,411,CVE-2019-13106,14,"void reset_phy(void){	unsigned int oui;	unsigned char model, rev;	char *name = ""egiga0"";	if (miiphy_set_current_dev(name))		return;	 	miiphy_reset(name, CONFIG_PHY_BASE_ADR);	 	if (miiphy_info(name, CONFIG_PHY_BASE_ADR, &oui, &model, &rev))		return;	 	if ((oui == PHY_MARVELL_OUI) &&	    (model == PHY_MARVELL_88E1118R_MODEL)) {		 		if (miiphy_write(name, CONFIG_PHY_BASE_ADR,				 PHY_MARVELL_PAGE_REG,				 PHY_MARVELL_88E1118R_LED_CTRL_PAGE))			printf(""Error writing PHY page reg\n"");		 		if (miiphy_write(name, CONFIG_PHY_BASE_ADR,				 PHY_MARVELL_88E1118R_LED_CTRL_REG,				 PHY_MARVELL_88E1118R_LED_CTRL_RESERVED |				 PHY_MARVELL_88E1118R_LED_CTRL_LED0_1000MB |				 PHY_MARVELL_88E1118R_LED_CTRL_LED1_ACT |				 PHY_MARVELL_88E1118R_LED_CTRL_LED2_LINK))			printf(""Error writing PHY LED reg\n"");		 		if (miiphy_write(name, CONFIG_PHY_BASE_ADR,				 PHY_MARVELL_PAGE_REG,				 PHY_MARVELL_DEFAULT_PAGE))			printf(""Error writing PHY page reg\n"");	}}",26756
0,221,CVE-2018-12714,14,"static int snapshot_raw_open(struct inode *inode, struct file *filp){	struct ftrace_buffer_info *info;	int ret;	ret = tracing_buffers_open(inode, filp);	if (ret < 0)		return ret;	info = filp->private_data;	if (info->iter.trace->use_max_tr) {		tracing_buffers_release(inode, filp);		return -EBUSY;	}	info->iter.snapshot = true;	info->iter.trace_buffer = &info->iter.tr->max_buffer;	return ret;}",24855
80,174,CVE-2018-12714,14,"static int eval_map_show(struct seq_file *m, void *v){	union trace_eval_map_item *ptr = v;	seq_printf(m, ""%s %ld (%s)\n"",		   ptr->map.eval_string, ptr->map.eval_value,		   ptr->map.system);	return 0;}",24808
103,60,CVE-2017-9203,14,"static void iwbmpr_misc_config(struct iw_context *ctx, struct iwbmprcontext *rctx){	if(!rctx->topdown) {		iw_reorient_image(ctx,IW_REORIENT_FLIP_V);	}	iw_set_input_colorspace(ctx,&rctx->csdescr);	if(rctx->bitcount==16 || rctx->bitcount==32) {		if(rctx->bf_bits_count[0]!=8 || rctx->bf_bits_count[1]!=8 || rctx->bf_bits_count[2]!=8 ||			(IW_IMGTYPE_HAS_ALPHA(rctx->img->imgtype) && rctx->bf_bits_count[3]!=8))		{			iw_set_input_max_color_code(ctx,0, (1 << rctx->bf_bits_count[0])-1 );			iw_set_input_max_color_code(ctx,1, (1 << rctx->bf_bits_count[1])-1 );			iw_set_input_max_color_code(ctx,2, (1 << rctx->bf_bits_count[2])-1 );			if(IW_IMGTYPE_HAS_ALPHA(rctx->img->imgtype)) {				iw_set_input_max_color_code(ctx,3, (1 << rctx->bf_bits_count[3])-1 );			}		}	}}",20802
8,145,CVE-2018-12714,14,"void tasklet_init(struct tasklet_struct *t,		  void (*func)(unsigned long), unsigned long data){	t->next = NULL;	t->state = 0;	atomic_set(&t->count, 0);	t->func = func;	t->data = data;}",24779
50,57,CVE-2017-9203,14,static int iwbmp_write_bmp_header(struct iwbmpwcontext *wctx){	if(wctx->bmpversion==2) {		return iwbmp_write_bmp_v2header(wctx);	}	else if(wctx->bmpversion==5) {		if(!iwbmp_write_bmp_v3header(wctx)) return 0;		return iwbmp_write_bmp_v45header_fields(wctx);	}	return iwbmp_write_bmp_v3header(wctx);},20799
102,223,CVE-2018-12714,14,"static void t_stop(struct seq_file *m, void *p){	mutex_unlock(&trace_types_lock);}",24857
58,290,CVE-2018-12714,14,"tracing_free_buffer_release(struct inode *inode, struct file *filp){	struct trace_array *tr = inode->i_private;	 	if (tr->trace_flags & TRACE_ITER_STOP_ON_FREE)		tracer_tracing_off(tr);	 	tracing_resize_ring_buffer(tr, 0, RING_BUFFER_ALL_CPUS);	trace_array_put(tr);	return 0;}",24924
1,37,CVE-2016-9540,14,"processCompressOptions(char* opt){	if (streq(opt, ""none"")) {		defcompression = COMPRESSION_NONE;	} else if (streq(opt, ""packbits"")) {		defcompression = COMPRESSION_PACKBITS;	} else if (strneq(opt, ""jpeg"", 4)) {		char* cp = strchr(opt, ':');		defcompression = COMPRESSION_JPEG;		while( cp )		{			if (isdigit((int)cp[1]))				quality = atoi(cp+1);			else if (cp[1] == 'r' )				jpegcolormode = JPEGCOLORMODE_RAW;			else				usage();			cp = strchr(cp+1,':');		}	} else if (strneq(opt, ""g3"", 2)) {		processG3Options(opt);		defcompression = COMPRESSION_CCITTFAX3;	} else if (streq(opt, ""g4"")) {		defcompression = COMPRESSION_CCITTFAX4;	} else if (strneq(opt, ""lzw"", 3)) {		char* cp = strchr(opt, ':');		if (cp)			defpredictor = atoi(cp+1);		defcompression = COMPRESSION_LZW;	} else if (strneq(opt, ""zip"", 3)) {		processZIPOptions(opt);		defcompression = COMPRESSION_ADOBE_DEFLATE;	} else if (strneq(opt, ""lzma"", 4)) {		processZIPOptions(opt);		defcompression = COMPRESSION_LZMA;	} else if (strneq(opt, ""jbig"", 4)) {		defcompression = COMPRESSION_JBIG;	} else if (strneq(opt, ""sgilog"", 6)) {		defcompression = COMPRESSION_SGILOG;	} else		return (0);	return (1);}",15180
109,461,CVE-2017-5130,14,htmlHandleOmittedElem(int val) {    int old = htmlOmittedDefaultValue;    htmlOmittedDefaultValue = val;    return(old);},30150
107,445,CVE-2018-20763,14,"int getch() {	struct termios old;	struct termios new;	int rc;	if (tcgetattr(0, &old) == -1) {		return -1;	}	new = old;	new.c_lflag &= ~(ICANON | ECHO);	new.c_cc[VMIN] = 1;	new.c_cc[VTIME] = 0;	if (tcsetattr(0, TCSANOW, &new) == -1) {		return -1;	}	rc = getchar();	(void) tcsetattr(0, TCSANOW, &old);	return rc;}",27863
98,63,CVE-2017-9203,14,static int rle4_get_incr_unc_cost(struct rle_context *rlectx){	int n;	int m;	n = (int)rlectx->unc_len;	if(n==2 || n==255 || n==257 || n==507 || n==510) return 2;	if(n==256 || n==508) return 0;	if(n>=759) {		m = n%252;		if(m==3 || m==6 || m==9) return 2;		if(m==4 || m==8) return 0;	}	return (n%4)?0:2;},20805
37,310,CVE-2018-12714,14,"static int tracing_resize_saved_cmdlines(unsigned int val){	struct saved_cmdlines_buffer *s, *savedcmd_temp;	s = kmalloc(sizeof(*s), GFP_KERNEL);	if (!s)		return -ENOMEM;	if (allocate_cmdlines_buffer(val, s) < 0) {		kfree(s);		return -ENOMEM;	}	arch_spin_lock(&trace_cmdline_lock);	savedcmd_temp = savedcmd;	savedcmd = s;	arch_spin_unlock(&trace_cmdline_lock);	free_saved_cmdlines_buffer(savedcmd_temp);	return 0;}",24944
31,255,CVE-2018-12714,14,void trace_init_global_iter(struct trace_iterator *iter){	iter->tr = &global_trace;	iter->trace = iter->tr->current_trace;	iter->cpu_file = RING_BUFFER_ALL_CPUS;	iter->trace_buffer = &global_trace.trace_buffer;	if (iter->trace && iter->trace->open)		iter->trace->open(iter);	 	if (ring_buffer_overruns(iter->trace_buffer->buffer))		iter->iter_flags |= TRACE_FILE_ANNOTATE;	 	if (trace_clocks[iter->tr->clock_id].in_ns)		iter->iter_flags |= TRACE_FILE_TIME_IN_NS;},24889
10,334,CVE-2018-12714,14,"static int wait_on_pipe(struct trace_iterator *iter, int full){	 	if (trace_buffer_iter(iter, iter->cpu_file))		return 0;	return ring_buffer_wait(iter->trace_buffer->buffer, iter->cpu_file,				full);}",24968
44,45,CVE-2017-14041,14,static int int_floorlog2(int a){    int l;    for (l = 0; a > 1; l++) {        a >>= 1;    }    return l;},20229
17,436,CVE-2019-13106,14,"static int spl_fit_get_image_node(const void *fit, int images,				  const char *type, int index){	const char *str;	int err;	int node;	err = spl_fit_get_image_name(fit, images, type, index, &str);	if (err)		return err;	debug(""%s: '%s'\n"", type, str);	node = fdt_subnode_offset(fit, images, str);	if (node < 0) {		pr_err(""cannot find image node '%s': %d\n"", str, node);		return -EINVAL;	}	return node;}",26781
52,155,CVE-2018-12714,14,"int __trace_puts(unsigned long ip, const char *str, int size){	struct ring_buffer_event *event;	struct ring_buffer *buffer;	struct print_entry *entry;	unsigned long irq_flags;	int alloc;	int pc;	if (!(global_trace.trace_flags & TRACE_ITER_PRINTK))		return 0;	pc = preempt_count();	if (unlikely(tracing_selftest_running || tracing_disabled))		return 0;	alloc = sizeof(*entry) + size + 2;  	local_save_flags(irq_flags);	buffer = global_trace.trace_buffer.buffer;	event = __trace_buffer_lock_reserve(buffer, TRACE_PRINT, alloc, 					    irq_flags, pc);	if (!event)		return 0;	entry = ring_buffer_event_data(event);	entry->ip = ip;	memcpy(&entry->buf, str, size);	 	if (entry->buf[size - 1] != '\n') {		entry->buf[size] = '\n';		entry->buf[size + 1] = '\0';	} else		entry->buf[size] = '\0';	__buffer_unlock_commit(buffer, event);	ftrace_trace_stack(&global_trace, buffer, irq_flags, 4, pc, NULL);	return size;}",24789
68,192,CVE-2018-12714,14,"get_tracer_for_array(struct trace_array *tr, struct tracer *t){	while (t && !trace_ok_for_array(t, tr))		t = t->next;	return t;}",24826
32,426,CVE-2019-13106,14,"static int parse_integer(char **c, int *dst){	struct token t;	char *s = *c;	get_token(c, &t, L_SLITERAL);	if (t.type != T_STRING) {		printf(""Expected string: %.*s\n"", (int)(*c - s), s);		return -EINVAL;	}	*dst = simple_strtol(t.val, NULL, 10);	free(t.val);	return 1;}",26771
57,86,CVE-2017-7865,14,int av_get_exact_bits_per_sample(enum AVCodecID codec_id){    switch (codec_id) {    case AV_CODEC_ID_8SVX_EXP:    case AV_CODEC_ID_8SVX_FIB:    case AV_CODEC_ID_ADPCM_CT:    case AV_CODEC_ID_ADPCM_IMA_APC:    case AV_CODEC_ID_ADPCM_IMA_EA_SEAD:    case AV_CODEC_ID_ADPCM_IMA_OKI:    case AV_CODEC_ID_ADPCM_IMA_WS:    case AV_CODEC_ID_ADPCM_G722:    case AV_CODEC_ID_ADPCM_YAMAHA:    case AV_CODEC_ID_ADPCM_AICA:        return 4;    case AV_CODEC_ID_DSD_LSBF:    case AV_CODEC_ID_DSD_MSBF:    case AV_CODEC_ID_DSD_LSBF_PLANAR:    case AV_CODEC_ID_DSD_MSBF_PLANAR:    case AV_CODEC_ID_PCM_ALAW:    case AV_CODEC_ID_PCM_MULAW:    case AV_CODEC_ID_PCM_S8:    case AV_CODEC_ID_PCM_S8_PLANAR:    case AV_CODEC_ID_PCM_U8:    case AV_CODEC_ID_PCM_ZORK:    case AV_CODEC_ID_SDX2_DPCM:        return 8;    case AV_CODEC_ID_PCM_S16BE:    case AV_CODEC_ID_PCM_S16BE_PLANAR:    case AV_CODEC_ID_PCM_S16LE:    case AV_CODEC_ID_PCM_S16LE_PLANAR:    case AV_CODEC_ID_PCM_U16BE:    case AV_CODEC_ID_PCM_U16LE:        return 16;    case AV_CODEC_ID_PCM_S24DAUD:    case AV_CODEC_ID_PCM_S24BE:    case AV_CODEC_ID_PCM_S24LE:    case AV_CODEC_ID_PCM_S24LE_PLANAR:    case AV_CODEC_ID_PCM_U24BE:    case AV_CODEC_ID_PCM_U24LE:        return 24;    case AV_CODEC_ID_PCM_S32BE:    case AV_CODEC_ID_PCM_S32LE:    case AV_CODEC_ID_PCM_S32LE_PLANAR:    case AV_CODEC_ID_PCM_U32BE:    case AV_CODEC_ID_PCM_U32LE:    case AV_CODEC_ID_PCM_F32BE:    case AV_CODEC_ID_PCM_F32LE:    case AV_CODEC_ID_PCM_F24LE:    case AV_CODEC_ID_PCM_F16LE:        return 32;    case AV_CODEC_ID_PCM_F64BE:    case AV_CODEC_ID_PCM_F64LE:    case AV_CODEC_ID_PCM_S64BE:    case AV_CODEC_ID_PCM_S64LE:        return 64;    default:        return 0;    }},21466
66,283,CVE-2018-12714,14,"int tracing_alloc_snapshot(void){	WARN_ONCE(1, ""Snapshot feature not enabled, but snapshot allocation used"");	return -ENODEV;}",24917
81,350,CVE-2018-12714,14,"static inline void event_set_filter(struct trace_event_file *file,				    struct event_filter *filter){	rcu_assign_pointer(file->filter, filter);}",24984
72,42,CVE-2017-17806,14,"static int crypto_shash_report(struct sk_buff *skb, struct crypto_alg *alg){	struct crypto_report_hash rhash;	struct shash_alg *salg = __crypto_shash_alg(alg);	strncpy(rhash.type, ""shash"", sizeof(rhash.type));	rhash.blocksize = alg->cra_blocksize;	rhash.digestsize = salg->digestsize;	if (nla_put(skb, CRYPTOCFGA_REPORT_HASH,		    sizeof(struct crypto_report_hash), &rhash))		goto nla_put_failure;	return 0;nla_put_failure:	return -EMSGSIZE;}",19572
18,371,CVE-2018-12714,14,void ftrace_profile_free_filter(struct perf_event *event){	struct event_filter *filter = event->filter;	event->filter = NULL;	__free_filter(filter);},25005
41,88,CVE-2017-7865,14,"int av_lockmgr_register(int (*cb)(void **mutex, enum AVLockOp op)){    if (lockmgr_cb) {        lockmgr_cb(&codec_mutex,    AV_LOCK_DESTROY);        lockmgr_cb(&avformat_mutex, AV_LOCK_DESTROY);        lockmgr_cb     = NULL;        codec_mutex    = NULL;        avformat_mutex = NULL;    }    if (cb) {        void *new_codec_mutex    = NULL;        void *new_avformat_mutex = NULL;        int err;        if (err = cb(&new_codec_mutex, AV_LOCK_CREATE)) {            return err > 0 ? AVERROR_UNKNOWN : err;        }        if (err = cb(&new_avformat_mutex, AV_LOCK_CREATE)) {            cb(&new_codec_mutex, AV_LOCK_DESTROY);            return err > 0 ? AVERROR_UNKNOWN : err;        }        lockmgr_cb     = cb;        codec_mutex    = new_codec_mutex;        avformat_mutex = new_avformat_mutex;    }    return 0;}",21468
92,204,CVE-2018-12714,14,"static enum print_line_t print_trace_fmt(struct trace_iterator *iter){	struct trace_array *tr = iter->tr;	struct trace_seq *s = &iter->seq;	unsigned long sym_flags = (tr->trace_flags & TRACE_ITER_SYM_MASK);	struct trace_entry *entry;	struct trace_event *event;	entry = iter->ent;	test_cpu_buff_start(iter);	event = ftrace_find_event(entry->type);	if (tr->trace_flags & TRACE_ITER_CONTEXT_INFO) {		if (iter->iter_flags & TRACE_FILE_LAT_FMT)			trace_print_lat_context(iter);		else			trace_print_context(iter);	}	if (trace_seq_has_overflowed(s))		return TRACE_TYPE_PARTIAL_LINE;	if (event)		return event->funcs->trace(iter, sym_flags, event);	trace_seq_printf(s, ""Unknown type %d\n"", entry->type);	return trace_handle_return(s);}",24838
101,156,CVE-2018-12714,14,"void __trace_stack(struct trace_array *tr, unsigned long flags, int skip,		   int pc){	struct ring_buffer *buffer = tr->trace_buffer.buffer;	if (rcu_is_watching()) {		__ftrace_trace_stack(buffer, flags, skip, pc, NULL);		return;	}	 	if (unlikely(in_nmi()))		return;	rcu_irq_enter_irqson();	__ftrace_trace_stack(buffer, flags, skip, pc, NULL);	rcu_irq_exit_irqson();}",24790
12,26,CVE-2016-9540,14,"DECLAREcpFunc(cpContigStrips2ContigTiles){	return cpImage(in, out,	    readContigStripsIntoBuffer,	    writeBufferToContigTiles,	    imagelength, imagewidth, spp);}",15169
4,298,CVE-2018-12714,14,void tracing_on(void){	tracer_tracing_on(&global_trace);},24932
49,339,CVE-2018-12714,14,"static void append_filter_err(struct filter_parse_error *pe,			      struct event_filter *filter){	struct trace_seq *s;	int pos = pe->lasterr_pos;	char *buf;	int len;	if (WARN_ON(!filter->filter_string))		return;	s = kmalloc(sizeof(*s), GFP_KERNEL);	if (!s)		return;	trace_seq_init(s);	len = strlen(filter->filter_string);	if (pos > len)		pos = len;	 	if (pos)		pos++;	trace_seq_puts(s, filter->filter_string);	if (pe->lasterr > 0) {		trace_seq_printf(s, ""\n%*s"", pos, ""^"");		trace_seq_printf(s, ""\nparse_error: %s\n"", err_text[pe->lasterr]);	} else {		trace_seq_printf(s, ""\nError: (%d)\n"", pe->lasterr);	}	trace_seq_putc(s, 0);	buf = kmemdup_nul(s->buffer, s->seq.len, GFP_KERNEL);	if (buf) {		kfree(filter->filter_string);		filter->filter_string = buf;	}	kfree(s);}",24973
55,335,CVE-2018-12714,14,static void __free_filter(struct event_filter *filter){	if (!filter)		return;	free_prog(filter);	kfree(filter->filter_string);	kfree(filter);},24969
25,281,CVE-2018-12714,14,void tracer_tracing_on(struct trace_array *tr){	if (tr->trace_buffer.buffer)		ring_buffer_record_on(tr->trace_buffer.buffer);	 	tr->buffer_disabled = 0;	 	smp_wmb();},24915
75,456,CVE-2018-6063,14,  void SimulateBufferDestroyed(int buffer_id) {    video_capture_impl_->OnBufferDestroyed(buffer_id);  },30128
74,282,CVE-2018-12714,14,int tracing_alloc_snapshot(void){	struct trace_array *tr = &global_trace;	int ret;	ret = tracing_alloc_snapshot_instance(tr);	WARN_ON(ret < 0);	return ret;},24916
35,212,CVE-2018-12714,14,"static int save_selftest(struct tracer *type){	struct trace_selftests *selftest;	selftest = kmalloc(sizeof(*selftest), GFP_KERNEL);	if (!selftest)		return -ENOMEM;	selftest->type = type;	list_add(&selftest->list, &postponed_selftests);	return 0;}",24846
29,349,CVE-2018-12714,14,event_no_set_filter_flag(struct trace_event_file *file){	if (file->flags & EVENT_FILE_FL_NO_SET_FILTER)		return true;	return false;},24983
21,314,CVE-2018-12714,14,"static int tracing_single_release_tr(struct inode *inode, struct file *file){	struct trace_array *tr = inode->i_private;	trace_array_put(tr);	return single_release(inode, file);}",24948
40,446,CVE-2018-20763,14,int getch() {	return getchar();},27864
56,458,CVE-2018-6063,14,  void increase_released_buffer_count() { released_buffer_count_++; },30130
85,148,CVE-2018-12714,14,static void wakeup_softirqd(void){	 	struct task_struct *tsk = __this_cpu_read(ksoftirqd);	if (tsk && tsk->state != TASK_RUNNING)		wake_up_process(tsk);},24782
7,369,CVE-2018-12714,14,"static int ftrace_function_set_filter_pred(struct filter_pred *pred,					   struct function_filter_data *data){	int ret;	 	ret = ftrace_function_check_pred(pred);	if (ret)		return ret;	return __ftrace_function_set_filter(pred->op == OP_EQ,					    pred->regex.pattern,					    pred->regex.len,					    data);}",25003
87,139,CVE-2018-12714,14,"void open_softirq(int nr, void (*action)(struct softirq_action *)){	softirq_vec[nr].action = action;}",24773
43,408,CVE-2019-13106,14,"int mvebu_board_spi_claim_bus(struct udevice *dev){	spi_mpp_backup[3] = 0;	 	kirkwood_mpp_conf(spi_mpp_config, spi_mpp_backup);	kw_gpio_set_value(KM_FLASH_GPIO_PIN, 0);	return 0;}",26753
23,438,CVE-2019-13106,14,"struct blk_desc *blk_get_dev(const char *ifname, int dev){	return NULL;}",26783
86,24,CVE-2016-9755,14,static int nf_ct_net_init(struct net *net){	int res;	net->nf_frag.frags.high_thresh = IPV6_FRAG_HIGH_THRESH;	net->nf_frag.frags.low_thresh = IPV6_FRAG_LOW_THRESH;	net->nf_frag.frags.timeout = IPV6_FRAG_TIMEOUT;	res = inet_frags_init_net(&net->nf_frag.frags);	if (res)		return res;	res = nf_ct_frag6_sysctl_register(net);	if (res)		inet_frags_uninit_net(&net->nf_frag.frags);	return res;},15110
78,175,CVE-2018-12714,14,"static void eval_map_stop(struct seq_file *m, void *v){	mutex_unlock(&trace_eval_mutex);}",24809
65,142,CVE-2018-12714,14,static void run_ksoftirqd(unsigned int cpu){	local_irq_disable();	if (local_softirq_pending()) {		 		__do_softirq();		local_irq_enable();		cond_resched();		return;	}	local_irq_enable();},24776
110,457,CVE-2018-6063,14,  void StopCapture(int client_id) {     video_capture_impl_->StopCapture(client_id);   },30129
90,325,CVE-2018-12714,14,"static int tracing_time_stamp_mode_open(struct inode *inode, struct file *file){	struct trace_array *tr = inode->i_private;	int ret;	if (tracing_disabled)		return -ENODEV;	if (trace_array_get(tr))		return -ENODEV;	ret = single_open(file, tracing_time_stamp_mode_show, inode->i_private);	if (ret < 0)		trace_array_put(tr);	return ret;}",24959
104,51,CVE-2017-9949,14,"grub_ext2_read_inode (struct grub_ext2_data *data,		      int ino, struct grub_ext2_inode *inode){  struct grub_ext2_block_group blkgrp;  struct grub_ext2_sblock *sblock = &data->sblock;  int inodes_per_block;  unsigned int blkno;  unsigned int blkoff;     ino--;  int div = grub_le_to_cpu32 (sblock->inodes_per_group);  if (div < 1) {    return grub_errno = GRUB_ERR_BAD_FS;  }  grub_ext2_blockgroup (data, ino / div, &blkgrp);  if (grub_errno)    return grub_errno;  int inode_size = EXT2_INODE_SIZE (data);  if (inode_size < 1) {    return grub_errno = GRUB_ERR_BAD_FS;  }  inodes_per_block = EXT2_BLOCK_SIZE (data) / inode_size;  if (inodes_per_block < 1) {    return grub_errno = GRUB_ERR_BAD_FS;  }  blkno = (ino % grub_le_to_cpu32 (sblock->inodes_per_group))    / inodes_per_block;  blkoff = (ino % grub_le_to_cpu32 (sblock->inodes_per_group))    % inodes_per_block;     if (grub_disk_read (data->disk,		      ((grub_le_to_cpu32 (blkgrp.inode_table_id) + blkno)		        << LOG2_EXT2_BLOCK_SIZE (data)),		      EXT2_INODE_SIZE (data) * blkoff,		      sizeof (struct grub_ext2_inode), inode))    return grub_errno;  return 0;}",20701
9,13,CVE-2016-7170,14,"static int vmsvga_post_load(void *opaque, int version_id){    struct vmsvga_state_s *s = opaque;    s->invalidated = 1;    if (s->config) {        s->fifo = (int *) s->fifo_ptr;    }    return 0;}",1367
59,219,CVE-2018-12714,14,"static void show_snapshot_main_help(struct seq_file *m){	seq_puts(m, ""# echo 0 > snapshot : Clears and frees snapshot buffer\n""		    ""# echo 1 > snapshot : Allocates snapshot buffer, if not already allocated.\n""		    ""#                      Takes a snapshot of the main buffer.\n""		    ""# echo 2 > snapshot : Clears snapshot buffer (but does not allocate or free)\n""		    ""#                      (Doesn't have to be '2' works with any number that\n""		    ""#                       is not a '0' or '1')\n"");}",24853
19,274,CVE-2018-12714,14,"trace_process_export(struct trace_export *export,	       struct ring_buffer_event *event){	struct trace_entry *entry;	unsigned int size = 0;	entry = ring_buffer_event_data(event);	size = ring_buffer_event_length(event);	export->write(export, entry, size);}",24908
106,91,CVE-2017-7865,14,"enum AVChromaLocation avcodec_chroma_pos_to_enum(int xpos, int ypos){    int pos, xout, yout;    for (pos = AVCHROMA_LOC_UNSPECIFIED + 1; pos < AVCHROMA_LOC_NB; pos++) {        if (avcodec_enum_to_chroma_pos(&xout, &yout, pos) == 0 && xout == xpos && yout == ypos)            return pos;    }    return AVCHROMA_LOC_UNSPECIFIED;}",21471
112,318,CVE-2018-12714,14,void tracing_snapshot_alloc(void){	 	tracing_snapshot();},24952
67,462,CVE-2017-5130,14,"htmlInitAutoClose(void) {    int indx, i = 0;    if (htmlStartCloseIndexinitialized) return;    for (indx = 0;indx < 100;indx ++) htmlStartCloseIndex[indx] = NULL;    indx = 0;    while ((htmlStartClose[i] != NULL) && (indx < 100 - 1)) {        htmlStartCloseIndex[indx++] = (const char**) &htmlStartClose[i];	while (htmlStartClose[i] != NULL) i++;	i++;    }    htmlStartCloseIndexinitialized = 1;}",30151
83,112,CVE-2018-19198,14,"	void testQueryListPair() {		testQueryListPairHelper(""one+two+%26+three=%2B"", ""one two & three"", ""+"");		testQueryListPairHelper(""one=two=three"", ""one"", ""two=three"", ""one=two%3Dthree"");		testQueryListPairHelper(""one=two=three=four"", ""one"", ""two=three=four"", ""one=two%3Dthree%3Dfour"");	}",23358
15,437,CVE-2019-13106,14,"struct blk_desc *blk_get_dev(const char *ifname, int dev){	return get_dev_hwpart(ifname, dev, 0);}",26782
89,373,CVE-2018-12714,14,static int is_not(const char *str){	switch (str[1]) {	case '=':	case '~':		return false;	}	return true;},25007
22,316,CVE-2018-12714,14,"void tracing_snapshot(void){	WARN_ONCE(1, ""Snapshot feature not enabled, but internal snapshot used"");}",24950
34,147,CVE-2018-12714,14,"void tasklet_kill_immediate(struct tasklet_struct *t, unsigned int cpu){	struct tasklet_struct **i;	BUG_ON(cpu_online(cpu));	BUG_ON(test_bit(TASKLET_STATE_RUN, &t->state));	if (!test_bit(TASKLET_STATE_SCHED, &t->state))		return;	 	for (i = &per_cpu(tasklet_vec, cpu).head; *i; i = &(*i)->next) {		if (*i == t) {			*i = t->next;			 			if (*i == NULL)				per_cpu(tasklet_vec, cpu).tail = i;			return;		}	}	BUG();}",24781
115,386,CVE-2018-1068,14,"static int compat_table_info(const struct ebt_table_info *info,			     struct compat_ebt_replace *newinfo){	unsigned int size = info->entries_size;	const void *entries = info->entries;	newinfo->entries_size = size;	xt_compat_init_offsets(NFPROTO_BRIDGE, info->nentries);	return EBT_ENTRY_ITERATE(entries, size, compat_calc_entry, info,							entries, newinfo);}",25554
111,70,CVE-2017-9203,14,static int iw_imgtype_alpha_channel_index(int t){	switch(t) {	case IW_IMGTYPE_RGBA:		return 3;	case IW_IMGTYPE_GRAYA:		return 1;	}	return 0;},20812
38,107,CVE-2018-19198,14,"	void testFilenameUriConversion() {		const int FOR_UNIX = true;		const int FOR_WINDOWS = false;		testFilenameUriConversionHelper(L""/bin/bash"", L""file:///bin/bash"", FOR_UNIX);		testFilenameUriConversionHelper(L""/bin/bash"", L""file:/bin/bash"", FOR_UNIX, L""file:///bin/bash"");		testFilenameUriConversionHelper(L""./configure"", L""./configure"", FOR_UNIX);		testFilenameUriConversionHelper(L""E:\\Documents and Settings"", L""file:///E:/Documents%20and%20Settings"", FOR_WINDOWS);		testFilenameUriConversionHelper(L""c:\\path\\to\\file.txt"", L""file:c:/path/to/file.txt"", FOR_WINDOWS, L""file:///c:/path/to/file.txt"");		testFilenameUriConversionHelper(L"".\\Readme.txt"", L""./Readme.txt"", FOR_WINDOWS);		testFilenameUriConversionHelper(L""index.htm"", L""index.htm"", FOR_WINDOWS);		testFilenameUriConversionHelper(L""index.htm"", L""index.htm"", FOR_UNIX);		testFilenameUriConversionHelper(L""abc def"", L""abc%20def"", FOR_WINDOWS);		testFilenameUriConversionHelper(L""abc def"", L""abc%20def"", FOR_UNIX);		testFilenameUriConversionHelper(L""\\\\Server01\\user\\docs\\Letter.txt"", L""file://Server01/user/docs/Letter.txt"", FOR_WINDOWS);	}",23353
100,270,CVE-2018-12714,14,"int trace_pid_show(struct seq_file *m, void *v){	unsigned long pid = (unsigned long)v - 1;	seq_printf(m, ""%lu\n"", pid);	return 0;}",24904
27,83,CVE-2017-7866,14,"void ff_add_png_paeth_prediction(int *dst, int *src, int *top,                                 int w, int bpp){    int i;    for (i = 0; i < w; i++) {        int a, b, c, p, pa, pb, pc;        a = dst[i - bpp];        b = top[i];        c = top[i - bpp];        p  = b - c;        pc = a - c;        pa = abs(p);        pb = abs(pc);        pc = abs(p + pc);        if (pa <= pb && pa <= pc)            p = a;        else if (pb <= pc)            p = b;        else            p = c;        dst[i] = p + src[i];    }}",21463
71,103,CVE-2017-6439,14,void plist_bin_deinit(void){     },21796
64,102,CVE-2017-6439,14,"static int is_ascii_string(char* s, int len){  int ret = 1, i = 0;  for(i = 0; i < len; i++)  {      if ( !isascii( s[i] ) )      {          ret = 0;          break;      }  }  return ret;}",21795
33,168,CVE-2018-12714,14,"create_trace_option_core_file(struct trace_array *tr,			      const char *option, long index){	struct dentry *t_options;	t_options = trace_options_init_dentry(tr);	if (!t_options)		return NULL;	return trace_create_file(option, 0644, t_options,				 (void *)&tr->trace_flags_index[index],				 &trace_options_core_fops);}",24802
114,429,CVE-2019-13106,14,"static int parse_label_menu(char **c, struct pxe_menu *cfg,			    struct pxe_label *label){	struct token t;	char *s;	s = *c;	get_token(c, &t, L_KEYWORD);	switch (t.type) {	case T_DEFAULT:		if (!cfg->default_label)			cfg->default_label = strdup(label->name);		if (!cfg->default_label)			return -ENOMEM;		break;	case T_LABEL:		parse_sliteral(c, &label->menu);		break;	default:		printf(""Ignoring malformed menu command: %.*s\n"",		       (int)(*c - s), s);	}	eol_or_eof(c);	return 0;}",26774
42,100,CVE-2017-7865,14,"static int get_audio_frame_duration(enum AVCodecID id, int sr, int ch, int ba,                                    int tag, int bits_per_coded_sample, int bitrate,                                    int * extradata, int frame_size, int frame_bytes){    int bps = av_get_exact_bits_per_sample(id);    int framecount = (ba > 0 && frame_bytes / ba > 0) ? frame_bytes / ba : 1;         if (bps > 0 && ch > 0 && frame_bytes > 0 && ch < 32768 && bps < 32768)        return (frame_bytes * 8LL) / (bps * ch);    bps = bits_per_coded_sample;         switch (id) {    case AV_CODEC_ID_ADPCM_ADX:    return   32;    case AV_CODEC_ID_ADPCM_IMA_QT: return   64;    case AV_CODEC_ID_ADPCM_EA_XAS: return  128;    case AV_CODEC_ID_AMR_NB:    case AV_CODEC_ID_EVRC:    case AV_CODEC_ID_GSM:    case AV_CODEC_ID_QCELP:    case AV_CODEC_ID_RA_288:       return  160;    case AV_CODEC_ID_AMR_WB:    case AV_CODEC_ID_GSM_MS:       return  320;    case AV_CODEC_ID_MP1:          return  384;    case AV_CODEC_ID_ATRAC1:       return  512;    case AV_CODEC_ID_ATRAC3:       return 1024 * framecount;    case AV_CODEC_ID_ATRAC3P:      return 2048;    case AV_CODEC_ID_MP2:    case AV_CODEC_ID_MUSEPACK7:    return 1152;    case AV_CODEC_ID_AC3:          return 1536;    }    if (sr > 0) {                 if (id == AV_CODEC_ID_TTA)            return 256 * sr / 245;        else if (id == AV_CODEC_ID_DST)            return 588 * sr / 44100;        if (ch > 0) {                         if (id == AV_CODEC_ID_BINKAUDIO_DCT)                return (480 << (sr / 22050)) / ch;        }    }    if (ba > 0) {                 if (id == AV_CODEC_ID_SIPR) {            switch (ba) {            case 20: return 160;            case 19: return 144;            case 29: return 288;            case 37: return 480;            }        } else if (id == AV_CODEC_ID_ILBC) {            switch (ba) {            case 38: return 160;            case 50: return 240;            }        }    }    if (frame_bytes > 0) {                 if (id == AV_CODEC_ID_TRUESPEECH)            return 240 * (frame_bytes / 32);        if (id == AV_CODEC_ID_NELLYMOSER)            return 256 * (frame_bytes / 64);        if (id == AV_CODEC_ID_RA_144)            return 160 * (frame_bytes / 20);        if (id == AV_CODEC_ID_G723_1)            return 240 * (frame_bytes / 24);        if (bps > 0) {                         if (id == AV_CODEC_ID_ADPCM_G726)                return frame_bytes * 8 / bps;        }        if (ch > 0 && ch < INT_MAX/16) {                         switch (id) {            case AV_CODEC_ID_ADPCM_AFC:                return frame_bytes / (9 * ch) * 16;            case AV_CODEC_ID_ADPCM_PSX:            case AV_CODEC_ID_ADPCM_DTK:                return frame_bytes / (16 * ch) * 28;            case AV_CODEC_ID_ADPCM_4XM:            case AV_CODEC_ID_ADPCM_IMA_DAT4:            case AV_CODEC_ID_ADPCM_IMA_ISS:                return (frame_bytes - 4 * ch) * 2 / ch;            case AV_CODEC_ID_ADPCM_IMA_SMJPEG:                return (frame_bytes - 4) * 2 / ch;            case AV_CODEC_ID_ADPCM_IMA_AMV:                return (frame_bytes - 8) * 2 / ch;            case AV_CODEC_ID_ADPCM_THP:            case AV_CODEC_ID_ADPCM_THP_LE:                if (extradata)                    return frame_bytes * 14 / (8 * ch);                break;            case AV_CODEC_ID_ADPCM_XA:                return (frame_bytes / 128) * 224 / ch;            case AV_CODEC_ID_INTERPLAY_DPCM:                return (frame_bytes - 6 - ch) / ch;            case AV_CODEC_ID_ROQ_DPCM:                return (frame_bytes - 8) / ch;            case AV_CODEC_ID_XAN_DPCM:                return (frame_bytes - 2 * ch) / ch;            case AV_CODEC_ID_MACE3:                return 3 * frame_bytes / ch;            case AV_CODEC_ID_MACE6:                return 6 * frame_bytes / ch;            case AV_CODEC_ID_PCM_LXF:                return 2 * (frame_bytes / (5 * ch));            case AV_CODEC_ID_IAC:            case AV_CODEC_ID_IMC:                return 4 * frame_bytes / ch;            }            if (tag) {                                 if (id == AV_CODEC_ID_SOL_DPCM) {                    if (tag == 3)                        return frame_bytes / ch;                    else                        return frame_bytes * 2 / ch;                }            }            if (ba > 0) {                                 int blocks = frame_bytes / ba;                switch (id) {                case AV_CODEC_ID_ADPCM_IMA_WAV:                    if (bps < 2 || bps > 5)                        return 0;                    return blocks * (1 + (ba - 4 * ch) / (bps * ch) * 8);                case AV_CODEC_ID_ADPCM_IMA_DK3:                    return blocks * (((ba - 16) * 2 / 3 * 4) / ch);                case AV_CODEC_ID_ADPCM_IMA_DK4:                    return blocks * (1 + (ba - 4 * ch) * 2 / ch);                case AV_CODEC_ID_ADPCM_IMA_RAD:                    return blocks * ((ba - 4 * ch) * 2 / ch);                case AV_CODEC_ID_ADPCM_MS:                    return blocks * (2 + (ba - 7 * ch) * 2 / ch);                case AV_CODEC_ID_ADPCM_MTAF:                    return blocks * (ba - 16) * 2 / ch;                }            }            if (bps > 0) {                                 switch (id) {                case AV_CODEC_ID_PCM_DVD:                    if(bps<4)                        return 0;                    return 2 * (frame_bytes / ((bps * 2 / 8) * ch));                case AV_CODEC_ID_PCM_BLURAY:                    if(bps<4)                        return 0;                    return frame_bytes / ((FFALIGN(ch, 2) * bps) / 8);                case AV_CODEC_ID_S302M:                    return 2 * (frame_bytes / ((bps + 4) / 4)) / ch;                }            }        }    }         if (frame_size > 1 && frame_bytes)        return frame_size;    if (bitrate > 0 && frame_bytes > 0 && sr > 0 && ba > 1) {        if (id == AV_CODEC_ID_WMAV1 || id == AV_CODEC_ID_WMAV2)            return  (frame_bytes * 8LL * sr) / bitrate;    }    return 0;}",21480
5,403,CVE-2019-13106,14,int ethernet_present(void){	return 1;},26748
26,133,CVE-2018-12714,14,static int ksoftirqd_running(void){	struct task_struct *tsk = __this_cpu_read(ksoftirqd);	return tsk && (tsk->state == TASK_RUNNING);},24767
93,210,CVE-2018-12714,14,static inline int run_tracer_selftest(struct tracer *type){	return 0;},24844
77,16,CVE-2016-7170,14,"static inline void vmsvga_update_rect_delayed(struct vmsvga_state_s *s,                int x, int y, int w, int h){    struct vmsvga_rect_s *rect = &s->redraw_fifo[s->redraw_fifo_last++];    s->redraw_fifo_last &= REDRAW_FIFO_LEN - 1;    rect->x = x;    rect->y = y;    rect->w = w;    rect->h = h;}",1370
99,225,CVE-2018-12714,14,"static void test_ftrace_alive(struct seq_file *m){	if (!ftrace_is_dead())		return;	seq_puts(m, ""# WARNING: FUNCTION TRACING IS CORRUPTED\n""		    ""#          MAY BE MISSING FUNCTION EVENTS\n"");}",24859
47,9,CVE-2016-7170,14,static inline int vmsvga_fifo_read_raw(struct vmsvga_state_s *s){    int cmd = s->fifo[s->fifo_stop >> 2];    s->fifo_stop += 4;    if (s->fifo_stop >= s->fifo_max) {        s->fifo_stop = s->fifo_min;    }    s->fifo[SVGA_FIFO_STOP] = cpu_to_le32(s->fifo_stop);    return cmd;},1363
96,46,CVE-2017-14041,14,"static char *skip_idf(char *start, char out_idf[256]){    char *s;    char c;    s = skip_white(start);    if (s == NULL) {        return NULL;    }    start = s;    while (*s) {        if (isalpha(*s) || *s == '_') {            ++s;            continue;        }        break;    }    c = *s;    *s = 0;    strncpy(out_idf, start, 255);    *s = c;    return s;}",20230
84,292,CVE-2018-12714,14,static struct dentry *tracing_get_dentry(struct trace_array *tr){	if (WARN_ON(!tr->dir))		return ERR_PTR(-ENODEV);	 	if (tr->flags & TRACE_ARRAY_FL_GLOBAL)		return NULL;	 	return tr->dir;},24926
48,166,CVE-2018-12714,14,"static void buffer_spd_release(struct splice_pipe_desc *spd, unsigned int i){	struct buffer_ref *ref =		(struct buffer_ref *)spd->partial[i].private;	if (--ref->ref)		return;	ring_buffer_free_read_page(ref->buffer, ref->cpu, ref->page);	kfree(ref);	spd->partial[i].private = 0;}",24800
116,236,CVE-2018-12714,14,int trace_clock_in_ns(struct trace_array *tr){	if (trace_clocks[tr->clock_id].in_ns)		return true;	return false;},24870
88,276,CVE-2018-12714,14,"static int trace_save_cmdline(struct task_struct *tsk){	unsigned pid, idx;	 	if (!tsk->pid)		return 1;	if (unlikely(tsk->pid > PID_MAX_DEFAULT))		return 0;	 	if (!arch_spin_trylock(&trace_cmdline_lock))		return 0;	idx = savedcmd->map_pid_to_cmdline[tsk->pid];	if (idx == NO_CMDLINE_MAP) {		idx = (savedcmd->cmdline_idx + 1) % savedcmd->cmdline_num;		 		pid = savedcmd->map_cmdline_to_pid[idx];		if (pid != NO_CMDLINE_MAP)			savedcmd->map_pid_to_cmdline[pid] = NO_CMDLINE_MAP;		savedcmd->map_cmdline_to_pid[idx] = tsk->pid;		savedcmd->map_pid_to_cmdline[tsk->pid] = idx;		savedcmd->cmdline_idx = idx;	}	set_cmdline(idx, tsk->comm);	arch_spin_unlock(&trace_cmdline_lock);	return 1;}",24910
24,217,CVE-2018-12714,14,"static inline void set_cmdline(int idx, const char *cmdline){	memcpy(get_saved_cmdlines(idx), cmdline, TASK_COMM_LEN);}",24851
11,425,CVE-2019-13106,14,"static void label_print(void *data){	struct pxe_label *label = data;	const char *c = label->menu ? label->menu : label->name;	printf(""%s:\t%s\n"", label->num, c);}",26770
20,245,CVE-2018-12714,14,"trace_event_buffer_lock_reserve(struct ring_buffer **current_rb,			  struct trace_event_file *trace_file,			  int type, unsigned long len,			  unsigned long flags, int pc){	struct ring_buffer_event *entry;	int val;	*current_rb = trace_file->tr->trace_buffer.buffer;	if (!ring_buffer_time_stamp_abs(*current_rb) && (trace_file->flags &	     (EVENT_FILE_FL_SOFT_DISABLED | EVENT_FILE_FL_FILTERED)) &&	    (entry = this_cpu_read(trace_buffered_event))) {		 		val = this_cpu_inc_return(trace_buffered_event_cnt);		if (val == 1) {			trace_event_setup(entry, type, flags, pc);			entry->array[0] = len;			return entry;		}		this_cpu_dec(trace_buffered_event_cnt);	}	entry = __trace_buffer_lock_reserve(*current_rb,					    type, len, flags, pc);	 	if (!entry && trace_file->flags & EVENT_FILE_FL_TRIGGER_COND) {		*current_rb = temp_buffer;		entry = __trace_buffer_lock_reserve(*current_rb,						    type, len, flags, pc);	}	return entry;}",24879
105,222,CVE-2018-12714,14,"static int t_show(struct seq_file *m, void *v){	struct tracer *t = v;	if (!t)		return 0;	seq_puts(m, t->name);	if (t->next)		seq_putc(m, ' ');	else		seq_putc(m, '\n');	return 0;}",24856
13,347,CVE-2018-12714,14,event_clear_no_set_filter_flag(struct trace_event_file *file){	file->flags &= ~EVENT_FILE_FL_NO_SET_FILTER;},24981
79,122,CVE-2018-14681,14,"static struct kwajd_stream *lzh_init(struct mspack_system *sys,    struct mspack_file *in, struct mspack_file *out){    struct kwajd_stream *lzh;    if (!sys || !in || !out) return NULL;    if (!(lzh = (struct kwajd_stream *) sys->alloc(sys, sizeof(struct kwajd_stream)))) return NULL;    lzh->sys    = sys;    lzh->input  = in;    lzh->output = out;    return lzh;}",24448
76,333,CVE-2018-12714,14,static void update_tracer_options(struct trace_array *tr){	mutex_lock(&trace_types_lock);	__update_tracer_options(tr);	mutex_unlock(&trace_types_lock);},24967
82,164,CVE-2018-12714,14,"static void buffer_pipe_buf_get(struct pipe_inode_info *pipe,				struct pipe_buffer *buf){	struct buffer_ref *ref = (struct buffer_ref *)buf->private;	ref->ref++;}",24798
69,161,CVE-2018-12714,14,"add_trace_export(struct trace_export **list, struct trace_export *export){	rcu_assign_pointer(export->next, *list);	 	rcu_assign_pointer(*list, export);}",24795
39,151,CVE-2018-12714,14,static void __trace_array_put(struct trace_array *this_tr){	WARN_ON(!this_tr->ref);	this_tr->ref--;},24785
46,452,CVE-2018-6063,14,  SiteProcessCountTracker() {},30124
16,52,CVE-2017-9949,14,"grub_fshelp_log2blksize (unsigned int blksize, unsigned int *pow){  int mod;  *pow = 0;  while (blksize > 1)    {      mod = blksize - ((blksize >> 1) << 1);      blksize >>= 1;             if (mod)	return grub_error (GRUB_ERR_BAD_NUMBER,			   ""the blocksize is not a power of two"");      (*pow)++;    }  return GRUB_ERR_NONE;}",20702
63,294,CVE-2018-12714,14,int tracing_is_disabled(void){	return (tracing_disabled) ? true: false;},24928
97,400,CVE-2019-14495,14,"static void stdpr(struct printparam* pp, char *buf, int inbuf){	if((pp->inbuf + inbuf > 1024) || !buf) {		socksend(pp->cp->clisock, (unsigned char *)pp->buf, pp->inbuf, conf.timeouts[STRING_S]);		pp->inbuf = 0;		if(!buf) return;	}	if(inbuf >= 1000){		socksend(pp->cp->clisock, (unsigned char *)buf, inbuf, conf.timeouts[STRING_S]);			}	else {		memcpy(pp->buf + pp->inbuf, buf, inbuf);		pp->inbuf += inbuf;	}}",26694
14,191,CVE-2018-12714,14,static char *get_trace_buf(void){	struct trace_buffer_struct *buffer = this_cpu_ptr(trace_percpu_buffer);	if (!buffer || buffer->nesting >= 4)		return NULL;	buffer->nesting++;	 	barrier();	return &buffer->buffer[buffer->nesting][0];},24825
28,99,CVE-2017-7865,14,"int ff_match_2uint16(const int(*tab)[2], int size, int a, int b){    int i;    for (i = 0; i < size && !(tab[i][0] == a && tab[i][1] == b); i++) ;    return i;}",21479
95,295,CVE-2018-12714,14,int tracing_is_enabled(void){	 	smp_rmb();	return !global_trace.buffer_disabled;},24929
60,2,CVE-2016-7948,14,"_XRRHasOutputPrimary (int major, int minor){    return major > 1 || (major == 1 && minor >= 3);}",1318
51,80,CVE-2017-9203,14,"static void put_raw_sample(struct iw_context *ctx, double s,	   int x, int y, int channel){	switch(ctx->img2.bit_depth) {	case 8:  put_raw_sample_8(ctx,s,x,y,channel); break;	case 16: put_raw_sample_16(ctx,s,x,y,channel); break;	}}",20822
94,69,CVE-2017-9203,14,"static int iw_get_channeltype(int imgtype, int channel){	switch(imgtype) {	case IW_IMGTYPE_GRAY:		if(channel==0) return IW_CHANNELTYPE_GRAY;		break;	case IW_IMGTYPE_GRAYA:		if(channel==0) return IW_CHANNELTYPE_GRAY;		if(channel==1) return IW_CHANNELTYPE_ALPHA;		break;	case IW_IMGTYPE_RGB:		if(channel==0) return IW_CHANNELTYPE_RED;		if(channel==1) return IW_CHANNELTYPE_GREEN;		if(channel==2) return IW_CHANNELTYPE_BLUE;		break;	case IW_IMGTYPE_RGBA:		if(channel==0) return IW_CHANNELTYPE_RED;		if(channel==1) return IW_CHANNELTYPE_GREEN;		if(channel==2) return IW_CHANNELTYPE_BLUE;		if(channel==3) return IW_CHANNELTYPE_ALPHA;		break;	}	return 0;}",20811
91,141,CVE-2018-12714,14,inline void raise_softirq_irqoff(unsigned int nr){	__raise_softirq_irqoff(nr);	 	if (!in_interrupt())		wakeup_softirqd();},24775
61,416,CVE-2019-13106,14, unsigned long get_board_sys_clk(unsigned long dummy){	return 66666666;},26761
36,383,CVE-2018-12714,14,"static void update_preds(struct prog_entry *prog, int N, int invert){	int t, s;	t = prog[N].target;	s = prog[t].target;	prog[t].when_to_branch = invert;	prog[t].target = N;	prog[N].target = s;}",25017
113,414,CVE-2019-13106,14,"int checkboard(void){	printf(""Board: Keymile %s\n"", CONFIG_SYS_CONFIG_NAME); 	return 0; }",26759
73,261,CVE-2018-12714,14,"static void trace_module_add_evals(struct module *mod){	if (!mod->num_trace_evals)		return;	 	if (trace_module_has_bad_taint(mod))		return;	trace_insert_eval_map(mod, mod->trace_evals, mod->num_trace_evals);}",24895
70,301,CVE-2018-12714,14,"static int tracing_open_pipe(struct inode *inode, struct file *filp){	struct trace_array *tr = inode->i_private;	struct trace_iterator *iter;	int ret = 0;	if (tracing_disabled)		return -ENODEV;	if (trace_array_get(tr) < 0)		return -ENODEV;	mutex_lock(&trace_types_lock);	 	iter = kzalloc(sizeof(*iter), GFP_KERNEL);	if (!iter) {		ret = -ENOMEM;		__trace_array_put(tr);		goto out;	}	trace_seq_init(&iter->seq);	iter->trace = tr->current_trace;	if (!alloc_cpumask_var(&iter->started, GFP_KERNEL)) {		ret = -ENOMEM;		goto fail;	}	 	cpumask_setall(iter->started);	if (tr->trace_flags & TRACE_ITER_LATENCY_FMT)		iter->iter_flags |= TRACE_FILE_LAT_FMT;	 	if (trace_clocks[tr->clock_id].in_ns)		iter->iter_flags |= TRACE_FILE_TIME_IN_NS;	iter->tr = tr;	iter->trace_buffer = &tr->trace_buffer;	iter->cpu_file = tracing_get_cpu(inode);	mutex_init(&iter->mutex);	filp->private_data = iter;	if (iter->trace->pipe_open)		iter->trace->pipe_open(iter);	nonseekable_open(inode, filp);	tr->current_trace->ref++;out:	mutex_unlock(&trace_types_lock);	return ret;fail:	kfree(iter->trace);	kfree(iter);	__trace_array_put(tr);	mutex_unlock(&trace_types_lock);	return ret;}",24935
62,126,CVE-2018-14681,14,void mspack_destroy_kwaj_decompressor(struct mskwaj_decompressor *base){    struct mskwaj_decompressor_p *self = (struct mskwaj_decompressor_p *) base;    if (self) {	struct mspack_system *sys = self->system;	sys->free(self);    }},24452
30,277,CVE-2018-12714,14,static int trace_save_tgid(struct task_struct *tsk){	 	if (!tsk->pid)		return 1;	if (unlikely(!tgid_map || tsk->pid > PID_MAX_DEFAULT))		return 0;	tgid_map[tsk->pid] = tsk->tgid;	return 1;},24911
45,77,CVE-2017-9203,14,"static void iw_set_intermed_channeltypes(struct iw_context *ctx){	int i;	for(i=0;i<ctx->intermed_numchannels;i++) {		ctx->intermed_ci[i].channeltype = iw_get_channeltype(ctx->intermed_imgtype,i);	}}",20819
2,443,CVE-2018-20763,14,"void PrintHelp(){	fprintf(stderr, ""MP4Client command keys:\n""	        ""\tq: quit\n""	        ""\tX: kill\n""	        ""\to: connect to the specified URL\n""	        ""\tO: connect to the specified playlist\n""	        ""\tN: switch to the next URL in the playlist. Also works with \\n\n""	        ""\tP: jumps to a given number ahead in the playlist\n""	        ""\tr: reload current presentation\n""	        ""\tD: disconnects the current presentation\n""	        ""\tG: selects object or service ID\n""	        ""\n""	        ""\tp: play/pause the presentation\n""	        ""\ts: step one frame ahead\n""	        ""\tz: seek into presentation by percentage\n""	        ""\tT: seek into presentation by time\n""	        ""\tt: print current timing\n""	        ""\n""	        ""\tu: sends a command (BIFS or LASeR) to the main scene\n""	        ""\te: evaluates JavaScript code\n""	        ""\tZ: dumps output video to PNG\n""	        ""\n""	        ""\tw: view world info\n""	        ""\tv: view Object Descriptor list\n""	        ""\ti: view Object Descriptor info (by ID)\n""	        ""\tj: view Object Descriptor info (by number)\n""	        ""\tb: view media objects timing and buffering info\n""	        ""\tm: view media objects buffering and memory info\n""	        ""\td: dumps scene graph\n""	        ""\n""	        ""\tk: turns stress mode on/off\n""	        ""\tn: changes navigation mode\n""	        ""\tx: reset to last active viewpoint\n""	        ""\n""	        ""\t3: switch OpenGL on or off for 2D scenes\n""	        ""\n""	        ""\t4: forces 4/3 Aspect Ratio\n""	        ""\t5: forces 16/9 Aspect Ratio\n""	        ""\t6: forces no Aspect Ratio (always fill screen)\n""	        ""\t7: forces original Aspect Ratio (default)\n""	        ""\n""	        ""\tL: changes to new log level. CF MP4Client usage for possible values\n""	        ""\tT: select new tools to log. CF MP4Client usage for possible values\n""	        ""\n""	        ""\tl: list available modules\n""	        ""\tc: prints some GPAC configuration info\n""	        ""\tE: forces reload of GPAC configuration\n""	        ""\n""	        ""\tR: toggles run-time info display in window title bar on/off\n""	        ""\tF: toggle displaying of FPS in stderr on/off\n""	        ""\tg: print GPAC allocated memory\n""	        ""\th: print this message\n""	        ""\n""	        ""\tEXPERIMENTAL/UNSTABLE OPTIONS\n""	        ""\tC: Enable Streaming Cache\n""	        ""\tS: Stops Streaming Cache and save to file\n""	        ""\tA: Aborts Streaming Cache\n""	        ""\tM: specifies video cache memory for 2D objects\n""	        ""\n""	        ""MP4Client - GPAC command line player - version %s\n""	        ""GPAC Written by Jean Le Feuvre (c) 2001-2005 - ENST (c) 2005-200X\n"",	        GPAC_FULL_VERSION	       );}",27861
108,420,CVE-2019-13106,14,static void eol_or_eof(char **c){	while (**c && **c != '\n')		(*c)++;},26765
117,445,CVE-2018-20784,15,"static void task_fork_fair(struct task_struct *p){	struct cfs_rq *cfs_rq;	struct sched_entity *se = &p->se, *curr;	struct rq *rq = this_rq();	struct rq_flags rf;	rq_lock(rq, &rf);	update_rq_clock(rq);	cfs_rq = task_cfs_rq(current);	curr = cfs_rq->curr;	if (curr) {		update_curr(cfs_rq);		se->vruntime = curr->vruntime;	}	place_entity(cfs_rq, se, 1);	if (sysctl_sched_child_runs_first && curr && entity_before(curr, se)) {		 		swap(curr->vruntime, se->vruntime);		resched_curr(rq);	}	se->vruntime -= cfs_rq->min_vruntime;	rq_unlock(rq, &rf);}",27799
22,410,CVE-2018-20784,15,"static inline int propagate_entity_load_avg(struct sched_entity *se){	struct cfs_rq *cfs_rq, *gcfs_rq;	if (entity_is_task(se))		return 0;	gcfs_rq = group_cfs_rq(se);	if (!gcfs_rq->propagate)		return 0;	gcfs_rq->propagate = 0;	cfs_rq = cfs_rq_of(se);	add_tg_cfs_propagate(cfs_rq, gcfs_rq->prop_runnable_sum);	update_tg_cfs_util(cfs_rq, se, gcfs_rq);	update_tg_cfs_runnable(cfs_rq, se, gcfs_rq);	return 1;}",27764
67,2,CVE-2016-9915,15,"static inline int name_to_handle(int dirfd, const char *name,                                 struct file_handle *fh, int *mnt_id, int flags){    return name_to_handle_at(dirfd, name, fh, mnt_id, flags);}",1244
49,100,CVE-2016-8666,15,int netif_receive_skb(struct sk_buff *skb){	trace_netif_receive_skb_entry(skb);	return netif_receive_skb_internal(skb);},15416
122,318,CVE-2018-20784,15,"static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_flags){	struct task_struct *curr = rq->curr;	struct sched_entity *se = &curr->se, *pse = &p->se;	struct cfs_rq *cfs_rq = task_cfs_rq(curr);	int scale = cfs_rq->nr_running >= sched_nr_latency;	int next_buddy_marked = 0;	if (unlikely(se == pse))		return;	 	if (unlikely(throttled_hierarchy(cfs_rq_of(pse))))		return;	if (sched_feat(NEXT_BUDDY) && scale && !(wake_flags & WF_FORK)) {		set_next_buddy(pse);		next_buddy_marked = 1;	}	 	if (test_tsk_need_resched(curr))		return;	 	if (unlikely(task_has_idle_policy(curr)) &&	    likely(!task_has_idle_policy(p)))		goto preempt;	 	if (unlikely(p->policy != SCHED_NORMAL) || !sched_feat(WAKEUP_PREEMPTION))		return;	find_matching_se(&se, &pse);	update_curr(cfs_rq_of(se));	BUG_ON(!pse);	if (wakeup_preempt_entity(se, pse) == 1) {		 		if (!next_buddy_marked)			set_next_buddy(pse);		goto preempt;	}	return;preempt:	resched_curr(rq);	 	if (unlikely(!se->on_rq || curr == rq->idle))		return;	if (sched_feat(LAST_BUDDY) && scale && entity_is_task(se))		set_last_buddy(se);}",27672
59,155,CVE-2016-6213,15,static struct user_namespace *mntns_owner(struct ns_common *ns){	return to_mnt_ns(ns)->user_ns;},16177
3,37,CVE-2016-8666,15,"int dev_change_proto_down(struct net_device *dev, int proto_down){	const struct net_device_ops *ops = dev->netdev_ops;	if (!ops->ndo_change_proto_down)		return -EOPNOTSUPP;	if (!netif_device_present(dev))		return -ENODEV;	return ops->ndo_change_proto_down(dev, proto_down);}",15353
0,431,CVE-2018-20784,15,static inline int skip_blocked_update(struct sched_entity *se){	struct cfs_rq *gcfs_rq = group_cfs_rq(se);	 	if (se->avg.load_avg || se->avg.util_avg)		return false;	 	if (gcfs_rq->propagate)		return false;	 	return true;},27785
120,457,CVE-2018-20784,15,static inline unsigned long task_util(struct task_struct *p){	return READ_ONCE(p->se.avg.util_avg);},27811
66,219,CVE-2018-20169,15,"static int usb_dev_uevent(struct device *dev, struct kobj_uevent_env *env){	struct usb_device *usb_dev;	usb_dev = to_usb_device(dev);	if (add_uevent_var(env, ""BUSNUM=%03d"", usb_dev->bus->busnum))		return -ENOMEM;	if (add_uevent_var(env, ""DEVNUM=%03d"", usb_dev->devnum))		return -ENOMEM;	return 0;}",23311
81,261,CVE-2019-17351,15,"void balloon_set_new_target(unsigned long target){	 	balloon_stats.target_pages = target;	schedule_delayed_work(&balloon_worker, 0);}",26403
32,133,CVE-2016-6213,15,"static void dec_mnt_namespaces(struct ucounts *ucounts){	dec_ucount(ucounts, UCOUNT_MNT_NAMESPACES);}",16155
92,112,CVE-2016-8666,15,"static inline int skb_loop_sk(struct packet_type *ptype, struct sk_buff *skb){	if (!ptype->af_packet_priv || !skb->sk)		return false;	if (ptype->id_match)		return ptype->id_match(ptype, skb->sk);	else if ((struct sock *)ptype->af_packet_priv == skb->sk)		return true;	return false;}",15428
8,372,CVE-2018-20784,15,"static inline int idle_balance(struct rq *rq, struct rq_flags *rf){	return 0;}",27726
41,212,CVE-2018-20169,15,"static int usb_dev_freeze(struct device *dev){	return usb_suspend(dev, PMSG_FREEZE);}",23304
6,298,CVE-2018-20784,15,void cfs_bandwidth_usage_dec(void){	static_key_slow_dec_cpuslocked(&__cfs_bandwidth_used);},27652
31,281,CVE-2019-11413,15,static int isunicodeletter(int c){	return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || isalpharune(c);},27146
75,470,CVE-2018-20784,15,void unregister_fair_sched_group(struct task_group *tg) { },27824
37,255,CVE-2015-9253,15,"int fpm_stdio_prepare_pipes(struct fpm_child_s *child)  {	if (0 == child->wp->config->catch_workers_output) {  		return 0;	}	if (0 > pipe(fd_stdout)) {		zlog(ZLOG_SYSERROR, ""failed to prepare the stdout pipe"");		return -1;	}	if (0 > pipe(fd_stderr)) {		zlog(ZLOG_SYSERROR, ""failed to prepare the stderr pipe"");		close(fd_stdout[0]);		close(fd_stdout[1]);		return -1;	}	if (0 > fd_set_blocked(fd_stdout[0], 0) || 0 > fd_set_blocked(fd_stderr[0], 0)) {		zlog(ZLOG_SYSERROR, ""failed to unblock pipes"");		close(fd_stdout[0]);		close(fd_stdout[1]);		close(fd_stderr[0]);		close(fd_stderr[1]);		return -1;	}	return 0;} ",26263
53,495,CVE-2018-20784,15,"static inline void util_est_enqueue(struct cfs_rq *cfs_rq,				    struct task_struct *p){	unsigned int enqueued;	if (!sched_feat(UTIL_EST))		return;	 	enqueued  = cfs_rq->avg.util_est.enqueued;	enqueued += _task_util_est(p);	WRITE_ONCE(cfs_rq->avg.util_est.enqueued, enqueued);}",27849
119,504,CVE-2018-20784,15,"static inline int within_margin(int value, int margin){	return ((unsigned int)(value + margin - 1) < (2 * margin - 1));}",27858
1,338,CVE-2018-20784,15,"static void detach_task(struct task_struct *p, struct lb_env *env){	lockdep_assert_held(&env->src_rq->lock);	p->on_rq = TASK_ON_RQ_MIGRATING;	deactivate_task(env->src_rq, p, DEQUEUE_NOCLOCK);	set_task_cpu(p, env->dst_cpu);}",27692
68,501,CVE-2018-20784,15,"static int wake_wide(struct task_struct *p){	unsigned int master = current->wakee_flips;	unsigned int slave = p->wakee_flips;	int factor = this_cpu_read(sd_llc_size);	if (master < slave)		swap(master, slave);	if (slave < factor || master < slave * factor)		return 0;	return 1;}",27855
111,156,CVE-2016-6213,15,static void mntns_put(struct ns_common *ns){	put_mnt_ns(to_mnt_ns(ns));},16178
15,466,CVE-2018-20784,15,static inline int throttled_hierarchy(struct cfs_rq *cfs_rq){	return 0;},27820
105,295,CVE-2018-20784,15,static void attach_task_cfs_rq(struct task_struct *p){	struct sched_entity *se = &p->se;	struct cfs_rq *cfs_rq = cfs_rq_of(se);	attach_entity_cfs_rq(se);	if (!vruntime_normalized(p))		se->vruntime += cfs_rq->min_vruntime;},27649
50,455,CVE-2018-20784,15,"static void task_set_group_fair(struct task_struct *p){	struct sched_entity *se = &p->se;	set_task_rq(p, task_cpu(p));	se->depth = se->parent ? se->parent->depth + 1 : 0;}",27809
83,499,CVE-2018-20784,15,"wake_affine_idle(int this_cpu, int prev_cpu, int sync){	 	if (available_idle_cpu(this_cpu) && cpus_share_cache(this_cpu, prev_cpu))		return available_idle_cpu(prev_cpu) ? prev_cpu : this_cpu;	if (sync && cpu_rq(this_cpu)->nr_running == 1)		return this_cpu;	return nr_cpumask_bits;}",27853
10,406,CVE-2018-20784,15,"void post_init_entity_util_avg(struct sched_entity *se){	struct cfs_rq *cfs_rq = cfs_rq_of(se);	struct sched_avg *sa = &se->avg;	long cpu_scale = arch_scale_cpu_capacity(NULL, cpu_of(rq_of(cfs_rq)));	long cap = (long)(cpu_scale - cfs_rq->avg.util_avg) / 2;	if (cap > 0) {		if (cfs_rq->avg.util_avg != 0) {			sa->util_avg  = cfs_rq->avg.util_avg * se->load.weight;			sa->util_avg /= (cfs_rq->avg.load_avg + 1);			if (sa->util_avg > cap)				sa->util_avg = cap;		} else {			sa->util_avg = cap;		}	}	if (entity_is_task(se)) {		struct task_struct *p = task_of(se);		if (p->sched_class != &fair_sched_class) {			 			se->avg.last_update_time = cfs_rq_clock_task(cfs_rq);			return;		}	}	attach_entity_cfs_rq(se);}",27760
126,236,CVE-2018-20169,15,static void hwahc_security_release(struct hwahc *hwahc){	 },23328
58,80,CVE-2016-8666,15,"static void netdev_adjacent_sysfs_del(struct net_device *dev,			       char *name,			       struct list_head *dev_list){	char linkname[IFNAMSIZ+7];	sprintf(linkname, dev_list == &dev->adj_list.upper ?		""upper_%s"" : ""lower_%s"", name);	sysfs_remove_link(&(dev->dev.kobj), linkname);}",15396
17,347,CVE-2018-20784,15,static inline enum fbq_type fbq_classify_group(struct sg_lb_stats *sgs){	return all;},27701
99,325,CVE-2018-20784,15,void cpu_load_update_nohz_start(void){	struct rq *this_rq = this_rq();	 	this_rq->cpu_load[0] = weighted_cpuload(this_rq);},27679
87,122,CVE-2016-8666,15,"static struct sk_buff **udp4_gro_receive(struct sk_buff **head,					 struct sk_buff *skb){	struct udphdr *uh = udp_gro_udphdr(skb);	if (unlikely(!uh))		goto flush;	 	if (NAPI_GRO_CB(skb)->flush)		goto skip;	if (skb_gro_checksum_validate_zero_check(skb, IPPROTO_UDP, uh->check,						 inet_gro_compute_pseudo))		goto flush;	else if (uh->check)		skb_gro_checksum_try_convert(skb, IPPROTO_UDP, uh->check,					     inet_gro_compute_pseudo);skip:	NAPI_GRO_CB(skb)->is_ipv6 = 0;	return udp_gro_receive(head, skb, uh);flush:	NAPI_GRO_CB(skb)->flush = 1;	return NULL;}",15438
113,60,CVE-2016-8666,15,"static void gro_pull_from_frag0(struct sk_buff *skb, int grow){	struct skb_shared_info *pinfo = skb_shinfo(skb);	BUG_ON(skb->end - skb->tail < grow);	memcpy(skb_tail_pointer(skb), NAPI_GRO_CB(skb)->frag0, grow);	skb->data_len -= grow;	skb->tail += grow;	pinfo->frags[0].page_offset += grow;	skb_frag_size_sub(&pinfo->frags[0], grow);	if (unlikely(!skb_frag_size(&pinfo->frags[0]))) {		skb_frag_unref(skb, 0);		memmove(pinfo->frags, pinfo->frags + 1,			--pinfo->nr_frags * sizeof(pinfo->frags[0]));	}}",15376
88,174,CVE-2016-6213,15,"static int do_proc_dointvec_minmax_conv(int *negp, unsigned long *lvalp,					int *valp,					int write, void *data){	struct do_proc_dointvec_minmax_conv_param *param = data;	if (write) {		int val = *negp ? -*lvalp : *lvalp;		if ((param->min && *param->min > val) ||		    (param->max && *param->max < val))			return -EINVAL;		*valp = val;	} else {		int val = *valp;		if (val < 0) {			*negp = true;			*lvalp = -(unsigned long)val;		} else {			*negp = false;			*lvalp = (unsigned long)val;		}	}	return 0;}",16196
85,16,CVE-2016-8666,15,"static int __netdev_adjacent_dev_insert(struct net_device *dev,					struct net_device *adj_dev,					struct list_head *dev_list,					void *private, int master){	struct netdev_adjacent *adj;	int ret;	adj = __netdev_find_adj(adj_dev, dev_list);	if (adj) {		adj->ref_nr++;		return 0;	}	adj = kmalloc(sizeof(*adj), GFP_KERNEL);	if (!adj)		return -ENOMEM;	adj->dev = adj_dev;	adj->master = master;	adj->ref_nr = 1;	adj->private = private;	dev_hold(adj_dev);	pr_debug(""dev_hold for %s, because of link added from %s to %s\n"",		 adj_dev->name, dev->name, adj_dev->name);	if (netdev_adjacent_is_neigh_list(dev, adj_dev, dev_list)) {		ret = netdev_adjacent_sysfs_add(dev, adj_dev, dev_list);		if (ret)			goto free_adj;	}	 	if (master) {		ret = sysfs_create_link(&(dev->dev.kobj),					&(adj_dev->dev.kobj), ""master"");		if (ret)			goto remove_symlinks;		list_add_rcu(&adj->list, dev_list);	} else {		list_add_tail_rcu(&adj->list, dev_list);	}	return 0;remove_symlinks:	if (netdev_adjacent_is_neigh_list(dev, adj_dev, dev_list))		netdev_adjacent_sysfs_del(dev, adj_dev->name, dev_list);free_adj:	kfree(adj);	dev_put(adj_dev);	return ret;}",15332
121,70,CVE-2016-8666,15,"static int napi_poll(struct napi_struct *n, struct list_head *repoll){	void *have;	int work, weight;	list_del_init(&n->poll_list);	have = netpoll_poll_lock(n);	weight = n->weight;	 	work = 0;	if (test_bit(NAPI_STATE_SCHED, &n->state)) {		work = n->poll(n, weight);		trace_napi_poll(n);	}	WARN_ON_ONCE(work > weight);	if (likely(work < weight))		goto out_unlock;	 	if (unlikely(napi_disable_pending(n))) {		napi_complete(n);		goto out_unlock;	}	if (n->gro_list) {		 		napi_gro_flush(n, HZ >= 1000);	}	 	if (unlikely(!list_empty(&n->poll_list))) {		pr_warn_once(""%s: Budget exhausted after napi rescheduled\n"",			     n->dev ? n->dev->name : ""backlog"");		goto out_unlock;	}	list_add_tail(&n->poll_list, repoll);out_unlock:	netpoll_poll_unlock(have);	return work;}",15386
65,290,CVE-2018-20784,15,"static inline void add_tg_cfs_propagate(struct cfs_rq *cfs_rq, long runnable_sum){	cfs_rq->propagate = 1;	cfs_rq->prop_runnable_sum += runnable_sum;}",27644
56,339,CVE-2018-20784,15,"static void detach_task_cfs_rq(struct task_struct *p){	struct sched_entity *se = &p->se;	struct cfs_rq *cfs_rq = cfs_rq_of(se);	if (!vruntime_normalized(p)) {		 		place_entity(cfs_rq, se, 0);		se->vruntime -= cfs_rq->min_vruntime;	}	detach_entity_cfs_rq(se);}",27693
44,395,CVE-2018-20784,15,"static int nohz_idle_balance(struct rq *this_rq, enum cpu_idle_type idle){	int this_cpu = this_rq->cpu;	unsigned int flags;	if (!(atomic_read(nohz_flags(this_cpu)) & NOHZ_KICK_MASK))		return false;	if (idle != CPU_IDLE) {		atomic_andnot(NOHZ_KICK_MASK, nohz_flags(this_cpu));		return false;	}	 	flags = atomic_fetch_andnot(NOHZ_KICK_MASK, nohz_flags(this_cpu));	if (!(flags & NOHZ_KICK_MASK))		return false;	_nohz_idle_balance(this_rq, flags, idle);	return true;}",27749
18,191,CVE-2018-20169,15,"static void report_wakeup_requests(struct usb_hub *hub){	struct usb_device	*hdev = hub->hdev;	struct usb_device	*udev;	struct usb_hcd		*hcd;	unsigned long		resuming_ports;	int			i;	if (hdev->parent)		return;		 	hcd = bus_to_hcd(hdev->bus);	if (hcd->driver->get_resuming_ports) {		 		resuming_ports = hcd->driver->get_resuming_ports(hcd);		for (i = 0; i < hdev->maxchild; ++i) {			if (test_bit(i, &resuming_ports)) {				udev = hub->ports[i]->child;				if (udev)					pm_wakeup_event(&udev->dev, 0);			}		}	}}",23283
12,145,CVE-2016-6213,15,"static struct ucounts *inc_mnt_namespaces(struct user_namespace *ns){	return inc_ucount(ns, current_euid(), UCOUNT_MNT_NAMESPACES);}",16167
4,486,CVE-2018-20784,15,"update_stats_curr_start(struct cfs_rq *cfs_rq, struct sched_entity *se){	 	se->exec_start = rq_clock_task(rq_of(cfs_rq));}",27840
52,77,CVE-2016-8666,15,static inline void net_timestamp_set(struct sk_buff *skb){	skb->tstamp.tv64 = 0;	if (static_key_false(&netstamp_needed))		__net_timestamp(skb);},15393
90,164,CVE-2016-6213,15,static void unlock_mount(struct mountpoint *where){	struct dentry *dentry = where->m_dentry;	put_mountpoint(where);	namespace_unlock();	inode_unlock(dentry->d_inode);},16186
25,314,CVE-2018-20784,15,static int check_cfs_rq_runtime(struct cfs_rq *cfs_rq) { return false; },27668
84,333,CVE-2018-20784,15,static void destroy_cfs_bandwidth(struct cfs_bandwidth *cfs_b){	 	if (!cfs_b->throttled_cfs_rq.next)		return;	hrtimer_cancel(&cfs_b->period_timer);	hrtimer_cancel(&cfs_b->slack_timer);},27687
98,373,CVE-2018-20784,15,"void init_cfs_bandwidth(struct cfs_bandwidth *cfs_b){	raw_spin_lock_init(&cfs_b->lock);	cfs_b->runtime = 0;	cfs_b->quota = RUNTIME_INF;	cfs_b->period = ns_to_ktime(default_cfs_period());	INIT_LIST_HEAD(&cfs_b->throttled_cfs_rq);	hrtimer_init(&cfs_b->period_timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS_PINNED);	cfs_b->period_timer.function = sched_cfs_period_timer;	hrtimer_init(&cfs_b->slack_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);	cfs_b->slack_timer.function = sched_cfs_slack_timer;	cfs_b->distribute_running = 0;}",27727
35,349,CVE-2018-20784,15,static inline enum fbq_type fbq_classify_rq(struct rq *rq){	return regular;},27703
29,480,CVE-2018-20784,15,"static inline void update_overutilized_status(struct rq *rq){	if (!READ_ONCE(rq->rd->overutilized) && cpu_overutilized(rq->cpu))		WRITE_ONCE(rq->rd->overutilized, SG_OVERUTILIZED);}",27834
21,478,CVE-2018-20784,15,"static inline void update_misfit_status(struct task_struct *p, struct rq *rq) {}",27832
55,166,CVE-2016-6213,15,"static inline int do_refcount_check(struct mount *mnt, int count){	return mnt_get_count(mnt) > count;}",16188
40,147,CVE-2016-6213,15,static int is_mnt_ns_file(struct dentry *dentry){	 	return dentry->d_op == &ns_dentry_operations &&	       dentry->d_fsdata == &mntns_operations;},16169
19,412,CVE-2018-20784,15,"static inline void put_numa_group(struct numa_group *grp){	if (atomic_dec_and_test(&grp->refcount))		kfree_rcu(grp, rcu);}",27766
89,350,CVE-2018-20784,15,"static struct sched_group *find_busiest_group(struct lb_env *env){	struct sg_lb_stats *local, *busiest;	struct sd_lb_stats sds;	init_sd_lb_stats(&sds);	 	update_sd_lb_stats(env, &sds);	if (static_branch_unlikely(&sched_energy_present)) {		struct root_domain *rd = env->dst_rq->rd;		if (rcu_dereference(rd->pd) && !READ_ONCE(rd->overutilized))			goto out_balanced;	}	local = &sds.local_stat;	busiest = &sds.busiest_stat;	 	if (check_asym_packing(env, &sds))		return sds.busiest;	 	if (!sds.busiest || busiest->sum_nr_running == 0)		goto out_balanced;	 	sds.avg_load = (SCHED_CAPACITY_SCALE * sds.total_load)						/ sds.total_capacity;	 	if (busiest->group_type == group_imbalanced)		goto force_balance;	 	if (env->idle != CPU_NOT_IDLE && group_has_capacity(env, local) &&	    busiest->group_no_capacity)		goto force_balance;	 	if (busiest->group_type == group_misfit_task)		goto force_balance;	 	if (local->avg_load >= busiest->avg_load)		goto out_balanced;	 	if (local->avg_load >= sds.avg_load)		goto out_balanced;	if (env->idle == CPU_IDLE) {		 		if ((busiest->group_type != group_overloaded) &&				(local->idle_cpus <= (busiest->idle_cpus + 1)))			goto out_balanced;	} else {		 		if (100 * busiest->avg_load <=				env->sd->imbalance_pct * local->avg_load)			goto out_balanced;	}force_balance:	 	env->src_grp_type = busiest->group_type;	calculate_imbalance(env, &sds);	return env->imbalance ? sds.busiest : NULL;out_balanced:	env->imbalance = 0;	return NULL;}",27704
115,222,CVE-2018-20169,15,"int usb_find_common_endpoints_reverse(struct usb_host_interface *alt,		struct usb_endpoint_descriptor **bulk_in,		struct usb_endpoint_descriptor **bulk_out,		struct usb_endpoint_descriptor **int_in,		struct usb_endpoint_descriptor **int_out){	struct usb_endpoint_descriptor *epd;	int i;	if (bulk_in)		*bulk_in = NULL;	if (bulk_out)		*bulk_out = NULL;	if (int_in)		*int_in = NULL;	if (int_out)		*int_out = NULL;	for (i = alt->desc.bNumEndpoints - 1; i >= 0; --i) {		epd = &alt->endpoint[i].desc;		if (match_endpoint(epd, bulk_in, bulk_out, int_in, int_out))			return 0;	}	return -ENXIO;}",23314
54,9,CVE-2016-8666,15,"void __dev_kfree_skb_irq(struct sk_buff *skb, enum skb_free_reason reason){	unsigned long flags;	if (likely(atomic_read(&skb->users) == 1)) {		smp_rmb();		atomic_set(&skb->users, 0);	} else if (likely(!atomic_dec_and_test(&skb->users))) {		return;	}	get_kfree_skb_cb(skb)->reason = reason;	local_irq_save(flags);	skb->next = __this_cpu_read(softnet_data.completion_queue);	__this_cpu_write(softnet_data.completion_queue, skb);	raise_softirq_irqoff(NET_TX_SOFTIRQ);	local_irq_restore(flags);}",15325
7,443,CVE-2018-20784,15,"static inline int task_faults_idx(enum numa_faults_stats s, int nid, int priv){	return NR_NUMA_HINT_FAULT_TYPES * (s * nr_node_ids + nid) + priv;}",27797
96,139,CVE-2016-6213,15,"static int do_new_mount(struct path *path, const char *fstype, int flags,			int mnt_flags, const char *name, void *data){	struct file_system_type *type;	struct vfsmount *mnt;	int err;	if (!fstype)		return -EINVAL;	type = get_fs_type(fstype);	if (!type)		return -ENODEV;	mnt = vfs_kern_mount(type, flags, name, data);	if (!IS_ERR(mnt) && (type->fs_flags & FS_HAS_SUBTYPE) &&	    !mnt->mnt_sb->s_subtype)		mnt = fs_set_subtype(mnt, fstype);	put_filesystem(type);	if (IS_ERR(mnt))		return PTR_ERR(mnt);	if (mount_too_revealing(mnt, &mnt_flags)) {		mntput(mnt);		return -EPERM;	}	err = do_add_mount(real_mount(mnt), path, mnt_flags);	if (err)		mntput(mnt);	return err;}",16161
43,310,CVE-2018-20784,15,static inline int cfs_rq_throttled(struct cfs_rq *cfs_rq){	return 0;},27664
23,274,CVE-2019-11413,15,"static void addranges_d(struct cstate *g){	addrange(g, '0', '9');}",27139
112,223,CVE-2018-20169,15,"struct usb_interface *usb_find_interface(struct usb_driver *drv, int minor){	struct find_interface_arg argb;	struct device *dev;	argb.minor = minor;	argb.drv = &drv->drvwrap.driver;	dev = bus_find_device(&usb_bus_type, NULL, &argb, __find_interface);	 	put_device(dev);	return dev ? to_usb_interface(dev) : NULL;}",23315
86,175,CVE-2016-6213,15,"static int do_proc_dointvec_ms_jiffies_conv(int *negp, unsigned long *lvalp,					    int *valp,					    int write, void *data){	if (write) {		unsigned long jif = msecs_to_jiffies(*negp ? -*lvalp : *lvalp);		if (jif > INT_MAX)			return 1;		*valp = (int)jif;	} else {		int val = *valp;		unsigned long lval;		if (val < 0) {			*negp = true;			lval = -(unsigned long)val;		} else {			*negp = false;			lval = (unsigned long)val;		}		*lvalp = jiffies_to_msecs(lval);	}	return 0;}",16197
74,448,CVE-2018-20784,15,"static unsigned int task_nr_scan_windows(struct task_struct *p){	unsigned long rss = 0;	unsigned long nr_scan_pages;	 	nr_scan_pages = sysctl_numa_balancing_scan_size << (20 - PAGE_SHIFT);	rss = get_mm_rss(p->mm);	if (!rss)		rss = nr_scan_pages;	rss = round_up(rss, nr_scan_pages);	return rss / nr_scan_pages;}",27802
102,204,CVE-2018-20169,15,"static int __find_interface(struct device *dev, void *data){	struct find_interface_arg *arg = data;	struct usb_interface *intf;	if (!is_usb_interface(dev))		return 0;	if (dev->driver != arg->drv)		return 0;	intf = to_usb_interface(dev);	return intf->minor == arg->minor;}",23296
114,51,CVE-2016-8666,15,"int dev_queue_xmit_accel(struct sk_buff *skb, void *accel_priv){	return __dev_queue_xmit(skb, accel_priv);}",15367
9,202,CVE-2018-20169,15,"static int use_new_scheme(struct usb_device *udev, int retry,			   struct usb_port *port_dev){	int old_scheme_first_port =		port_dev->quirks & USB_PORT_QUIRK_OLD_SCHEME;	int quick_enumeration = (udev->speed == USB_SPEED_HIGH);	if (udev->speed >= USB_SPEED_SUPER)		return false;	return USE_NEW_SCHEME(retry, old_scheme_first_port || old_scheme_first			      || quick_enumeration);}",23294
71,102,CVE-2016-8666,15,int netif_rx_ni(struct sk_buff *skb){	int err;	trace_netif_rx_ni_entry(skb);	preempt_disable();	err = netif_rx_internal(skb);	if (local_softirq_pending())		do_softirq();	preempt_enable();	return err;},15418
57,57,CVE-2016-8666,15,"int dev_valid_name(const char *name){	if (*name == '\0')		return false;	if (strlen(name) >= IFNAMSIZ)		return false;	if (!strcmp(name, ""."") || !strcmp(name, ""..""))		return false;	while (*name) {		if (*name == '/' || *name == ':' || isspace(*name))			return false;		name++;	}	return true;}",15373
72,142,CVE-2016-6213,15,"void drop_collected_mounts(struct vfsmount *mnt){	namespace_lock();	lock_mount_hash();	umount_tree(real_mount(mnt), UMOUNT_SYNC);	unlock_mount_hash();	namespace_unlock();}",16164
101,463,CVE-2018-20784,15,"static int tg_throttle_down(struct task_group *tg, void *data){	struct rq *rq = data;	struct cfs_rq *cfs_rq = tg->cfs_rq[cpu_of(rq)];	 	if (!cfs_rq->throttle_count)		cfs_rq->throttled_clock_task = rq_clock_task(rq);	cfs_rq->throttle_count++;	return 0;}",27817
78,301,CVE-2018-20784,15,void cfs_bandwidth_usage_inc(void) {},27655
34,99,CVE-2016-8666,15,void netif_napi_del(struct napi_struct *napi){	might_sleep();	if (napi_hash_del(napi))		synchronize_net();	list_del_init(&napi->dev_list);	napi_free_frags(napi);	kfree_skb_list(napi->gro_list);	napi->gro_list = NULL;	napi->gro_count = 0;},15415
125,386,CVE-2018-20784,15,static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq) { },27740
100,141,CVE-2016-6213,15,"static int do_umount(struct mount *mnt, int flags){	struct super_block *sb = mnt->mnt.mnt_sb;	int retval;	retval = security_sb_umount(&mnt->mnt, flags);	if (retval)		return retval;	 	if (flags & MNT_EXPIRE) {		if (&mnt->mnt == current->fs->root.mnt ||		    flags & (MNT_FORCE | MNT_DETACH))			return -EINVAL;		 		lock_mount_hash();		if (mnt_get_count(mnt) != 2) {			unlock_mount_hash();			return -EBUSY;		}		unlock_mount_hash();		if (!xchg(&mnt->mnt_expiry_mark, 1))			return -EAGAIN;	}	 	if (flags & MNT_FORCE && sb->s_op->umount_begin) {		sb->s_op->umount_begin(sb);	}	 	if (&mnt->mnt == current->fs->root.mnt && !(flags & MNT_DETACH)) {		 		if (!capable(CAP_SYS_ADMIN))			return -EPERM;		down_write(&sb->s_umount);		if (!(sb->s_flags & MS_RDONLY))			retval = do_remount_sb(sb, MS_RDONLY, NULL, 0);		up_write(&sb->s_umount);		return retval;	}	namespace_lock();	lock_mount_hash();	event++;	if (flags & MNT_DETACH) {		if (!list_empty(&mnt->mnt_list))			umount_tree(mnt, UMOUNT_PROPAGATE);		retval = 0;	} else {		shrink_submounts(mnt);		retval = -EBUSY;		if (!propagate_mount_busy(mnt, 2)) {			if (!list_empty(&mnt->mnt_list))				umount_tree(mnt, UMOUNT_PROPAGATE|UMOUNT_SYNC);			retval = 0;		}	}	unlock_mount_hash();	namespace_unlock();	return retval;}",16163
38,467,CVE-2018-20784,15,"static inline int throttled_lb_pair(struct task_group *tg,				    int src_cpu, int dest_cpu){	struct cfs_rq *src_cfs_rq, *dest_cfs_rq;	src_cfs_rq = tg->cfs_rq[src_cpu];	dest_cfs_rq = tg->cfs_rq[dest_cpu];	return throttled_hierarchy(src_cfs_rq) ||	       throttled_hierarchy(dest_cfs_rq);}",27821
110,270,CVE-2019-11413,15,"static int accept(struct cstate *g, int t){	if (g->lookahead == t) {		next(g);		return 1;	}	return 0;}",27135
27,396,CVE-2018-20784,15,"static inline int nohz_idle_balance(struct rq *this_rq, enum cpu_idle_type idle){	return false;}",27750
80,42,CVE-2016-8666,15,"int dev_get_phys_port_id(struct net_device *dev,			 struct netdev_phys_item_id *ppid){	const struct net_device_ops *ops = dev->netdev_ops;	if (!ops->ndo_get_phys_port_id)		return -EOPNOTSUPP;	return ops->ndo_get_phys_port_id(dev, ppid);}",15358
64,86,CVE-2016-8666,15,"int netdev_has_upper_dev(struct net_device *dev,			  struct net_device *upper_dev){	ASSERT_RTNL();	return __netdev_find_adj(upper_dev, &dev->all_adj_list.upper);}",15402
33,83,CVE-2016-8666,15,void netdev_freemem(struct net_device *dev){	char *addr = (char *)dev - dev->padded;	kvfree(addr);},15399
124,429,CVE-2018-20784,15,static inline int sg_imbalanced(struct sched_group *group){	return group->sgc->imbalance;},27783
42,383,CVE-2018-20784,15,"static inline void list_add_leaf_cfs_rq(struct cfs_rq *cfs_rq){	if (!cfs_rq->on_list) {		struct rq *rq = rq_of(cfs_rq);		int cpu = cpu_of(rq);		 		if (cfs_rq->tg->parent &&		    cfs_rq->tg->parent->cfs_rq[cpu]->on_list) {			 			list_add_tail_rcu(&cfs_rq->leaf_cfs_rq_list,				&(cfs_rq->tg->parent->cfs_rq[cpu]->leaf_cfs_rq_list));			 			rq->tmp_alone_branch = &rq->leaf_cfs_rq_list;		} else if (!cfs_rq->tg->parent) {			 			list_add_tail_rcu(&cfs_rq->leaf_cfs_rq_list,				&rq->leaf_cfs_rq_list);			 			rq->tmp_alone_branch = &rq->leaf_cfs_rq_list;		} else {			 			list_add_rcu(&cfs_rq->leaf_cfs_rq_list,				rq->tmp_alone_branch);			 			rq->tmp_alone_branch = &cfs_rq->leaf_cfs_rq_list;		}		cfs_rq->on_list = 1;	}}",27737
5,289,CVE-2018-20784,15,"static inline void account_numa_enqueue(struct rq *rq, struct task_struct *p){}",27643
26,316,CVE-2018-20784,15,"static void check_enqueue_throttle(struct cfs_rq *cfs_rq){	if (!cfs_bandwidth_used())		return;	 	if (!cfs_rq->runtime_enabled || cfs_rq->curr)		return;	 	if (cfs_rq_throttled(cfs_rq))		return;	 	account_cfs_rq_runtime(cfs_rq, 0);	if (cfs_rq->runtime_remaining <= 0)		throttle_cfs_rq(cfs_rq);}",27670
116,91,CVE-2016-8666,15,"void netdev_rx_csum_fault(struct net_device *dev){	if (net_ratelimit()) {		pr_err(""%s: hw csum failure\n"", dev ? dev->name : ""<unknown>"");		dump_stack();	}}",15407
77,161,CVE-2016-6213,15,static void put_mountpoint(struct mountpoint *mp){	if (!--mp->m_count) {		struct dentry *dentry = mp->m_dentry;		BUG_ON(!hlist_empty(&mp->m_list));		spin_lock(&dentry->d_lock);		dentry->d_flags &= ~DCACHE_MOUNTED;		spin_unlock(&dentry->d_lock);		hlist_del(&mp->m_hash);		kfree(mp);	}},16183
107,400,CVE-2018-20784,15,"static void numa_migrate_preferred(struct task_struct *p){	unsigned long interval = HZ;	 	if (unlikely(p->numa_preferred_nid == -1 || !p->numa_faults))		return;	 	interval = min(interval, msecs_to_jiffies(p->numa_scan_period) / 16);	p->numa_migrate_retry = jiffies + interval;	 	if (task_node(p) == p->numa_preferred_nid)		return;	 	task_numa_migrate(p);}",27754
47,489,CVE-2018-20784,15,"static void update_task_scan_period(struct task_struct *p,			unsigned long shared, unsigned long private){	unsigned int period_slot;	int lr_ratio, ps_ratio;	int diff;	unsigned long remote = p->numa_faults_locality[0];	unsigned long local = p->numa_faults_locality[1];	 	if (local + shared == 0 || p->numa_faults_locality[2]) {		p->numa_scan_period = min(p->numa_scan_period_max,			p->numa_scan_period << 1);		p->mm->numa_next_scan = jiffies +			msecs_to_jiffies(p->numa_scan_period);		return;	}	 	period_slot = DIV_ROUND_UP(p->numa_scan_period, NUMA_PERIOD_SLOTS);	lr_ratio = (local * NUMA_PERIOD_SLOTS) / (local + remote);	ps_ratio = (private * NUMA_PERIOD_SLOTS) / (private + shared);	if (ps_ratio >= NUMA_PERIOD_THRESHOLD) {		 		int slot = ps_ratio - NUMA_PERIOD_THRESHOLD;		if (!slot)			slot = 1;		diff = slot * period_slot;	} else if (lr_ratio >= NUMA_PERIOD_THRESHOLD) {		 		int slot = lr_ratio - NUMA_PERIOD_THRESHOLD;		if (!slot)			slot = 1;		diff = slot * period_slot;	} else {		 		int ratio = max(lr_ratio, ps_ratio);		diff = -(NUMA_PERIOD_THRESHOLD - ratio) * period_slot;	}	p->numa_scan_period = clamp(p->numa_scan_period + diff,			task_scan_min(p), task_scan_max(p));	memset(p->numa_faults_locality, 0, sizeof(p->numa_faults_locality));}",27843
106,46,CVE-2016-8666,15,"int dev_loopback_xmit(struct net *net, struct sock *sk, struct sk_buff *skb){	skb_reset_mac_header(skb);	__skb_pull(skb, skb_network_offset(skb));	skb->pkt_type = PACKET_LOOPBACK;	skb->ip_summed = CHECKSUM_UNNECESSARY;	WARN_ON(!skb_dst(skb));	skb_dst_force(skb);	netif_rx_ni(skb);	return 0;}",15362
93,292,CVE-2018-20784,15,"attach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags) {}",27646
48,88,CVE-2016-8666,15,"void netdev_lower_state_changed(struct net_device *lower_dev,				void *lower_state_info){	struct netdev_notifier_changelowerstate_info changelowerstate_info;	ASSERT_RTNL();	changelowerstate_info.lower_state_info = lower_state_info;	call_netdevice_notifiers_info(NETDEV_CHANGELOWERSTATE, lower_dev,				      &changelowerstate_info.info);}",15404
118,420,CVE-2018-20784,15,static void rq_online_fair(struct rq *rq){	update_sysctl();	update_runtime_enabled(rq);},27774
109,225,CVE-2018-20169,15,int usb_get_current_frame_number(struct usb_device *dev){	return usb_hcd_get_frame_number(dev);},23317
24,245,CVE-2015-9253,15,"int fpm_children_create_initial(struct fpm_worker_pool_s *wp)  {	if (wp->config->pm == PM_STYLE_ONDEMAND) {		wp->ondemand_event = (struct fpm_event_s *)malloc(sizeof(struct fpm_event_s));		if (!wp->ondemand_event) {			zlog(ZLOG_ERROR, ""[pool %s] unable to malloc the ondemand socket event"", wp->config->name);			return 1;		}		memset(wp->ondemand_event, 0, sizeof(struct fpm_event_s));		fpm_event_set(wp->ondemand_event, wp->listening_socket, FPM_EV_READ | FPM_EV_EDGE, fpm_pctl_on_socket_accept, wp);		wp->socket_event_set = 1;		fpm_event_add(wp->ondemand_event, 0);		return 1;	}	return fpm_children_make(wp, 0  , 0, 1);} ",26253
11,359,CVE-2018-20784,15,"static inline int get_sd_load_idx(struct sched_domain *sd,					enum cpu_idle_type idle){	int load_idx;	switch (idle) {	case CPU_NOT_IDLE:		load_idx = sd->busy_idx;		break;	case CPU_NEWLY_IDLE:		load_idx = sd->newidle_idx;		break;	default:		load_idx = sd->idle_idx;		break;	}	return load_idx;}",27713
20,52,CVE-2016-8666,15,void dev_remove_offload(struct packet_offload *po){	__dev_remove_offload(po);	synchronize_net();},15368
103,210,CVE-2018-20169,15,"static void usb_debugfs_init(void){	usb_debug_root = debugfs_create_dir(""usb"", NULL);	debugfs_create_file(""devices"", 0444, usb_debug_root, NULL,			    &usbfs_devices_fops);}",23302
13,13,CVE-2016-8666,15,"void __dev_set_rx_mode(struct net_device *dev){	const struct net_device_ops *ops = dev->netdev_ops;	 	if (!(dev->flags&IFF_UP))		return;	if (!netif_device_present(dev))		return;	if (!(dev->priv_flags & IFF_UNICAST_FLT)) {		 		if (!netdev_uc_empty(dev) && !dev->uc_promisc) {			__dev_set_promiscuity(dev, 1, false);			dev->uc_promisc = true;		} else if (netdev_uc_empty(dev) && dev->uc_promisc) {			__dev_set_promiscuity(dev, -1, false);			dev->uc_promisc = false;		}	}	if (ops->ndo_set_rx_mode)		ops->ndo_set_rx_mode(dev);}",15329
79,103,CVE-2016-8666,15,void netif_schedule_queue(struct netdev_queue *txq){	rcu_read_lock();	if (!(txq->state & QUEUE_STATE_ANY_XOFF)) {		struct Qdisc *q = rcu_dereference(txq->qdisc);		__netif_schedule(q);	}	rcu_read_unlock();},15419
76,192,CVE-2018-20169,15,"static int usb_disable_link_state(struct usb_hcd *hcd, struct usb_device *udev,		enum usb3_link_state state){	switch (state) {	case USB3_LPM_U1:	case USB3_LPM_U2:		break;	default:		dev_warn(&udev->dev, ""%s: Can't disable non-U1 or U2 state.\n"",				__func__);		return -EINVAL;	}	if (usb_set_lpm_timeout(udev, state, 0))		return -EBUSY;	usb_set_device_initiated_lpm(udev, state, false);	if (hcd->driver->disable_usb3_lpm_timeout(hcd, udev, state))		dev_warn(&udev->dev, ""Could not disable xHCI %s timeout, ""				""bus schedule bandwidth may be impacted.\n"",				usb3_lpm_names[state]);	 	if (state == USB3_LPM_U1)		udev->usb3_lpm_u1_enabled = 0;	else if (state == USB3_LPM_U2)		udev->usb3_lpm_u2_enabled = 0;	return 0;}",23284
82,282,CVE-2019-11413,15,static int iswordchar(int c){	return c == '_' ||		(c >= 'a' && c <= 'z') ||		(c >= 'A' && c <= 'Z') ||		(c >= '0' && c <= '9');},27147
69,126,CVE-2016-8666,15,"static int ipv6_gso_pull_exthdrs(struct sk_buff *skb, int proto){	const struct net_offload *ops = NULL;	for (;;) {		struct ipv6_opt_hdr *opth;		int len;		if (proto != NEXTHDR_HOP) {			ops = rcu_dereference(inet6_offloads[proto]);			if (unlikely(!ops))				break;			if (!(ops->flags & INET6_PROTO_GSO_EXTHDR))				break;		}		if (unlikely(!pskb_may_pull(skb, 8)))			break;		opth = (void *)skb->data;		len = ipv6_optlen(opth);		if (unlikely(!pskb_may_pull(skb, len)))			break;		opth = (void *)skb->data;		proto = opth->nexthdr;		__skb_pull(skb, len);	}	return proto;}",15442
39,168,CVE-2016-6213,15,"static struct mount *next_group(struct mount *m, struct mount *origin){	while (1) {		while (1) {			struct mount *next;			if (!IS_MNT_NEW(m) && !list_empty(&m->mnt_slave_list))				return first_slave(m);			next = next_peer(m);			if (m->mnt_group_id == origin->mnt_group_id) {				if (next == origin)					return NULL;			} else if (m->mnt_slave.next != &next->mnt_slave)				break;			m = next;		}		 		while (1) {			struct mount *master = m->mnt_master;			if (m->mnt_slave.next != &master->mnt_slave_list)				return next_slave(m);			m = next_peer(master);			if (master->mnt_group_id == origin->mnt_group_id)				break;			if (master->mnt_slave.next == &m->mnt_slave)				break;			m = master;		}		if (m == origin)			return NULL;	}}",16190
104,69,CVE-2016-8666,15,"int napi_hash_del(struct napi_struct *napi){	int rcu_sync_needed = false;	spin_lock(&napi_hash_lock);	if (test_and_clear_bit(NAPI_STATE_HASHED, &napi->state)) {		rcu_sync_needed = true;		hlist_del_rcu(&napi->napi_hash_node);	}	spin_unlock(&napi_hash_lock);	return rcu_sync_needed;}",15385
46,151,CVE-2016-6213,15,int mnt_may_suid(struct vfsmount *mnt){	 	return !(mnt->mnt_flags & MNT_NOSUID) && check_mnt(real_mount(mnt)) &&	       current_in_userns(mnt->mnt_sb->s_user_ns);},16173
16,26,CVE-2016-8666,15,static inline void __netif_reschedule(struct Qdisc *q){	struct softnet_data *sd;	unsigned long flags;	local_irq_save(flags);	sd = this_cpu_ptr(&softnet_data);	q->next_sched = NULL;	*sd->output_queue_tailp = q;	sd->output_queue_tailp = &q->next_sched;	raise_softirq_irqoff(NET_TX_SOFTIRQ);	local_irq_restore(flags);},15342
63,454,CVE-2018-20784,15,"static unsigned int task_scan_start(struct task_struct *p){	unsigned long smin = task_scan_min(p);	unsigned long period = smin;	 	if (p->numa_group) {		struct numa_group *ng = p->numa_group;		unsigned long shared = group_faults_shared(ng);		unsigned long private = group_faults_priv(ng);		period *= atomic_read(&ng->refcount);		period *= shared + 1;		period /= private + shared + 1;	}	return max(smin, period);}",27808
97,276,CVE-2019-11413,15,"static void addranges_w(struct cstate *g){	addrange(g, '0', '9');	addrange(g, 'A', 'Z');	addrange(g, '_', '_');	addrange(g, 'a', 'z');}",27141
14,334,CVE-2018-20784,15,static inline void destroy_cfs_bandwidth(struct cfs_bandwidth *cfs_b) {},27688
28,388,CVE-2018-20784,15,"static int load_too_imbalanced(long src_load, long dst_load,				struct task_numa_env *env){	long imb, old_imb;	long orig_src_load, orig_dst_load;	long src_capacity, dst_capacity;	 	src_capacity = env->src_stats.compute_capacity;	dst_capacity = env->dst_stats.compute_capacity;	imb = abs(dst_load * src_capacity - src_load * dst_capacity);	orig_src_load = env->src_stats.load;	orig_dst_load = env->dst_stats.load;	old_imb = abs(orig_dst_load * src_capacity - orig_src_load * dst_capacity);	 	return (imb > old_imb);}",27742
95,24,CVE-2016-8666,15,"static void __netdev_printk(const char *level, const struct net_device *dev,			    struct va_format *vaf){	if (dev && dev->dev.parent) {		dev_printk_emit(level[1] - '0',				dev->dev.parent,				""%s %s %s%s: %pV"",				dev_driver_string(dev->dev.parent),				dev_name(dev->dev.parent),				netdev_name(dev), netdev_reg_state(dev),				vaf);	} else if (dev) {		printk(""%s%s%s: %pV"",		       level, netdev_name(dev), netdev_reg_state(dev), vaf);	} else {		printk(""%s(NULL net_device): %pV"", level, vaf);	}}",15340
60,451,CVE-2018-20784,15,"void task_numa_free(struct task_struct *p){	struct numa_group *grp = p->numa_group;	void *numa_faults = p->numa_faults;	unsigned long flags;	int i;	if (grp) {		spin_lock_irqsave(&grp->lock, flags);		for (i = 0; i < NR_NUMA_HINT_FAULT_STATS * nr_node_ids; i++)			grp->faults[i] -= p->numa_faults[i];		grp->total_faults -= p->total_numa_faults;		grp->nr_tasks--;		spin_unlock_irqrestore(&grp->lock, flags);		RCU_INIT_POINTER(p->numa_group, NULL);		put_numa_group(grp);	}	p->numa_faults = NULL;	kfree(numa_faults);}",27805
51,45,CVE-2016-8666,15,"struct sk_buff *dev_hard_start_xmit(struct sk_buff *first, struct net_device *dev,				    struct netdev_queue *txq, int *ret){	struct sk_buff *skb = first;	int rc = NETDEV_TX_OK;	while (skb) {		struct sk_buff *next = skb->next;		skb->next = NULL;		rc = xmit_one(skb, dev, txq, next != NULL);		if (unlikely(!dev_xmit_complete(rc))) {			skb->next = next;			goto out;		}		skb = next;		if (netif_xmit_stopped(txq) && skb) {			rc = NETDEV_TX_BUSY;			break;		}	}out:	*ret = rc;	return skb;}",15361
94,148,CVE-2016-6213,15,"int legitimize_mnt(struct vfsmount *bastard, unsigned seq){	int res = __legitimize_mnt(bastard, seq);	if (likely(!res))		return true;	if (unlikely(res < 0)) {		rcu_read_unlock();		mntput(bastard);		rcu_read_lock();	}	return false;}",16170
91,432,CVE-2018-20784,15,"static unsigned long source_load(int cpu, int type){	struct rq *rq = cpu_rq(cpu);	unsigned long total = weighted_cpuload(rq);	if (type == 0 || !sched_feat(LB_BIAS))		return total;	return min(rq->cpu_load[type-1], total);}",27786
61,473,CVE-2018-20784,15,"static void update_cpu_capacity(struct sched_domain *sd, int cpu){	unsigned long capacity = scale_rt_capacity(sd, cpu);	struct sched_group *sdg = sd->groups;	cpu_rq(cpu)->cpu_capacity_orig = arch_scale_cpu_capacity(sd, cpu);	if (!capacity)		capacity = 1;	cpu_rq(cpu)->cpu_capacity = capacity;	sdg->sgc->capacity = capacity;	sdg->sgc->min_capacity = capacity;	sdg->sgc->max_capacity = capacity;}",27827
36,277,CVE-2019-11413,15,"static int dec(struct cstate *g, int c){	if (c >= '0' && c <= '9') return c - '0';	die(g, ""invalid quantifier"");	return 0;}",27142
123,414,CVE-2018-20784,15,"static void record_wakee(struct task_struct *p){	 	if (time_after(jiffies, current->wakee_flip_decay_ts + HZ)) {		current->wakee_flips >>= 1;		current->wakee_flip_decay_ts = jiffies;	}	if (current->last_wakee != p) {		current->last_wakee = p;		current->wakee_flips++;	}}",27768
73,283,CVE-2018-20784,15,"static void __dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se){	rb_erase_cached(&se->run_node, &cfs_rq->tasks_timeline);}",27637
70,294,CVE-2018-20784,15,"static void attach_task(struct rq *rq, struct task_struct *p){	lockdep_assert_held(&rq->lock);	BUG_ON(task_rq(p) != rq);	activate_task(rq, p, ENQUEUE_NOCLOCK);	p->on_rq = TASK_ON_RQ_QUEUED;	check_preempt_curr(rq, p, 0);}",27648
62,335,CVE-2018-20784,15,"static void detach_entity_cfs_rq(struct sched_entity *se){	struct cfs_rq *cfs_rq = cfs_rq_of(se);	 	update_load_avg(cfs_rq, se, 0);	detach_entity_load_avg(cfs_rq, se);	update_tg_load_avg(cfs_rq, false);	propagate_entity_cfs_rq(se);}",27689
30,217,CVE-2018-20169,15,"static int usb_dev_suspend(struct device *dev){	return usb_suspend(dev, PMSG_SUSPEND);}",23309
45,107,CVE-2016-8666,15,static inline struct list_head *ptype_head(const struct packet_type *pt){	if (pt->type == htons(ETH_P_ALL))		return pt->dev ? &pt->dev->ptype_all : &ptype_all;	else		return pt->dev ? &pt->dev->ptype_specific :				 &ptype_base[ntohs(pt->type) & PTYPE_HASH_MASK];},15423
2,221,CVE-2018-20169,15,"int usb_find_common_endpoints(struct usb_host_interface *alt,		struct usb_endpoint_descriptor **bulk_in,		struct usb_endpoint_descriptor **bulk_out,		struct usb_endpoint_descriptor **int_in,		struct usb_endpoint_descriptor **int_out){	struct usb_endpoint_descriptor *epd;	int i;	if (bulk_in)		*bulk_in = NULL;	if (bulk_out)		*bulk_out = NULL;	if (int_in)		*int_in = NULL;	if (int_out)		*int_out = NULL;	for (i = 0; i < alt->desc.bNumEndpoints; ++i) {		epd = &alt->endpoint[i].desc;		if (match_endpoint(epd, bulk_in, bulk_out, int_in, int_out))			return 0;	}	return -ENXIO;}",23313
108,63,CVE-2016-8666,15,"void napi_complete_done(struct napi_struct *n, int work_done){	unsigned long flags;	 	if (unlikely(test_bit(NAPI_STATE_NPSVC, &n->state)))		return;	if (n->gro_list) {		unsigned long timeout = 0;		if (work_done)			timeout = n->dev->gro_flush_timeout;		if (timeout)			hrtimer_start(&n->timer, ns_to_ktime(timeout),				      HRTIMER_MODE_REL_PINNED);		else			napi_gro_flush(n, false);	}	if (likely(list_empty(&n->poll_list))) {		WARN_ON_ONCE(!test_and_clear_bit(NAPI_STATE_SCHED, &n->state));	} else {		 		local_irq_save(flags);		__napi_complete(n);		local_irq_restore(flags);	}}",15379
3,300,CVE-2016-9754,30,static void rb_list_head_clear(struct list_head *list){	unsigned long *ptr = (unsigned long *)&list->next;	*ptr &= ~RB_FLAG_MASK;},22694
89,525,CVE-2018-12896,30,"static inline int task_cputime_expired(const struct task_cputime *sample,					const struct task_cputime *expires){	if (expires->utime && sample->utime >= expires->utime)		return 1;	if (expires->stime && sample->utime + sample->stime >= expires->stime)		return 1;	if (expires->sum_exec_runtime != 0 &&	    sample->sum_exec_runtime >= expires->sum_exec_runtime)		return 1;	return 0;}",24745
100,217,CVE-2016-5844,30,"release_files(struct iso9660 *iso9660){	struct content *con, *connext;	struct file_info *file;	file = iso9660->use_files;	while (file != NULL) {		struct file_info *next = file->use_next;		archive_string_free(&file->name);		archive_string_free(&file->symlink);		free(file->utf16be_name);		con = file->contents.first;		while (con != NULL) {			connext = con->next;			free(con);			con = connext;		}		free(file);		file = next;	}}",16336
72,373,CVE-2016-9557,30,"static int jp2_getct(int colorspace, int type, int assoc){	if (type == 1 && assoc == 0) {		return JAS_IMAGE_CT_OPACITY;	}	if (type == 0 && assoc >= 1 && assoc <= 65534) {		switch (colorspace) {		case JAS_CLRSPC_FAM_RGB:			switch (assoc) {			case JP2_CDEF_RGB_R:				return JAS_IMAGE_CT_COLOR(JAS_CLRSPC_CHANIND_RGB_R);				break;			case JP2_CDEF_RGB_G:				return JAS_IMAGE_CT_COLOR(JAS_CLRSPC_CHANIND_RGB_G);				break;			case JP2_CDEF_RGB_B:				return JAS_IMAGE_CT_COLOR(JAS_CLRSPC_CHANIND_RGB_B);				break;			}			break;		case JAS_CLRSPC_FAM_YCBCR:			switch (assoc) {			case JP2_CDEF_YCBCR_Y:				return JAS_IMAGE_CT_COLOR(JAS_CLRSPC_CHANIND_YCBCR_Y);				break;			case JP2_CDEF_YCBCR_CB:				return JAS_IMAGE_CT_COLOR(JAS_CLRSPC_CHANIND_YCBCR_CB);				break;			case JP2_CDEF_YCBCR_CR:				return JAS_IMAGE_CT_COLOR(JAS_CLRSPC_CHANIND_YCBCR_CR);				break;			}			break;		case JAS_CLRSPC_FAM_GRAY:			switch (assoc) {			case JP2_CDEF_GRAY_Y:				return JAS_IMAGE_CT_COLOR(JAS_CLRSPC_CHANIND_GRAY_Y);				break;			}			break;		default:			return JAS_IMAGE_CT_COLOR(assoc - 1);			break;		}	}	return JAS_IMAGE_CT_UNKNOWN;}",22767
101,133,CVE-2016-6250,30,isoent_clone(struct isoent *src){	return (isoent_new(src->file));},16089
87,314,CVE-2016-9754,30,"rb_set_commit_to_write(struct ring_buffer_per_cpu *cpu_buffer){	unsigned long max_count;	  again:	max_count = cpu_buffer->nr_pages * 100;	while (cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)) {		if (RB_WARN_ON(cpu_buffer, !(--max_count)))			return;		if (RB_WARN_ON(cpu_buffer,			       rb_is_reader_page(cpu_buffer->tail_page)))			return;		local_set(&cpu_buffer->commit_page->page->commit,			  rb_page_write(cpu_buffer->commit_page));		rb_inc_page(cpu_buffer, &cpu_buffer->commit_page);		 		if (rb_page_write(cpu_buffer->commit_page))			cpu_buffer->write_stamp =				cpu_buffer->commit_page->page->time_stamp;		 		barrier();	}	while (rb_commit_index(cpu_buffer) !=	       rb_page_write(cpu_buffer->commit_page)) {		local_set(&cpu_buffer->commit_page->page->commit,			  rb_page_write(cpu_buffer->commit_page));		RB_WARN_ON(cpu_buffer,			   local_read(&cpu_buffer->commit_page->page->commit) &			   ~RB_WRITE_MASK);		barrier();	}	 	barrier();	 	if (unlikely(cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)))		goto again;}",22708
138,276,CVE-2016-9754,30,"static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer){	unsigned long commits;	if (RB_WARN_ON(cpu_buffer,		       !local_read(&cpu_buffer->committing)))		return; again:	commits = local_read(&cpu_buffer->commits);	 	barrier();	if (local_read(&cpu_buffer->committing) == 1)		rb_set_commit_to_write(cpu_buffer);	local_dec(&cpu_buffer->committing);	 	barrier();	 	if (unlikely(local_read(&cpu_buffer->commits) != commits) &&	    !local_read(&cpu_buffer->committing)) {		local_inc(&cpu_buffer->committing);		goto again;	}}",22670
95,191,CVE-2016-6250,30,zisofs_free(struct archive_write *a){	(void)a;  	return (ARCHIVE_OK);},16147
35,90,CVE-2016-9084,30,"static int vfio_pci_validate_devs(struct pci_dev *pdev, void *data){	struct vfio_pci_group_info *info = data;	struct iommu_group *group;	int id, i;	group = iommu_group_get(&pdev->dev);	if (!group)		return -EPERM;	id = iommu_group_id(group);	for (i = 0; i < info->count; i++)		if (info->groups[i].id == id)			break;	iommu_group_put(group);	return (i == info->count) ? -EINVAL : 0;}",15300
30,403,CVE-2015-4645,30,"void insert_hash_table(struct cache *cache, struct cache_entry *entry){	int hash = CALCULATE_HASH(entry->block);	entry->hash_next = cache->hash_table[hash];	cache->hash_table[hash] = entry;	entry->hash_prev = NULL;	if(entry->hash_next)		entry->hash_next->hash_prev = entry;}",22945
1,115,CVE-2016-6250,30,"extra_setup_location(struct isoent *isoent, int location){	struct extr_rec *rec;	int cnt;	cnt = 0;	rec = isoent->extr_rec_list.first;	isoent->extr_rec_list.current = rec;	while (rec) {		cnt++;		rec->location = location++;		rec->offset = 0;		rec = rec->next;	}	return (cnt);}",16071
56,500,CVE-2018-13406,30,"static void uvesafb_exit(void){	struct uvesafb_ktask *task;	if (v86d_started) {		task = uvesafb_prep();		if (task) {			task->t.flags = TF_EXIT;			uvesafb_exec(task);			uvesafb_free(task);		}	}	cn_del_callback(&uvesafb_cn_id);	driver_remove_file(&uvesafb_driver.driver, &driver_attr_v86d);	platform_device_unregister(uvesafb_device);	platform_driver_unregister(&uvesafb_driver);}",24568
154,429,CVE-2015-4645,30,"int squashfs_readdir(struct dir *dir, char **name, unsigned int *start_block,unsigned int *offset, unsigned int *type){	if(dir->cur_entry == dir->dir_count)		return FALSE;	*name = dir->dirs[dir->cur_entry].name;	*start_block = dir->dirs[dir->cur_entry].start_block;	*offset = dir->dirs[dir->cur_entry].offset;	*type = dir->dirs[dir->cur_entry].type;	dir->cur_entry ++;	return TRUE;}",22971
66,353,CVE-2016-9754,30,"int ring_buffer_write(struct ring_buffer *buffer,		      unsigned long length,		      void *data){	struct ring_buffer_per_cpu *cpu_buffer;	struct ring_buffer_event *event;	void *body;	int ret = -EBUSY;	int cpu;	preempt_disable_notrace();	if (atomic_read(&buffer->record_disabled))		goto out;	cpu = raw_smp_processor_id();	if (!cpumask_test_cpu(cpu, buffer->cpumask))		goto out;	cpu_buffer = buffer->buffers[cpu];	if (atomic_read(&cpu_buffer->record_disabled))		goto out;	if (length > BUF_MAX_DATA_SIZE)		goto out;	if (unlikely(trace_recursive_lock(cpu_buffer)))		goto out;	event = rb_reserve_next_event(buffer, cpu_buffer, length);	if (!event)		goto out_unlock;	body = rb_event_data(event);	memcpy(body, data, length);	rb_commit(cpu_buffer, event);	rb_wakeups(buffer, cpu_buffer);	ret = 0; out_unlock:	trace_recursive_unlock(cpu_buffer); out:	preempt_enable_notrace();	return ret;}",22747
22,323,CVE-2016-9754,30,"ring_buffer_commit_overrun_cpu(struct ring_buffer *buffer, int cpu){	struct ring_buffer_per_cpu *cpu_buffer;	unsigned long ret;	if (!cpumask_test_cpu(cpu, buffer->cpumask))		return 0;	cpu_buffer = buffer->buffers[cpu];	ret = local_read(&cpu_buffer->commit_overrun);	return ret;}",22717
59,39,CVE-2017-0553,30,struct nl_msg *nlmsg_inherit(struct nlmsghdr *hdr){	struct nl_msg *nm;	nm = nlmsg_alloc();	if (nm && hdr) {		struct nlmsghdr *new = nm->nm_nlh;		new->nlmsg_type = hdr->nlmsg_type;		new->nlmsg_flags = hdr->nlmsg_flags;		new->nlmsg_seq = hdr->nlmsg_seq;		new->nlmsg_pid = hdr->nlmsg_pid;	}	return nm;},2103
90,334,CVE-2016-9754,30,"unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu){	struct ring_buffer_per_cpu *cpu_buffer;	unsigned long ret;	if (!cpumask_test_cpu(cpu, buffer->cpumask))		return 0;	cpu_buffer = buffer->buffers[cpu];	ret = local_read(&cpu_buffer->overrun);	return ret;}",22728
153,70,CVE-2017-12179,30,"barrier_inside_hit_box(struct PointerBarrier *barrier, int x, int y){    int x1, x2, y1, y2;    int dir;    x1 = barrier->x1;    x2 = barrier->x2;    y1 = barrier->y1;    y2 = barrier->y2;    dir = ~(barrier->directions);    if (barrier_is_vertical(barrier)) {        if (dir & BarrierPositiveX)            x1 -= HIT_EDGE_EXTENTS;        if (dir & BarrierNegativeX)            x2 += HIT_EDGE_EXTENTS;    }    if (barrier_is_horizontal(barrier)) {        if (dir & BarrierPositiveY)            y1 -= HIT_EDGE_EXTENTS;        if (dir & BarrierNegativeY)            y2 += HIT_EDGE_EXTENTS;    }    return x >= x1 && x <= x2 && y >= y1 && y <= y2;}",2576
93,538,CVE-2018-12896,30,"static void release_posix_timer(struct k_itimer *tmr, int it_id_set){	if (it_id_set) {		unsigned long flags;		spin_lock_irqsave(&hash_lock, flags);		hlist_del_rcu(&tmr->t_hash);		spin_unlock_irqrestore(&hash_lock, flags);	}	put_pid(tmr->it_pid);	sigqueue_free(tmr->sigq);	call_rcu(&tmr->it.rcu, k_itimer_rcu_free);}",24758
65,448,CVE-2018-1000524,30,"map_engine_change_map(const char* filename){	return change_map(filename, false);}",23202
96,52,CVE-2017-0553,30,int nlmsg_total_size(int payload){	return NLMSG_ALIGN(nlmsg_msg_size(payload));},2116
98,245,CVE-2016-4300,30,folder_uncompressed_size(struct _7z_folder *f){	int n = (int)f->numOutStreams;	unsigned pairs = (unsigned)f->numBindPairs;	while (--n >= 0) {		unsigned i;		for (i = 0; i < pairs; i++) {			if (f->bindPairs[i].outIndex == (int)n)				break;		}		if (i >= pairs)			return (f->unPackSize[n]);	}	return (0);},17108
107,63,CVE-2014-0143,30,"static int count_contiguous_clusters(int nb_clusters, int cluster_size,        int *l2_table, int stop_flags){    int i;    int mask = stop_flags | L2E_OFFSET_MASK | QCOW_OFLAG_COMPRESSED;    int first_entry = be64_to_cpu(l2_table[0]);    int offset = first_entry & mask;    if (!offset)        return 0;    assert(qcow2_get_cluster_type(first_entry) != QCOW2_CLUSTER_COMPRESSED);    for (i = 0; i < nb_clusters; i++) {        int l2_entry = be64_to_cpu(l2_table[i]) & mask;        if (offset + (int) i * cluster_size != l2_entry) {            break;        }    }	return i;}",2518
31,203,CVE-2016-5844,30,"isNull(struct iso9660 *iso9660, const unsigned char *h, unsigned offset,unsigned bytes){	while (bytes >= sizeof(iso9660->null)) {		if (!memcmp(iso9660->null, h + offset, sizeof(iso9660->null)))			return (0);		offset += sizeof(iso9660->null);		bytes -= sizeof(iso9660->null);	}	if (bytes)		return memcmp(iso9660->null, h + offset, bytes) == 0;	else		return (1);}",16322
7,234,CVE-2016-5096,30,"PHP_NAMED_FUNCTION(php_if_tmpfile){	php_stream *stream;	if (zend_parse_parameters_none() == FAILURE) {		return;	}	stream = php_stream_fopen_tmpfile();	if (stream) {		php_stream_to_zval(stream, return_value);	} else {		RETURN_FALSE;	}}",16523
121,219,CVE-2016-5770,30,"SPL_METHOD(DirectoryIterator, __construct){	spl_filesystem_object_construct(INTERNAL_FUNCTION_PARAM_PASSTHRU, 0);}",16345
41,443,CVE-2018-1000524,30,"layer_size(int layer){	struct map_layer* layer_data;	layer_data = &s_map->layers[layer];	return mk_size2(layer_data->width, layer_data->height);}",23197
50,241,CVE-2016-4300,30,"archive_read_support_format_7zip(struct archive *_a){	struct archive_read *a = (struct archive_read *)_a;	struct _7zip *zip;	int r;	archive_check_magic(_a, ARCHIVE_READ_MAGIC,	    ARCHIVE_STATE_NEW, ""archive_read_support_format_7zip"");	zip = calloc(1, sizeof(*zip));	if (zip == NULL) {		archive_set_error(&a->archive, ENOMEM,		    ""Can't allocate 7zip data"");		return (ARCHIVE_FATAL);	}	 	zip->has_encrypted_entries = ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW;	r = __archive_read_register_format(a,	    zip,	    ""7zip"",	    archive_read_format_7zip_bid,	    NULL,	    archive_read_format_7zip_read_header,	    archive_read_format_7zip_read_data,	    archive_read_format_7zip_read_data_skip,	    NULL,	    archive_read_format_7zip_cleanup,	    archive_read_support_format_7zip_capabilities,	    archive_read_format_7zip_has_encrypted_entries);	if (r != ARCHIVE_OK)		free(zip);	return (ARCHIVE_OK);}",17104
74,427,CVE-2015-4645,30,"void sigwinch_handler(){	struct winsize winsize;	if(ioctl(1, TIOCGWINSZ, &winsize) == -1) {		if(isatty(STDOUT_FILENO))			ERROR(""TIOCGWINSZ ioctl failed, defaulting to 80 ""				""columns\n"");		columns = 80;	} else		columns = winsize.ws_col;}",22969
15,433,CVE-2018-1000524,30,layer_get_color_mask(int layer){	return s_map->layers[layer].color_mask;},23187
104,255,CVE-2016-4300,30,"read_consume(struct archive_read *a){	struct _7zip *zip = (struct _7zip *)a->format->data;	if (zip->pack_stream_bytes_unconsumed) {		__archive_read_consume(a, zip->pack_stream_bytes_unconsumed);		zip->stream_offset += zip->pack_stream_bytes_unconsumed;		zip->pack_stream_bytes_unconsumed = 0;	}}",17118
67,130,CVE-2016-6250,30,"isoent_add_child_head(struct isoent *parent, struct isoent *child){	if (!__archive_rb_tree_insert_node(	    &(parent->rbtree), (struct archive_rb_node *)child))		return (0);	if ((child->chnext = parent->children.first) == NULL)		parent->children.last = &(child->chnext);	parent->children.first = child;	parent->children.cnt++;	child->parent = parent;	 	if (child->dir) {		if ((child->drnext = parent->subdirs.first) == NULL)			parent->subdirs.last = &(child->drnext);		parent->subdirs.first = child;		parent->subdirs.cnt++;		child->parent = parent;	} else		child->drnext = NULL;	return (1);}",16086
128,261,CVE-2017-6308,30,get_alloc_limit(){     return alloc_limit; },21845
0,426,CVE-2015-4645,30,void sigalrm_handler(){	rotate = (rotate + 1) % 4;},22968
73,458,CVE-2018-1000524,30,map_engine_set_talk_distance(int distance){	s_talk_distance = distance;},23212
61,529,CVE-2018-12896,30,"SYSCALL_DEFINE1(timer_delete, timer_t, timer_id){	struct k_itimer *timer;	unsigned long flags;retry_delete:	timer = lock_timer(timer_id, &flags);	if (!timer)		return -EINVAL;	if (timer_delete_hook(timer) == TIMER_RETRY) {		unlock_timer(timer, flags);		goto retry_delete;	}	spin_lock(&current->sighand->siglock);	list_del(&timer->list);	spin_unlock(&current->sighand->siglock);	 	timer->it_signal = NULL;	unlock_timer(timer, flags);	release_posix_timer(timer, IT_ID_SET);	return 0;}",24749
106,151,CVE-2016-6250,30,"isoent_remove_child(struct isoent *parent, struct isoent *child){	struct isoent *ent;	 	ent = parent->children.first;	while (ent->chnext != child)		ent = ent->chnext;	if ((ent->chnext = ent->chnext->chnext) == NULL)		parent->children.last = &(ent->chnext);	parent->children.cnt--;	if (child->dir) {		 		ent = parent->subdirs.first;		while (ent->drnext != child)			ent = ent->drnext;		if ((ent->drnext = ent->drnext->drnext) == NULL)			parent->subdirs.last = &(ent->drnext);		parent->subdirs.cnt--;	}	__archive_rb_tree_remove_node(&(parent->rbtree),	    (struct archive_rb_node *)child);}",16107
146,156,CVE-2016-6250,30,"isofile_add_entry(struct iso9660 *iso9660, struct isofile *file){	file->allnext = NULL;	*iso9660->all_file_list.last = file;	iso9660->all_file_list.last = &(file->allnext);}",16112
55,274,CVE-2016-9754,30,rb_commit_index(struct ring_buffer_per_cpu *cpu_buffer){	return rb_page_commit(cpu_buffer->commit_page);},22668
137,139,CVE-2016-6250,30,"isoent_cmp_key_joliet(const struct archive_rb_node *node, const void *key){	const struct isoent *isoent = (const struct isoent *)key;	const struct idrent *idrent = (const struct idrent *)node;	return (isoent_cmp_joliet_identifier(isoent, idrent->isoent));}",16095
108,88,CVE-2016-9084,30,"static unsigned int vfio_pci_set_vga_decode(void *opaque, int single_vga){	struct vfio_pci_device *vdev = opaque;	struct pci_dev *tmp = NULL, *pdev = vdev->pdev;	unsigned char max_busnr;	unsigned int decodes;	if (single_vga || !vfio_vga_disabled() || pci_is_root_bus(pdev->bus))		return VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM |		       VGA_RSRC_LEGACY_IO | VGA_RSRC_LEGACY_MEM;	max_busnr = pci_bus_max_busnr(pdev->bus);	decodes = VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM;	while ((tmp = pci_get_class(PCI_CLASS_DISPLAY_VGA << 8, tmp)) != NULL) {		if (tmp == pdev ||		    pci_domain_nr(tmp->bus) != pci_domain_nr(pdev->bus) ||		    pci_is_root_bus(tmp->bus))			continue;		if (tmp->bus->number >= pdev->bus->number &&		    tmp->bus->number <= max_busnr) {			pci_dev_put(tmp);			decodes |= VGA_RSRC_LEGACY_IO | VGA_RSRC_LEGACY_MEM;			break;		}	}	return decodes;}",15298
32,413,CVE-2015-4645,30,"void progress_bar(long long current, long long max, int columns){	char rotate_list[] = { '|', '/', '-', '\\' };	int max_digits, used, hashes, spaces;	static int tty = -1;	if(max == 0)		return;	max_digits = floor(log10(max)) + 1;	used = max_digits * 2 + 11;	hashes = (current * (columns - used)) / max;	spaces = columns - used - hashes;	if((current > max) || (columns - used < 0))		return;	if(tty == -1)		tty = isatty(STDOUT_FILENO);	if(!tty) {		static long long previous = -1;		 		if((current % 100) != 0 && current != max)			return;		 		if(current == previous)			return;		previous = current;	}	printf(""\r["");	while (hashes --)		putchar('=');	putchar(rotate_list[rotate]);	while(spaces --)		putchar(' ');	printf(""] %*lld/%*lld"", max_digits, current, max_digits, max);	printf("" %3lld%%"", current * 100 / max);	fflush(stdout);}",22955
124,467,CVE-2018-1000524,30,map_num_zones(void){	return vector_len(s_map->zones);},23221
82,289,CVE-2016-9754,30,"static int rb_head_page_set(struct ring_buffer_per_cpu *cpu_buffer,			    struct buffer_page *head,			    struct buffer_page *prev,			    int old_flag, int new_flag){	struct list_head *list;	unsigned long val = (unsigned long)&head->list;	unsigned long ret;	list = &prev->list;	val &= ~RB_FLAG_MASK;	ret = cmpxchg((unsigned long *)&list->next,		      val | old_flag, val | new_flag);	 	if ((ret & ~RB_FLAG_MASK) != val)		return RB_PAGE_MOVED;	return ret & RB_FLAG_MASK;}",22683
48,28,CVE-2017-0553,30,"struct nlattr *nlmsg_attrdata(const struct nlmsghdr *nlh, int hdrlen){	unsigned char *data = nlmsg_data(nlh);	return (struct nlattr *) (data + NLMSG_ALIGN(hdrlen));}",2092
120,86,CVE-2016-9084,30,"static void vfio_pci_remove(struct pci_dev *pdev){	struct vfio_pci_device *vdev;	vdev = vfio_del_group_dev(&pdev->dev);	if (!vdev)		return;	vfio_iommu_group_put(pdev->dev.iommu_group, &pdev->dev);	kfree(vdev->region);	kfree(vdev);	if (vfio_pci_is_vga(pdev)) {		vga_client_register(pdev, NULL, NULL, NULL);		vga_set_legacy_decoding(pdev,				VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM |				VGA_RSRC_LEGACY_IO | VGA_RSRC_LEGACY_MEM);	}	if (!disable_idle_d3)		pci_set_power_state(pdev, PCI_D0);}",15296
75,392,CVE-2015-4645,30,"struct cache_entry *cache_get(struct cache *cache, long long block, int size){	 	int hash = CALCULATE_HASH(block);	struct cache_entry *entry;	pthread_mutex_lock(&cache->mutex);	for(entry = cache->hash_table[hash]; entry; entry = entry->hash_next)		if(entry->block == block)			break;	if(entry) {		 		if(entry->used == 0) {			cache->used ++;			remove_free_list(cache, entry);		}		entry->used ++;		pthread_mutex_unlock(&cache->mutex);	} else {		 		if(cache->count < cache->max_buffers) {			entry = malloc(sizeof(struct cache_entry));			if(entry == NULL)				EXIT_UNSQUASH(""Out of memory in cache_get\n"");			entry->data = malloc(cache->buffer_size);			if(entry->data == NULL)				EXIT_UNSQUASH(""Out of memory in cache_get\n"");			entry->cache = cache;			entry->free_prev = entry->free_next = NULL;			cache->count ++;		} else {			 			while(cache->free_list == NULL) {				cache->wait_free = TRUE;				pthread_cond_wait(&cache->wait_for_free,					&cache->mutex);			}			entry = cache->free_list;			remove_free_list(cache, entry);			remove_hash_table(cache, entry);		}		 		entry->block = block;		entry->size = size;		entry->used = 1;		entry->error = FALSE;		entry->pending = TRUE;		insert_hash_table(cache, entry);		cache->used ++;		 		pthread_mutex_unlock(&cache->mutex);		queue_put(to_reader, entry);	}	return entry;}",22934
118,155,CVE-2016-6250,30,"isofile_add_data_file(struct iso9660 *iso9660, struct isofile *file){	file->datanext = NULL;	*iso9660->data_file_list.last = file;	iso9660->data_file_list.last = &(file->datanext);}",16111
10,105,CVE-2016-9084,30,"int vfio_pci_set_irqs_ioctl(struct vfio_pci_device *vdev, int flags,			    unsigned index, unsigned start, unsigned count,			    void *data){	int (*func)(struct vfio_pci_device *vdev, unsigned index,		    unsigned start, unsigned count, int flags,		    void *data) = NULL;	switch (index) {	case VFIO_PCI_INTX_IRQ_INDEX:		switch (flags & VFIO_IRQ_SET_ACTION_TYPE_MASK) {		case VFIO_IRQ_SET_ACTION_MASK:			func = vfio_pci_set_intx_mask;			break;		case VFIO_IRQ_SET_ACTION_UNMASK:			func = vfio_pci_set_intx_unmask;			break;		case VFIO_IRQ_SET_ACTION_TRIGGER:			func = vfio_pci_set_intx_trigger;			break;		}		break;	case VFIO_PCI_MSI_IRQ_INDEX:	case VFIO_PCI_MSIX_IRQ_INDEX:		switch (flags & VFIO_IRQ_SET_ACTION_TYPE_MASK) {		case VFIO_IRQ_SET_ACTION_MASK:		case VFIO_IRQ_SET_ACTION_UNMASK:			 			break;		case VFIO_IRQ_SET_ACTION_TRIGGER:			func = vfio_pci_set_msi_trigger;			break;		}		break;	case VFIO_PCI_ERR_IRQ_INDEX:		switch (flags & VFIO_IRQ_SET_ACTION_TYPE_MASK) {		case VFIO_IRQ_SET_ACTION_TRIGGER:			if (pci_is_pcie(vdev->pdev))				func = vfio_pci_set_err_trigger;			break;		}		break;	case VFIO_PCI_REQ_IRQ_INDEX:		switch (flags & VFIO_IRQ_SET_ACTION_TYPE_MASK) {		case VFIO_IRQ_SET_ACTION_TRIGGER:			func = vfio_pci_set_req_trigger;			break;		}		break;	}	if (!func)		return -ENOTTY;	return func(vdev, index, start, count, flags, data);}",15315
49,80,CVE-2016-9084,30,"static int vfio_pci_get_devs(struct pci_dev *pdev, void *data){	struct vfio_devices *devs = data;	struct vfio_device *device;	if (devs->cur_index == devs->max_index)		return -ENOSPC;	device = vfio_device_get_from_dev(&pdev->dev);	if (!device)		return -EINVAL;	if (pci_dev_driver(pdev) != &vfio_pci_driver) {		vfio_device_put(device);		return -EBUSY;	}	devs->devices[devs->cur_index++] = device;	return 0;}",15290
53,592,CVE-2017-18255,30,"int perf_event_account_interrupt(struct perf_event *event){	return __perf_event_account_interrupt(event, 1);}",25665
43,30,CVE-2017-0553,30,void *nlmsg_data(const struct nlmsghdr *nlh){	return (unsigned char *) nlh + NLMSG_HDRLEN;},2094
8,299,CVE-2016-9754,30,static struct list_head *rb_list_head(struct list_head *list){	unsigned long val = (unsigned long)list;	return (struct list_head *)(val & ~RB_FLAG_MASK);},22693
85,474,CVE-2018-1000524,30,"trigger_get_xyz(int trigger_index, int* out_x, int* out_y, int* out_layer){	struct map_trigger* trigger;	trigger = vector_get(s_map->triggers, trigger_index);	if (out_x != NULL)		*out_x = trigger->x;	if (out_y != NULL)		*out_y = trigger->y;	if (out_layer) *out_layer = trigger->z;}",23228
28,79,CVE-2016-9084,30,"static int vfio_pci_for_each_slot_or_bus(struct pci_dev *pdev,					 int (*fn)(struct pci_dev *,						   void *data), void *data,					 int slot){	struct vfio_pci_walk_info walk = {		.fn = fn, .data = data, .pdev = pdev, .slot = slot, .ret = 0,	};	pci_walk_bus(pdev->bus, vfio_pci_walk_wrapper, &walk);	return walk.ret;}",15289
6,265,CVE-2016-9754,30,"__rb_reserve_next(struct ring_buffer_per_cpu *cpu_buffer,		  struct rb_event_info *info){	struct ring_buffer_event *event;	struct buffer_page *tail_page;	unsigned long tail, write;	 	if (unlikely(info->add_timestamp))		info->length += RB_LEN_TIME_EXTEND;	 	tail_page = info->tail_page = READ_ONCE(cpu_buffer->tail_page);	write = local_add_return(info->length, &tail_page->write);	 	write &= RB_WRITE_MASK;	tail = write - info->length;	 	if (!tail)		info->delta = 0;	 	if (unlikely(write > BUF_PAGE_SIZE))		return rb_move_tail(cpu_buffer, tail, info);	 	event = __rb_page_index(tail_page, tail);	kmemcheck_annotate_bitfield(event, bitfield);	rb_update_event(cpu_buffer, event, info);	local_inc(&tail_page->entries);	 	if (!tail)		tail_page->page->time_stamp = info->ts;	 	local_add(info->length, &cpu_buffer->entries_bytes);	return event;}",22659
113,77,CVE-2016-9084,30,"static int vfio_pci_dev_below_slot(struct pci_dev *pdev, struct pci_slot *slot){	for (; pdev; pdev = pdev->bus->self)		if (pdev->bus == slot->bus)			return (pdev->slot == slot);	return false;}",15287
99,396,CVE-2015-4645,30,"void dir_scan(char *parent_name, unsigned int start_block, unsigned int offset,	struct pathnames *paths){	unsigned int type;	char *name;	struct pathnames *new;	struct inode *i;	struct dir *dir = s_ops.squashfs_opendir(start_block, offset, &i);	if(dir == NULL) {		ERROR(""dir_scan: failed to read directory %s, skipping\n"",			parent_name);		return;	}	if(lsonly || info)		print_filename(parent_name, i);	if(!lsonly) {		 		int res = mkdir(parent_name, S_IRUSR|S_IWUSR|S_IXUSR);		if(res == -1) {			 			if(!force || errno != EEXIST) {				ERROR(""dir_scan: failed to make directory %s, ""					""because %s\n"", parent_name,					strerror(errno));				squashfs_closedir(dir);				FAILED = TRUE;				return;			} 			 			res = chmod(parent_name, S_IRUSR|S_IWUSR|S_IXUSR);			if (res == -1)				ERROR(""dir_scan: failed to change permissions ""					""for directory %s, because %s\n"",					parent_name, strerror(errno));		}	}	while(squashfs_readdir(dir, &name, &start_block, &offset, &type)) {		char *pathname;		int res;		TRACE(""dir_scan: name %s, start_block %d, offset %d, type %d\n"",			name, start_block, offset, type);		if(!matches(paths, name, &new))			continue;		res = asprintf(&pathname, ""%s/%s"", parent_name, name);		if(res == -1)			EXIT_UNSQUASH(""asprintf failed in dir_scan\n"");		if(type == SQUASHFS_DIR_TYPE) {			dir_scan(pathname, start_block, offset, new);			free(pathname);		} else if(new == NULL) {			update_info(pathname);			i = s_ops.read_inode(start_block, offset);			if(lsonly || info)				print_filename(pathname, i);			if(!lsonly)				create_inode(pathname, i);			if(i->type == SQUASHFS_SYMLINK_TYPE ||					i->type == SQUASHFS_LSYMLINK_TYPE)				free(i->symlink);		} else			free(pathname);		free_subdir(new);	}	if(!lsonly)		queue_dir(parent_name, dir);	squashfs_closedir(dir);	dir_count ++;}",22938
78,328,CVE-2016-9754,30,void *ring_buffer_event_data(struct ring_buffer_event *event){	return rb_event_data(event);},22722
81,295,CVE-2016-9754,30,"rb_is_head_page(struct ring_buffer_per_cpu *cpu_buffer,		struct buffer_page *page, struct list_head *list){	unsigned long val;	val = (unsigned long)list->next;	if ((val & ~RB_FLAG_MASK) != (unsigned long)&page->list)		return RB_PAGE_MOVED;	return val & RB_FLAG_MASK;}",22689
29,446,CVE-2018-1000524,30,map_engine_active_trigger(void){	return s_current_trigger;},23200
37,72,CVE-2017-12179,30,"barrier_is_blocking_direction(const struct PointerBarrier * barrier,                              int direction){         return (barrier->directions & direction) != direction;}",2578
145,575,CVE-2017-18257,30,"static int f2fs_set_data_page_dirty(struct page *page){	struct address_space *mapping = page->mapping;	struct inode *inode = mapping->host;	trace_f2fs_set_page_dirty(page, DATA);	if (!PageUptodate(page))		SetPageUptodate(page);	if (f2fs_is_atomic_file(inode) && !f2fs_is_commit_atomic_write(inode)) {		if (!IS_ATOMIC_WRITTEN_PAGE(page)) {			register_inmem_page(inode, page);			return 1;		}		 		return 0;	}	if (!PageDirty(page)) {		f2fs_set_page_dirty_nobuffers(page);		update_dirty_page(inode, page);		return 1;	}	return 0;}",25648
126,301,CVE-2016-9754,30,static int rb_lost_events(struct ring_buffer_per_cpu *cpu_buffer){	return cpu_buffer->lost_events;},22695
76,10,CVE-2016-6888,30,"void net_tx_pkt_build_vheader(struct NetTxPkt *pkt, int tso_enable,    int csum_enable, int gso_size){    struct tcp_hdr l4hdr;    assert(pkt);         assert(csum_enable || !tso_enable);    pkt->virt_hdr.gso_type = net_tx_pkt_get_gso_type(pkt, tso_enable);    switch (pkt->virt_hdr.gso_type & ~VIRTIO_NET_HDR_GSO_ECN) {    case VIRTIO_NET_HDR_GSO_NONE:        pkt->virt_hdr.hdr_len = 0;        pkt->virt_hdr.gso_size = 0;        break;    case VIRTIO_NET_HDR_GSO_UDP:        pkt->virt_hdr.gso_size = gso_size;        pkt->virt_hdr.hdr_len = pkt->hdr_len + sizeof(struct udp_header);        break;    case VIRTIO_NET_HDR_GSO_TCPV4:    case VIRTIO_NET_HDR_GSO_TCPV6:        iov_to_buf(&pkt->vec[NET_TX_PKT_PL_START_FRAG], pkt->payload_frags,                   0, &l4hdr, sizeof(l4hdr));        pkt->virt_hdr.hdr_len = pkt->hdr_len + l4hdr.th_off * sizeof(int);        pkt->virt_hdr.gso_size = gso_size;        break;    default:        g_assert_not_reached();    }    if (csum_enable) {        switch (pkt->l4proto) {        case IP_PROTO_TCP:            pkt->virt_hdr.flags = VIRTIO_NET_HDR_F_NEEDS_CSUM;            pkt->virt_hdr.csum_start = pkt->hdr_len;            pkt->virt_hdr.csum_offset = offsetof(struct tcp_hdr, th_sum);            break;        case IP_PROTO_UDP:            pkt->virt_hdr.flags = VIRTIO_NET_HDR_F_NEEDS_CSUM;            pkt->virt_hdr.csum_start = pkt->hdr_len;            pkt->virt_hdr.csum_offset = offsetof(struct udp_hdr, uh_sum);            break;        default:            break;        }    }}",1531
129,333,CVE-2016-9754,30,"ring_buffer_lock_reserve(struct ring_buffer *buffer, unsigned long length){	struct ring_buffer_per_cpu *cpu_buffer;	struct ring_buffer_event *event;	int cpu;	 	preempt_disable_notrace();	if (unlikely(atomic_read(&buffer->record_disabled)))		goto out;	cpu = raw_smp_processor_id();	if (unlikely(!cpumask_test_cpu(cpu, buffer->cpumask)))		goto out;	cpu_buffer = buffer->buffers[cpu];	if (unlikely(atomic_read(&cpu_buffer->record_disabled)))		goto out;	if (unlikely(length > BUF_MAX_DATA_SIZE))		goto out;	if (unlikely(trace_recursive_lock(cpu_buffer)))		goto out;	event = rb_reserve_next_event(buffer, cpu_buffer, length);	if (!event)		goto out_unlock;	return event; out_unlock:	trace_recursive_unlock(cpu_buffer); out:	preempt_enable_notrace();	return NULL;}",22727
44,125,CVE-2016-6250,30,"idr_resolve(struct idr *idr, void (*fsetnum)(unsigned char *p, int num)){	struct idrent *n;	unsigned char *p;	for (n = idr->wait_list.first; n != NULL; n = n->wnext) {		idr_extend_identifier(n, idr->num_size, idr->null_size);		p = (unsigned char *)n->isoent->identifier + n->noff;		do {			fsetnum(p, n->avail->rename_num++);		} while (!__archive_rb_tree_insert_node(		    &(idr->rbtree), &(n->rbnode)));	}}",16081
110,100,CVE-2016-9084,30,"static int vfio_pci_set_ctx_trigger_single(struct eventfd_ctx **ctx,					   unsigned int count, int flags,					   void *data){	 	if (flags & VFIO_IRQ_SET_DATA_NONE) {		if (*ctx) {			if (count) {				eventfd_signal(*ctx, 1);			} else {				eventfd_ctx_put(*ctx);				*ctx = NULL;			}			return 0;		}	} else if (flags & VFIO_IRQ_SET_DATA_BOOL) {		int trigger;		if (!count)			return -EINVAL;		trigger = *(int *)data;		if (trigger && *ctx)			eventfd_signal(*ctx, 1);		return 0;	} else if (flags & VFIO_IRQ_SET_DATA_EVENTFD) {		int fd;		if (!count)			return -EINVAL;		fd = *(int *)data;		if (fd == -1) {			if (*ctx)				eventfd_ctx_put(*ctx);			*ctx = NULL;		} else if (fd >= 0) {			struct eventfd_ctx *efdctx;			efdctx = eventfd_ctx_fdget(fd);			if (IS_ERR(efdctx))				return PTR_ERR(efdctx);			if (*ctx)				eventfd_ctx_put(*ctx);			*ctx = efdctx;		}		return 0;	}	return -EINVAL;}",15310
17,456,CVE-2018-1000524,30,map_engine_set_framerate(int framerate){	s_frame_rate = framerate;},23210
13,510,CVE-2018-13406,30,"static int uvesafb_setup(char *options){	char *this_opt;	if (!options || !*options)		return 0;	while ((this_opt = strsep(&options, "","")) != NULL) {		if (!*this_opt) continue;		if (!strcmp(this_opt, ""redraw""))			ypan = 0;		else if (!strcmp(this_opt, ""ypan""))			ypan = 1;		else if (!strcmp(this_opt, ""ywrap""))			ypan = 2;		else if (!strcmp(this_opt, ""vgapal""))			pmi_setpal = 0;		else if (!strcmp(this_opt, ""pmipal""))			pmi_setpal = 1;		else if (!strncmp(this_opt, ""mtrr:"", 5))			mtrr = simple_strtoul(this_opt+5, NULL, 0);		else if (!strcmp(this_opt, ""nomtrr""))			mtrr = 0;		else if (!strcmp(this_opt, ""nocrtc""))			nocrtc = 1;		else if (!strcmp(this_opt, ""noedid""))			noedid = 1;		else if (!strcmp(this_opt, ""noblank""))			blank = 0;		else if (!strncmp(this_opt, ""vtotal:"", 7))			vram_total = simple_strtoul(this_opt + 7, NULL, 0);		else if (!strncmp(this_opt, ""vremap:"", 7))			vram_remap = simple_strtoul(this_opt + 7, NULL, 0);		else if (!strncmp(this_opt, ""maxhf:"", 6))			maxhf = simple_strtoul(this_opt + 6, NULL, 0);		else if (!strncmp(this_opt, ""maxvf:"", 6))			maxvf = simple_strtoul(this_opt + 6, NULL, 0);		else if (!strncmp(this_opt, ""maxclk:"", 7))			maxclk = simple_strtoul(this_opt + 7, NULL, 0);		else if (!strncmp(this_opt, ""vbemode:"", 8))			vbemode = simple_strtoul(this_opt + 8, NULL, 0);		else if (this_opt[0] >= '0' && this_opt[0] <= '9') {			mode_option = this_opt;		} else {			pr_warn(""unrecognized option %s\n"", this_opt);		}	}	if (mtrr != 3 && mtrr != 0)		pr_warn(""uvesafb: mtrr should be set to 0 or 3; %d is unsupported"", mtrr);	return 0;}",24578
68,136,CVE-2016-6250,30,"isoent_cmp_joliet_identifier(const struct isoent *p1, const struct isoent *p2){	const unsigned char *s1, *s2;	int cmp;	int l;	s1 = (const unsigned char *)p1->identifier;	s2 = (const unsigned char *)p2->identifier;	 	l = p1->ext_off;	if (l > p2->ext_off)		l = p2->ext_off;	cmp = memcmp(s1, s2, l);	if (cmp != 0)		return (cmp);	if (p1->ext_off < p2->ext_off) {		s2 += l;		l = p2->ext_off - p1->ext_off;		while (l--)			if (0 != *s2++)				return (- *(const unsigned char *)(s2 - 1));	} else if (p1->ext_off > p2->ext_off) {		s1 += l;		l = p1->ext_off - p2->ext_off;		while (l--)			if (0 != *s1++)				return (*(const unsigned char *)(s1 - 1));	}	 	if (p1->ext_len == 0 && p2->ext_len == 0)		return (0);	if (p1->ext_len == 2 && p2->ext_len == 2)		return (0);	if (p1->ext_len <= 2)		return (-1);	if (p2->ext_len <= 2)		return (1);	l = p1->ext_len;	if (l > p2->ext_len)		l = p2->ext_len;	s1 = (unsigned char *)(p1->identifier + p1->ext_off);	s2 = (unsigned char *)(p2->identifier + p2->ext_off);	if (l > 1) {		cmp = memcmp(s1, s2, l);		if (cmp != 0)			return (cmp);	}	if (p1->ext_len < p2->ext_len) {		s2 += l;		l = p2->ext_len - p1->ext_len;		while (l--)			if (0 != *s2++)				return (- *(const unsigned char *)(s2 - 1));	} else if (p1->ext_len > p2->ext_len) {		s1 += l;		l = p1->ext_len - p2->ext_len;		while (l--)			if (0 != *s1++)				return (*(const unsigned char *)(s1 - 1));	}	 	 	return (cmp);}",16092
133,432,CVE-2018-1000524,30,"draw_persons(int layer, int is_flipped, int cam_x, int cam_y){	person_t*    person;	spriteset_t* sprite;	int          w, h;	double       x, y;	int          i;	for (i = 0; i < s_num_persons; ++i) {		person = s_persons[i];		if (!person->is_visible || person->layer != layer)			continue;		sprite = person->sprite;		w = spriteset_width(sprite);		h = spriteset_height(sprite);		person_get_xy(person, &x, &y, true);		x -= cam_x - person->x_offset;		y -= cam_y - person->y_offset;		spriteset_draw(sprite, person->mask, is_flipped, person->theta, person->scale_x, person->scale_y,			person->direction, trunc(x), trunc(y), person->frame);	}}",23186
131,122,CVE-2016-6250,30,"idr_init(struct iso9660 *iso9660, struct vdd *vdd, struct idr *idr){	idr->idrent_pool = NULL;	idr->pool_size = 0;	if (vdd->vdd_type != VDD_JOLIET) {		if (iso9660->opt.iso_level <= 3) {			memcpy(idr->char_map, d_characters_map,			    sizeof(idr->char_map));		} else {			memcpy(idr->char_map, d1_characters_map,			    sizeof(idr->char_map));			idr_relaxed_filenames(idr->char_map);		}	}}",16078
97,603,CVE-2018-18341,30,int IsNonCharacter(int character) {  return character >= kNonCharacter3 && character <= kNonCharacter1;},29972
143,46,CVE-2017-0553,30,"void nlmsg_set_creds(struct nl_msg *msg, struct ucred *creds){	memcpy(&msg->nm_creds, creds, sizeof(*creds));	msg->nm_flags |= NL_MSG_CRED_PRESENT;}",2110
52,381,CVE-2015-4645,30,"struct xattr_list *get_xattr(int i, unsigned int *count, int ignore){	long long start;	struct xattr_list *xattr_list = NULL;	unsigned int offset;	void *xptr;	int j = 0, res = 1;	TRACE(""get_xattr\n"");	*count = xattr_ids[i].count;	start = SQUASHFS_XATTR_BLK(xattr_ids[i].xattr) + xattr_table_start;	offset = SQUASHFS_XATTR_OFFSET(xattr_ids[i].xattr);	xptr = xattrs + get_xattr_block(start) + offset;	TRACE(""get_xattr: xattr_id %d, count %d, start %lld, offset %d\n"", i,			*count, start, offset);	while(j < *count) {		struct squashfs_xattr_entry entry;		struct squashfs_xattr_val val;		if(res != 0) {			xattr_list = realloc(xattr_list, (j + 1) *						sizeof(struct xattr_list));			if(xattr_list == NULL)				MEM_ERROR();		}					SQUASHFS_SWAP_XATTR_ENTRY(xptr, &entry);		xptr += sizeof(entry);		res = read_xattr_entry(&xattr_list[j], &entry, xptr);		if(ignore && res == 0) {			 			(*count) --;			continue;		}		if(res != 1)			goto failed;		xptr += entry.size;					TRACE(""get_xattr: xattr %d, type %d, size %d, name %s\n"", j,			entry.type, entry.size, xattr_list[j].full_name); 		if(entry.type & SQUASHFS_XATTR_VALUE_OOL) {			long long xattr;			void *ool_xptr;			xptr += sizeof(val);			SQUASHFS_SWAP_LONG_LONGS(xptr, &xattr, 1);			xptr += sizeof(xattr);				start = SQUASHFS_XATTR_BLK(xattr) + xattr_table_start;			offset = SQUASHFS_XATTR_OFFSET(xattr);			ool_xptr = xattrs + get_xattr_block(start) + offset;			SQUASHFS_SWAP_XATTR_VAL(ool_xptr, &val);			xattr_list[j].value = ool_xptr + sizeof(val);		} else {			SQUASHFS_SWAP_XATTR_VAL(xptr, &val);			xattr_list[j].value = xptr + sizeof(val);			xptr += sizeof(val) + val.vsize;		}		TRACE(""get_xattr: xattr %d, vsize %d\n"", j, val.vsize);		xattr_list[j ++].vsize = val.vsize;	}	if(*count == 0)		goto failed;	return xattr_list;failed:	free_xattr(xattr_list, j);	return NULL;}",22923
140,204,CVE-2016-5844,30,"isVDSetTerminator(struct iso9660 *iso9660, const unsigned char *h){	(void)iso9660;  	 	if (h[0] != 255)		return (0);	 	if (h[6] != 1)		return (0);	 	if (!isNull(iso9660, h, 7, 2048-7))		return (0);	return (1);}",16323
136,24,CVE-2017-0553,30,"int nl_msg_parse(struct nl_msg *msg, void (*cb)(struct nl_object *, void *),		 void *arg){	struct nl_cache_ops *ops;	struct nl_parser_param p = {		.pp_cb = parse_cb	};	struct dp_xdata x = {		.cb = cb,		.arg = arg,	};	int err;	ops = nl_cache_ops_associate_safe(nlmsg_get_proto(msg),					  nlmsg_hdr(msg)->nlmsg_type);	if (ops == NULL)		return -NLE_MSGTYPE_NOSUPPORT;	p.pp_arg = &x;	err = nl_cache_parse(ops, NULL, nlmsg_hdr(msg), &p);	nl_cache_ops_put(ops);	return err;}",2088
18,337,CVE-2016-9754,30,"ring_buffer_read_finish(struct ring_buffer_iter *iter){	struct ring_buffer_per_cpu *cpu_buffer = iter->cpu_buffer;	unsigned long flags;	 	raw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);	rb_check_pages(cpu_buffer);	raw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);	atomic_dec(&cpu_buffer->record_disabled);	atomic_dec(&cpu_buffer->buffer->resize_disabled);	kfree(iter);}",22731
58,338,CVE-2016-9754,30,"ring_buffer_read_prepare(struct ring_buffer *buffer, int cpu){	struct ring_buffer_per_cpu *cpu_buffer;	struct ring_buffer_iter *iter;	if (!cpumask_test_cpu(cpu, buffer->cpumask))		return NULL;	iter = kmalloc(sizeof(*iter), GFP_KERNEL);	if (!iter)		return NULL;	cpu_buffer = buffer->buffers[cpu];	iter->cpu_buffer = cpu_buffer;	atomic_inc(&buffer->resize_disabled);	atomic_inc(&cpu_buffer->record_disabled);	return iter;}",22732
150,91,CVE-2016-9084,30,"static int vfio_pci_walk_wrapper(struct pci_dev *pdev, void *data){	struct vfio_pci_walk_info *walk = data;	if (!walk->slot || vfio_pci_dev_below_slot(pdev, walk->pdev->slot))		walk->ret = walk->fn(pdev, walk->data);	return walk->ret;}",15301
12,590,CVE-2017-18255,30,"list_add_event(struct perf_event *event, struct perf_event_context *ctx){	lockdep_assert_held(&ctx->lock);	WARN_ON_ONCE(event->attach_state & PERF_ATTACH_CONTEXT);	event->attach_state |= PERF_ATTACH_CONTEXT;	 	if (event->group_leader == event) {		struct list_head *list;		event->group_caps = event->event_caps;		list = ctx_group_list(event, ctx);		list_add_tail(&event->group_entry, list);	}	list_update_cgroup_event(event, ctx, true);	list_add_rcu(&event->event_entry, &ctx->event_list);	ctx->nr_events++;	if (event->attr.inherit_stat)		ctx->nr_stat++;	ctx->generation++;}",25663
4,486,CVE-2018-1000127,30,"static void remove_pidfile(const char *pid_file) {  if (pid_file == NULL)      return;  if (unlink(pid_file) != 0) {      vperror(""Could not remove the pid file %s"", pid_file);  }}",23241
142,488,CVE-2018-1000127,30,static void settings_init(void) {    settings.use_cas = true;    settings.access = 0700;    settings.port = 11211;    settings.udpport = 11211;         settings.inter = NULL;    settings.maxbytes = 64 * 1024 * 1024;      settings.maxconns = 1024;              settings.verbose = 0;    settings.oldest_live = 0;    settings.oldest_cas = 0;               settings.evict_to_free = 1;            settings.socketpath = NULL;            settings.factor = 1.25;    settings.chunk_size = 48;              settings.num_threads = 4;              settings.num_threads_per_udp = 0;    settings.prefix_delimiter = ':';    settings.detail_enabled = 0;    settings.reqs_per_event = 20;    settings.backlog = 1024;    settings.binding_protocol = negotiating_prot;    settings.item_size_max = 1024 * 1024;      settings.slab_page_size = 1024 * 1024;      settings.slab_chunk_size_max = settings.slab_page_size;    settings.sasl = false;    settings.maxconns_fast = false;    settings.lru_crawler = false;    settings.lru_crawler_sleep = 100;    settings.lru_crawler_tocrawl = 0;    settings.lru_maintainer_thread = false;    settings.lru_segmented = false;    settings.hot_lru_pct = 32;    settings.warm_lru_pct = 32;    settings.hot_max_age = 3600;    settings.warm_max_factor = 2.0;    settings.inline_ascii_response = true;    settings.temp_lru = false;    settings.temporary_ttl = 61;    settings.idle_timeout = 0;      settings.hashpower_init = 0;    settings.slab_reassign = false;    settings.slab_automove = 0;    settings.shutdown_command = false;    settings.tail_repair_time = TAIL_REPAIR_TIME_DEFAULT;    settings.flush_enabled = true;    settings.dump_enabled = true;    settings.crawls_persleep = 1000;    settings.logger_watcher_buf_size = LOGGER_WATCHER_BUF_SIZE;    settings.logger_buf_size = LOGGER_BUF_SIZE;},23243
25,523,CVE-2018-12896,30,"static inline void sample_cputime_atomic(struct task_cputime *times,					 struct task_cputime_atomic *atomic_times){	times->utime = atomic64_read(&atomic_times->utime);	times->stime = atomic64_read(&atomic_times->stime);	times->sum_exec_runtime = atomic64_read(&atomic_times->sum_exec_runtime);}",24743
155,236,CVE-2016-5094,30,"PHP_FUNCTION(htmlentities){	php_html_entities(INTERNAL_FUNCTION_PARAM_PASSTHRU, 1);}",16525
105,383,CVE-2015-4645,30,"static int read_xattr_entry(struct xattr_list *xattr,	struct squashfs_xattr_entry *entry, void *name){	int i, len, type = entry->type & XATTR_PREFIX_MASK;	for(i = 0; prefix_table[i].type != -1; i++)		if(prefix_table[i].type == type)			break;	if(prefix_table[i].type == -1) {		ERROR(""Unrecognised type in read_xattr_entry\n"");		return 0;	}	len = strlen(prefix_table[i].prefix);	xattr->full_name = malloc(len + entry->size + 1);	if(xattr->full_name == NULL)		MEM_ERROR();	memcpy(xattr->full_name, prefix_table[i].prefix, len);	memcpy(xattr->full_name + len, name, entry->size);	xattr->full_name[len + entry->size] = '\0';	xattr->name = xattr->full_name + len;	xattr->size = entry->size;	xattr->type = type;	return 1;}",22925
21,489,CVE-2018-1000127,30,"static void sig_handler(const int sig) {    printf(""Signal handled: %s.\n"", strsignal(sig));    exit(EXIT_SUCCESS);}",23244
114,613,CVE-2019-5792,30,  void FlushMojo() { client_.FlushForTesting(); },30215
40,249,CVE-2016-4300,30,free_Header(struct _7z_header_info *h){	free(h->emptyStreamBools);	free(h->emptyFileBools);	free(h->antiBools);	free(h->attrBools);},17112
19,401,CVE-2015-4645,30,"char *get_component(char *target, char **targname){	char *start;	while(*target == '/')		target ++;	start = target;	while(*target != '/' && *target != '\0')		target ++;	*targname = strndup(start, target - start);	while(*target == '/')		target ++;	return target;}",22943
47,304,CVE-2016-9754,30,rb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer){	return local_read(&cpu_buffer->entries) -		(local_read(&cpu_buffer->overrun) + cpu_buffer->read);},22698
84,335,CVE-2016-9754,30,"int ring_buffer_print_entry_header(struct trace_seq *s){	trace_seq_puts(s, ""# compressed entry header\n"");	trace_seq_puts(s, ""\ttype_len    :    5 bits\n"");	trace_seq_puts(s, ""\ttime_delta  :   27 bits\n"");	trace_seq_puts(s, ""\tarray       :   32 bits\n"");	trace_seq_putc(s, '\n');	trace_seq_printf(s, ""\tpadding     : type == %d\n"",			 RINGBUF_TYPE_PADDING);	trace_seq_printf(s, ""\ttime_extend : type == %d\n"",			 RINGBUF_TYPE_TIME_EXTEND);	trace_seq_printf(s, ""\tdata max type_len  == %d\n"",			 RINGBUF_TYPE_DATA_TYPE_LEN_MAX);	return !trace_seq_has_overflowed(s);}",22729
54,157,CVE-2016-6250,30,"isofile_free(struct isofile *file){	struct content *con, *tmp;	con = file->content.next;	while (con != NULL) {		tmp = con;		con = con->next;		free(tmp);	}	archive_entry_free(file->entry);	archive_string_free(&(file->parentdir));	archive_string_free(&(file->basename));	archive_string_free(&(file->basename_utf16));	archive_string_free(&(file->symlink));	free(file);}",16113
71,260,CVE-2017-17854,30,"static int regsafe(struct bpf_reg_state *rold, struct bpf_reg_state *rcur,		    struct idpair *idmap){	if (!(rold->live & REG_LIVE_READ))		 		return true;	if (memcmp(rold, rcur, offsetof(struct bpf_reg_state, live)) == 0)		return true;	if (rold->type == NOT_INIT)		 		return true;	if (rcur->type == NOT_INIT)		return false;	switch (rold->type) {	case SCALAR_VALUE:		if (rcur->type == SCALAR_VALUE) {			 			return range_within(rold, rcur) &&			       tnum_in(rold->var_off, rcur->var_off);		} else {			 			return false;		}	case PTR_TO_MAP_VALUE:		 		return memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)) == 0 &&		       range_within(rold, rcur) &&		       tnum_in(rold->var_off, rcur->var_off);	case PTR_TO_MAP_VALUE_OR_NULL:		 		if (rcur->type != PTR_TO_MAP_VALUE_OR_NULL)			return false;		if (memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)))			return false;		 		return check_ids(rold->id, rcur->id, idmap);	case PTR_TO_PACKET_META:	case PTR_TO_PACKET:		if (rcur->type != rold->type)			return false;		 		if (rold->range > rcur->range)			return false;		 		if (rold->off != rcur->off)			return false;		 		if (rold->id && !check_ids(rold->id, rcur->id, idmap))			return false;		 		return range_within(rold, rcur) &&		       tnum_in(rold->var_off, rcur->var_off);	case PTR_TO_CTX:	case CONST_PTR_TO_MAP:	case PTR_TO_STACK:	case PTR_TO_PACKET_END:		 	default:		 		return false;	}	 	WARN_ON_ONCE(1);	return false;}",19568
11,390,CVE-2015-4645,30,"void cache_block_put(struct cache_entry *entry){	 	pthread_mutex_lock(&entry->cache->mutex);	entry->used --;	if(entry->used == 0) {		insert_free_list(entry->cache, entry);		entry->cache->used --;		 		if(entry->cache->wait_free) {			entry->cache->wait_free = FALSE;			pthread_cond_broadcast(&entry->cache->wait_for_free);		}	}	pthread_mutex_unlock(&entry->cache->mutex);}",22932
23,194,CVE-2016-5844,30,"archive_read_format_iso9660_options(struct archive_read *a,		const char *key, const char *val){	struct iso9660 *iso9660;	iso9660 = (struct iso9660 *)(a->format->data);	if (strcmp(key, ""joliet"") == 0) {		if (val == NULL || strcmp(val, ""off"") == 0 ||				strcmp(val, ""ignore"") == 0 ||				strcmp(val, ""disable"") == 0 ||				strcmp(val, ""0"") == 0)			iso9660->opt_support_joliet = 0;		else			iso9660->opt_support_joliet = 1;		return (ARCHIVE_OK);	}	if (strcmp(key, ""rockridge"") == 0 ||	    strcmp(key, ""Rockridge"") == 0) {		iso9660->opt_support_rockridge = val != NULL;		return (ARCHIVE_OK);	}	 	return (ARCHIVE_WARN);}",16313
148,563,CVE-2018-6927,30,"void requeue_futex(struct futex_q *q, struct futex_hash_bucket *hb1,		   struct futex_hash_bucket *hb2, union futex_key *key2){	 	if (likely(&hb1->chain != &hb2->chain)) {		plist_del(&q->list, &hb1->chain);		hb_waiters_dec(hb1);		hb_waiters_inc(hb2);		plist_add(&q->list, &hb2->chain);		q->lock_ptr = &hb2->lock;	}	get_futex_key_refs(key2);	q->key = *key2;}",25394
88,145,CVE-2016-6250,30,"isoent_create_virtual_dir(struct archive_write *a, struct iso9660 *iso9660, const char *pathname){	struct isofile *file;	struct isoent *isoent;	file = isofile_new(a, NULL);	if (file == NULL)		return (NULL);	archive_entry_set_pathname(file->entry, pathname);	archive_entry_unset_mtime(file->entry);	archive_entry_unset_atime(file->entry);	archive_entry_unset_ctime(file->entry);	archive_entry_set_uid(file->entry, getuid());	archive_entry_set_gid(file->entry, getgid());	archive_entry_set_mode(file->entry, 0555 | AE_IFDIR);	archive_entry_set_nlink(file->entry, 2);	if (isofile_gen_utility_names(a, file) < ARCHIVE_WARN) {		isofile_free(file);		return (NULL);	}	isofile_add_entry(iso9660, file);	isoent = isoent_new(file);	if (isoent == NULL)		return (NULL);	isoent->dir = 1;	isoent->virtual = 1;	return (isoent);}",16101
115,9,CVE-2017-9835,30,"broken_splay(){    dlprintf(""Broken splay tree!\n"");}",896
127,554,CVE-2018-6927,30,"static inline void __queue_me(struct futex_q *q, struct futex_hash_bucket *hb){	int prio;	 	prio = min(current->normal_prio, MAX_RT_PRIO);	plist_node_init(&q->list, prio);	plist_add(&q->list, &hb->chain);	q->task = current;}",25385
132,174,CVE-2016-6250,30,"set_num_721(unsigned char *p, int value){	archive_le16enc(p, value);}",16130
151,445,CVE-2018-1000524,30,map_engine_active_person(void){	return s_current_person;},23199
9,341,CVE-2016-9754,30,void ring_buffer_record_disable(struct ring_buffer *buffer){	atomic_inc(&buffer->record_disabled);},22735
109,511,CVE-2018-13406,30,"static void uvesafb_setup_var(struct fb_var_screeninfo *var,		struct fb_info *info, struct vbe_mode_ib *mode){	struct uvesafb_par *par = info->par;	var->vmode = FB_VMODE_NONINTERLACED;	var->sync = FB_SYNC_VERT_HIGH_ACT;	var->xres = mode->x_res;	var->yres = mode->y_res;	var->xres_virtual = mode->x_res;	var->yres_virtual = (par->ypan) ?			info->fix.smem_len / mode->bytes_per_scan_line :			mode->y_res;	var->xoffset = 0;	var->yoffset = 0;	var->bits_per_pixel = mode->bits_per_pixel;	if (var->bits_per_pixel == 15)		var->bits_per_pixel = 16;	if (var->bits_per_pixel > 8) {		var->red.offset    = mode->red_off;		var->red.length    = mode->red_len;		var->green.offset  = mode->green_off;		var->green.length  = mode->green_len;		var->blue.offset   = mode->blue_off;		var->blue.length   = mode->blue_len;		var->transp.offset = mode->rsvd_off;		var->transp.length = mode->rsvd_len;	} else {		var->red.offset    = 0;		var->green.offset  = 0;		var->blue.offset   = 0;		var->transp.offset = 0;		var->red.length    = 8;		var->green.length  = 8;		var->blue.length   = 8;		var->transp.length = 0;	}}",24579
116,339,CVE-2016-9754,30,ring_buffer_read_prepare_sync(void){	synchronize_sched();},22733
57,463,CVE-2018-1000524,30,"map_layer_by_name(const char* name){	int i;	for (i = 0; i < s_map->num_layers; ++i) {		if (strcmp(name, lstr_cstr(s_map->layers[0].name)) == 0)			return i;	}	return -1;}",23217
80,221,CVE-2016-5770,30,"SPL_METHOD(FilesystemIterator, __construct){	spl_filesystem_object_construct(INTERNAL_FUNCTION_PARAM_PASSTHRU, DIT_CTOR_FLAGS | SPL_FILE_DIR_SKIPDOTS);}",16347
111,588,CVE-2017-18255,30,static void free_pmu_context(struct pmu *pmu){	mutex_lock(&pmus_lock);	free_percpu(pmu->pmu_cpu_context);	mutex_unlock(&pmus_lock);},25661
119,283,CVE-2016-9754,30,static void rb_event_set_padding(struct ring_buffer_event *event){	 	event->type_len = RINGBUF_TYPE_PADDING;	event->time_delta = 0;},22677
79,514,CVE-2018-13406,30,"static void uvesafb_vbe_getmonspecs(struct uvesafb_ktask *task,				    struct fb_info *info){	struct uvesafb_par *par = info->par;	int i;	memset(&info->monspecs, 0, sizeof(info->monspecs));	 	if (uvesafb_vbe_getedid(task, info)) {		info->monspecs.gtf = 0;		par->nocrtc = 1;	}	 	if (maxclk)		info->monspecs.dclkmax = maxclk * 1000000;	if (maxvf)		info->monspecs.vfmax = maxvf;	if (maxhf)		info->monspecs.hfmax = maxhf * 1000;	 	if (info->monspecs.gtf == 0 && maxclk && maxvf && maxhf) {		info->monspecs.dclkmin = 0;		info->monspecs.vfmin = 60;		info->monspecs.hfmin = 29000;		info->monspecs.gtf = 1;		par->nocrtc = 0;	}	if (info->monspecs.gtf)		pr_info(""monitor limits: vf = %d Hz, hf = %d kHz, clk = %d MHz\n"",			info->monspecs.vfmax,			(int)(info->monspecs.hfmax / 1000),			(int)(info->monspecs.dclkmax / 1000000));	else		pr_info(""no monitor limits have been set, default refresh rate will be used\n"");	 	for (i = 0; i < par->vbe_modes_cnt; i++) {		struct fb_var_screeninfo var;		struct vbe_mode_ib *mode;		struct fb_videomode vmode;		mode = &par->vbe_modes[i];		memset(&var, 0, sizeof(var));		var.xres = mode->x_res;		var.yres = mode->y_res;		fb_get_mode(FB_VSYNCTIMINGS | FB_IGNOREMON, 60, &var, info);		fb_var_to_videomode(&vmode, &var);		fb_add_videomode(&vmode, &info->modelist);	}	 	for (i = 0; i < VESA_MODEDB_SIZE; i++) {		if (uvesafb_is_valid_mode((struct fb_videomode *)						&vesa_modes[i], info))			fb_add_videomode(&vesa_modes[i], &info->modelist);	}	for (i = 0; i < info->monspecs.modedb_len; i++) {		if (uvesafb_is_valid_mode(&info->monspecs.modedb[i], info))			fb_add_videomode(&info->monspecs.modedb[i],					&info->modelist);	}	return;}",24582
134,292,CVE-2016-9754,30,"static int rb_head_page_set_update(struct ring_buffer_per_cpu *cpu_buffer,				   struct buffer_page *head,				   struct buffer_page *prev,				   int old_flag){	return rb_head_page_set(cpu_buffer, head, prev,				old_flag, RB_PAGE_UPDATE);}",22686
86,428,CVE-2015-4645,30,void squashfs_closedir(struct dir *dir){	free(dir->dirs);	free(dir);},22970
34,361,CVE-2016-9557,30,int jas_setdbglevel(int dbglevel){	int olddbglevel;	 	olddbglevel = jas_dbglevel;	 	jas_dbglevel = dbglevel;	 	return olddbglevel;},22755
152,414,CVE-2015-4645,30,"void *progress_thread(void *arg){	struct timespec requested_time, remaining;	struct itimerval itimerval;	struct winsize winsize;	if(ioctl(1, TIOCGWINSZ, &winsize) == -1) {		if(isatty(STDOUT_FILENO))			ERROR(""TIOCGWINSZ ioctl failed, defaulting to 80 ""				""columns\n"");		columns = 80;	} else		columns = winsize.ws_col;	signal(SIGWINCH, sigwinch_handler);	signal(SIGALRM, sigalrm_handler);	itimerval.it_value.tv_sec = 0;	itimerval.it_value.tv_usec = 250000;	itimerval.it_interval.tv_sec = 0;	itimerval.it_interval.tv_usec = 250000;	setitimer(ITIMER_REAL, &itimerval, NULL);	requested_time.tv_sec = 0;	requested_time.tv_nsec = 250000000;	while(1) {		int res = nanosleep(&requested_time, &remaining);		if(res == -1 && errno != EINTR)			EXIT_UNSQUASH(""nanosleep failed in progress thread\n"");		if(progress_enabled) {			pthread_mutex_lock(&screen_mutex);			progress_bar(sym_count + dev_count +				fifo_count + cur_blocks, total_inodes -				total_files + total_blocks, columns);			pthread_mutex_unlock(&screen_mutex);		}	}}",22956
2,595,CVE-2017-18255,30,"static int perf_event_read(struct perf_event *event, int group){	int event_cpu, ret = 0;	 	if (event->state == PERF_EVENT_STATE_ACTIVE) {		struct perf_read_data data = {			.event = event,			.group = group,			.ret = 0,		};		event_cpu = READ_ONCE(event->oncpu);		if ((unsigned)event_cpu >= nr_cpu_ids)			return 0;		preempt_disable();		event_cpu = __perf_event_read_cpu(event, event_cpu);		 		(void)smp_call_function_single(event_cpu, __perf_event_read, &data, 1);		preempt_enable();		ret = data.ret;	} else if (event->state == PERF_EVENT_STATE_INACTIVE) {		struct perf_event_context *ctx = event->ctx;		unsigned long flags;		raw_spin_lock_irqsave(&ctx->lock, flags);		 		if (ctx->is_active) {			update_context_time(ctx);			update_cgrp_time_from_event(event);		}		if (group)			update_group_times(event);		else			update_event_times(event);		raw_spin_unlock_irqrestore(&ctx->lock, flags);	}	return ret;}",25668
83,404,CVE-2015-4645,30,"long long lookup_entry(struct hash_table_entry *hash_table[], long long start){	int hash = CALCULATE_HASH(start);	struct hash_table_entry *hash_table_entry;	for(hash_table_entry = hash_table[hash]; hash_table_entry;				hash_table_entry = hash_table_entry->next)		if(hash_table_entry->start == start)			return hash_table_entry->bytes;	return -1;}",22946
92,528,CVE-2018-12896,30,"static void update_gt_cputime(struct task_cputime_atomic *cputime_atomic, struct task_cputime *sum){	__update_gt_cputime(&cputime_atomic->utime, sum->utime);	__update_gt_cputime(&cputime_atomic->stime, sum->stime);	__update_gt_cputime(&cputime_atomic->sum_exec_runtime, sum->sum_exec_runtime);}",24748
123,2,CVE-2017-16612,30,"_XcursorBuildFullname (const char *dir, const char *subdir, const char *file){    char    *full;    if (!dir || !subdir || !file)        return NULL;    full = malloc (strlen (dir) + 1 + strlen (subdir) + 1 + strlen (file) + 1);    if (!full)	return NULL;    full[0] = '\0';    _XcursorAddPathElt (full, dir, -1);    _XcursorAddPathElt (full, subdir, -1);    _XcursorAddPathElt (full, file, -1);    return full;}",307
38,540,CVE-2018-12896,30,"static inline void unlock_timer(struct k_itimer *timr, unsigned long flags){	spin_unlock_irqrestore(&timr->it_lock, flags);}",24760
102,83,CVE-2016-9084,30,"static int vfio_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id){	struct vfio_pci_device *vdev;	struct iommu_group *group;	int ret;	if (pdev->hdr_type != PCI_HEADER_TYPE_NORMAL)		return -EINVAL;	group = vfio_iommu_group_get(&pdev->dev);	if (!group)		return -EINVAL;	vdev = kzalloc(sizeof(*vdev), GFP_KERNEL);	if (!vdev) {		vfio_iommu_group_put(group, &pdev->dev);		return -ENOMEM;	}	vdev->pdev = pdev;	vdev->irq_type = VFIO_PCI_NUM_IRQS;	mutex_init(&vdev->igate);	spin_lock_init(&vdev->irqlock);	ret = vfio_add_group_dev(&pdev->dev, &vfio_pci_ops, vdev);	if (ret) {		vfio_iommu_group_put(group, &pdev->dev);		kfree(vdev);		return ret;	}	if (vfio_pci_is_vga(pdev)) {		vga_client_register(pdev, vdev, NULL, vfio_pci_set_vga_decode);		vga_set_legacy_decoding(pdev,					vfio_pci_set_vga_decode(vdev, false));	}	if (!disable_idle_d3) {		 		pci_set_power_state(pdev, PCI_D0);		pci_set_power_state(pdev, PCI_D3hot);	}	return ret;}",15293
149,222,CVE-2016-5770,30,"SPL_METHOD(RecursiveDirectoryIterator, __construct){	spl_filesystem_object_construct(INTERNAL_FUNCTION_PARAM_PASSTHRU, DIT_CTOR_FLAGS);}",16348
27,169,CVE-2016-6250,30,"set_SUSP_CE(unsigned char *p, int location, int offset, int size){	unsigned char *bp = p -1;	 	bp[1] = 'C';	bp[2] = 'E';	bp[3] = RR_CE_SIZE;	 	bp[4] = 1;		 	set_num_733(bp+5, location);	set_num_733(bp+13, offset);	set_num_733(bp+21, size);	return (RR_CE_SIZE);}",16125
125,142,CVE-2016-6250,30,"isoent_cmp_node_joliet(const struct archive_rb_node *n1,    const struct archive_rb_node *n2){	const struct idrent *e1 = (const struct idrent *)n1;	const struct idrent *e2 = (const struct idrent *)n2;	return (isoent_cmp_joliet_identifier(e2->isoent, e1->isoent));}",16098
135,148,CVE-2016-6250,30,"isoent_free_all(struct isoent *isoent){	struct isoent *np, *np_temp;	if (isoent == NULL)		return;	np = isoent;	for (;;) {		if (np->dir) {			if (np->children.first != NULL) {				 				np = np->children.first;				continue;			}		}		for (;;) {			np_temp = np;			if (np->chnext == NULL) {				 				np = np->parent;				_isoent_free(np_temp);				if (np == np_temp)					return;			} else {				np = np->chnext;				_isoent_free(np_temp);				break;			}		}	}}",16104
64,73,CVE-2017-12179,30,barrier_is_horizontal(const struct PointerBarrier *barrier){    return barrier->y1 == barrier->y2;},2579
33,36,CVE-2017-0553,30,int nlmsg_get_proto(struct nl_msg *msg){	return msg->nm_protocol;},2100
45,166,CVE-2016-6250,30,"joliet_allowed_char(unsigned char high, unsigned char low){	int utf16 = (high << 8) | low;	if (utf16 <= 0x001F)		return (0);	switch (utf16) {	case 0x002A:  	case 0x002F:  	case 0x003A:  	case 0x003B:  	case 0x003F:  	case 0x005C:  		return (0); 	}	return (1);}",16122
103,99,CVE-2016-9084,30,"static int vfio_pci_intx_unmask_handler(void *opaque, void *unused){	struct vfio_pci_device *vdev = opaque;	struct pci_dev *pdev = vdev->pdev;	unsigned long flags;	int ret = 0;	spin_lock_irqsave(&vdev->irqlock, flags);	 	if (unlikely(!is_intx(vdev))) {		if (vdev->pci_2_3)			pci_intx(pdev, 1);	} else if (vdev->ctx[0].masked && !vdev->virq_disabled) {		 		if (vdev->pci_2_3) {			if (!pci_check_and_unmask_intx(pdev))				ret = 1;		} else			enable_irq(pdev->irq);		vdev->ctx[0].masked = (ret > 0);	}	spin_unlock_irqrestore(&vdev->irqlock, flags);	return ret;}",15309
42,349,CVE-2016-9754,30,"unsigned long ring_buffer_size(struct ring_buffer *buffer, int cpu){	 	if (!cpumask_test_cpu(cpu, buffer->cpumask))		return 0;	return BUF_PAGE_SIZE * buffer->buffers[cpu]->nr_pages;}",22743
5,31,CVE-2017-0553,30,int nlmsg_datalen(const struct nlmsghdr *nlh){	return nlh->nlmsg_len - NLMSG_HDRLEN;},2095
26,363,CVE-2016-9557,30,"static long jas_iccpowi(int x, int n){	long y;	y = 1;	while (--n >= 0)		y *= x;	return y; }",22757
77,566,CVE-2018-6927,30,static int unqueue_me(struct futex_q *q){	spinlock_t *lock_ptr;	int ret = 0;	 retry:	 	lock_ptr = READ_ONCE(q->lock_ptr);	if (lock_ptr != NULL) {		spin_lock(lock_ptr);		 		if (unlikely(lock_ptr != q->lock_ptr)) {			spin_unlock(lock_ptr);			goto retry;		}		__unqueue_futex(q);		BUG_ON(q->pi_state);		spin_unlock(lock_ptr);		ret = 1;	}	drop_futex_key_refs(&q->key);	return ret;},25397
16,376,CVE-2016-8636,30,"int rxe_mem_init_fast(struct rxe_dev *rxe, struct rxe_pd *pd,		      int max_pages, struct rxe_mem *mem){	int err;	rxe_mem_init(0, mem);	 	mem->ibmr.rkey = mem->ibmr.lkey;	err = rxe_mem_alloc(rxe, mem, max_pages);	if (err)		goto err1;	mem->pd			= pd;	mem->max_buf		= max_pages;	mem->state		= RXE_MEM_STATE_FREE;	mem->type		= RXE_MEM_TYPE_MR;	return 0;err1:	return err;}",22781
122,505,CVE-2018-13406,30,"static struct uvesafb_ktask *uvesafb_prep(void){	struct uvesafb_ktask *task;	task = kzalloc(sizeof(*task), GFP_KERNEL);	if (task) {		task->done = kzalloc(sizeof(*task->done), GFP_KERNEL);		if (!task->done) {			kfree(task);			task = NULL;		}	}	return task;}",24573
94,347,CVE-2016-9754,30,"void ring_buffer_record_on(struct ring_buffer *buffer){	unsigned int rd;	unsigned int new_rd;	do {		rd = atomic_read(&buffer->record_disabled);		new_rd = rd & ~RB_BUFFER_OFF;	} while (atomic_cmpxchg(&buffer->record_disabled, rd, new_rd) != rd);}",22741
112,45,CVE-2017-0553,30,"struct nlmsghdr *nlmsg_put(struct nl_msg *n, int pid, int seq,			   int type, int payload, int flags){	struct nlmsghdr *nlh;	if (n->nm_nlh->nlmsg_len < NLMSG_HDRLEN)		BUG();	nlh = (struct nlmsghdr *) n->nm_nlh;	nlh->nlmsg_type = type;	nlh->nlmsg_flags = flags;	nlh->nlmsg_pid = pid;	nlh->nlmsg_seq = seq;	NL_DBG(2, ""msg %p: Added netlink header type=%d, flags=%d, pid=%d, ""		  ""seq=%d\n"", n, type, flags, pid, seq);	if (payload > 0 &&	    nlmsg_reserve(n, payload, NLMSG_ALIGNTO) == NULL)		return NULL;	return nlh;}",2109
36,208,CVE-2016-5844,30,"parse_rockridge_NM1(struct file_info *file,		    const unsigned char *data, int data_length){	if (!file->name_continues)		archive_string_empty(&file->name);	file->name_continues = 0;	if (data_length < 1)		return;	 	switch(data[0]) {	case 0:		if (data_length < 2)			return;		archive_strncat(&file->name,		    (const char *)data + 1, data_length - 1);		break;	case 1:		if (data_length < 2)			return;		archive_strncat(&file->name,		    (const char *)data + 1, data_length - 1);		file->name_continues = 1;		break;	case 2:		archive_strcat(&file->name, ""."");		break;	case 4:		archive_strcat(&file->name, "".."");		break;	default:		return;	}}",16327
24,550,CVE-2018-11590,30,"long long stringToInt(const char *s) {  return stringToIntWithRadix(s,0,NULL,NULL);}",25145
139,141,CVE-2016-6250,30,"isoent_cmp_node_iso9660(const struct archive_rb_node *n1,    const struct archive_rb_node *n2){	const struct idrent *e1 = (const struct idrent *)n1;	const struct idrent *e2 = (const struct idrent *)n2;	return (isoent_cmp_iso9660_identifier(e2->isoent, e1->isoent));}",16097
20,183,CVE-2016-6250,30,wb_buffptr(struct archive_write *a){	struct iso9660 *iso9660 = (struct iso9660 *)a->format_data;	return (&(iso9660->wbuff[sizeof(iso9660->wbuff)		- iso9660->wbuff_remaining]));},16139
117,57,CVE-2014-0143,30,static void bdrv_bochs_init(void){    bdrv_register(&bdrv_bochs);},2512
147,60,CVE-2014-0143,30,"int bdrv_parse_discard_flags(const char *mode, int *flags){    *flags &= ~BDRV_O_UNMAP;    if (!strcmp(mode, ""off"") || !strcmp(mode, ""ignore"")) {             } else if (!strcmp(mode, ""on"") || !strcmp(mode, ""unmap"")) {        *flags |= BDRV_O_UNMAP;    } else {        return -1;    }    return 0;}",2515
141,69,CVE-2017-12179,30,"barrier_get_direction(int x1, int y1, int x2, int y2){    int direction = 0;         if (x2 > x1)        direction |= BarrierPositiveX;    if (x2 < x1)        direction |= BarrierNegativeX;    if (y2 > y1)        direction |= BarrierPositiveY;    if (y2 < y1)        direction |= BarrierNegativeY;    return direction;}",2575
69,247,CVE-2016-4300,30,free_Digest(struct _7z_digests *d){	free(d->defineds);	free(d->digests);},17110
39,47,CVE-2017-0553,30,"void nlmsg_set_dst(struct nl_msg *msg, struct sockaddr_nl *addr){	memcpy(&msg->nm_dst, addr, sizeof(*addr));}",2111
46,369,CVE-2016-9557,30,char *jas_image_fmttostr(int fmt){	jas_image_fmtinfo_t *fmtinfo;	if (!(fmtinfo = jas_image_lookupfmtbyid(fmt))) {		return 0;	}	return fmtinfo->name;},22763
144,400,CVE-2015-4645,30,void free_subdir(struct pathnames *paths){	free(paths);},22942
63,377,CVE-2016-5735,30,static void rwpng_free_chunks(struct rwpng_chunk *chunk) {    if (!chunk) return;    rwpng_free_chunks(chunk->next);    free(chunk->data);    free(chunk);},22826
14,26,CVE-2017-0553,30,struct nl_msg *nlmsg_alloc(void){	return __nlmsg_alloc(default_msg_size);},2090
60,555,CVE-2018-6927,30,static struct futex_pi_state *alloc_pi_state(void){	struct futex_pi_state *pi_state = current->pi_state_cache;	WARN_ON(!pi_state);	current->pi_state_cache = NULL;	return pi_state;},25386
51,521,CVE-2018-12896,30,void posix_cpu_timers_exit(struct task_struct *tsk){	cleanup_timers(tsk->cpu_timers);},24741
91,452,CVE-2018-1000524,30,map_engine_get_talk_button(void){	return s_talk_button;},23206
70,27,CVE-2017-0553,30,"struct nl_msg *nlmsg_alloc_simple(int nlmsgtype, int flags){	struct nl_msg *msg;	struct nlmsghdr nlh = {		.nlmsg_type = nlmsgtype,		.nlmsg_flags = flags,	};	msg = nlmsg_inherit(&nlh);	if (msg)		NL_DBG(2, ""msg %p: Allocated new simple message\n"", msg);	return msg;}",2091
62,542,CVE-2018-11590,30,"int flash_strcmp(const char *mem, const char *flash) {  while (1) {    char m = *mem++;    char c = READ_FLASH_UINT8(flash++);    if (m == 0) return c != 0 ? -1 : 0;    if (c == 0) return 1;    if (c > m) return -1;    if (m > c) return 1;  }}",25137
130,16,CVE-2016-6888,30,"void net_tx_pkt_reset(struct NetTxPkt *pkt){    int i;         if (!pkt) {        return;    }    memset(&pkt->virt_hdr, 0, sizeof(pkt->virt_hdr));    assert(pkt->vec);    pkt->payload_len = 0;    pkt->payload_frags = 0;    assert(pkt->raw);    for (i = 0; i < pkt->raw_frags; i++) {        assert(pkt->raw[i].iov_base);        pci_dma_unmap(pkt->pci_dev, pkt->raw[i].iov_base, pkt->raw[i].iov_len,                      DMA_DIRECTION_TO_DEVICE, 0);    }    pkt->raw_frags = 0;    pkt->hdr_len = 0;    pkt->l4proto = 0;}",1537
188,2,CVE-2019-9923,17,pax_dump_header (struct tar_sparse_file *file){  file->stat_info->sparse_major = tar_sparse_major;  file->stat_info->sparse_minor = tar_sparse_minor;  return (file->stat_info->sparse_major == 0) ?           pax_dump_header_0 (file) : pax_dump_header_1 (file);},894
61,361,CVE-2017-2647,17,int nfs_idmap_init(void){	int ret;	ret = nfs_idmap_init_keyring();	if (ret != 0)		goto out;out:	return ret;},22177
178,592,CVE-2017-18241,17,"static void __set_sit_entry_type(struct f2fs_sb_info *sbi, int type,					unsigned int segno, int modified){	struct seg_entry *se = get_seg_entry(sbi, segno);	se->type = type;	if (modified)		__mark_sit_entry_dirty(sbi, segno);}",25704
118,514,CVE-2018-7492,17,void __rds_put_mr_final(struct rds_mr *mr){	rds_destroy_mr(mr);	kfree(mr);},25363
143,891,CVE-2018-7191,17,"static int tun_chr_fasync(int fd, struct file *file, int on){	struct tun_file *tfile = file->private_data;	int ret;	if ((ret = fasync_helper(fd, file, on, &tfile->fasync)) < 0)		goto out;	if (on) {		__f_setown(file, task_pid(current), PIDTYPE_PID, 0);		tfile->flags |= TUN_FASYNC;	} else		tfile->flags &= ~TUN_FASYNC;	ret = 0;out:	return ret;}",27941
180,934,CVE-2018-7191,17,"int __dev_forward_skb(struct net_device *dev, struct sk_buff *skb){	int ret = ____dev_forward_skb(dev, skb);	if (likely(!ret)) {		skb->protocol = eth_type_trans(skb, dev);		skb_postpull_rcsum(skb, eth_hdr(skb), ETH_HLEN);	}	return ret;}",27984
81,157,CVE-2016-3070,17,"static int do_move_page_to_node_array(struct mm_struct *mm,				      struct page_to_node *pm,				      int migrate_all){	int err;	struct page_to_node *pp;	LIST_HEAD(pagelist);	down_read(&mm->mmap_sem);	 	for (pp = pm; pp->node != MAX_NUMNODES; pp++) {		struct vm_area_struct *vma;		struct page *page;		err = -EFAULT;		vma = find_vma(mm, pp->addr);		if (!vma || pp->addr < vma->vm_start || !vma_migratable(vma))			goto set_status;		 		page = follow_page(vma, pp->addr,				FOLL_GET | FOLL_SPLIT | FOLL_DUMP);		err = PTR_ERR(page);		if (IS_ERR(page))			goto set_status;		err = -ENOENT;		if (!page)			goto set_status;		pp->page = page;		err = page_to_nid(page);		if (err == pp->node)			 			goto put_and_set;		err = -EACCES;		if (page_mapcount(page) > 1 &&				!migrate_all)			goto put_and_set;		if (PageHuge(page)) {			if (PageHead(page))				isolate_huge_page(page, &pagelist);			goto put_and_set;		}		err = isolate_lru_page(page);		if (!err) {			list_add_tail(&page->lru, &pagelist);			inc_zone_page_state(page, NR_ISOLATED_ANON +					    page_is_file_cache(page));		}put_and_set:		 		put_page(page);set_status:		pp->status = err;	}	err = 0;	if (!list_empty(&pagelist)) {		err = migrate_pages(&pagelist, new_page_node, NULL,				(unsigned long)pm, MIGRATE_SYNC, MR_SYSCALL);		if (err)			putback_movable_pages(&pagelist);	}	up_read(&mm->mmap_sem);	return err;}",17461
87,39,CVE-2017-6210,17,"static int vrend_decode_set_framebuffer_state(struct vrend_decode_ctx *ctx, int length){   if (length < 2)      return EINVAL;   int nr_cbufs = get_buf_entry(ctx, VIRGL_SET_FRAMEBUFFER_STATE_NR_CBUFS);   int zsurf_handle = get_buf_entry(ctx, VIRGL_SET_FRAMEBUFFER_STATE_NR_ZSURF_HANDLE);   int surf_handle[8];   int i;   if (length != (2 + nr_cbufs))      return EINVAL;   if (nr_cbufs > 8)      return EINVAL;   for (i = 0; i < nr_cbufs; i++)      surf_handle[i] = get_buf_entry(ctx, VIRGL_SET_FRAMEBUFFER_STATE_CBUF_HANDLE(i));   vrend_set_framebuffer_state(ctx->grctx, nr_cbufs, surf_handle, zsurf_handle);   return 0;}",1580
95,448,CVE-2018-18585,17,"static struct mschmd_header *chmd_fast_open(struct mschm_decompressor *base,					    const char *filename){  return chmd_real_open(base, filename, 0);}",23480
11,642,CVE-2017-18216,17,"static struct config_group *o2nm_cluster_group_make_group(struct config_group *group,							  const char *name){	struct o2nm_cluster *cluster = NULL;	struct o2nm_node_group *ns = NULL;	struct config_group *o2hb_group = NULL, *ret = NULL;	 	if (o2nm_single_cluster)		return ERR_PTR(-ENOSPC);	cluster = kzalloc(sizeof(struct o2nm_cluster), GFP_KERNEL);	ns = kzalloc(sizeof(struct o2nm_node_group), GFP_KERNEL);	o2hb_group = o2hb_alloc_hb_set();	if (cluster == NULL || ns == NULL || o2hb_group == NULL)		goto out;	config_group_init_type_name(&cluster->cl_group, name,				    &o2nm_cluster_type);	configfs_add_default_group(&ns->ns_group, &cluster->cl_group);	config_group_init_type_name(&ns->ns_group, ""node"",				    &o2nm_node_group_type);	configfs_add_default_group(o2hb_group, &cluster->cl_group);	rwlock_init(&cluster->cl_nodes_lock);	cluster->cl_node_ip_tree = RB_ROOT;	cluster->cl_reconnect_delay_ms = O2NET_RECONNECT_DELAY_MS_DEFAULT;	cluster->cl_idle_timeout_ms    = O2NET_IDLE_TIMEOUT_MS_DEFAULT;	cluster->cl_keepalive_delay_ms = O2NET_KEEPALIVE_DELAY_MS_DEFAULT;	cluster->cl_fence_method       = O2NM_FENCE_RESET;	ret = &cluster->cl_group;	o2nm_single_cluster = cluster;out:	if (ret == NULL) {		kfree(cluster);		kfree(ns);		o2hb_free_hb_set(o2hb_group);		ret = ERR_PTR(-ENOMEM);	}	return ret;}",25884
76,80,CVE-2016-10708,17,"ssh_packet_write_poll(struct ssh *ssh){	struct session_state *state = ssh->state;	int len = sshbuf_len(state->output);	int r;	if (len > 0) {		len = write(state->connection_out,		    sshbuf_ptr(state->output), len);		if (len == -1) {			if (errno == EINTR || errno == EAGAIN ||			    errno == EWOULDBLOCK)				return 0;			return SSH_ERR_SYSTEM_ERROR;		}		if (len == 0)			return SSH_ERR_CONN_CLOSED;		if ((r = sshbuf_consume(state->output, len)) != 0)			return r;	}	return 0;}",2615
169,100,CVE-2016-6327,17,"static int srpt_ch_qp_rtr(struct srpt_rdma_ch *ch, struct ib_qp *qp){	struct ib_qp_attr qp_attr;	int attr_mask;	int ret;	qp_attr.qp_state = IB_QPS_RTR;	ret = ib_cm_init_qp_attr(ch->cm_id, &qp_attr, &attr_mask);	if (ret)		goto out;	qp_attr.max_dest_rd_atomic = 4;	ret = ib_modify_qp(qp, &qp_attr, attr_mask);out:	return ret;}",16015
12,163,CVE-2016-3070,17,int migrate_prep_local(void){	lru_add_drain();	return 0;},17467
227,46,CVE-2017-6210,17,"static int vrend_decode_set_streamout_targets(struct vrend_decode_ctx *ctx,                                              int length){   int handles[16];   int num_handles = length - 1;   int append_bitmask;   int i;   if (length < 1)      return EINVAL;   if (num_handles > ARRAY_SIZE(handles))      return EINVAL;   append_bitmask = get_buf_entry(ctx, VIRGL_SET_STREAMOUT_TARGETS_APPEND_BITMASK);   for (i = 0; i < num_handles; i++)      handles[i] = get_buf_entry(ctx, VIRGL_SET_STREAMOUT_TARGETS_H0 + i);   vrend_set_streamout_targets(ctx->grctx, append_bitmask, num_handles, handles);   return 0;}",1587
110,392,CVE-2017-2647,17,void big_key_destroy(struct key *key){	if (key->type_data.x[1] > BIG_KEY_FILE_THRESHOLD) {		struct path *path = (struct path *)&key->payload.data2;		path_put(path);		path->mnt = NULL;		path->dentry = NULL;	} else {		kfree(key->payload.data);		key->payload.data = NULL;	}},22208
7,478,CVE-2018-13094,17,"xfs_attr_leaf_newentsize(	struct xfs_da_args	*args,	int			*local){	int			size;	size = xfs_attr_leaf_entsize_local(args->namelen, args->valuelen);	if (size < xfs_attr_leaf_entsize_local_max(args->geo->blksize)) {		if (local)			*local = 1;		return size;	}	if (local)		*local = 0;	return xfs_attr_leaf_entsize_remote(args->namelen);}",24642
160,659,CVE-2017-18079,17,"static void i8042_dritek_enable(void){	unsigned char param = 0x90;	int error;	error = i8042_command(&param, 0x1059);	if (error)		pr_warn(""Failed to enable DRITEK extension: %d\n"", error);}",26087
85,463,CVE-2018-13095,17,"xfs_inode_validate_cowextsize(	struct xfs_mount		*mp,	int			cowextsize,	int			mode,	int			flags,	int			flags2){	int				rt_flag;	int				hint_flag;	int			cowextsize_bytes;	rt_flag = (flags & XFS_DIFLAG_REALTIME);	hint_flag = (flags2 & XFS_DIFLAG2_COWEXTSIZE);	cowextsize_bytes = XFS_FSB_TO_B(mp, cowextsize);	if (hint_flag && !xfs_sb_version_hasreflink(&mp->m_sb))		return __this_address;	if (hint_flag && !(S_ISDIR(mode) || S_ISREG(mode)))		return __this_address;	if (hint_flag && cowextsize == 0)		return __this_address;	if (!hint_flag && cowextsize != 0)		return __this_address;	if (hint_flag && rt_flag)		return __this_address;	if (cowextsize_bytes % mp->m_sb.sb_blocksize)		return __this_address;	if (cowextsize > MAXEXTLEN)		return __this_address;	if (cowextsize > mp->m_sb.sb_agblocks / 2)		return __this_address;	return NULL;}",24627
135,452,CVE-2018-18585,17,"static int find_sys_file(struct mschm_decompressor_p *self,			 struct mschmd_sec_mscompressed *sec,			 struct mschmd_file **f_ptr, const char *name){    struct mspack_system *sys = self->system;    struct mschmd_file result;         if (*f_ptr) return MSPACK_ERR_OK;         if (chmd_fast_find((struct mschm_decompressor *) self, sec->base.chm,		       name, &result, (int)sizeof(result)) || !result.section)    {	return MSPACK_ERR_DATAFORMAT;    }    if (!(*f_ptr = (struct mschmd_file *) sys->alloc(sys, sizeof(result)))) {	return MSPACK_ERR_NOMEMORY;    }         *(*f_ptr) = result;    (*f_ptr)->filename = (char *) name;         (*f_ptr)->next = sec->base.chm->sysfiles;    sec->base.chm->sysfiles = *f_ptr;    return MSPACK_ERR_OK;}",23484
68,542,CVE-2018-1066,17,"add_durable_context(struct kvec *iov, unsigned int *num_iovec,		    struct cifs_open_parms *oparms, int use_persistent){	struct smb2_create_req *req = iov[0].iov_base;	unsigned int num = *num_iovec;	if (use_persistent) {		if (oparms->reconnect)			return add_durable_reconnect_v2_context(iov, num_iovec,								oparms);		else			return add_durable_v2_context(iov, num_iovec, oparms);	}	if (oparms->reconnect) {		iov[num].iov_base = create_reconnect_durable_buf(oparms->fid);		 		oparms->reconnect = false;	} else		iov[num].iov_base = create_durable_buf();	if (iov[num].iov_base == NULL)		return -ENOMEM;	iov[num].iov_len = sizeof(struct create_durable);	if (!req->CreateContextsOffset)		req->CreateContextsOffset =			cpu_to_le32(sizeof(struct smb2_create_req) - 4 +								iov[1].iov_len);	le32_add_cpu(&req->CreateContextsLength, sizeof(struct create_durable));	inc_rfc1001_len(&req->hdr, sizeof(struct create_durable));	*num_iovec = num + 1;	return 0;}",25581
0,908,CVE-2018-7191,17,"static int tun_get_link_ksettings(struct net_device *dev,				  struct ethtool_link_ksettings *cmd){	ethtool_link_ksettings_zero_link_mode(cmd, supported);	ethtool_link_ksettings_zero_link_mode(cmd, advertising);	cmd->base.speed		= SPEED_10;	cmd->base.duplex	= DUPLEX_FULL;	cmd->base.port		= PORT_TP;	cmd->base.phy_address	= 0;	cmd->base.autoneg	= AUTONEG_DISABLE;	return 0;}",27958
53,889,CVE-2018-7191,17,"static int tun_can_build_skb(struct tun_struct *tun, struct tun_file *tfile,			      int len, int noblock, int zerocopy){	if ((tun->flags & TUN_TYPE_MASK) != IFF_TAP)		return false;	if (tfile->socket.sk->sk_sndbuf != INT_MAX)		return false;	if (!noblock)		return false;	if (zerocopy)		return false;	if (SKB_DATA_ALIGN(len + TUN_RX_PAD) +	    SKB_DATA_ALIGN(sizeof(struct skb_shared_info)) > PAGE_SIZE)		return false;	return true;}",27939
137,538,CVE-2018-1066,17,"SMB2_sess_sendreceive(struct SMB2_sess_data *sess_data){	int rc;	struct smb2_sess_setup_req *req = sess_data->iov[0].iov_base;	struct kvec rsp_iov = { NULL, 0 };	 	req->SecurityBufferOffset =		cpu_to_le16(sizeof(struct smb2_sess_setup_req) -			1   - 4  );	req->SecurityBufferLength = cpu_to_le16(sess_data->iov[1].iov_len);	inc_rfc1001_len(req, sess_data->iov[1].iov_len - 1  );	 	rc = SendReceive2(sess_data->xid, sess_data->ses,				sess_data->iov, 2,				&sess_data->buf0_type,				CIFS_LOG_ERROR | CIFS_NEG_OP, &rsp_iov);	cifs_small_buf_release(sess_data->iov[0].iov_base);	memcpy(&sess_data->iov[0], &rsp_iov, sizeof(struct kvec));	return rc;}",25577
101,774,CVE-2019-12984,17,"static int nfc_genl_dump_ses(struct sk_buff *skb,				 struct netlink_callback *cb){	struct class_dev_iter *iter = (struct class_dev_iter *) cb->args[0];	struct nfc_dev *dev = (struct nfc_dev *) cb->args[1];	int first_call = false;	if (!iter) {		first_call = true;		iter = kmalloc(sizeof(struct class_dev_iter), GFP_KERNEL);		if (!iter)			return -ENOMEM;		cb->args[0] = (long) iter;	}	mutex_lock(&nfc_devlist_mutex);	cb->seq = nfc_devlist_generation;	if (first_call) {		nfc_device_iter_init(iter);		dev = nfc_device_iter_next(iter);	}	while (dev) {		int rc;		rc = nfc_genl_send_se(skb, dev, NETLINK_CB(cb->skb).portid,					  cb->nlh->nlmsg_seq, cb, NLM_F_MULTI);		if (rc < 0)			break;		dev = nfc_device_iter_next(iter);	}	mutex_unlock(&nfc_devlist_mutex);	cb->args[1] = (long) dev;	return skb->len;}",26796
123,289,CVE-2017-9211,17,"static int crypto_init_skcipher_ops_ablkcipher(struct crypto_tfm *tfm){	struct crypto_alg *calg = tfm->__crt_alg;	struct crypto_skcipher *skcipher = __crypto_skcipher_cast(tfm);	struct crypto_ablkcipher **ctx = crypto_tfm_ctx(tfm);	struct crypto_ablkcipher *ablkcipher;	struct crypto_tfm *abtfm;	if (!crypto_mod_get(calg))		return -EAGAIN;	abtfm = __crypto_alloc_tfm(calg, 0, 0);	if (IS_ERR(abtfm)) {		crypto_mod_put(calg);		return PTR_ERR(abtfm);	}	ablkcipher = __crypto_ablkcipher_cast(abtfm);	*ctx = ablkcipher;	tfm->exit = crypto_exit_skcipher_ops_ablkcipher;	skcipher->setkey = skcipher_setkey_ablkcipher;	skcipher->encrypt = skcipher_encrypt_ablkcipher;	skcipher->decrypt = skcipher_decrypt_ablkcipher;	skcipher->ivsize = crypto_ablkcipher_ivsize(ablkcipher);	skcipher->reqsize = crypto_ablkcipher_reqsize(ablkcipher) +			    sizeof(struct ablkcipher_request);	skcipher->keysize = calg->cra_ablkcipher.max_keysize; 	return 0; }",20758
131,871,CVE-2019-11810,17,static inline void megasas_set_adapter_type(struct megasas_instance *instance){	if ((instance->pdev->vendor == PCI_VENDOR_ID_DELL) &&	    (instance->pdev->device == PCI_DEVICE_ID_DELL_PERC5)) {		instance->adapter_type = MFI_SERIES;	} else {		switch (instance->pdev->device) {		case PCI_DEVICE_ID_LSI_AERO_10E1:		case PCI_DEVICE_ID_LSI_AERO_10E2:		case PCI_DEVICE_ID_LSI_AERO_10E5:		case PCI_DEVICE_ID_LSI_AERO_10E6:			instance->adapter_type = AERO_SERIES;			break;		case PCI_DEVICE_ID_LSI_VENTURA:		case PCI_DEVICE_ID_LSI_CRUSADER:		case PCI_DEVICE_ID_LSI_HARPOON:		case PCI_DEVICE_ID_LSI_TOMCAT:		case PCI_DEVICE_ID_LSI_VENTURA_4PORT:		case PCI_DEVICE_ID_LSI_CRUSADER_4PORT:			instance->adapter_type = VENTURA_SERIES;			break;		case PCI_DEVICE_ID_LSI_FUSION:		case PCI_DEVICE_ID_LSI_PLASMA:			instance->adapter_type = THUNDERBOLT_SERIES;			break;		case PCI_DEVICE_ID_LSI_INVADER:		case PCI_DEVICE_ID_LSI_INTRUDER:		case PCI_DEVICE_ID_LSI_INTRUDER_24:		case PCI_DEVICE_ID_LSI_CUTLASS_52:		case PCI_DEVICE_ID_LSI_CUTLASS_53:		case PCI_DEVICE_ID_LSI_FURY:			instance->adapter_type = INVADER_SERIES;			break;		default:  			instance->adapter_type = MFI_SERIES;			break;		}	}},27036
3,643,CVE-2017-18216,17,static void o2nm_cluster_release(struct config_item *item){	struct o2nm_cluster *cluster = to_o2nm_cluster(item);	kfree(cluster);},25885
150,217,CVE-2017-16532,17,"static void usbtest_disconnect(struct usb_interface *intf){	struct usbtest_dev	*dev = usb_get_intfdata(intf);	usb_set_intfdata(intf, NULL);	dev_dbg(&intf->dev, ""disconnect\n"");	kfree(dev);}",19775
162,383,CVE-2017-2647,17,static void rxrpc_free_krb5_principal(struct krb5_principal *princ){	int loop;	if (princ->name_parts) {		for (loop = princ->n_name_parts - 1; loop >= 0; loop--)			kfree(princ->name_parts[loop]);		kfree(princ->name_parts);	}	kfree(princ->realm);},22199
170,930,CVE-2018-7191,17,"static int tun_xdp(struct net_device *dev, struct netdev_xdp *xdp){	switch (xdp->command) {	case XDP_SETUP_PROG:		return tun_xdp_set(dev, xdp->prog, xdp->extack);	case XDP_QUERY_PROG:		xdp->prog_id = tun_xdp_query(dev);		xdp->prog_attached = !!xdp->prog_id;		return 0;	default:		return -EINVAL;	}}",27980
171,45,CVE-2017-6210,17,"static int vrend_decode_set_stencil_ref(struct vrend_decode_ctx *ctx, int length){   if (length != VIRGL_SET_STENCIL_REF_SIZE)      return EINVAL;   struct pipe_stencil_ref ref;   int val = get_buf_entry(ctx, VIRGL_SET_STENCIL_REF);   ref.ref_value[0] = val & 0xff;   ref.ref_value[1] = (val >> 8) & 0xff;   vrend_set_stencil_ref(ctx->grctx, &ref);   return 0;}",1586
119,850,CVE-2019-11810,17,"static int megasas_get_ld_vf_affiliation(struct megasas_instance *instance,	int initial){	int retval;	if (instance->PlasmaFW111)		retval = megasas_get_ld_vf_affiliation_111(instance, initial);	else		retval = megasas_get_ld_vf_affiliation_12(instance, initial);	return retval;}",27015
221,141,CVE-2016-6327,17,"static int srpt_test_and_set_cmd_state(struct srpt_send_ioctx *ioctx,					enum srpt_command_state old,					enum srpt_command_state new){	enum srpt_command_state previous;	unsigned long flags;	WARN_ON(!ioctx);	WARN_ON(old == SRPT_STATE_DONE);	WARN_ON(new == SRPT_STATE_NEW);	spin_lock_irqsave(&ioctx->spinlock, flags);	previous = ioctx->state;	if (previous == old)		ioctx->state = new;	spin_unlock_irqrestore(&ioctx->spinlock, flags);	return previous == old;}",16056
247,236,CVE-2017-15306,17,"void kvm_arch_vcpu_free(struct kvm_vcpu *vcpu){	 	hrtimer_cancel(&vcpu->arch.dec_timer);	kvmppc_remove_vcpu_debugfs(vcpu);	switch (vcpu->arch.irq_type) {	case KVMPPC_IRQ_MPIC:		kvmppc_mpic_disconnect_vcpu(vcpu->arch.mpic, vcpu);		break;	case KVMPPC_IRQ_XICS:		if (xive_enabled())			kvmppc_xive_cleanup_vcpu(vcpu);		else			kvmppc_xics_free_icp(vcpu);		break;	}	kvmppc_core_vcpu_free(vcpu);}",19998
233,735,CVE-2019-15922,17,"static void do_pf_read_drq(void){	while (1) {		if (pf_wait(pf_current, STAT_BUSY, STAT_DRQ | STAT_ERR,			    ""read block"", ""completion"") & STAT_ERR) {			pi_disconnect(pf_current->pi);			if (pf_retries < PF_MAX_RETRIES) {				pf_req_sense(pf_current, 0);				pf_retries++;				pi_do_claimed(pf_current->pi, do_pf_read_start);				return;			}			next_request(BLK_STS_IOERR);			return;		}		pi_read_block(pf_current->pi, pf_buf, 512);		if (pf_next_buf())			break;	}	pi_disconnect(pf_current->pi);	next_request(0);}",26532
35,115,CVE-2016-6327,17,"static enum rdma_ch_state srpt_get_ch_state(struct srpt_rdma_ch *ch){	unsigned long flags;	enum rdma_ch_state state;	spin_lock_irqsave(&ch->spinlock, flags);	state = ch->state;	spin_unlock_irqrestore(&ch->spinlock, flags);	return state;}",16030
104,544,CVE-2018-1066,17,"add_durable_v2_context(struct kvec *iov, unsigned int *num_iovec,		    struct cifs_open_parms *oparms){	struct smb2_create_req *req = iov[0].iov_base;	unsigned int num = *num_iovec;	iov[num].iov_base = create_durable_v2_buf(oparms->fid);	if (iov[num].iov_base == NULL)		return -ENOMEM;	iov[num].iov_len = sizeof(struct create_durable_v2);	if (!req->CreateContextsOffset)		req->CreateContextsOffset =			cpu_to_le32(sizeof(struct smb2_create_req) - 4 +								iov[1].iov_len);	le32_add_cpu(&req->CreateContextsLength, sizeof(struct create_durable_v2));	inc_rfc1001_len(&req->hdr, sizeof(struct create_durable_v2));	*num_iovec = num + 1;	return 0;}",25583
187,505,CVE-2018-13093,17,"xfs_reclaim_work_queue(	struct xfs_mount        *mp){	rcu_read_lock();	if (radix_tree_tagged(&mp->m_perag_tree, XFS_ICI_RECLAIM_TAG)) {		queue_delayed_work(mp->m_reclaim_workqueue, &mp->m_reclaim_work,			msecs_to_jiffies(xfs_syncd_centisecs / 6 * 10));	}	rcu_read_unlock();}",24669
98,130,CVE-2016-6327,17,static void srpt_queue_tm_rsp(struct se_cmd *cmd){	srpt_queue_response(cmd);},16045
15,457,CVE-2018-15854,17,"ExprCreateInteger(int ival){    EXPR_CREATE(ExprInteger, expr, EXPR_VALUE, EXPR_TYPE_INT);    expr->integer.ival = ival;     return expr; }",24408
23,201,CVE-2017-16532,17,"static int is_good_config(struct usbtest_dev *tdev, int len){	struct usb_config_descriptor	*config;	if (len < sizeof(*config))		return 0;	config = (struct usb_config_descriptor *) tdev->buf;	switch (config->bDescriptorType) {	case USB_DT_CONFIG:	case USB_DT_OTHER_SPEED_CONFIG:		if (config->bLength != 9) {			ERROR(tdev, ""bogus config descriptor length\n"");			return 0;		}		 		if (!realworld && !(config->bmAttributes & 0x80)) {			ERROR(tdev, ""high bit of config attributes not set\n"");			return 0;		}		if (config->bmAttributes & 0x1f) {	 			ERROR(tdev, ""reserved config bits set\n"");			return 0;		}		break;	default:		return 0;	}	if (le16_to_cpu(config->wTotalLength) == len)	 		return 1;	if (le16_to_cpu(config->wTotalLength) >= TBUF_SIZE)	 		return 1;	ERROR(tdev, ""bogus config descriptor read size\n"");	return 0;}",19759
50,489,CVE-2018-13093,17,"xfs_inode_ag_walk(	struct xfs_mount	*mp,	struct xfs_perag	*pag,	int			(*execute)(struct xfs_inode *ip, int flags,					   void *args),	int			flags,	void			*args,	int			tag,	int			iter_flags){	int		first_index;	int			last_error = 0;	int			skipped;	int			done;	int			nr_found;restart:	done = 0;	skipped = 0;	first_index = 0;	nr_found = 0;	do {		struct xfs_inode *batch[XFS_LOOKUP_BATCH];		int		error = 0;		int		i;		rcu_read_lock();		if (tag == -1)			nr_found = radix_tree_gang_lookup(&pag->pag_ici_root,					(void **)batch, first_index,					XFS_LOOKUP_BATCH);		else			nr_found = radix_tree_gang_lookup_tag(					&pag->pag_ici_root,					(void **) batch, first_index,					XFS_LOOKUP_BATCH, tag);		if (!nr_found) {			rcu_read_unlock();			break;		}		 		for (i = 0; i < nr_found; i++) {			struct xfs_inode *ip = batch[i];			if (done || xfs_inode_ag_walk_grab(ip, iter_flags))				batch[i] = NULL;			 			if (XFS_INO_TO_AGNO(mp, ip->i_ino) != pag->pag_agno)				continue;			first_index = XFS_INO_TO_AGINO(mp, ip->i_ino + 1);			if (first_index < XFS_INO_TO_AGINO(mp, ip->i_ino))				done = 1;		}		 		rcu_read_unlock();		for (i = 0; i < nr_found; i++) {			if (!batch[i])				continue;			if ((iter_flags & XFS_AGITER_INEW_WAIT) &&			    xfs_iflags_test(batch[i], XFS_INEW))				xfs_inew_wait(batch[i]);			error = execute(batch[i], flags, args);			IRELE(batch[i]);			if (error == -EAGAIN) {				skipped++;				continue;			}			if (error && last_error != -EFSCORRUPTED)				last_error = error;		}		 		if (error == -EFSCORRUPTED)			break;		cond_resched();	} while (nr_found && !done);	if (skipped) {		delay(1);		goto restart;	}	return last_error;}",24653
209,174,CVE-2015-8956,17,"static void rfcomm_sk_data_ready(struct rfcomm_dlc *d, struct sk_buff *skb){	struct sock *sk = d->owner;	if (!sk)		return;	atomic_add(skb->len, &sk->sk_rmem_alloc);	skb_queue_tail(&sk->sk_receive_queue, skb);	sk->sk_data_ready(sk);	if (atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf)		rfcomm_dlc_throttle(d);}",18399
71,369,CVE-2017-2647,17,"static struct crypto_blkcipher *ceph_crypto_alloc_cipher(void){	return crypto_alloc_blkcipher(""cbc(aes)"", 0, CRYPTO_ALG_ASYNC);}",22185
149,962,CVE-2018-7191,17,"static void napi_hash_add(struct napi_struct *napi){	if (test_bit(NAPI_STATE_NO_BUSY_POLL, &napi->state) ||	    test_and_set_bit(NAPI_STATE_HASHED, &napi->state))		return;	spin_lock(&napi_hash_lock);	 	do {		if (unlikely(++napi_gen_id < MIN_NAPI_ID))			napi_gen_id = MIN_NAPI_ID;	} while (napi_by_id(napi_gen_id));	napi->napi_id = napi_gen_id;	hlist_add_head_rcu(&napi->napi_hash_node,			   &napi_hash[napi->napi_id % HASH_SIZE(napi_hash)]);	spin_unlock(&napi_hash_lock);}",28012
193,614,CVE-2017-18241,17,static void f2fs_submit_discard_endio(struct bio *bio){	struct discard_cmd *dc = (struct discard_cmd *)bio->bi_private;	dc->error = bio->bi_error;	dc->state = D_DONE;	complete_all(&dc->wait);	bio_put(bio);},25726
216,24,CVE-2017-6210,17,"static int vrend_decode_create_stream_output_target(struct vrend_decode_ctx *ctx, int handle, int length){   int res_handle, buffer_size, buffer_offset;   if (length != VIRGL_OBJ_STREAMOUT_SIZE)      return EINVAL;   res_handle = get_buf_entry(ctx, VIRGL_OBJ_STREAMOUT_RES_HANDLE);   buffer_offset = get_buf_entry(ctx, VIRGL_OBJ_STREAMOUT_BUFFER_OFFSET);   buffer_size = get_buf_entry(ctx, VIRGL_OBJ_STREAMOUT_BUFFER_SIZE);   return vrend_create_so_target(ctx->grctx, handle, res_handle, buffer_offset,                                 buffer_size);}",1565
65,47,CVE-2017-6210,17,"static int vrend_decode_set_sub_ctx(struct vrend_decode_ctx *ctx, int length){   if (length != 1)      return EINVAL;   int ctx_sub_id = get_buf_entry(ctx, 1);   vrend_renderer_set_sub_ctx(ctx->grctx, ctx_sub_id);   return 0;}",1588
121,549,CVE-2018-1066,17,"create_reconnect_durable_v2_buf(struct cifs_fid *fid){	struct create_durable_handle_reconnect_v2 *buf;	buf = kzalloc(sizeof(struct create_durable_handle_reconnect_v2),			GFP_KERNEL);	if (!buf)		return NULL;	buf->ccontext.DataOffset =		cpu_to_le16(offsetof(struct create_durable_handle_reconnect_v2,				     dcontext));	buf->ccontext.DataLength =		cpu_to_le32(sizeof(struct durable_reconnect_context_v2));	buf->ccontext.NameOffset =		cpu_to_le16(offsetof(struct create_durable_handle_reconnect_v2,			    Name));	buf->ccontext.NameLength = cpu_to_le16(4);	buf->dcontext.Fid.PersistentFileId = fid->persistent_fid;	buf->dcontext.Fid.VolatileFileId = fid->volatile_fid;	buf->dcontext.Flags = cpu_to_le32(SMB2_DHANDLE_FLAG_PERSISTENT);	memcpy(buf->dcontext.CreateGuid, fid->create_guid, 16);	 	buf->Name[0] = 'D';	buf->Name[1] = 'H';	buf->Name[2] = '2';	buf->Name[3] = 'C';	return buf;}",25588
114,894,CVE-2018-7191,17,static void tun_cleanup(void){	misc_deregister(&tun_miscdev);	rtnl_link_unregister(&tun_link_ops);	unregister_netdevice_notifier(&tun_notifier_block);},27944
56,79,CVE-2016-10708,17,ssh_packet_is_rekeying(struct ssh *ssh){	return compat20 &&	    (ssh->state->rekeying || (ssh->kex != NULL && ssh->kex->done == 0));},2614
1,367,CVE-2017-2647,17,void nfs_idmap_quit(void){	nfs_idmap_quit_keyring();},22183
40,265,CVE-2017-15102,17,"static void tower_disconnect (struct usb_interface *interface){	struct lego_usb_tower *dev;	int minor;	dev = usb_get_intfdata (interface);	mutex_lock(&open_disc_mutex);	usb_set_intfdata (interface, NULL);	minor = dev->minor;	 	usb_deregister_dev (interface, &tower_class);	mutex_lock(&dev->lock);	mutex_unlock(&open_disc_mutex);	 	if (!dev->open_count) {		mutex_unlock(&dev->lock);		tower_delete (dev);	} else {		dev->udev = NULL;		 		wake_up_interruptible_all(&dev->read_wait);		wake_up_interruptible_all(&dev->write_wait);		mutex_unlock(&dev->lock);	}	dev_info(&interface->dev, ""LEGO USB Tower #%d now disconnected\n"",		 (minor - LEGO_USB_TOWER_MINOR_BASE));}",20093
92,582,CVE-2017-18241,17,"static int __get_segment_type(struct f2fs_io_info *fio){	int type = 0;	switch (fio->sbi->active_logs) {	case 2:		type = __get_segment_type_2(fio);		break;	case 4:		type = __get_segment_type_4(fio);		break;	case 6:		type = __get_segment_type_6(fio);		break;	default:		f2fs_bug_on(fio->sbi, true);	}	if (IS_HOT(type))		fio->temp = HOT;	else if (IS_WARM(type))		fio->temp = WARM;	else		fio->temp = COLD;	return type;}",25694
22,728,CVE-2019-15923,17,"static void pcd_start(void){	int b, i;	char rd_cmd[12] = { 0xa8, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0 };	pcd_bufblk = pcd_sector / 4;	b = pcd_bufblk;	for (i = 0; i < 4; i++) {		rd_cmd[5 - i] = b & 0xff;		b = b >> 8;	}	if (pcd_command(pcd_current, rd_cmd, 2048, ""read block"")) {		pcd_bufblk = -1;		next_request(BLK_STS_IOERR);		return;	}	mdelay(1);	ps_set_intr(do_pcd_read_drq, pcd_ready, PCD_TMO, nice);}",26525
198,673,CVE-2017-18079,17,"static int i8042_pm_resume_noirq(struct device *dev){	if (!pm_resume_via_firmware())		i8042_interrupt(0, NULL);	return 0;}",26101
215,148,CVE-2016-3120,17,void limit_string(char *name){    int     i;    if (!name)        return;    if (strlen(name) < NAME_LENGTH_LIMIT)        return;    i = NAME_LENGTH_LIMIT-4;    name[i++] = '.';    name[i++] = '.';    name[i++] = '.';    name[i] = '\0';    return;},17448
154,99,CVE-2016-6327,17,"static int srpt_ch_qp_err(struct srpt_rdma_ch *ch){	struct ib_qp_attr qp_attr;	qp_attr.qp_state = IB_QPS_ERR;	return ib_modify_qp(ch->qp, &qp_attr, IB_QP_STATE);}",16014
138,347,CVE-2017-2647,17,"compare_sids(const struct cifs_sid *ctsid, const struct cifs_sid *cwsid){	int i;	int num_subauth, num_sat, num_saw;	if ((!ctsid) || (!cwsid))		return 1;	 	if (ctsid->revision != cwsid->revision) {		if (ctsid->revision > cwsid->revision)			return 1;		else			return -1;	}	 	for (i = 0; i < NUM_AUTHS; ++i) {		if (ctsid->authority[i] != cwsid->authority[i]) {			if (ctsid->authority[i] > cwsid->authority[i])				return 1;			else				return -1;		}	}	 	num_sat = ctsid->num_subauth;	num_saw = cwsid->num_subauth;	num_subauth = num_sat < num_saw ? num_sat : num_saw;	if (num_subauth) {		for (i = 0; i < num_subauth; ++i) {			if (ctsid->sub_auth[i] != cwsid->sub_auth[i]) {				if (le32_to_cpu(ctsid->sub_auth[i]) >					le32_to_cpu(cwsid->sub_auth[i]))					return 1;				else					return -1;			}		}	}	return 0;  }",22163
212,432,CVE-2018-1000879,17,"append_id(char **p, int id){	if (id < 0)		id = 0;	if (id > 9)		append_id(p, id / 10);	*(*p)++ = ""0123456789""[id % 10];}",23170
120,221,CVE-2017-16359,17,"static inline int __strnlen(const char *str, int len) {	int l = 0;	while (IS_PRINTABLE (*str) && --len) {		if (((ut8)*str) == 0xff) {			break;		}		str++;		l++;	}	return l + 1;}",19889
44,105,CVE-2016-6327,17,"static void srpt_cm_drep_recv(struct ib_cm_id *cm_id){	pr_info(""Received InfiniBand DREP message for cm_id %p.\n"", cm_id);	srpt_drain_channel(cm_id);}",16020
163,822,CVE-2019-12109,17,"GetFirewallStatus(struct upnphttp * h, const char * action, const char * ns){	static const char resp[] =		""<u:%sResponse ""		""xmlns:u=\""%s\"">""		""<FirewallEnabled>%d</FirewallEnabled>""		""<InboundPinholeAllowed>%d</InboundPinholeAllowed>""		""</u:%sResponse>"";	char body[512];	int bodylen;	bodylen = snprintf(body, sizeof(body), resp,		action, ns,  	    GETFLAG(IPV6FCFWDISABLEDMASK) ? 0 : 1,	    GETFLAG(IPV6FCINBOUNDDISALLOWEDMASK) ? 0 : 1,	    action);	BuildSendAndCloseSoapResp(h, body, bodylen);}",26896
172,77,CVE-2016-10708,17,ssh_local_ipaddr(struct ssh *ssh){	(void)ssh_remote_ipaddr(ssh);  	return ssh->local_ipaddr;},2612
31,22,CVE-2017-6210,17,"static int vrend_decode_create_sampler_view(struct vrend_decode_ctx *ctx, int handle, int length){   int res_handle, format, val0, val1, swizzle_packed;   if (length != VIRGL_OBJ_SAMPLER_VIEW_SIZE)      return EINVAL;   res_handle = get_buf_entry(ctx, VIRGL_OBJ_SAMPLER_VIEW_RES_HANDLE);   format = get_buf_entry(ctx, VIRGL_OBJ_SAMPLER_VIEW_FORMAT);   val0 = get_buf_entry(ctx, VIRGL_OBJ_SAMPLER_VIEW_BUFFER_FIRST_ELEMENT);   val1 = get_buf_entry(ctx, VIRGL_OBJ_SAMPLER_VIEW_BUFFER_LAST_ELEMENT);   swizzle_packed = get_buf_entry(ctx, VIRGL_OBJ_SAMPLER_VIEW_SWIZZLE);   return vrend_create_sampler_view(ctx->grctx, handle, res_handle, format, val0, val1,swizzle_packed);}",1563
177,57,CVE-2018-6942,17,  Ins_POP( void )  {       },1857
190,939,CVE-2018-7191,17,"static int __netdev_adjacent_dev_link_neighbour(struct net_device *dev,						struct net_device *upper_dev,						void *private, int master){	return __netdev_adjacent_dev_link_lists(dev, upper_dev,						&dev->adj_list.upper,						&upper_dev->adj_list.lower,						private, master);}",27989
125,810,CVE-2019-12111,17,"static void printSADSCPOpcode(const int *buf){	unsigned char sadscp_tol;	sadscp_tol = buf[12];	 	syslog(LOG_DEBUG, ""PCP SADSCP: Opcode specific information.\n"");	syslog(LOG_DEBUG, ""Delay tolerance %d \n"", (sadscp_tol>>6)&3);	syslog(LOG_DEBUG, ""Loss tolerance %d \n"",  (sadscp_tol>>4)&3);	syslog(LOG_DEBUG, ""Jitter tolerance %d \n"",  (sadscp_tol>>2)&3);	syslog(LOG_DEBUG, ""RRR %d \n"", sadscp_tol&3);	syslog(LOG_DEBUG, ""AppName Length %d \n"", buf[13]);	syslog(LOG_DEBUG, ""Application name %.*s \n"", buf[13], buf + 14);}",26884
231,782,CVE-2019-12984,17,"int nfc_genl_tm_deactivated(struct nfc_dev *dev){	struct sk_buff *msg;	void *hdr;	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);	if (!msg)		return -ENOMEM;	hdr = genlmsg_put(msg, 0, 0, &nfc_genl_family, 0,			  NFC_EVENT_TM_DEACTIVATED);	if (!hdr)		goto free_msg;	if (nla_put_u32(msg, NFC_ATTR_DEVICE_INDEX, dev->idx))		goto nla_put_failure;	genlmsg_end(msg, hdr);	genlmsg_multicast(&nfc_genl_family, msg, 0, 0, GFP_KERNEL);	return 0;nla_put_failure:free_msg:	nlmsg_free(msg);	return -EMSGSIZE;}",26804
89,836,CVE-2019-11810,17,"megasas_complete_abort(struct megasas_instance *instance,		       struct megasas_cmd *cmd){	if (cmd->sync_cmd) {		cmd->sync_cmd = 0;		cmd->cmd_status_drv = 0;		wake_up(&instance->abort_cmd_wait_q);	}}",27001
146,826,CVE-2019-12109,17,static int is_numeric(const char * s){	while(*s) {		if(*s < '0' || *s > '9') return 0;		s++;	}	return 1;},26900
49,456,CVE-2018-15854,17," ExprCreateBoolean(int set) {    EXPR_CREATE(ExprBoolean, expr, EXPR_VALUE, EXPR_TYPE_BOOLEAN);    expr->intean.set = set;    return expr;}",24407
128,428,CVE-2016-10129,17,"static int parse_len(const char *line){	char num[PKT_LEN_SIZE + 1];	int i, k, error;	int len;	const char *num_end;	memcpy(num, line, PKT_LEN_SIZE);	num[PKT_LEN_SIZE] = '\0';	for (i = 0; i < PKT_LEN_SIZE; ++i) {		if (!isxdigit(num[i])) {			 			for (k = 0; k < PKT_LEN_SIZE; ++k) {				if(!isprint(num[k])) {					num[k] = '.';				}			}						giterr_set(GITERR_NET, ""invalid hex digit in length: '%s'"", num);			return -1;		}	}	if ((error = git__strtol32(&len, num, &num_end, 16)) < 0)		return error;	return len;}",22548
17,658,CVE-2017-18079,17,"static void i8042_controller_reset(int s2r_wants_reset){	i8042_flush(); 	i8042_ctr |= I8042_CTR_KBDDIS | I8042_CTR_AUXDIS;	i8042_ctr &= ~(I8042_CTR_KBDINT | I8042_CTR_AUXINT);	if (i8042_command(&i8042_ctr, I8042_CMD_CTL_WCTR))		pr_warn(""Can't write CTR while resetting\n""); 	if (i8042_mux_present)		i8042_set_mux_mode(false, NULL); 	if (i8042_reset == I8042_RESET_ALWAYS ||	    (i8042_reset == I8042_RESET_ON_S2RAM && s2r_wants_reset)) {		i8042_controller_selftest();	} 	if (i8042_command(&i8042_initial_ctr, I8042_CMD_CTL_WCTR))		pr_warn(""Can't restore CTR\n"");}",26086
55,169,CVE-2015-8970,17,"static void skcipher_free_sgl(struct sock *sk){	struct alg_sock *ask = alg_sk(sk);	struct skcipher_ctx *ctx = ask->private;	skcipher_pull_sgl(sk, ctx->used, 1);}",18289
67,443,CVE-2018-1000879,17,"isint(const char *start, const char *end, int *result){	int n = 0;	if (start >= end)		return (0);	while (start < end) {		if (*start < '0' || *start > '9')			return (0);		if (n > (INT_MAX / 10) ||		    (n == INT_MAX / 10 && (*start - '0') > INT_MAX % 10)) {			n = INT_MAX;		} else {			n *= 10;			n += *start - '0';		}		start++;	}	*result = n;	return (1);}",23181
66,249,CVE-2017-15306,17,"static int kvmppc_emulate_mmio_vsx_loadstore(struct kvm_vcpu *vcpu,			struct kvm_run *run){	enum emulation_result emulated = EMULATE_FAIL;	int r;	vcpu->arch.paddr_accessed += run->mmio.len;	if (!vcpu->mmio_is_write) {		emulated = kvmppc_handle_vsx_load(run, vcpu, vcpu->arch.io_gpr,			 run->mmio.len, 1, vcpu->arch.mmio_sign_extend);	} else {		emulated = kvmppc_handle_vsx_store(run, vcpu,			 vcpu->arch.io_gpr, run->mmio.len, 1);	}	switch (emulated) {	case EMULATE_DO_MMIO:		run->exit_reason = KVM_EXIT_MMIO;		r = RESUME_HOST;		break;	case EMULATE_FAIL:		pr_info(""KVM: MMIO emulation failed (VSX repeat)\n"");		run->exit_reason = KVM_EXIT_INTERNAL_ERROR;		run->internal.suberror = KVM_INTERNAL_ERROR_EMULATION;		r = RESUME_HOST;		break;	default:		r = RESUME_GUEST;		break;	}	return r;}",20011
41,234,CVE-2017-15306,17,"int kvm_arch_prepare_memory_region(struct kvm *kvm,				   struct kvm_memory_slot *memslot,				   const struct kvm_userspace_memory_region *mem,				   enum kvm_mr_change change){	return kvmppc_core_prepare_memory_region(kvm, memslot, mem);}",19996
243,830,CVE-2019-11810,17,"void megaraid_sas_kill_hba(struct megasas_instance *instance){	 	atomic_set(&instance->adprecovery, MEGASAS_HW_CRITICAL_ERROR);	 	msleep(1000);	if ((instance->pdev->device == PCI_DEVICE_ID_LSI_SAS0073SKINNY) ||		(instance->pdev->device == PCI_DEVICE_ID_LSI_SAS0071SKINNY) ||		(instance->adapter_type != MFI_SERIES)) {		if (!instance->requestorId) {			writel(MFI_STOP_ADP, &instance->reg_set->doorbell);			 			readl(&instance->reg_set->doorbell);		}		if (instance->requestorId && instance->peerIsPresent)			memset(instance->ld_ids, 0xff, MEGASAS_MAX_LD_IDS);	} else {		writel(MFI_STOP_ADP,			&instance->reg_set->inbound_doorbell);	}	 	megasas_complete_outstanding_ioctls(instance);}",26995
19,68,CVE-2016-10708,17,"kex_new(struct ssh *ssh, char *proposal[PROPOSAL_MAX], struct kex **kexp){	struct kex *kex;	int r;	*kexp = NULL;	if ((kex = calloc(1, sizeof(*kex))) == NULL)		return SSH_ERR_ALLOC_FAIL;	if ((kex->peer = sshbuf_new()) == NULL ||	    (kex->my = sshbuf_new()) == NULL) {		r = SSH_ERR_ALLOC_FAIL;		goto out;	}	if ((r = kex_prop2buf(kex->my, proposal)) != 0)		goto out;	kex->done = 0;	kex_reset_dispatch(ssh);	r = 0;	*kexp = kex; out:	if (r != 0)		kex_free(kex);	return r;}",2603
75,28,CVE-2017-6210,17,"static int vrend_decode_destroy_object(struct vrend_decode_ctx *ctx, int length){   if (length != 1)      return EINVAL;   int handle = get_buf_entry(ctx, VIRGL_OBJ_DESTROY_HANDLE);   vrend_renderer_object_destroy(ctx->grctx, handle);   return 0;}",1569
96,353,CVE-2017-2647,17,static void nfs_fattr_free_group_name(struct nfs_fattr *fattr){	fattr->valid &= ~NFS_ATTR_FATTR_GROUP_NAME;	kfree(fattr->group_name->data);},22169
208,122,CVE-2016-6327,17,"static void srpt_mad_recv_handler(struct ib_mad_agent *mad_agent,				  struct ib_mad_send_buf *send_buf,				  struct ib_mad_recv_wc *mad_wc){	struct srpt_port *sport = (struct srpt_port *)mad_agent->context;	struct ib_ah *ah;	struct ib_mad_send_buf *rsp;	struct ib_dm_mad *dm_mad;	if (!mad_wc || !mad_wc->recv_buf.mad)		return;	ah = ib_create_ah_from_wc(mad_agent->qp->pd, mad_wc->wc,				  mad_wc->recv_buf.grh, mad_agent->port_num);	if (IS_ERR(ah))		goto err;	BUILD_BUG_ON(offsetof(struct ib_dm_mad, data) != IB_MGMT_DEVICE_HDR);	rsp = ib_create_send_mad(mad_agent, mad_wc->wc->src_qp,				 mad_wc->wc->pkey_index, 0,				 IB_MGMT_DEVICE_HDR, IB_MGMT_DEVICE_DATA,				 GFP_KERNEL,				 IB_MGMT_BASE_VERSION);	if (IS_ERR(rsp))		goto err_rsp;	rsp->ah = ah;	dm_mad = rsp->mad;	memcpy(dm_mad, mad_wc->recv_buf.mad, sizeof *dm_mad);	dm_mad->mad_hdr.method = IB_MGMT_METHOD_GET_RESP;	dm_mad->mad_hdr.status = 0;	switch (mad_wc->recv_buf.mad->mad_hdr.method) {	case IB_MGMT_METHOD_GET:		srpt_mgmt_method_get(sport, mad_wc->recv_buf.mad, dm_mad);		break;	case IB_MGMT_METHOD_SET:		dm_mad->mad_hdr.status =		    cpu_to_be16(DM_MAD_STATUS_UNSUP_METHOD_ATTR);		break;	default:		dm_mad->mad_hdr.status =		    cpu_to_be16(DM_MAD_STATUS_UNSUP_METHOD);		break;	}	if (!ib_post_send_mad(rsp, NULL)) {		ib_free_recv_mad(mad_wc);		 		return;	}	ib_free_send_mad(rsp);err_rsp:	ib_destroy_ah(ah);err:	ib_free_recv_mad(mad_wc);}",16037
196,952,CVE-2018-7191,17,"struct rtnl_link_stats64 *dev_get_stats(struct net_device *dev,					struct rtnl_link_stats64 *storage){	const struct net_device_ops *ops = dev->netdev_ops;	if (ops->ndo_get_stats64) {		memset(storage, 0, sizeof(*storage));		ops->ndo_get_stats64(dev, storage);	} else if (ops->ndo_get_stats) {		netdev_stats_to_stats64(storage, ops->ndo_get_stats(dev));	} else {		netdev_stats_to_stats64(storage, &dev->stats);	}	storage->rx_dropped += (unsigned long)atomic_long_read(&dev->rx_dropped);	storage->tx_dropped += (unsigned long)atomic_long_read(&dev->tx_dropped);	storage->rx_nohandler += (unsigned long)atomic_long_read(&dev->rx_nohandler);	return storage;}",28002
232,156,CVE-2016-3070,17,"static void copy_huge_page(struct page *dst, struct page *src){	int i;	int nr_pages;	if (PageHuge(src)) {		 		struct hstate *h = page_hstate(src);		nr_pages = pages_per_huge_page(h);		if (unlikely(nr_pages > MAX_ORDER_NR_PAGES)) {			__copy_gigantic_page(dst, src, nr_pages);			return;		}	} else {		 		BUG_ON(!PageTransHuge(src));		nr_pages = hpage_nr_pages(src);	}	for (i = 0; i < nr_pages; i++) {		cond_resched();		copy_highpage(dst + i, src + i);	}}",17460
184,86,CVE-2014-4344,17,"g_verify_neg_token_init(unsigned char **buf_in, unsigned int cur_size){	unsigned char *buf = *buf_in;	unsigned char *endptr = buf + cur_size;	int seqsize;	int ret = 0;	unsigned int bytes;	 	if (g_get_tag_and_length(&buf, CONTEXT, cur_size, &bytes) < 0)		return (G_BAD_TOK_HEADER);	cur_size = bytes;  	 	if (*buf++ == SEQUENCE) {		if ((seqsize = gssint_get_der_length(&buf, cur_size, &bytes)) < 0)			return (G_BAD_TOK_HEADER);		 		if (seqsize > endptr - buf)			return (G_BAD_TOK_HEADER);	} else {		return (G_BAD_TOK_HEADER);	}	cur_size = seqsize;  	 	if (*buf++ == CONTEXT) {		if ((seqsize = gssint_get_der_length(&buf, cur_size, &bytes)) < 0)			return (G_BAD_TOK_HEADER);		 		if (seqsize > endptr - buf)			return (G_BAD_TOK_HEADER);	} else {		return (G_BAD_TOK_HEADER);	}	 	*buf_in = buf;	return (ret);}",10898
47,879,CVE-2019-11810,17,"void megasas_start_timer(struct megasas_instance *instance){	struct timer_list *timer = &instance->sriov_heartbeat_timer;	timer_setup(timer, megasas_sriov_heartbeat_handler, 0);	timer->expires = jiffies + MEGASAS_SRIOV_HEARTBEAT_INTERVAL_VF;	add_timer(timer);}",27044
59,715,CVE-2019-15923,17,"static int pcd_identify(struct pcd_unit *cd, char *id){	int k, s;	char id_cmd[12] = { 0x12, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0 };	pcd_bufblk = -1;	s = pcd_atapi(cd, id_cmd, 36, pcd_buffer, ""identify"");	if (s)		return -1;	if ((pcd_buffer[0] & 0x1f) != 5) {		if (verbose)			printk(""%s: %s is not a CD-ROM\n"",			       cd->name, cd->drive ? ""Slave"" : ""Master"");		return -1;	}	memcpy(id, pcd_buffer + 16, 16);	id[16] = 0;	k = 16;	while ((k >= 0) && (id[k] <= 0x20)) {		id[k] = 0;		k--;	}	printk(""%s: %s: %s\n"", cd->name, cd->drive ? ""Slave"" : ""Master"", id);	return 0;}",26512
30,74,CVE-2016-10708,17,"kex_start_rekex(struct ssh *ssh){	if (ssh->kex == NULL) {		error(""%s: no kex"", __func__);		return SSH_ERR_INTERNAL_ERROR;	}	if (ssh->kex->done == 0) {		error(""%s: requested twice"", __func__);		return SSH_ERR_INTERNAL_ERROR;	}	ssh->kex->done = 0;	return kex_send_kexinit(ssh);}",2609
183,283,CVE-2017-9608,17,"static int dnxhd_get_hr_frame_size(int cid, int w, int h){    int result, i = ff_dnxhd_get_cid_table(cid);    if (i < 0)        return i;    result = ((h + 15) / 16) * ((w + 15) / 16) * ff_dnxhd_cid_table[i].packet_scale.num / ff_dnxhd_cid_table[i].packet_scale.den;    result = (result + 2048) / 4096 * 4096;    return FFMAX(result, 8192);}",20714
48,376,CVE-2017-2647,17,static void ceph_key_destroy(struct key *key){	struct ceph_crypto_key *ckey = key->payload.data;	ceph_crypto_key_destroy(ckey);	kfree(ckey);},22192
246,898,CVE-2018-7191,17,"static void tun_disable_queue(struct tun_struct *tun, struct tun_file *tfile){	tfile->detached = tun;	list_add_tail(&tfile->next, &tun->disabled);	++tun->numdisabled;}",27948
129,714,CVE-2019-15923,17,"static int pcd_get_mcn(struct cdrom_device_info *cdi, struct cdrom_mcn *mcn){	char cmd[12] =	    { GPCMD_READ_SUBCHANNEL, 0, 0x40, 2, 0, 0, 0, 0, 24, 0, 0, 0 };	char buffer[32];	if (pcd_atapi(cdi->handle, cmd, 24, buffer, ""get mcn""))		return -EIO;	memcpy(mcn->medium_catalog_number, buffer + 9, 13);	mcn->medium_catalog_number[13] = 0;	return 0;}",26511
28,296,CVE-2017-9211,17,void crypto_unregister_skcipher(struct skcipher_alg *alg){	crypto_unregister_alg(&alg->base);},20765
111,596,CVE-2017-18241,17,"void allocate_new_segments(struct f2fs_sb_info *sbi){	struct curseg_info *curseg;	unsigned int old_segno;	int i;	for (i = CURSEG_HOT_DATA; i <= CURSEG_COLD_DATA; i++) {		curseg = CURSEG_I(sbi, i);		old_segno = curseg->segno;		SIT_I(sbi)->s_ops->allocate_segment(sbi, i, true);		locate_dirty_segment(sbi, old_segno);	}}",25708
195,795,CVE-2019-12818,17,"void nfc_llcp_recv(void *data, struct sk_buff *skb, int err){	struct nfc_llcp_local *local = (struct nfc_llcp_local *) data;	pr_debug(""Received an LLCP PDU\n"");	if (err < 0) {		pr_err(""err %d\n"", err);		return;	}	__nfc_llcp_recv(local, skb);}",26845
29,631,CVE-2017-18241,17,"void register_inmem_page(struct inode *inode, struct page *page){	struct f2fs_inode_info *fi = F2FS_I(inode);	struct inmem_pages *new;	f2fs_trace_pid(page);	set_page_private(page, (unsigned long)ATOMIC_WRITTEN_PAGE);	SetPagePrivate(page);	new = f2fs_kmem_cache_alloc(inmem_entry_slab, GFP_NOFS);	 	new->page = page;	INIT_LIST_HEAD(&new->list);	 	mutex_lock(&fi->inmem_lock);	get_page(page);	list_add_tail(&new->list, &fi->inmem_pages);	inc_page_count(F2FS_I_SB(inode), F2FS_INMEM_PAGES);	mutex_unlock(&fi->inmem_lock);	trace_f2fs_register_inmem_page(page, INMEM);}",25743
181,955,CVE-2018-7191,17,"int dev_set_mtu(struct net_device *dev, int new_mtu){	int err, orig_mtu;	if (new_mtu == dev->mtu)		return 0;	 	if (new_mtu < 0 || new_mtu < dev->min_mtu) {		net_err_ratelimited(""%s: Invalid MTU %d requested, hw min %d\n"",				    dev->name, new_mtu, dev->min_mtu);		return -EINVAL;	}	if (dev->max_mtu > 0 && new_mtu > dev->max_mtu) {		net_err_ratelimited(""%s: Invalid MTU %d requested, hw max %d\n"",				    dev->name, new_mtu, dev->max_mtu);		return -EINVAL;	}	if (!netif_device_present(dev))		return -ENODEV;	err = call_netdevice_notifiers(NETDEV_PRECHANGEMTU, dev);	err = notifier_to_errno(err);	if (err)		return err;	orig_mtu = dev->mtu;	err = __dev_set_mtu(dev, new_mtu);	if (!err) {		err = call_netdevice_notifiers(NETDEV_CHANGEMTU, dev);		err = notifier_to_errno(err);		if (err) {			 			__dev_set_mtu(dev, orig_mtu);			call_netdevice_notifiers(NETDEV_CHANGEMTU, dev);		}	}	return err;}",28005
152,133,CVE-2016-6327,17,"static void srpt_remove_one(struct ib_device *device, void *client_data){	struct srpt_device *sdev = client_data;	int i;	if (!sdev) {		pr_info(""%s(%s): nothing to do.\n"", __func__, device->name);		return;	}	srpt_unregister_mad_agent(sdev);	ib_unregister_event_handler(&sdev->event_handler);	 	for (i = 0; i < sdev->device->phys_port_cnt; i++)		cancel_work_sync(&sdev->port[i].work);	ib_destroy_cm_id(sdev->cm_id);	 	spin_lock(&srpt_dev_lock);	list_del(&sdev->list);	spin_unlock(&srpt_dev_lock);	srpt_release_sdev(sdev);	ib_destroy_srq(sdev->srq);	ib_dealloc_pd(sdev->pd);	srpt_free_ioctx_ring((struct srpt_ioctx **)sdev->ioctx_ring, sdev,			     sdev->srq_size, srp_max_req_size, DMA_FROM_DEVICE);	sdev->ioctx_ring = NULL;	kfree(sdev);}",16048
106,260,CVE-2017-15116,17,"void crypto_unregister_rngs(struct rng_alg *algs, int count){	int i;	for (i = count - 1; i >= 0; --i)		crypto_unregister_rng(algs + i);}",20066
108,458,CVE-2018-13095,17,"xfs_dinode_calc_crc(	struct xfs_mount	*mp,	struct xfs_dinode	*dip){	int		crc;	if (dip->di_version < 3)		return;	ASSERT(xfs_sb_version_hascrc(&mp->m_sb));	crc = xfs_start_cksum_update((char *)dip, mp->m_sb.sb_inodesize,			      XFS_DINODE_CRC_OFF);	dip->di_crc = xfs_end_cksum(crc);}",24622
136,528,CVE-2018-1066,17,"sess_establish_session(struct sess_data *sess_data){	struct cifs_ses *ses = sess_data->ses;	mutex_lock(&ses->server->srv_mutex);	if (!ses->server->session_estab) {		if (ses->server->sign) {			ses->server->session_key.response =				kmemdup(ses->auth_key.response,				ses->auth_key.len, GFP_KERNEL);			if (!ses->server->session_key.response) {				mutex_unlock(&ses->server->srv_mutex);				return -ENOMEM;			}			ses->server->session_key.len =						ses->auth_key.len;		}		ses->server->sequence_number = 0x2;		ses->server->session_estab = true;	}	mutex_unlock(&ses->server->srv_mutex);	cifs_dbg(FYI, ""CIFS session established successfully\n"");	spin_lock(&GlobalMid_Lock);	ses->status = CifsGood;	ses->need_reconnect = false;	spin_unlock(&GlobalMid_Lock);	return 0;}",25567
228,400,CVE-2017-2647,17,"static int search_nested_keyrings(struct key *keyring,				   struct keyring_search_context *ctx){	struct {		struct key *keyring;		struct assoc_array_node *node;		int slot;	} stack[KEYRING_SEARCH_MAX_DEPTH];	struct assoc_array_shortcut *shortcut;	struct assoc_array_node *node;	struct assoc_array_ptr *ptr;	struct key *key;	int sp = 0, slot;	kenter(""{%d},{%s,%s}"",	       keyring->serial,	       ctx->index_key.type->name,	       ctx->index_key.description);	if (ctx->index_key.description)		ctx->index_key.desc_len = strlen(ctx->index_key.description);	 	if (ctx->match_data.lookup_type == KEYRING_SEARCH_LOOKUP_ITERATE ||	    keyring_compare_object(keyring, &ctx->index_key)) {		ctx->skipped_ret = 2;		ctx->flags |= KEYRING_SEARCH_DO_STATE_CHECK;		switch (ctx->iterator(keyring_key_to_ptr(keyring), ctx)) {		case 1:			goto found;		case 2:			return false;		default:			break;		}	}	ctx->skipped_ret = 0;	if (ctx->flags & KEYRING_SEARCH_NO_STATE_CHECK)		ctx->flags &= ~KEYRING_SEARCH_DO_STATE_CHECK;	 descend_to_keyring:	kdebug(""descend to %d"", keyring->serial);	if (keyring->flags & ((1 << KEY_FLAG_INVALIDATED) |			      (1 << KEY_FLAG_REVOKED)))		goto not_this_keyring;	 	if (search_keyring(keyring, ctx))		goto found;	 	ptr = ACCESS_ONCE(keyring->keys.root);	if (!ptr)		goto not_this_keyring;	if (assoc_array_ptr_is_shortcut(ptr)) {		 		shortcut = assoc_array_ptr_to_shortcut(ptr);		smp_read_barrier_depends();		if ((shortcut->index_key[0] & ASSOC_ARRAY_FAN_MASK) != 0)			goto not_this_keyring;		ptr = ACCESS_ONCE(shortcut->next_node);		node = assoc_array_ptr_to_node(ptr);		goto begin_node;	}	node = assoc_array_ptr_to_node(ptr);	smp_read_barrier_depends();	ptr = node->slots[0];	if (!assoc_array_ptr_is_meta(ptr))		goto begin_node;descend_to_node:	 	kdebug(""descend"");	if (assoc_array_ptr_is_shortcut(ptr)) {		shortcut = assoc_array_ptr_to_shortcut(ptr);		smp_read_barrier_depends();		ptr = ACCESS_ONCE(shortcut->next_node);		BUG_ON(!assoc_array_ptr_is_node(ptr));	}	node = assoc_array_ptr_to_node(ptr);begin_node:	kdebug(""begin_node"");	smp_read_barrier_depends();	slot = 0;ascend_to_node:	 	for (; slot < ASSOC_ARRAY_FAN_OUT; slot++) {		ptr = ACCESS_ONCE(node->slots[slot]);		if (assoc_array_ptr_is_meta(ptr) && node->back_pointer)			goto descend_to_node;		if (!keyring_ptr_is_keyring(ptr))			continue;		key = keyring_ptr_to_key(ptr);		if (sp >= KEYRING_SEARCH_MAX_DEPTH) {			if (ctx->flags & KEYRING_SEARCH_DETECT_TOO_DEEP) {				ctx->result = ERR_PTR(-ELOOP);				return false;			}			goto not_this_keyring;		}		 		if (!(ctx->flags & KEYRING_SEARCH_NO_CHECK_PERM) &&		    key_task_permission(make_key_ref(key, ctx->possessed),					ctx->cred, KEY_NEED_SEARCH) < 0)			continue;		 		stack[sp].keyring = keyring;		stack[sp].node = node;		stack[sp].slot = slot;		sp++;		 		keyring = key;		goto descend_to_keyring;	}	 	ptr = ACCESS_ONCE(node->back_pointer);	slot = node->parent_slot;	if (ptr && assoc_array_ptr_is_shortcut(ptr)) {		shortcut = assoc_array_ptr_to_shortcut(ptr);		smp_read_barrier_depends();		ptr = ACCESS_ONCE(shortcut->back_pointer);		slot = shortcut->parent_slot;	}	if (!ptr)		goto not_this_keyring;	node = assoc_array_ptr_to_node(ptr);	smp_read_barrier_depends();	slot++;	 	if (node->back_pointer) {		kdebug(""ascend %d"", slot);		goto ascend_to_node;	}	 not_this_keyring:	kdebug(""not_this_keyring %d"", sp);	if (sp <= 0) {		kleave("" = false"");		return false;	}	 	sp--;	keyring = stack[sp].keyring;	node = stack[sp].node;	slot = stack[sp].slot + 1;	kdebug(""ascend to %d [%d]"", keyring->serial, slot);	goto ascend_to_node;	 found:	key = key_ref_to_ptr(ctx->result);	key_check(key);	if (!(ctx->flags & KEYRING_SEARCH_NO_UPDATE_TIME)) {		key->last_used_at = ctx->now.tv_sec;		keyring->last_used_at = ctx->now.tv_sec;		while (sp > 0)			stack[--sp].keyring->last_used_at = ctx->now.tv_sec;	}	kleave("" = true"");	return true;}",22216
90,856,CVE-2019-11810,17,"megasas_issue_polled(struct megasas_instance *instance, struct megasas_cmd *cmd){	struct megasas_header *frame_hdr = &cmd->frame->hdr;	frame_hdr->cmd_status = MFI_STAT_INVALID_STATUS;	frame_hdr->flags |= cpu_to_le16(MFI_FRAME_DONT_POST_IN_REPLY_QUEUE);	if (atomic_read(&instance->adprecovery) == MEGASAS_HW_CRITICAL_ERROR) {		dev_err(&instance->pdev->dev, ""Failed from %s %d\n"",			__func__, __LINE__);		return DCMD_NOT_FIRED;	}	instance->instancet->issue_dcmd(instance, cmd);	return wait_and_poll(instance, cmd, instance->requestorId ?			MEGASAS_ROUTINE_WAIT_TIME_VF : MFI_IO_TIMEOUT_SECS);}",27021
109,427,CVE-2016-10147,17,"static void mcryptd_hash_update(struct crypto_async_request *req_async, int err){	struct ahash_request *req = ahash_request_cast(req_async);	struct mcryptd_hash_request_ctx *rctx = ahash_request_ctx(req);	if (unlikely(err == -EINPROGRESS))		goto out;	rctx->out = req->result;	err = ahash_mcryptd_update(&rctx->areq);	if (err) {		req->base.complete = rctx->complete;		goto out;	}	return;out:	local_bh_disable();	rctx->complete(&req->base, err);	local_bh_enable();}",22547
202,261,CVE-2017-15102,17,"static inline void lego_usb_tower_debug_data(struct device *dev,					     const char *function, int size,					     const unsigned char *data){	dev_dbg(dev, ""%s - length = %d, data = %*ph\n"",		function, size, size, data);}",20089
167,88,CVE-2014-4344,17,void gss_spnegoint_lib_fini(void){},10900
242,70,CVE-2016-10708,17,"kex_send_ext_info(struct ssh *ssh){	int r;	char *algs;	if ((algs = sshkey_alg_list(0, 1, ',')) == NULL)		return SSH_ERR_ALLOC_FAIL;	if ((r = sshpkt_start(ssh, SSH2_MSG_EXT_INFO)) != 0 ||	    (r = sshpkt_put_u32(ssh, 1)) != 0 ||	    (r = sshpkt_put_cstring(ssh, ""server-sig-algs"")) != 0 ||	    (r = sshpkt_put_cstring(ssh, algs)) != 0 ||	    (r = sshpkt_send(ssh)) != 0)		goto out;	 	r = 0; out:	free(algs);	return 0;}",2605
134,334,CVE-2017-5668,17,"static void prpl_xfer_canceled(struct file_transfer *ft, char *reason){	struct prpl_xfer_data *px = ft->data;	if (px->xfer) {		if (!purple_xfer_is_completed(px->xfer) && !purple_xfer_is_canceled(px->xfer)) {			purple_xfer_cancel_local(px->xfer);		}		px->xfer->ui_data = NULL;		purple_xfer_unref(px->xfer);		px->xfer = NULL;	}}",21982
73,860,CVE-2019-11810,17,"static int megasas_mgmt_open(struct inode *inode, struct file *filep){	 	if (!capable(CAP_SYS_ADMIN))		return -EACCES;	return 0;}",27025
64,584,CVE-2017-18241,17,static int __get_segment_type_4(struct f2fs_io_info *fio){	if (fio->type == DATA) {		struct inode *inode = fio->page->mapping->host;		if (S_ISDIR(inode->i_mode))			return CURSEG_HOT_DATA;		else			return CURSEG_COLD_DATA;	} else {		if (IS_DNODE(fio->page) && is_cold_node(fio->page))			return CURSEG_WARM_NODE;		else			return CURSEG_COLD_NODE;	}},25696
97,776,CVE-2019-12984,17,static int nfc_genl_dump_targets_done(struct netlink_callback *cb){	struct nfc_dev *dev = (struct nfc_dev *) cb->args[1];	if (dev)		nfc_put_device(dev);	return 0;},26798
124,404,CVE-2017-2647,17,"static void request_key_auth_describe(const struct key *key,				      struct seq_file *m){	struct request_key_auth *rka = key->payload.data;	seq_puts(m, ""key:"");	seq_puts(m, key->description);	if (key_is_instantiated(key))		seq_printf(m, "" pid:%d ci:%zu"", rka->pid, rka->callout_len);}",22220
159,680,CVE-2017-18079,17,"static int i8042_set_reset(const char *val, const struct kernel_param *kp){	enum i8042_controller_reset_mode *arg = kp->arg;	int error;	int reset;	if (val) {		error = kstrtoint(val, &reset);		if (error)			return error;	} else {		reset = true;	}	*arg = reset ? I8042_RESET_ALWAYS : I8042_RESET_NEVER;	return 0;}",26108
105,656,CVE-2017-18079,17,"static int i8042_controller_check(void){	if (i8042_flush()) {		pr_info(""No controller found\n"");		return -ENODEV;	}	return 0;}",26084
165,151,CVE-2016-3070,17,"static int __unmap_and_move(struct page *page, struct page *newpage,				int force, enum migrate_mode mode){	int rc = -EAGAIN;	int page_was_mapped = 0;	struct anon_vma *anon_vma = NULL;	if (!trylock_page(page)) {		if (!force || mode == MIGRATE_ASYNC)			goto out;		 		if (current->flags & PF_MEMALLOC)			goto out;		lock_page(page);	}	if (PageWriteback(page)) {		 		if (mode != MIGRATE_SYNC) {			rc = -EBUSY;			goto out_unlock;		}		if (!force)			goto out_unlock;		wait_on_page_writeback(page);	}	 	if (PageAnon(page) && !PageKsm(page))		anon_vma = page_get_anon_vma(page);	 	if (unlikely(!trylock_page(newpage)))		goto out_unlock;	if (unlikely(isolated_balloon_page(page))) {		 		rc = balloon_page_migrate(newpage, page, mode);		goto out_unlock_both;	}	 	if (!page->mapping) {		VM_BUG_ON_PAGE(PageAnon(page), page);		if (page_has_private(page)) {			try_to_free_buffers(page);			goto out_unlock_both;		}	} else if (page_mapped(page)) {		 		VM_BUG_ON_PAGE(PageAnon(page) && !PageKsm(page) && !anon_vma,				page);		try_to_unmap(page,			TTU_MIGRATION|TTU_IGNORE_MLOCK|TTU_IGNORE_ACCESS);		page_was_mapped = 1;	}	if (!page_mapped(page))		rc = move_to_new_page(newpage, page, mode);	if (page_was_mapped)		remove_migration_ptes(page,			rc == MIGRATEPAGE_SUCCESS ? newpage : page);out_unlock_both:	unlock_page(newpage);out_unlock:	 	if (anon_vma)		put_anon_vma(anon_vma);	unlock_page(page);out:	return rc;}",17455
6,752,CVE-2019-15922,17,"static void pf_req_sense(struct pf_unit *pf, int quiet){	char rs_cmd[12] =	    { ATAPI_REQ_SENSE, pf->lun << 5, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0 };	char buf[16];	int r;	r = pf_command(pf, rs_cmd, 16, ""Request sense"");	mdelay(1);	if (!r)		pf_completion(pf, buf, ""Request sense"");	if ((!r) && (!quiet))		printk(""%s: Sense key: %x, ASC: %x, ASQ: %x\n"",		       pf->name, buf[2] & 0xf, buf[12], buf[13]);}",26549
214,292,CVE-2017-9211,17,"int crypto_register_skciphers(struct skcipher_alg *algs, int count){	int i, ret;	for (i = 0; i < count; i++) {		ret = crypto_register_skcipher(&algs[i]);		if (ret)			goto err;	}	return 0;err:	for (--i; i >= 0; --i)		crypto_unregister_skcipher(&algs[i]);	return ret;}",20761
186,219,CVE-2017-16532,17,"usbtest_ioctl(struct usb_interface *intf, unsigned int code, void *buf){	struct usbtest_dev	*dev = usb_get_intfdata(intf);	struct usbtest_param_64 *param_64 = buf;	struct usbtest_param_32 temp;	struct usbtest_param_32 *param_32 = buf;	struct timespec64 start;	struct timespec64 end;	struct timespec64 duration;	int retval = -EOPNOTSUPP;	 	pattern = mod_pattern;	if (mutex_lock_interruptible(&dev->lock))		return -ERESTARTSYS;	 	 	if (dev->info->alt >= 0) {		if (intf->altsetting->desc.bInterfaceNumber) {			retval = -ENODEV;			goto free_mutex;		}		retval = set_altsetting(dev, dev->info->alt);		if (retval) {			dev_err(&intf->dev,					""set altsetting to %d failed, %d\n"",					dev->info->alt, retval);			goto free_mutex;		}	}	switch (code) {	case USBTEST_REQUEST_64:		temp.test_num = param_64->test_num;		temp.iterations = param_64->iterations;		temp.length = param_64->length;		temp.sglen = param_64->sglen;		temp.vary = param_64->vary;		param_32 = &temp;		break;	case USBTEST_REQUEST_32:		break;	default:		retval = -EOPNOTSUPP;		goto free_mutex;	}	ktime_get_ts64(&start);	retval = usbtest_do_ioctl(intf, param_32);	if (retval < 0)		goto free_mutex;	ktime_get_ts64(&end);	duration = timespec64_sub(end, start);	temp.duration_sec = duration.tv_sec;	temp.duration_usec = duration.tv_nsec/NSEC_PER_USEC;	switch (code) {	case USBTEST_REQUEST_32:		param_32->duration_sec = temp.duration_sec;		param_32->duration_usec = temp.duration_usec;		break;	case USBTEST_REQUEST_64:		param_64->duration_sec = temp.duration_sec;		param_64->duration_usec = temp.duration_usec;		break;	}free_mutex:	mutex_unlock(&dev->lock);	return retval;}",19777
32,19,CVE-2017-6210,17,"static int vrend_decode_create_object(struct vrend_decode_ctx *ctx, int length){   if (length < 1)      return EINVAL;   int header = get_buf_entry(ctx, VIRGL_OBJ_CREATE_HEADER);   int handle = get_buf_entry(ctx, VIRGL_OBJ_CREATE_HANDLE);   int obj_type = (header >> 8) & 0xff;   int ret = 0;   if (handle == 0)      return EINVAL;   switch (obj_type){   case VIRGL_OBJECT_BLEND:      ret = vrend_decode_create_blend(ctx, handle, length);      break;   case VIRGL_OBJECT_DSA:      ret = vrend_decode_create_dsa(ctx, handle, length);      break;   case VIRGL_OBJECT_RASTERIZER:      ret = vrend_decode_create_rasterizer(ctx, handle, length);      break;   case VIRGL_OBJECT_SHADER:      ret = vrend_decode_create_shader(ctx, handle, length);      break;   case VIRGL_OBJECT_VERTEX_ELEMENTS:      ret = vrend_decode_create_ve(ctx, handle, length);      break;   case VIRGL_OBJECT_SURFACE:      ret = vrend_decode_create_surface(ctx, handle, length);      break;   case VIRGL_OBJECT_SAMPLER_VIEW:      ret = vrend_decode_create_sampler_view(ctx, handle, length);      break;   case VIRGL_OBJECT_SAMPLER_STATE:      ret = vrend_decode_create_sampler_state(ctx, handle, length);      break;   case VIRGL_OBJECT_QUERY:      ret = vrend_decode_create_query(ctx, handle, length);      break;   case VIRGL_OBJECT_STREAMOUT_TARGET:      ret = vrend_decode_create_stream_output_target(ctx, handle, length);      break;   default:      return EINVAL;   }   return ret;}",1560
145,245,CVE-2017-15306,17,"int kvm_vcpu_ioctl_interrupt(struct kvm_vcpu *vcpu, struct kvm_interrupt *irq){	if (irq->irq == KVM_INTERRUPT_UNSET) {		kvmppc_core_dequeue_external(vcpu);		return 0;	}	kvmppc_core_queue_external(vcpu, irq);	kvm_vcpu_kick(vcpu);	return 0;}",20007
4,308,CVE-2017-9211,17,static int skcipher_next_fast(struct skcipher_walk *walk){	unsigned long diff;	walk->src.phys.page = scatterwalk_page(&walk->in);	walk->src.phys.offset = offset_in_page(walk->in.offset);	walk->dst.phys.page = scatterwalk_page(&walk->out);	walk->dst.phys.offset = offset_in_page(walk->out.offset);	if (walk->flags & SKCIPHER_WALK_PHYS)		return 0;	diff = walk->src.phys.offset - walk->dst.phys.offset;	diff |= walk->src.virt.page - walk->dst.virt.page;	skcipher_map_src(walk);	walk->dst.virt.addr = walk->src.virt.addr;	if (diff) {		walk->flags |= SKCIPHER_WALK_DIFF;		skcipher_map_dst(walk);	}	return 0;},20777
219,885,CVE-2019-9213,17,"static void vma_gap_update(struct vm_area_struct *vma){	 	vma_gap_callbacks_propagate(&vma->vm_rb, NULL);}",27204
74,650,CVE-2017-18216,17,void o2nm_node_put(struct o2nm_node *node){	config_item_put(&node->nd_item);},25892
115,328,CVE-2017-8825,17,static inline int is_dtext(char ch){  unsigned char uch = (unsigned char) ch;  if (is_no_ws_ctl(ch))    return TRUE;  if (uch < 33)    return FALSE;  if ((uch >= 91) && (uch <= 93))    return FALSE;  if (uch == 127)    return FALSE;  return TRUE;},21259
182,847,CVE-2019-11810,17,"megasas_fw_crash_state_show(struct device *cdev,	struct device_attribute *attr, char *buf){	struct Scsi_Host *shost = class_to_shost(cdev);	struct megasas_instance *instance =		(struct megasas_instance *) shost->hostdata;	return snprintf(buf, PAGE_SIZE, ""%d\n"", instance->fw_crash_state);}",27012
43,299,CVE-2017-9211,17,"static int skcipher_crypt_ablkcipher(struct skcipher_request *req,				     int (*crypt)(struct ablkcipher_request *)){	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);	struct crypto_ablkcipher **ctx = crypto_skcipher_ctx(tfm);	struct ablkcipher_request *subreq = skcipher_request_ctx(req);	ablkcipher_request_set_tfm(subreq, *ctx);	ablkcipher_request_set_callback(subreq, skcipher_request_flags(req),					req->base.complete, req->base.data);	ablkcipher_request_set_crypt(subreq, req->src, req->dst, req->cryptlen,				     req->iv);	return crypt(subreq);}",20768
8,766,CVE-2019-13225,17,"onig_positive_int_multiply(int x, int y){  if (x == 0 || y == 0) return 0;  if (x < INT_MAX / y)    return x * y;  else    return -1;}",26744
84,500,CVE-2018-13093,17,"xfs_prep_free_cowblocks(	struct xfs_inode	*ip,	struct xfs_ifork	*ifp){	 	if (!xfs_is_reflink_inode(ip) || !ifp->if_bytes) {		trace_xfs_inode_free_cowblocks_invalid(ip);		xfs_inode_clear_cowblocks_tag(ip);		return false;	}	 	if ((VFS_I(ip)->i_state & I_DIRTY_PAGES) ||	    mapping_tagged(VFS_I(ip)->i_mapping, PAGECACHE_TAG_DIRTY) ||	    mapping_tagged(VFS_I(ip)->i_mapping, PAGECACHE_TAG_WRITEBACK) ||	    atomic_read(&VFS_I(ip)->i_dio_count))		return false;	return true;}",24664
10,689,CVE-2019-15924,17,static void fm10k_assign_rings(struct fm10k_intfc *interface){	if (fm10k_cache_ring_qos(interface))		return;	fm10k_cache_ring_rss(interface);},26486
113,625,CVE-2017-18241,17,"static int init_victim_secmap(struct f2fs_sb_info *sbi){	struct dirty_seglist_info *dirty_i = DIRTY_I(sbi);	unsigned int bitmap_size = f2fs_bitmap_size(MAIN_SECS(sbi));	dirty_i->victim_secmap = f2fs_kvzalloc(bitmap_size, GFP_KERNEL);	if (!dirty_i->victim_secmap)		return -ENOMEM;	return 0;}",25737
168,511,CVE-2018-8043,17,"static inline unsigned int unimac_mdio_busy(struct unimac_mdio_priv *priv){	return unimac_mdio_readl(priv, MDIO_CMD) & MDIO_START_BUSY;}",25326
72,304,CVE-2017-9211,17,"static int skcipher_encrypt_blkcipher(struct skcipher_request *req){	struct crypto_skcipher *skcipher = crypto_skcipher_reqtfm(req);	struct crypto_tfm *tfm = crypto_skcipher_tfm(skcipher);	struct blkcipher_alg *alg = &tfm->__crt_alg->cra_blkcipher;	return skcipher_crypt_blkcipher(req, alg->encrypt);}",20773
245,429,CVE-2018-1000879,17,"acl_new_entry(struct archive_acl *acl,    int type, int permset, int tag, int id){	struct archive_acl_entry *ap, *aq;	 	if (type & ARCHIVE_ENTRY_ACL_TYPE_NFS4) {		if (acl->acl_types & ~ARCHIVE_ENTRY_ACL_TYPE_NFS4) {			return (NULL);		}		if (permset &		    ~(ARCHIVE_ENTRY_ACL_PERMS_NFS4			| ARCHIVE_ENTRY_ACL_INHERITANCE_NFS4)) {			return (NULL);		}	} else	if (type & ARCHIVE_ENTRY_ACL_TYPE_POSIX1E) {		if (acl->acl_types & ~ARCHIVE_ENTRY_ACL_TYPE_POSIX1E) {			return (NULL);		}		if (permset & ~ARCHIVE_ENTRY_ACL_PERMS_POSIX1E) {			return (NULL);		}	} else {		return (NULL);	}	 	switch (tag) {	case ARCHIVE_ENTRY_ACL_USER:	case ARCHIVE_ENTRY_ACL_USER_OBJ:	case ARCHIVE_ENTRY_ACL_GROUP:	case ARCHIVE_ENTRY_ACL_GROUP_OBJ:		 		break;	case ARCHIVE_ENTRY_ACL_MASK:	case ARCHIVE_ENTRY_ACL_OTHER:		 		if (type & ~ARCHIVE_ENTRY_ACL_TYPE_POSIX1E) {			return (NULL);		}		break;	case ARCHIVE_ENTRY_ACL_EVERYONE:		 		if (type & ~ARCHIVE_ENTRY_ACL_TYPE_NFS4) {			return (NULL);		}		break;	default:		 		return (NULL);	}	if (acl->acl_text_w != NULL) {		free(acl->acl_text_w);		acl->acl_text_w = NULL;	}	if (acl->acl_text != NULL) {		free(acl->acl_text);		acl->acl_text = NULL;	}	 	ap = acl->acl_head;	aq = NULL;	while (ap != NULL) {		if (((type & ARCHIVE_ENTRY_ACL_TYPE_NFS4) == 0) &&		    ap->type == type && ap->tag == tag && ap->id == id) {			if (id != -1 || (tag != ARCHIVE_ENTRY_ACL_USER &&			    tag != ARCHIVE_ENTRY_ACL_GROUP)) {				ap->permset = permset;				return (ap);			}		}		aq = ap;		ap = ap->next;	}	 	ap = (struct archive_acl_entry *)calloc(1, sizeof(*ap));	if (ap == NULL)		return (NULL);	if (aq == NULL)		acl->acl_head = ap;	else		aq->next = ap;	ap->type = type;	ap->tag = tag;	ap->id = id;	ap->permset = permset;	acl->acl_types |= type;	return (ap);}",23167
82,920,CVE-2018-7191,17,static void tun_put(struct tun_struct *tun){	dev_put(tun->dev);},27970
37,300,CVE-2017-9211,17,"static int skcipher_crypt_blkcipher(struct skcipher_request *req,				    int (*crypt)(struct blkcipher_desc *,						 struct scatterlist *,						 struct scatterlist *,						 unsigned int)){	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);	struct crypto_blkcipher **ctx = crypto_skcipher_ctx(tfm);	struct blkcipher_desc desc = {		.tfm = *ctx,		.info = req->iv,		.flags = req->base.flags,	};	return crypt(&desc, req->dst, req->src, req->cryptlen);}",20769
226,488,CVE-2018-13093,17,"xfs_inode_ag_iterator(	struct xfs_mount	*mp,	int			(*execute)(struct xfs_inode *ip, int flags,					   void *args),	int			flags,	void			*args){	return xfs_inode_ag_iterator_flags(mp, execute, flags, args, 0);}",24652
33,144,CVE-2016-6327,17,"static int srpt_xfer_data(struct srpt_rdma_ch *ch,			  struct srpt_send_ioctx *ioctx){	int ret;	ret = srpt_map_sg_to_ib_sge(ch, ioctx);	if (ret) {		pr_err(""%s[%d] ret=%d\n"", __func__, __LINE__, ret);		goto out;	}	ret = srpt_perform_rdmas(ch, ioctx);	if (ret) {		if (ret == -EAGAIN || ret == -ENOMEM)			pr_info(""%s[%d] queue full -- ret=%d\n"",				__func__, __LINE__, ret);		else			pr_err(""%s[%d] fatal error -- ret=%d\n"",			       __func__, __LINE__, ret);		goto out_unmap;	}out:	return ret;out_unmap:	srpt_unmap_sg_to_ib_sge(ch, ioctx);	goto out;}",16059
241,969,CVE-2018-7191,17,"int netdev_boot_setup_check(struct net_device *dev){	struct netdev_boot_setup *s = dev_boot_setup;	int i;	for (i = 0; i < NETDEV_BOOT_SETUP_MAX; i++) {		if (s[i].name[0] != '\0' && s[i].name[0] != ' ' &&		    !strcmp(dev->name, s[i].name)) {			dev->irq = s[i].map.irq;			dev->base_addr = s[i].map.base_addr;			dev->mem_start = s[i].map.mem_start;			dev->mem_end = s[i].map.mem_end;			return 1;		}	}	return 0;}",28019
185,802,CVE-2019-12818,17,void nfc_llcp_socket_remote_param_init(struct nfc_llcp_sock *sock){	sock->remote_rw = LLCP_DEFAULT_RW;	sock->remote_miu = LLCP_MAX_MIU + 1;},26852
116,709,CVE-2019-15923,17,"static unsigned int pcd_check_events(struct cdrom_device_info *cdi,				     unsigned int clearing, int slot_nr){	struct pcd_unit *cd = cdi->handle;	int res = cd->changed;	if (res)		cd->changed = 0;	return res ? DISK_EVENT_MEDIA_CHANGE : 0;}",26506
153,83,CVE-2015-9261,17,"static void abort_unzip(STATE_PARAM_ONLY){	huft_free_all(PASS_STATE_ONLY);	longjmp(error_jmp, 1);}",2621
200,615,CVE-2017-18241,17,"void f2fs_wait_discard_bios(struct f2fs_sb_info *sbi){	__issue_discard_cmd(sbi, false);	__wait_discard_cmd(sbi, false);}",25727
13,721,CVE-2019-15923,17,static int pcd_ready(void){	return (((status_reg(pcd_current) & (IDE_BUSY | IDE_DRQ)) == IDE_DRQ));},26518
78,888,CVE-2018-7191,17,"static int tun_attach_filter(struct tun_struct *tun){	int i, ret = 0;	struct tun_file *tfile;	for (i = 0; i < tun->numqueues; i++) {		tfile = rtnl_dereference(tun->tfiles[i]);		lock_sock(tfile->socket.sk);		ret = sk_attach_filter(&tun->fprog, tfile->socket.sk);		release_sock(tfile->socket.sk);		if (ret) {			tun_detach_filter(tun, i);			return ret;		}	}	tun->filter_attached = true;	return ret;}",27938
206,16,CVE-2017-6210,17,"static int vrend_decode_clear(struct vrend_decode_ctx *ctx, int length){   union pipe_color_union color;   double depth;   unsigned stencil, buffers;   int i;   if (length != VIRGL_OBJ_CLEAR_SIZE)      return EINVAL;   buffers = get_buf_entry(ctx, VIRGL_OBJ_CLEAR_BUFFERS);   for (i = 0; i < 4; i++)      color.ui[i] = get_buf_entry(ctx, VIRGL_OBJ_CLEAR_COLOR_0 + i);   depth = *(double *)(int *)get_buf_ptr(ctx, VIRGL_OBJ_CLEAR_DEPTH_0);   stencil = get_buf_entry(ctx, VIRGL_OBJ_CLEAR_STENCIL);   vrend_clear(ctx->grctx, buffers, &color, depth, stencil);   return 0;}",1557
203,794,CVE-2019-12818,17,"int nfc_llcp_queue_i_frames(struct nfc_llcp_sock *sock){	int nr_frames = 0;	struct nfc_llcp_local *local = sock->local;	pr_debug(""Remote ready %d tx queue len %d remote rw %d"",		 sock->remote_ready, skb_queue_len(&sock->tx_pending_queue),		 sock->remote_rw);	 	while (sock->remote_ready &&	       skb_queue_len(&sock->tx_pending_queue) < sock->remote_rw) {		struct sk_buff *pdu;		pdu = skb_dequeue(&sock->tx_queue);		if (pdu == NULL)			break;		 		nfc_llcp_set_nrns(sock, pdu);		skb_queue_tail(&local->tx_queue, pdu);		nr_frames++;	}	return nr_frames;}",26844
237,91,CVE-2016-8646,17,"static void hash_sock_destruct(struct sock *sk){	struct alg_sock *ask = alg_sk(sk);	struct hash_ctx *ctx = ask->private;	sock_kzfree_s(sk, ctx->result,		      crypto_ahash_digestsize(crypto_ahash_reqtfm(&ctx->req)));	sock_kfree_s(sk, ctx, ctx->len);	af_alg_release_parent(sk);}",15525
240,414,CVE-2016-10147,17,int ahash_mcryptd_update(struct ahash_request *desc){	 	return crypto_ahash_update(desc);},22534
52,194,CVE-2017-16532,17,"static void complicated_callback(struct urb *urb){	struct transfer_context	*ctx = urb->context;	spin_lock(&ctx->lock);	ctx->count--;	ctx->packet_count += urb->number_of_packets;	if (urb->error_count > 0)		ctx->errors += urb->error_count;	else if (urb->status != 0)		ctx->errors += (ctx->is_iso ? urb->number_of_packets : 1);	else if (urb->actual_length != urb->transfer_buffer_length)		ctx->errors++;	else if (check_guard_bytes(ctx->dev, urb) != 0)		ctx->errors++;	if (urb->status == 0 && ctx->count > (ctx->pending - 1)			&& !ctx->submit_error) {		int status = usb_submit_urb(urb, GFP_ATOMIC);		switch (status) {		case 0:			goto done;		default:			dev_err(&ctx->dev->intf->dev,					""resubmit err %d\n"",					status);			 		case -ENODEV:			 		case -ESHUTDOWN:		 			ctx->submit_error = 1;			break;		}	}	ctx->pending--;	if (ctx->pending == 0) {		if (ctx->errors)			dev_err(&ctx->dev->intf->dev,				""during the test, %lu errors out of %lu\n"",				ctx->errors, ctx->packet_count);		complete(&ctx->done);	}done:	spin_unlock(&ctx->lock);}",19752
218,276,CVE-2017-13686,17,"static int ip_rt_bug(struct net *net, struct sock *sk, struct sk_buff *skb){	pr_debug(""%s: %pI4 -> %pI4, %s\n"",		 __func__, &ip_hdr(skb)->saddr, &ip_hdr(skb)->daddr,		 skb->dev ? skb->dev->name : ""?"");	kfree_skb(skb);	WARN_ON(1);	return 0;}",20245
157,255,CVE-2017-15116,17,int crypto_register_rng(struct rng_alg *alg){	struct crypto_alg *base = &alg->base;	if (alg->seedsize > PAGE_SIZE / 8)		return -EINVAL;	base->cra_type = &crypto_rng_type;	base->cra_flags &= ~CRYPTO_ALG_TYPE_MASK;	base->cra_flags |= CRYPTO_ALG_TYPE_RNG;	return crypto_register_alg(base);},20061
18,407,CVE-2017-2647,17,"static void trusted_destroy(struct key *key){	struct trusted_key_payload *p = key->payload.data;	if (!p)		return;	memset(p->key, 0, p->key_len);	kfree(key->payload.data);}",22223
58,403,CVE-2017-2647,17,"int wait_for_key_construction(struct key *key, int intr){	int ret;	ret = wait_on_bit(&key->flags, KEY_FLAG_USER_CONSTRUCT,			  intr ? key_wait_bit_intr : key_wait_bit,			  intr ? TASK_INTERRUPTIBLE : TASK_UNINTERRUPTIBLE);	if (ret < 0)		return ret;	if (test_bit(KEY_FLAG_NEGATIVE, &key->flags)) {		smp_rmb();		return key->type_data.reject_error;	}	return key_validate(key);}",22219
234,60,CVE-2014-0146,17,static void bdrv_qcow2_init(void){    bdrv_register(&bdrv_qcow2);},2510
140,893,CVE-2018-7191,17,"static void tun_chr_show_fdinfo(struct seq_file *m, struct file *f){	struct tun_struct *tun;	struct ifreq ifr;	memset(&ifr, 0, sizeof(ifr));	rtnl_lock();	tun = tun_get(f);	if (tun)		tun_get_iff(current->nsproxy->net_ns, tun, &ifr);	rtnl_unlock();	if (tun)		tun_put(tun);	seq_printf(m, ""iff:\t%s\n"", ifr.ifr_name);}",27943
132,145,CVE-2016-5354,17,midi_data_reassemble_cleanup(void){    reassembly_table_destroy(&midi_data_reassembly_table);},16476
220,837,CVE-2019-11810,17,"megasas_complete_int_cmd(struct megasas_instance *instance,			 struct megasas_cmd *cmd){	cmd->cmd_status_drv = cmd->frame->io.cmd_status;	wake_up(&instance->int_cmd_wait_q);}",27002
25,5,CVE-2016-9294,17,static int isfun(enum js_AstType T){	return T == AST_FUNDEC || T == EXP_FUN || T == EXP_PROP_GET || T == EXP_PROP_SET;},1311
133,525,CVE-2018-1066,17,"static void ascii_ssetup_strings(char **pbcc_area, struct cifs_ses *ses,				 const struct nls_table *nls_cp){	char *bcc_ptr = *pbcc_area;	 	 	 	if (ses->user_name != NULL) {		strncpy(bcc_ptr, ses->user_name, CIFS_MAX_USERNAME_LEN);		bcc_ptr += strnlen(ses->user_name, CIFS_MAX_USERNAME_LEN);	}	 	*bcc_ptr = 0;	bcc_ptr++;  	 	if (ses->domainName != NULL) {		strncpy(bcc_ptr, ses->domainName, CIFS_MAX_DOMAINNAME_LEN);		bcc_ptr += strnlen(ses->domainName, CIFS_MAX_DOMAINNAME_LEN);	}  	*bcc_ptr = 0;	bcc_ptr++;	 	strcpy(bcc_ptr, ""Linux version "");	bcc_ptr += strlen(""Linux version "");	strcpy(bcc_ptr, init_utsname()->release);	bcc_ptr += strlen(init_utsname()->release) + 1;	strcpy(bcc_ptr, CIFS_NETWORK_OPSYS);	bcc_ptr += strlen(CIFS_NETWORK_OPSYS) + 1;	*pbcc_area = bcc_ptr;}",25564
179,155,CVE-2016-3070,17,"int buffer_migrate_page(struct address_space *mapping,		struct page *newpage, struct page *page, enum migrate_mode mode){	struct buffer_head *bh, *head;	int rc;	if (!page_has_buffers(page))		return migrate_page(mapping, newpage, page, mode);	head = page_buffers(page);	rc = migrate_page_move_mapping(mapping, newpage, page, head, mode, 0);	if (rc != MIGRATEPAGE_SUCCESS)		return rc;	 	if (mode != MIGRATE_ASYNC)		BUG_ON(!buffer_migrate_lock_buffers(head, mode));	ClearPagePrivate(page);	set_page_private(newpage, page_private(page));	set_page_private(page, 0);	put_page(page);	get_page(newpage);	bh = head;	do {		set_bh_page(bh, newpage, bh_offset(bh));		bh = bh->b_this_page;	} while (bh != head);	SetPagePrivate(newpage);	migrate_page_copy(newpage, page);	bh = head;	do {		unlock_buffer(bh); 		put_bh(bh);		bh = bh->b_this_page;	} while (bh != head);	return MIGRATEPAGE_SUCCESS;}",17459
99,136,CVE-2016-6327,17,"static enum srpt_command_state srpt_set_cmd_state(struct srpt_send_ioctx *ioctx,						  enum srpt_command_state new){	enum srpt_command_state previous;	unsigned long flags;	BUG_ON(!ioctx);	spin_lock_irqsave(&ioctx->spinlock, flags);	previous = ioctx->state;	if (previous != SRPT_STATE_DONE)		ioctx->state = new;	spin_unlock_irqrestore(&ioctx->spinlock, flags);	return previous;}",16051
93,965,CVE-2018-7191,17,"int napi_schedule_prep(struct napi_struct *n){	unsigned long val, new;	do {		val = READ_ONCE(n->state);		if (unlikely(val & NAPIF_STATE_DISABLE))			return false;		new = val | NAPIF_STATE_SCHED;		 		new |= (val & NAPIF_STATE_SCHED) / NAPIF_STATE_SCHED *						   NAPIF_STATE_MISSED;	} while (cmpxchg(&n->state, val, new) != val);	return !(val & NAPIF_STATE_SCHED);}",28015
21,324,CVE-2017-9211,17,"static int skcipher_walk_skcipher(struct skcipher_walk *walk,				  struct skcipher_request *req){	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);	scatterwalk_start(&walk->in, req->src);	scatterwalk_start(&walk->out, req->dst);	walk->total = req->cryptlen;	walk->iv = req->iv;	walk->oiv = req->iv;	walk->flags &= ~SKCIPHER_WALK_SLEEP;	walk->flags |= req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ?		       SKCIPHER_WALK_SLEEP : 0;	walk->blocksize = crypto_skcipher_blocksize(tfm);	walk->stride = crypto_skcipher_walksize(tfm);	walk->ivsize = crypto_skcipher_ivsize(tfm);	walk->alignmask = crypto_skcipher_alignmask(tfm);	return skcipher_walk_first(walk);}",20793
147,828,CVE-2019-11810,17,"format_class(int class){	static char buffer[6];	switch (class) {	case MFI_EVT_CLASS_DEBUG:		return ""debug"";	case MFI_EVT_CLASS_PROGRESS:		return ""progress"";	case MFI_EVT_CLASS_INFO:		return ""info"";	case MFI_EVT_CLASS_WARNING:		return ""WARN"";	case MFI_EVT_CLASS_CRITICAL:		return ""CRIT"";	case MFI_EVT_CLASS_FATAL:		return ""FATAL"";	case MFI_EVT_CLASS_DEAD:		return ""DEAD"";	default:		snprintf(buffer, sizeof(buffer), ""%d"", class);		return buffer;	}}",26993
127,474,CVE-2018-13094,17,"xfs_attr3_leaf_unbalance(	struct xfs_da_state	*state,	struct xfs_da_state_blk	*drop_blk,	struct xfs_da_state_blk	*save_blk){	struct xfs_attr_leafblock *drop_leaf = drop_blk->bp->b_addr;	struct xfs_attr_leafblock *save_leaf = save_blk->bp->b_addr;	struct xfs_attr3_icleaf_hdr drophdr;	struct xfs_attr3_icleaf_hdr savehdr;	struct xfs_attr_leaf_entry *entry;	trace_xfs_attr_leaf_unbalance(state->args);	drop_leaf = drop_blk->bp->b_addr;	save_leaf = save_blk->bp->b_addr;	xfs_attr3_leaf_hdr_from_disk(state->args->geo, &drophdr, drop_leaf);	xfs_attr3_leaf_hdr_from_disk(state->args->geo, &savehdr, save_leaf);	entry = xfs_attr3_leaf_entryp(drop_leaf);	 	drop_blk->hashval = be32_to_cpu(entry[drophdr.count - 1].hashval);	 	if (savehdr.holes == 0) {		 		if (xfs_attr3_leaf_order(save_blk->bp, &savehdr,					 drop_blk->bp, &drophdr)) {			xfs_attr3_leaf_moveents(state->args,						drop_leaf, &drophdr, 0,						save_leaf, &savehdr, 0,						drophdr.count);		} else {			xfs_attr3_leaf_moveents(state->args,						drop_leaf, &drophdr, 0,						save_leaf, &savehdr,						savehdr.count, drophdr.count);		}	} else {		 		struct xfs_attr_leafblock *tmp_leaf;		struct xfs_attr3_icleaf_hdr tmphdr;		tmp_leaf = kmem_zalloc(state->args->geo->blksize, KM_SLEEP);		 		memcpy(tmp_leaf, save_leaf, xfs_attr3_leaf_hdr_size(save_leaf));		memset(&tmphdr, 0, sizeof(tmphdr));		tmphdr.magic = savehdr.magic;		tmphdr.forw = savehdr.forw;		tmphdr.back = savehdr.back;		tmphdr.firstused = state->args->geo->blksize;		 		xfs_attr3_leaf_hdr_to_disk(state->args->geo, tmp_leaf, &tmphdr);		if (xfs_attr3_leaf_order(save_blk->bp, &savehdr,					 drop_blk->bp, &drophdr)) {			xfs_attr3_leaf_moveents(state->args,						drop_leaf, &drophdr, 0,						tmp_leaf, &tmphdr, 0,						drophdr.count);			xfs_attr3_leaf_moveents(state->args,						save_leaf, &savehdr, 0,						tmp_leaf, &tmphdr, tmphdr.count,						savehdr.count);		} else {			xfs_attr3_leaf_moveents(state->args,						save_leaf, &savehdr, 0,						tmp_leaf, &tmphdr, 0,						savehdr.count);			xfs_attr3_leaf_moveents(state->args,						drop_leaf, &drophdr, 0,						tmp_leaf, &tmphdr, tmphdr.count,						drophdr.count);		}		memcpy(save_leaf, tmp_leaf, state->args->geo->blksize);		savehdr = tmphdr;  		kmem_free(tmp_leaf);	}	xfs_attr3_leaf_hdr_to_disk(state->args->geo, save_leaf, &savehdr);	xfs_trans_log_buf(state->args->trans, save_blk->bp, 0,					   state->args->geo->blksize - 1);	 	entry = xfs_attr3_leaf_entryp(save_leaf);	save_blk->hashval = be32_to_cpu(entry[savehdr.count - 1].hashval);}",24638
54,363,CVE-2017-2647,17,"nfs_idmap_new(struct nfs_client *clp){	struct idmap *idmap;	struct rpc_pipe *pipe;	int error;	idmap = kzalloc(sizeof(*idmap), GFP_KERNEL);	if (idmap == NULL)		return -ENOMEM;	rpc_init_pipe_dir_object(&idmap->idmap_pdo,			&nfs_idmap_pipe_dir_object_ops,			idmap);	pipe = rpc_mkpipe_data(&idmap_upcall_ops, 0);	if (IS_ERR(pipe)) {		error = PTR_ERR(pipe);		goto err;	}	idmap->idmap_pipe = pipe;	mutex_init(&idmap->idmap_mutex);	error = rpc_add_pipe_dir_object(clp->cl_net,			&clp->cl_rpcclient->cl_pipedir_objects,			&idmap->idmap_pdo);	if (error)		goto err_destroy_pipe;	clp->cl_idmap = idmap;	return 0;err_destroy_pipe:	rpc_destroy_pipe_data(idmap->idmap_pipe);err:	kfree(idmap);	return error;}",22179
217,139,CVE-2016-6327,17,"static void srpt_srq_event(struct ib_event *event, void *ctx){	pr_info(""SRQ event %d\n"", event->event);}",16054
107,373,CVE-2017-2647,17,"int ceph_crypto_key_encode(struct ceph_crypto_key *key, void **p, void *end){	if (*p + sizeof(u16) + sizeof(key->created) +	    sizeof(u16) + key->len > end)		return -ERANGE;	ceph_encode_16(p, key->type);	ceph_encode_copy(p, &key->created, sizeof(key->created));	ceph_encode_16(p, key->len);	ceph_encode_copy(p, key->key, key->len);	return 0;}",22189
151,793,CVE-2019-12818,17,"void nfc_llcp_mac_is_down(struct nfc_dev *dev){	struct nfc_llcp_local *local;	local = nfc_llcp_find_local(dev);	if (local == NULL)		return;	local->remote_miu = LLCP_DEFAULT_MIU;	local->remote_lto = LLCP_DEFAULT_LTO;	 	nfc_llcp_socket_release(local, true, 0);}",26843
229,575,CVE-2018-1065,17,"icmp6_match(const struct sk_buff *skb, struct xt_action_param *par){	const struct icmp6hdr *ic;	struct icmp6hdr _icmph;	const struct ip6t_icmp *icmpinfo = par->matchinfo;	 	if (par->fragoff != 0)		return false;	ic = skb_header_pointer(skb, par->thoff, sizeof(_icmph), &_icmph);	if (ic == NULL) {		 		par->hotdrop = true;		return false;	}	return icmp6_type_code_match(icmpinfo->type,				     icmpinfo->code[0],				     icmpinfo->code[1],				     ic->icmp6_type, ic->icmp6_code,				     !!(icmpinfo->invflags&IP6T_ICMP_INV));}",25614
88,876,CVE-2019-11810,17,"static void megasas_sriov_heartbeat_handler(struct timer_list *t){	struct megasas_instance *instance =		from_timer(instance, t, sriov_heartbeat_timer);	if (instance->hb_host_mem->HB.fwCounter !=	    instance->hb_host_mem->HB.driverCounter) {		instance->hb_host_mem->HB.driverCounter =			instance->hb_host_mem->HB.fwCounter;		mod_timer(&instance->sriov_heartbeat_timer,			  jiffies + MEGASAS_SRIOV_HEARTBEAT_INTERVAL_VF);	} else {		dev_warn(&instance->pdev->dev, ""SR-IOV: Heartbeat never ""		       ""completed for scsi%d\n"", instance->host->host_no);		schedule_work(&instance->work_init);	}}",27041
100,247,CVE-2017-15306,17,"long kvmppc_alloc_lpid(void){	long lpid;	do {		lpid = find_first_zero_bit(lpid_inuse, KVMPPC_NR_LPIDS);		if (lpid >= nr_lpids) {			pr_err(""%s: No LPIDs free\n"", __func__);			return -ENOMEM;		}	} while (test_and_set_bit(lpid, lpid_inuse));	return lpid;}",20009
238,445,CVE-2018-1000879,17,"next_field(const char **p, const char **start,    const char **end, char *sep){	 	while (**p == ' ' || **p == '\t' || **p == '\n') {		(*p)++;	}	*start = *p;	 	while (**p != '\0' && **p != ',' && **p != ':' && **p != '\n' &&	    **p != '#') {		(*p)++;	}	*sep = **p;	 	if (*p == *start) {		*end = *p;	} else {		*end = *p - 1;		while (**end == ' ' || **end == '\t' || **end == '\n') {			(*end)--;		}		(*end)++;	}	 	if (*sep == '#') {		while (**p != '\0' && **p != ',' && **p != '\n') {			(*p)++;		}		*sep = **p;	}	 	if (**p != '\0')		(*p)++;}",23183
199,301,CVE-2017-9211,17,"static int skcipher_decrypt_ablkcipher(struct skcipher_request *req){	struct crypto_skcipher *skcipher = crypto_skcipher_reqtfm(req);	struct crypto_tfm *tfm = crypto_skcipher_tfm(skcipher);	struct ablkcipher_alg *alg = &tfm->__crt_alg->cra_ablkcipher;	return skcipher_crypt_ablkcipher(req, alg->decrypt);}",20770
205,333,CVE-2017-5668,17,"static void prpl_xfer_accept(struct file_transfer *ft){	struct prpl_xfer_data *px = ft->data;	purple_xfer_request_accepted(px->xfer, NULL);	prpl_xfer_write_request(ft);}",21981
235,563,CVE-2018-1065,17,"static int mark_source_chains(const struct xt_table_info *newinfo,			      unsigned int valid_hooks, void *entry0,			      unsigned int *offsets){	unsigned int hook;	 	for (hook = 0; hook < NF_ARP_NUMHOOKS; hook++) {		unsigned int pos = newinfo->hook_entry[hook];		struct arpt_entry *e = entry0 + pos;		if (!(valid_hooks & (1 << hook)))			continue;		 		e->counters.pcnt = pos;		for (;;) {			const struct xt_standard_target *t				= (void *)arpt_get_target_c(e);			int visited = e->comefrom & (1 << hook);			if (e->comefrom & (1 << NF_ARP_NUMHOOKS))				return 0;			e->comefrom				|= ((1 << hook) | (1 << NF_ARP_NUMHOOKS));			 			if ((unconditional(e) &&			     (strcmp(t->target.u.user.name,				     XT_STANDARD_TARGET) == 0) &&			     t->verdict < 0) || visited) {				unsigned int oldpos, size;				if ((strcmp(t->target.u.user.name,					    XT_STANDARD_TARGET) == 0) &&				    t->verdict < -NF_MAX_VERDICT - 1)					return 0;				 				do {					e->comefrom ^= (1<<NF_ARP_NUMHOOKS);					oldpos = pos;					pos = e->counters.pcnt;					e->counters.pcnt = 0;					 					if (pos == oldpos)						goto next;					e = entry0 + pos;				} while (oldpos == pos + e->next_offset);				 				size = e->next_offset;				e = entry0 + pos + size;				if (pos + size >= newinfo->size)					return 0;				e->counters.pcnt = pos;				pos += size;			} else {				int newpos = t->verdict;				if (strcmp(t->target.u.user.name,					   XT_STANDARD_TARGET) == 0 &&				    newpos >= 0) {					 					if (!xt_find_jump_offset(offsets, newpos,								 newinfo->number))						return 0;				} else {					 					newpos = pos + e->next_offset;					if (newpos >= newinfo->size)						return 0;				}				e = entry0 + newpos;				e->counters.pcnt = pos;				pos = newpos;			}		}next:		;	}	return 1;}",25602
9,685,CVE-2017-18079,17,static int i8042_wait_write(void){	int i = 0;	while ((i8042_read_status() & I8042_STR_IBF) && (i < I8042_CTL_TIMEOUT)) {		udelay(50);		i++;	}	return -(i == I8042_CTL_TIMEOUT);},26113
166,63,CVE-2016-10708,17,"choose_kex(struct kex *k, char *client, char *server){	const struct kexalg *kexalg;	k->name = match_list(client, server, NULL);	debug(""kex: algorithm: %s"", k->name ? k->name : ""(no match)"");	if (k->name == NULL)		return SSH_ERR_NO_KEX_ALG_MATCH;	if ((kexalg = kex_alg_by_name(k->name)) == NULL)		return SSH_ERR_INTERNAL_ERROR;	k->kex_type = kexalg->type;	k->hash_alg = kexalg->hash_alg;	k->ec_nid = kexalg->ec_nid;	return 0;}",2598
83,274,CVE-2017-13686,17,"static void ip_multipath_l3_keys(const struct sk_buff *skb,				 struct flow_keys *hash_keys){	const struct iphdr *outer_iph = ip_hdr(skb);	const struct iphdr *inner_iph;	const struct icmphdr *icmph;	struct iphdr _inner_iph;	struct icmphdr _icmph;	hash_keys->addrs.v4addrs.src = outer_iph->saddr;	hash_keys->addrs.v4addrs.dst = outer_iph->daddr;	if (likely(outer_iph->protocol != IPPROTO_ICMP))		return;	if (unlikely((outer_iph->frag_off & htons(IP_OFFSET)) != 0))		return;	icmph = skb_header_pointer(skb, outer_iph->ihl * 4, sizeof(_icmph),				   &_icmph);	if (!icmph)		return;	if (icmph->type != ICMP_DEST_UNREACH &&	    icmph->type != ICMP_REDIRECT &&	    icmph->type != ICMP_TIME_EXCEEDED &&	    icmph->type != ICMP_PARAMETERPROB)		return;	inner_iph = skb_header_pointer(skb,				       outer_iph->ihl * 4 + sizeof(_icmph),				       sizeof(_inner_iph), &_inner_iph);	if (!inner_iph)		return;	hash_keys->addrs.v4addrs.src = inner_iph->saddr;	hash_keys->addrs.v4addrs.dst = inner_iph->daddr;}",20243
57,446,CVE-2018-18585,17,"static void chmd_close(struct mschm_decompressor *base,		       struct mschmd_header *chm){  struct mschm_decompressor_p *self = (struct mschm_decompressor_p *) base;  struct mschmd_file *fi, *nfi;  struct mspack_system *sys;  unsigned int i;  if (!base) return;  sys = self->system;  self->error = MSPACK_ERR_OK;     for (fi = chm->files; fi; fi = nfi) {    nfi = fi->next;    sys->free(fi);  }  for (fi = chm->sysfiles; fi; fi = nfi) {    nfi = fi->next;    sys->free(fi);  }     if (self->d && (self->d->chm == chm)) {    if (self->d->infh) sys->close(self->d->infh);    if (self->d->state) lzxd_free(self->d->state);    sys->free(self->d);    self->d = NULL;  }     if (chm->chunk_cache) {      for (i = 0; i < chm->num_chunks; i++) sys->free(chm->chunk_cache[i]);      sys->free(chm->chunk_cache);  }  sys->free(chm);}",23478
80,985,CVE-2018-7191,17,"sch_handle_egress(struct sk_buff *skb, int *ret, struct net_device *dev){	struct tcf_proto *cl = rcu_dereference_bh(dev->egress_cl_list);	struct tcf_result cl_res;	if (!cl)		return skb;	 	qdisc_bstats_cpu_update(cl->q, skb);	switch (tcf_classify(skb, cl, &cl_res, false)) {	case TC_ACT_OK:	case TC_ACT_RECLASSIFY:		skb->tc_index = TC_H_MIN(cl_res.classid);		break;	case TC_ACT_SHOT:		qdisc_qstats_cpu_drop(cl->q);		*ret = NET_XMIT_DROP;		kfree_skb(skb);		return NULL;	case TC_ACT_STOLEN:	case TC_ACT_QUEUED:	case TC_ACT_TRAP:		*ret = NET_XMIT_SUCCESS;		consume_skb(skb);		return NULL;	case TC_ACT_REDIRECT:		 		skb_do_redirect(skb);		*ret = NET_XMIT_SUCCESS;		return NULL;	default:		break;	}	return skb;}",28035
155,861,CVE-2019-11810,17,"megasas_page_size_show(struct device *cdev,	struct device_attribute *attr, char *buf){	return snprintf(buf, PAGE_SIZE, ""%ld\n"", (unsigned long)PAGE_SIZE - 1);}",27026
191,638,CVE-2017-18241,17,"void write_data_page(struct dnode_of_data *dn, struct f2fs_io_info *fio){	struct f2fs_sb_info *sbi = fio->sbi;	struct f2fs_summary sum;	struct node_info ni;	f2fs_bug_on(sbi, dn->data_blkaddr == NULL_ADDR);	get_node_info(sbi, dn->nid, &ni);	set_summary(&sum, dn->nid, dn->ofs_in_node, ni.version);	do_write_page(&sum, fio);	f2fs_update_data_blkaddr(dn, fio->new_blkaddr);}",25750
213,624,CVE-2017-18241,17,"static void init_min_max_mtime(struct f2fs_sb_info *sbi){	struct sit_info *sit_i = SIT_I(sbi);	unsigned int segno;	mutex_lock(&sit_i->sentry_lock);	sit_i->min_mtime = LLONG_MAX;	for (segno = 0; segno < MAIN_SEGS(sbi); segno += sbi->segs_per_sec) {		unsigned int i;		unsigned long long mtime = 0;		for (i = 0; i < sbi->segs_per_sec; i++)			mtime += get_seg_entry(sbi, segno + i)->mtime;		mtime = div_u64(mtime, sbi->segs_per_sec);		if (sit_i->min_mtime > mtime)			sit_i->min_mtime = mtime;	}	sit_i->max_mtime = get_mtime(sbi);	mutex_unlock(&sit_i->sentry_lock);}",25736
79,381,CVE-2017-2647,17,static void rxrpc_destroy(struct key *key){	rxrpc_free_token_list(key->payload.data);},22197
194,142,CVE-2016-6327,17,"static void srpt_unmap_sg_to_ib_sge(struct srpt_rdma_ch *ch,				    struct srpt_send_ioctx *ioctx){	struct scatterlist *sg;	enum dma_data_direction dir;	BUG_ON(!ch);	BUG_ON(!ioctx);	BUG_ON(ioctx->n_rdma && !ioctx->rdma_wrs);	while (ioctx->n_rdma)		kfree(ioctx->rdma_wrs[--ioctx->n_rdma].wr.sg_list);	kfree(ioctx->rdma_wrs);	ioctx->rdma_wrs = NULL;	if (ioctx->mapped_sg_count) {		sg = ioctx->sg;		WARN_ON(!sg);		dir = ioctx->cmd.data_direction;		BUG_ON(dir == DMA_NONE);		ib_dma_unmap_sg(ch->sport->sdev->device, sg, ioctx->sg_cnt,				opposite_dma_dir(dir));		ioctx->mapped_sg_count = 0;	}}",16057
86,338,CVE-2017-2647,17,static void asymmetric_key_destroy(struct key *key){	struct asymmetric_key_subtype *subtype = asymmetric_key_subtype(key);	if (subtype) {		subtype->destroy(key->payload.data);		module_put(subtype->owner);		key->type_data.p[0] = NULL;	}	kfree(key->type_data.p[1]);	key->type_data.p[1] = NULL;},22154
34,426,CVE-2016-10147,17," static int mcryptd_hash_init_tfm(struct crypto_tfm *tfm){	struct crypto_instance *inst = crypto_tfm_alg_instance(tfm);	struct hashd_instance_ctx *ictx = crypto_instance_ctx(inst);	struct crypto_ahash_spawn *spawn = &ictx->spawn;	struct mcryptd_hash_ctx *ctx = crypto_tfm_ctx(tfm);	struct crypto_ahash *hash;	hash = crypto_spawn_ahash(spawn);	if (IS_ERR(hash))		return PTR_ERR(hash);	ctx->child = hash;	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),				 sizeof(struct mcryptd_hash_request_ctx) +				 crypto_ahash_reqsize(hash));	return 0;}",22546
2,147,CVE-2016-3120,17,"asn1length(unsigned char **astream){    int length;              int sublen;              int blen;                unsigned char *p;        if (**astream & 0x80) {        blen = **astream & 0x7f;        if (blen > 3) {            return(-1);        }        for (++*astream, length = 0; blen; ++*astream, blen--) {            length = (length << 8) | **astream;        }        if (length == 0) {                         p = *astream;            p++;            while (1) {                                 if ((sublen = asn1length(&p)) < 0) {                    return(-1);                }                p += sublen;                                 if ((!*p++) && (!*p)) {                    p++;                    break;                }            }            length = p - *astream;        }    } else {        length = **astream;        ++*astream;    }    return(length);}",17447
126,335,CVE-2017-5668,17,"static void prpl_xfer_free(struct file_transfer *ft){	struct prpl_xfer_data *px = ft->data;	struct purple_data *pd = px->ic->proto_data;	pd->filetransfers = g_slist_remove(pd->filetransfers, px);	if (px->xfer) {		px->xfer->ui_data = NULL;		purple_xfer_unref(px->xfer);	}	if (px->timeout) {		b_event_remove(px->timeout);	}	g_free(px->fn);	g_free(px->handle);	if (px->fd >= 0) {		close(px->fd);	}	g_free(px);}",21983
38,341,CVE-2017-2647,17,"void unregister_asymmetric_key_parser(struct asymmetric_key_parser *parser){	down_write(&asymmetric_key_parsers_sem);	list_del(&parser->link);	up_write(&asymmetric_key_parsers_sem);	pr_notice(""Asymmetric key parser '%s' unregistered\n"", parser->name);}",22157
102,548,CVE-2018-1066,17,"create_durable_v2_buf(struct cifs_fid *pfid){	struct create_durable_v2 *buf;	buf = kzalloc(sizeof(struct create_durable_v2), GFP_KERNEL);	if (!buf)		return NULL;	buf->ccontext.DataOffset = cpu_to_le16(offsetof					(struct create_durable_v2, dcontext));	buf->ccontext.DataLength = cpu_to_le32(sizeof(struct durable_context_v2));	buf->ccontext.NameOffset = cpu_to_le16(offsetof				(struct create_durable_v2, Name));	buf->ccontext.NameLength = cpu_to_le16(4);	buf->dcontext.Timeout = 0;  	buf->dcontext.Flags = cpu_to_le32(SMB2_DHANDLE_FLAG_PERSISTENT);	generate_random_uuid(buf->dcontext.CreateGuid);	memcpy(pfid->create_guid, buf->dcontext.CreateGuid, 16);	 	buf->Name[0] = 'D';	buf->Name[1] = 'H';	buf->Name[2] = '2';	buf->Name[3] = 'Q';	return buf;}",25587
142,960,CVE-2018-7191,17,"int napi_complete_done(struct napi_struct *n, int work_done){	unsigned long flags, val, new;	 	if (unlikely(n->state & (NAPIF_STATE_NPSVC |				 NAPIF_STATE_IN_BUSY_POLL)))		return false;	if (n->gro_list) {		unsigned long timeout = 0;		if (work_done)			timeout = n->dev->gro_flush_timeout;		if (timeout)			hrtimer_start(&n->timer, ns_to_ktime(timeout),				      HRTIMER_MODE_REL_PINNED);		else			napi_gro_flush(n, false);	}	if (unlikely(!list_empty(&n->poll_list))) {		 		local_irq_save(flags);		list_del_init(&n->poll_list);		local_irq_restore(flags);	}	do {		val = READ_ONCE(n->state);		WARN_ON_ONCE(!(val & NAPIF_STATE_SCHED));		new = val & ~(NAPIF_STATE_MISSED | NAPIF_STATE_SCHED);		 		new |= (val & NAPIF_STATE_MISSED) / NAPIF_STATE_MISSED *						    NAPIF_STATE_SCHED;	} while (cmpxchg(&n->state, val, new) != val);	if (unlikely(val & NAPIF_STATE_MISSED)) {		__napi_schedule(n);		return false;	}	return true;}",28010
27,193,CVE-2017-16532,17,"static int ch9_postconfig(struct usbtest_dev *dev){	struct usb_interface	*iface = dev->intf;	struct usb_device	*udev = interface_to_usbdev(iface);	int			i, alt, retval;	 	for (i = 0; i < iface->num_altsetting; i++) {		 		alt = iface->altsetting[i].desc.bAlternateSetting;		if (alt < 0 || alt >= iface->num_altsetting) {			dev_err(&iface->dev,					""invalid alt [%d].bAltSetting = %d\n"",					i, alt);		}		 		if (realworld && iface->num_altsetting == 1)			continue;		 		retval = set_altsetting(dev, alt);		if (retval) {			dev_err(&iface->dev, ""can't set_interface = %d, %d\n"",					alt, retval);			return retval;		}		 		retval = get_altsetting(dev);		if (retval != alt) {			dev_err(&iface->dev, ""get alt should be %d, was %d\n"",					alt, retval);			return (retval < 0) ? retval : -EDOM;		}	}	 	if (!realworld || udev->descriptor.bNumConfigurations != 1) {		int	expected = udev->actconfig->desc.bConfigurationValue;		 		retval = usb_control_msg(udev, usb_rcvctrlpipe(udev, 0),				USB_REQ_GET_CONFIGURATION,				USB_DIR_IN | USB_RECIP_DEVICE,				0, 0, dev->buf, 1, USB_CTRL_GET_TIMEOUT);		if (retval != 1 || dev->buf[0] != expected) {			dev_err(&iface->dev, ""get config --> %d %d (1 %d)\n"",				retval, dev->buf[0], expected);			return (retval < 0) ? retval : -EDOM;		}	}	 	retval = usb_get_descriptor(udev, USB_DT_DEVICE, 0,			dev->buf, sizeof(udev->descriptor));	if (retval != sizeof(udev->descriptor)) {		dev_err(&iface->dev, ""dev descriptor --> %d\n"", retval);		return (retval < 0) ? retval : -EDOM;	}	 	if (le16_to_cpu(udev->descriptor.bcdUSB) >= 0x0210) {		struct usb_bos_descriptor *bos = NULL;		struct usb_dev_cap_header *header = NULL;		unsigned total, num, length;		u8 *buf;		retval = usb_get_descriptor(udev, USB_DT_BOS, 0, dev->buf,				sizeof(*udev->bos->desc));		if (retval != sizeof(*udev->bos->desc)) {			dev_err(&iface->dev, ""bos descriptor --> %d\n"", retval);			return (retval < 0) ? retval : -EDOM;		}		bos = (struct usb_bos_descriptor *)dev->buf;		total = le16_to_cpu(bos->wTotalLength);		num = bos->bNumDeviceCaps;		if (total > TBUF_SIZE)			total = TBUF_SIZE;		 		retval = usb_get_descriptor(udev, USB_DT_BOS, 0, dev->buf,				total);		if (retval != total) {			dev_err(&iface->dev, ""bos descriptor set --> %d\n"",					retval);			return (retval < 0) ? retval : -EDOM;		}		length = sizeof(*udev->bos->desc);		buf = dev->buf;		for (i = 0; i < num; i++) {			buf += length;			if (buf + sizeof(struct usb_dev_cap_header) >					dev->buf + total)				break;			header = (struct usb_dev_cap_header *)buf;			length = header->bLength;			if (header->bDescriptorType !=					USB_DT_DEVICE_CAPABILITY) {				dev_warn(&udev->dev, ""not device capability descriptor, skip\n"");				continue;			}			switch (header->bDevCapabilityType) {			case USB_CAP_TYPE_EXT:				if (buf + USB_DT_USB_EXT_CAP_SIZE >						dev->buf + total ||						!is_good_ext(dev, buf)) {					dev_err(&iface->dev, ""bogus usb 2.0 extension descriptor\n"");					return -EDOM;				}				break;			case USB_SS_CAP_TYPE:				if (buf + USB_DT_USB_SS_CAP_SIZE >						dev->buf + total ||						!is_good_ss_cap(dev, buf)) {					dev_err(&iface->dev, ""bogus superspeed device capability descriptor\n"");					return -EDOM;				}				break;			case CONTAINER_ID_TYPE:				if (buf + USB_DT_USB_SS_CONTN_ID_SIZE >						dev->buf + total ||						!is_good_con_id(dev, buf)) {					dev_err(&iface->dev, ""bogus container id descriptor\n"");					return -EDOM;				}				break;			default:				break;			}		}	}	 	for (i = 0; i < udev->descriptor.bNumConfigurations; i++) {		retval = usb_get_descriptor(udev, USB_DT_CONFIG, i,				dev->buf, TBUF_SIZE);		if (!is_good_config(dev, retval)) {			dev_err(&iface->dev,					""config [%d] descriptor --> %d\n"",					i, retval);			return (retval < 0) ? retval : -EDOM;		}		 	}	 	if (le16_to_cpu(udev->descriptor.bcdUSB) == 0x0200) {		struct usb_qualifier_descriptor *d = NULL;		 		retval = usb_get_descriptor(udev,				USB_DT_DEVICE_QUALIFIER, 0, dev->buf,				sizeof(struct usb_qualifier_descriptor));		if (retval == -EPIPE) {			if (udev->speed == USB_SPEED_HIGH) {				dev_err(&iface->dev,						""hs dev qualifier --> %d\n"",						retval);				return retval;			}			 		} else if (retval != sizeof(struct usb_qualifier_descriptor)) {			dev_err(&iface->dev, ""dev qualifier --> %d\n"", retval);			return (retval < 0) ? retval : -EDOM;		} else			d = (struct usb_qualifier_descriptor *) dev->buf;		 		if (d) {			unsigned max = d->bNumConfigurations;			for (i = 0; i < max; i++) {				retval = usb_get_descriptor(udev,					USB_DT_OTHER_SPEED_CONFIG, i,					dev->buf, TBUF_SIZE);				if (!is_good_config(dev, retval)) {					dev_err(&iface->dev,						""other speed config --> %d\n"",						retval);					return (retval < 0) ? retval : -EDOM;				}			}		}	}	 	 	retval = usb_get_status(udev, USB_RECIP_DEVICE, 0, dev->buf);	if (retval) {		dev_err(&iface->dev, ""get dev status --> %d\n"", retval);		return retval;	}	 	retval = usb_get_status(udev, USB_RECIP_INTERFACE,			iface->altsetting[0].desc.bInterfaceNumber, dev->buf);	if (retval) {		dev_err(&iface->dev, ""get interface status --> %d\n"", retval);		return retval;	}	 	return 0;}",19751
197,704,CVE-2019-15923,17,"static void do_pcd_read(void){	pcd_busy = 1;	pcd_retries = 0;	pcd_transfer();	if (!pcd_count) {		next_request(0);		return;	}	pi_do_claimed(pcd_current->pi, pcd_start);}",26501
224,69,CVE-2016-10708,17,"kex_reset_dispatch(struct ssh *ssh){	ssh_dispatch_range(ssh, SSH2_MSG_TRANSPORT_MIN,	    SSH2_MSG_TRANSPORT_MAX, &kex_protocol_error);	ssh_dispatch_set(ssh, SSH2_MSG_KEXINIT, &kex_input_kexinit);}",2604
192,806,CVE-2019-12111,17,"static void printMAPOpcodeVersion1(const int *buf){	char map_addr[INET6_ADDRSTRLEN];	syslog(LOG_DEBUG, ""PCP MAP: v1 Opcode specific information. \n"");	syslog(LOG_DEBUG, ""MAP protocol: \t\t %d\n"", (int)buf[0] );	syslog(LOG_DEBUG, ""MAP int port: \t\t %d\n"", (int)READNU16(buf+4));	syslog(LOG_DEBUG, ""MAP ext port: \t\t %d\n"", (int)READNU16(buf+6));	syslog(LOG_DEBUG, ""MAP Ext IP: \t\t %s\n"", inet_ntop(AF_INET6,	       buf+8, map_addr, INET6_ADDRSTRLEN));}",26880
161,724,CVE-2019-15923,17,"static void pcd_req_sense(struct pcd_unit *cd, char *fun){	char rs_cmd[12] = { 0x03, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0 };	char buf[16];	int r, c;	r = pcd_command(cd, rs_cmd, 16, ""Request sense"");	mdelay(1);	if (!r)		pcd_completion(cd, buf, ""Request sense"");	cd->last_sense = -1;	c = 2;	if (!r) {		if (fun)			printk(""%s: %s: Sense key: %x, ASC: %x, ASQ: %x\n"",			       cd->name, fun, buf[2] & 0xf, buf[12], buf[13]);		c = buf[2] & 0xf;		cd->last_sense =		    c | ((buf[12] & 0xff) << 8) | ((buf[13] & 0xff) << 16);	}	if ((c == 2) || (c == 6))		cd->changed = 1;}",26521
45,654,CVE-2017-18079,17,"static int i8042_aux_write(struct serio *serio, unsigned char c){	struct i8042_port *port = serio->port_data;	return i8042_command(&c, port->mux == -1 ?					I8042_CMD_AUX_SEND :					I8042_CMD_MUX_SEND + port->mux);}",26082
103,27,CVE-2017-6210,17,"static int vrend_decode_create_ve(struct vrend_decode_ctx *ctx, int handle, int length){   struct pipe_vertex_element *ve = NULL;   int num_elements;   int i;   int ret;   if (length < 1)      return EINVAL;   if ((length - 1) % 4)      return EINVAL;   num_elements = (length - 1) / 4;   if (num_elements) {      ve = calloc(num_elements, sizeof(struct pipe_vertex_element));      if (!ve)         return ENOMEM;      for (i = 0; i < num_elements; i++) {         ve[i].src_offset = get_buf_entry(ctx, VIRGL_OBJ_VERTEX_ELEMENTS_V0_SRC_OFFSET(i));         ve[i].instance_divisor = get_buf_entry(ctx, VIRGL_OBJ_VERTEX_ELEMENTS_V0_INSTANCE_DIVISOR(i));         ve[i].vertex_buffer_index = get_buf_entry(ctx, VIRGL_OBJ_VERTEX_ELEMENTS_V0_VERTEX_BUFFER_INDEX(i));         if (ve[i].vertex_buffer_index >= PIPE_MAX_ATTRIBS)            return EINVAL;         ve[i].src_format = get_buf_entry(ctx, VIRGL_OBJ_VERTEX_ELEMENTS_V0_SRC_FORMAT(i));      }   }   ret = vrend_create_vertex_elements_state(ctx->grctx, handle, num_elements, ve);   FREE(ve);   return ret;}",1568
42,502,CVE-2018-13093,17,"xfs_queue_eofblocks(	struct xfs_mount *mp){	rcu_read_lock();	if (radix_tree_tagged(&mp->m_perag_tree, XFS_ICI_EOFBLOCKS_TAG))		queue_delayed_work(mp->m_eofblocks_workqueue,				   &mp->m_eofblocks_work,				   msecs_to_jiffies(xfs_eofb_secs * 1000));	rcu_read_unlock();}",24666
5,700,CVE-2019-15924,17,static void fm10k_set_num_queues(struct fm10k_intfc *interface){	 	if (fm10k_set_qos_queues(interface))		return;	 	fm10k_set_rss_queues(interface);},26497
26,153,CVE-2016-3070,17,"static int buffer_migrate_lock_buffers(struct buffer_head *head,							enum migrate_mode mode){	struct buffer_head *bh = head;	 	if (mode != MIGRATE_ASYNC) {		do {			get_bh(bh);			lock_buffer(bh);			bh = bh->b_this_page;		} while (bh != head);		return true;	}	 	do {		get_bh(bh);		if (!trylock_buffer(bh)) {			 			struct buffer_head *failed_bh = bh;			put_bh(failed_bh);			bh = head;			while (bh != failed_bh) {				unlock_buffer(bh);				put_bh(bh);				bh = bh->b_this_page;			}			return false;		}		bh = bh->b_this_page;	} while (bh != head);	return true;}",17457
211,676,CVE-2017-18079,17,"static void i8042_port_close(struct serio *serio){	int irq_bit;	int disable_bit;	const char *port_name;	if (serio == i8042_ports[I8042_AUX_PORT_NO].serio) {		irq_bit = I8042_CTR_AUXINT;		disable_bit = I8042_CTR_AUXDIS;		port_name = ""AUX"";	} else {		irq_bit = I8042_CTR_KBDINT;		disable_bit = I8042_CTR_KBDDIS;		port_name = ""KBD"";	}	i8042_ctr &= ~irq_bit;	if (i8042_command(&i8042_ctr, I8042_CMD_CTL_WCTR))		pr_warn(""Can't write CTR while closing %s port\n"", port_name);	udelay(50);	i8042_ctr &= ~disable_bit;	i8042_ctr |= irq_bit;	if (i8042_command(&i8042_ctr, I8042_CMD_CTL_WCTR))		pr_err(""Can't reactivate %s port\n"", port_name);	 	i8042_interrupt(0, NULL);}",26104
77,241,CVE-2017-15306,17,int kvm_arch_vcpu_runnable(struct kvm_vcpu *v){	return !!(v->arch.pending_exceptions) || kvm_request_pending(v);},20003
16,183,CVE-2013-4119,17,int credssp_sizeof_pub_key_auth(int length){	length = ber_sizeof_octet_string(length);	length += ber_sizeof_contextual_tag(length);	return length;},19373
175,678,CVE-2017-18079,17,"int i8042_remove_filter(int (*filter)(unsigned char data, unsigned char str,				       struct serio *port)){	unsigned long flags;	int ret = 0;	spin_lock_irqsave(&i8042_lock, flags);	if (i8042_platform_filter != filter) {		ret = -EINVAL;		goto out;	}	i8042_platform_filter = NULL;out:	spin_unlock_irqrestore(&i8042_lock, flags);	return ret;}",26106
122,295,CVE-2017-9211,17,"static int crypto_skcipher_report(struct sk_buff *skb, struct crypto_alg *alg){	return -ENOSYS;}",20764
174,9,CVE-2017-6210,17,static float uif(unsigned int ui){   union { float f; unsigned int ui; } myuif;   myuif.ui = ui;   return myuif.f;},1550
94,73,CVE-2016-10708,17,"kex_setup(struct ssh *ssh, char *proposal[PROPOSAL_MAX]){	int r;	if ((r = kex_new(ssh, proposal, &ssh->kex)) != 0)		return r;	if ((r = kex_send_kexinit(ssh)) != 0) {		 		kex_free(ssh->kex);		ssh->kex = NULL;		return r;	}	return 0;}",2608
239,932,CVE-2018-7191,17,"int __dev_change_flags(struct net_device *dev, unsigned int flags){	unsigned int old_flags = dev->flags;	int ret;	ASSERT_RTNL();	 	dev->flags = (flags & (IFF_DEBUG | IFF_NOTRAILERS | IFF_NOARP |			       IFF_DYNAMIC | IFF_MULTICAST | IFF_PORTSEL |			       IFF_AUTOMEDIA)) |		     (dev->flags & (IFF_UP | IFF_VOLATILE | IFF_PROMISC |				    IFF_ALLMULTI));	 	if ((old_flags ^ flags) & IFF_MULTICAST)		dev_change_rx_flags(dev, IFF_MULTICAST);	dev_set_rx_mode(dev);	 	ret = 0;	if ((old_flags ^ flags) & IFF_UP) {		if (old_flags & IFF_UP)			__dev_close(dev);		else			ret = __dev_open(dev);	}	if ((flags ^ dev->gflags) & IFF_PROMISC) {		int inc = (flags & IFF_PROMISC) ? 1 : -1;		unsigned int old_flags = dev->flags;		dev->gflags ^= IFF_PROMISC;		if (__dev_set_promiscuity(dev, inc, false) >= 0)			if (dev->flags != old_flags)				dev_set_rx_mode(dev);	}	 	if ((flags ^ dev->gflags) & IFF_ALLMULTI) {		int inc = (flags & IFF_ALLMULTI) ? 1 : -1;		dev->gflags ^= IFF_ALLMULTI;		__dev_set_allmulti(dev, inc, false);	}	return ret;}",27982
176,339,CVE-2017-2647,17,"static void asymmetric_key_free_preparse(struct key_preparsed_payload *prep){	struct asymmetric_key_subtype *subtype = prep->type_data[0];	pr_devel(""==>%s()\n"", __func__);	if (subtype) {		subtype->destroy(prep->payload[0]);		module_put(subtype->owner);	}	kfree(prep->type_data[1]);	kfree(prep->description);}",22155
112,10,CVE-2017-6210,17,"static int vrend_decode_begin_query(struct vrend_decode_ctx *ctx, int length){   if (length != 1)      return EINVAL;   int handle = get_buf_entry(ctx, VIRGL_QUERY_BEGIN_HANDLE);   vrend_begin_query(ctx->grctx, handle);   return 0;}",1551
36,878,CVE-2019-11810,17,"static int megasas_start_aen(struct megasas_instance *instance){	struct megasas_evt_log_info eli;	union megasas_evt_class_locale class_locale;	 	memset(&eli, 0, sizeof(eli));	if (megasas_get_seq_num(instance, &eli))		return -1;	 	class_locale.members.reserved = 0;	class_locale.members.locale = MR_EVT_LOCALE_ALL;	class_locale.members.class = MR_EVT_CLASS_DEBUG;	return megasas_register_aen(instance,			le32_to_cpu(eli.newest_seq_num) + 1,			class_locale.word);}",27043
148,396,CVE-2017-2647,17,"static int __key_instantiate_and_link(struct key *key,				      struct key_preparsed_payload *prep,				      struct key *keyring,				      struct key *authkey,				      struct assoc_array_edit **_edit){	int ret, awaken;	key_check(key);	key_check(keyring);	awaken = 0;	ret = -EBUSY;	mutex_lock(&key_construction_mutex);	 	if (!test_bit(KEY_FLAG_INSTANTIATED, &key->flags)) {		 		ret = key->type->instantiate(key, prep);		if (ret == 0) {			 			atomic_inc(&key->user->nikeys);			set_bit(KEY_FLAG_INSTANTIATED, &key->flags);			if (test_and_clear_bit(KEY_FLAG_USER_CONSTRUCT, &key->flags))				awaken = 1;			 			if (keyring)				__key_link(key, _edit);			 			if (authkey)				key_revoke(authkey);			if (prep->expiry != TIME_T_MAX) {				key->expiry = prep->expiry;				key_schedule_gc(prep->expiry + key_gc_delay);			}		}	}	mutex_unlock(&key_construction_mutex);	 	if (awaken)		wake_up_bit(&key->flags, KEY_FLAG_USER_CONSTRUCT);	return ret;}",22212
24,644,CVE-2017-18216,17,"int o2nm_configured_node_map(unsigned long *map, unsigned bytes){	struct o2nm_cluster *cluster = o2nm_single_cluster;	BUG_ON(bytes < (sizeof(cluster->cl_nodes_bitmap)));	if (cluster == NULL)		return -EINVAL;	read_lock(&cluster->cl_nodes_lock);	memcpy(map, cluster->cl_nodes_bitmap, sizeof(cluster->cl_nodes_bitmap));	read_unlock(&cluster->cl_nodes_lock);	return 0;}",25886
139,191,CVE-2017-16532,17,"alloc_sglist(int nents, int max, int vary, struct usbtest_dev *dev, int pipe){	struct scatterlist	*sg;	unsigned int		n_size = 0;	unsigned		i;	unsigned		size = max;	unsigned		maxpacket =		get_maxpacket(interface_to_usbdev(dev->intf), pipe);	if (max == 0)		return NULL;	sg = kmalloc_array(nents, sizeof(*sg), GFP_KERNEL);	if (!sg)		return NULL;	sg_init_table(sg, nents);	for (i = 0; i < nents; i++) {		char		*buf;		unsigned	j;		buf = kzalloc(size, GFP_KERNEL);		if (!buf) {			free_sglist(sg, i);			return NULL;		}		 		sg_set_buf(&sg[i], buf, size);		switch (pattern) {		case 0:			 			break;		case 1:			for (j = 0; j < size; j++)				*buf++ = (u8) (((j + n_size) % maxpacket) % 63);			n_size += size;			break;		}		if (vary) {			size += vary;			size %= max;			if (size == 0)				size = (vary < max) ? vary : max;		}	}	return sg;}",19749
20,832,CVE-2019-11810,17,"static int megasas_alloc_ctrl_mem(struct megasas_instance *instance){	instance->reply_map = kcalloc(nr_cpu_ids, sizeof(unsigned int),				      GFP_KERNEL);	if (!instance->reply_map)		return -ENOMEM;	switch (instance->adapter_type) {	case MFI_SERIES:		if (megasas_alloc_mfi_ctrl_mem(instance))			goto fail;		break;	case AERO_SERIES:	case VENTURA_SERIES:	case THUNDERBOLT_SERIES:	case INVADER_SERIES:		if (megasas_alloc_fusion_context(instance))			goto fail;		break;	}	return 0; fail:	kfree(instance->reply_map);	instance->reply_map = NULL;	return -ENOMEM;}",26997
117,668,CVE-2017-18079,17,void i8042_lock_chip(void){	mutex_lock(&i8042_mutex);},26096
230,737,CVE-2019-15922,17,"static void do_pf_write(void){	ps_set_intr(do_pf_write_start, NULL, 0, nice);}",26534
141,52,CVE-2017-6210,17,"int vrend_renderer_context_create(int handle, int nlen, const char *debug_name){   if (handle >= VREND_MAX_CTX)      return EINVAL;       if (handle == 0)      return EINVAL;   vrend_renderer_context_create_internal(handle, nlen, debug_name);   return 0;}",1593
207,687,CVE-2019-15924,17,"static int fm10k_alloc_q_vector(struct fm10k_intfc *interface,				unsigned int v_count, unsigned int v_idx,				unsigned int txr_count, unsigned int txr_idx,				unsigned int rxr_count, unsigned int rxr_idx){	struct fm10k_q_vector *q_vector;	struct fm10k_ring *ring;	int ring_count;	ring_count = txr_count + rxr_count;	 	q_vector = kzalloc(struct_size(q_vector, ring, ring_count), GFP_KERNEL);	if (!q_vector)		return -ENOMEM;	 	netif_napi_add(interface->netdev, &q_vector->napi,		       fm10k_poll, NAPI_POLL_WEIGHT);	 	interface->q_vector[v_idx] = q_vector;	q_vector->interface = interface;	q_vector->v_idx = v_idx;	 	ring = q_vector->ring;	 	q_vector->tx.ring = ring;	q_vector->tx.work_limit = FM10K_DEFAULT_TX_WORK;	q_vector->tx.itr = interface->tx_itr;	q_vector->tx.itr_scale = interface->hw.mac.itr_scale;	q_vector->tx.count = txr_count;	while (txr_count) {		 		ring->dev = &interface->pdev->dev;		ring->netdev = interface->netdev;		 		ring->q_vector = q_vector;		 		ring->count = interface->tx_ring_count;		ring->queue_index = txr_idx;		 		interface->tx_ring[txr_idx] = ring;		 		txr_count--;		txr_idx += v_count;		 		ring++;	}	 	q_vector->rx.ring = ring;	q_vector->rx.itr = interface->rx_itr;	q_vector->rx.itr_scale = interface->hw.mac.itr_scale;	q_vector->rx.count = rxr_count;	while (rxr_count) {		 		ring->dev = &interface->pdev->dev;		ring->netdev = interface->netdev;		rcu_assign_pointer(ring->l2_accel, interface->l2_accel);		 		ring->q_vector = q_vector;		 		ring->count = interface->rx_ring_count;		ring->queue_index = rxr_idx;		 		interface->rx_ring[rxr_idx] = ring;		 		rxr_count--;		rxr_idx += v_count;		 		ring++;	}	fm10k_dbg_q_vector_init(q_vector);	return 0;}",26484
204,981,CVE-2018-7191,17,"void netif_stacked_transfer_operstate(const struct net_device *rootdev,					struct net_device *dev){	if (rootdev->operstate == IF_OPER_DORMANT)		netif_dormant_on(dev);	else		netif_dormant_off(dev);	if (netif_carrier_ok(rootdev))		netif_carrier_on(dev);	else		netif_carrier_off(dev);}",28031
210,862,CVE-2019-11810,17,"megasas_queue_command(struct Scsi_Host *shost, struct scsi_cmnd *scmd){	struct megasas_instance *instance;	struct MR_PRIV_DEVICE *mr_device_priv_data;	instance = (struct megasas_instance *)	    scmd->device->host->hostdata;	if (instance->unload == 1) {		scmd->result = DID_NO_CONNECT << 16;		scmd->scsi_done(scmd);		return 0;	}	if (instance->issuepend_done == 0)		return SCSI_MLQUEUE_HOST_BUSY;	 	if (atomic_read(&instance->adprecovery) == MEGASAS_ADPRESET_SM_INFAULT) {		if (megasas_check_mpio_paths(instance, scmd) ==		    (DID_REQUEUE << 16)) {			return SCSI_MLQUEUE_HOST_BUSY;		} else {			scmd->result = DID_NO_CONNECT << 16;			scmd->scsi_done(scmd);			return 0;		}	}	if (atomic_read(&instance->adprecovery) == MEGASAS_HW_CRITICAL_ERROR) {		scmd->result = DID_NO_CONNECT << 16;		scmd->scsi_done(scmd);		return 0;	}	mr_device_priv_data = scmd->device->hostdata;	if (!mr_device_priv_data) {		scmd->result = DID_NO_CONNECT << 16;		scmd->scsi_done(scmd);		return 0;	}	if (atomic_read(&instance->adprecovery) != MEGASAS_HBA_OPERATIONAL)		return SCSI_MLQUEUE_HOST_BUSY;	if (mr_device_priv_data->tm_busy)		return SCSI_MLQUEUE_DEVICE_BUSY;	scmd->result = 0;	if (MEGASAS_IS_LOGICAL(scmd->device) &&	    (scmd->device->id >= instance->fw_supported_vd_count ||		scmd->device->lun)) {		scmd->result = DID_BAD_TARGET << 16;		goto out_done;	}	if ((scmd->cmnd[0] == SYNCHRONIZE_CACHE) &&	    MEGASAS_IS_LOGICAL(scmd->device) &&	    (!instance->fw_sync_cache_support)) {		scmd->result = DID_OK << 16;		goto out_done;	}	return instance->instancet->build_and_issue_cmd(instance, scmd); out_done:	scmd->scsi_done(scmd);	return 0;}",27027
69,125,CVE-2016-6327,17,"static int srpt_perform_rdmas(struct srpt_rdma_ch *ch,			      struct srpt_send_ioctx *ioctx){	struct ib_send_wr *bad_wr;	int sq_wr_avail, ret, i;	enum dma_data_direction dir;	const int n_rdma = ioctx->n_rdma;	dir = ioctx->cmd.data_direction;	if (dir == DMA_TO_DEVICE) {		 		ret = -ENOMEM;		sq_wr_avail = atomic_sub_return(n_rdma, &ch->sq_wr_avail);		if (sq_wr_avail < 0) {			pr_warn(""IB send queue full (needed %d)\n"",				n_rdma);			goto out;		}	}	for (i = 0; i < n_rdma; i++) {		struct ib_send_wr *wr = &ioctx->rdma_wrs[i].wr;		wr->opcode = (dir == DMA_FROM_DEVICE) ?				IB_WR_RDMA_WRITE : IB_WR_RDMA_READ;		if (i == n_rdma - 1) {			 			if (dir == DMA_TO_DEVICE) {				wr->send_flags = IB_SEND_SIGNALED;				ioctx->rdma_cqe.done = srpt_rdma_read_done;			} else {				ioctx->rdma_cqe.done = srpt_rdma_write_done;			}			wr->wr_cqe = &ioctx->rdma_cqe;			wr->next = NULL;		} else {			wr->wr_cqe = NULL;			wr->next = &ioctx->rdma_wrs[i + 1].wr;		}	}	ret = ib_post_send(ch->qp, &ioctx->rdma_wrs->wr, &bad_wr);	if (ret)		pr_err(""%s[%d]: ib_post_send() returned %d for %d/%d\n"",				 __func__, __LINE__, ret, i, n_rdma);out:	if (unlikely(dir == DMA_TO_DEVICE && ret < 0))		atomic_add(n_rdma, &ch->sq_wr_avail);	return ret;}",16040
39,543,CVE-2018-1066,17,"add_durable_reconnect_v2_context(struct kvec *iov, unsigned int *num_iovec,		    struct cifs_open_parms *oparms){	struct smb2_create_req *req = iov[0].iov_base;	unsigned int num = *num_iovec;	 	oparms->reconnect = false;	iov[num].iov_base = create_reconnect_durable_v2_buf(oparms->fid);	if (iov[num].iov_base == NULL)		return -ENOMEM;	iov[num].iov_len = sizeof(struct create_durable_handle_reconnect_v2);	if (!req->CreateContextsOffset)		req->CreateContextsOffset =			cpu_to_le32(sizeof(struct smb2_create_req) - 4 +								iov[1].iov_len);	le32_add_cpu(&req->CreateContextsLength,			sizeof(struct create_durable_handle_reconnect_v2));	inc_rfc1001_len(&req->hdr,			sizeof(struct create_durable_handle_reconnect_v2));	*num_iovec = num + 1;	return 0;}",25582
46,166,CVE-2016-3070,17,"static void remove_migration_ptes(struct page *old, struct page *new){	struct rmap_walk_control rwc = {		.rmap_one = remove_migration_pte,		.arg = old,	};	rmap_walk(new, &rwc);}",17470
144,786,CVE-2019-12818,17,"int nfc_llcp_send_rr(struct nfc_llcp_sock *sock){	struct sk_buff *skb;	struct nfc_llcp_local *local;	pr_debug(""Send rr nr %d\n"", sock->recv_n);	local = sock->local;	if (local == NULL)		return -ENODEV;	skb = llcp_allocate_pdu(sock, LLCP_PDU_RR, LLCP_SEQUENCE_SIZE);	if (skb == NULL)		return -ENOMEM;	skb_put(skb, LLCP_SEQUENCE_SIZE);	skb->data[2] = sock->recv_n;	skb_queue_head(&local->tx_queue, skb);	return 0;}",26836
63,208,CVE-2017-16532,17,"static int simple_io(	struct usbtest_dev	*tdev,	struct urb		*urb,	int			iterations,	int			vary,	int			expected,	const char		*label){	struct usb_device	*udev = urb->dev;	int			max = urb->transfer_buffer_length;	struct completion	completion;	int			retval = 0;	unsigned long		expire;	urb->context = &completion;	while (retval == 0 && iterations-- > 0) {		init_completion(&completion);		if (usb_pipeout(urb->pipe)) {			simple_fill_buf(urb);			urb->transfer_flags |= URB_ZERO_PACKET;		}		retval = usb_submit_urb(urb, GFP_KERNEL);		if (retval != 0)			break;		expire = msecs_to_jiffies(SIMPLE_IO_TIMEOUT);		if (!wait_for_completion_timeout(&completion, expire)) {			usb_kill_urb(urb);			retval = (urb->status == -ENOENT ?				  -ETIMEDOUT : urb->status);		} else {			retval = urb->status;		}		urb->dev = udev;		if (retval == 0 && usb_pipein(urb->pipe))			retval = simple_check_buf(tdev, urb);		if (vary) {			int	len = urb->transfer_buffer_length;			len += vary;			len %= max;			if (len == 0)				len = (vary < max) ? vary : max;			urb->transfer_buffer_length = len;		}		 	}	urb->transfer_buffer_length = max;	if (expected != retval)		dev_err(&udev->dev,			""%s failed, iterations left %d, status %d (not %d)\n"",				label, iterations, retval, expected);	return retval;}",19766
225,807,CVE-2019-12111,17,"static void printMAPOpcodeVersion2(const int *buf){	char map_addr[INET6_ADDRSTRLEN];	syslog(LOG_DEBUG, ""PCP MAP: v2 Opcode specific information."");	syslog(LOG_DEBUG, ""MAP nonce:   \t%08x%08x%08x"",	       READNU32(buf), READNU32(buf+4), READNU32(buf+8));	syslog(LOG_DEBUG, ""MAP protocol:\t%d"", (int)buf[12]);	syslog(LOG_DEBUG, ""MAP int port:\t%d"", (int)READNU16(buf+16));	syslog(LOG_DEBUG, ""MAP ext port:\t%d"", (int)READNU16(buf+18));	syslog(LOG_DEBUG, ""MAP Ext IP:  \t%s"", inet_ntop(AF_INET6,	       buf+20, map_addr, INET6_ADDRSTRLEN));}",26881
14,881,CVE-2019-11810,17,"support_nvme_encapsulation_show(struct device_driver *dd, char *buf){	return sprintf(buf, ""%u\n"", support_nvme_encapsulation);}",27046
156,789,CVE-2019-12818,17,"int nfc_llcp_data_received(struct nfc_dev *dev, struct sk_buff *skb){	struct nfc_llcp_local *local;	local = nfc_llcp_find_local(dev);	if (local == NULL) {		kfree_skb(skb);		return -ENODEV;	}	__nfc_llcp_recv(local, skb);	return 0;}",26839
223,722,CVE-2019-15923,17,"static int pcd_ready_wait(struct pcd_unit *cd, int tmo){	char tr_cmd[12] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };	int k, p;	k = 0;	while (k < tmo) {		cd->last_sense = 0;		pcd_atapi(cd, tr_cmd, 0, NULL, DBMSG(""test unit ready""));		p = cd->last_sense;		if (!p)			return 0;		if (!(((p & 0xffff) == 0x0402) || ((p & 0xff) == 6)))			return p;		k++;		pcd_sleep(HZ);	}	return 0x000020;	 }",26519
60,36,CVE-2017-6210,17,"static int vrend_decode_set_blend_color(struct vrend_decode_ctx *ctx, int length){   struct pipe_blend_color color;   int i;   if (length != VIRGL_SET_BLEND_COLOR_SIZE)      return EINVAL;   for (i = 0; i < 4; i++)      color.color[i] = uif(get_buf_entry(ctx, VIRGL_SET_BLEND_COLOR(i)));   vrend_set_blend_color(ctx->grctx, &color);   return 0;}",1577
51,695,CVE-2019-15924,17,static inline int fm10k_page_is_reserved(struct page *page){	return (page_to_nid(page) != numa_mem_id()) || page_is_pfmemalloc(page);},26492
222,204,CVE-2017-16532,17,"static int set_altsetting(struct usbtest_dev *dev, int alternate){	struct usb_interface		*iface = dev->intf;	struct usb_device		*udev;	if (alternate < 0 || alternate >= 256)		return -EINVAL;	udev = interface_to_usbdev(iface);	return usb_set_interface(udev,			iface->altsetting[0].desc.bInterfaceNumber,			alternate);}",19762
91,377,CVE-2017-2647,17,static void ceph_key_free_preparse(struct key_preparsed_payload *prep){	struct ceph_crypto_key *ckey = prep->payload[0];	ceph_crypto_key_destroy(ckey);	kfree(ckey);},22193
189,467,CVE-2018-13094,17,"xfs_attr3_leaf_add_work(	struct xfs_buf		*bp,	struct xfs_attr3_icleaf_hdr *ichdr,	struct xfs_da_args	*args,	int			mapindex){	struct xfs_attr_leafblock *leaf;	struct xfs_attr_leaf_entry *entry;	struct xfs_attr_leaf_name_local *name_loc;	struct xfs_attr_leaf_name_remote *name_rmt;	struct xfs_mount	*mp;	int			tmp;	int			i;	trace_xfs_attr_leaf_add_work(args);	leaf = bp->b_addr;	ASSERT(mapindex >= 0 && mapindex < XFS_ATTR_LEAF_MAPSIZE);	ASSERT(args->index >= 0 && args->index <= ichdr->count);	 	entry = &xfs_attr3_leaf_entryp(leaf)[args->index];	if (args->index < ichdr->count) {		tmp  = ichdr->count - args->index;		tmp *= sizeof(xfs_attr_leaf_entry_t);		memmove(entry + 1, entry, tmp);		xfs_trans_log_buf(args->trans, bp,		    XFS_DA_LOGRANGE(leaf, entry, tmp + sizeof(*entry)));	}	ichdr->count++;	 	mp = args->trans->t_mountp;	ASSERT(ichdr->freemap[mapindex].base < args->geo->blksize);	ASSERT((ichdr->freemap[mapindex].base & 0x3) == 0);	ASSERT(ichdr->freemap[mapindex].size >=		xfs_attr_leaf_newentsize(args, NULL));	ASSERT(ichdr->freemap[mapindex].size < args->geo->blksize);	ASSERT((ichdr->freemap[mapindex].size & 0x3) == 0);	ichdr->freemap[mapindex].size -= xfs_attr_leaf_newentsize(args, &tmp);	entry->nameidx = cpu_to_be16(ichdr->freemap[mapindex].base +				     ichdr->freemap[mapindex].size);	entry->hashval = cpu_to_be32(args->hashval);	entry->flags = tmp ? XFS_ATTR_LOCAL : 0;	entry->flags |= XFS_ATTR_NSP_ARGS_TO_ONDISK(args->flags);	if (args->op_flags & XFS_DA_OP_RENAME) {		entry->flags |= XFS_ATTR_INCOMPLETE;		if ((args->blkno2 == args->blkno) &&		    (args->index2 <= args->index)) {			args->index2++;		}	}	xfs_trans_log_buf(args->trans, bp,			  XFS_DA_LOGRANGE(leaf, entry, sizeof(*entry)));	ASSERT((args->index == 0) ||	       (be32_to_cpu(entry->hashval) >= be32_to_cpu((entry-1)->hashval)));	ASSERT((args->index == ichdr->count - 1) ||	       (be32_to_cpu(entry->hashval) <= be32_to_cpu((entry+1)->hashval)));	 	if (entry->flags & XFS_ATTR_LOCAL) {		name_loc = xfs_attr3_leaf_name_local(leaf, args->index);		name_loc->namelen = args->namelen;		name_loc->valuelen = cpu_to_be16(args->valuelen);		memcpy((char *)name_loc->nameval, args->name, args->namelen);		memcpy((char *)&name_loc->nameval[args->namelen], args->value,				   be16_to_cpu(name_loc->valuelen));	} else {		name_rmt = xfs_attr3_leaf_name_remote(leaf, args->index);		name_rmt->namelen = args->namelen;		memcpy((char *)name_rmt->name, args->name, args->namelen);		entry->flags |= XFS_ATTR_INCOMPLETE;		 		name_rmt->valuelen = 0;		name_rmt->valueblk = 0;		args->rmtblkno = 1;		args->rmtblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);		args->rmtvaluelen = args->valuelen;	}	xfs_trans_log_buf(args->trans, bp,	     XFS_DA_LOGRANGE(leaf, xfs_attr3_leaf_name(leaf, args->index),				   xfs_attr_leaf_entsize(leaf, args->index)));	 	if (be16_to_cpu(entry->nameidx) < ichdr->firstused)		ichdr->firstused = be16_to_cpu(entry->nameidx);	ASSERT(ichdr->firstused >= ichdr->count * sizeof(xfs_attr_leaf_entry_t)					+ xfs_attr3_leaf_hdr_size(leaf));	tmp = (ichdr->count - 1) * sizeof(xfs_attr_leaf_entry_t)					+ xfs_attr3_leaf_hdr_size(leaf);	for (i = 0; i < XFS_ATTR_LEAF_MAPSIZE; i++) {		if (ichdr->freemap[i].base == tmp) {			ichdr->freemap[i].base += sizeof(xfs_attr_leaf_entry_t);			ichdr->freemap[i].size -= sizeof(xfs_attr_leaf_entry_t);		}	}	ichdr->usedbytes += xfs_attr_leaf_entsize(leaf, args->index);	return 0;}",24631
164,619,CVE-2017-18241,17,"static int get_ssr_segment(struct f2fs_sb_info *sbi, int type){	struct curseg_info *curseg = CURSEG_I(sbi, type);	const struct victim_selection *v_ops = DIRTY_I(sbi)->v_ops;	unsigned segno = NULL_SEGNO;	int i, cnt;	int reversed = false;	 	if (v_ops->get_victim(sbi, &segno, BG_GC, type, SSR)) {		curseg->next_segno = segno;		return 1;	}	 	if (IS_NODESEG(type)) {		if (type >= CURSEG_WARM_NODE) {			reversed = true;			i = CURSEG_COLD_NODE;		} else {			i = CURSEG_HOT_NODE;		}		cnt = NR_CURSEG_NODE_TYPE;	} else {		if (type >= CURSEG_WARM_DATA) {			reversed = true;			i = CURSEG_COLD_DATA;		} else {			i = CURSEG_HOT_DATA;		}		cnt = NR_CURSEG_DATA_TYPE;	}	for (; cnt-- > 0; reversed ? i-- : i++) {		if (i == type)			continue;		if (v_ops->get_victim(sbi, &segno, BG_GC, i, SSR)) {			curseg->next_segno = segno;			return 1;		}	}	return 0;}",25731
244,926,CVE-2018-7191,17,"static void tun_set_real_num_queues(struct tun_struct *tun){	netif_set_real_num_tx_queues(tun->dev, tun->numqueues);	netif_set_real_num_rx_queues(tun->dev, tun->numqueues);}",27976
201,554,CVE-2018-1066,17,"smb2_new_read_req(void **buf, unsigned int *total_len,		  struct cifs_io_parms *io_parms, unsigned int remaining_bytes,		  int request_type){	int rc = -EACCES;	struct smb2_read_plain_req *req = NULL;	struct smb2_sync_hdr *shdr;	rc = smb2_plain_req_init(SMB2_READ, io_parms->tcon, (void **) &req,				 total_len);	if (rc)		return rc;	if (io_parms->tcon->ses->server == NULL)		return -ECONNABORTED;	shdr = &req->sync_hdr;	shdr->ProcessId = cpu_to_le32(io_parms->pid);	req->PersistentFileId = io_parms->persistent_fid;	req->VolatileFileId = io_parms->volatile_fid;	req->ReadChannelInfoOffset = 0;  	req->ReadChannelInfoLength = 0;  	req->Channel = 0;  	req->MinimumCount = 0;	req->Length = cpu_to_le32(io_parms->length);	req->Offset = cpu_to_le64(io_parms->offset);	if (request_type & CHAINED_REQUEST) {		if (!(request_type & END_OF_CHAIN)) {			 			*total_len = DIV_ROUND_UP(*total_len, 8) * 8;			shdr->NextCommand = cpu_to_le32(*total_len);		} else  			shdr->NextCommand = 0;		if (request_type & RELATED_REQUEST) {			shdr->Flags |= SMB2_FLAGS_RELATED_OPERATIONS;			 			shdr->SessionId = 0xFFFFFFFF;			shdr->TreeId = 0xFFFFFFFF;			req->PersistentFileId = 0xFFFFFFFF;			req->VolatileFileId = 0xFFFFFFFF;		}	}	if (remaining_bytes > io_parms->length)		req->RemainingBytes = cpu_to_le32(remaining_bytes);	else		req->RemainingBytes = 0;	*buf = req;	return rc;}",25593
70,917,CVE-2018-7191,17,static void tun_net_uninit(struct net_device *dev){	tun_detach_all(dev);},27967
62,602,CVE-2017-18241,17,"int commit_inmem_pages(struct inode *inode){	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);	struct f2fs_inode_info *fi = F2FS_I(inode);	struct list_head revoke_list;	int err;	INIT_LIST_HEAD(&revoke_list);	f2fs_balance_fs(sbi, true);	f2fs_lock_op(sbi);	set_inode_flag(inode, FI_ATOMIC_COMMIT);	mutex_lock(&fi->inmem_lock);	err = __commit_inmem_pages(inode, &revoke_list);	if (err) {		int ret;		 		ret = __revoke_inmem_pages(inode, &revoke_list, false, true);		if (ret)			err = ret;		 		__revoke_inmem_pages(inode, &fi->inmem_pages, true, false);	}	mutex_unlock(&fi->inmem_lock);	clear_inode_flag(inode, FI_ATOMIC_COMMIT);	f2fs_unlock_op(sbi);	return err;}",25714
158,949,CVE-2018-7191,17,"int dev_change_net_namespace(struct net_device *dev, struct net *net, const char *pat){	int err;	ASSERT_RTNL();	 	err = -EINVAL;	if (dev->features & NETIF_F_NETNS_LOCAL)		goto out;	 	if (dev->reg_state != NETREG_REGISTERED)		goto out;	 	err = 0;	if (net_eq(dev_net(dev), net))		goto out;	 	err = -EEXIST;	if (__dev_get_by_name(net, dev->name)) {		 		if (!pat)			goto out;		if (dev_get_valid_name(net, dev, pat) < 0)			goto out;	}	 	 	dev_close(dev);	 	err = -ENODEV;	unlist_netdevice(dev);	synchronize_net();	 	dev_shutdown(dev);	 	call_netdevice_notifiers(NETDEV_UNREGISTER, dev);	rcu_barrier();	call_netdevice_notifiers(NETDEV_UNREGISTER_FINAL, dev);	rtmsg_ifinfo(RTM_DELLINK, dev, ~0U, GFP_KERNEL);	 	dev_uc_flush(dev);	dev_mc_flush(dev);	 	kobject_uevent(&dev->dev.kobj, KOBJ_REMOVE);	netdev_adjacent_del_links(dev);	 	dev_net_set(dev, net);	 	if (__dev_get_by_index(net, dev->ifindex))		dev->ifindex = dev_new_index(net);	 	kobject_uevent(&dev->dev.kobj, KOBJ_ADD);	netdev_adjacent_add_links(dev);	 	err = device_rename(&dev->dev, dev->name);	WARN_ON(err);	 	list_netdevice(dev);	 	call_netdevice_notifiers(NETDEV_REGISTER, dev);	 	rtmsg_ifinfo(RTM_NEWLINK, dev, ~0U, GFP_KERNEL);	synchronize_net();	err = 0;out:	return err;}",27999
173,977,CVE-2018-7191,17,"void netdev_upper_dev_unlink(struct net_device *dev,			     struct net_device *upper_dev){	struct netdev_notifier_changeupper_info changeupper_info;	ASSERT_RTNL();	changeupper_info.upper_dev = upper_dev;	changeupper_info.master = netdev_master_upper_dev_get(dev) == upper_dev;	changeupper_info.linking = false;	call_netdevice_notifiers_info(NETDEV_PRECHANGEUPPER, dev,				      &changeupper_info.info);	__netdev_adjacent_dev_unlink_neighbour(dev, upper_dev);	call_netdevice_notifiers_info(NETDEV_CHANGEUPPER, dev,				      &changeupper_info.info);}",28027
130,314,CVE-2017-9211,17,"static inline void skcipher_unmap_dst(struct skcipher_walk *walk){	skcipher_unmap(&walk->out, walk->dst.virt.addr);}",20783
236,222,CVE-2017-15306,17,void kvm_arch_check_processor_compat(void *rtn){	*(int *)rtn = kvmppc_core_check_processor_compat();},19984
